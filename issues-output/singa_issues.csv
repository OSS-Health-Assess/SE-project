type,issue_url,comment_url,repo_name,id,issue_num,title,user_login,user_id,user_name,user_email,issue_state,created_at,updated_at,body,reactions
issue,https://api.github.com/repos/apache/singa/issues/576,https://api.github.com/repos/apache/singa/issues/576,singa,552688439,576,(i) Some bugs in autograd.py and (ii) test_operation.py needs updates,chrishkchris,38325429,Chris Yeung,,CLOSED,2020-01-21T08:08:53Z,2020-01-29T07:17:36Z,"Today when I run the singa/test/python/test_operation.py, I get these errors:

```
ubuntu@ip-172-31-24-48:~/singa/test/python$ python3 test_operation.py
..................................................................E.FF..............................FF.....FF................
======================================================================
ERROR: test_conv2d_cpu (__main__.TestPythonOperation)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""test_operation.py"", line 216, in test_conv2d_cpu
    y = conv_1(cpu_input_tensor)  # PyTensor
  File ""/home/ubuntu/singa/build/python/singa/autograd.py"", line 1380, in __call__
    y = conv2d(self.handle, x, self.W, self.b)
  File ""/home/ubuntu/singa/build/python/singa/autograd.py"", line 1241, in conv2d
    return _Conv2d(handle)(x, W, b)[0]
  File ""/home/ubuntu/singa/build/python/singa/autograd.py"", line 247, in __call__
    return self._do_forward(*xs)
  File ""/home/ubuntu/singa/build/python/singa/autograd.py"", line 298, in _do_forward
    ys = self.forward(*xs)
  File ""/home/ubuntu/singa/build/python/singa/autograd.py"", line 1203, in forward
    return singa.GpuConvForward(x, W, b, self.handle)
TypeError: in method 'GpuConvForward', argument 4 of type 'singa::CudnnConvHandle const &'

======================================================================
FAIL: test_div_broadcast_cpu (__main__.TestPythonOperation)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""test_operation.py"", line 2616, in test_div_broadcast_cpu
    np.testing.assert_array_almost_equal(tensor.to_numpy(tensor.from_raw_tensor(dx1)), grad1, decimal=5)
  File ""/usr/local/lib/python3.5/dist-packages/numpy/testing/_private/utils.py"", line 1007, in assert_array_almost_equal
    precision=decimal)
  File ""/usr/local/lib/python3.5/dist-packages/numpy/testing/_private/utils.py"", line 819, in assert_array_compare
    raise AssertionError(msg)
AssertionError:
Arrays are not almost equal to 5 decimals

Mismatch: 3.33%
Max absolute difference: 3.0517578e-05
Max relative difference: 9.684139e-07
 x: array([[-1.30722e+01,  2.65515e+00, -6.92423e-02, -2.97908e-01,
         6.12429e+00,  3.71461e-01],
       [ 1.33601e+01, -4.65283e+00, -4.74600e-01, -9.15998e-01,...
 y: array([[-1.30722e+01,  2.65515e+00, -6.92423e-02, -2.97908e-01,
         6.12429e+00,  3.71461e-01],
       [ 1.33601e+01, -4.65283e+00, -4.74600e-01, -9.15998e-01,...

======================================================================
FAIL: test_div_broadcast_gpu (__main__.TestPythonOperation)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""test_operation.py"", line 2584, in test_div_broadcast_gpu
    np.testing.assert_array_almost_equal(tensor.to_numpy(tensor.from_raw_tensor(dx1)), grad1, decimal=5)
  File ""/usr/local/lib/python3.5/dist-packages/numpy/testing/_private/utils.py"", line 1007, in assert_array_almost_equal
    precision=decimal)
  File ""/usr/local/lib/python3.5/dist-packages/numpy/testing/_private/utils.py"", line 819, in assert_array_compare
    raise AssertionError(msg)
AssertionError:
Arrays are not almost equal to 5 decimals

Mismatch: 40%
Max absolute difference: 6.1035156e-05
Max relative difference: 3.51512e-07
 x: array([-173.63599,  -30.95938,  139.375  ,   -4.83802,   -2.26971],
      dtype=float32)
 y: array([-173.63605,  -30.95938,  139.37502,   -4.83802,   -2.26971],
      dtype=float32)

======================================================================
FAIL: test_pow_broadcast_cpu (__main__.TestPythonOperation)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""test_operation.py"", line 2678, in test_pow_broadcast_cpu
    np.testing.assert_array_almost_equal(tensor.to_numpy(tensor.from_raw_tensor(dx1)), grad1, decimal=5)
  File ""/usr/local/lib/python3.5/dist-packages/numpy/testing/_private/utils.py"", line 1007, in assert_array_almost_equal
    precision=decimal)
  File ""/usr/local/lib/python3.5/dist-packages/numpy/testing/_private/utils.py"", line 819, in assert_array_compare
    raise AssertionError(msg)
AssertionError:
Arrays are not almost equal to 5 decimals

Mismatch: 40%
Max absolute difference: 6.1035156e-05
Max relative difference: 1.3951524e-07
 x: array([ 169.04495, -238.43016, 1852.8772 ,  437.48016,  -20.75186],
      dtype=float32)
 y: array([ 169.04497, -238.43016, 1852.8772 ,  437.48022,  -20.75186],
      dtype=float32)

======================================================================
FAIL: test_pow_broadcast_gpu (__main__.TestPythonOperation)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""test_operation.py"", line 2645, in test_pow_broadcast_gpu
    np.testing.assert_array_almost_equal(tensor.to_numpy(result), y, decimal=5)
  File ""/usr/local/lib/python3.5/dist-packages/numpy/testing/_private/utils.py"", line 1007, in assert_array_almost_equal
    precision=decimal)
  File ""/usr/local/lib/python3.5/dist-packages/numpy/testing/_private/utils.py"", line 819, in assert_array_compare
    raise AssertionError(msg)
AssertionError:
Arrays are not almost equal to 5 decimals

Mismatch: 6.67%
Max absolute difference: 6.1035156e-05
Max relative difference: 8.3724494e-08
 x: array([[[  1.     , 216.     ,  64.     ,  36.     , 343.     ],
        [ 27.     , 125.     , 512.     ,  36.     , 343.     ],
        [  1.     , 343.     ,   1.     ,  81.     , 343.     ],...
 y: array([[[  1., 216.,  64.,  36., 343.],
        [ 27., 125., 512.,  36., 343.],
        [  1., 343.,   1.,  81., 343.],...

======================================================================
FAIL: test_reshape_cpu (__main__.TestPythonOperation)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""test_operation.py"", line 1455, in test_reshape_cpu
    np.testing.assert_array_almost_equal(tensor.to_numpy(tensor.from_raw_tensor(dx)), grad, decimal=5)
  File ""/usr/local/lib/python3.5/dist-packages/numpy/testing/_private/utils.py"", line 1007, in assert_array_almost_equal
    precision=decimal)
  File ""/usr/local/lib/python3.5/dist-packages/numpy/testing/_private/utils.py"", line 752, in assert_array_compare
    raise AssertionError(msg)
AssertionError:
Arrays are not almost equal to 5 decimals

(shapes (2, 3), (3, 2) mismatch)
 x: array([[1., 1., 1.],
       [1., 1., 1.]], dtype=float32)
 y: array([[1., 1.],
       [1., 1.],
       [1., 1.]], dtype=float32)

======================================================================
FAIL: test_reshape_gpu (__main__.TestPythonOperation)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""test_operation.py"", line 1475, in test_reshape_gpu
    np.testing.assert_array_almost_equal(tensor.to_numpy(tensor.from_raw_tensor(dx)), grad, decimal=5)
  File ""/usr/local/lib/python3.5/dist-packages/numpy/testing/_private/utils.py"", line 1007, in assert_array_almost_equal
    precision=decimal)
  File ""/usr/local/lib/python3.5/dist-packages/numpy/testing/_private/utils.py"", line 752, in assert_array_compare
    raise AssertionError(msg)
AssertionError:
Arrays are not almost equal to 5 decimals

(shapes (2, 3), (3, 2) mismatch)
 x: array([[1., 1., 1.],
       [1., 1., 1.]], dtype=float32)
 y: array([[1., 1.],
       [1., 1.],
       [1., 1.]], dtype=float32)

----------------------------------------------------------------------
Ran 125 tests in 0.586s

FAILED (failures=6, errors=1)

```","{""url"": ""https://api.github.com/repos/apache/singa/issues/576/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/576,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU3Njk4ODgxNA==,singa,576988814,576,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-01-22T03:17:01Z,2020-01-22T03:17:01Z,"A highlight is why the reshaped tensor have different shape?
see test_reshape_gpu

Then, other test failure should be due to very small numerical errors (order of 1e-5) that can be fixed by reducing the number of significant in comparison.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU3Njk4ODgxNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/576,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU3Njk5NDEzNA==,singa,576994134,576,NA,dcslin,13751447,Shicong,,NA,2020-01-22T03:42:35Z,2020-01-22T03:42:35Z,should we make travis build fail when encountering errors raised from python unit test?,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU3Njk5NDEzNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/576,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU3Njk5NDgxNQ==,singa,576994815,576,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-01-22T03:46:25Z,2020-01-22T03:46:25Z,"

> should we make travis build fail when encountering errors raised from python unit test?

In my opinion, this is a very good feature. However, I am not sure if the machine that runs the test case by travis has GPU.
On the other hand, this test_operation.py is still important because it lets the developers to check whether the system has any problem after their commits.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU3Njk5NDgxNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/576,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU3NzAwMzk1Nw==,singa,577003957,576,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-01-22T04:38:31Z,2020-01-22T04:38:31Z,"If I am correct, the reshape is due to the error in backward:

```
class Reshape(Operation):

    def __init__(self,shape):
        super(Reshape, self).__init__()
        if isinstance(shape, tensor.Tensor):
            self.shape = np.asarray(tensor.to_numpy(shape).astype(np.int32)).tolist()
        else:
            self.shape = list(shape)

    def forward(self, x):
        _shape = x.shape()
        shape = self.shape
        # handle the shape with 0
        shape = [_shape[i] if i < len(_shape) and shape[i] == 0 else shape[i] for i in range(len(shape))]
        # handle the shape with -1
        hidden_shape = int(np.prod(_shape) // np.abs(np.prod(shape)))
        self.cache=[s if s != -1 else hidden_shape for s in shape]
        return singa.Reshape(x, self.cache)

    def backward(self, dy):
        return singa.Reshape(dy, self.cache)
```

I think the function should change to 
```
class Reshape(Operation):
    def __init__(self,shape):
        super(Reshape, self).__init__()
        if isinstance(shape, tensor.Tensor):
            self.shape = np.asarray(tensor.to_numpy(shape).astype(np.int32)).tolist()
        else:
            self.shape = list(shape)

    def forward(self, x):
        self._shape = x.shape()
        shape = self.shape
        # handle the shape with 0
        shape = [self._shape[i] if i < len(self._shape) and shape[i] == 0 else shape[i] for i in range(len(shape))]
        # handle the shape with -1
        hidden_shape = int(np.prod(self._shape) // np.abs(np.prod(shape)))
        self.cache=[s if s != -1 else hidden_shape for s in shape]

        return singa.Reshape(x, self.cache)

    def backward(self, dy):
        return singa.Reshape(dy, self._shape)

```","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU3NzAwMzk1Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/576,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU3NzAzNzMzNA==,singa,577037334,576,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-01-22T07:00:32Z,2020-01-22T07:00:32Z,"To resolve the problem completely, I opened a hotfix at PR #579 ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU3NzAzNzMzNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/576,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU3OTYyNTg5OA==,singa,579625898,576,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-01-29T07:17:35Z,2020-01-29T07:17:35Z,the problem is resolved completely,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU3OTYyNTg5OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/578,https://api.github.com/repos/apache/singa/issues/578,singa,553286561,578,The autograd.softmax has some problems,chrishkchris,38325429,Chris Yeung,,CLOSED,2020-01-22T03:30:56Z,2020-02-12T02:36:54Z,"The autograd.softmax may have some problem, where I found it when I took part in the review of PR #572.

In examples/autograd/mlp.py (multilayer perception), the result is:

```
ubuntu@ip-172-31-26-47:~/singa/examples/autograd$ python3 mlp.py
train_data_shape: (400, 2)
train_label_shape: (400, 2)
training loss =  0.6908062
training loss =  0.5960194
training loss =  0.57797414
training loss =  0.55334115
training loss =  0.48568404
training loss =  0.38458923
training loss =  0.30776194
training loss =  0.24188559
training loss =  0.18657134
training loss =  0.15864176
training loss =  0.13929243
```

However, if I use softmax + cross_entropy instead of softmax_cross_entropy, there is such error:

```
ubuntu@ip-172-31-26-47:~/singa/examples/autograd$ python3 mlp.py
train_data_shape: (400, 2)
train_label_shape: (400, 2)
training loss =  6.682101
WARNING: Logging before InitGoogleLogging() is written to STDERR
F0113 09:20:05.180658 12032 tensor_math_cpp.h:357] Check failed: a > 0.f (-nan vs. 0)
*** Check failure stack trace: ***
Aborted (core dumped)
```

In the review of PR #572, I did not suspect SoftMax because I compared the 1-D result with Pytorch. However, now when I run the result with 2-D input, the backpropagation cannot with parameter axis = 1.

My test codes and results for softmax are in:
https://gist.github.com/chrishkchris/1bce55260b5e771ce974940a855292e2

I will need to further see how to debug.  ","{""url"": ""https://api.github.com/repos/apache/singa/issues/578/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/578,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4MDY1ODg3OQ==,singa,580658879,578,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-01-31T09:36:54Z,2020-01-31T09:36:54Z,The numpy code in SoftMax backward has some error. This error will be resolved by changing numpy to CUDNN and DNNL using PR #588,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4MDY1ODg3OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/578,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDk5MDA4Mw==,singa,584990083,578,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-02-12T02:36:54Z,2020-02-12T02:36:54Z,addressed by PR #588,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDk5MDA4Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/583,https://api.github.com/repos/apache/singa/issues/583,singa,556881663,583,"The padding of Conv2d and Pool22 not support SAME_UPPER, SAME_LOWER",joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,CLOSED,2020-01-29T14:01:47Z,2020-03-08T12:41:07Z,"Now the singa's padding is, we assign a value, and it adds the amount of value's padding at both sides of head and tail.

However, according to the [onnx doc](https://github.com/onnx/onnx/blob/master/docs/Operators.md#Conv), there are four types of padding method, which are NOTSET, SAME_UPPER, SAME_LOWER or VALID. Singa cannot support SAME_UPPER, SAME_LOWER yet.

> SAME_UPPER or SAME_LOWER mean pad the input so that the output spatial size match the input. In case of an odd number add the extra padding at the end for SAME_UPPER and at the beginning for SAME_LOWER.

For example, the input is 32\*32, the stride is 1, the kernel is 4\*4, and output is same, we need to add (3,3) zeros totally, each side is 3/2 = 1.5, cannot work basing on the current setting of singa.
","{""url"": ""https://api.github.com/repos/apache/singa/issues/583/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/583,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5NjE3NDIyNA==,singa,596174224,583,NA,nudles,3797447,Wei Wang,,NA,2020-03-08T07:06:37Z,2020-03-08T07:06:37Z,@joddiy Has the issues been fixed?,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5NjE3NDIyNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/583,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5NjIwMTM2NQ==,singa,596201365,583,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-03-08T12:41:04Z,2020-03-08T12:41:04Z,"yes, by PR #612 ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5NjIwMTM2NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/584,https://api.github.com/repos/apache/singa/issues/584,singa,557338025,584,Make the project name consistent,nudles,3797447,Wei Wang,,OPEN,2020-01-30T08:30:05Z,2020-01-30T08:30:05Z,"In both the codes and documentation, we need to make the project name consistent. 
The official name of the project is `SINGA`, but sometimes we have to use `singa` like for the url or github repo name.
So I suggest to use `SINGA` (e.g., in documentation) and `singa` (e.g., in codes), and avoid `Singa`","{""url"": ""https://api.github.com/repos/apache/singa/issues/584/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/585,https://api.github.com/repos/apache/singa/issues/585,singa,557366177,585,"Release, versioning and continous integration",nudles,3797447,Wei Wang,,OPEN,2020-01-30T09:27:34Z,2020-03-31T14:31:45Z,"1. We are following the [semantic versioning scheme](https://semver.org/) (i.e., X.Y.Z) , which means every hotfix will bump the version number to X.Y.(Z+1). 
2. To support it, we need continuous integration which tracks the master branch to update the version number and generate the conda packages.
3. For updates to the dev branch, we also need the continuous integration tool to run the test and generate the nightly builds (conda packages).
4. Currently, we have Travis (for CPU) and Jenkins (CPU). They need to be updated to support 1, 2 and 3.","{""url"": ""https://api.github.com/repos/apache/singa/issues/585/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/585,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5MDIxMjc3OA==,singa,590212778,585,NA,dcslin,13751447,Shicong,,NA,2020-02-24T08:30:59Z,2020-02-24T08:30:59Z,"Hi @nudles , is it possible to access the machine running jenkins?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5MDIxMjc3OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/585,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5MDIyNDk5NQ==,singa,590224995,585,NA,dcslin,13751447,Shicong,,NA,2020-02-24T09:06:50Z,2020-02-24T09:06:50Z,"I have studied how fastai release process works, and semantic versioning and etc.

In my opinion, this topic involves 2 roles:
1. developers code, commit, and send PR to `singa:master` or `singa:dev`. For each PR, CI compiles, builds(conda), tests and returns pass/fail.

2. supervisors make release, and decide if the release is a patch, minor, major. There should be some automation here, supervisors then can just run command like `$ make release-patch` or `$ make release-minor`.

The automation should do
a) checkout to latest singa:master (the code merged in latest master should pass CI)
b) define `new_version` <-- semantic versioning
c) `git tag new_version && git push new_version`
d) build anaconda package and upload to anaconda cloud

If this approach is ok, then we need to add automation part.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5MDIyNDk5NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/585,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5MzcyMjk4NQ==,singa,593722985,585,NA,dcslin,13751447,Shicong,,NA,2020-03-03T01:45:51Z,2020-03-03T01:45:51Z,"Hi @nudles , how release is done currently?  is this flag ""TRAVIS_SECURE_ENV_VARS"" (tool/travis/build.sh line 41) used?
``` bash
if [[ ""$TRAVIS_SECURE_ENV_VARS"" == ""false"" ]];
  # install and run unittest
then
  echo ""no uploading if ANACONDA_UPLOAD_TOKEN not set""
else
  # turn off debug to hide the token in travis log
  set +x
  # upload the package onto anaconda cloud
  anaconda -t $ANACONDA_UPLOAD_TOKEN upload -u $USER -l main $CONDA_BLD_PATH/$OS/singa-*.tar.bz2 --force
fi
```","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5MzcyMjk4NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/585,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5Mzc2NTA4NA==,singa,593765084,585,NA,nudles,3797447,Wei Wang,,NA,2020-03-03T04:44:10Z,2020-03-03T04:44:10Z,"Yes. Currently, we use Travis to build CPU package and Jenkins to build GPU package. 
If the TRAVIS_SECURE_ENV_VARS is available, the package will be uploaded to the cloud.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5Mzc2NTA4NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/585,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5Mzc3NDU2NQ==,singa,593774565,585,NA,dcslin,13751447,Shicong,,NA,2020-03-03T05:27:03Z,2020-03-03T05:27:03Z,"> Yes. Currently, we use Travis to build CPU package and Jenkins to build GPU package.
> If the TRAVIS_SECURE_ENV_VARS is available, the package will be uploaded to the cloud.

Currently, how is the ""release"" build triggered or how is the Env Var TRAVIS_SECURE_ENV_VARS set? for travis is it done by web UI? https://blog.travis-ci.com/2017-08-24-trigger-custom-build","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5Mzc3NDU2NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/585,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5Mzc4NjU1Nw==,singa,593786557,585,NA,nudles,3797447,Wei Wang,,NA,2020-03-03T06:14:47Z,2020-03-03T06:14:47Z,"The travis for apache/singa does not upload the package because the variable is not set.
In jenkins, we sync the master branch to nusdbsystem/singa, whose travis will do the building and send the package to the cloud.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5Mzc4NjU1Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/585,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5Njg4NTgyOA==,singa,596885828,585,NA,dcslin,13751447,Shicong,,NA,2020-03-10T03:39:14Z,2020-03-10T03:39:14Z,"Hi @nudles , could you kindly advise if this PR caters this issue?
https://github.com/apache/singa/pull/621
usage: https://github.com/apache/singa/blob/d25539e16b6f3551ad6b1e2a74713025e150d30c/tool/release/README.md","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5Njg4NTgyOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/585,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5NjkzMzY5MQ==,singa,596933691,585,NA,nudles,3797447,Wei Wang,,NA,2020-03-10T06:58:47Z,2020-03-10T06:58:47Z,"1. if the building of the conda package fails, we need to delete the newly updated tag? Alternatively, we may need to consider a pre-release version like 3.0.0-alpha0.  Then, we need to parse the version ID with `-alphaX`. 
2. both the CMake and Conda building scripts need to parse the version from the git tag.
3. The CI needs to monitor both the dev and master branch. Only when the tag of the master branch changes, it uploads the pacakges (and docker images?).","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5NjkzMzY5MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/585,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5ODEwOTE0MQ==,singa,598109141,585,NA,moazreyad,2278792,Moaz Reyad,moazreyad@gmail.com,NA,2020-03-12T10:16:50Z,2020-03-12T10:16:50Z,"> 1. if the building of the conda package fails, we need to delete the newly updated tag? Alternatively, we may need to consider a pre-release version like 3.0.0-alpha0.  Then, we need to parse the version ID with `-alphaX`.
> 2. both the CMake and Conda building scripts need to parse the version from the git tag.
> 3. The CI needs to monitor both the dev and master branch. Only when the tag of the master branch changes, it uploads the pacakges (and docker images?).

All of this can be easily done with [Github Actions](https://github.com/features/actions). The CI in Github can be configured to monitor a given branch. There are many actions available for use that manage the [version tags](https://github.com/sdras/awesome-actions#semantic-versioning), [create docker containers](https://github.com/sdras/awesome-actions#docker-container-actions) and so on. ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5ODEwOTE0MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/585,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5ODUyMzQ0OQ==,singa,598523449,585,NA,dcslin,13751447,Shicong,,NA,2020-03-13T02:54:40Z,2020-03-13T02:54:40Z,"Hi @moazreyad , thank you for the advice, I will study how github actions works. ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5ODUyMzQ0OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/585,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5ODUyNTM1Mg==,singa,598525352,585,NA,dcslin,13751447,Shicong,,NA,2020-03-13T03:02:44Z,2020-03-13T03:02:44Z,"> 1. if the building of the conda package fails, we need to delete the newly updated tag? Alternatively, we may need to consider a pre-release version like 3.0.0-alpha0.  Then, we need to parse the version ID with `-alphaX`.
> 2. both the CMake and Conda building scripts need to parse the version from the git tag.
> 3. The CI needs to monitor both the dev and master branch. Only when the tag of the master branch changes, it uploads the pacakges (and docker images?).

Regarding 1, after comparing other framework, like tf. 
- For `major` release, they have `alpha` and `beta`, then followed by `rc`, release candidate.
- And for `minor`, pre release starts from `rc`. 
- While `patch` will be released directly.

For torch, similarily:
- `major` starts from `alpha`, followed by `rc`
- `minor` starts from `rc`
- patch is released directly.

By right, simply speaking, `alpha` is first phase of testing internally. `beta` is testing publicly. `rc` is almost like stable release unless serious bug is discovered.
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5ODUyNTM1Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/585,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5ODUyNjYyNA==,singa,598526624,585,NA,nudles,3797447,Wei Wang,,NA,2020-03-13T03:06:59Z,2020-03-13T03:06:59Z,"Since everything here is public, we do not have an internal testing phase.
I suggest skipping alpha and beta versions.

On Fri, Mar 13, 2020 at 11:03 AM Shicong <notifications@github.com> wrote:

>
>    1. if the building of the conda package fails, we need to delete the
>    newly updated tag? Alternatively, we may need to consider a pre-release
>    version like 3.0.0-alpha0. Then, we need to parse the version ID with
>    -alphaX.
>    2. both the CMake and Conda building scripts need to parse the version
>    from the git tag.
>    3. The CI needs to monitor both the dev and master branch. Only when
>    the tag of the master branch changes, it uploads the pacakges (and docker
>    images?).
>
> Regarding 1, after comparing other framework, like tf.
>
>    - For major release, they have alpha and beta, then followed by rc,
>    release candidate.
>    - And for minor, pre release starts from rc.
>    - While patch will be release directly.
>
> For torch, similarily:
>
>    - major starts from alpha, followed by rc
>    - minor starts from rc
>    - patch is release directly.
>
> By right, simply speaking, alpha is first phase of testing internally.
> beta is testing publicly. rc is almost like stable release unless serious
> bug is discovered.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/apache/singa/issues/585#issuecomment-598525352>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AA47DRZC7TN6ADQQCSJLYSDRHGO6DANCNFSM4KNSRRIQ>
> .
>
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5ODUyNjYyNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/585,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwNjY2NDg2NQ==,singa,606664865,585,NA,nudles,3797447,Wei Wang,,NA,2020-03-31T14:31:45Z,2020-03-31T14:31:45Z,"> 
> 
> > 1. if the building of the conda package fails, we need to delete the newly updated tag? Alternatively, we may need to consider a pre-release version like 3.0.0-alpha0.  Then, we need to parse the version ID with `-alphaX`.
> > 2. both the CMake and Conda building scripts need to parse the version from the git tag.
> > 3. The CI needs to monitor both the dev and master branch. Only when the tag of the master branch changes, it uploads the pacakges (and docker images?).
> 
> All of this can be easily done with [Github Actions](https://github.com/features/actions). The CI in Github can be configured to monitor a given branch. There are many actions available for use that manage the [version tags](https://github.com/sdras/awesome-actions#semantic-versioning), [create docker containers](https://github.com/sdras/awesome-actions#docker-container-actions) and so on.

Is it possible to build the website via Github Action? We need the following steps
1. when there is a new commit to singa-doc, we build the website to generate the html files
2. push the html files to singa-site as a new commit","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwNjY2NDg2NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/591,singa,559432026,591,Dev branch cpu training problem (with conv and pool),chrishkchris,38325429,Chris Yeung,,CLOSED,2020-02-04T01:27:23Z,2020-02-21T02:40:20Z,"After merging the PR #590, today I am trying to solve the problem that the mnist cnn hangs as reported in PR #589.
When I run mnist_cnn after changing to cpu, it hangs. So the training has some problem.
","{""url"": ""https://api.github.com/repos/apache/singa/issues/591/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4MTcwNzUyMA==,singa,581707520,591,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-02-04T02:05:36Z,2020-02-04T02:05:36Z,"It does not hangs, it is just too slow, much slower than the previous version","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4MTcwNzUyMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4MTc0NTU3Nw==,singa,581745577,591,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-02-04T05:09:11Z,2020-02-04T05:09:11Z,"Using the mnist_cnn.py in CPU training:

The dev branch takes 14.469275s for one batch of training and one batch of evaulation.
The master branch takes 0.08s for one batch of training and one batch of evaulation.

So maybe something wrong.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4MTc0NTU3Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4MTc3MDA2MA==,singa,581770060,591,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-02-04T06:59:07Z,2020-02-04T06:59:07Z,"I profiled the time for different operations in mnist.py:
conv1: 0.5253171920776367
relu: 0.015198707580566406
pooling1: 0.0033032894134521484
conv2: 2.7908501625061035
relu: 0.004743099212646484
pooling2: 0.0012176036834716797
flatten: 0.00013828277587890625
linear1: 0.0011014938354492188
relu: 0.0008671283721923828
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4MTc3MDA2MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4MTc3MDI1MA==,singa,581770250,591,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-02-04T06:59:54Z,2020-02-04T06:59:54Z,I think need to double check the conv2d,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4MTc3MDI1MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDQ4NTgzOQ==,singa,584485839,591,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-02-11T05:43:31Z,2020-02-11T05:43:31Z,"I have tried using GCC OpenMP and Intel TBB (threading building block) when complile DNNL from source.

The time is extremely slow (normal time per epoch should be around a minute), but the training loss results are correct.

1. GCC OpenMP

```
root@3edb30e30b08:~/dcsysh/singa/examples/autograd# python3 mnist_cnn.py
Starting Epoch 0:
Training loss = 564.547180, training accuracy = 0.800644
Evaluation accuracy = 0.931591, Elapsed Time = 1348.363244s
Starting Epoch 1:
Training loss = 229.964905, training accuracy = 0.922892
Evaluation accuracy = 0.959535, Elapsed Time = 1344.685418s
Starting Epoch 2:
Training loss = 163.646332, training accuracy = 0.944837
Evaluation accuracy = 0.973758, Elapsed Time = 1346.530425s
Starting Epoch 3:
Training loss = 135.699615, training accuracy = 0.954526
Evaluation accuracy = 0.970152, Elapsed Time = 1346.398193s
Starting Epoch 4:
Training loss = 115.944962, training accuracy = 0.962096
Evaluation accuracy = 0.968750, Elapsed Time = 1349.933991s
Starting Epoch 5:
Training loss = 102.581963, training accuracy = 0.965548
Evaluation accuracy = 0.976963, Elapsed Time = 1343.627475s
Starting Epoch 6:
Training loss = 91.995560, training accuracy = 0.969701
Evaluation accuracy = 0.980168, Elapsed Time = 1345.709435s
Starting Epoch 7:
Training loss = 85.334785, training accuracy = 0.971051
Evaluation accuracy = 0.977664, Elapsed Time = 1342.384448s
Starting Epoch 8:
Training loss = 81.609375, training accuracy = 0.972018
Evaluation accuracy = 0.981571, Elapsed Time = 1345.214866s
Starting Epoch 9:
Training loss = 76.690147, training accuracy = 0.974203
Evaluation accuracy = 0.977364, Elapsed Time = 1354.111479s

```
2. TBB (threading building block)

```
root@3edb30e30b08:~/dcsysh/singa/examples/autograd# python3 mnist_cnn.py
Starting Epoch 0:
Training loss = 566.089539, training accuracy = 0.800527
Evaluation accuracy = 0.938201, Elapsed Time = 1571.624848s
Starting Epoch 1:
Training loss = 229.882874, training accuracy = 0.923192
Evaluation accuracy = 0.957833, Elapsed Time = 1569.219801s
Starting Epoch 2:
Training loss = 164.734573, training accuracy = 0.945137
Evaluation accuracy = 0.955929, Elapsed Time = 1567.359108s
Starting Epoch 3:
Training loss = 132.956802, training accuracy = 0.955310
Evaluation accuracy = 0.968550, Elapsed Time = 1572.159664s
Starting Epoch 4:
Training loss = 117.263237, training accuracy = 0.960646
Evaluation accuracy = 0.969151, Elapsed Time = 1570.090345s
Starting Epoch 5:
Training loss = 105.917274, training accuracy = 0.965115
Evaluation accuracy = 0.978466, Elapsed Time = 1569.966338s
Starting Epoch 6:
Training loss = 93.056519, training accuracy = 0.968700
Evaluation accuracy = 0.976362, Elapsed Time = 1571.289907s
Starting Epoch 7:
Training loss = 85.500954, training accuracy = 0.971101
Evaluation accuracy = 0.981771, Elapsed Time = 1572.169596s
```

3. The old mkldnn in master branch, results copied from PR https://github.com/apache/singa/pull/579

```
ubuntu@ip-172-31-24-48:~/singa/examples/autograd$ python3 mnist_cnn.py
Starting Epoch 0:
Training loss = 585.431152, training accuracy = 0.791739
Evaluation accuracy = 0.930088, Elapsed Time = 55.447133s
Starting Epoch 1:
Training loss = 232.831589, training accuracy = 0.922158
Evaluation accuracy = 0.967949, Elapsed Time = 55.337850s
Starting Epoch 2:
Training loss = 166.067307, training accuracy = 0.945788
Evaluation accuracy = 0.968550, Elapsed Time = 55.367847s
Starting Epoch 3:
Training loss = 136.865341, training accuracy = 0.954092
Evaluation accuracy = 0.973357, Elapsed Time = 55.358584s
Starting Epoch 4:
Training loss = 118.813286, training accuracy = 0.960195
Evaluation accuracy = 0.979567, Elapsed Time = 55.270505s
Starting Epoch 5:
Training loss = 106.185112, training accuracy = 0.964481
Evaluation accuracy = 0.975962, Elapsed Time = 55.281344s
Starting Epoch 6:
Training loss = 94.444023, training accuracy = 0.968016
Evaluation accuracy = 0.980970, Elapsed Time = 55.081426s
Starting Epoch 7:
Training loss = 88.213493, training accuracy = 0.970418
Evaluation accuracy = 0.982873, Elapsed Time = 54.912524s
Starting Epoch 8:
Training loss = 81.126442, training accuracy = 0.972886
Evaluation accuracy = 0.981470, Elapsed Time = 54.907317s
Starting Epoch 9:
Training loss = 77.790993, training accuracy = 0.974236
Evaluation accuracy = 0.974159, Elapsed Time = 54.915229s
```
So the dnnl may be around 300 times slower than the old mkldnn?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDQ4NTgzOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NzI3MzM0Mw==,singa,587273343,591,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-02-18T04:31:58Z,2020-02-18T04:31:58Z,"I have found that the reason, the format of the memory tag should be any in order to use the direct algorithm, otherwise the implementation will silently fall back to an explicit GEMM algorithm which is slower:
https://intel.github.io/mkl-dnn/dev_guide_convolution.html

An example code of the correct implementation is:
https://intel.github.io/mkl-dnn/cnn_training_f32_8cpp-example.html

@dcslin I will try to modify the code myself first. If I find it too complex I will ask for your help because you are more familiar with the dnnl library. Thanks!","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NzI3MzM0Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NzMwMDE0Ng==,singa,587300146,591,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-02-18T06:28:12Z,2020-02-18T06:28:12Z,"@dcslin 

I have tried to reorder the format before passing into conv, but seems I am not familiar with the DNNL API and too difficult to debug
See the reorder descripter I was trying and the new memory descriptor I added:
https://github.com/chrishkchris/singa/blob/conv_reorder/src/model/operation/convolution.cc#L111

From my understanding, the key concept and the step-by-step-prodcedure is:
1. Create memory decriptor of tag::any format of conv2d for the input, weight, bias, output 
2. Create the conv primitive descriptor based on the memory decriptor created above
3. Reorder the input and weight format to the tag::any format
4. the reordered format input and weight can be passed into the conv for processing

Could you help to make this work, thanks! ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NzMwMDE0Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NzQ3NjM3MQ==,singa,587476371,591,NA,dcslin,13751447,Shicong,,NA,2020-02-18T14:06:56Z,2020-02-18T14:06:56Z,"HI @chrishkchris , Thank you for raising the issue. I have tried on your branch, the function 'order' is behaving very weird. It seems that it does not work well with the memory we passed in.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NzQ3NjM3MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NzQ5MjcxMw==,singa,587492713,591,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-02-18T14:41:11Z,2020-02-18T14:41:11Z,"@dcslin I just realized that should use the cpp example instead of c example because the API are different.
https://intel.github.io/mkl-dnn/cnn_training_f32_8cpp-example.html","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NzQ5MjcxMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NzUwMzgzNw==,singa,587503837,591,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-02-18T15:03:29Z,2020-02-18T15:03:29Z,"> HI @chrishkchris , Thank you for raising the issue. I have tried on your branch, the function 'order' is behaving very weird. It seems that it does not work well with the memory we passed in.

yes, sorry, by reading cpp example the way to create a reorder primitive_desc in cpp
the example code use just:
reorder(conv_user_src_memory, conv_src_memory)
to convert the format from source to conv kernel format  
for execute, pass the stream and parameter
{{DNNL_ARG_FROM, conv_user_src_memory},
                {DNNL_ARG_TO, conv_src_memory}}","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NzUwMzgzNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NzUzMzU1Nw==,singa,587533557,591,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-02-18T15:58:44Z,2020-02-18T15:58:44Z,"> HI @chrishkchris , Thank you for raising the issue. I have tried on your branch, the function 'order' is behaving very weird. It seems that it does not work well with the memory we passed in.

@dcslin 
I updated the code, the reorder primitive is moved to here:
https://github.com/chrishkchris/singa/blob/conv_reorder/src/model/operation/convolution.cc#L162
now the error log is
```
[ RUN      ] DNNLOperation_Convolution.Forward
pass0
pass1
unknown file: Failure
C++ exception with description ""could not create a memory"" thrown in the test body.
[  FAILED  ] DNNLOperation_Convolution.Forward (0 ms)


```","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NzUzMzU1Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODA2MzE1NA==,singa,588063154,591,NA,dcslin,13751447,Shicong,,NA,2020-02-19T06:48:42Z,2020-02-19T06:48:42Z,"Hi @chrishkchris , FYI
https://github.com/dcslin/singa/blob/conv_reorder/src/model/operation/convolution.cc","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODA2MzE1NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODYwNzI4MQ==,singa,588607281,591,NA,dcslin,13751447,Shicong,,NA,2020-02-20T04:46:50Z,2020-02-20T04:46:50Z,"Hi @chrishkchris , I am still working on this issue, but I am encountering something very weird.

I borrow the code from dnnl example and testing result shows similar performance compared to mkldnn(conv forward in 5000~microsec).

However, after some modification to the example code(just introducing Singa Tensor https://github.com/dcslin/singa/commit/06ec6ce8453f524640c704695d30d3f39fca0469), I still can get reasonable performance(conv forward in 5000~ microsec). But the weird part is, the result is not stable, out of 10 times testing, `segmentation fault` appear ~6 times.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODYwNzI4MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODYxMDMwMQ==,singa,588610301,591,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-02-20T05:00:09Z,2020-02-20T05:00:09Z,"> Hi @chrishkchris , I am still working on this issue, but I am encountering something very weird.
> I borrow the code from dnnl example and testing result shows similar performance compared to mkldnn(conv forward in 5000~microsec).
> However, after some modification to the example code(just introducing Singa Tensor dcslin@06ec6ce), I still can get reasonable performance(conv forward in 5000~ microsec). But the weird part is, the result is not stable, out of 10 times testing, segmentation fault appear ~6 times.

maybe can try adding s.wait() after each reorder, the stream process them one by one
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODYxMDMwMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODYxODAzMQ==,singa,588618031,591,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-02-20T05:34:07Z,2020-02-20T05:34:07Z,"> Hi @chrishkchris , I am still working on this issue, but I am encountering something very weird.
> I borrow the code from dnnl example and testing result shows similar performance compared to mkldnn(conv forward in 5000~microsec).
> However, after some modification to the example code(just introducing Singa Tensor dcslin@06ec6ce), I still can get reasonable performance(conv forward in 5000~ microsec). But the weird part is, the result is not stable, out of 10 times testing, segmentation fault appear ~6 times.

I run your example code but did not find any problem, it display mytestok. The last segmentation fault of ""double free"" is due to freeing of variables.  

```
[ RUN      ] MYTEST.Forward
[total]Time difference = 58228[mu s]
[avg]Time difference = 582[mu s]
mytestok
double free or corruption (!prev)
Aborted (core dumped)


```","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODYxODAzMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODYyMTIxNQ==,singa,588621215,591,NA,dcslin,13751447,Shicong,,NA,2020-02-20T05:46:55Z,2020-02-20T05:46:55Z,"> > Hi @chrishkchris , I am still working on this issue, but I am encountering something very weird.
> > I borrow the code from dnnl example and testing result shows similar performance compared to mkldnn(conv forward in 5000~microsec).
> > However, after some modification to the example code(just introducing Singa Tensor [dcslin/singa@06ec6ce](https://github.com/dcslin/singa/commit/06ec6ce)), I still can get reasonable performance(conv forward in 5000~ microsec). But the weird part is, the result is not stable, out of 10 times testing, segmentation fault appear ~6 times.
> 
> I run your example code but did not find any problem, it display mytestok. The last segmentation fault of ""double free"" is due to freeing of variables.
> 
> ```
> [ RUN      ] MYTEST.Forward
> [total]Time difference = 58228[mu s]
> [avg]Time difference = 582[mu s]
> mytestok
> double free or corruption (!prev)
> Aborted (core dumped)
> ```

do you how to fix this?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODYyMTIxNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODYzMDU5OQ==,singa,588630599,591,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-02-20T06:22:33Z,2020-02-20T06:22:33Z,"> Hi @chrishkchris , I am still working on this issue, but I am encountering something very weird.
> I borrow the code from dnnl example and testing result shows similar performance compared to mkldnn(conv forward in 5000microsec).
> However, after some modification to the example code(just introducing Singa Tensor dcslin/singa@06ec6ce), I still can get reasonable performance(conv forward in 5000 microsec). But the weird part is, the result is not stable, out of 10 times testing, segmentation fault appear ~6 times.
> 
> I run your example code but did not find any problem, it display mytestok. The last segmentation fault of ""double free"" is due to freeing of variables.
> [ RUN      ] MYTEST.Forward
> [total]Time difference = 58228[mu s]
> [avg]Time difference = 582[mu s]
> mytestok
> double free or corruption (!prev)
> Aborted (core dumped)
> 
> 
> do you how to fix this?

OK now, I tried by turning the tensor to pointer. 

```
  Tensor *in = new Tensor(Shape{batch, in_chan, image_h, image_h});
  Tensor *out = new Tensor(Shape{batch, out_chan, out_size, out_size});
  Tensor *weights = new Tensor(Shape{out_chan, in_chan, ker, ker});
  Tensor *bias = new Tensor(Shape{out_chan});
  in->SetValue(1.0f);
  weights->SetValue(1.0f);
  bias->SetValue(1.0f);
```

Now it display:
```
[----------] 1 test from MYTEST
[ RUN      ] MYTEST.Forward
[total]Time difference = 51943[mu s]
[avg]Time difference = 519[mu s]
mytestok
[       OK ] MYTEST.Forward (53 ms)
[----------] 1 test from MYTEST (53 ms total)

```
so I suspect that when it destruct dnnl memory object, it will free the memory from in->block()->mutable_data … 
For the same reason, I suspect that in the constructor of dnnl memory object, it will reallocate memory based on the pointer given.

The solution is to avoid passing the block memory pointer to the dnnl memory constructor, instead we copy the block memory to the dnnl memory after dnnl memory object is constructed. ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODYzMDU5OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODY0ODMxMw==,singa,588648313,591,NA,dcslin,13751447,Shicong,,NA,2020-02-20T07:02:27Z,2020-02-20T07:02:27Z,"@chrishkchris , in fact, even disabling reorder part, the performance is still the same

> > Hi @chrishkchris , I am still working on this issue, but I am encountering something very weird.
> > I borrow the code from dnnl example and testing result shows similar performance compared to mkldnn(conv forward in 5000microsec).
> > However, after some modification to the example code(just introducing Singa Tensor [dcslin/singa@06ec6ce](https://github.com/dcslin/singa/commit/06ec6ce)), I still can get reasonable performance(conv forward in 5000 microsec). But the weird part is, the result is not stable, out of 10 times testing, segmentation fault appear ~6 times.
> > I run your example code but did not find any problem, it display mytestok. The last segmentation fault of ""double free"" is due to freeing of variables.
> > [ RUN      ] MYTEST.Forward
> > [total]Time difference = 58228[mu s]
> > [avg]Time difference = 582[mu s]
> > mytestok
> > double free or corruption (!prev)
> > Aborted (core dumped)
> > do you how to fix this?
> 
> OK now, I tried by turning the tensor to pointer.
> 
> ```
>   Tensor *in = new Tensor(Shape{batch, in_chan, image_h, image_h});
>   Tensor *out = new Tensor(Shape{batch, out_chan, out_size, out_size});
>   Tensor *weights = new Tensor(Shape{out_chan, in_chan, ker, ker});
>   Tensor *bias = new Tensor(Shape{out_chan});
>   in->SetValue(1.0f);
>   weights->SetValue(1.0f);
>   bias->SetValue(1.0f);
> ```
> 
> Now it display:
> 
> ```
> [----------] 1 test from MYTEST
> [ RUN      ] MYTEST.Forward
> [total]Time difference = 51943[mu s]
> [avg]Time difference = 519[mu s]
> mytestok
> [       OK ] MYTEST.Forward (53 ms)
> [----------] 1 test from MYTEST (53 ms total)
> ```
> 
> so I suspect that when it destruct dnnl memory object, it will free the memory from in->block()->mutable_data …
> For the same reason, I suspect that in the constructor of dnnl memory object, it will reallocate memory based on the pointer given.
> 
> The solution is to avoid passing the block memory pointer to the dnnl memory constructor, instead we copy the block memory to the dnnl memory after dnnl memory object is constructed.

will it cost double memory usage?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODY0ODMxMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODY1MDA0NQ==,singa,588650045,591,NA,dcslin,13751447,Shicong,,NA,2020-02-20T07:03:58Z,2020-02-20T07:03:58Z,"somehow i fixed conv forward, 
https://github.com/dcslin/singa/commit/8e85fdc8d6efd6bcae11ff45217471f784cd2462
it's now in the magnitude of ~5000microsec which is similar to mkldnn.

I see backward also has problem, still checking","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODY1MDA0NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODY2Nzg4NA==,singa,588667884,591,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-02-20T07:24:30Z,2020-02-20T07:24:30Z,"> somehow i fixed conv forward,
> dcslin@8e85fdc
> it's now in the magnitude of ~5000microsec which is similar to mkldnn.
> I see backward also has problem, still checking

I have read the updated code
so the error is caused by dnnl::prop_kind::forward?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODY2Nzg4NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODY2ODg5NQ==,singa,588668895,591,NA,dcslin,13751447,Shicong,,NA,2020-02-20T07:25:13Z,2020-02-20T07:25:13Z,"> > somehow i fixed conv forward,
> > [dcslin/singa@8e85fdc](https://github.com/dcslin/singa/commit/8e85fdc)
> > it's now in the magnitude of ~5000microsec which is similar to mkldnn.
> > I see backward also has problem, still checking
> 
> I have read the updated code
> so the error is caused by dnnl::prop_kind::forward?

not sure","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODY2ODg5NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODcyNDI2MA==,singa,588724260,591,NA,dcslin,13751447,Shicong,,NA,2020-02-20T08:04:39Z,2020-02-20T08:04:39Z,"@chrishkchris could you please help to test the performance of this branch? it looks ok at my side. 
let me know if the performance is ok?
https://github.com/dcslin/singa/tree/dnnl-perf-issue

I will clean the code","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODcyNDI2MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODcyNzAzNQ==,singa,588727035,591,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-02-20T08:06:40Z,2020-02-20T08:06:40Z,"> @chrishkchris could you please help to test the performance of this branch? it looks ok at my side.
> let me know if the performance is ok?
> https://github.com/dcslin/singa/tree/dnnl-perf-issue
> I will clean the code

Thanks a lot! I will test and let you know","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODcyNzAzNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODc1NzExOA==,singa,588757118,591,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-02-20T08:28:19Z,2020-02-20T08:28:19Z,"@dcslin Thank you so much!
It is much much faster than before. The training loss is correct.

```
root@71b7b910ae0b:~/dcsysh/singa/examples/autograd# python3 mnist_cnn.py
Starting Epoch 0:
Training loss = 577.733337, training accuracy = 0.796858
Evaluation accuracy = 0.937300, Elapsed Time = 139.402045s
Starting Epoch 1:
Training loss = 234.865036, training accuracy = 0.920891
Evaluation accuracy = 0.954327, Elapsed Time = 138.340753s
Starting Epoch 2:
Training loss = 174.085022, training accuracy = 0.941402
Evaluation accuracy = 0.973157, Elapsed Time = 138.636959s
Starting Epoch 3:
Training loss = 137.803268, training accuracy = 0.953475
Evaluation accuracy = 0.966246, Elapsed Time = 138.846091s
Starting Epoch 4:
Training loss = 116.644051, training accuracy = 0.961963
Evaluation accuracy = 0.974459, Elapsed Time = 139.520643s
Starting Epoch 5:
Training loss = 104.833313, training accuracy = 0.964915
Evaluation accuracy = 0.976562, Elapsed Time = 139.725914s
Starting Epoch 6:
Training loss = 95.696701, training accuracy = 0.967466
Evaluation accuracy = 0.979066, Elapsed Time = 141.454090s
Starting Epoch 7:
Training loss = 87.961937, training accuracy = 0.969784
Evaluation accuracy = 0.983474, Elapsed Time = 137.189445s
Starting Epoch 8:
Training loss = 81.685951, training accuracy = 0.972002
Evaluation accuracy = 0.982772, Elapsed Time = 138.908067s
Starting Epoch 9:
Training loss = 76.445320, training accuracy = 0.973986
Evaluation accuracy = 0.983073, Elapsed Time = 136.998992s
```","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODc1NzExOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODc2NTUwOA==,singa,588765508,591,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-02-20T08:34:29Z,2020-02-20T08:34:29Z,@dcslin I guess you will need to change the test_operation_convolution.cc back,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODc2NTUwOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODc3MzU5NA==,singa,588773594,591,NA,dcslin,13751447,Shicong,,NA,2020-02-20T08:40:24Z,2020-02-20T08:40:24Z,"> @dcslin I guess you will need to change the test_operation_convolution.cc back

yes sure","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODc3MzU5NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODc4Mzk3Ng==,singa,588783976,591,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-02-20T08:48:01Z,2020-02-20T08:48:01Z,The code is great! It resolved the problem. I think you can send the PR,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODc4Mzk3Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODc4NzExMw==,singa,588787113,591,NA,dcslin,13751447,Shicong,,NA,2020-02-20T08:50:12Z,2020-02-20T08:50:12Z,"> The code is great! It resolved the problem. I think you can send the PR

thanks for testing","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODc4NzExMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/591,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODk4MjY0MQ==,singa,588982641,591,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-02-20T11:52:50Z,2020-02-20T11:52:50Z,This issue can be resolved by PR #605 ,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODk4MjY0MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/596,https://api.github.com/repos/apache/singa/issues/596,singa,562542295,596,Clang-formatter results in different formatting?,chrishkchris,38325429,Chris Yeung,,CLOSED,2020-02-10T12:54:39Z,2020-03-11T03:46:43Z,"I used the clang-formatter with VS-code after I alter the tensor.h file, it results in different format with the dev branch.

![format](https://user-images.githubusercontent.com/38325429/74151458-2f68ae80-4c47-11ea-8d5b-b5107171b1b5.png)
![fromat2](https://user-images.githubusercontent.com/38325429/74153518-c59ed380-4c4b-11ea-8e6b-942fa5dedcf6.png)

The tensor.cc should have re-formatted before in PR #581. So, did I use incorrect setting in clang-formatter?","{""url"": ""https://api.github.com/repos/apache/singa/issues/596/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/596,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDQ2MjUyMQ==,singa,584462521,596,NA,dcslin,13751447,Shicong,,NA,2020-02-11T03:16:49Z,2020-02-11T03:16:49Z,"Hi @chrishkchris , I have tested on windows at my side. Could you please check again your configuration? I hope this guide could help: https://github.com/apache/singa-doc/blob/0efbdbee811901fbcd7ce1f2d057669cb246e4c9/docs-site/docs/contribute-code.md

You might need to install LLVM in windows, and add below lines to VS Code configuration:
```
""[cpp]"": {
    ""editor.defaultFormatter"": ""xaver.clang-format""
},
""cpplint.cpplintPath"": ""path/to/cpplint"",

""editor.formatOnSave"": true,
""python.formatting.provider"": ""yapf"",
""python.linting.enabled"": true,
""python.linting.lintOnSave"": true,
```","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDQ2MjUyMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/596,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDQ2NDA1Mg==,singa,584464052,596,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-02-11T03:25:19Z,2020-02-11T03:25:19Z,"I have installed LLVM, and the following VS code configuration:

{
  ""git.ignoreMissingGitWarning"": true,
  ""python.pythonPath"": ""C:\\ProgramData\\Anaconda3"",

  ""[cpp]"": {
    ""editor.defaultFormatter"": ""xaver.clang-format""
  },
  ""cpplint.cpplintPath"": ""c:\\ProgramData\\Anaconda3\\Scripts\\cpplint.exe"",

  ""editor.formatOnSave"": true,
  ""python.formatting.provider"": ""yapf"",
  ""python.linting.enabled"": true,
  ""python.linting.lintOnSave"": true,
  ""python.linting.pylintEnabled"": true,
  ""python.linting.pylamaEnabled"": false,
  ""C_Cpp.dimInactiveRegions"": false
}


Seems to be strange. I think my setting corresponding to clang-formatter is the same as you?
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDQ2NDA1Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/596,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDQ2NTAxOA==,singa,584465018,596,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-02-11T03:31:03Z,2020-02-11T03:31:03Z,"is it due to the different of cpplint we uses?
I was using pip install cpplint","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDQ2NTAxOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/596,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDQ2NTAzNw==,singa,584465037,596,NA,dcslin,13751447,Shicong,,NA,2020-02-11T03:31:10Z,2020-02-11T03:31:10Z,hi @chrishkchris have you installed this extension https://marketplace.visualstudio.com/items?itemName=xaver.clang-format,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDQ2NTAzNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/596,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDQ2NTA3NQ==,singa,584465075,596,NA,dcslin,13751447,Shicong,,NA,2020-02-11T03:31:30Z,2020-02-11T03:31:30Z,"> is it due to the different of cpplint we uses?
> I was using pip install cpplint

clang-format is independent from cpplint","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDQ2NTA3NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/596,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDQ2NTM4NQ==,singa,584465385,596,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-02-11T03:33:34Z,2020-02-11T03:33:34Z,"yes, I am using
![env](https://user-images.githubusercontent.com/38325429/74209338-4698b200-4cc2-11ea-820d-6a14e81a2202.png)
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDQ2NTM4NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/596,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDQ2NTU4MQ==,singa,584465581,596,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-02-11T03:34:56Z,2020-02-11T03:34:56Z,version is the same?,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDQ2NTU4MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/596,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDQ2NTgzNQ==,singa,584465835,596,NA,dcslin,13751447,Shicong,,NA,2020-02-11T03:36:20Z,2020-02-11T03:36:20Z,"> version is the same?

extension is auto updated i think","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDQ2NTgzNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/596,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDQ2NTk3Nw==,singa,584465977,596,NA,dcslin,13751447,Shicong,,NA,2020-02-11T03:37:07Z,2020-02-11T03:37:07Z,may be for workaround could you try to set 'clang-format.language.cpp.style' this option to google.,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDQ2NTk3Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/596,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDQ2NjA4NQ==,singa,584466085,596,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-02-11T03:37:44Z,2020-02-11T03:37:44Z,"> may be for workaround could you try to set 'clang-format.language.cpp.style' this option to google.

ok, I will try this one","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDQ2NjA4NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/596,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDQ2NzE0Nw==,singa,584467147,596,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-02-11T03:44:45Z,2020-02-11T03:44:45Z,"> may be for workaround could you try to set 'clang-format.language.cpp.style' this option to google.
> 
> ok, I will try this one

Yes, this is the solution
need to add in the json
""clang-format.language.cpp.style"": ""google""

Could you update this to the instruction so everyone can use the same? thanks a lot","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDQ2NzE0Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/596,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDQ4MDIzMA==,singa,584480230,596,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-02-11T05:09:57Z,2020-02-11T05:09:57Z,@shicong I will submit a PR in singa-doc to make this clear in the introduction,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDQ4MDIzMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/596,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDQ4NDY5Ng==,singa,584484696,596,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-02-11T05:36:34Z,2020-02-11T05:36:34Z,@shicong I have updated the instruction in https://github.com/apache/singa-doc/pull/4. I will close this issue when everything is okay. Thanks a lot for your advice!,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDQ4NDY5Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/596,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDUyNDMxMA==,singa,584524310,596,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-02-11T08:30:13Z,2020-02-11T08:30:13Z,"In https://github.com/apache/singa-doc/pull/4, I also added also the google style for python yapf :
""python.formatting.yapfArgs"" : [""--style"" , ""{based_on_style: google}"" ]
This will be good if VSCode cannot catch the  .style.yapf and .clang-format in the project root directory, where I encountered this problem in the remote edit environment (WinSCP)","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4NDUyNDMxMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/596,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODA2MzkxMQ==,singa,588063911,596,NA,dcslin,13751447,Shicong,,NA,2020-02-19T06:51:41Z,2020-02-19T06:51:41Z,"Hi @chrishkchris FYI
https://github.com/apache/singa/pull/603","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU4ODA2MzkxMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/596,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5NjE3NDE4NA==,singa,596174184,596,NA,nudles,3797447,Wei Wang,,NA,2020-03-08T07:05:52Z,2020-03-08T07:05:52Z,@chrishkchris  is this issue fixed?,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5NjE3NDE4NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/596,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5NjE3Njc1NA==,singa,596176754,596,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-03-08T07:47:13Z,2020-03-08T07:47:13Z,"@nudles I think to solve is to use the same version of formatters as well as the same config for all the contributors, where I addressed in the new doc repo for the instruction of how to do the formatting https://github.com/apache/singa-doc/pull/4
Although my method may not resolve 100% of the problem (some people may use not exactly the same version, e.g. LVMM 9.0 vs 10.0), but should resolve most of the problem.

@XJDKC I remembered that Rulin has even proposed a better method than me (the same docker container with the formatter pre-installed, with the same git hooks) 
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5NjE3Njc1NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/622,https://api.github.com/repos/apache/singa/issues/622,singa,576785961,622,Preparation for the next release,nudles,3797447,Wei Wang,,CLOSED,2020-03-06T08:54:16Z,2020-08-30T04:07:51Z,"Release version,  2.1 vs 3.0 depending on the API change

Please tick the feature if it is done.
  - [ ] onnx (vision and nlp), model-zoo md files   @joddiy 
  - [ ] distributed training with MPI and NCCL, dist-train.md @chrishkchris 
  - [ ] computational graph with memory optimization, device.md @ Rulin 
  - [ ] new website  
  - [ ] code quality and coverage management @moazreyad 
  - [ ] dnnl integration, installation.md, build.md @dcslin 
  - [ ] tensor APIs, tensor.md @dcslin 
  - [ ] new autograd operators; upgrade existing operators, autograd.md @joddiy 
  - [ ] anything else?

Here is the checklist and [steps](http://www.apache.org/dev/release-publishing.html)
- [ ] Select a release manager. The release manager (RM) is the coordinator for the release process. It is the RM's signature (.asc) that is uploaded together with the release. The RM generates KEY (RSA 4096-bit) and uploads it to a public key server. The RM needs to get his key endorsed (signed) by other Apache user, to be connected to the web of trust. He should first ask the mentor to help signing his key. [How to generate the key](http://www.apache.org/dev/release-signing.html)?

- [ ] Check license. [FAQ](https://www.apache.org/legal/src-headers.html#faq-docs); [SINGA Issue](https://issues.apache.org/jira/projects/SINGA/issues/SINGA-447)
  - [ ] the codebase does not include third-party code which is not compatible to APL;
  - [ ] The dependencies are compatible with APL. GNU-like licenses are NOT compatible; 
  - [ ] All source files written by us MUST include the Apache license header: http://www.apache.org/legal/src-headers.html. There's a script in there which helps propagating the header to all files.
  - [ ] Update the LICENSE file. If we include any third party code in the release package which is not APL, must state it at the end of the [LICENSE](https://github.com/apache/singa/blob/master/LICENSE#L448) file and include the license boilerplate in the original file.

- [ ] Bump the version. Check code and documentation
  - [ ] The build process is error-free.
  - [ ] Unit tests are included (as much as possible)
  - [ ] Conda packages run without errors. 
  - [ ] The online documentation on the Apache website is up to date.

- [ ] Prepare the RELEASE_NOTES file. Include the following items, Introduction, Features, Bugs (link to JIRA or Github PR), Changes, Dependency list, Incompatibility issues. Follow this [example](http://commons.apache.org/proper/commons-digester/commons-digester-3.0/RELEASE-NOTES.txt). 

- [ ] Prepare DISCLAIMER file. Modify from the [template](http://incubator.apache.org/guides/branding.html#disclaimers)

- [ ] Package the release candidate. The release should be packaged into : apache-singa-VERSION.tar.gz. The release should not include any binary files including git files. Upload the release to for [stage](https://dist.apache.org/repos/dist/dev/VERSION/). The tar file, signature, KEY and SHA256 checksum file should be included. MD5 is no longer used. Policy is [here](http://www.apache.org/dev/release-distribution#sigs-and-sums)
    * apache-singa-VERSION.tar.gz
    * KEY
    * XX.acs
    * .SHA256

- [ ] Call for vote by sending an email
    ``` 
    To: dev@singa.apache.org
    Subject: [VOTE] Release apache-singa-X.Y.Z (release candidate N)

    Hi all,

    I have created a build for Apache SINGA X.Y.Z, release candidate N.
    The artifacts to be voted on are located here:  xxxx
    The hashes of the artifacts are as follows: xxx
    Release artifacts are signed with the following key: xxx
    Please vote on releasing this package. The vote is open for at least 72 hours and passes if a majority of at least three +1 votes are cast.

   [ ] +1 Release this package as Apache SINGA X.Y.Z
   [ ] 0 I don't feel strongly about it, but I'm okay with the release
   [ ] -1 Do not release this package because...

   Here is my vote:
   +1 
    ```

- [ ] Wait at least 48 hours for test responses. Any PMC, committer or contributor can test features for releasing, and feedback. Everyone should check these before vote +1. If the vote passes, then send the result email. Otherwise, repeat from the beginning.
    ```
    Subject: [RESULT] [VOTE] Release apache-singa-X.Y.Z (release candidate N)
    To: dev@singa.apache.org
 
    Thanks to everyone who has voted and given their comments. The tally is as follows.
 
    N binding +1s:
    <names>
 
    N non-binding +1s:
    <names>
 
    No 0s or -1s.
 
     I am delighted to announce that the proposal to release Apache SINGA X.Y.Zhas passed.
     ````

- [ ] Upload the package for [distribution](http://www.apache.org/dev/release-publishing.html#distribution) to https://dist.apache.org/repos/dist/release/VERSION/. 

- [ ] Update the Download page of SINGA website. The tar.gz file MUST be downloaded from mirror, using closer.cgi script; other artifacts MUST be downloaded from main Apache site. More details [here](http://www.apache.org/dev/release-download-pages.html). Some feedback we got during the previous releases:  ""Download pages must only link to formal releases, so must not include links to GitHub."",  ""Links to KEYS, sigs and hashes must not use dist.apache.org; instead use https://www.apache.org/dist/singa/...;"", ""Also you only need one KEYS link, and there should be a description of how to use KEYS + sig or hash to verify the downloads.""

- [ ] Remove the RC tag and compile the conda packages.

- [ ] Publish the release information. 
    ```
    To: announce@apache.org, dev@singa.apache.org 
    Subject: [ANNOUNCE] Apache SINGA X.Y.Z released

    We are pleased to announce that SINGA X.Y.Z is released.

    SINGA is a general distributed deep learning platform for training big deep learning models over large datasets. 
    The release is available at: http://singa.apache.org/downloads.html
    The main features of this release include XXX
    We look forward to hearing your feedback, suggestions, and contributions to the project.

    On behalf of the SINGA team, {SINGA Team Member Name}
    ````














","{""url"": ""https://api.github.com/repos/apache/singa/issues/622/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/622,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5NjE0NzM5Nw==,singa,596147397,622,NA,moazreyad,2278792,Moaz Reyad,moazreyad@gmail.com,NA,2020-03-07T23:20:03Z,2020-03-07T23:20:03Z,"We may aim to include some internal features for developers. I wrote two discussions in the mail list, one for [Code Quality]( http://mail-archives.apache.org/mod_mbox/singa-dev/201909.mbox/%3CCAH%3DWUUbgvL62dZOCRJeEDA-a-JWNEyGvvK1Dn3ZL1YDvLXWktQ%40mail.gmail.com%3E) and the other for [Coverage](http://mail-archives.apache.org/mod_mbox/singa-dev/201911.mbox/%3CCAH%3DWUUaq4eDJKrQPyVbkCoJYQ8mjtNycXQvXUA9x4UK3MtCg%3DA%40mail.gmail.com%3E). I am planning to write more discussions for other improvements soon.

The code quality improvements seems fine now. We have lgtm, linting and license checks. But the code coverage is not ready. There are many tasks to enable coverage as proposed in the discussion. I will try to work on some of them and everyone is welcome to participate.

About 2.1 vs 3.0, I vote for 2.1.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5NjE0NzM5Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/622,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5NjE3Mzg3Nw==,singa,596173877,622,NA,nudles,3797447,Wei Wang,,NA,2020-03-08T07:01:50Z,2020-03-08T07:01:50Z,"Thanks for the suggestion, Moaz!
In terms of the version number, I think if we have major API changes that are not compatible with V2.0, then we need to release V3.0; ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5NjE3Mzg3Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/622,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMDQ5NTE2Mg==,singa,600495162,622,NA,nudles,3797447,Wei Wang,,NA,2020-03-18T08:44:05Z,2020-03-18T08:44:05Z,@moazreyad  pls help double check the release steps. This is our first release as TLP; hence it is a bit from past releases.,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMDQ5NTE2Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/622,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMDY1ODkzMg==,singa,600658932,622,NA,moazreyad,2278792,Moaz Reyad,moazreyad@gmail.com,NA,2020-03-18T14:35:36Z,2020-03-18T14:35:36Z,"1. At the end, we will need to [publish the release](http://singa.apache.org/develop/how-to-release.html#publish-release).

1. The step of check license is not required. It will be done [automatically](https://github.com/apache/singa/pull/629) when any pull request is merged with master.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMDY1ODkzMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/622,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTA2ODkwNQ==,singa,601068905,622,NA,dcslin,13751447,Shicong,,NA,2020-03-19T09:10:45Z,2020-03-19T09:10:45Z,"changelog of some of the mentioned points
https://gist.github.com/dcslin/1e8934ffc791fdea4b95810f437cf361","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTA2ODkwNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/622,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwNTgxNjk5NQ==,singa,605816995,622,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-03-30T06:54:06Z,2020-03-30T06:54:06Z,"changelog of some of the mentioned points
https://gist.github.com/joddiy/ff7a5f8e8dd35668a2f300c26ad01cdb","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwNTgxNjk5NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/622,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwNTgyMTUwOQ==,singa,605821509,622,NA,nudles,3797447,Wei Wang,,NA,2020-03-30T07:05:57Z,2020-03-30T07:05:57Z,@joddiy pls create the colab notebooks for the onnx examples,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwNTgyMTUwOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/622,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwNTg2ODc3OQ==,singa,605868779,622,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-03-30T08:51:20Z,2020-03-30T08:51:20Z,"> @joddiy pls create the colab notebooks for the onnx examples

Got it, I am going to create it right now.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwNTg2ODc3OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/622,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwNjM5ODgzMw==,singa,606398833,622,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-03-31T04:53:48Z,2020-03-31T04:53:48Z,"> @joddiy pls create the colab notebooks for the onnx examples

please check the colab examples. However, I just clean the code now, since the new version SINGA has not been released, it cannot run yet. After we release the new version, I will adjust it then.

## Face Analysis
[arcface](https://colab.research.google.com/drive/1qanaqUKGIDtifdzEzJOHjEj4kYzA9uJC), [fer+ emotion](https://colab.research.google.com/drive/1XHtBQGRhe58PDi4LGYJzYueWBeWbO23r)

## Object Detection
[tiny yolo v2](https://colab.research.google.com/drive/11V4I6cRjIJNUv5ZGsEGwqHuoQEie6b1T)

## Image Classification
[mobilenet](https://colab.research.google.com/drive/1HsixqJMIpKyEPhkbB8jy7NwNEFEAUWAf), [vgg16](https://colab.research.google.com/drive/14kxgRKtbjPCKKsDJVNi3AvTev81Gp_Ds), [resnet18](https://colab.research.google.com/drive/1u1RYefSsVbiP4I-5wiBKHjsT9L0FxLm9)

## Machine Comprehension
[bert squad](https://colab.research.google.com/drive/1kud-lUPjS_u-TkDAzihBTw0Vqr0FjCE-)

## Mnist demo for inference, re-training, and transfer learning
[mnist](https://colab.research.google.com/drive/1-YOfQqqw3HNhS8WpB8xjDQYutRdUdmCq)
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwNjM5ODgzMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/623,https://api.github.com/repos/apache/singa/issues/623,singa,576982606,623,Some consultations using the conda build in singa/tool/conda/singa,chrishkchris,38325429,Chris Yeung,,CLOSED,2020-03-06T14:54:19Z,2020-03-09T02:15:47Z,"@dcslin  Shicong, did you encountered such error using conda build before? I would like your help because seems you are recently on CI/CD

I am trying to use the dev branch to build conda using singa/tool/conda/singa, it gives the errors concerning onnx version

conda_build.exceptions.DependencyNeedsBuildingError: Unsatisfiable dependencies for platform linux-64: {""onnx[version='>=1.3.0']""}

```
dcsysh@panda:~/singa/tool/conda/singa$ export CUDA=10.0
dcsysh@panda:~/singa/tool/conda/singa$ conda-build .  --python 3.6
No numpy version specified in conda_build_config.yaml.  Falling back to default numpy value of 1.11
WARNING:conda_build.metadata:No numpy version specified in conda_build_config.yaml.  Falling back to default numpy value of 1.11
Copying /home/dcsysh/singa to /home/dcsysh/anaconda3/conda-bld/singa_1583505296868/work/
Adding in variants from internal_defaults
INFO:conda_build.variants:Adding in variants from internal_defaults
Adding in variants from /home/dcsysh/singa/tool/conda/singa/conda_build_config.yaml
INFO:conda_build.variants:Adding in variants from /home/dcsysh/singa/tool/conda/singa/conda_build_config.yaml
Adding in variants from config.variant
INFO:conda_build.variants:Adding in variants from config.variant
/home/dcsysh/anaconda3/lib/python3.6/site-packages/conda_build/environ.py:427: UserWarning: The environment variable 'CUDA' is being passed through with value '10.0'.  If you are splitting build and test phases with --no-test, please ensure that this value is also set similarly at test time.
  UserWarning
Attempting to finalize metadata for singa
INFO:conda_build.metadata:Attempting to finalize metadata for singa
Collecting package metadata (repodata.json): ...working... done
Solving environment: ...working... done
Collecting package metadata (repodata.json): ...working... done
Solving environment: ...working... done
Collecting package metadata (repodata.json): ...working... done
Solving environment: ...working... done
Collecting package metadata (repodata.json): ...working... done
Solving environment: ...working... done
Adding .* to spec 'libprotobuf 3.6.1' to ensure satisfiability.  Please consider putting {{ var_name }}.* or some relational operator (>/</>=/<=) on this spec in meta.yaml, or if req is also a build req, using {{ pin_compatible() }} jinja2 function instead.  See https://conda.io/docs/user-guide/tasks/build-packages/variants.html#pinning-at-the-variant-level
WARNING:conda_build.utils:Adding .* to spec 'libprotobuf 3.6.1' to ensure satisfiability.  Please consider putting {{ var_name }}.* or some relational operator (>/</>=/<=) on this spec in meta.yaml, or if req is also a build req, using {{ pin_compatible() }} jinja2 function instead.  See https://conda.io/docs/user-guide/tasks/build-packages/variants.html#pinning-at-the-variant-level
WARNING conda_build.utils:ensure_valid_spec(1749): Adding .* to spec 'libprotobuf 3.6.1' to ensure satisfiability.  Please consider putting {{ var_name }}.* or some relational operator (>/</>=/<=) on this spec in meta.yaml, or if req is also a build req, using {{ pin_compatible() }} jinja2 function instead.  See https://conda.io/docs/user-guide/tasks/build-packages/variants.html#pinning-at-the-variant-level
Adding .* to spec 'libopenblas 0.3.3' to ensure satisfiability.  Please consider putting {{ var_name }}.* or some relational operator (>/</>=/<=) on this spec in meta.yaml, or if req is also a build req, using {{ pin_compatible() }} jinja2 function instead.  See https://conda.io/docs/user-guide/tasks/build-packages/variants.html#pinning-at-the-variant-level
WARNING:conda_build.utils:Adding .* to spec 'libopenblas 0.3.3' to ensure satisfiability.  Please consider putting {{ var_name }}.* or some relational operator (>/</>=/<=) on this spec in meta.yaml, or if req is also a build req, using {{ pin_compatible() }} jinja2 function instead.  See https://conda.io/docs/user-guide/tasks/build-packages/variants.html#pinning-at-the-variant-level
WARNING conda_build.utils:ensure_valid_spec(1749): Adding .* to spec 'libopenblas 0.3.3' to ensure satisfiability.  Please consider putting {{ var_name }}.* or some relational operator (>/</>=/<=) on this spec in meta.yaml, or if req is also a build req, using {{ pin_compatible() }} jinja2 function instead.  See https://conda.io/docs/user-guide/tasks/build-packages/variants.html#pinning-at-the-variant-level
BUILD START: ['singa-2.1.0.dev-cudnn7.3.1_cuda10.0_py36.tar.bz2']
Collecting package metadata (repodata.json): ...working... done
Solving environment: ...working... done

## Package Plan ##

  environment location: /home/dcsysh/anaconda3/conda-bld/singa_1583505296868/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_place


The following NEW packages will be INSTALLED:

    _libgcc_mutex:    0.1-main
    blas:             1.0-openblas
    ca-certificates:  2020.1.1-0
    certifi:          2019.11.28-py36_0
    cudatoolkit:      10.0.130-0
    cudnn:            7.3.1-cuda10.0_0
    gflags:           2.2.2-he6710b0_0
    glog:             0.3.5-hf484d3e_1
    intel-openmp:     2018.0.3-0
    ld_impl_linux-64: 2.33.1-h53a641e_7
    libedit:          3.1.20181209-hc058e9b_0
    libffi:           3.2.1-hd88cf55_4
    libgcc-ng:        9.1.0-hdf63c60_0
    libgfortran-ng:   7.3.0-hdf63c60_0
    libmklml:         2018.0.3-0
    libopenblas:      0.3.3-h5a2b251_3
    libprotobuf:      3.6.1-hd408876_0
    libstdcxx-ng:     9.1.0-hdf63c60_0
    mkl-dnn:          0.14-h6bb024c_0
    ncurses:          6.2-he6710b0_0
    nomkl:            3.0-0
    numpy:            1.16.0-py36h99e49ec_1
    numpy-base:       1.16.0-py36h2f8d375_1
    openblas:         0.3.3-3
    openblas-devel:   0.3.3-3
    openssl:          1.1.1d-h7b6447c_4
    pcre:             8.43-he6710b0_0
    pip:              20.0.2-py36_1
    protobuf:         3.6.1-py36he6710b0_0
    python:           3.6.10-h0371630_0
    readline:         7.0-h7b6447c_5
    setuptools:       45.2.0-py36_0
    six:              1.14.0-py36_0
    sqlite:           3.31.1-h7b6447c_0
    swig:             3.0.12-h38cdd7d_3
    tk:               8.6.8-hbc83047_0
    wheel:            0.34.2-py36_0
    xz:               5.2.4-h14c3975_4
    zlib:             1.2.11-h7b6447c_3

Preparing transaction: ...working... done
Verifying transaction: ...working... done
Executing transaction: ...working... done
Collecting package metadata (repodata.json): ...working... done
Solving environment: ...working... done
Collecting package metadata (repodata.json): ...working... done
Solving environment: ...working... failed

Leaving build/test directories:
  Work:
 /home/dcsysh/anaconda3/conda-bld/work
  Test:
 /home/dcsysh/anaconda3/conda-bld/test_tmp
Leaving build/test environments:
  Test:
source activate  /home/dcsysh/anaconda3/conda-bld/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_
  Build:
source activate  /home/dcsysh/anaconda3/conda-bld/_build_env


Traceback (most recent call last):
  File ""/home/dcsysh/anaconda3/lib/python3.6/site-packages/conda_build/environ.py"", line 757, in get_install_actions
    actions = install_actions(prefix, index, specs, force=True)
  File ""/home/dcsysh/anaconda3/lib/python3.6/site-packages/conda/common/io.py"", line 88, in decorated
    return f(*args, **kwds)
  File ""/home/dcsysh/anaconda3/lib/python3.6/site-packages/conda/plan.py"", line 474, in install_actions
    txn = solver.solve_for_transaction(prune=prune, ignore_pinned=not pinned)
  File ""/home/dcsysh/anaconda3/lib/python3.6/site-packages/conda/core/solve.py"", line 117, in solve_for_transaction
    should_retry_solve)
  File ""/home/dcsysh/anaconda3/lib/python3.6/site-packages/conda/core/solve.py"", line 158, in solve_for_diff
    force_remove, should_retry_solve)
  File ""/home/dcsysh/anaconda3/lib/python3.6/site-packages/conda/core/solve.py"", line 275, in solve_final_state
    ssc = self._add_specs(ssc)
  File ""/home/dcsysh/anaconda3/lib/python3.6/site-packages/conda/core/solve.py"", line 555, in _add_specs
    explicit_pool = ssc.r._get_package_pool(self.specs_to_add)
  File ""/home/dcsysh/anaconda3/lib/python3.6/site-packages/conda/resolve.py"", line 553, in _get_package_pool
    pool = self.get_reduced_index(specs)
  File ""/home/dcsysh/anaconda3/lib/python3.6/site-packages/conda/common/io.py"", line 88, in decorated
    return f(*args, **kwds)
  File ""/home/dcsysh/anaconda3/lib/python3.6/site-packages/conda/resolve.py"", line 574, in get_reduced_index
    explicit_specs, features = self.verify_specs(explicit_specs)
  File ""/home/dcsysh/anaconda3/lib/python3.6/site-packages/conda/resolve.py"", line 288, in verify_specs
    raise ResolvePackageNotFound(bad_deps)
conda.exceptions.ResolvePackageNotFound:
  - onnx[version='>=1.3.0']

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/dcsysh/anaconda3/bin/conda-build"", line 11, in <module>
    sys.exit(main())
  File ""/home/dcsysh/anaconda3/lib/python3.6/site-packages/conda_build/cli/main_build.py"", line 469, in main
    execute(sys.argv[1:])
  File ""/home/dcsysh/anaconda3/lib/python3.6/site-packages/conda_build/cli/main_build.py"", line 460, in execute
    verify=args.verify, variants=args.variants)
  File ""/home/dcsysh/anaconda3/lib/python3.6/site-packages/conda_build/api.py"", line 209, in build
    notest=notest, need_source_download=need_source_download, variants=variants)
  File ""/home/dcsysh/anaconda3/lib/python3.6/site-packages/conda_build/build.py"", line 2344, in build_tree
    notest=notest,
  File ""/home/dcsysh/anaconda3/lib/python3.6/site-packages/conda_build/build.py"", line 1408, in build
    create_build_envs(top_level_pkg, notest)
  File ""/home/dcsysh/anaconda3/lib/python3.6/site-packages/conda_build/build.py"", line 1292, in create_build_envs
    raise e
  File ""/home/dcsysh/anaconda3/lib/python3.6/site-packages/conda_build/build.py"", line 1282, in create_build_envs
    channel_urls=tuple(m.config.channel_urls))
  File ""/home/dcsysh/anaconda3/lib/python3.6/site-packages/conda_build/environ.py"", line 759, in get_install_actions
    raise DependencyNeedsBuildingError(exc, subdir=subdir)
conda_build.exceptions.DependencyNeedsBuildingError: Unsatisfiable dependencies for platform linux-64: {""onnx[version='>=1.3.0']""}
```","{""url"": ""https://api.github.com/repos/apache/singa/issues/623/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/623,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5NjE3NDEwNA==,singa,596174104,623,NA,nudles,3797447,Wei Wang,,NA,2020-03-08T07:04:26Z,2020-03-08T07:04:26Z,"you may need to add the conda-forge channel manually in the build command

`conda-build -c conda-forge ...`

This is because the onnx package is in the conda-forge channel, which is not the default channel.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5NjE3NDEwNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/623,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5NjE3NTIzNw==,singa,596175237,623,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-03-08T07:22:30Z,2020-03-08T07:22:30Z,"@nudles ok, thanks a lot! 

> you may need to add the conda-forge channel manually in the build command
> conda-build -c conda-forge ...
> This is because the onnx package is in the conda-forge channel, which is not the default channel.

","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5NjE3NTIzNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/623,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5NjIxMDk0OQ==,singa,596210949,623,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-03-08T14:22:58Z,2020-03-08T14:22:58Z,"thanks, keeps trying","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5NjIxMDk0OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/623,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5NjMwMTMwNw==,singa,596301307,623,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-03-09T02:15:40Z,2020-03-09T02:15:40Z,"Thanks a lot, seems I have learnt the basic how to build a singa conda package now in a docker container
The following is the build log
```
root@3c17fd6cb72e:~/dcsysh/singa/tool/conda/singa# conda-build -c conda-forge . --python 3.6
No numpy version specified in conda_build_config.yaml.  Falling back to default numpy value of 1.11
WARNING:conda_build.metadata:No numpy version specified in conda_build_config.yaml.  Falling back to default numpy value of 1.11
Copying /root/dcsysh/singa to /root/miniconda/conda-bld/singa_1583719327583/work/
Adding in variants from internal_defaults
INFO:conda_build.variants:Adding in variants from internal_defaults
Adding in variants from /root/dcsysh/singa/tool/conda/singa/conda_build_config.yaml
INFO:conda_build.variants:Adding in variants from /root/dcsysh/singa/tool/conda/singa/conda_build_config.yaml
Adding in variants from config.variant
INFO:conda_build.variants:Adding in variants from config.variant
/root/miniconda/lib/python3.7/site-packages/conda_build/environ.py:427: UserWarning: The environment variable 'CUDA' is being passed through with value '10.0'.  If you are splitting build and test phases with --no-test, please ensure that this value is also set similarly at test time.
  UserWarning
Attempting to finalize metadata for singa
INFO:conda_build.metadata:Attempting to finalize metadata for singa
Collecting package metadata (repodata.json): ...working... done
Solving environment: ...working... done
Collecting package metadata (repodata.json): ...working... done
Solving environment: ...working... done
Collecting package metadata (repodata.json): ...working... done
Solving environment: ...working... done
Collecting package metadata (repodata.json): ...working... done
Solving environment: ...working... done
Adding .* to spec 'libopenblas 0.3.3' to ensure satisfiability.  Please consider putting {{ var_name }}.* or some relational operator (>/</>=/<=) on this spec in meta.yaml, or if req is also a build req, using {{ pin_compatible() }} jinja2 function instead.  See https://conda.io/docs/user-guide/tasks/build-packages/variants.html#pinning-at-the-variant-level
WARNING:conda_build.utils:Adding .* to spec 'libopenblas 0.3.3' to ensure satisfiability.  Please consider putting {{ var_name }}.* or some relational operator (>/</>=/<=) on this spec in meta.yaml, or if req is also a build req, using {{ pin_compatible() }} jinja2 function instead.  See https://conda.io/docs/user-guide/tasks/build-packages/variants.html#pinning-at-the-variant-level
WARNING conda_build.utils:ensure_valid_spec(1749): Adding .* to spec 'libopenblas 0.3.3' to ensure satisfiability.  Please consider putting {{ var_name }}.* or some relational operator (>/</>=/<=) on this spec in meta.yaml, or if req is also a build req, using {{ pin_compatible() }} jinja2 function instead.  See https://conda.io/docs/user-guide/tasks/build-packages/variants.html#pinning-at-the-variant-level
Adding .* to spec 'libprotobuf 3.6.1' to ensure satisfiability.  Please consider putting {{ var_name }}.* or some relational operator (>/</>=/<=) on this spec in meta.yaml, or if req is also a build req, using {{ pin_compatible() }} jinja2 function instead.  See https://conda.io/docs/user-guide/tasks/build-packages/variants.html#pinning-at-the-variant-level
WARNING:conda_build.utils:Adding .* to spec 'libprotobuf 3.6.1' to ensure satisfiability.  Please consider putting {{ var_name }}.* or some relational operator (>/</>=/<=) on this spec in meta.yaml, or if req is also a build req, using {{ pin_compatible() }} jinja2 function instead.  See https://conda.io/docs/user-guide/tasks/build-packages/variants.html#pinning-at-the-variant-level
WARNING conda_build.utils:ensure_valid_spec(1749): Adding .* to spec 'libprotobuf 3.6.1' to ensure satisfiability.  Please consider putting {{ var_name }}.* or some relational operator (>/</>=/<=) on this spec in meta.yaml, or if req is also a build req, using {{ pin_compatible() }} jinja2 function instead.  See https://conda.io/docs/user-guide/tasks/build-packages/variants.html#pinning-at-the-variant-level
BUILD START: ['singa-2.1.0.dev-cudnn7.3.1_cuda10.0_py36.tar.bz2']
Collecting package metadata (repodata.json): ...working... done
Solving environment: ...working... done

## Package Plan ##

  environment location: /root/miniconda/conda-bld/singa_1583719327583/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl


The following NEW packages will be INSTALLED:

    _libgcc_mutex:    0.1-conda_forge                        conda-forge
    _openmp_mutex:    4.5-0_gnu                              conda-forge
    blas:             1.1-openblas                           conda-forge
    ca-certificates:  2019.11.28-hecc5488_0                  conda-forge
    certifi:          2019.11.28-py36_0                      conda-forge
    cudatoolkit:      10.0.130-0
    cudnn:            7.3.1-cuda10.0_0
    glog:             0.3.5-hf484d3e_1001                    conda-forge
    intel-openmp:     2018.0.3-0
    ld_impl_linux-64: 2.33.1-h53a641e_8                      conda-forge
    libffi:           3.2.1-he1b5a44_1006                    conda-forge
    libgcc-ng:        9.2.0-h24d8f2e_2                       conda-forge
    libgfortran-ng:   7.3.0-hdf63c60_5                       conda-forge
    libgomp:          9.2.0-h24d8f2e_2                       conda-forge
    libmklml:         2018.0.3-0
    libprotobuf:      3.6.1-hdbcaa40_1001                    conda-forge
    libstdcxx-ng:     9.2.0-hdf63c60_2                       conda-forge
    mkl-dnn:          0.14-h6bb024c_0
    ncurses:          6.1-hf484d3e_1002                      conda-forge
    numpy:            1.16.0-py36_blas_openblash1522bff_1000 conda-forge [blas_openblas]
    openblas:         0.3.3-h9ac9557_1001                    conda-forge
    openssl:          1.1.1d-h516909a_0                      conda-forge
    pcre:             8.44-he1b5a44_0                        conda-forge
    pip:              20.0.2-py_2                            conda-forge
    protobuf:         3.6.1-py36hf484d3e_1001                conda-forge
    python:           3.6.10-h9d8adfe_1009_cpython           conda-forge
    python_abi:       3.6-1_cp36m                            conda-forge
    readline:         8.0-hf8c457e_0                         conda-forge
    setuptools:       46.0.0-py36_0                          conda-forge
    six:              1.14.0-py36_0                          conda-forge
    sqlite:           3.30.1-hcee41ef_0                      conda-forge
    swig:             3.0.12-hf484d3e_1003                   conda-forge
    tk:               8.6.10-hed695b0_0                      conda-forge
    wheel:            0.34.2-py_1                            conda-forge
    xz:               5.2.4-h14c3975_1001                    conda-forge
    zlib:             1.2.11-h516909a_1006                   conda-forge

Preparing transaction: ...working... done
Verifying transaction: ...working... done
Executing transaction: ...working... done
Collecting package metadata (repodata.json): ...working... done
Solving environment: ...working... done
Collecting package metadata (repodata.json): ...working... done
Solving environment: ...working... done

## Package Plan ##

  environment location: /root/miniconda/conda-bld/singa_1583719327583/_build_env


The following NEW packages will be INSTALLED:

    _libgcc_mutex:          0.1-conda_forge            conda-forge
    _openmp_mutex:          4.5-0_gnu                  conda-forge
    binutils_impl_linux-64: 2.28.1-had2808c_3
    binutils_linux-64:      5.4.0-had2808c_24
    bzip2:                  1.0.8-h516909a_2           conda-forge
    ca-certificates:        2019.11.28-hecc5488_0      conda-forge
    cmake:                  3.16.4-h28c56e5_0          conda-forge
    expat:                  2.2.9-he1b5a44_2           conda-forge
    gcc_impl_linux-64:      5.4.0-habb00fd_3
    gcc_linux-64:           5.4.0-h98af8de_24
    gxx_impl_linux-64:      5.4.0-hdf63c60_3
    gxx_linux-64:           5.4.0-h98af8de_24
    krb5:                   1.16.4-h2fd8d38_0          conda-forge
    libcurl:                7.68.0-hda55be3_0          conda-forge
    libedit:                3.1.20170329-hf8c457e_1001 conda-forge
    libgcc-ng:              9.2.0-h24d8f2e_2           conda-forge
    libgomp:                9.2.0-h24d8f2e_2           conda-forge
    libssh2:                1.8.2-h22169c7_2           conda-forge
    libstdcxx-ng:           9.2.0-hdf63c60_2           conda-forge
    libuv:                  1.34.0-h516909a_0          conda-forge
    make:                   4.3-h516909a_0             conda-forge
    ncurses:                6.1-hf484d3e_1002          conda-forge
    openssl:                1.1.1d-h516909a_0          conda-forge
    rhash:                  1.3.6-h14c3975_1001        conda-forge
    tk:                     8.6.10-hed695b0_0          conda-forge
    xz:                     5.2.4-h14c3975_1001        conda-forge
    zlib:                   1.2.11-h516909a_1006       conda-forge

Preparing transaction: ...working... done
Verifying transaction: ...working... done
Executing transaction: ...working... done
source tree in: /root/miniconda/conda-bld/singa_1583719327583/work
export PREFIX=/root/miniconda/conda-bld/singa_1583719327583/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl
export BUILD_PREFIX=/root/miniconda/conda-bld/singa_1583719327583/_build_env
export SRC_DIR=/root/miniconda/conda-bld/singa_1583719327583/work
INFO: activate-binutils_linux-64.sh made the following environmental changes:
+ADDR2LINE=$BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-addr2line
+AR=$BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-ar
+AS=$BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-as
+CXXFILT=$BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-c++filt
+ELFEDIT=$BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-elfedit
+GPROF=$BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-gprof
+HOST=x86_64-conda_cos6-linux-gnu
+LD=$BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-ld
+LD_GOLD=$BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-ld.gold
+NM=$BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-nm
+OBJCOPY=$BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-objcopy
+OBJDUMP=$BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-objdump
+RANLIB=$BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-ranlib
+READELF=$BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-readelf
+SIZE=$BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-size
+STRINGS=$BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-strings
+STRIP=$BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-strip
INFO: activate-gcc_linux-64.sh made the following environmental changes:
+CC=$BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-cc
+CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -O2 -pipe -I$PREFIX/include -fdebug-prefix-map=${SRC_DIR}=/usr/local/src/conda/${PKG_NAME}-${PKG_VERSION} -fdebug-prefix-map=${PREFIX}=/usr/local/src/conda-prefix
+CPP=$BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-cpp
+CPPFLAGS=-DNDEBUG -D_FORTIFY_SOURCE=2 -O2
+DEBUG_CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe -I$PREFIX/include -fdebug-prefix-map=${SRC_DIR}=/usr/local/src/conda/${PKG_NAME}-${PKG_VERSION} -fdebug-prefix-map=${PREFIX}=/usr/local/src/conda-prefix
+DEBUG_CPPFLAGS=-D_DEBUG -D_FORTIFY_SOURCE=2 -Og
+GCC=$BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-gcc
+GCC_AR=$BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-gcc-ar
+GCC_NM=$BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-gcc-nm
+GCC_RANLIB=$BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-gcc-ranlib
+LDFLAGS=-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,-rpath,$PREFIX/lib -L$PREFIX/lib
+_PYTHON_SYSCONFIGDATA_NAME=_sysconfigdata_x86_64_conda_cos6_linux_gnu
INFO: activate-gxx_linux-64.sh made the following environmental changes:
+CXX=$BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-c++
+CXXFLAGS=-fvisibility-inlines-hidden -std=c++11 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -O2 -pipe -I$PREFIX/include -fdebug-prefix-map=${SRC_DIR}=/usr/local/src/conda/${PKG_NAME}-${PKG_VERSION} -fdebug-prefix-map=${PREFIX}=/usr/local/src/conda-prefix
+DEBUG_CXXFLAGS=-fvisibility-inlines-hidden -std=c++11 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe -I$PREFIX/include -fdebug-prefix-map=${SRC_DIR}=/usr/local/src/conda/${PKG_NAME}-${PKG_VERSION} -fdebug-prefix-map=${PREFIX}=/usr/local/src/conda-prefix
+GXX=$BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-g++
-- The C compiler identification is GNU 5.4.0
-- The CXX compiler identification is GNU 5.4.0
-- Check for working C compiler: $BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-cc
-- Check for working C compiler: $BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-cc -- works
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Detecting C compile features
-- Detecting C compile features - done
-- Check for working CXX compiler: $BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-c++
-- Check for working CXX compiler: $BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-c++ -- works
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Found Protobuf: $PREFIX/lib/libprotobuf.so;-lpthread (found suitable version ""3.6.1"", minimum required is ""3.0"")
-- Found CBLAS: $PREFIX/include
-- Found GLOG: $PREFIX/include
-- Found Threads: TRUE
CMake Warning at /root/miniconda/conda-bld/singa_1583719327583/_build_env/share/cmake-3.16/Modules/FindCUDA.cmake:900 (message):
  Expecting to find librt for libcudart_static, but didn't find it.
Call Stack (most recent call first):
  cmake/Cuda.cmake:20 (FIND_PACKAGE)
  cmake/Dependencies.cmake:85 (INCLUDE)
  CMakeLists.txt:75 (INCLUDE)


-- Found cuda_v10.0
-- Found CUDNN: $PREFIX/include
-- Found Cudnn_7301 at $PREFIX/include $PREFIX/lib/libcudnn.so
-- Found PythonInterp: $PREFIX/bin/python3 (found suitable version ""3.6.10"", minimum required is ""3"")
-- Found PythonLibs: $PREFIX/lib/libpython3.6m.so (found suitable version ""3.6.10"", minimum required is ""3"")
-- Found SWIG: $PREFIX/bin/swig (found suitable version ""3.0.12"", minimum required is ""3.0.10"")
-- Configuring done
-- Generating done
CMake Warning:
  Manually-specified variables were not used by the project:

    USE_DNNL


-- Build files have been written to: $SRC_DIR/build
make[1]: Entering directory '$SRC_DIR/build'
make[2]: Entering directory '$SRC_DIR/build'
Scanning dependencies of target cnmem
make[2]: Leaving directory '$SRC_DIR/build'
make[2]: Entering directory '$SRC_DIR/build'
[  1%] Creating directories for 'cnmem'
[  2%] Performing download step (git clone) for 'cnmem'
Cloning into 'cnmem'...
Already on 'master'
Your branch is up-to-date with 'origin/master'.
[  3%] No patch step for 'cnmem'
[  4%] Performing update step for 'cnmem'
Current branch master is up to date.
[  5%] Performing configure step for 'cnmem'
-- The C compiler identification is GNU 5.4.0
-- The CXX compiler identification is GNU 5.4.0
-- Check for working C compiler: $BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-cc
-- Check for working C compiler: $BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-cc -- works
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Detecting C compile features
-- Detecting C compile features - done
-- Check for working CXX compiler: $BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-c++
-- Check for working CXX compiler: $BUILD_PREFIX/bin/x86_64-conda_cos6-linux-gnu-c++ -- works
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Looking for pthread.h
-- Looking for pthread.h - found
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed
-- Looking for pthread_create in pthreads
-- Looking for pthread_create in pthreads - not found
-- Looking for pthread_create in pthread
-- Looking for pthread_create in pthread - found
-- Found Threads: TRUE
CMake Warning at /root/miniconda/conda-bld/singa_1583719327583/_build_env/share/cmake-3.16/Modules/FindCUDA.cmake:900 (message):
  Expecting to find librt for libcudart_static, but didn't find it.
Call Stack (most recent call first):
  CMakeLists.txt:6 (find_package)


-- Configuring done
-- Generating done
-- Build files have been written to: $SRC_DIR/build/cnmem-prefix/src/cnmem-build
[  6%] Performing build step for 'cnmem'
make[3]: Entering directory '$SRC_DIR/build/cnmem-prefix/src/cnmem-build'
make[4]: Entering directory '$SRC_DIR/build/cnmem-prefix/src/cnmem-build'
make[5]: Entering directory '$SRC_DIR/build/cnmem-prefix/src/cnmem-build'
Scanning dependencies of target cnmem
make[5]: Leaving directory '$SRC_DIR/build/cnmem-prefix/src/cnmem-build'
make[5]: Entering directory '$SRC_DIR/build/cnmem-prefix/src/cnmem-build'
[ 50%] Building CXX object CMakeFiles/cnmem.dir/src/cnmem.cpp.o
[100%] Linking CXX static library libcnmem.a
make[5]: Leaving directory '$SRC_DIR/build/cnmem-prefix/src/cnmem-build'
[100%] Built target cnmem
make[4]: Leaving directory '$SRC_DIR/build/cnmem-prefix/src/cnmem-build'
make[3]: Leaving directory '$SRC_DIR/build/cnmem-prefix/src/cnmem-build'
[  7%] Performing install step for 'cnmem'
make[3]: Entering directory '$SRC_DIR/build/cnmem-prefix/src/cnmem-build'
make[4]: Entering directory '$SRC_DIR/build/cnmem-prefix/src/cnmem-build'
make[5]: Entering directory '$SRC_DIR/build/cnmem-prefix/src/cnmem-build'
make[5]: Leaving directory '$SRC_DIR/build/cnmem-prefix/src/cnmem-build'
[100%] Built target cnmem
make[4]: Leaving directory '$SRC_DIR/build/cnmem-prefix/src/cnmem-build'
Install the project...
-- Install configuration: """"
-- Installing: $SRC_DIR/build/lib/libcnmem.a
-- Installing: $SRC_DIR/build/include/cnmem.h
make[3]: Leaving directory '$SRC_DIR/build/cnmem-prefix/src/cnmem-build'
[  8%] Completed 'cnmem'
make[2]: Leaving directory '$SRC_DIR/build'
[  8%] Built target cnmem
make[2]: Entering directory '$SRC_DIR/build'
Scanning dependencies of target copy_protobuf
make[2]: Leaving directory '$SRC_DIR/build'
make[2]: Entering directory '$SRC_DIR/build'
[  9%] Running cpp protocol buffer compiler on $SRC_DIR/src/proto/model.proto
[libprotobuf WARNING google/protobuf/compiler/parser.cc:562] No syntax specified for the proto file: model.proto. Please use 'syntax = ""proto2"";' or 'syntax = ""proto3"";' to specify a syntax version. (Defaulted to proto2 syntax.)
[ 10%] Running cpp protocol buffer compiler on $SRC_DIR/src/proto/caffe.proto
[ 11%] Running cpp protocol buffer compiler on $SRC_DIR/src/proto/core.proto
[libprotobuf WARNING google/protobuf/compiler/parser.cc:562] No syntax specified for the proto file: core.proto. Please use 'syntax = ""proto2"";' or 'syntax = ""proto3"";' to specify a syntax version. (Defaulted to proto2 syntax.)
[ 12%] Running cpp protocol buffer compiler on $SRC_DIR/src/proto/io.proto
[libprotobuf WARNING google/protobuf/compiler/parser.cc:562] No syntax specified for the proto file: io.proto. Please use 'syntax = ""proto2"";' or 'syntax = ""proto3"";' to specify a syntax version. (Defaulted to proto2 syntax.)
[ 13%] Copying Protobuf headers
make[2]: Leaving directory '$SRC_DIR/build'
[ 13%] Built target copy_protobuf
make[2]: Entering directory '$SRC_DIR/build'
[ 14%] Building NVCC (Device) object src/CMakeFiles/cuda_compile_1.dir/core/tensor/cuda_compile_1_generated_math_kernel.cu.o
Scanning dependencies of target singa_objects
make[2]: Leaving directory '$SRC_DIR/build'
make[2]: Entering directory '$SRC_DIR/build'
[ 15%] Building CXX object src/CMakeFiles/singa_objects.dir/caffe.pb.cc.o
[ 16%] Building CXX object src/CMakeFiles/singa_objects.dir/core.pb.cc.o
[ 17%] Building CXX object src/CMakeFiles/singa_objects.dir/io.pb.cc.o
[ 18%] Building CXX object src/CMakeFiles/singa_objects.dir/model.pb.cc.o
[ 19%] Building CXX object src/CMakeFiles/singa_objects.dir/utils/channel.cc.o
[ 20%] Building CXX object src/CMakeFiles/singa_objects.dir/utils/logging.cc.o
[ 21%] Building CXX object src/CMakeFiles/singa_objects.dir/io/binfile_reader.cc.o
[ 22%] Building CXX object src/CMakeFiles/singa_objects.dir/io/binfile_writer.cc.o
[ 23%] Building CXX object src/CMakeFiles/singa_objects.dir/io/communicator.cc.o
[ 24%] Building CXX object src/CMakeFiles/singa_objects.dir/io/csv_decoder.cc.o
[ 25%] Building CXX object src/CMakeFiles/singa_objects.dir/io/csv_encoder.cc.o
[ 26%] Building CXX object src/CMakeFiles/singa_objects.dir/io/image_transformer.cc.o
[ 27%] Building CXX object src/CMakeFiles/singa_objects.dir/io/jpg_decoder.cc.o
[ 28%] Building CXX object src/CMakeFiles/singa_objects.dir/io/jpg_encoder.cc.o
[ 29%] Building CXX object src/CMakeFiles/singa_objects.dir/io/lmdb_reader.cc.o
[ 30%] Building CXX object src/CMakeFiles/singa_objects.dir/io/lmdb_writer.cc.o
[ 31%] Building CXX object src/CMakeFiles/singa_objects.dir/io/snapshot.cc.o
[ 32%] Building CXX object src/CMakeFiles/singa_objects.dir/io/textfile_reader.cc.o
[ 34%] Building CXX object src/CMakeFiles/singa_objects.dir/io/textfile_writer.cc.o
[ 35%] Building CXX object src/CMakeFiles/singa_objects.dir/io/network/endpoint.cc.o
[ 36%] Building CXX object src/CMakeFiles/singa_objects.dir/io/network/message.cc.o
[ 37%] Building CXX object src/CMakeFiles/singa_objects.dir/core/device/cpp_cpu.cc.o
[ 38%] Building CXX object src/CMakeFiles/singa_objects.dir/core/device/cuda_gpu.cc.o
[ 39%] Building CXX object src/CMakeFiles/singa_objects.dir/core/device/device.cc.o
[ 40%] Building CXX object src/CMakeFiles/singa_objects.dir/core/device/opencl_device.cc.o
[ 41%] Building CXX object src/CMakeFiles/singa_objects.dir/core/device/platform.cc.o
[ 42%] Building CXX object src/CMakeFiles/singa_objects.dir/core/memory/memory.cc.o
[ 43%] Building CXX object src/CMakeFiles/singa_objects.dir/core/scheduler/scheduler.cc.o
[ 44%] Building CXX object src/CMakeFiles/singa_objects.dir/core/tensor/sparse_tensor.cc.o
[ 45%] Building CXX object src/CMakeFiles/singa_objects.dir/core/tensor/tensor.cc.o
/root/miniconda/conda-bld/singa_1583719327583/work/src/core/tensor/tensor.cc: In function 'void singa::SoftMax(const singa::Tensor&, singa::Tensor*, int)':
/root/miniconda/conda-bld/singa_1583719327583/work/src/core/tensor/tensor.cc:758:13: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
       if (i < axis)
             ^
In file included from /root/miniconda/conda-bld/singa_1583719327583/work/include/singa/utils/logging.h:31:0,
                 from /root/miniconda/conda-bld/singa_1583719327583/work/include/singa/core/common.h:26,
                 from /root/miniconda/conda-bld/singa_1583719327583/work/include/singa/core/tensor.h:26,
                 from /root/miniconda/conda-bld/singa_1583719327583/work/src/core/tensor/tensor.cc:18:
/root/miniconda/conda-bld/singa_1583719327583/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl/include/glog/logging.h: In instantiation of 'std::__cxx11::string* google::Check_LEImpl(const T1&, const T2&, const char*) [with T1 = long unsigned int; T2 = int; std::__cxx11::string = std::__cxx11::basic_string<char>]':
/root/miniconda/conda-bld/singa_1583719327583/work/src/core/tensor/./tensor_math_cuda.h:58:3:   required from here
/root/miniconda/conda-bld/singa_1583719327583/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl/include/glog/logging.h:719:32: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
 DEFINE_CHECK_OP_IMPL(Check_LE, <=)
                                ^
/root/miniconda/conda-bld/singa_1583719327583/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl/include/glog/logging.h:148:53: note: in definition of macro 'GOOGLE_PREDICT_TRUE'
 #define GOOGLE_PREDICT_TRUE(x) (__builtin_expect(!!(x), 1))
                                                     ^
/root/miniconda/conda-bld/singa_1583719327583/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl/include/glog/logging.h:719:1: note: in expansion of macro 'DEFINE_CHECK_OP_IMPL'
 DEFINE_CHECK_OP_IMPL(Check_LE, <=)
 ^
/root/miniconda/conda-bld/singa_1583719327583/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl/include/glog/logging.h: In instantiation of 'std::__cxx11::string* google::Check_EQImpl(const T1&, const T2&, const char*) [with T1 = long unsigned int; T2 = int; std::__cxx11::string = std::__cxx11::basic_string<char>]':
/root/miniconda/conda-bld/singa_1583719327583/work/src/core/tensor/tensor.cc:353:7:   required from here
/root/miniconda/conda-bld/singa_1583719327583/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl/include/glog/logging.h:717:32: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
 DEFINE_CHECK_OP_IMPL(Check_EQ, ==)  // Compilation error with CHECK_EQ(NULL, x)?
                                ^
/root/miniconda/conda-bld/singa_1583719327583/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl/include/glog/logging.h:148:53: note: in definition of macro 'GOOGLE_PREDICT_TRUE'
 #define GOOGLE_PREDICT_TRUE(x) (__builtin_expect(!!(x), 1))
                                                     ^
/root/miniconda/conda-bld/singa_1583719327583/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl/include/glog/logging.h:717:1: note: in expansion of macro 'DEFINE_CHECK_OP_IMPL'
 DEFINE_CHECK_OP_IMPL(Check_EQ, ==)  // Compilation error with CHECK_EQ(NULL, x)?
 ^
/root/miniconda/conda-bld/singa_1583719327583/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl/include/glog/logging.h: In instantiation of 'std::__cxx11::string* google::Check_GEImpl(const T1&, const T2&, const char*) [with T1 = long unsigned int; T2 = int; std::__cxx11::string = std::__cxx11::basic_string<char>]':
/root/miniconda/conda-bld/singa_1583719327583/work/src/core/tensor/tensor.cc:506:5:   required from here
/root/miniconda/conda-bld/singa_1583719327583/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl/include/glog/logging.h:721:32: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
 DEFINE_CHECK_OP_IMPL(Check_GE, >=)
                                ^
/root/miniconda/conda-bld/singa_1583719327583/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl/include/glog/logging.h:148:53: note: in definition of macro 'GOOGLE_PREDICT_TRUE'
 #define GOOGLE_PREDICT_TRUE(x) (__builtin_expect(!!(x), 1))
                                                     ^
/root/miniconda/conda-bld/singa_1583719327583/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl/include/glog/logging.h:721:1: note: in expansion of macro 'DEFINE_CHECK_OP_IMPL'
 DEFINE_CHECK_OP_IMPL(Check_GE, >=)
 ^
[ 46%] Building CXX object src/CMakeFiles/singa_objects.dir/model/feed_forward_net.cc.o
[ 47%] Building CXX object src/CMakeFiles/singa_objects.dir/model/layer/activation.cc.o
[ 48%] Building CXX object src/CMakeFiles/singa_objects.dir/model/layer/batchnorm.cc.o
[ 49%] Building CXX object src/CMakeFiles/singa_objects.dir/model/layer/concat.cc.o
In file included from /root/miniconda/conda-bld/singa_1583719327583/work/include/singa/utils/logging.h:31:0,
                 from /root/miniconda/conda-bld/singa_1583719327583/work/include/singa/core/common.h:26,
                 from /root/miniconda/conda-bld/singa_1583719327583/work/include/singa/core/tensor.h:26,
                 from /root/miniconda/conda-bld/singa_1583719327583/work/include/singa/model/layer.h:27,
                 from /root/miniconda/conda-bld/singa_1583719327583/work/src/model/layer/concat.cc:19:
/root/miniconda/conda-bld/singa_1583719327583/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl/include/glog/logging.h: In instantiation of 'std::__cxx11::string* google::Check_GEImpl(const T1&, const T2&, const char*) [with T1 = long unsigned int; T2 = int; std::__cxx11::string = std::__cxx11::basic_string<char>]':
/root/miniconda/conda-bld/singa_1583719327583/work/src/model/layer/concat.cc:47:8:   required from here
/root/miniconda/conda-bld/singa_1583719327583/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl/include/glog/logging.h:721:32: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
 DEFINE_CHECK_OP_IMPL(Check_GE, >=)
                                ^
/root/miniconda/conda-bld/singa_1583719327583/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl/include/glog/logging.h:148:53: note: in definition of macro 'GOOGLE_PREDICT_TRUE'
 #define GOOGLE_PREDICT_TRUE(x) (__builtin_expect(!!(x), 1))
                                                     ^
/root/miniconda/conda-bld/singa_1583719327583/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl/include/glog/logging.h:721:1: note: in expansion of macro 'DEFINE_CHECK_OP_IMPL'
 DEFINE_CHECK_OP_IMPL(Check_GE, >=)
 ^
[ 50%] Building CXX object src/CMakeFiles/singa_objects.dir/model/layer/convolution.cc.o
[ 51%] Building CXX object src/CMakeFiles/singa_objects.dir/model/layer/cudnn_activation.cc.o
[ 52%] Building CXX object src/CMakeFiles/singa_objects.dir/model/layer/cudnn_batchnorm.cc.o
[ 53%] Building CXX object src/CMakeFiles/singa_objects.dir/model/layer/cudnn_convolution.cc.o
[ 54%] Building CXX object src/CMakeFiles/singa_objects.dir/model/layer/cudnn_dropout.cc.o
[ 55%] Building CXX object src/CMakeFiles/singa_objects.dir/model/layer/cudnn_lrn.cc.o
[ 56%] Building CXX object src/CMakeFiles/singa_objects.dir/model/layer/cudnn_pooling.cc.o
[ 57%] Building CXX object src/CMakeFiles/singa_objects.dir/model/layer/cudnn_rnn.cc.o
[ 58%] Building CXX object src/CMakeFiles/singa_objects.dir/model/layer/cudnn_softmax.cc.o
[ 59%] Building CXX object src/CMakeFiles/singa_objects.dir/model/layer/dense.cc.o
[ 60%] Building CXX object src/CMakeFiles/singa_objects.dir/model/layer/dropout.cc.o
[ 61%] Building CXX object src/CMakeFiles/singa_objects.dir/model/layer/flatten.cc.o
[ 62%] Building CXX object src/CMakeFiles/singa_objects.dir/model/layer/lrn.cc.o
[ 63%] Building CXX object src/CMakeFiles/singa_objects.dir/model/layer/merge.cc.o
[ 64%] Building CXX object src/CMakeFiles/singa_objects.dir/model/layer/opencl_convolution.cc.o
[ 65%] Building CXX object src/CMakeFiles/singa_objects.dir/model/layer/opencl_pooling.cc.o
[ 67%] Building CXX object src/CMakeFiles/singa_objects.dir/model/layer/pooling.cc.o
[ 68%] Building CXX object src/CMakeFiles/singa_objects.dir/model/layer/prelu.cc.o
[ 69%] Building CXX object src/CMakeFiles/singa_objects.dir/model/layer/rnn.cc.o
[ 70%] Building CXX object src/CMakeFiles/singa_objects.dir/model/layer/slice.cc.o
In file included from /root/miniconda/conda-bld/singa_1583719327583/work/include/singa/utils/logging.h:31:0,
                 from /root/miniconda/conda-bld/singa_1583719327583/work/include/singa/core/common.h:26,
                 from /root/miniconda/conda-bld/singa_1583719327583/work/include/singa/core/tensor.h:26,
                 from /root/miniconda/conda-bld/singa_1583719327583/work/include/singa/model/layer.h:27,
                 from /root/miniconda/conda-bld/singa_1583719327583/work/src/model/layer/slice.cc:19:
/root/miniconda/conda-bld/singa_1583719327583/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl/include/glog/logging.h: In instantiation of 'std::__cxx11::string* google::Check_GEImpl(const T1&, const T2&, const char*) [with T1 = int; T2 = unsigned int; std::__cxx11::string = std::__cxx11::basic_string<char>]':
/root/miniconda/conda-bld/singa_1583719327583/work/src/model/layer/slice.cc:33:3:   required from here
/root/miniconda/conda-bld/singa_1583719327583/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl/include/glog/logging.h:721:32: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
 DEFINE_CHECK_OP_IMPL(Check_GE, >=)
                                ^
/root/miniconda/conda-bld/singa_1583719327583/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl/include/glog/logging.h:148:53: note: in definition of macro 'GOOGLE_PREDICT_TRUE'
 #define GOOGLE_PREDICT_TRUE(x) (__builtin_expect(!!(x), 1))
                                                     ^
/root/miniconda/conda-bld/singa_1583719327583/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl/include/glog/logging.h:721:1: note: in expansion of macro 'DEFINE_CHECK_OP_IMPL'
 DEFINE_CHECK_OP_IMPL(Check_GE, >=)
 ^
[ 71%] Building CXX object src/CMakeFiles/singa_objects.dir/model/layer/softmax.cc.o
[ 72%] Building CXX object src/CMakeFiles/singa_objects.dir/model/layer/split.cc.o
[ 73%] Building CXX object src/CMakeFiles/singa_objects.dir/model/optimizer/adagrad.cc.o
[ 74%] Building CXX object src/CMakeFiles/singa_objects.dir/model/optimizer/local_all_reduce.cc.o
[ 75%] Building CXX object src/CMakeFiles/singa_objects.dir/model/optimizer/nesterov.cc.o
[ 76%] Building CXX object src/CMakeFiles/singa_objects.dir/model/optimizer/optimizer.cc.o
[ 77%] Building CXX object src/CMakeFiles/singa_objects.dir/model/optimizer/rmsprop.cc.o
[ 78%] Building CXX object src/CMakeFiles/singa_objects.dir/model/optimizer/sgd.cc.o
[ 79%] Building CXX object src/CMakeFiles/singa_objects.dir/model/loss/mse.cc.o
[ 80%] Building CXX object src/CMakeFiles/singa_objects.dir/model/loss/softmax_cross_entropy.cc.o
[ 81%] Building CXX object src/CMakeFiles/singa_objects.dir/model/metric/accuracy.cc.o
[ 82%] Building CXX object src/CMakeFiles/singa_objects.dir/model/updater/local_updater.cc.o
[ 83%] Building CXX object src/CMakeFiles/singa_objects.dir/model/updater/updater.cc.o
[ 84%] Building CXX object src/CMakeFiles/singa_objects.dir/model/operation/batchnorm.cc.o
[ 85%] Building CXX object src/CMakeFiles/singa_objects.dir/model/operation/convolution.cc.o
[ 86%] Building CXX object src/CMakeFiles/singa_objects.dir/model/operation/pooling.cc.o
/root/miniconda/conda-bld/singa_1583719327583/work/src/model/operation/pooling.cc: In function 'singa::Tensor singa::GpuPoolingForward(const singa::CudnnPoolingHandle&, const singa::Tensor&)':
/root/miniconda/conda-bld/singa_1583719327583/work/src/model/operation/pooling.cc:220:51: warning: narrowing conversion of '(int)(& cph)->singa::CudnnPoolingHandle::<anonymous>.singa::PoolingHandle::batchsize' from 'int' to 'long unsigned int' inside { } [-Wnarrowing]
                          x.device(), x.data_type());
                                                   ^
/root/miniconda/conda-bld/singa_1583719327583/work/src/model/operation/pooling.cc:219:31: warning: narrowing conversion of '(& cph)->singa::CudnnPoolingHandle::<anonymous>.singa::PoolingHandle::batchsize' from 'const int' to 'long unsigned int' inside { } [-Wnarrowing]
   Tensor output = Tensor({cph.batchsize, cph.channels, cph.pooled_height, cph.pooled_width},
                               ^
/root/miniconda/conda-bld/singa_1583719327583/work/src/model/operation/pooling.cc:220:51: warning: narrowing conversion of '(int)(& cph)->singa::CudnnPoolingHandle::<anonymous>.singa::PoolingHandle::channels' from 'int' to 'long unsigned int' inside { } [-Wnarrowing]
                          x.device(), x.data_type());
                                                   ^
/root/miniconda/conda-bld/singa_1583719327583/work/src/model/operation/pooling.cc:219:46: warning: narrowing conversion of '(& cph)->singa::CudnnPoolingHandle::<anonymous>.singa::PoolingHandle::channels' from 'const int' to 'long unsigned int' inside { } [-Wnarrowing]
   Tensor output = Tensor({cph.batchsize, cph.channels, cph.pooled_height, cph.pooled_width},
                                              ^
/root/miniconda/conda-bld/singa_1583719327583/work/src/model/operation/pooling.cc:220:51: warning: narrowing conversion of '(int)(& cph)->singa::CudnnPoolingHandle::<anonymous>.singa::PoolingHandle::pooled_height' from 'int' to 'long unsigned int' inside { } [-Wnarrowing]
                          x.device(), x.data_type());
                                                   ^
/root/miniconda/conda-bld/singa_1583719327583/work/src/model/operation/pooling.cc:219:60: warning: narrowing conversion of '(& cph)->singa::CudnnPoolingHandle::<anonymous>.singa::PoolingHandle::pooled_height' from 'const int' to 'long unsigned int' inside { } [-Wnarrowing]
   Tensor output = Tensor({cph.batchsize, cph.channels, cph.pooled_height, cph.pooled_width},
                                                            ^
/root/miniconda/conda-bld/singa_1583719327583/work/src/model/operation/pooling.cc:220:51: warning: narrowing conversion of '(int)(& cph)->singa::CudnnPoolingHandle::<anonymous>.singa::PoolingHandle::pooled_width' from 'int' to 'long unsigned int' inside { } [-Wnarrowing]
                          x.device(), x.data_type());
                                                   ^
/root/miniconda/conda-bld/singa_1583719327583/work/src/model/operation/pooling.cc:219:79: warning: narrowing conversion of '(& cph)->singa::CudnnPoolingHandle::<anonymous>.singa::PoolingHandle::pooled_width' from 'const int' to 'long unsigned int' inside { } [-Wnarrowing]
   Tensor output = Tensor({cph.batchsize, cph.channels, cph.pooled_height, cph.pooled_width},
                                                                               ^
make[2]: Leaving directory '$SRC_DIR/build'
[ 90%] Built target singa_objects
make[2]: Entering directory '$SRC_DIR/build'
Scanning dependencies of target singa
make[2]: Leaving directory '$SRC_DIR/build'
make[2]: Entering directory '$SRC_DIR/build'
[ 91%] Linking CXX shared library ../lib/libsinga.so
make[2]: Leaving directory '$SRC_DIR/build'
[ 92%] Built target singa
make[2]: Entering directory '$SRC_DIR/build'
[ 93%] Running Python protocol buffer compiler on $SRC_DIR/src/proto/caffe.proto
[ 94%] Running Python protocol buffer compiler on $SRC_DIR/src/proto/core.proto
[libprotobuf WARNING google/protobuf/compiler/parser.cc:562] No syntax specified for the proto file: core.proto. Please use 'syntax = ""proto2"";' or 'syntax = ""proto3"";' to specify a syntax version. (Defaulted to proto2 syntax.)
[ 95%] Running Python protocol buffer compiler on $SRC_DIR/src/proto/io.proto
[libprotobuf WARNING google/protobuf/compiler/parser.cc:562] No syntax specified for the proto file: io.proto. Please use 'syntax = ""proto2"";' or 'syntax = ""proto3"";' to specify a syntax version. (Defaulted to proto2 syntax.)
[ 96%] Running Python protocol buffer compiler on $SRC_DIR/src/proto/model.proto
[libprotobuf WARNING google/protobuf/compiler/parser.cc:562] No syntax specified for the proto file: model.proto. Please use 'syntax = ""proto2"";' or 'syntax = ""proto3"";' to specify a syntax version. (Defaulted to proto2 syntax.)
Scanning dependencies of target _singa_wrap
make[2]: Leaving directory '$SRC_DIR/build'
make[2]: Entering directory '$SRC_DIR/build'
[ 97%] Building CXX object python/CMakeFiles/_singa_wrap.dir/__/src/api/singa_wrap.cxx.o
[ 98%] Linking CXX shared library singa/_singa_wrap.so
make[2]: Leaving directory '$SRC_DIR/build'
[100%] Built target _singa_wrap
make[1]: Leaving directory '$SRC_DIR/build'
CMake Warning at /root/miniconda/conda-bld/singa_1583719327583/_build_env/share/cmake-3.16/Modules/FindCUDA.cmake:900 (message):
  Expecting to find librt for libcudart_static, but didn't find it.
Call Stack (most recent call first):
  cmake/Cuda.cmake:20 (FIND_PACKAGE)
  cmake/Dependencies.cmake:85 (INCLUDE)
  CMakeLists.txt:75 (INCLUDE)


-- Found cuda_v10.0
-- Found Cudnn_7301 at $PREFIX/include $PREFIX/lib/libcudnn.so
-- Configuring done
-- Generating done
-- Build files have been written to: $SRC_DIR/build
make[1]: Entering directory '$SRC_DIR/build'
make[2]: Entering directory '$SRC_DIR/build'
make[2]: Leaving directory '$SRC_DIR/build'
make[2]: Entering directory '$SRC_DIR/build'
[  1%] Performing update step for 'cnmem'
Current branch master is up to date.
[  2%] Performing configure step for 'cnmem'
CMake Warning at /root/miniconda/conda-bld/singa_1583719327583/_build_env/share/cmake-3.16/Modules/FindCUDA.cmake:900 (message):
  Expecting to find librt for libcudart_static, but didn't find it.
Call Stack (most recent call first):
  CMakeLists.txt:6 (find_package)


-- Configuring done
-- Generating done
-- Build files have been written to: $SRC_DIR/build/cnmem-prefix/src/cnmem-build
[  3%] Performing build step for 'cnmem'
make[3]: Entering directory '$SRC_DIR/build/cnmem-prefix/src/cnmem-build'
make[4]: Entering directory '$SRC_DIR/build/cnmem-prefix/src/cnmem-build'
make[5]: Entering directory '$SRC_DIR/build/cnmem-prefix/src/cnmem-build'
make[5]: Leaving directory '$SRC_DIR/build/cnmem-prefix/src/cnmem-build'
[100%] Built target cnmem
make[4]: Leaving directory '$SRC_DIR/build/cnmem-prefix/src/cnmem-build'
make[3]: Leaving directory '$SRC_DIR/build/cnmem-prefix/src/cnmem-build'
[  4%] Performing install step for 'cnmem'
make[3]: Entering directory '$SRC_DIR/build/cnmem-prefix/src/cnmem-build'
make[4]: Entering directory '$SRC_DIR/build/cnmem-prefix/src/cnmem-build'
make[5]: Entering directory '$SRC_DIR/build/cnmem-prefix/src/cnmem-build'
make[5]: Leaving directory '$SRC_DIR/build/cnmem-prefix/src/cnmem-build'
[100%] Built target cnmem
make[4]: Leaving directory '$SRC_DIR/build/cnmem-prefix/src/cnmem-build'
Install the project...
-- Install configuration: """"
-- Up-to-date: $SRC_DIR/build/lib/libcnmem.a
-- Up-to-date: $SRC_DIR/build/include/cnmem.h
make[3]: Leaving directory '$SRC_DIR/build/cnmem-prefix/src/cnmem-build'
[  5%] Completed 'cnmem'
make[2]: Leaving directory '$SRC_DIR/build'
[  8%] Built target cnmem
make[2]: Entering directory '$SRC_DIR/build'
make[2]: Leaving directory '$SRC_DIR/build'
make[2]: Entering directory '$SRC_DIR/build'
[  9%] Copying Protobuf headers
make[2]: Leaving directory '$SRC_DIR/build'
[ 13%] Built target copy_protobuf
make[2]: Entering directory '$SRC_DIR/build'
make[2]: Leaving directory '$SRC_DIR/build'
[ 90%] Built target singa_objects
make[2]: Entering directory '$SRC_DIR/build'
make[2]: Leaving directory '$SRC_DIR/build'
make[2]: Entering directory '$SRC_DIR/build'
[ 91%] Linking CXX shared library ../lib/libsinga.so
make[2]: Leaving directory '$SRC_DIR/build'
[ 92%] Built target singa
make[2]: Entering directory '$SRC_DIR/build'
Scanning dependencies of target _singa_wrap
make[2]: Leaving directory '$SRC_DIR/build'
make[2]: Entering directory '$SRC_DIR/build'
[ 93%] Building CXX object python/CMakeFiles/_singa_wrap.dir/__/src/api/singa_wrap.cxx.o
[ 94%] Linking CXX shared library singa/_singa_wrap.so
make[2]: Leaving directory '$SRC_DIR/build'
[100%] Built target _singa_wrap
make[1]: Leaving directory '$SRC_DIR/build'
Install the project...
-- Install configuration: """"
-- Up-to-date: $PREFIX//include
-- Installing: $PREFIX//include/singa
-- Installing: $PREFIX//include/singa/singa_config.h
-- Installing: $PREFIX//include/singa/proto
-- Installing: $PREFIX//include/singa/proto/model.pb.h
-- Installing: $PREFIX//include/singa/proto/caffe.pb.h
-- Installing: $PREFIX//include/singa/proto/core.pb.h
-- Installing: $PREFIX//include/singa/proto/io.pb.h
-- Installing: $PREFIX//include/cnmem.h
-- Up-to-date: $PREFIX/include//singa
-- Installing: $PREFIX/include//singa/core
-- Installing: $PREFIX/include//singa/core/device.h
-- Installing: $PREFIX/include//singa/core/tensor.h
-- Installing: $PREFIX/include//singa/core/memory.h
-- Installing: $PREFIX/include//singa/core/scheduler.h
-- Installing: $PREFIX/include//singa/core/common.h
-- Installing: $PREFIX/include//singa/utils
-- Installing: $PREFIX/include//singa/utils/tinydir.h
-- Installing: $PREFIX/include//singa/utils/factory.h
-- Installing: $PREFIX/include//singa/utils/logging.h
-- Installing: $PREFIX/include//singa/utils/safe_queue.h
-- Installing: $PREFIX/include//singa/utils/singleton.h
-- Installing: $PREFIX/include//singa/utils/cuda_utils.h
-- Installing: $PREFIX/include//singa/utils/channel.h
-- Installing: $PREFIX/include//singa/utils/timer.h
-- Installing: $PREFIX/include//singa/utils/integer.h
-- Installing: $PREFIX/include//singa/utils/opencl_utils.h
-- Installing: $PREFIX/include//singa/utils/string.h
-- Installing: $PREFIX/include//singa/utils/mkldnn_utils.h
-- Installing: $PREFIX/include//singa/model
-- Installing: $PREFIX/include//singa/model/loss.h
-- Installing: $PREFIX/include//singa/model/updater.h
-- Installing: $PREFIX/include//singa/model/layer.h
-- Installing: $PREFIX/include//singa/model/initializer.h
-- Installing: $PREFIX/include//singa/model/optimizer.h
-- Installing: $PREFIX/include//singa/model/metric.h
-- Installing: $PREFIX/include//singa/model/feed_forward_net.h
-- Installing: $PREFIX/include//singa/io
-- Installing: $PREFIX/include//singa/io/encoder.h
-- Installing: $PREFIX/include//singa/io/reader.h
-- Installing: $PREFIX/include//singa/io/writer.h
-- Installing: $PREFIX/include//singa/io/integer.h
-- Installing: $PREFIX/include//singa/io/network.h
-- Installing: $PREFIX/include//singa/io/snapshot.h
-- Installing: $PREFIX/include//singa/io/communicator.h
-- Installing: $PREFIX/include//singa/io/transformer.h
-- Installing: $PREFIX/include//singa/io/decoder.h
-- Up-to-date: $PREFIX//lib
-- Installing: $PREFIX//lib/libcnmem.a
-- Installing: $PREFIX//lib/libsinga.so
running install
running bdist_egg
running egg_info
creating singa.egg-info
writing singa.egg-info/PKG-INFO
writing dependency_links to singa.egg-info/dependency_links.txt
writing entry points to singa.egg-info/entry_points.txt
writing top-level names to singa.egg-info/top_level.txt
writing manifest file 'singa.egg-info/SOURCES.txt'
reading manifest file 'singa.egg-info/SOURCES.txt'
writing manifest file 'singa.egg-info/SOURCES.txt'
installing library code to build/bdist.linux-x86_64/egg
running install_lib
running build_py
creating build
creating build/lib
creating build/lib/rafiki
copying rafiki/agent.py -> build/lib/rafiki
copying rafiki/__init__.py -> build/lib/rafiki
creating build/lib/singa
copying singa/model.py -> build/lib/singa
copying singa/tensor.py -> build/lib/singa
copying singa/singa_wrap.py -> build/lib/singa
copying singa/image_tool.py -> build/lib/singa
copying singa/device.py -> build/lib/singa
copying singa/opt.py -> build/lib/singa
copying singa/__init__.py -> build/lib/singa
copying singa/sonnx.py -> build/lib/singa
copying singa/net.py -> build/lib/singa
copying singa/autograd.py -> build/lib/singa
copying singa/metric.py -> build/lib/singa
copying singa/layer.py -> build/lib/singa
copying singa/optimizer.py -> build/lib/singa
copying singa/utils.py -> build/lib/singa
copying singa/data.py -> build/lib/singa
copying singa/converter.py -> build/lib/singa
copying singa/loss.py -> build/lib/singa
copying singa/snapshot.py -> build/lib/singa
copying singa/initializer.py -> build/lib/singa
creating build/lib/singa/proto
copying singa/proto/core_pb2.py -> build/lib/singa/proto
copying singa/proto/caffe_pb2.py -> build/lib/singa/proto
copying singa/proto/__init__.py -> build/lib/singa/proto
copying singa/proto/model_pb2.py -> build/lib/singa/proto
copying singa/proto/io_pb2.py -> build/lib/singa/proto
copying singa/_singa_wrap.so -> build/lib/singa
creating build/bdist.linux-x86_64
creating build/bdist.linux-x86_64/egg
creating build/bdist.linux-x86_64/egg/singa
copying build/lib/singa/model.py -> build/bdist.linux-x86_64/egg/singa
copying build/lib/singa/tensor.py -> build/bdist.linux-x86_64/egg/singa
copying build/lib/singa/singa_wrap.py -> build/bdist.linux-x86_64/egg/singa
copying build/lib/singa/image_tool.py -> build/bdist.linux-x86_64/egg/singa
copying build/lib/singa/device.py -> build/bdist.linux-x86_64/egg/singa
copying build/lib/singa/_singa_wrap.so -> build/bdist.linux-x86_64/egg/singa
copying build/lib/singa/opt.py -> build/bdist.linux-x86_64/egg/singa
copying build/lib/singa/__init__.py -> build/bdist.linux-x86_64/egg/singa
copying build/lib/singa/sonnx.py -> build/bdist.linux-x86_64/egg/singa
copying build/lib/singa/net.py -> build/bdist.linux-x86_64/egg/singa
copying build/lib/singa/autograd.py -> build/bdist.linux-x86_64/egg/singa
copying build/lib/singa/metric.py -> build/bdist.linux-x86_64/egg/singa
copying build/lib/singa/layer.py -> build/bdist.linux-x86_64/egg/singa
copying build/lib/singa/optimizer.py -> build/bdist.linux-x86_64/egg/singa
copying build/lib/singa/utils.py -> build/bdist.linux-x86_64/egg/singa
copying build/lib/singa/data.py -> build/bdist.linux-x86_64/egg/singa
copying build/lib/singa/converter.py -> build/bdist.linux-x86_64/egg/singa
copying build/lib/singa/loss.py -> build/bdist.linux-x86_64/egg/singa
copying build/lib/singa/snapshot.py -> build/bdist.linux-x86_64/egg/singa
creating build/bdist.linux-x86_64/egg/singa/proto
copying build/lib/singa/proto/core_pb2.py -> build/bdist.linux-x86_64/egg/singa/proto
copying build/lib/singa/proto/caffe_pb2.py -> build/bdist.linux-x86_64/egg/singa/proto
copying build/lib/singa/proto/__init__.py -> build/bdist.linux-x86_64/egg/singa/proto
copying build/lib/singa/proto/model_pb2.py -> build/bdist.linux-x86_64/egg/singa/proto
copying build/lib/singa/proto/io_pb2.py -> build/bdist.linux-x86_64/egg/singa/proto
copying build/lib/singa/initializer.py -> build/bdist.linux-x86_64/egg/singa
creating build/bdist.linux-x86_64/egg/rafiki
copying build/lib/rafiki/agent.py -> build/bdist.linux-x86_64/egg/rafiki
copying build/lib/rafiki/__init__.py -> build/bdist.linux-x86_64/egg/rafiki
byte-compiling build/bdist.linux-x86_64/egg/singa/model.py to model.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/singa/tensor.py to tensor.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/singa/singa_wrap.py to singa_wrap.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/singa/image_tool.py to image_tool.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/singa/device.py to device.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/singa/opt.py to opt.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/singa/__init__.py to __init__.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/singa/sonnx.py to sonnx.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/singa/net.py to net.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/singa/autograd.py to autograd.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/singa/metric.py to metric.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/singa/layer.py to layer.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/singa/optimizer.py to optimizer.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/singa/utils.py to utils.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/singa/data.py to data.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/singa/converter.py to converter.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/singa/loss.py to loss.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/singa/snapshot.py to snapshot.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/singa/proto/core_pb2.py to core_pb2.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/singa/proto/caffe_pb2.py to caffe_pb2.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/singa/proto/__init__.py to __init__.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/singa/proto/model_pb2.py to model_pb2.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/singa/proto/io_pb2.py to io_pb2.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/singa/initializer.py to initializer.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/rafiki/agent.py to agent.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/rafiki/__init__.py to __init__.cpython-36.pyc
creating build/bdist.linux-x86_64/egg/EGG-INFO
copying singa.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO
copying singa.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO
copying singa.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO
copying singa.egg-info/entry_points.txt -> build/bdist.linux-x86_64/egg/EGG-INFO
copying singa.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO
writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt
zip_safe flag not set; analyzing archive contents...
singa.__pycache__.singa_wrap.cpython-36: module references __file__
creating dist
creating 'dist/singa-2.1.0-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it
removing 'build/bdist.linux-x86_64/egg' (and everything under it)
Processing singa-2.1.0-py3.6.egg
creating $PREFIX/lib/python3.6/site-packages/singa-2.1.0-py3.6.egg
Extracting singa-2.1.0-py3.6.egg to $PREFIX/lib/python3.6/site-packages
Adding singa 2.1.0 to easy-install.pth file
Installing singa script to $PREFIX/bin

Installed $PREFIX/lib/python3.6/site-packages/singa-2.1.0-py3.6.egg
Processing dependencies for singa==2.1.0
Finished processing dependencies for singa==2.1.0

Resource usage statistics from building singa:
   Process count: 10
   CPU time: Sys=0:00:07.3, User=0:02:26.8
   Memory: 737.2M
   Disk usage: 219.7K
   Time elapsed: 0:04:07.6

Packaging singa
INFO:conda_build.build:Packaging singa
INFO conda_build.build:build(1571): Packaging singa
/root/miniconda/lib/python3.7/site-packages/conda_build/environ.py:427: UserWarning: The environment variable 'CUDA' is being passed through with value '10.0'.  If you are splitting build and test phases with --no-test, please ensure that this value is also set similarly at test time.
  UserWarning
Packaging singa-2.1.0.dev-cudnn7.3.1_cuda10.0_py36
INFO:conda_build.build:Packaging singa-2.1.0.dev-cudnn7.3.1_cuda10.0_py36
INFO conda_build.build:bundle_conda(891): Packaging singa-2.1.0.dev-cudnn7.3.1_cuda10.0_py36
compiling .pyc files...
found egg dir: /root/miniconda/conda-bld/singa_1583719327583/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl/lib/python3.6/site-packages/singa-2.1.0-py3.6.egg
number of files: 102
Warning: rpath /root/miniconda/conda-bld/singa_1583719327583/_build_env/lib is outside prefix /root/miniconda/conda-bld/singa_1583719327583/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl (removing it)
Warning: rpath /usr/local/cuda/lib64 is outside prefix /root/miniconda/conda-bld/singa_1583719327583/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl (removing it)
Warning: rpath /root/miniconda/conda-bld/singa_1583719327583/_build_env/lib is outside prefix /root/miniconda/conda-bld/singa_1583719327583/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl (removing it)
Warning: rpath /usr/local/cuda/lib64 is outside prefix /root/miniconda/conda-bld/singa_1583719327583/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl (removing it)
   INFO (singa,lib/libsinga.so): Needed DSO x86_64-conda_cos6-linux-gnu/sysroot/lib/libm.so.6 found in CDT/compiler package defaults::gcc_impl_linux-64-5.4.0-habb00fd_3
WARNING (singa,lib/libsinga.so): Needed DSO lib/libcublas.so.10.0 found in ['cudatoolkit']
WARNING (singa,lib/libsinga.so): .. but ['cudatoolkit'] not in reqs/run, (i.e. it is overlinking) (likely) or a missing dependency (less likely)
   INFO (singa,lib/libsinga.so): Needed DSO lib/libprotobuf.so.17 found in conda-forge::libprotobuf-3.6.1-hdbcaa40_1001
   INFO (singa,lib/libsinga.so): Needed DSO x86_64-conda_cos6-linux-gnu/sysroot/lib/ld-linux-x86-64.so.2 found in CDT/compiler package defaults::gcc_impl_linux-64-5.4.0-habb00fd_3
   INFO (singa,lib/libsinga.so): Needed DSO lib/libgcc_s.so.1 found in conda-forge::libgcc-ng-9.2.0-h24d8f2e_2
WARNING (singa,lib/libsinga.so): Needed DSO lib/libopenblas.so.0 found in ['openblas']
WARNING (singa,lib/libsinga.so): .. but ['openblas'] not in reqs/run, (i.e. it is overlinking) (likely) or a missing dependency (less likely)
   INFO (singa,lib/libsinga.so): Needed DSO x86_64-conda_cos6-linux-gnu/sysroot/lib/libc.so.6 found in CDT/compiler package defaults::gcc_impl_linux-64-5.4.0-habb00fd_3
WARNING (singa,lib/libsinga.so): Needed DSO lib/libcurand.so.10.0 found in ['cudatoolkit']
WARNING (singa,lib/libsinga.so): .. but ['cudatoolkit'] not in reqs/run, (i.e. it is overlinking) (likely) or a missing dependency (less likely)
   INFO (singa,lib/libsinga.so): Needed DSO lib/libstdc++.so.6 found in conda-forge::libstdcxx-ng-9.2.0-hdf63c60_2
   INFO (singa,lib/libsinga.so): Needed DSO x86_64-conda_cos6-linux-gnu/sysroot/lib/libpthread.so.0 found in CDT/compiler package defaults::gcc_impl_linux-64-5.4.0-habb00fd_3
   INFO (singa,lib/libsinga.so): Needed DSO lib/libglog.so.0 found in conda-forge::glog-0.3.5-hf484d3e_1001
WARNING (singa,lib/libsinga.so): Needed DSO lib/libcudart.so.10.0 found in ['cudatoolkit']
WARNING (singa,lib/libsinga.so): .. but ['cudatoolkit'] not in reqs/run, (i.e. it is overlinking) (likely) or a missing dependency (less likely)
   INFO (singa,lib/libsinga.so): Needed DSO lib/libcudnn.so.7 found in defaults::cudnn-7.3.1-cuda10.0_0
   INFO (singa,lib/python3.6/site-packages/singa/_singa_wrap.so): Needed DSO lib/libprotobuf.so.17 found in conda-forge::libprotobuf-3.6.1-hdbcaa40_1001
   INFO (singa,lib/python3.6/site-packages/singa/_singa_wrap.so): Needed DSO x86_64-conda_cos6-linux-gnu/sysroot/lib/libm.so.6 found in CDT/compiler package defaults::gcc_impl_linux-64-5.4.0-habb00fd_3
WARNING (singa,lib/python3.6/site-packages/singa/_singa_wrap.so): Needed DSO lib/libcurand.so.10.0 found in ['cudatoolkit']
WARNING (singa,lib/python3.6/site-packages/singa/_singa_wrap.so): .. but ['cudatoolkit'] not in reqs/run, (i.e. it is overlinking) (likely) or a missing dependency (less likely)
WARNING (singa,lib/python3.6/site-packages/singa/_singa_wrap.so): Needed DSO lib/libcudart.so.10.0 found in ['cudatoolkit']
WARNING (singa,lib/python3.6/site-packages/singa/_singa_wrap.so): .. but ['cudatoolkit'] not in reqs/run, (i.e. it is overlinking) (likely) or a missing dependency (less likely)
WARNING (singa,lib/python3.6/site-packages/singa/_singa_wrap.so): Needed DSO lib/libcublas.so.10.0 found in ['cudatoolkit']
WARNING (singa,lib/python3.6/site-packages/singa/_singa_wrap.so): .. but ['cudatoolkit'] not in reqs/run, (i.e. it is overlinking) (likely) or a missing dependency (less likely)
   INFO (singa,lib/python3.6/site-packages/singa/_singa_wrap.so): Needed DSO lib/libpython3.6m.so.1.0 found in conda-forge::python-3.6.10-h9d8adfe_1009_cpython
   INFO (singa,lib/python3.6/site-packages/singa/_singa_wrap.so): Needed DSO lib/libglog.so.0 found in conda-forge::glog-0.3.5-hf484d3e_1001
   INFO (singa,lib/python3.6/site-packages/singa/_singa_wrap.so): Needed DSO x86_64-conda_cos6-linux-gnu/sysroot/lib/ld-linux-x86-64.so.2 found in CDT/compiler package defaults::gcc_impl_linux-64-5.4.0-habb00fd_3
   INFO (singa,lib/python3.6/site-packages/singa/_singa_wrap.so): Needed DSO lib/libgcc_s.so.1 found in conda-forge::libgcc-ng-9.2.0-h24d8f2e_2
   INFO (singa,lib/python3.6/site-packages/singa/_singa_wrap.so): Needed DSO x86_64-conda_cos6-linux-gnu/sysroot/lib/libc.so.6 found in CDT/compiler package defaults::gcc_impl_linux-64-5.4.0-habb00fd_3
WARNING (singa,lib/python3.6/site-packages/singa/_singa_wrap.so): Needed DSO lib/libopenblas.so.0 found in ['openblas']
WARNING (singa,lib/python3.6/site-packages/singa/_singa_wrap.so): .. but ['openblas'] not in reqs/run, (i.e. it is overlinking) (likely) or a missing dependency (less likely)
   INFO (singa,lib/python3.6/site-packages/singa/_singa_wrap.so): Needed DSO lib/libcudnn.so.7 found in defaults::cudnn-7.3.1-cuda10.0_0
   INFO (singa,lib/python3.6/site-packages/singa/_singa_wrap.so): Needed DSO lib/libstdc++.so.6 found in conda-forge::libstdcxx-ng-9.2.0-hdf63c60_2
   INFO (singa,lib/python3.6/site-packages/singa/_singa_wrap.so): Needed DSO x86_64-conda_cos6-linux-gnu/sysroot/lib/libpthread.so.0 found in CDT/compiler package defaults::gcc_impl_linux-64-5.4.0-habb00fd_3
WARNING (singa): dso library package defaults::mkl-dnn-0.14-h6bb024c_0 in requirements/run but it is not used (i.e. it is overdepending or perhaps statically linked? If that is what you want then add it to `build/ignore_run_exports`)
   INFO (singa): plugin library package conda-forge::numpy-1.16.0-py36_blas_openblash1522bff_1000 in requirements/run but it is not used (i.e. it is overdepending or perhaps statically linked? If that is what you want then add it to `build/ignore_run_exports`)
Fixing permissions
Packaged license file/s.
Detected hard-coded path in text file bin/singa
Detected hard-coded path in binary file lib/libsinga.so
Detected hard-coded path in binary file lib/python3.6/site-packages/singa/_singa_wrap.so
Importing conda-verify failed.  Please be sure to test your packages.  conda install conda-verify to make this message go away.
WARNING:conda_build.build:Importing conda-verify failed.  Please be sure to test your packages.  conda install conda-verify to make this message go away.
WARNING conda_build.build:bundle_conda(1042): Importing conda-verify failed.  Please be sure to test your packages.  conda install conda-verify to make this message go away.
TEST START: /root/miniconda/conda-bld/linux-64/singa-2.1.0.dev-cudnn7.3.1_cuda10.0_py36.tar.bz2
Renaming work directory,  /root/miniconda/conda-bld/singa_1583719327583/work  to  /root/miniconda/conda-bld/singa_1583719327583/work_moved_singa-2.1.0.dev-cudnn7.3.1_cuda10.0_py36_linux-64
Collecting package metadata (repodata.json): ...working... done
Solving environment: ...working... done

## Package Plan ##

  environment location: /root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho


The following NEW packages will be INSTALLED:

    _libgcc_mutex:    0.1-conda_forge                    conda-forge
    _openmp_mutex:    4.5-1_llvm                         conda-forge
    ca-certificates:  2019.11.28-hecc5488_0              conda-forge
    certifi:          2019.11.28-py36_0                  conda-forge
    cudatoolkit:      10.0.130-0
    cudnn:            7.3.1-cuda10.0_0
    freetype:         2.10.0-he983fc9_1                  conda-forge
    future:           0.18.2-py36_0                      conda-forge
    glog:             0.3.5-hf484d3e_1001                conda-forge
    intel-openmp:     2018.0.3-0
    jpeg:             9c-h14c3975_1001                   conda-forge
    ld_impl_linux-64: 2.33.1-h53a641e_8                  conda-forge
    libblas:          3.8.0-15_mkl                       conda-forge
    libcblas:         3.8.0-15_mkl                       conda-forge
    libffi:           3.2.1-he1b5a44_1006                conda-forge
    libgcc-ng:        9.2.0-h24d8f2e_2                   conda-forge
    libgfortran-ng:   7.3.0-hdf63c60_5                   conda-forge
    liblapack:        3.8.0-15_mkl                       conda-forge
    libmklml:         2018.0.3-0
    libopenblas:      0.3.3-h5a2b251_3
    libpng:           1.6.37-hed695b0_0                  conda-forge
    libprotobuf:      3.6.1-hdbcaa40_1001                conda-forge
    libstdcxx-ng:     9.2.0-hdf63c60_2                   conda-forge
    libtiff:          4.1.0-hc3755c2_3                   conda-forge
    llvm-openmp:      9.0.1-hc9558a2_2                   conda-forge
    lz4-c:            1.8.3-he1b5a44_1001                conda-forge
    mkl:              2020.0-166                         conda-forge
    mkl-dnn:          0.14-h6bb024c_0
    ncurses:          6.1-hf484d3e_1002                  conda-forge
    numpy:            1.16.5-py36h95a1406_0              conda-forge
    olefile:          0.46-py_0                          conda-forge
    onnx:             1.6.0-py36he1b5a44_0               conda-forge
    openssl:          1.1.1d-h516909a_0                  conda-forge
    pillow:           7.0.0-py36hefe7db6_0               conda-forge
    pip:              20.0.2-py_2                        conda-forge
    protobuf:         3.6.1-py36hf484d3e_1001            conda-forge
    python:           3.6.10-h9d8adfe_1009_cpython       conda-forge
    python_abi:       3.6-1_cp36m                        conda-forge
    readline:         8.0-hf8c457e_0                     conda-forge
    setuptools:       46.0.0-py36_0                      conda-forge
    singa:            2.1.0.dev-cudnn7.3.1_cuda10.0_py36 local
    six:              1.14.0-py36_0                      conda-forge
    sqlite:           3.30.1-hcee41ef_0                  conda-forge
    tk:               8.6.10-hed695b0_0                  conda-forge
    tqdm:             4.43.0-py_0                        conda-forge
    wheel:            0.34.2-py_1                        conda-forge
    xz:               5.2.4-h14c3975_1001                conda-forge
    zlib:             1.2.11-h516909a_1006               conda-forge
    zstd:             1.4.4-h3b9ef0a_1                   conda-forge

Preparing transaction: ...working... done
Verifying transaction: ...working...
ClobberWarning: This transaction has incompatible packages due to a shared path.
  packages: defaults/linux-64::intel-openmp-2018.0.3-0, conda-forge/linux-64::llvm-openmp-9.0.1-hc9558a2_2
  path: 'lib/libiomp5.so'


ClobberWarning: This transaction has incompatible packages due to a shared path.
  packages: conda-forge/linux-64::libblas-3.8.0-15_mkl, defaults/linux-64::libopenblas-0.3.3-h5a2b251_3
  path: 'lib/libblas.so'


ClobberWarning: This transaction has incompatible packages due to a shared path.
  packages: defaults/linux-64::libopenblas-0.3.3-h5a2b251_3, conda-forge/linux-64::libcblas-3.8.0-15_mkl
  path: 'lib/libcblas.so'


ClobberWarning: This transaction has incompatible packages due to a shared path.
  packages: defaults/linux-64::libopenblas-0.3.3-h5a2b251_3, conda-forge/linux-64::liblapack-3.8.0-15_mkl
  path: 'lib/liblapack.so'



done
Executing transaction: ...working...
ClobberWarning: Conda was asked to clobber an existing path.
  source path: /root/miniconda/pkgs/llvm-openmp-9.0.1-hc9558a2_2/lib/libiomp5.so
  target path: /root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/libiomp5.so




ClobberWarning: Conda was asked to clobber an existing path.
  source path: /root/miniconda/pkgs/libopenblas-0.3.3-h5a2b251_3/lib/libblas.so
  target path: /root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/libblas.so




ClobberWarning: Conda was asked to clobber an existing path.
  source path: /root/miniconda/pkgs/libcblas-3.8.0-15_mkl/lib/libcblas.so
  target path: /root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/libcblas.so




ClobberWarning: Conda was asked to clobber an existing path.
  source path: /root/miniconda/pkgs/liblapack-3.8.0-15_mkl/lib/liblapack.so
  target path: /root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/liblapack.so



done
export PREFIX=/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho
export SRC_DIR=/root/miniconda/conda-bld/singa_1583719327583/test_tmp
+ cd test/python
+ python run.py
EEEEEFEEEEEEE
======================================================================
ERROR: test_api (unittest.loader._FailedTest)
----------------------------------------------------------------------
ImportError: Failed to import test module: test_api
Traceback (most recent call last):
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/unittest/loader.py"", line 428, in _find_test_path
    module = self._get_module_from_name(name)
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/unittest/loader.py"", line 369, in _get_module_from_name
    __import__(name)
  File ""/root/miniconda/conda-bld/singa_1583719327583/test_tmp/test/python/test_api.py"", line 27, in <module>
    from singa import tensor
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/site-packages/singa/tensor.py"", line 58, in <module>
    from deprecated import deprecated
ModuleNotFoundError: No module named 'deprecated'


======================================================================
ERROR: test_layer (unittest.loader._FailedTest)
----------------------------------------------------------------------
ImportError: Failed to import test module: test_layer
Traceback (most recent call last):
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/unittest/loader.py"", line 428, in _find_test_path
    module = self._get_module_from_name(name)
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/unittest/loader.py"", line 369, in _get_module_from_name
    __import__(name)
  File ""/root/miniconda/conda-bld/singa_1583719327583/test_tmp/test/python/test_layer.py"", line 24, in <module>
    from singa import layer
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/site-packages/singa/layer.py"", line 57, in <module>
    from . import tensor
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/site-packages/singa/tensor.py"", line 58, in <module>
    from deprecated import deprecated
ModuleNotFoundError: No module named 'deprecated'


======================================================================
ERROR: test_loss (unittest.loader._FailedTest)
----------------------------------------------------------------------
ImportError: Failed to import test module: test_loss
Traceback (most recent call last):
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/unittest/loader.py"", line 428, in _find_test_path
    module = self._get_module_from_name(name)
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/unittest/loader.py"", line 369, in _get_module_from_name
    __import__(name)
  File ""/root/miniconda/conda-bld/singa_1583719327583/test_tmp/test/python/test_loss.py"", line 23, in <module>
    from singa import loss
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/site-packages/singa/loss.py"", line 43, in <module>
    from . import tensor
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/site-packages/singa/tensor.py"", line 58, in <module>
    from deprecated import deprecated
ModuleNotFoundError: No module named 'deprecated'


======================================================================
ERROR: test_metric (unittest.loader._FailedTest)
----------------------------------------------------------------------
ImportError: Failed to import test module: test_metric
Traceback (most recent call last):
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/unittest/loader.py"", line 428, in _find_test_path
    module = self._get_module_from_name(name)
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/unittest/loader.py"", line 369, in _get_module_from_name
    __import__(name)
  File ""/root/miniconda/conda-bld/singa_1583719327583/test_tmp/test/python/test_metric.py"", line 23, in <module>
    from singa import metric
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/site-packages/singa/metric.py"", line 45, in <module>
    from . import tensor
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/site-packages/singa/tensor.py"", line 58, in <module>
    from deprecated import deprecated
ModuleNotFoundError: No module named 'deprecated'


======================================================================
ERROR: test_batch_norm (test_mkldnn.TestPythonOperation)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/root/miniconda/conda-bld/singa_1583719327583/test_tmp/test/python/test_mkldnn.py"", line 150, in test_batch_norm
    y = singa_wrap.CpuBatchNormForwardInference(handle, x, scale, bias,
AttributeError: module 'singa.singa_wrap' has no attribute 'CpuBatchNormForwardInference'

======================================================================
ERROR: test_pooling (test_mkldnn.TestPythonOperation)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/root/miniconda/conda-bld/singa_1583719327583/test_tmp/test/python/test_mkldnn.py"", line 112, in test_pooling
    y = singa_wrap.CpuPoolingForward(handle, x)
AttributeError: module 'singa.singa_wrap' has no attribute 'CpuPoolingForward'

======================================================================
ERROR: test_net (unittest.loader._FailedTest)
----------------------------------------------------------------------
ImportError: Failed to import test module: test_net
Traceback (most recent call last):
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/unittest/loader.py"", line 428, in _find_test_path
    module = self._get_module_from_name(name)
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/unittest/loader.py"", line 369, in _get_module_from_name
    __import__(name)
  File ""/root/miniconda/conda-bld/singa_1583719327583/test_tmp/test/python/test_net.py"", line 25, in <module>
    from singa import net
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/site-packages/singa/net.py"", line 68, in <module>
    from . import tensor
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/site-packages/singa/tensor.py"", line 58, in <module>
    from deprecated import deprecated
ModuleNotFoundError: No module named 'deprecated'


======================================================================
ERROR: test_onnx (unittest.loader._FailedTest)
----------------------------------------------------------------------
ImportError: Failed to import test module: test_onnx
Traceback (most recent call last):
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/unittest/loader.py"", line 428, in _find_test_path
    module = self._get_module_from_name(name)
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/unittest/loader.py"", line 369, in _get_module_from_name
    __import__(name)
  File ""/root/miniconda/conda-bld/singa_1583719327583/test_tmp/test/python/test_onnx.py"", line 21, in <module>
    from singa import tensor
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/site-packages/singa/tensor.py"", line 58, in <module>
    from deprecated import deprecated
ModuleNotFoundError: No module named 'deprecated'


======================================================================
ERROR: test_onnx_backend (unittest.loader._FailedTest)
----------------------------------------------------------------------
ImportError: Failed to import test module: test_onnx_backend
Traceback (most recent call last):
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/unittest/loader.py"", line 428, in _find_test_path
    module = self._get_module_from_name(name)
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/unittest/loader.py"", line 369, in _get_module_from_name
    __import__(name)
  File ""/root/miniconda/conda-bld/singa_1583719327583/test_tmp/test/python/test_onnx_backend.py"", line 21, in <module>
    from singa import tensor
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/site-packages/singa/tensor.py"", line 58, in <module>
    from deprecated import deprecated
ModuleNotFoundError: No module named 'deprecated'


======================================================================
ERROR: test_operation (unittest.loader._FailedTest)
----------------------------------------------------------------------
ImportError: Failed to import test module: test_operation
Traceback (most recent call last):
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/unittest/loader.py"", line 428, in _find_test_path
    module = self._get_module_from_name(name)
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/unittest/loader.py"", line 369, in _get_module_from_name
    __import__(name)
  File ""/root/miniconda/conda-bld/singa_1583719327583/test_tmp/test/python/test_operation.py"", line 21, in <module>
    from singa import tensor
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/site-packages/singa/tensor.py"", line 58, in <module>
    from deprecated import deprecated
ModuleNotFoundError: No module named 'deprecated'


======================================================================
ERROR: test_optimizer (unittest.loader._FailedTest)
----------------------------------------------------------------------
ImportError: Failed to import test module: test_optimizer
Traceback (most recent call last):
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/unittest/loader.py"", line 428, in _find_test_path
    module = self._get_module_from_name(name)
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/unittest/loader.py"", line 369, in _get_module_from_name
    __import__(name)
  File ""/root/miniconda/conda-bld/singa_1583719327583/test_tmp/test/python/test_optimizer.py"", line 27, in <module>
    import singa.tensor as tensor
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/site-packages/singa/tensor.py"", line 58, in <module>
    from deprecated import deprecated
ModuleNotFoundError: No module named 'deprecated'


======================================================================
ERROR: test_tensor (unittest.loader._FailedTest)
----------------------------------------------------------------------
ImportError: Failed to import test module: test_tensor
Traceback (most recent call last):
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/unittest/loader.py"", line 428, in _find_test_path
    module = self._get_module_from_name(name)
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/unittest/loader.py"", line 369, in _get_module_from_name
    __import__(name)
  File ""/root/miniconda/conda-bld/singa_1583719327583/test_tmp/test/python/test_tensor.py"", line 25, in <module>
    from singa import tensor
  File ""/root/miniconda/conda-bld/singa_1583719327583/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/site-packages/singa/tensor.py"", line 58, in <module>
    from deprecated import deprecated
ModuleNotFoundError: No module named 'deprecated'


======================================================================
FAIL: test_conv2d (test_mkldnn.TestPythonOperation)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/root/miniconda/conda-bld/singa_1583719327583/test_tmp/test/python/test_mkldnn.py"", line 78, in test_conv2d
    self.assertAlmostEqual(4.0, _dW[0], places=5)
AssertionError: 4.0 != 0.040000003 within 5 places

----------------------------------------------------------------------
Ran 13 tests in 0.002s

FAILED (failures=1, errors=12)
TEST CONV2D FORWARD
TEST CONV2D DATA BACKWARD
TEST CONV2D WEIGHT BACKWARD
+ exit 0

Resource usage statistics from testing singa:
   Process count: 1
   CPU time: Sys=0:00:00.0, User=0:00:00.0
   Memory: 2.7M
   Disk usage: 584B
   Time elapsed: 0:00:02.1

TEST END: /root/miniconda/conda-bld/linux-64/singa-2.1.0.dev-cudnn7.3.1_cuda10.0_py36.tar.bz2
Renaming work directory,  /root/miniconda/conda-bld/singa_1583719327583/work  to  /root/miniconda/conda-bld/singa_1583719327583/work_moved_singa-2.1.0.dev-cudnn7.3.1_cuda10.0_py36_linux-64_main_build_loop
# Automatic uploading is disabled
# If you want to upload package(s) to anaconda.org later, type:

anaconda upload /root/miniconda/conda-bld/linux-64/singa-2.1.0.dev-cudnn7.3.1_cuda10.0_py36.tar.bz2

# To have conda build upload to anaconda.org automatically, use
# $ conda config --set anaconda_upload yes

anaconda_upload is not set.  Not uploading wheels: []
####################################################################################
Resource usage summary:

Total time: 0:08:01.5
CPU usage: sys=0:00:07.3, user=0:02:26.8
Maximum memory usage observed: 737.2M
Total disk usage observed (not including envs): 220.2K


####################################################################################
Source and build intermediates have been left in /root/miniconda/conda-bld.
There are currently 3 accumulated.
To remove them, you can run the ```conda build purge``` command
root@3c17fd6cb72e:~/dcsysh/singa/tool/conda/singa# cd /root/miniconda/conda-bld/linux-64/
root@3c17fd6cb72e:~/miniconda/conda-bld/linux-64# ls
current_repodata.json      index.html     repodata.json.bz2            repodata_from_packages.json.bz2
current_repodata.json.bz2  repodata.json  repodata_from_packages.json  singa-2.1.0.dev-cudnn7.3.1_cuda10.0_py36.tar.bz2
```
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDU5NjMwMTMwNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/627,https://api.github.com/repos/apache/singa/issues/627,singa,580385837,627,Create DNNL conda package,nudles,3797447,Wei Wang,,CLOSED,2020-03-13T05:48:17Z,2020-03-25T01:52:37Z,"To use DNNL in SINGA, it would be convenient to have a DNNL conda package.
However, Intel does not provide the conda package for DNNL.
Therefore, we may need to compile DNNL via conda and upload it to anaconda cloud.

","{""url"": ""https://api.github.com/repos/apache/singa/issues/627/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/627,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTA2ODM3Mg==,singa,601068372,627,NA,dcslin,13751447,Shicong,,NA,2020-03-19T09:09:36Z,2020-03-19T09:09:36Z,This is uploaded https://anaconda.org/nusdbsystem/dnnl,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTA2ODM3Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/630,https://api.github.com/repos/apache/singa/issues/630,singa,582946170,630,AsType cannot work when after Reshape,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,CLOSED,2020-03-17T11:31:00Z,2020-03-24T04:54:38Z,"Hi, @dcslin , The asType cannot work when it is after the reshape operators.

Please check by using the following code:

```
    dev = device.create_cuda_gpu()
    X = np.array([[1, 0], [1, 1]]).astype(np.int32)
    x = tensor.from_numpy(X)
    x.to_device(dev)

    x = autograd.cast(x, tensor.int32)
    x = autograd.reshape(x, [1, 2, 2])
    x = autograd.cast(x, tensor.float32)
```","{""url"": ""https://api.github.com/repos/apache/singa/issues/630/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/630,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTAyOTczMA==,singa,601029730,630,NA,dcslin,13751447,Shicong,,NA,2020-03-19T07:32:22Z,2020-03-19T07:32:22Z,"hi @joddiy ,thank you for raising the issue, it should be working after this pr
https://github.com/apache/singa/blob/205a2832b23694b748134ef69ef9c0b4c642afd5/test/python/test_tensor.py#L341","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTAyOTczMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/630,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMjM3NTk0Mw==,singa,602375943,630,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-03-23T04:16:53Z,2020-03-23T04:16:53Z,"Thanks shicong, it works fine for me.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMjM3NTk0Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/631,https://api.github.com/repos/apache/singa/issues/631,singa,584184449,631,Is there any runtime problem of onnx in Travis CI built SINGA CPU version related to libprotobuf.so.20?,chrishkchris,38325429,Chris Yeung,,CLOSED,2020-03-19T06:06:06Z,2020-03-20T06:13:54Z,"In the log of travis CI CPU version build, it displays the error in test_onnx that cannot import libprotobuf.so.20
https://travis-ci.org/github/apache/singa/jobs/664251025#L3998
```

======================================================================
3966
ERROR: test_onnx (unittest.loader._FailedTest)
3967
----------------------------------------------------------------------
3968
ImportError: Failed to import test module: test_onnx
3969
Traceback (most recent call last):
3970
  File ""/home/travis/conda-bld-1971.5/singa_1584596418932/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/lib/python3.7/unittest/loader.py"", line 436, in _find_test_path
3971
    module = self._get_module_from_name(name)
3972
  File ""/home/travis/conda-bld-1971.5/singa_1584596418932/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/lib/python3.7/unittest/loader.py"", line 377, in _get_module_from_name
3973
    __import__(name)
3974
  File ""/home/travis/conda-bld-1971.5/singa_1584596418932/test_tmp/test/python/test_onnx.py"", line 24, in <module>
3975
    from singa import sonnx
3976
  File ""/home/travis/conda-bld-1971.5/singa_1584596418932/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/lib/python3.7/site-packages/singa/sonnx.py"", line 23, in <module>
3977
    import onnx.utils
3978
  File ""/home/travis/conda-bld-1971.5/singa_1584596418932/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/lib/python3.7/site-packages/onnx/__init__.py"", line 8, in <module>
3979
    from .onnx_cpp2py_export import ONNX_ML
3980
ImportError: libprotobuf.so.20: cannot open shared object file: No such file or directory
```","{""url"": ""https://api.github.com/repos/apache/singa/issues/631/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/631,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTAwNjMwMA==,singa,601006300,631,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-03-19T06:11:12Z,2020-03-19T06:11:12Z,"maybe the version of protobuf used in conda package does not match, but I am not sure","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTAwNjMwMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/631,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTAyMzI3MQ==,singa,601023271,631,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-03-19T07:12:06Z,2020-03-19T07:12:06Z,"https://blog.csdn.net/kailvechao1536/article/details/103538689 this blog says that changes to protobuf 3.9 can solve problem for onnx

or this onnx issue
https://github.com/onnx/onnx/issues/2434","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTAyMzI3MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/631,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTAyODIwOQ==,singa,601028209,631,NA,nudles,3797447,Wei Wang,,NA,2020-03-19T07:27:33Z,2020-03-19T07:27:33Z,"which version of onnx are you using?
you may need to use the onnx that is compatible with SINGA.
Protobuf has many versions. It is a bit difficult to make other dependencies compatible with some protobuf versions.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTAyODIwOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/631,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTAyOTgwMQ==,singa,601029801,631,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-03-19T07:32:37Z,2020-03-19T07:32:37Z,"https://github.com/apache/singa/blob/dev/tool/conda/singa/meta.yaml
currently our conda metal.yaml is using
- libprotobuf 3.6.1
- onnx >=1.3.0
maybe the two are not compatible
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTAyOTgwMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/631,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTAzMDc5Mg==,singa,601030792,631,NA,nudles,3797447,Wei Wang,,NA,2020-03-19T07:35:26Z,2020-03-19T07:35:26Z,you can compare the libprotobuf of SINGA and onnx via methods here https://github.com/conda/conda/issues/2361,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTAzMDc5Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/631,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTA0MDQ4Ng==,singa,601040486,631,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-03-19T08:01:53Z,2020-03-19T08:01:53Z,"OK, from the Travis CI build log the onnx version was onnx-1.6.0-py36he1b5a44_0
seems that protobuf is not specified (then should be the most latest version), so I may try to use later version.
```
dcsysh@panda8:~$ conda search onnx=1.6.0=py36he1b5a44_0 --info
Loading channels: done
onnx 1.6.0 py36he1b5a44_0
-------------------------
file name   : onnx-1.6.0-py36he1b5a44_0.tar.bz2
name        : onnx
version     : 1.6.0
build       : py36he1b5a44_0
build number: 0
size        : 2.9 MB
license     : MIT
subdir      : linux-64
url         : https://conda.anaconda.org/conda-forge/linux-64/onnx-1.6.0-py36he1b5a44_0.tar.bz2
md5         : 26073522c9dcaa50a8894c762668d7da
timestamp   : 2019-09-28 06:49:12 UTC
constraints :
  - python_abi * *_cp36m
dependencies:
  - libgcc-ng >=7.3.0
  - libstdcxx-ng >=7.3.0
  - numpy
  - protobuf
  - python >=3.6,<3.7.0a0
  - six
```","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTA0MDQ4Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/631,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTA0MzIwOQ==,singa,601043209,631,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-03-19T08:09:22Z,2020-03-19T08:09:22Z,"Also, our singa dockerfile is using  `pip3 install protobuf`, so I may get the same version to conda

Currently, the pip install protobuf version is 3.11.3, but our conda package uses 3.6.1, so it may be better to upgrade
```
(builder) dcsysh@panda8:~$ pip install protobuf
Collecting protobuf
  Downloading protobuf-3.11.3-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)
     |████████████████████████████████| 1.3 MB 4.0 MB/s
Requirement already satisfied: six>=1.9 in ./anaconda3/envs/builder/lib/python3.6/site-packages (from protobuf) (1.14.0)
Requirement already satisfied: setuptools in ./anaconda3/envs/builder/lib/python3.6/site-packages (from protobuf) (45.2.0.post20200210)
Installing collected packages: protobuf
Successfully installed protobuf-3.11.3
```","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTA0MzIwOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/631,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTA0ODAyMQ==,singa,601048021,631,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-03-19T08:22:03Z,2020-03-19T08:22:03Z,So I will try the conda build singa onnx test case with protobuf 3.11.3 first,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTA0ODAyMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/631,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTA1MTAyMA==,singa,601051020,631,NA,nudles,3797447,Wei Wang,,NA,2020-03-19T08:29:41Z,2020-03-19T08:29:41Z,you can try. I got many troubles when I was trying to upgrade protobuf..,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTA1MTAyMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/631,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTA3ODMwNQ==,singa,601078305,631,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-03-19T09:31:40Z,2020-03-19T09:31:40Z,"Hi, all, please use onnx==1.5.0, we now support op set of version 10 for onnx 1.5.0. 

https://github.com/onnx/onnx/blob/master/docs/Versioning.md#released-versions","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTA3ODMwNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/631,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTA4ODcwMg==,singa,601088702,631,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-03-19T09:55:01Z,2020-03-19T09:55:01Z,"> Hi, all, please use onnx==1.5.0, we now support op set of version 10 for onnx 1.5.0.
> https://github.com/onnx/onnx/blob/master/docs/Versioning.md#released-versions

got it, I will fix the conda version of onnx to 1.5.0. Thanks a lot","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTA4ODcwMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/631,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTA5MTIxMA==,singa,601091210,631,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-03-19T10:00:40Z,2020-03-19T10:00:40Z,so in the dockerfile (everyone is using for development) we may need to set to onnx==1.5.0,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTA5MTIxMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/631,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTUyMzU4OQ==,singa,601523589,631,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-03-20T04:15:08Z,2020-03-20T04:15:08Z,"After quite a exhaustive search of conda package versions' combinations, I found that this seems to be working for both onnx and singa:
```
  host:
    - swig 3.0.12
    - openblas 0.3.9
    - protobuf 3.9.2
    - glog 0.3.5
    - numpy 1.11.3
    - cudnn {{ cudnn }}       # ['cudnn' in str(build_str)]
    - dnnl {{ dnnl }}
    - python {{ python }}

  run:
    - {{ pin_compatible('glog', max_pin='x.x') }}
    - {{ pin_compatible('numpy', max_pin='x.x') }}
    - {{ pin_compatible('dnnl', max_pin='x.x') }}
    - cudnn {{ cudnn }}       # ['cudnn' in str(build_str)]
    - python {{ python }}
    - libprotobuf 3.9.2
    - libopenblas 0.3.9
    - pillow
    - future
    - tqdm
    - onnx 1.6.0
    - deprecated 1.2.7
```
onnx 1.5 fails one more test case due to numerical error, so I choose onnx 1.6

However, now there are still two errors in the test case I am investigating why:
```
+ python run.py
..............................................................................................................................EE...................................................F............................................................................................................................................................................................................................
======================================================================
ERROR: test_clip (test_onnx_backend.TestPythonOnnxBackend)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/root/miniconda/conda-bld/singa_1584677090067/test_tmp/test/python/test_onnx_backend.py"", line 1896, in test_clip
    name='test_clip_example')
  File ""/root/miniconda/conda-bld/singa_1584677090067/test_tmp/test/python/test_onnx_backend.py"", line 55, in expect
    outputs_dict = sonnx.run_node(onnx_node, input_tensors, opset_version)
  File ""/root/miniconda/conda-bld/singa_1584677090067/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/site-packages/singa/sonnx.py"", line 1300, in run_node
    return cls._run_node(onnx_node, inputs, handle, forward, opset_version)
  File ""/root/miniconda/conda-bld/singa_1584677090067/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/site-packages/singa/sonnx.py"", line 1324, in _run_node
    outputs = forward(*inputs) if handle is None else forward(
  File ""/root/miniconda/conda-bld/singa_1584677090067/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/site-packages/singa/autograd.py"", line 499, in clip
    return Clip(min, max)(x)[0]
  File ""/root/miniconda/conda-bld/singa_1584677090067/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/site-packages/singa/autograd.py"", line 245, in __call__
    return self._do_forward(*xs)
  File ""/root/miniconda/conda-bld/singa_1584677090067/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/site-packages/singa/autograd.py"", line 295, in _do_forward
    ys = self.forward(*xs)
  File ""/root/miniconda/conda-bld/singa_1584677090067/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/site-packages/singa/autograd.py"", line 479, in forward
    mask0 = singa.LTFloat(x, self.min)
TypeError: in method 'LTFloat', argument 2 of type 'float'

======================================================================
ERROR: test_clip_default (test_onnx_backend.TestPythonOnnxBackend)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/root/miniconda/conda-bld/singa_1584677090067/test_tmp/test/python/test_onnx_backend.py"", line 1946, in test_clip_default
    name='test_clip_default_min')
  File ""/root/miniconda/conda-bld/singa_1584677090067/test_tmp/test/python/test_onnx_backend.py"", line 55, in expect
    outputs_dict = sonnx.run_node(onnx_node, input_tensors, opset_version)
  File ""/root/miniconda/conda-bld/singa_1584677090067/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/site-packages/singa/sonnx.py"", line 1300, in run_node
    return cls._run_node(onnx_node, inputs, handle, forward, opset_version)
  File ""/root/miniconda/conda-bld/singa_1584677090067/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/site-packages/singa/sonnx.py"", line 1324, in _run_node
    outputs = forward(*inputs) if handle is None else forward(
TypeError: clip() missing 1 required positional argument: 'max'

======================================================================
FAIL: test_pow (test_onnx_backend.TestPythonOnnxBackend)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/root/miniconda/conda-bld/singa_1584677090067/test_tmp/test/python/test_onnx_backend.py"", line 1851, in test_pow
    expect(node, inputs=[x, y], outputs=[z], name='test_pow_example')
  File ""/root/miniconda/conda-bld/singa_1584677090067/test_tmp/test/python/test_onnx_backend.py"", line 59, in expect
    decimal=5)
  File ""/root/miniconda/conda-bld/singa_1584677090067/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/site-packages/numpy/testing/utils.py"", line 918, in assert_array_almost_equal
    precision=decimal)
  File ""/root/miniconda/conda-bld/singa_1584677090067/_test_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeho/lib/python3.6/site-packages/numpy/testing/utils.py"", line 739, in assert_array_compare
    raise AssertionError(msg)
AssertionError:
Arrays are not almost equal to 5 decimals

(mismatch 33.33333333333333%)
 x: array([   1.,   32.,  729.], dtype=float32)
 y: array([   1.     ,   32.     ,  729.00006], dtype=float32)

----------------------------------------------------------------------
Ran 400 tests in 1.563s
```
P.S. The above remaining two test case error on test_clip (onnx backend @joddiy) occurs also in docker container enivornment without conda, so needed to be fixed. ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTUyMzU4OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/631,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTUzNzA1NA==,singa,601537054,631,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-03-20T04:49:13Z,2020-03-20T04:49:13Z,"In conclusion, I have posted an conda package versions' combinations that works for SINGA and onnx in conda environment, so I close this issue. The change of conda package version is addressed in #624 ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMTUzNzA1NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/633,https://api.github.com/repos/apache/singa/issues/633,singa,586697313,633,Cannot do mul for int tensors,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,OPEN,2020-03-24T05:12:11Z,2020-03-25T04:45:57Z,"Hi, @dcslin , we cannot do the mul operator for int tensors:

The error is:
> F0324 05:04:22.542809 14739 tensor.cc:932] Unknown combination of data type kInt and language kCuda

please use this test case:
```python3
x1 = np.array([1], dtype=np.int32)
x2 = np.array([256], dtype=np.int32)
x1 = tensor.from_numpy(x1)
x1.to_device(gpu_dev)
x2 = tensor.from_numpy(x2)
x2.to_device(gpu_dev)

y = autograd.Mul()(x1, x2)
print(tensor.to_numpy(y[0]))
```","{""url"": ""https://api.github.com/repos/apache/singa/issues/633/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/633,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMzYzNzgzNA==,singa,603637834,633,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-03-25T04:45:47Z,2020-03-25T04:45:47Z,"same issue for sub, add, div, and reshape operators.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMzYzNzgzNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/634,https://api.github.com/repos/apache/singa/issues/634,singa,586710831,634,cannot do matmul for high-dim tensors,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,CLOSED,2020-03-24T05:49:50Z,2020-03-28T15:34:25Z,"Hi, @dcslin , we ccannot do matmul for high-dim tensors:

The error is:
> F0324 05:47:19.174587 15611 tensor.cc:1413] Check failed: A.shape().size() == 2u (4 vs. 2)

please use this test case:
```python3
x1 = np.random.randn(1, 12, 256, 64).astype(np.float32)
x2 = np.random.randn(1, 12, 64, 256).astype(np.float32)
x1 = tensor.from_numpy(x1)
x1.to_device(gpu_dev)
x2 = tensor.from_numpy(x2)
x2.to_device(gpu_dev)

y = autograd.Matmul()(x1, x2)
print(tensor.to_numpy(y[0]))
```","{""url"": ""https://api.github.com/repos/apache/singa/issues/634/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/634,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMzE5MDUzMw==,singa,603190533,634,NA,dcslin,13751447,Shicong,,NA,2020-03-24T11:41:22Z,2020-03-24T11:41:22Z,"Hi @joddiy , for tensor mul >2d, please use `tensor.tensordot`, it depends on which axis to perform the `tensordot`
```python
    def test_4d_tensor_dot(self):
        for dev in [cpu_dev, gpu_dev]:
            x1 = np.random.randn(1, 12, 256, 64).astype(np.float32)
            x2 = np.random.randn(1, 12, 64, 256).astype(np.float32)
            x1 = tensor.from_numpy(x1)
            x1.to_device(dev)
            x2 = tensor.from_numpy(x2)
            x2.to_device(dev)

            y = tensor.tensordot(x1, x2, axes=([3],[2]))
            print(y.shape)

            y = tensor.tensordot(x1, x2, axes=([2,3],[3,2]))
            print(y.shape)

```
output:
```
(1, 12, 256, 1, 12, 256)
(1, 12, 1, 12)
(1, 12, 256, 1, 12, 256)
(1, 12, 1, 12)
...........................
----------------------------------------------------------------------
Ran 27 tests in 0.121s

OK
```

reference: https://docs.scipy.org/doc/numpy/reference/generated/numpy.tensordot.html","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMzE5MDUzMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/634,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMzYzODczMQ==,singa,603638731,634,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-03-25T04:49:51Z,2020-03-25T04:49:51Z,"Hi, shicong, according to the np's definition, the matmul for high-dim matrix should be:

```python3
x1 = np.random.randn(1, 12, 256, 64).astype(np.float32)
x2 = np.random.randn(1, 12, 64, 256).astype(np.float32)
print(np.matmul(x1, x2).shape)
```

Output:
> (1, 12, 256, 256)

Actually, it does the matmul for (256, 64) * (64, 256) for all cells of the first two axes (1, 12).","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwMzYzODczMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/634,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwNDIwOTgxMw==,singa,604209813,634,NA,dcslin,13751447,Shicong,,NA,2020-03-26T03:36:14Z,2020-03-26T03:36:14Z,"fixed in https://github.com/apache/singa/pull/639
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwNDIwOTgxMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/634,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwNTA3NDI4MA==,singa,605074280,634,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-03-27T15:50:55Z,2020-03-27T15:50:55Z,"Hi, @dcslin , thanks for your help, this PR works fine for basic test cases. However, for some special cases in onnx, it has an incorrect result, I've extracted this test case for you, please use this:

```python3
for dev in [cpu_dev, gpu_dev]:

      X = np.random.random((1, 256, 12, 64)).astype(np.float32)
      x = tensor.from_numpy(X)
      x.to_device(dev)

      W = np.random.random((1, 256, 12, 64)).astype(np.float32)
      w = tensor.from_numpy(W)
      w.to_device(dev)

      X = np.transpose(X, (0, 2, 1, 3))
      W = np.transpose(W, (0, 2, 1, 3))
      W = np.transpose(W, (0, 1, 3, 2))
      Y = np.matmul(X, W)

      x = autograd.transpose(x, (0, 2, 1, 3))
      w = autograd.transpose(w, (0, 2, 1, 3))
      w = autograd.transpose(w, (0, 1, 3, 2))
      y = autograd.matmul(x, w)

      np.testing.assert_array_almost_equal(tensor.to_numpy(x), X)
      np.testing.assert_array_almost_equal(tensor.to_numpy(w), W)
      np.testing.assert_array_almost_equal(tensor.to_numpy(y), Y)
```

This test case reports:
> Traceback (most recent call last):
  File ""../../test/python/test_tensor.py"", line 389, in test_matmul
    np.testing.assert_array_almost_equal(tensor.to_numpy(y), Y)
  File ""/usr/local/lib/python3.5/dist-packages/numpy/testing/_private/utils.py"", line 1015, in assert_array_almost_equal
    precision=decimal)
  File ""/usr/local/lib/python3.5/dist-packages/numpy/testing/_private/utils.py"", line 827, in assert_array_compare
    raise AssertionError(msg)
AssertionError:
Arrays are not almost equal to 6 decimals

> Mismatch: 100%
Max absolute difference: 11.377065
Max relative difference: 1.148434
 x: array([[[[14.145736, 13.506734, 13.252323, ..., 14.569139, 15.795746,
          15.196916],
         [18.76216 , 17.117498, 14.830437, ..., 17.131226, 17.974703,...
 y: array([[[[16.710552, 17.515999, 15.49446 , ..., 15.438944, 18.269606,
          15.611665],
         [14.75556 , 14.552402, 14.04308 , ..., 14.70639 , 15.604133,...","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwNTA3NDI4MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/634,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwNTA3NTg4OA==,singa,605075888,634,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-03-27T15:53:06Z,2020-03-27T15:53:06Z,"And please check the subgraph for this test case:

![image](https://user-images.githubusercontent.com/14108933/77774443-09c42700-7086-11ea-8c27-2ccbd2085851.png)
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwNTA3NTg4OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/634,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwNTQ0OTU0OQ==,singa,605449549,634,NA,dcslin,13751447,Shicong,,NA,2020-03-28T13:47:06Z,2020-03-28T13:47:06Z,"Hi @joddiy , Thank you for pointing out the issue, kindly help to check the lastest code 
PR:https://github.com/apache/singa/pull/639
your test is added: https://github.com/apache/singa/blob/fc1de1d699969e063c47491ded14ef034ec30a0d/test/python/test_tensor.py#L409","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwNTQ0OTU0OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/634,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwNTQ2MzMzMQ==,singa,605463331,634,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-03-28T15:34:11Z,2020-03-28T15:34:11Z,"Hi @dcslin , it works now, thanks for your hlep.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYwNTQ2MzMzMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/635,https://api.github.com/repos/apache/singa/issues/635,singa,586723441,635,cannot init scalar tensor,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,OPEN,2020-03-24T06:23:36Z,2020-03-24T06:23:36Z,"Hi, @dcslin , since some onnx models need scalar-tensor but we can't support.

The error is:
> Traceback (most recent call last):
  File ""../../test/python/test_operation.py"", line 4015, in test_tmp
    x = tensor.from_numpy(x)
  File ""/usr/local/lib/python3.5/dist-packages/singa/tensor.py"", line 766, in from_numpy
    ret.copy_from_numpy(np_array)
  File ""/usr/local/lib/python3.5/dist-packages/singa/tensor.py"", line 307, in copy_from_numpy
    assert np_array.size == self.size(), 'tensor shape should be the same'
AssertionError: tensor shape should be the same

please use this test case:
```python3
x = np.array(256, ndmin=0).astype(np.int32)
x = tensor.from_numpy(x)
```","{""url"": ""https://api.github.com/repos/apache/singa/issues/635/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/644,https://api.github.com/repos/apache/singa/issues/644,singa,591904883,644,Add editorconfig,nudles,3797447,Wei Wang,,OPEN,2020-04-01T13:11:50Z,2020-04-01T13:11:50Z,"[editorconfig](https://editorconfig.org/) is a configuration file adopted by many editors to ensure consistent coding style, which can avoid many diff results when we do git merge.","{""url"": ""https://api.github.com/repos/apache/singa/issues/644/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/655,https://api.github.com/repos/apache/singa/issues/655,singa,594273136,655,Implement cudnn_rnn operation,nudles,3797447,Wei Wang,,CLOSED,2020-04-05T05:39:18Z,2020-11-19T10:33:49Z,"Currently, we implement the rnn operations from scratch, which may not be as fast as the cudnn versions.
To use cudnn rnn operations, we need to implement the cpp operation and call it from the python side.
https://docs.nvidia.com/deeplearning/sdk/cudnn-api/index.html#cudnnRNNMode_t","{""url"": ""https://api.github.com/repos/apache/singa/issues/655/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/655,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDczMDI4MTk1Ng==,singa,730281956,655,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-11-19T10:33:49Z,2020-11-19T10:33:49Z,cudnn rnn was implemented on singa 3.1,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDczMDI4MTk1Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/674,https://api.github.com/repos/apache/singa/issues/674,singa,598283890,674,Autograd Layer constructor,nudles,3797447,Wei Wang,,CLOSED,2020-04-11T15:04:15Z,2020-06-18T02:44:18Z,"The Layer class in Autograd is to maintain the model parameters.
It passes the parameters into the operation and thus operations are stateless.

Typically the parameter size depends on the input and layer configuration.
Currently, we require the users to provide the input size in the layer constructor.
Then we can create the parameter tensor and initialize it in the constructor, e.g., [Linear layer](https://github.com/apache/singa/blob/master/python/singa/autograd.py#L1387). One potential problem is that the initialization operation may not be buffered. @XJDKC  Is it an issue?
For some layers like RNN implemented using cudnn, although we can get the input size, the parameter size is unknown until the cudnn handle is created, which is done until the data is forwarded through the layer.

Another way is to delay the parameter tensor creation until the layer is called for forward propagation. At that time, we have the input tensor (and its device). Then in the layer constructor, we do not need the user to provide the input size. The drawback is that after the layer is created, the get_params() function would still fail to get the parameter tensors as they are not created yet. @dcslin  To switch to this approach, we need to change the constructors of existing layer classes and examples. We also need to provide an initializer function/class into the constructor for initializing the parameter tensors after they are created.

Please add your comments.





","{""url"": ""https://api.github.com/repos/apache/singa/issues/674/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/674,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjQ0MjkxMg==,singa,612442912,674,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-04-11T15:12:28Z,2020-04-11T15:12:28Z,"I think it's not an issue. When we use the computational graph, initialization operations won't be buffered since we just need to execute them once. For these operations, I just execute them immediately instead of buffering them into the graph at present. So before running the entire graph, all parameter tensors will be initialized.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjQ0MjkxMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/674,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjQ0NDQyMg==,singa,612444422,674,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-04-11T15:18:32Z,2020-04-11T15:18:32Z,The module class just buffers the operations during calling the \_\_call\_\_ function of the Layer and the forward function and backward function of the Operation.,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjQ0NDQyMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/674,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjQ0NTkyNA==,singa,612445924,674,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-04-11T15:25:34Z,2020-04-11T15:25:34Z,"I think the Module class is quite similar to Layer, we can think about combining them together. At present, users can't get params from the Module, they can only get them from the Layer. If the Layer class is the subclass of Module, this problem will be solved.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjQ0NTkyNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/674,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjQ0OTkzNw==,singa,612449937,674,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-04-11T15:42:58Z,2020-04-11T15:42:58Z,"> I think it's not an issue. When we use the computational graph, initialization operations won't be buffered since we just need to execute them once. For these operations, I just execute them immediately instead of buffering them into the graph at present. So before running the entire graph, all parameter tensors will be initialized.

Yes, if the initization is in the init function, it will be not buffered automatically. If the initialization is in call function, we can still add a few lines to turn off the buffering. In both case, the graph function won't be affected. ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjQ0OTkzNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/674,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjQ1NDU3OA==,singa,612454578,674,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-04-11T16:10:14Z,2020-04-11T16:10:14Z,"> I think the Module class is quite similar to Layer, we can think about combining them together. At present, users can't get params from the Module, they can only get them from the Layer. If the Layer class is the subclass of Module, this problem will be solved.

Yes, when we buffer the ops, there won't be any actual run, but all the parameters size will be obtained after the call function. ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjQ1NDU3OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/674,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjUzODYwMA==,singa,612538600,674,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-04-11T23:57:47Z,2020-04-11T23:57:47Z,"> > I think the Module class is quite similar to Layer, we can think about combining them together. At present, users can't get params from the Module, they can only get them from the Layer. If the Layer class is the subclass of Module, this problem will be solved.
> 
> Yes, when we buffer the ops, there won't be any actual run, but all the parameters size will be obtained after the call function.

After calling the constructor of Layer class.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjUzODYwMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/674,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU0Mzk2MA==,singa,612543960,674,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-04-12T00:37:09Z,2020-04-12T00:37:09Z,"> > > I think the Module class is quite similar to Layer, we can think about combining them together. At present, users can't get params from the Module, they can only get them from the Layer. If the Layer class is the subclass of Module, this problem will be solved.
> > 
> > 
> > Yes, when we buffer the ops, there won't be any actual run, but all the parameters size will be obtained after the call function.
> 
> After calling the constructor of Layer class.

Constructor might not be enough, because in the case of RNN the CudnnRNNHandle.weight_size is inferred from the input size. So this can only be obtained from the forward function. FYI, this is the new Shicong's code in his PR (I guess this issue is for solving this PR problem):
https://github.com/apache/singa/blob/19f2020fda36032fdc26dc5910dacbfcff638e7f/python/singa/autograd.py#L3406
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU0Mzk2MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/674,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU0ODM4Mg==,singa,612548382,674,NA,nudles,3797447,Wei Wang,,NA,2020-04-12T01:34:19Z,2020-04-12T01:34:19Z,"> 
> 
> I think the Module class is quite similar to Layer, we can think about combining them together. At present, users can't get params from the Module, they can only get them from the Layer. If the Layer class is the subclass of Module, this problem will be solved.

do you mean making Module a subclass of Layer?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU0ODM4Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/674,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU0ODYwMw==,singa,612548603,674,NA,nudles,3797447,Wei Wang,,NA,2020-04-12T01:37:38Z,2020-04-12T01:37:38Z,"> 
> 
> > I think it's not an issue. When we use the computational graph, initialization operations won't be buffered since we just need to execute them once. For these operations, I just execute them immediately instead of buffering them into the graph at present. So before running the entire graph, all parameter tensors will be initialized.
> 
> Yes, if the initization is in the init function, it will be not buffered automatically. If the initialization is in call function, we can still add a few lines to turn off the buffering. In both case, the graph function won't be affected.

how to turn it off? 
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU0ODYwMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/674,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU0OTE2OQ==,singa,612549169,674,NA,nudles,3797447,Wei Wang,,NA,2020-04-12T01:47:00Z,2020-04-12T01:47:00Z,"> 
> 
> I think it's not an issue. When we use the computational graph, initialization operations won't be buffered since we just need to execute them once. For these operations, I just execute them immediately instead of buffering them into the graph at present. So before running the entire graph, all parameter tensors will be initialized.

but you need to identify the operations for initialization.. how to tell if an operation is for initialization or not?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU0OTE2OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/674,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU0OTE5OA==,singa,612549198,674,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-04-12T01:47:19Z,2020-04-12T01:47:19Z,"> > > I think it's not an issue. When we use the computational graph, initialization operations won't be buffered since we just need to execute them once. For these operations, I just execute them immediately instead of buffering them into the graph at present. So before running the entire graph, all parameter tensors will be initialized.
> > 
> > 
> > Yes, if the initization is in the init function, it will be not buffered automatically. If the initialization is in call function, we can still add a few lines to turn off the buffering. In both case, the graph function won't be affected.
> 
> how to turn it off?

To turn off just need to add three lines: 
1. Before the statament before you want to execute, add two lines:
flag = param.device.graph_enabled()
param.device.EnableGraph(False)
2. After the statement, add one line
param.device.EnableGraph(flag)
Note that param is any input tensor that has the attribute ""device"" for us to use","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU0OTE5OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/674,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU1MDAyNQ==,singa,612550025,674,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-04-12T01:58:32Z,2020-04-12T01:58:32Z,"> > I think it's not an issue. When we use the computational graph, initialization operations won't be buffered since we just need to execute them once. For these operations, I just execute them immediately instead of buffering them into the graph at present. So before running the entire graph, all parameter tensors will be initialized.
> 
> but you need to identify the operations for initialization.. how to tell if an operation is for initialization or not?

If the initization statement is in forward function: to tell that it is an initialization operation not for buffering, we need to add three lines:
1. Before the initialization statament not for buffering, add two lines:
flag = param.device.graph_enabled()
param.device.EnableGraph(False)
2. After the statement, add one line
param.device.EnableGraph(flag)
Note that param is any input tensor that has the attribute ""device"" for us to use
 ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU1MDAyNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/674,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU1MTkwOQ==,singa,612551909,674,NA,nudles,3797447,Wei Wang,,NA,2020-04-12T02:21:59Z,2020-04-12T02:21:59Z,"I think it would be better to define a new function to wrap these lines:
```
def execute_once(fn):
    get flag
    disable graph
    fn()
    set flag
```","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU1MTkwOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/674,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU1MzkxNw==,singa,612553917,674,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-04-12T02:42:44Z,2020-04-12T02:42:44Z,"> I think it would be better to define a new function to wrap these lines:
> 
> ```
> def execute_once(fn):
>     get flag
>     disable graph
>     fn()
>     set flag
> ```

@XJDKC Since we have used this stucture at least 2 times before, this wrapper should be useful. Could you help us wrap these line to turn off the buffering temporatory for tensor initialization (need to select the most suitable place/class to add the wrapper)","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU1MzkxNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/674,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU1NjY0Mw==,singa,612556643,674,NA,nudles,3797447,Wei Wang,,NA,2020-04-12T03:11:52Z,2020-04-12T03:11:52Z,"we may need more discussion before the implementation, e.g., which option to go?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU1NjY0Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/674,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU1ODUzMw==,singa,612558533,674,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-04-12T03:33:53Z,2020-04-12T03:33:53Z,"> we may need more discussion before the implementation, e.g., which option to go?

My personal opinion is: 
1. keep the constructors of existing layer classes and examples unchanged (otherwise may not be backward compatible to current examples/APIs and may need lot of debug and finding errors of current examples, it is near the release so better not take the risk)
2. for the new RNN PR the tensor size is infered from the input, and this initialzation statement should put inside execute_once(fn, dev), then there is no problem
3. If we really want to support ""get_params()"" when we use RNN function, we may make use of module class to buffer the ops, then there won't be any actual run. In this case, all the parameters size will be obtained after the forward function and so we can use""get_params()"" afterward. Say if we don't want to use graph after getting the parameter size, we can use ResetGraph to clear the buffer, then turn off buffer and run without graph. (In this setting, layer class needs to have module class buffering, so need to be a subclass of module)

@XJDKC @dcslin @joddiy may you please give your suggestions as well","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU1ODUzMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/674,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU1OTQxMg==,singa,612559412,674,NA,nudles,3797447,Wei Wang,,NA,2020-04-12T03:44:27Z,2020-04-12T03:44:27Z,"We can make the code compatible in this way

```python
# in v3.1
def Foo(**kwargs):
   check if the args are for v3.0 or v3.1 and then call FooV300 or FooV310
```
In V4.0, we change the API completely.

yes. We may need to update Module later to support more functionalities like save and load.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU1OTQxMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/674,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU2MDY3OQ==,singa,612560679,674,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-04-12T03:59:38Z,2020-04-12T03:59:38Z,"> We can make the code compatible in this way
> 
> ```python
> # in v3.1
> def Foo(**kwargs):
>    check if the args are for v3.0 or v3.1 and then call FooV300 or FooV310
> ```
> 
> In V4.0, we change the API completely.
> 
> yes. We may need to update Module later to support more functionalities like save and load.

Yes, this selector for function version is very helpful (says v3.1), and will make the code compatible. Then later in V4.0, can change the API completely.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU2MDY3OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/674,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU2OTg2NA==,singa,612569864,674,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-04-12T06:13:22Z,2020-04-12T06:13:22Z,"> > I think the Module class is quite similar to Layer, we can think about combining them together. At present, users can't get params from the Module, they can only get them from the Layer. If the Layer class is the subclass of Module, this problem will be solved.
> 
> Yes, when we buffer the ops, there won't be any actual run, but all the parameters size will be obtained after the call function.



> > > > I think the Module class is quite similar to Layer, we can think about combining them together. At present, users can't get params from the Module, they can only get them from the Layer. If the Layer class is the subclass of Module, this problem will be solved.
> > > 
> > > 
> > > Yes, when we buffer the ops, there won't be any actual run, but all the parameters size will be obtained after the call function.
> > 
> > 
> > After calling the constructor of Layer class.
> 
> Constructor might not be enough, because in the case of RNN the CudnnRNNHandle.weight_size is inferred from the input size. So this can only be obtained from the forward function. FYI, this is the new Shicong's code in his PR (I guess this issue is for solving this PR problem):
> https://github.com/apache/singa/blob/19f2020fda36032fdc26dc5910dacbfcff638e7f/python/singa/autograd.py#L3406

Sorry, I haven't checked the newest code. Handles in the past code like ConvHandle are initialized in the constructor, so I thought CudnnRNNHandle was the same.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU2OTg2NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/674,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU2OTkxNw==,singa,612569917,674,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-04-12T06:14:04Z,2020-04-12T06:14:04Z,"> > I think the Module class is quite similar to Layer, we can think about combining them together. At present, users can't get params from the Module, they can only get them from the Layer. If the Layer class is the subclass of Module, this problem will be solved.
> 
> do you mean making Module a subclass of Layer?

Yes, or making Layer a subclass of Module.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU2OTkxNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/674,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU3MDM2Mw==,singa,612570363,674,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-04-12T06:19:26Z,2020-04-12T06:19:26Z,"> > I think it's not an issue. When we use the computational graph, initialization operations won't be buffered since we just need to execute them once. For these operations, I just execute them immediately instead of buffering them into the graph at present. So before running the entire graph, all parameter tensors will be initialized.
> 
> but you need to identify the operations for initialization.. how to tell if an operation is for initialization or not?

At present, if the operations are for initialization, they are likely to be in the constructor function. So I just turn on the graph before calling the \_\_call\_\_ function of Layer and forward and backward function of Operation. So all the initialization operations in the constructor will be executed immediately. For those initialization operations in the functions I mentioned above, I turn off the buffer before calling them. Like this, [turn off graph](https://github.com/apache/singa/blob/master/python/singa/opt.py#L155).","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU3MDM2Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/674,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU3MDQwMQ==,singa,612570401,674,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-04-12T06:20:01Z,2020-04-12T06:20:01Z,"> > > I think the Module class is quite similar to Layer, we can think about combining them together. At present, users can't get params from the Module, they can only get them from the Layer. If the Layer class is the subclass of Module, this problem will be solved.
> > 
> > 
> > Yes, when we buffer the ops, there won't be any actual run, but all the parameters size will be obtained after the call function.
> 
> > > > > I think the Module class is quite similar to Layer, we can think about combining them together. At present, users can't get params from the Module, they can only get them from the Layer. If the Layer class is the subclass of Module, this problem will be solved.
> > > > 
> > > > 
> > > > Yes, when we buffer the ops, there won't be any actual run, but all the parameters size will be obtained after the call function.
> > > 
> > > 
> > > After calling the constructor of Layer class.
> > 
> > 
> > Constructor might not be enough, because in the case of RNN the CudnnRNNHandle.weight_size is inferred from the input size. So this can only be obtained from the forward function. FYI, this is the new Shicong's code in his PR (I guess this issue is for solving this PR problem):
> > https://github.com/apache/singa/blob/19f2020fda36032fdc26dc5910dacbfcff638e7f/python/singa/autograd.py#L3406
> 
> Sorry, I haven't checked the newest code. Handles in the past code like ConvHandle are initialized in the constructor, so I thought CudnnRNNHandle was the same.

@XJDKC FYI Even ConvHandle is not initialized in the constructor of Layer but in the call function, but the RNN is different from conv2d just because there is tensor initization in the call function  https://github.com/apache/singa/blob/master/python/singa/autograd.py#L1758","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU3MDQwMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/674,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU3MDYzNA==,singa,612570634,674,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-04-12T06:23:26Z,2020-04-12T06:23:26Z,"> > > I think it's not an issue. When we use the computational graph, initialization operations won't be buffered since we just need to execute them once. For these operations, I just execute them immediately instead of buffering them into the graph at present. So before running the entire graph, all parameter tensors will be initialized.
> > 
> > 
> > but you need to identify the operations for initialization.. how to tell if an operation is for initialization or not?
> 
> At present, if the operations are for initialization, they are likely to be in the constructor function. So I just turn on the graph before calling the __call__ function of Layer and forward and backward function of Operation. So all the initialization operations in the constructor will be executed immediately. For those initialization operations in the functions I mentioned above, I turn off the buffer before calling them. Like this, [turn off graph](https://github.com/apache/singa/blob/master/python/singa/opt.py#L155).

@XJDKC Yes, that' why prof. suggest add the wrapper to it：
```
I think it would be better to define a new function to wrap these lines:
def execute_once(fn):
    get flag
    disable graph
    fn()
    set flag
```","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU3MDYzNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/674,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU3MDkwNw==,singa,612570907,674,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-04-12T06:26:41Z,2020-04-12T06:26:41Z,"@chrishkchris. Thanks for the correction, It is my fault. But for the initialization of the handle, it won't submit operations to Device. So they are not included in the graph either.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU3MDkwNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/674,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU3MTA5Nw==,singa,612571097,674,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-04-12T06:29:09Z,2020-04-12T06:29:09Z,"> > > > I think it's not an issue. When we use the computational graph, initialization operations won't be buffered since we just need to execute them once. For these operations, I just execute them immediately instead of buffering them into the graph at present. So before running the entire graph, all parameter tensors will be initialized.
> > > 
> > > 
> > > but you need to identify the operations for initialization.. how to tell if an operation is for initialization or not?
> > 
> > 
> > At present, if the operations are for initialization, they are likely to be in the constructor function. So I just turn on the graph before calling the **call** function of Layer and forward and backward function of Operation. So all the initialization operations in the constructor will be executed immediately. For those initialization operations in the functions I mentioned above, I turn off the buffer before calling them. Like this, [turn off graph](https://github.com/apache/singa/blob/master/python/singa/opt.py#L155).
> 
> @XJDKC Yes, that' why prof. suggest add the wrapper to it：
> 
> ```
> I think it would be better to define a new function to wrap these lines:
> def execute_once(fn):
>     get flag
>     disable graph
>     fn()
>     set flag
> ```

Yes, we can use a decorator to achieve it.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU3MTA5Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/674,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU3MTY4Mg==,singa,612571682,674,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-04-12T06:37:19Z,2020-04-12T06:37:19Z,"> @chrishkchris. Thanks for the correction, It is my fault. But for the initialization of the handle, it won't submit operations to Device. So they are not included in the graph either.

yes, constructor of handle don't contain any operations to submit to Device, no matter in conv2d or in rnn. 

In Shicong code the only thing to modify is to turn off buffering by wrapping the line in the link below https://github.com/apache/singa/blob/19f2020fda36032fdc26dc5910dacbfcff638e7f/python/singa/autograd.py#L3406

While in long term (says V4.0), it is possible all the initizaltion will be moved to init function of Layer, not in the call function","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU3MTY4Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/674,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU3Mjk2Nw==,singa,612572967,674,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-04-12T06:53:50Z,2020-04-12T06:53:50Z,"Got it, thanks.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU3Mjk2Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/674,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0NTczNTk3MQ==,singa,645735971,674,NA,nudles,3797447,Wei Wang,,NA,2020-06-18T02:44:18Z,2020-06-18T02:44:18Z,resolved in #697 ,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0NTczNTk3MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/675,https://api.github.com/repos/apache/singa/issues/675,singa,598484913,675,Improve the assertion message,nudles,3797447,Wei Wang,,CLOSED,2020-04-12T13:29:15Z,2022-03-05T04:51:11Z,"The check and assertion in some functions now have very brief descriptions, which make it not easy to locate and identify the error.
The displayed information should include at least:
1. the function name 
2. the value of the variable in the check/assertion","{""url"": ""https://api.github.com/repos/apache/singa/issues/675/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/675,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0NTczNTY5Nw==,singa,645735697,675,NA,nudles,3797447,Wei Wang,,NA,2020-06-18T02:43:25Z,2020-06-18T02:43:25Z,We should also print the calling stack if the error/assertion is from the cpp backend.,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0NTczNTY5Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/680,https://api.github.com/repos/apache/singa/issues/680,singa,599996756,680,Propose to upgrade RNN operation buffering for Graph ,chrishkchris,38325429,Chris Yeung,,CLOSED,2020-04-15T03:42:58Z,2020-11-19T10:31:50Z,"In singa/examples/rnn/train.py,

When we run it with Graph using Sequential, i.e. line 200: model.graph(True, True), the training can complete without error.

However, when we run it with Graph using node input dependencies,  i.e. line 200: model.graph(True, False), it will display the error as below:

![errorseq](https://user-images.githubusercontent.com/38325429/79296212-5eccbd80-7f0d-11ea-96f3-8e1badbb4b10.png)

Summarized from some discussion with @XJDKC, the error may be due to the following:

1. There may be some operations we have used but did not specify read_blocks and write_blocks well
2.  Hence, some operations are performed in advance because the operation is not buffer as required  

Therefore, to support computation of graph using node input dependencies, we may need to update the buffering of some RNN operation.
","{""url"": ""https://api.github.com/repos/apache/singa/issues/680/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/680,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyMDYzOTg4NQ==,singa,620639885,680,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-04-28T14:23:37Z,2020-04-28T14:23:37Z,addressed by PR #687 ,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyMDYzOTg4NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/680,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyMDY0MDc2Mg==,singa,620640762,680,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-04-28T14:24:42Z,2020-04-28T14:24:42Z,"Thanks, Chris.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyMDY0MDc2Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/680,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDczMDI4MDkwMQ==,singa,730280901,680,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-11-19T10:31:49Z,2020-11-19T10:31:49Z,solved in previous PRs,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDczMDI4MDkwMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/681,https://api.github.com/repos/apache/singa/issues/681,singa,603263485,681,AlexNet bacward shape missmatch + ReLu return a tuple,Belegkarnil,1352258,,,OPEN,2020-04-20T14:02:43Z,2020-05-04T07:48:19Z,"Hi,

I have implemented AlexNet in singa but I obtain an error during the backward_and_update instruction. I am using Singa 3.0.0.rc1 on cpu.

This is my AlexNet implementation:
`from singa import autograd
from singa import module
from singa import opt

__all__ = ['AlexNet', 'alexnet']

class AlexNet(module.Module):
	def __init__(self, num_classes=1000):
		super(AlexNet, self).__init__()
		# 12 sur GPU donc 6 & 6
		self.features1 = [
			autograd.Conv2d(3,64,kernel_size=11,stride=4,padding=2),
			autograd.ReLU(),
			autograd.MaxPool2d(kernel_size=3, stride=2),
			autograd.Conv2d(64,192,kernel_size=5,padding=2),
			autograd.ReLU(),
			autograd.MaxPool2d(kernel_size=3, stride=2),
			autograd.Conv2d(192,384,kernel_size=3,padding=1),
			autograd.ReLU(),
			autograd.Conv2d(384, 256,kernel_size=3,padding=1),
			autograd.ReLU()
		]
		self.features2 = [
			autograd.Conv2d(256, 256,kernel_size=3,padding=1),
			autograd.ReLU(),
			autograd.MaxPool2d(kernel_size=3, stride=2)
		]
		self.avgpool = autograd.AvgPool2d(6, stride=1)
		self.flatten = autograd.Flatten()
		self.classifier = [
			autograd.Dropout(),
			autograd.Linear(256 * 6 * 6, 4096),
			autograd.ReLU(),
			autograd.Dropout(),
			autograd.Linear(4096, 4096),
			autograd.ReLU(),
			autograd.Linear(4096, num_classes)
		]
		self.optimizer = opt.SGD(lr=0.001, momentum=0.9)
	def loss(self, out, ty):
		return autograd.softmax_cross_entropy(out, ty)
	def optim(self, loss, dist_option, spars):
		if dist_option == 'fp32':
			self.optimizer.backward_and_update(loss)
		elif dist_option == 'fp16':
			self.optimizer.backward_and_update_half(loss)
		elif dist_option == 'partialUpdate':
			self.optimizer.backward_and_partial_update(loss)
		elif dist_option == 'sparseTopK':
			self.optimizer.backward_and_sparse_update(loss, topK=True, spars=spars)
		elif dist_option == 'sparseThreshold':
			self.optimizer.backward_and_sparse_update(loss, topK=False, spars=spars)
	def forward(self, x):
		for (i,layers) in enumerate([self.features1, self.features2, [ self.avgpool,self.flatten  ] , self.classifier]):
			for (j,fn) in enumerate(layers):
				x = fn(x)
				if(type(x) is tuple):# FIXME I have to do that because of a bug in Singa? (ReLU)
					x = x[0]
		return x

def alexnet(**kwargs):
    return  AlexNet(**kwargs)
`
And I get : **AssertionError: ('shape mismatch', (9216, 4096), (256, 4096))**
Which is my first linear layer : 256 * 6 * 6, 4096

When I use my VGG16 implementation, I got a similar error :
AssertionError: ('shape mismatch', (25088, 4096), (512, 4096))

It seems that the backward operation does not map the correct shape to the corresponding layer. 

Moreover, the ReLu class return a 1-tuple containing a Tensor. Is it intended or is it a bug?","{""url"": ""https://api.github.com/repos/apache/singa/issues/681/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/681,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxNzUzNzUxOQ==,singa,617537519,681,NA,dcslin,13751447,Shicong,,NA,2020-04-22T04:10:26Z,2020-04-22T04:10:26Z,"Hi, as pointed out by @chrishkchris , the convention is to use RELU as stateless layer.
usage:
https://github.com/apache/singa/blob/master/examples/cnn/model/cnn.py#L40

For shape mismatch, you might need to check the shape of layers again. Let me know if further info is required.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxNzUzNzUxOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/681,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxNzU5Mjk3Ng==,singa,617592976,681,NA,Belegkarnil,1352258,,,NA,2020-04-22T07:06:14Z,2020-04-22T07:06:14Z,"Ok, I'll try but why to provide a statefull ReLU Layer? Is it for a specific purpose?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxNzU5Mjk3Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/681,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxODE5MTE4MA==,singa,618191180,681,NA,Belegkarnil,1352258,,,NA,2020-04-23T05:44:07Z,2020-04-23T05:44:07Z,"I compared my implementation to other frameworks and it is the same shapes.
Moreover the forward pass does not cause any issue, it is the backward pass.
This is why I suspect a bug. Is it possible?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxODE5MTE4MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/681,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxODQzMDI3NQ==,singa,618430275,681,NA,nudles,3797447,Wei Wang,,NA,2020-04-23T14:34:02Z,2020-04-23T14:34:02Z,"> 
> 
> Hi, as pointed out by @chrishkchris , the convention is to use RELU as stateless layer.
> usage:
> https://github.com/apache/singa/blob/master/examples/cnn/model/cnn.py#L40
> 
> For shape mismatch, you might need to check the shape of layers again. Let me know if further info is required.

@dcslin Did you try to run the code pasted by @Belegkarnil ?
Can you reproduce the error?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxODQzMDI3NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/681,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxODc1NDk0NQ==,singa,618754945,681,NA,dcslin,13751447,Shicong,,NA,2020-04-24T01:41:00Z,2020-04-24T01:41:00Z,"> > Hi, as pointed out by @chrishkchris , the convention is to use RELU as stateless layer.
> > usage:
> > https://github.com/apache/singa/blob/master/examples/cnn/model/cnn.py#L40
> > For shape mismatch, you might need to check the shape of layers again. Let me know if further info is required.
> 
> @dcslin Did you try to run the code pasted by @Belegkarnil ?
> Can you reproduce the error?

I am still checking the code","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYxODc1NDk0NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/681,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyMTAyNjkxNw==,singa,621026917,681,NA,dcslin,13751447,Shicong,,NA,2020-04-29T07:06:09Z,2020-04-29T07:06:09Z,"Hi @Belegkarnil, you might need to change 256 * 6 * 6, 4096 to 256, 4096 to make it works.

Also you are recommended to use relu/dropout/flatten like this https://github.com/apache/singa/blob/master/examples/cnn/model/cnn.py#L40","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyMTAyNjkxNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/681,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyMzMxMTA3Mw==,singa,623311073,681,NA,Belegkarnil,1352258,,,NA,2020-05-04T07:48:19Z,2020-05-04T07:48:19Z,Ok thanks a lot ! I assumed that it works like other frameworks but that the result of AvgPool has a different shape.,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyMzMxMTA3Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/682,https://api.github.com/repos/apache/singa/issues/682,singa,603852091,682,Build conda packages for the master branch,nudles,3797447,Wei Wang,,OPEN,2020-04-21T09:32:04Z,2020-04-21T09:32:04Z,"The update frequency of the dev branch, master branch and version is high, middle and low respectively.
However, the current CI builds the conda package once the master has new commits.
I suggest to
1. build the package when there is a new commit in master branch or a new release. Do not build conda packages when there is a new commit to the dev branch.
2. name the package built against the master branch with the tag 'next' in the build string, which is to be consistent with the documentation site like http://singa.apache.org/docs/next/installation/. But the internal version is still the latest release version. singa-gpu and singa-cpu still points to the latest release  versions.","{""url"": ""https://api.github.com/repos/apache/singa/issues/682/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/690,https://api.github.com/repos/apache/singa/issues/690,singa,615098151,690,Unify the error code,nudles,3797447,Wei Wang,,OPEN,2020-05-09T05:37:55Z,2020-05-12T11:42:40Z,"It would be better to have a error code list for debugging.
Then we can raise the errors.

Here are some example errors:

1. device not set or not match for input tensors to an operator
2. memory not allocated for a tensor
3. parameters not created in a layer
4. tensor shape not match
5. tensor dtype not match
","{""url"": ""https://api.github.com/repos/apache/singa/issues/690/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/690,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzI4OTIyMA==,singa,627289220,690,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-05-12T11:37:36Z,2020-05-12T11:37:36Z,"Yes, currently one of the problem in the debugging is that it do not tell which file and which line has problem.

I suggest we can add `__FILE__`, `__LINE__` to incidate which file and which line when we handle the five examples errors in this issue. For examples:
https://github.com/apache/singa/blob/master/include/singa/io/communicator.h#L54
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzI4OTIyMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/690,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzI5MDMzMw==,singa,627290333,690,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-05-12T11:40:10Z,2020-05-12T11:40:10Z,"> Yes, currently one of the problem in the debugging is that it do not tell which file and which line has problem.
> 
> I suggest we can add `__FILE__`, `__LINE__` to incidate which file and which line when we handle the five examples errors in this issue. For examples:
> https://github.com/apache/singa/blob/master/include/singa/io/communicator.h#L54

Yeah, we can use macros to achieve that. But @nudles suggested we can use an error code list. We can provide a table for users to look up the details of the error by using the error code they get.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzI5MDMzMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/691,https://api.github.com/repos/apache/singa/issues/691,singa,615129967,691,Add save and load method for Module class,nudles,3797447,Wei Wang,,CLOSED,2020-05-09T09:06:26Z,2020-11-14T07:32:31Z,"**Updated on May 15**

```python
class Layer:
   def get_params(self):
       """"""the params of this layer and sublayers as a dict;  param name is: layername.param
           e.g., self.W = Tensor(), self.b=Tensor()
                  name of W and b is  like conv1.W and conv1.b  
       """"""

    def get_states(self):
       """"""states of this layer as sublayers that are necessary for model evaluation/inference.
           the states include the params and others, e.g., the running mean and var of batchnorm.
      """"""

class Module(Layer):   
  def compile(self ...):
     """"""set the name of each layer and sublayers, which will be used to create the dict 
          for get_params and get_states. Then no need to manually config the layer name 
         the __init__ method of a layer.
 
        For instance,
        class Blk(Layer):
             def __init__(self):
                  self.conv1= Conv2d()
                  self.conv2 = Conv2d()

        class MyModel(Module):
              def __init__(self):         
                 self.blk1 = Blk() --> blk1.conv1, blk1.conv2
                 self.blk2 = Blk()  --> blk2.conv1, blk2.conv2
   """"""

  # high priority
  def save(self, fpath, ckp_states={}):
      """"""Save the model and optionally some states.
      
      Args:
         fpath: output file path (without the extension)
         ckp_states(dict): states for checkpoint that are not attributes of Module, e.g., epoch ID.
      """"""
      cust_states = {}
      if ckp_states is not None:
         cust_states = ckp_states + model (include sublayers) attributes - get_states()
      save model states via onnx with customized field for the cust_states

  def load(self, fpath, dev, use_graph, graph_alg):
      """"""Load the model onto dev
   
       Args:
         path: input file path (without the extension)

       Returns:
          dict for the ckp_states.
      ```
      load model states + cust_states
      model attributes = model states + attributes from cust_states
      self.compile()
      restore the model attributes
      return the rest states as a dict

# lower priority
def save(fpath, model, ckp_states):
    attributes <-- model
    replace all tensors in attributes + ckp_states into dict name -->(shape, dtype)
    dump the tensors via numpy.savez_compressed
    dump model via pickle

def load(fpath, dev, use_graph, graph_alg):
     load model via pickle
     load tensors via numpy.load
     restore the tensors 
     return the ckp_states
```

Clarification:
* Params: layer parameters (Tensor) that are updated via SGD. `Layer.get_params()`
* States: Params + other variables that are necessary for model evaluation/inference. Superset of params.  `Layer.get_states()`
* Attributes: members of a class instance `class.__dict__`. Superset of states.","{""url"": ""https://api.github.com/repos/apache/singa/issues/691/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/691,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzI2ODY3OQ==,singa,627268679,691,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-05-12T10:56:17Z,2020-05-12T10:56:17Z,Do we need to save params of the model?,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzI2ODY3OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/691,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzI3OTg0MA==,singa,627279840,691,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-05-12T11:21:48Z,2020-05-12T11:21:48Z,"> Do we need to save params of the model?

Yes, says if we did the training and want to save the model, so that later we can deploy it as web service for inference

This is common because we can train the model inside a cluster with many computational resource.
Then, we deploy the model in a different environment, e.g. to host a inference job web application like image classification.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzI3OTg0MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/691,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzI4OTUxMQ==,singa,627289511,691,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-05-12T11:38:13Z,2020-05-12T11:38:13Z,"> > Do we need to save params of the model?
> 
> Yes, says if we did the training and want to save the model, so that later we can deploy it as web service for inference
> 
> This is common because we can train the model inside a cluster with many computational resource.
> Then, we deploy the model in a different environment, e.g. to host a inference job web application like image classification.

Got it. So I think we better implement this feature on the Python side because the scheduler doesn't have information about the type of operator and it also has no concept of neural network layer.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzI4OTUxMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/691,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzI5MzI5Ng==,singa,627293296,691,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-05-12T11:47:02Z,2020-05-12T11:47:02Z,"> > > Do we need to save params of the model?
> > 
> > 
> > Yes, says if we did the training and want to save the model, so that later we can deploy it as web service for inference
> > This is common because we can train the model inside a cluster with many computational resource.
> > Then, we deploy the model in a different environment, e.g. to host a inference job web application like image classification.
> 
> Got it. So I think we better implement this feature on the Python side because the scheduler doesn't have information about the type of operator and it also has no concept of neural network layer.

If it is in the python side, I guess the easiest way is use pickle to pack a python list or dict, but a drawback is that pickle cannot pack SWIG python object (if I am not wrong)
https://docs.python.org/3/library/pickle.html","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzI5MzI5Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/691,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzI5NzQ1NQ==,singa,627297455,691,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-05-12T11:56:58Z,2020-05-12T11:56:58Z,"> > > > Do we need to save params of the model?
> > > 
> > > 
> > > Yes, says if we did the training and want to save the model, so that later we can deploy it as web service for inference
> > > This is common because we can train the model inside a cluster with many computational resource.
> > > Then, we deploy the model in a different environment, e.g. to host a inference job web application like image classification.
> > 
> > 
> > Got it. So I think we better implement this feature on the Python side because the scheduler doesn't have information about the type of operator and it also has no concept of neural network layer.
> 
> If it is in the python side, I guess the easiest way is use pickle to pack a python list or dict, but a drawback is that pickle cannot pack SWIG python object (if I am not wrong)
> https://docs.python.org/3/library/pickle.html

Or we can serialize and deserialize data ourselves. There is no need to serialize the entire objects, we just need to save the state data.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzI5NzQ1NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/691,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzMwODQ1OQ==,singa,627308459,691,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-05-12T12:21:57Z,2020-05-12T12:21:57Z,"> > > > > Do we need to save params of the model?
> > > > 
> > > > 
> > > > Yes, says if we did the training and want to save the model, so that later we can deploy it as web service for inference
> > > > This is common because we can train the model inside a cluster with many computational resource.
> > > > Then, we deploy the model in a different environment, e.g. to host a inference job web application like image classification.
> > > 
> > > 
> > > Got it. So I think we better implement this feature on the Python side because the scheduler doesn't have information about the type of operator and it also has no concept of neural network layer.
> > 
> > 
> > If it is in the python side, I guess the easiest way is use pickle to pack a python list or dict, but a drawback is that pickle cannot pack SWIG python object (if I am not wrong)
> > https://docs.python.org/3/library/pickle.html
> 
> Or we can serialize and deserialize data ourselves. There is no need to serialize the entire objects, we just need to save the state data.

Yes, I guess it is something like this
1. save https://github.com/nginyc/rafiki/blob/b027c588f27ed4e801e8e300785b0eca230b5167/examples/models/image_classification/TfVgg16.py#L105
2. load
https://github.com/nginyc/rafiki/blob/b027c588f27ed4e801e8e300785b0eca230b5167/examples/models/image_classification/TfVgg16.py#L127
But the different is that this issue is conncerning the ONNX format.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzMwODQ1OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/691,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzMzNDg0MQ==,singa,627334841,691,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-05-12T13:11:58Z,2020-05-12T13:11:58Z,Rafiki dumps model in ONNX format?,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzMzNDg0MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/691,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzMzNjM4MQ==,singa,627336381,691,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-05-12T13:14:18Z,2020-05-12T13:14:18Z,"> Rafiki dumps model in ONNX format?

No, I didn't mean that. They dumps model in different format not in ONNX.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzMzNjM4MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/691,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTEwODk4MA==,singa,629108980,691,NA,dcslin,13751447,Shicong,,NA,2020-05-15T08:36:54Z,2020-05-15T08:36:54Z,"How are the topological connection(`forward()`) and configs(`Linear(2,3)`) handled when `module.save()` is called?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTEwODk4MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/691,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTEyMDU5Nw==,singa,629120597,691,NA,dcslin,13751447,Shicong,,NA,2020-05-15T09:00:15Z,2020-05-15T09:00:15Z,"I guess ""high/low priority"" refers to the preference? In the ""low priority"" option, the `save` and `load` is non intrusive/not part of class `module`.
Personally, serialization, is a mechanism telling how to handle a class, is preferred to be non intrusive/ not part of the class. The class itself is a structure. For example `mymodel = MyModel(); mymodel.load(fp)`. Maybe can be `mymodel=singa.module.load(fp)` 

","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTEyMDU5Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/691,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTE0NzY5NA==,singa,629147694,691,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-05-15T10:00:21Z,2020-05-15T10:00:21Z,"## Conslusion first

Good news: 
> The ONNX can defines the loss and optimizer now within its format. However, current loss only have `NegativeLogLikelihoodLoss` and `SoftmaxCrossEntropyLoss`. Also, it only can store optimizers, only have - `Adagrad`, `Adam`, `Momentum`(SGD with standard momentum). 

Bad news:
> we need to update the onnx to 1.7, which is released last week, may not be so stable. In this release, ONNX defines a comlicated node called `GraphCall` to specify which gradients should be computed and how to update the tensors by using these gradients. Since we will update the weights following the backward, so this part may not be useful for us.

## ONNX Training Preview (TrainingInfoProto)

In last week, the ONNX team has released a new version [1.7.0](https://github.com/onnx/onnx/releases/tag/v1.7.0) which upgrade its opset version to 12. In this new rleases, they add a new feature called [`TrainingInfoProto`](https://github.com/onnx/onnx/blob/3368834cf0b1f0ab9838cf6bdf78a27299d08187/onnx/onnx.proto3#L211-L316). 

This new feature defines something about training information. There are two main parts in it, `initialization-step` and `training-algorithm-step`.

### initialization-step

`initialization-step` means the developer can defines a `initialization`. For its type, the `initialization` is a formal ONNX graph. It doesn't have input but seveal outputs. The developer can defines some nodes in this graph, such as `RandomNormal` or `RandomUniform`, and in another field called `initialization_binding`, the developer can assign these outputs to the specific tensors in the inference graph.

The current supported ramdom methods are: `RandomNormal` or `RandomUniform`.

### training-algorithm-step

`training-algorithm-step` defines a field called `algorithm`. It defines a inference graph which represents a training algorithm's step. Given required inputs, it computes outputs to update tensors in its own or in the main computaton graph. `update_binding` contains a key-value pair of strings to assign the outputs to some specific tensors.

In general, this graph contains loss node, gradient node, optimizer node, increment of iteration count, and some calls to the inference graph. The field algorithm.node is the only place the user can use GraphCall operator. 

#### Loss node

- `NegativeLogLikelihoodLoss`
- `SoftmaxCrossEntropyLoss`


#### Optimizer node

- `Adagrad`
- `Adam`
- `Momentum`: SG with standard momentum

#### Gradient node

The gradient node actually only defines the necessary information to compute the gradient for all graph, for example, at the following graph, the gradient defines its inputs containing the `xs`(intermidate weights) and `zs`(input of the graph), and `y`(the output of the graph), and its outputs having `dY/dW`, `dY/dZ` whose order corresponds to the inputs in `xs`. 

It doesn't defines any logic about how to compute the `dY/dW`, `dY/dZ`.

```
W --> Conv --> H --> Gemm --> Y
|      ^              ^
|      |              |
|      X              Z
|      |              |
|      |   .----------'
|      |   |  (W/Z/X is the 1st/2nd/3rd input of Gradient as shown in
|      |   |   ""xs"" followed by ""zs"")
|      v   v
'---> Gradient(xs=[""W"", ""Z""], zs=[""X""], y=""Y"")
       |   |
       |   '-----------------------------------> dY/dW (1st output of Gradient)
       |
       '---------------------------------------> dY/dZ (2nd output of Gradient)
```

#### GraphCall node

The GraphCall operator invokes a graph inside TrainingInfoProto's algorithm field. The GraphCall inputs and outputs are bound to those of invoked graph by position.

Based on the above inference graph, the GraphCall can use like this:

```
.-------- W (a global and mutable variable from
|         |  the inference graph)
|         |
|   .-----'-----------.
|   |                 |
|   |                 v
|   | .-- X_1 --> GraphCall(graph_name=""MyInferenceGraph"")
|   | |            |  |
|   | |            |  |
|   | |   Z_1 -----'  |
|   | |    |          V
|   | |    |         Y_1 ---> Loss ---> O
|   | |    |                    ^
|   | |    |                    |
|   | `--. |                    C
|   |    | |                    |
|   |    | |   .----------------'
|   |    | |   |
|   |    v v   v
|   `--> Gradient(xs=[""W""], zs=[""X_1"", ""Z_1"", ""C""], y=""O"")
|        |
|        v
|      dO_dW (gradient of W)      1 (a scalar one)
|        |                        |
|        V                        v
|       Div <--- T ------------> Add ---> T_new
|        |    (T is the number of training iterations.
|        |     T is also globally visible and mutable.)
|        v
`-----> Sub ----> W_new
```

The previous section's inference graph is called by `GraphCall(graph_name=""MyInferenceGraph"")`, and it uses a new batch of inputs (`X_1`, `Z_1`) to compute `Y_1`. 

`Gradient` defines the graidents the graph should compute, finally, it gets `W_new` amd `T_new`.

The it uses the following `update_binding` to udpate the tensors:

```
update_binding: {""W"": ""W_new"", ""T"": ""T_new""}
```","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTE0NzY5NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/691,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTE3NzA5OA==,singa,629177098,691,NA,nudles,3797447,Wei Wang,,NA,2020-05-15T11:12:31Z,2020-05-15T11:12:31Z,"> 
> 
> How are the topological connection(`forward()`) and configs(`Linear(2,3)`) handled when `module.save()` is called?

we do a forward (e.g., using placeholder recorded by compile()) inside save() to get the output y and then trace back to get all operations.
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTE3NzA5OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/691,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTE3OTU0MQ==,singa,629179541,691,NA,nudles,3797447,Wei Wang,,NA,2020-05-15T11:18:22Z,2020-05-15T11:18:22Z,"> 
> 
> I guess ""high/low priority"" refers to the preference? In the ""low priority"" option, the `save` and `load` is non intrusive/not part of class `module`.
> Personally, serialization, is a mechanism telling how to handle a class, is preferred to be non intrusive/ not part of the class. The class itself is a structure. For example `mymodel = MyModel(); mymodel.load(fp)`. Maybe can be `mymodel=singa.module.load(fp)`

we provide two approaches.
1. save and load as class method. The disk file is in onnx format. Major application scenario: checkpoint and restore training. Or rename is to checkpoint() and restore().
2. singa.save() and singa.load(). Major application scenario: we do not have the code of MyModule and only have the serialized model. The disk file is in pickle format as we use pickle to serialize MyModule class.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTE3OTU0MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/691,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTI2OTQ4Mg==,singa,629269482,691,NA,nudles,3797447,Wei Wang,,NA,2020-05-15T14:34:21Z,2020-05-15T14:34:21Z,"**Updated on May 15 Night**

```python
class Layer:
   def get_params(self):
       """"""the params of this layer and sublayers as a dict;  param name is: layername.param
           e.g., self.W = Tensor(), self.b=Tensor()
                  name of W and b is  like conv1.W and conv1.b  
       """"""

    def get_states(self):
       """"""states of this layer as sublayers that are necessary for model training/evaluation/inference.
           the states include the params and others, e.g., the running mean and var of batchnorm.
      """"""

class Module(Layer):   
  def compile(self ...):
     """"""set the name of each layer and sublayers, which will be used to create the dict 
          for get_params and get_states. Then no need to manually config the layer name 
         the __init__ method of a layer.
 
        For instance,
        class Blk(Layer):
             def __init__(self):
                  self.conv1= Conv2d()
                  self.conv2 = Conv2d()

        class MyModel(Module):
              def __init__(self):         
                 self.blk1 = Blk() --> blk1.conv1, blk1.conv2
                 self.blk2 = Blk()  --> blk2.conv1, blk2.conv2
   """"""

  # high priority
  def save_states(self, fpath, aux_states={}):
      """"""Save states.
      
      Args:
         fpath: output file path (without the extension)
         aux_states(dict): values are standard data types or Tensor, 
                                   e.g., epoch ID, learning rate, optimizer states
      """"""
      states = get_states() + aux_states + input_placeholders
      tensor_dict = {}
      for k, v in states:
           if type(v) is Tensor:
             tensor_dict[k] = v
             states[k] = {'shape': v.shape, 'dtype': v.dtype}
      save states as json file
      save tensor_dict via numpy or hdf5 or protobuf
      zip the output files

  def load_states(self, fpath, dev, use_graph=True, graph_alg='sequence'):
      """"""Load the model onto dev
   
       Args:
         path: input file path (without the extension)
       Returns:
          dict 
      ```
      unzip the input file
      load the json file --> states
      load the tensor files --> tensor_dict
      put the tensors into states
      states --> model_states + input_placeholders + aux_states
      self.compile(input_placeholders, dev, use_graph, graph_alg)
     model.set_states(model_states) 
     return the rest states as a dict

# lower priority
def save(fpath, model):
    attributes <-- model
    replace all tensors in attributes --> {'shape': v.shape, 'dtype': v.dtype}
    dump the tensors via numpy or protobuf or hdf5
    dump model via pickle
    zip the output files

def load(fpath, dev, use_graph, graph_alg):
     unzip the input file
     load model via pickle
     load tensors 
     restore the tensors in model attributes
     return the model


# handle ONNX 
def to_onnx(model):
    return a onnx model 

class SONNXModel(Module):
     def __init__(self, onnx_model):
          self.store_output = store_output
          for layer_name, layer_config in get_layer(onnx_model):
              self.__dict__[layer_name] = CreateLayer(...)

    def forward(self, aux_output):
          run forward according to onnx graph 
         return the last output + aux_output

class MyModel(SONNXModel):
     def __init__(self, onnx):
          super.__init__(onnx)
          self.layer1 = Conv()
          self.layer2 = Conv()

     def forward(self, x):
           x1, x2 = super.forward(x, aux_output)
           x = self.layer1.forward(x2)
           return self.layer2.forward(x1) + x

      def train_one_batch(self, x, y):
           y_ = self.forward(x)
           ....

```

Clarification:
* Params: layer parameters (Tensor) that are updated via SGD. `Layer.get_params()`
* States: Params + other variables that are necessary for model evaluation/inference. Superset of params.  `Layer.get_states()`
* Attributes: members of a class instance `class.__dict__`. Superset of states.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTI2OTQ4Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/691,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTI5NzY5Nw==,singa,629297697,691,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-05-15T15:16:49Z,2020-05-15T15:16:49Z,"If we have the model stats, we can recreate the params. Do the placeholders still make sense? I think we don't need to compile the module if we use the set_states function.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTI5NzY5Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/691,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTU4MDY2OA==,singa,629580668,691,NA,nudles,3797447,Wei Wang,,NA,2020-05-16T03:20:58Z,2020-05-16T03:20:58Z,"> 
> 
> If we have the model stats, we can recreate the params. Do the placeholders still make sense? I think we don't need to compile the module if we use the set_states function.

The API is a bit ugly.. But we need to compile() to create the handles, which are not serialized as states.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTU4MDY2OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/691,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTU4MTAyMQ==,singa,629581021,691,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-05-16T03:24:41Z,2020-05-16T03:24:41Z,"> > If we have the model stats, we can recreate the params. Do the placeholders still make sense? I think we don't need to compile the module if we use the set_states function.
> 
> The API is a bit ugly.. But we need to compile() to create the handles, which are not serialized as states.

Got it. I thought handles were also state info.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTU4MTAyMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/691,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTU4MzEzMA==,singa,629583130,691,NA,dcslin,13751447,Shicong,,NA,2020-05-16T03:49:03Z,2020-05-16T03:49:03Z,"current save params and states

stateful Layers | Params | States
-- | -- | --
Linear | W, b |  
Conv2D | W, b |  
SeparableConv2d(2 sub layers - Conv2D) |   |  
BatchNorm2d | scale, bias | running_mean, running_var
RNN | Wx, Wh, b |  
LSTM | Wx \* 4, Wh \* 4, Bx \* 4, Bh \*  4 |  
CudnnRNN(no in master) | W |  

","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTU4MzEzMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/691,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTYwNDUzMQ==,singa,629604531,691,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-05-16T07:49:28Z,2020-05-16T07:49:28Z,"```
# handle ONNX 
def to_onnx(model):
    return a onnx model 

class SONNXModel(Module):
    def __init__(self, onnx_model):
        singa_rep = sonnx.prepare(onnx_model, device=dev, batchsize=1)
        for layer_name, layer in singa_rep.layers:
            self.__dict__[layer_name] = layer
        # store weights here as numpy
        for weith_name, weight in singa_rep.weights:
            self.weights[weith_name] = weight
        # store layer info such as input and output name(only weights)
        for layer_name, layer_info in singa_rep.layer_infos:
            self.layer_infos[layer_name] = layer_info

    def forward(self, aux_output):
        # run forward according to onnx graph 
        return the last output + aux_output

    def compile(self)
        # init weights
        super.compile(self)
        # set weights' value
        for layer_name, layer in self.__dict__:
            input_info, output_info = self.layer_infos[layer_name]
            for input_name in input_info:
                layer.set_weight(self.weights[input_name])

class MyModel(SONNXModel):
     def __init__(self, onnx):
          super.__init__(onnx)
          self.layer1 = Conv()
          self.layer2 = Conv()

     def forward(self, x):
           x1, x2 = super.forward(x, aux_output)
           x = self.layer1.forward(x2)
           return self.layer2.forward(x1) + x

      def train_one_batch(self, x, y):
           y_ = self.forward(x)
           ....
```
How about this one, we pareses onnx by `soon.prepare`(Backend), it returns a `singa_rep`(BackendRep), and the  singa_rep contains the layers, weights and input_output_info, we store the layers in `self.__dict__`. When we compile the model, first we call super() to init the params, then we set its value from the onnx loaded weights.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTYwNDUzMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/691,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTYwNjM0OQ==,singa,629606349,691,NA,nudles,3797447,Wei Wang,,NA,2020-05-16T08:03:22Z,2020-05-16T08:03:22Z,"Pls check my inline comments starting with **

> 
> 
> ```
> # handle ONNX 
> def to_onnx(model):
>     return a onnx model 
> 
> class SONNXModel(Module):
>     def __init__(self, onnx_model):  ** need to pass the dev as an argument.
>         singa_rep = sonnx.prepare(onnx_model, device=dev, batchsize=1)
>         for layer_name, layer in singa_rep.layers:
>             self.__dict__[layer_name] = layer
>         # store weights here as numpy
>         for weith_name, weight in singa_rep.weights:
>             self.weights[weith_name] = weight
>         # store layer info such as input and output name(only weights)
>         for layer_name, layer_info in singa_rep.layer_infos:
>             self.layer_infos[layer_name] = layer_info
> 
>     def forward(self, aux_output):
>         # run forward according to onnx graph 
>         return the last output + aux_output
> 
>     def compile(self)   
>         # init weights
>         super.compile(self)   ** args like dev, use_graph, graph_alg should be passed.
>         # set weights' value
>         for layer_name, layer in self.__dict__:
>             input_info, output_info = self.layer_infos[layer_name]
>             for input_name in input_info:
>                 layer.set_weight(self.weights[input_name])   ** remember to release self.weights to free memory.
> 
> class MyModel(SONNXModel):
>      def __init__(self, onnx):
>           super.__init__(onnx)
>           self.layer1 = Conv()
>           self.layer2 = Conv()
> 
>      def forward(self, x):
>            x1, x2 = super.forward(x, aux_output)
>            x = self.layer1.forward(x2)
>            return self.layer2.forward(x1) + x
> 
>       def train_one_batch(self, x, y):
>            y_ = self.forward(x)
>            ....
> ```
> 
> How about this one, we pareses onnx by `soon.prepare`(Backend), it returns a `singa_rep`(BackendRep), and the singa_rep contains the layers, weights and input_output_info, we store the layers in `self.__dict__`. When we compile the model, first we call super() to init the params, then we set its value from the onnx loaded weights.

It's good to reuse singa_rep.
To use MyModel,
```python
ox = onnx.load(fpath)
m = MyModel(ox)
m.compile([x]...)
```



","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTYwNjM0OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/691,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTYwODYwNw==,singa,629608607,691,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-05-16T08:23:24Z,2020-05-16T08:23:24Z,"```
# handle ONNX 
def to_onnx(model):
    return a onnx model 

class SONNXModel(Module):
    def __init__(self, onnx_mode): 
        singa_rep = sonnx.prepare(onnx_model) # will update the prepare function to remove device and batchsize
        for layer_name, layer in singa_rep.layers:
            self.__dict__[layer_name] = layer
        # store weights here as numpy
        for weith_name, weight in singa_rep.weights:
            self.weights[weith_name] = weight
        # store layer info such as input and output name(only weights)
        for layer_name, layer_info in singa_rep.layer_infos:
            self.layer_infos[layer_name] = layer_info

    def forward(self, aux_output):
        # run forward according to onnx graph 
        return the last output + aux_output

    def compile(self, inputs, is_train, use_graph, graph_alg)
        # init weights
        super.compile(self, inputs, is_train, use_graph, graph_alg)
        # set weights' value
        for layer_name, layer in self.__dict__:
            input_info, output_info = self.layer_infos[layer_name]
            for input_name in input_info:
                layer.set_weight(self.weights[input_name])   ** remember to release self.weights to free memory.

class MyModel(SONNXModel):
     def __init__(self, onnx):
          super.__init__(onnx)
          self.layer1 = Conv()
          self.layer2 = Conv()

     def forward(self, x):
           x1, x2 = super.forward(x, aux_output)
           x = self.layer1.forward(x2)
           return self.layer2.forward(x1) + x

      def train_one_batch(self, x, y):
           y_ = self.forward(x)
           ....

ox = onnx.load(fpath)
x = Placeholder((2, 3), device = gpu, dtype=singa.float) # alias of Tensor
m = MyModel(ox)
# compatible with existing code which does not have the following two statements.
m.compile([x], is_train=True, use_graph=True, graph_alg='sequence')

y = Placeholder((2,), device = gpu)
for npx, npy in data:
   x.copy_from(npx)
   y.copy_from(npy)
   m.train_one_batch(x, y)  # build the graph in the first iter.  For the old code, the params are initialized here.
```

update code with the comments with `**`

And I need to update the current `SingaBackend` and `SingabackendRep`, in the `SingaBackend`, we won't create tensors, we only create layers and store the weights as numpy array. We postpone the tensor creation to `SingabackendRep.run` to make this API be uniform with the above API.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTYwODYwNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/691,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTYwOTA4OQ==,singa,629609089,691,NA,nudles,3797447,Wei Wang,,NA,2020-05-16T08:27:55Z,2020-05-16T08:27:55Z,"To be consistent, I think we'd better always call `m.compile()` explicitly?
```python
m=MyModel()
m.compile([x], use_graph=True)
m.load_states(fpath)

m=MyONNXModel(onnx_model)
m.compile([x], use_graph=True)

m=singa.load(fpath)
m.compile([x], use_graph=True)
```

Then the `load_states()` only has a single argument, i.e., fpath.

Any better solution?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTYwOTA4OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/691,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTYxMDA3Mg==,singa,629610072,691,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-05-16T08:36:58Z,2020-05-16T08:36:58Z,"> To be consistent, I think we'd better always call `m.compile()` explicitly?
> 
> ```python
> m=MyModel()
> m.compile([x], use_graph=True)
> m.load_states(fpath)
> 
> m=MyONNXModel(onnx_model)
> m.compile([x], use_graph=True)
> 
> m=singa.load(fpath)
> m.compile([x], use_graph=True)
> ```
> 
> Then the `load_states()` only has a single argument, i.e., fpath.
> 
> Any better solution?

Actually, in the above sonnx API, we merge load_states into compile, right?
How about this one:

```
m=MyModel(path) # check the file is a model or just states
m.compile([x], use_graph=True) # do m.load_states(fpath) within compile

m=MyONNXModel(onnx_model)
m.compile([x], use_graph=True)

m=singa.load(fpath)
m.compile([x], use_graph=True)
```","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTYxMDA3Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/691,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTYxMDY0OQ==,singa,629610649,691,NA,nudles,3797447,Wei Wang,,NA,2020-05-16T08:41:40Z,2020-05-16T08:41:40Z,"1. I think you can still store numpy arrays in singabackend. Copy data from numpy array into the param tensors directly later.
2. The new APIs are more consistent. But users then do not call `load_states` explicitly. They do call `save_states()` explicitly.  Not symmetric..  @dcslin any comments?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTYxMDY0OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/691,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTYzNDU0MA==,singa,629634540,691,NA,dcslin,13751447,Shicong,,NA,2020-05-16T11:58:23Z,2020-05-16T11:58:23Z,"Quoted from @joddiy , `m=MyModel(path) # check the file is a model or just states`, this case, user know `MyModel` class, so just loading states right?


From the perspective of a new onnx user, please let me know if this part is not correct.
`singa_rep`: model like `singa.Module`
`singa.save()/singa.load()`: save/load model w/o states
`singa.Module.save_states()/load_states()`: save/load model states only

### Use case 1, load model from onnx file
```python
class MySONNXModel(SONNXModel):
    pass # so we know the structure of model already?

# load from onnx model
onnx_model=onnx.load('./saved_models/onnx_model_downloaded')
m1=MySONNXModel(onnx_model) # so we know the structure of model already?
m1.compile([placeholder_x], ...)
for _ in data:
    m1.train_one_batch(_)
```

### use case 2: save states and model
```python
# save
m1.save_states('./saved_models/my_checkpoint_1')
singa.save('./saved_models/my_model_1', m1)
```

### use case 3 load model and states from disk
```python
# Later reuse the model
m2=singa.load('./saved_models/my_model_1')
m2.load_states('./saved_models/my_checkpoint_1')
m2.compile([placeholder_x], use_graph=True)
```

### use case 4 load states only
```python
# singa model is known
class MyModel(Module):
    pass

m3=MyModel(states_path='./saved_models/my_checkpoint_1') # could only be states, right?
# m3=MyModel('./saved_models/my_model_1') # could not be saved_model right? since we know the model
m3.compile(...)
```

To be frank, I am a bit overwhelmed by all the discussions not just in this issue, is it possible to consolidate the new API into a specification including example in singa-doc? Which is useful for new users? btw, is API in [onnx-doc](https://github.com/apache/singa-doc/blob/master/docs-site/docs/onnx.md) gonna change?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTYzNDU0MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/691,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTY2MTM2MA==,singa,629661360,691,NA,nudles,3797447,Wei Wang,,NA,2020-05-16T15:12:53Z,2020-05-16T15:12:53Z,"Here is the latest summary: https://gist.github.com/nudles/d7f8043f251872333ec06f2701696cce

APIs in onnx-doc should be backward-compatible. ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTY2MTM2MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/691,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyNzE2MDc3Nw==,singa,727160777,691,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-11-14T07:32:30Z,2020-11-14T07:32:30Z,save and load functions are now available on 3.1 Model Class,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyNzE2MDc3Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/692,https://api.github.com/repos/apache/singa/issues/692,singa,615134864,692,Extend the opt module,nudles,3797447,Wei Wang,,CLOSED,2020-05-09T09:34:21Z,2020-11-19T10:36:19Z,Refer to https://gist.github.com/nudles/d7f8043f251872333ec06f2701696cce,"{""url"": ""https://api.github.com/repos/apache/singa/issues/692/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/692,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzI3ODExNw==,singa,627278117,692,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-05-12T11:18:00Z,2020-05-12T11:18:00Z,"There are a list of optimizers in optimizer.py but cannot use in opt.py
https://github.com/apache/singa/blob/master/python/singa/optimizer.py
I suggest we can move the optimizers from optimizer.py to opt.py
Those include:
1. class Nesterov(Optimizer):
2. class RMSProp(Optimizer):
3. class AdaGrad(Optimizer):
4. class Adam(Optimizer):
5. class L2Regularizer(Regularizer): // if regularization should be considered too","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzI3ODExNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/692,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY2Mzk5MTAwNg==,singa,663991006,692,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-07-26T13:54:54Z,2020-07-26T13:54:54Z,addressed in #773 ,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY2Mzk5MTAwNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/692,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDczMDI4MzI0NQ==,singa,730283245,692,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-11-19T10:36:18Z,2020-11-19T10:36:18Z,addressed in #773,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDczMDI4MzI0NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/693,https://api.github.com/repos/apache/singa/issues/693,singa,615139971,693,Extend the Module class,nudles,3797447,Wei Wang,,CLOSED,2020-05-09T10:03:31Z,2020-05-16T07:21:08Z,"In  #674 , we propose to move the param creation and initialization into the forward propagation stage, i.e., `__call__`. 
However, sometimes, we may want to access the parameters of a model after it is created, e.g., 
```python
m = ModelFoo()
m.get_params()  # returns the params of each layer via get_params
```
We will get errors since the params are not created yet.
To resolve this issue, we can add a new method to the Module class
```python
def init(self, x):
    # x represents the input tensor(s) whose values could be randomly filled, 
    # but the shape and device are set correctly.
    self.forward(x)  # the forward propagation will initialize all params.
```
The following code will pass without errors.
```python
m = ModelFoo()
m.init(x)
m.get_params()  # returns the params of each layer via get_params
```

Comments are welcomed
","{""url"": ""https://api.github.com/repos/apache/singa/issues/693/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/693,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzI2NTAzOQ==,singa,627265039,693,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-05-12T10:47:53Z,2020-05-12T10:47:53Z,"@XJDKC In this case, I suggest we can use the buffer operation feature so there won't be any actual run. 
Then, in case if we don't want to use graph after getting the parameter size, we can use ResetGraph to clear the buffer, then turn off buffer and run without graph.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzI2NTAzOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/693,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzI2NzAwOQ==,singa,627267009,693,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-05-12T10:52:22Z,2020-05-12T10:52:22Z,"I worry that if we move the param creation and initialization into the forward propagation stage, those initialization operations will also be buffered and included in the graph.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzI2NzAwOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/693,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzI2Nzg0OA==,singa,627267848,693,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-05-12T10:54:23Z,2020-05-12T10:54:23Z,"> I worry that if we move the param creation and initialization into the forward propagation stage, those initialization operations will also be buffered and included in the graph.

@XJDKC Can use ResetGraph to reset the buffer?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzI2Nzg0OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/693,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzI3MDIwMw==,singa,627270203,693,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-05-12T10:59:55Z,2020-05-12T10:59:55Z,"> > I worry that if we move the param creation and initialization into the forward propagation stage, those initialization operations will also be buffered and included in the graph.
> 
> @XJDKC Can use ResetGraph to reset the buffer?

I prefer adding an initialization function for Layer, the module just needs to call the init function of each layer to initialize the whole model.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzI3MDIwMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/693,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzI3NDc5Ng==,singa,627274796,693,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-05-12T11:10:41Z,2020-05-12T11:10:41Z,"> > > I worry that if we move the param creation and initialization into the forward propagation stage, those initialization operations will also be buffered and included in the graph.
> > 
> > 
> > @XJDKC Can use ResetGraph to reset the buffer?
> 
> I prefer adding an initialization function for Layer, the module just needs to call the init function of each layer to initialize the whole model.

@XJDKC 
Yes, in the following example the parameter of the layer is initialized in the call function, where its shape is infered from the input size of that layer 
https://github.com/apache/singa/blob/19f2020fda36032fdc26dc5910dacbfcff638e7f/python/singa/autograd.py#L3406
Can this case be handled?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzI3NDc5Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/693,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzI4NTQwOA==,singa,627285408,693,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-05-12T11:33:20Z,2020-05-12T11:33:20Z,"> > > > I worry that if we move the param creation and initialization into the forward propagation stage, those initialization operations will also be buffered and included in the graph.
> > > 
> > > 
> > > @XJDKC Can use ResetGraph to reset the buffer?
> > 
> > 
> > I prefer adding an initialization function for Layer, the module just needs to call the init function of each layer to initialize the whole model.
> 
> @XJDKC
> Yes, in the following example the parameter of the layer is initialized in the call function, where its shape is infered from the input size of that layer
> https://github.com/apache/singa/blob/19f2020fda36032fdc26dc5910dacbfcff638e7f/python/singa/autograd.py#L3406
> 
> 
> Can this case be handled?

The handle can be created in the init function, and then W can be initialized by the handle.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzI4NTQwOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/693,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTYwMTcwOA==,singa,629601708,693,NA,nudles,3797447,Wei Wang,,NA,2020-05-16T07:21:07Z,2020-05-16T07:21:07Z,#696 ,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTYwMTcwOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/695,https://api.github.com/repos/apache/singa/issues/695,singa,616324668,695,PackageNotFoundError in Installation,agnesnatasya,44172431,Agnes Natasya,agnesnatasya@u.nus.edu,CLOSED,2020-05-12T03:11:38Z,2020-05-16T07:21:35Z,"Followed the installation instruction in http://singa.apache.org/ but encountered a similar error as this issue https://issues.apache.org/jira/browse/SINGA-422

I tried to delete all installed package and redo, I encountered this error.

```
NoBaseEnvironmentError: This conda installation has no default base environment. Use
'conda create' to create new environments and 'conda activate' to
activate environments.

```

I created a new virtual environment and I encountered this error when I entered any of the three commands

```
PackagesNotFoundError: The following packages are not available from current channels:

  - singa-gpu
```
Has there been any similar issues to this? Thank you for the help!","{""url"": ""https://api.github.com/repos/apache/singa/issues/695/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/695,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODYwNTEzNQ==,singa,628605135,695,NA,dcslin,13751447,Shicong,,NA,2020-05-14T12:36:42Z,2020-05-14T12:36:42Z,"Hi @agnesnatasya , thank you for raising the issue, it seems that your conda is not configured properly. Would you like to follow this tutorial on conda website to configure your conda environment? https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html

I have just tested on a clean environment, it works at my side:
```
root@1e5cfb0a87dd:~# conda search -c nusdbsystem singa-gpu=3.0.0
Loading channels: done
# Name                       Version           Build  Channel
singa-gpu                      3.0.0            py37  nusdbsystem
```

```
root@1e5cfb0a87dd:~# conda install -c nusdbsystem singa-gpu=3.0.0
Collecting package metadata (current_repodata.json): done
Solving environment: failed with initial frozen solve. Retrying with flexible solve.
Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.
Collecting package metadata (repodata.json): done
Solving environment: done

## Package Plan ##

  environment location: /root/miniconda

  added / updated specs:
    - singa-gpu=3.0.0


The following packages will be downloaded:

...
...
...

Downloading and Extracting Packages
llvm-openmp-10.0.0   | 2.8 MB    | ################################################################################################################################################################### | 100%
libprotobuf-3.9.2    | 4.7 MB    | ################################################################################################################################################################### | 100%
_libgcc_mutex-0.1    | 3 KB      | ################################################################################################################################################################### | 100%
dnnl-1.1             | 3.6 MB    | ################################################################################################################################################################### | 100%
wrapt-1.12.1         | 46 KB     | ################################################################################################################################################################### | 100%
singa-gpu-3.0.0      | 4 KB      | ################################################################################################################################################################### | 100%
protobuf-3.9.2       | 688 KB    | ################################################################################################################################################################### | 100%
singa-3.0.0          | 26.8 MB   | ################################################################################################################################################################### | 100%
libopenblas-0.3.9    | 7.8 MB    | ################################################################################################################################################################### | 100%
deprecated-1.2.7     | 10 KB     | ################################################################################################################################################################### | 100%
libgcc-ng-9.2.0      | 8.2 MB    | ################################################################################################################################################################### | 100%
_openmp_mutex-4.5    | 5 KB      | ################################################################################################################################################################### | 100%
Preparing transaction: done
Verifying transaction: done
Executing transaction: done
```

```
root@1e5cfb0a87dd:~# python3
Python 3.7.6 (default, Jan  8 2020, 19:59:22)
[GCC 7.3.0] :: Anaconda, Inc. on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import singa
```

Kindly let me know if further info is required.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODYwNTEzNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/695,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODc5NTg5OQ==,singa,628795899,695,NA,agnesnatasya,44172431,Agnes Natasya,agnesnatasya@u.nus.edu,NA,2020-05-14T17:59:24Z,2020-05-14T17:59:24Z,"Hi @dcslin thank you so much for replying to my issue. Yes, I did not create the virtual environment properly. Now, I have created the virtual environment using 
`conda create -n singa python=3.6`
and I entered this command afterwards
`conda install -c nusdbsystem -c conda-forge singa=3.0.0`

I do not use singa-gpu=3.0.0 like you because if gave me a PackageNotFoundError as it is not listed in my channel, singa=3.0.0 works for me though. 

However, it still gave me a compatibility error. 
```
UnsatisfiableError: The following specifications were found to be incompatible with each other:



Package libcxx conflicts for:
python=3.6 -> libcxx[version='>=4.0.1']
singa=3.0.0 -> libcxx[version='>=9.0.1']
Package libopenblas conflicts for:
singa=3.0.0 -> libopenblas=0.3.9
Package numpy conflicts for:
singa=3.0.0 -> numpy[version='>=1.16,<1.17.0a0']
Package tk conflicts for:
python=3.6 -> tk[version='8.6.*|>=8.6.7,<8.7.0a0|>=8.6.8,<8.7.0a0']
Package zlib conflicts for:
python=3.6 -> zlib[version='>=1.2.11,<1.3.0a0']
Package glog conflicts for:
singa=3.0.0 -> glog[version='>=0.3.5,<0.4.0a0']
Package libprotobuf conflicts for:
singa=3.0.0 -> libprotobuf=3.10.0
Package python_abi conflicts for:
singa=3.0.0 -> python_abi[version='3.6.*|3.7.*',build='*_cp37m|*_cp36m']
Package tqdm conflicts for:
singa=3.0.0 -> tqdm
Package pip conflicts for:
python=3.6 -> pip
Package deprecated conflicts for:
singa=3.0.0 -> deprecated=1.2.7
Package sqlite conflicts for:
python=3.6 -> sqlite[version='>=3.20.1,<4.0a0|>=3.22.0,<4.0a0|>=3.23.1,<4.0a0|>=3.24.0,<4.0a0|>=3.25.2,<4.0a0|>=3.26.0,<4.0a0|>=3.29.0,<4.0a0|>=3.30.1,<4.0a0|>=3.31.1,<4.0a0']
Package xz conflicts for:
python=3.6 -> xz[version='>=5.2.3,<6.0a0|>=5.2.4,<6.0a0|>=5.2.5,<6.0a0']
Package readline conflicts for:
python=3.6 -> readline[version='7.*|>=7.0,<8.0a0|>=8.0,<9.0a0']
Package libffi conflicts for:
python=3.6 -> libffi[version='3.2.*|>=3.2.1,<3.3a0|>=3.3,<3.4.0a0']
Package future conflicts for:
singa=3.0.0 -> future
Package ncurses conflicts for:
python=3.6 -> ncurses[version='>=6.0,<7.0a0|>=6.1,<7.0a0|>=6.2,<7.0a0']
Package onnx conflicts for:
singa=3.0.0 -> onnx=1.6.0
Package dnnl conflicts for:
singa=3.0.0 -> dnnl[version='>=1.1,<1.2.0a0']
Package openssl conflicts for:
python=3.6 -> openssl[version='1.0.*|1.0.*,>=1.0.2l,<1.0.3a|>=1.0.2m,<1.0.3a|>=1.0.2n,<1.0.3a|>=1.0.2o,<1.0.3a|>=1.1.1a,<1.1.2a|>=1.1.1c,<1.1.2a|>=1.1.1d,<1.1.2a|>=1.1.1e,<1.1.2a|>=1.1.1g,<1.1.2a']
Package pillow conflicts for:
singa=3.0.0 -> pillow
```
I received similar long error message when I configure the python version of the virtual environment to be 3.7. 

Thus, I tried to create the virtual environment using package version according to what singa wants, such as 
```
conda install -n singa python=3.6 libcxx=9.0.1 libopenblas=0.3.9 numpy=1.16 tk=8.6.7 zlib=1.2.11 glog=0.3.5 tqdm pip deprecated=1.2.7 sqlite=3.20.1 xz=5.2.3 readline=7.0 libffi=3.2.1 future ncurses=6.1 openssl=1.0.2 pillow
```

It then give me some other incompatibility error like this
```
UnsatisfiableError: The following specifications were found to be incompatible with a past
explicit spec that is not an explicit spec in this operation (libopenblas):

  - libopenblas=0.3.9
  - numpy=1.16 -> mkl_random[version='>=1.0.2,<2.0a0'] -> numpy-base[version='>=1.0.2,<2.0a0,>=1.0.4,<2.0a0'] -> libopenblas[version='>=0.3.3,<1.0a0']

The following specifications were found to be incompatible with each other:



Package libgfortran conflicts for:
libgfortran
numpy=1.16 -> mkl_random[version='>=1.0.2,<2.0a0'] -> numpy-base[version='>=1.0.2,<2.0a0,>=1.0.4,<2.0a0'] -> libopenblas[version='>=0.3.3,<1.0a0'] -> libgfortran[version='>=3.0.1,<4.0.0.a0']
libopenblas=0.3.9 -> libgfortran[version='>=4.0.0,<5.0.0.a0']
```

Really apologise for the trouble, do you have any idea why this is happening?
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODc5NTg5OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/695,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTU5OTA3OQ==,singa,629599079,695,NA,agnesnatasya,44172431,Agnes Natasya,agnesnatasya@u.nus.edu,NA,2020-05-16T06:54:33Z,2020-05-16T06:54:33Z,"Hi, I have tried again from a clean environment, and I successfully installed it, somehow all the errors are not there anymore. Thank you for your help!","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTU5OTA3OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/696,https://api.github.com/repos/apache/singa/issues/696,singa,616336790,696,Refactor autograd module,nudles,3797447,Wei Wang,,CLOSED,2020-05-12T03:47:48Z,2020-06-18T02:45:22Z,"#688 is refactoring the autograd module.
Here are some comments about the current APIs in autograd.

1. Relationship between the classes and functions in autograd.
  `Operator` implements the forward and backward method for autograd.
For each `Operator` class, there is a function that creates an `Operator` instance and calls the forward method.
`Layer` stores the states (handles and parameters) and calls `Operator` function for the real computation. Note that a layer class can have sub-layers (as states) for creating complex and deep models.
  **Issue**:
  When we create a network using the `Module` API, there are both stateless (e.g., flatten) and statefull (conv2d) operations. Currently, we create layers in `__init__` of `Module` and calls the layers and operator function in `forward` method. Therefore, Layer and Operator are mixed, which may confuse the users. A better way is to use Layer instances only. For every operator, we create a corresponding layer class to replace the layer function.

2. Layer API.
  **issue**: when and how to initialize the parameters and (handle) of a layer?
  * do initialization in `__init__` method OR when the data is forwarded for the first time #674 
  * pass an `initializer` function to the `__init__` method of a layer and use it to initialize the parameters OR pass an `initializer` function to the `__init__` method of the Module class and use it to initialize the parameter (through `get_params`) of the layers after forwarding the layers for once. The second approach requires the Module class's `__init__` to do a forward pass of all layers and then `get_params` of each layer for initialization. To do that, it needs at least the shapes of the input tensors and the device. The drawback of the first approach is that we need to include the initializer in every Layer constructor. 

comments are welcomed.


","{""url"": ""https://api.github.com/repos/apache/singa/issues/696/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/696,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzczNjg4Ng==,singa,627736886,696,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-05-13T04:24:26Z,2020-05-13T04:24:26Z,"* Scheme 1
![scheme_1](https://user-images.githubusercontent.com/32295829/81771083-a34f7700-9514-11ea-92bd-48f884d760f7.png)
* Scheme 2
![scheme_2](https://user-images.githubusercontent.com/32295829/81771093-a9455800-9514-11ea-9ed6-7f6003c807ff.png)
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzczNjg4Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/696,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzc0NDg5MQ==,singa,627744891,696,NA,dcslin,13751447,Shicong,,NA,2020-05-13T04:53:58Z,2020-05-13T04:53:58Z,"Agree on point 1, `Layer` vs `Operation`:

Currently `Layer` is in `autograd.py`, but what `Layer` does is **defining forward connection using building blocks including `Operation` and `Layer`**. Thus by right `Layer` is not part of `autograd`. Singa `autograd` is more on constructing backward pass.

Thus, propose to separate `Layer` into individual module. Additionally, stateless function like `relu` should also be a conceptual `layer`.

For external user, only `Layer` and `Module` are visible. Can build new `Layer` with exisiting `Layer`. Can build new `Module` with existing `Layer`
```python
from singa.layers import Conv2d, relu
```

For internal user/advanced user, can build `Layer` with `Operation`.

Lastly, if this is finalized, `autograd.py` should contains only `Operation`, then we could keep the original naming convention. Not need to mark operation as ""private"" by prefixing underscore e.g. `_RNN`","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzc0NDg5MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/696,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzgzNzAzMA==,singa,627837030,696,NA,nudles,3797447,Wei Wang,,NA,2020-05-13T08:35:29Z,2020-05-13T08:35:29Z,"> 
> 
> Agree on point 1, `Layer` vs `Operation`:
> 
> Currently `Layer` is in `autograd.py`, but what `Layer` does is **defining forward connection using building blocks including `Operation` and `Layer`**. Thus by right `Layer` is not part of `autograd`. Singa `autograd` is more on constructing backward pass.
> 
> Thus, propose to separate `Layer` into individual module. Additionally, stateless function like `relu` should also be a conceptual `layer`.
We can create `class ReLU(Layer)` in layer.py.
> 
> For external user, only `Layer` and `Module` are visible. Can build new `Layer` with exisiting `Layer`. Can build new `Module` with existing `Layer`
> 
> ```python
> from singa.layers import Conv2d, relu
> ```
should be `ReLU`?
> 
> For internal user/advanced user, can build `Layer` with `Operation`.
> 
> Lastly, if this is finalized, `autograd.py` should contains only `Operation`, then we could keep the original naming convention. Not need to mark operation as ""private"" by prefixing underscore e.g. `_RNN`
yes.

","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzgzNzAzMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/696,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzg2OTc4Ng==,singa,627869786,696,NA,nudles,3797447,Wei Wang,,NA,2020-05-13T09:34:56Z,2020-05-13T09:34:56Z,"> 
> 
>     * Scheme 1
>       ![scheme_1](https://user-images.githubusercontent.com/32295829/81771083-a34f7700-9514-11ea-92bd-48f884d760f7.png)
> 
>     * Scheme 2
>       ![scheme_2](https://user-images.githubusercontent.com/32295829/81771093-a9455800-9514-11ea-9ed6-7f6003c807ff.png)

How about using the following APIs.

```python
class Module:
   def __init__(self, inputs):
       # inputs is a list of input tensors (placeholders)
       # randomly fill each input tensor
       self.forward(*inputs)  # turn off the graph mode completely

    # another option is to define a compile method
    def compile(self, inputs, is_train, use_graph, graph_alg):
        self.forward(*inputs)
       
class MyModel(Module):
    def __init__(self, inputs):
       # define all layers
       # can we force the next call to be invoked at the end of the __init__ method?
       super.__init__(inputs)  

x = Placeholder((2, 3), device = gpu)  # alias of Tensor.
m = MyModel([x])
# if use the other option
# m = MyModel()
# m.compile([x], is_train=True, use_graph=True, graph_alg='sequence')

for pname, ptensor in m.get_params():
    ptensor.uniform(-1, 1)

y = Tensor((2,), device = gpu)
for npx, npy in data:
   x.copy_from(npx)
   y.copy_from(npy)
   y_ = m(x)             # build the graph in the first iteration.
   l = m.loss(y, y_)
   # ...
```

```python
class MyLayer:
    def __init__(kernel_initialization=""he_uniform"", name=None):
       # kernel_initialization is a string for the predefined initialization method 
       # or a function that accept a tensor as input and fill the values in-place; 
       # this is to provide a default initialization method; 
       #  users can also configure it to use customized initialization method or 
      # get the params out and fill the values explicitly as shown below.
      self.init = False
      self.kernel_initialization = ...

    def __call__(self, x):
       if self.init == False:
           self.kernel = Tensor(...)
           self.kernel_initialization(self.kernel)
       else:
          # do the forward propagation 
```       ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzg2OTc4Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/696,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzg4OTI1Mg==,singa,627889252,696,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-05-13T10:14:37Z,2020-05-13T10:14:37Z,"> > ```
> > * Scheme 1
> >   ![scheme_1](https://user-images.githubusercontent.com/32295829/81771083-a34f7700-9514-11ea-92bd-48f884d760f7.png)
> > 
> > * Scheme 2
> >   ![scheme_2](https://user-images.githubusercontent.com/32295829/81771093-a9455800-9514-11ea-9ed6-7f6003c807ff.png)
> > ```
> 
> How about using the following APIs.
> 
> ```python
> class Module:
>    def __init__(self, inputs):
>        # inputs is a list of input tensors (placeholders)
>        # randomly fill each input tensor
>        self.forward(*inputs)  # turn off the graph mode completely
> 
>     # another option is to define a compile method
>     def compile(self, inputs, is_train, use_graph, graph_alg):
>         self.forward(*inputs)
>        
> class MyModel(Module):
>     def __init__(self, inputs):
>        # define all layers
>        # can we force the next call to be invoked at the end of the __init__ method?
>        super.__init__(inputs)  
> 
> x = Placeholder((2, 3), device = gpu)  # alias of Tensor.
> m = MyModel([x])
> # if use the other option
> # m = MyModel()
> # m.compile([x], is_train=True, use_graph=True, graph_alg='sequence')
> 
> for pname, ptensor in m.get_params():
>     ptensor.uniform(-1, 1)
> 
> y = Tensor((2,), device = gpu)
> for npx, npy in data:
>    x.copy_from(npx)
>    y.copy_from(npy)
>    y_ = m(x)             # build the graph in the first iteration.
>    l = m.loss(y, y_)
>    # ...
> ```
> 
> ```python
> class MyLayer:
>     def __init__(kernel_initialization=""he_uniform"", name=None):
>        # kernel_initialization is a string for the predefined initialization method 
>        # or a function that accept a tensor as input and fill the values in-place; 
>        # this is to provide a default initialization method; 
>        #  users can also configure it to use customized initialization method or 
>       # get the params out and fill the values explicitly as shown below.
>       self.init = False
>       self.kernel_initialization = ...
> 
>     def __call__(self, x):
>        if self.init == False:
>            self.kernel = Tensor(...)
>            self.kernel_initialization(self.kernel)
>        else:
>           # do the forward propagation 
> ```

Thanks for such a detailed explanation! For the first scheme, we can't call the forward function in \_\_init\_\_ function because `inputs` variable is just a list of placeholders. So we still need to separate initialization and forward propagation, or it will produce a runtime error.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzg4OTI1Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/696,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzg5NTE3NA==,singa,627895174,696,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-05-13T10:27:27Z,2020-05-13T10:27:27Z,"```Python
class MyLayer:
    def __init__(kernel_initialization=""he_uniform"", name=None):
       # kernel_initialization is a string for the predefined initialization method 
       # or a function that accept a tensor as input and fill the values in-place; 
       # this is to provide a default initialization method; 
       #  users can also configure it to use customized initialization method or 
      # get the params out and fill the values explicitly as shown below.
      self.initialized = False
      self.kernel_initialization = ...

    def init(self, x):
       # init params and other state data

    def forward(self, x): 
       # do the forward propagation

    # __call__ function is inherited by all subclasses
    # This part of code does not need to be implemented in every subclass
    def __call__(self, x):
       if self.initialized == False:
           self.init(inputs)
           self.initialized = True
       
       self.forward(inputs)
```

In this way,  when to initialize is transparent to users, users just need to implement \_\_init\_\_, init and forward function if they want to create a new Layer.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzg5NTE3NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/696,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzk4MjEwMw==,singa,627982103,696,NA,nudles,3797447,Wei Wang,,NA,2020-05-13T13:22:04Z,2020-05-13T13:22:04Z,"1. Before we call Module.forward(), we can randomly fill the placeholder tensors.
2. We can make Layer.init() optional. To implement a new layer, the parameter initialization can be done within the `__call__` method or in a `init()` method. It is up to the contributor.

Any comments on the drawbacks?
@dcslin @XJDKC ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzk4MjEwMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/696,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzk5MDk0MA==,singa,627990940,696,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-05-13T13:35:42Z,2020-05-13T13:35:42Z,"> 1. Before we call Module.forward(), we can randomly fill the placeholder tensors.
> 2. We can make Layer.init() optional. To implement a new layer, the parameter initialization can be done within the `__call__` method or in a `init()` method. It is up to the contributor.
> 
> Any comments on the drawbacks?
> @dcslin @XJDKC

1. If we separate the initialization and the forward propagation, there is no need to fill the placeholder. The data of tensors will only be accessed in the forward propagation. For initialization, we just access their shapes, types and so on. 
2. That's great. But if users move the initialization into \_\_call\_\_ function, they should determine whether the layer has been initialized by themselves.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNzk5MDk0MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/696,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODAzMzc5MQ==,singa,628033791,696,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-05-13T14:37:36Z,2020-05-13T14:37:36Z,"> 1. Before we call Module.forward(), we can randomly fill the placeholder tensors.
> 2. We can make Layer.init() optional. To implement a new layer, the parameter initialization can be done within the `__call__` method or in a `init()` method. It is up to the contributor.
> 
> Any comments on the drawbacks?
> @dcslin @XJDKC

For some models, it cannot use the random inputs, such as BERT within ONNX, some nodes may compute the indices of a tensor, and the next node may split the tensor by using these indices. If we randomly generate the inputs, this case always fails.

By the way, I prefer the idea of:

```py
# another option is to define a compile method
    def compile(self, inputs, is_train, use_graph, graph_alg):
        self.forward(*inputs)
```

However, I'd like to add a method to compute the shape based on the inputs of each node instead of calling the forward function:
```py
def compute_output_shape(self, input_shape):
    # print(input_shape) # [(None, 10), (None, 12)]
    return (None, input_shape[0][1] + input_shape[1][1] + 2)
```

Let me think about it, I'll comment the detailed API later.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODAzMzc5MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/696,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODM1NTUxNg==,singa,628355516,696,NA,dcslin,13751447,Shicong,,NA,2020-05-14T02:54:43Z,2020-05-14T02:54:43Z,"Considering the API requirement, and constraints as below:

API requirement:
1. [**Model**] multi-input/output (multi loss fn)
2. [**Model**] Load model from disk, in other words: Model param memory allocation should be done in `model.__init__`

API constraints:
1. [**Model**] graph module buffer first forward call **or** turn off graph module in the first forward call
2. [**Layer**] layer param memory allocation & initialization requires input x

@XJDKC 's scheme 2 and @nudles 's `Placeholder` is close to current implemenation, and changes required could be small.

For model building:
```python
class MyModel(Model):
  def __init__(self, inputs, configs):
    self.mylayer=MyLayer(configs)
    self.linear1=Linear(configs, kernel_init=configs.ker_init)
    super.__init__(inputs) # maybe a bit confuse for user what is this
  def forward(self, inputs):
    return linear1(mylayer(inputs[0], inputs[1]))
```

For model running:
```python
x=PlaceHolder(shape=(batch, shape1, shape2))
m=MyModel([x],**configs,**graph_configs)
m.on_device(gpu)
m.train()
for e in epochs:
  for x, y in data_gen:
    losses = m.loss(y, m(x))
    m.optim(l1)
    m.optim(l2)
```

For Layer building:
```python
class MyLayer(Layer):
  def __init__(self, configs):
    self.configs = configs
  def __call__(self, inputs):
    if not self.init:
      self.W = Tensor(self.configs, inputs.shape).initializer()
      self.device_check(inputs, self.W)
      self.init=True
    return = operator1(inputs[0], inputs[1])
```

For Module class impl:
```python
class Module:
  def __init__(self, placeholder_input, configs):
    turn_off_graph()
    self.forward(*placeholder_input)
    turn_on_graph()
  def __call__(self,inputs):
    return self.forward(*inputs)
```
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODM1NTUxNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/696,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODM2NDgzOA==,singa,628364838,696,NA,nudles,3797447,Wei Wang,,NA,2020-05-14T03:28:59Z,2020-05-14T03:28:59Z,"> 
> 
> > 1. Before we call Module.forward(), we can randomly fill the placeholder tensors.
> > 2. We can make Layer.init() optional. To implement a new layer, the parameter initialization can be done within the `__call__` method or in a `init()` method. It is up to the contributor.
> > 
> > Any comments on the drawbacks?
> > @dcslin @XJDKC
> 
>     1. If we separate the initialization and the forward propagation, there is no need to fill the placeholder. The data of tensors will only be accessed in the forward propagation. For initialization, we just access their shapes, types and so on.
Then we need a method like `infer_output_shapes(self, input_shapes)`; otherwise, we have to call the forward method to get the output shapes from the output tensor. I prefer to call the forward function to avoid adding a new method to each layer.  
> 
>     2. That's great. But if users move the initialization into __call__ function, they should determine whether the layer has been initialized by themselves.

","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODM2NDgzOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/696,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODM2NTM0Mg==,singa,628365342,696,NA,nudles,3797447,Wei Wang,,NA,2020-05-14T03:30:57Z,2020-05-14T03:30:57Z,"> 
> 
> > 1. Before we call Module.forward(), we can randomly fill the placeholder tensors.
> > 2. We can make Layer.init() optional. To implement a new layer, the parameter initialization can be done within the `__call__` method or in a `init()` method. It is up to the contributor.
> > 
> > Any comments on the drawbacks?
> > @dcslin @XJDKC
> 
> For some models, it cannot use the random inputs, such as BERT within ONNX, some nodes may compute the indices of a tensor, and the next node may split the tensor by using these indices. If we randomly generate the inputs, this case always fails.

Good point. Then we can config the data type when creating the placeholder and initialize the placeholder according to this data type. But how to initialize? randomly or set to 0? there could still be some issues. So the better way is to use real data instead of placeholders..
> 
> By the way, I prefer the idea of:
> 
> ```python
> # another option is to define a compile method
>     def compile(self, inputs, is_train, use_graph, graph_alg):
>         self.forward(*inputs)
> ```
> 
> However, I'd like to add a method to compute the shape based on the inputs of each node instead of calling the forward function:
> 
> ```python
> def compute_output_shape(self, input_shape):
>     # print(input_shape) # [(None, 10), (None, 12)]
>     return (None, input_shape[0][1] + input_shape[1][1] + 2)
> ```
> 

Do you need this one for onnx loading?

> Let me think about it, I'll comment the detailed API later.

","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODM2NTM0Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/696,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODQ4MzE1OQ==,singa,628483159,696,NA,nudles,3797447,Wei Wang,,NA,2020-05-14T08:34:50Z,2020-05-14T08:34:50Z,"Shall we go with the following APIs?
@joddiy @dcslin @XJDKC  
They should be compatible with the current APIs.

```python
class Module:
    def compile(self, inputs, is_train, use_graph, graph_alg):
        set train, graph etc config
        turn off graph
        if inputs are not filled, print warnings and fill inputs according to data type.
        self.forward(*inputs)
    
     def load(self, ckp_path, include_state=False):
       load onnx model and copy the params to each layer; 
       generate warnings for mismatched layers/params.
       restore the states and return it as a dict
     
     def save(self, ckp_path, state={}):
       save the model as onnx format
       save the states
    
     def forward(self, x):    # turn on graph if necessary
        pass

     def train_one_batch(self, x, y):  # turn on graph if necessary
        pass   
   
     @deprecated 
     def loss(self, ):
        pass

      @deprecated 
      def optim(self,):
          pass      


class Layer:
    def __init__(name=None):
      self.init = False
      
    def __call__(self, x):
       if self.init == False:
           init layer states
       else:
          # do the forward propagation 


class MyLayer(Layer):
     def __init__(self):
          self.layer1 = layer.Conv2d(nb_kernels = 32, kernel=3, stride=1, padding=0, kernel_init='he_uniform') 
          self.layer2 = layer.MaxPool2d(kernel=3, stride=2)

      def forward(self, x):
          return self.layer2(self.layer1(x))



class MyModule(Module):
     def __init__(self):
           self.blk1 = MyLayer()
           self.blk2 = MyLayer()
           self.optim = SGD()
           self.loss = CrossEntropyLoss()

      def forward(self, x):
           return self.blk2(self.blk1(x))    

      def train_one_batch(self, x, y): 
           y_ = self.forward(x)
           l = self.loss(y_, y)
           self.optim.backward_and_update(l)
           return l

x = Placeholder((2, 3), device = gpu, dtype=singa.float) # alias of Tensor
fill x with values
m = MyModel()

# compatible with existing code which does not have the following two statements.
m.compile([x], is_train=True, use_graph=True, graph_alg='sequence')
for pname, ptensor in m.get_params():
    ptensor.uniform(-1, 1)   # not necessary if each layer's param init methods are configured.

y = Placeholder((2,), device = gpu)
for npx, npy in data:
   x.copy_from(npx)
   y.copy_from(npy)
   m.train_one_batch(x, y)  # build the graph in the first iter.  For the old code, the params are initialized here.

m.save('mymodel', state={'epoch': data.size(), 'sgd': m.optim}
```
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODQ4MzE1OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/696,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODUyODc5OQ==,singa,628528799,696,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-05-14T09:56:31Z,2020-05-14T09:56:31Z,"So we replace the loss and optim with train_one_batch?
Should we make Module a subclass of Layer?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODUyODc5OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/696,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODU0NzkxMg==,singa,628547912,696,NA,dcslin,13751447,Shicong,,NA,2020-05-14T10:36:51Z,2020-05-14T10:36:51Z,"To me this api is more clear. For example, the `model.compile([x])` make more sense as it require `x` as arg, compared to `model([x])` (first call for init purpose).
Also introducing `train_one_batch()` gives flexibility on loss function and optim function. 
While `train_one_batch()` is only an interface, and let user to define, and there is no decorator for this method. It sounds like there is no enforcement for user to use this method. Maybe we can make it clear in documentation that this is singa-way to build the model to enforece this `train_one_batch()` method.
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODU0NzkxMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/696,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODU0ODczNw==,singa,628548737,696,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-05-14T10:38:39Z,2020-05-14T10:38:39Z,"> Shall we go with the following APIs?
> @joddiy @dcslin @XJDKC
> They should be compatible with the current APIs.
> 
> ```python
> class Module:
>     def compile(self, inputs, is_train, use_graph, graph_alg):
>         set train, graph etc config
>         turn off graph
>         if inputs are not filled, print warnings and fill inputs according to data type.
>         self.forward(*inputs)
>     
>      def load(self, ckp_path, include_state=False):
>        load onnx model and copy the params to each layer; 
>        generate warnings for mismatched layers/params.
>        restore the states and return it as a dict
>      
>      def save(self, ckp_path, state={}):
>        save the model as onnx format
>        save the states
>     
>      def forward(self, x):    # turn on graph if necessary
>         pass
> 
>      def train_one_batch(self, x, y):  # turn on graph if necessary
>         pass   
>    
>      @deprecated 
>      def loss(self, ):
>         pass
> 
>       @deprecated 
>       def optim(self,):
>           pass      
> 
> 
> class Layer:
>     def __init__(name=None):
>       self.init = False
>       
>     def __call__(self, x):
>        if self.init == False:
>            init layer states
>        else:
>           # do the forward propagation 
> 
> 
> class MyLayer(Layer):
>      def __init__(self):
>           self.layer1 = layer.Conv2d(nb_kernels = 32, kernel=3, stride=1, padding=0, kernel_init='he_uniform') 
>           self.layer2 = layer.MaxPool2d(kernel=3, stride=2)
> 
>       def forward(self, x):
>           return self.layer2(self.layer1(x))
> 
> 
> 
> class MyModule(Module):
>      def __init__(self):
>            self.blk1 = MyLayer()
>            self.blk2 = MyLayer()
>            self.optim = SGD()
>            self.loss = CrossEntropyLoss()
> 
>       def forward(self, x):
>            return self.blk2(self.blk1(x))    
> 
>       def train_one_batch(self, x, y): 
>            y_ = self.forward(x)
>            l = self.loss(y_, y)
>            self.optim.backward_and_update(l)
>            return l
> 
> x = Placeholder((2, 3), device = gpu, dtype=singa.float) # alias of Tensor
> fill x with values
> m = MyModel()
> 
> # compatible with existing code which does not have the following two statements.
> m.compile([x], is_train=True, use_graph=True, graph_alg='sequence')
> for pname, ptensor in m.get_params():
>     ptensor.uniform(-1, 1)   # not necessary if each layer's param init methods are configured.
> 
> y = Placeholder((2,), device = gpu)
> for npx, npy in data:
>    x.copy_from(npx)
>    y.copy_from(npy)
>    m.train_one_batch(x, y)  # build the graph in the first iter.  For the old code, the params are initialized here.
> 
> m.save('mymodel', state={'epoch': data.size(), 'sgd': m.optim}
> ```

This approach still postpones the operation init till the training phase right? When the user has a batch of samples, he calls `train_one_batch`, to call `forward`, and then to call `_call_`:
```py
def __call__(self, x):
    if self.init == False:
        init layer states
```
it's still strange to init the graph until the user has the data.

In my opinion, the current problem is, 
1. we don't have the shape of the input -> so we using a Placeholder as the input
2. even we have the shape of input data, we cannot compute the all shapes of intermediate tensors since we cannot call the forward with Placeholder -> we may want to init random data but it may incur error.

So, the key point is, we bind the graph construction with `forward` function. Only when we call forward, we construct the graph. But if we want to call forward we must have the real data.

Then I'm thinking about separating the graph construction with `forward` function. We define several classes called `Graph`, `Node`, the `Graph` stores relationship between `Node`s, and `Node`s stores an `Operation` as well as its input and output.  

In the `_call_` function of an `Operation`, we don't call the `forward` function, instead, create a `Node`, and stores this operation itself within this `Node`, set its input and output, then return this newly created `Node`. So finally, in the following code:
```py
class Operation(object):
    def __init__(self):
        pass

    def __call__(self, previous_node): # for multiply input is similiar
        # create an Node
        # link the current with previous node
        # do the infer_shape, set the shape of each input and output for the current node and previous node
        current_node = new Node()
        current_node.input.node = previous_node
        current_node.operation = self
        current_node.output.shape = infer_shape()
        previous_node.output.node = current_node
        return current_node

    def forward():
        pass

    def backward():
        pass

    def infer_shape():
        pass
```


We actually constructed a `Graph` linked with `Node` by using the following code:
```py
class MyModule(Module):
    def __init__(self):
        super(Model, self).__init__()

        self.conv1 = autograd.Conv2d(1, 20, 5, padding=0)
        self.conv2 = autograd.Conv2d(20, 50, 5, padding=0)

        self.sgd = opt.SGD(lr=0.01)

    def construt_graph(self, x):
        # x is a placeholder
       # create the Graph linked with Node
        y = self.conv1(x)
        y = self.conv2(y)
        self.graph = Graph(x, y)

    def train(self, x, y): 
        y_ = self.graph.forward(x)
        l = self.loss(y_, y)
        self.optim.backward_and_update(l)
        return l

    def loss(self, out, y):
        return autograd.softmax_cross_entropy(out, y)

    def optim(self, loss):
        self.sgd.backward_and_update(loss)

model = MyModule()
x = Placeholder((2, 3), device = gpu, dtype=singa.float) # alias of Tensor
model.construt_graph(x) # build the graph

y = Placeholder((2,), device = gpu)
for npx, npy in data:
   x.copy_from(npx)
   y.copy_from(npy)
   m.train(x, y)  # directly train

m.save('mymodel', state={'epoch': data.size(), 'sgd': m.optim}
```","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODU0ODczNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/696,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODU1MTU3NA==,singa,628551574,696,NA,dcslin,13751447,Shicong,,NA,2020-05-14T10:44:55Z,2020-05-14T10:44:55Z,"I see the @joddiy proposal is different only on a naming of a method, `compile` to `construt_graph` in terms of API perspective. Maybe can upgrade the backend to graph construction later without breaking new API?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODU1MTU3NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/696,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODU1NDM5OA==,singa,628554398,696,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-05-14T10:51:07Z,2020-05-14T10:51:07Z,"I think we don't need to fill placeholders. If we turn off the buffer, the operations and intermediate tensors in the forward functions can be generated without executing them. So we can get the output tensors in this way.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODU1NDM5OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/696,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODU1NDQwMA==,singa,628554400,696,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-05-14T10:51:07Z,2020-05-14T10:51:07Z,"> I see the @joddiy proposal is different only on a naming of a method, `compile` to `construt_graph` in terms of API perspective. Maybe can upgrade the backend to graph construction later without breaking new API?

Hi, @dcslin , the key point is the `_call_` function of Operation(or Layer, since we want to merge these two), this `_call` doesn't call the forward function instead it creates a new object we called `Node`, so within the `construt_graph`, or we say, `compile`, we build the graph with a placeholder, which means we don't need to postpone the graph construction til we call forward function after we have the real data.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODU1NDQwMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/696,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODU2MDc1NQ==,singa,628560755,696,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-05-14T11:04:57Z,2020-05-14T11:04:57Z,"```Python
class Module:
    def compile(self, inputs, is_train, use_graph, graph_alg):
        set train, graph etc config
        ===turn on graph===
        if inputs are not filled, print warnings and fill inputs according to data type.
        self.forward(*inputs)
        ===turn off graph===
    
     def load(self, ckp_path, include_state=False):
       load onnx model and copy the params to each layer; 
       generate warnings for mismatched layers/params.
       restore the states and return it as a dict
     
     def save(self, ckp_path, state={}):
       save the model as onnx format
       save the states
    
     def forward(self, x):    # turn on graph if necessary
        pass

     def train_one_batch(self, x, y):  # turn on graph if necessary
        pass   
   
     @deprecated 
     def loss(self, ):
        pass

      @deprecated 
      def optim(self,):
          pass      


class Layer:
    def __init__(name=None):
      self.init = False

    def do_init(x):
        ===turn off graph===
           init layer states
           As the graph is turned off, the initialization operations will be executed
        ===restore the state of the graph===
      
    def forward():
        # do the forward propagation 

    def __call__(self, x):
       if self.init == False:
          self.do_init(x)
       self.forward(x)

class MyLayer(Layer):
     def __init__(self):
          self.layer1 = layer.Conv2d(nb_kernels = 32, kernel=3, stride=1, padding=0, kernel_init='he_uniform') 
          self.layer2 = layer.MaxPool2d(kernel=3, stride=2)

      def forward(self, x):
          return self.layer2(self.layer1(x))



class MyModule(Module):
     def __init__(self):
           self.blk1 = MyLayer()
           self.blk2 = MyLayer()
           self.optim = SGD()
           self.loss = CrossEntropyLoss()

      def forward(self, x):
           return self.blk2(self.blk1(x))    

      def train_one_batch(self, x, y): 
           y_ = self.forward(x)
           l = self.loss(y_, y)
           self.optim.backward_and_update(l)
           return l

x = Placeholder((2, 3), device = gpu, dtype=singa.float) # alias of Tensor
#  === no need to fill x with values===
m = MyModel()

# compatible with existing code which does not have the following two statements.
m.compile([x], is_train=True, use_graph=True, graph_alg='sequence')
for pname, ptensor in m.get_params():
    ptensor.uniform(-1, 1)   # not necessary if each layer's param init methods are configured.

y = Placeholder((2,), device = gpu)
for npx, npy in data:
   x.copy_from(npx)
   y.copy_from(npy)
   m.train_one_batch(x, y)  # build the graph in the first iter.  For the old code, the params are initialized here.

m.save('mymodel', state={'epoch': data.size(), 'sgd': m.optim}
```

How about this proposal?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODU2MDc1NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/696,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODU3MzkyMQ==,singa,628573921,696,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-05-14T11:33:26Z,2020-05-14T11:33:26Z,"> ```python
> class Module:
>     def compile(self, inputs, is_train, use_graph, graph_alg):
>         set train, graph etc config
>         ===turn on graph===
>         if inputs are not filled, print warnings and fill inputs according to data type.
>         self.forward(*inputs)
>         ===turn off graph===
>     
>      def load(self, ckp_path, include_state=False):
>        load onnx model and copy the params to each layer; 
>        generate warnings for mismatched layers/params.
>        restore the states and return it as a dict
>      
>      def save(self, ckp_path, state={}):
>        save the model as onnx format
>        save the states
>     
>      def forward(self, x):    # turn on graph if necessary
>         pass
> 
>      def train_one_batch(self, x, y):  # turn on graph if necessary
>         pass   
>    
>      @deprecated 
>      def loss(self, ):
>         pass
> 
>       @deprecated 
>       def optim(self,):
>           pass      
> 
> 
> class Layer:
>     def __init__(name=None):
>       self.init = False
> 
>     def do_init(x):
>         ===turn off graph===
>            init layer states
>            As the graph is turned off, the initialization operations will be executed
>         ===restore the state of the graph===
>       
>     def forward():
>         # do the forward propagation 
> 
>     def __call__(self, x):
>        if self.init == False:
>           self.do_init(x)
>        self.forward(x)
> 
> class MyLayer(Layer):
>      def __init__(self):
>           self.layer1 = layer.Conv2d(nb_kernels = 32, kernel=3, stride=1, padding=0, kernel_init='he_uniform') 
>           self.layer2 = layer.MaxPool2d(kernel=3, stride=2)
> 
>       def forward(self, x):
>           return self.layer2(self.layer1(x))
> 
> 
> 
> class MyModule(Module):
>      def __init__(self):
>            self.blk1 = MyLayer()
>            self.blk2 = MyLayer()
>            self.optim = SGD()
>            self.loss = CrossEntropyLoss()
> 
>       def forward(self, x):
>            return self.blk2(self.blk1(x))    
> 
>       def train_one_batch(self, x, y): 
>            y_ = self.forward(x)
>            l = self.loss(y_, y)
>            self.optim.backward_and_update(l)
>            return l
> 
> x = Placeholder((2, 3), device = gpu, dtype=singa.float) # alias of Tensor
> #  === no need to fill x with values===
> m = MyModel()
> 
> # compatible with existing code which does not have the following two statements.
> m.compile([x], is_train=True, use_graph=True, graph_alg='sequence')
> for pname, ptensor in m.get_params():
>     ptensor.uniform(-1, 1)   # not necessary if each layer's param init methods are configured.
> 
> y = Placeholder((2,), device = gpu)
> for npx, npy in data:
>    x.copy_from(npx)
>    y.copy_from(npy)
>    m.train_one_batch(x, y)  # build the graph in the first iter.  For the old code, the params are initialized here.
> 
> m.save('mymodel', state={'epoch': data.size(), 'sgd': m.optim}
> ```
> 
> How about this proposal?

Thanks for your comments. I guess it's a good idea we add a compile function before the training. Based on Ruling's code, if we don't want to run the computation during the init phase, we can add a function to compute the shape:

```py
class Module:
    def compile(self, inputs, is_train, use_graph, graph_alg):
        set train, graph etc config
        turn off graph
        if inputs are not filled, print warnings and fill inputs according to data type.
        self.forward(*inputs)
    
     def load(self, ckp_path, include_state=False):
       load onnx model and copy the params to each layer; 
       generate warnings for mismatched layers/params.
       restore the states and return it as a dict
     
     def save(self, ckp_path, state={}):
       save the model as onnx format
       save the states
    
     def forward(self, x):    # turn on graph if necessary
        pass

     def train_one_batch(self, x, y):  # turn on graph if necessary
        pass   
   
     @deprecated 
     def loss(self, ):
        pass

      @deprecated 
      def optim(self,):
          pass      


class Layer:
    def __init__(name=None):
      self.init = False

    def do_init(x):
        #  compute the output shape
        output_shape = self.infer_shape(x)
        # init weights by the shape
        init_weights()
        # return a new Placeholder to the next operation
        return Placeholder(output_shape, device = gpu, dtype=singa.float) # alias of Tensor
      
    def forward():
        # do the forward propagation 

    def __call__(self, x):
       if self.init == False:
          y = self.do_init(x)
       y = self.forward(x)
       return y
    
    def infer_shape(x):
        # infer shape


class MyLayer(Layer):
     def __init__(self):
          self.layer1 = layer.Conv2d(nb_kernels = 32, kernel=3, stride=1, padding=0, kernel_init='he_uniform') 
          self.layer2 = layer.MaxPool2d(kernel=3, stride=2)

      def forward(self, x):
          return self.layer2(self.layer1(x))



class MyModule(Module):
     def __init__(self):
           self.blk1 = MyLayer()
           self.blk2 = MyLayer()
           self.optim = SGD()
           self.loss = CrossEntropyLoss()

      def forward(self, x):
           return self.blk2(self.blk1(x))    

      def train_one_batch(self, x, y): 
           y_ = self.forward(x)
           l = self.loss(y_, y)
           self.optim.backward_and_update(l)
           return l

x = Placeholder((2, 3), device = gpu, dtype=singa.float) # alias of Tensor
#  === no need to fill x with values===
m = MyModel()

# compatible with existing code which does not have the following two statements.
m.compile([x], is_train=True, use_graph=True, graph_alg='sequence')
for pname, ptensor in m.get_params():
    ptensor.uniform(-1, 1)   # not necessary if each layer's param init methods are configured.

y = Placeholder((2,), device = gpu)
for npx, npy in data:
   x.copy_from(npx)
   y.copy_from(npy)
   m.train_one_batch(x, y)  # build the graph in the first iter.  For the old code, the params are initialized here.

m.save('mymodel', state={'epoch': data.size(), 'sgd': m.optim}
```","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyODU3MzkyMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/696,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTc2MzA0MA==,singa,629763040,696,NA,nudles,3797447,Wei Wang,,NA,2020-05-17T08:40:36Z,2020-05-17T08:40:36Z,"Here is the latest API proposal
https://gist.github.com/nudles/d7f8043f251872333ec06f2701696cce","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTc2MzA0MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/696,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0NTczNjM1NQ==,singa,645736355,696,NA,nudles,3797447,Wei Wang,,NA,2020-06-18T02:45:22Z,2020-06-18T02:45:22Z,resolved in #697 ,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0NTczNjM1NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/698,https://api.github.com/repos/apache/singa/issues/698,singa,619419189,698,Implement popular initialization methods,nudles,3797447,Wei Wang,,CLOSED,2020-05-16T08:55:53Z,2020-07-01T01:36:02Z,"Add each initialization method as a function or class in https://github.com/apache/singa/blob/master/python/singa/initializer.py. e.g.,
```python
class InitializationBase(object):
      def __init__(self, ):
          pass
      def call(self, x):
          pass
      def __call__(self, x):
          self.call(x)

class Uniform(InitializationBase):
       def __init__(self, low=-1, high=1):
               self.low = low
               self.high = high
      def call(self, x):
              x.uniform(self.low, self.high)

def uniform(x, low=-1, high=1):
       x.uniform(low, high)
```","{""url"": ""https://api.github.com/repos/apache/singa/issues/698/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/698,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY1MjEzNTQyNA==,singa,652135424,698,NA,nudles,3797447,Wei Wang,,NA,2020-07-01T01:36:02Z,2020-07-01T01:36:02Z,resolved in PR#739,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY1MjEzNTQyNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/699,https://api.github.com/repos/apache/singa/issues/699,singa,619646171,699,Add new operators and layers,nudles,3797447,Wei Wang,,OPEN,2020-05-17T08:45:00Z,2020-05-17T08:45:00Z,"SINGA has many common operators and layers.
There are also many operators to be implemented.
Here is a list of popular operators define by ONNX https://github.com/onnx/onnx/blob/master/docs/Operators.md
Here is the list of operators implemented in SINGA http://singa.apache.org/docs/onnx/#supported-operators
The task is to add the operators in ONNX but not in SINGA.
Refer to this link for how to add new operators and corresponding layers into SINGA.","{""url"": ""https://api.github.com/repos/apache/singa/issues/699/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/700,singa,619646933,700,Expand the model zoo (example model set),nudles,3797447,Wei Wang,,OPEN,2020-05-17T08:49:33Z,2020-07-06T13:06:27Z,"SINGA has multiple example models at http://singa.apache.org/docs/examples/
Some are implemented from scratch and some are converted from ONNX, which has a bigger model zoo  https://github.com/onnx/models.
The task is to convert more onnx models and implement some popular (and interesting) models that are not in onnx model zoo.
Here are some reference model zoos https://modelzoo.co/, https://gluon-nlp.mxnet.io/model_zoo/index.html","{""url"": ""https://api.github.com/repos/apache/singa/issues/700/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTgwNzMyMw==,singa,629807323,700,NA,nudles,3797447,Wei Wang,,NA,2020-05-17T14:29:32Z,2020-05-17T14:29:32Z,"Examples (To be updated):
MobileNetV2
ShuffleNetV2
YOLO
Mask RCNN
Faster RCNN
InceptionNetV3","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTgwNzMyMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMDkwMjk0Mw==,singa,630902943,700,NA,Shashankwer,15552734,Shashank Nigam,shashanknigam40@gmail.com,NA,2020-05-19T15:36:33Z,2020-05-19T15:36:33Z,"Will Start working with MobileNetV2, InceptionNetV3","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMDkwMjk0Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMTg1MjMxMg==,singa,631852312,700,NA,Alvinnyk,32993514,Alvin Ng,,NA,2020-05-21T03:09:10Z,2020-05-21T03:09:10Z,I will work on Mask RCNN,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMTg1MjMxMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMTkxMzY0Mg==,singa,631913642,700,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-05-21T06:39:38Z,2020-05-21T06:39:38Z,"Hi, guys, @Shashankwer , @Alvinnyk , thanks for your help. 

Before you start, please check this Jira, https://issues.apache.org/jira/projects/SINGA/issues/SINGA-509?filter=allopenissues

It lists the models which require support and for some of the models, SINGA may lack the necessary operators now. 

So I hope you:

1. check the Jira carefully, to see which model we can do now(I guess is: super_resolution, ResNet101_DUC_HDC, ShuffleNet_V2, ShuffleNet_V1, inception_v2, squeezenet).
2. find these models in ONNX model zoo, download them and open them by a tool called [`Netron`](https://github.com/lutzroeder/netron), try to understand the model and check each part refer the [IR doc](https://github.com/onnx/onnx/blob/master/docs/IR.md) of ONNX.
3. try to read the code of `SingaRep` and `SingaBackend` in `python/singa/soonx.py` to understand how we parse and construct the SINGA model.
4. try to read the code `examples/onnx`, to make out how we load and do the inference for a ONNX model.
5. then you can try to support a model(in first point) by yourself.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMTkxMzY0Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMjc2MjIxNg==,singa,632762216,700,NA,agnesnatasya,44172431,Agnes Natasya,agnesnatasya@u.nus.edu,NA,2020-05-22T15:45:39Z,2020-05-22T15:45:39Z,I will try to work on the ShuffleNet,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMjc2MjIxNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMzI1ODU2Mw==,singa,633258563,700,NA,agnesnatasya,44172431,Agnes Natasya,agnesnatasya@u.nus.edu,NA,2020-05-24T16:46:42Z,2020-05-24T16:46:42Z,"Hi, may I ask how do we get the Amazon AWS link to download the model itself? For example, for ResNet, the link is https://s3.amazonaws.com/onnx-model-zoo/resnet/resnet18v1/resnet18v1.tar.gz. How do we get the link for the others? Because if I copy the link from ONNX's github, the link to download is Github's link, not Amazon AWS link. Thank you!","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMzI1ODU2Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMzY0MTY5MA==,singa,633641690,700,NA,Shashankwer,15552734,Shashank Nigam,shashanknigam40@gmail.com,NA,2020-05-25T16:22:21Z,2020-05-25T16:22:21Z,"For the models conversion do we also nee to train model on SINGA after conversion from onnx, and have a comparison matrix?

For example super_resolution via subpixel convolution layer was trained on BSD 300. Model is originally present in pytorch and can be converted well into SINGA using ONNX. It gives similar result for an image across pytorch, onnxruntime and SINGA. Do we need to compare the performance of the model across these platforms with the dataset they were trained on or SINGA compatibility is what we are checking at the moment?

Thanks and Regards,
Shashank Nigam","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMzY0MTY5MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMzc3NTczNg==,singa,633775736,700,NA,nudles,3797447,Wei Wang,,NA,2020-05-26T02:29:19Z,2020-05-26T02:29:19Z,"There is no need to retrain the model.
But we need to evaluate the model over a test dataset to make sure the conversion is correct.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMzc3NTczNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMzc3NjE1MA==,singa,633776150,700,NA,nudles,3797447,Wei Wang,,NA,2020-05-26T02:31:09Z,2020-05-26T02:31:09Z,"> 
> 
> Hi, may I ask how do we get the Amazon AWS link to download the model itself? For example, for ResNet, the link is https://s3.amazonaws.com/onnx-model-zoo/resnet/resnet18v1/resnet18v1.tar.gz. How do we get the link for the others? Because if I copy the link from ONNX's github, the link to download is Github's link, not Amazon AWS link. Thank you!

https://github.com/onnx/models
I think you need to go to the github page for each model and then find the link for the model checkpoint file, which may not all be on aws.
@joddiy  any comments?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMzc3NjE1MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMzc4NjU2MA==,singa,633786560,700,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-05-26T03:19:01Z,2020-05-26T03:19:01Z,"> Hi, may I ask how do we get the Amazon AWS link to download the model itself? For example, for ResNet, the link is https://s3.amazonaws.com/onnx-model-zoo/resnet/resnet18v1/resnet18v1.tar.gz. How do we get the link for the others? Because if I copy the link from ONNX's github, the link to download is Github's link, not Amazon AWS link. Thank you!

Hi, @agnesnatasya , it's not necessary to use the AWS download link. As you said, for the image classification models, I found the download link from the backend test cases [here](https://github.com/onnx/onnx/tree/master/onnx/backend/test/data/real). But if for other models, you can use the download link within GitHub repo directly.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMzc4NjU2MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMzc5MTUyMA==,singa,633791520,700,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-05-26T03:41:19Z,2020-05-26T03:41:19Z,"> For the models conversion do we also nee to train model on SINGA after conversion from onnx, and have a comparison matrix?
> 
> For example super_resolution via subpixel convolution layer was trained on BSD 300. Model is originally present in pytorch and can be converted well into SINGA using ONNX. It gives similar result for an image across pytorch, onnxruntime and SINGA. Do we need to compare the performance of the model across these platforms with the dataset they were trained on or SINGA compatibility is what we are checking at the moment?
> 
> Thanks and Regards,
> Shashank Nigam

For this version of SINGA, we don't need to consider the matter of training(or retaining), we just need to test if we can run the model without errors, and the result is correct. In the next version(what we are doing now), the ONNX of SINGA will support retraining.

So for now, we just need to do three things:

1. load the model correctly without errors.
2. verify the model by using the test dataset within the model download package. If you `Download (with sample test data)`, you can see a directory called `test_data_set_0`, and you can verify the result of the model by using these test data.
3. for demo, we need to do the inference by using a human-readable data(or image), so you need to find a public image and then use the model to do the inference, finally show the result.

","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMzc5MTUyMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMzk3OTAwNA==,singa,633979004,700,NA,agnesnatasya,44172431,Agnes Natasya,agnesnatasya@u.nus.edu,NA,2020-05-26T11:56:02Z,2020-05-26T11:56:02Z,"@joddiy Thank you for the reply, I could find the link to download, and I have completed SqueezeNet. May I ask how do I test if my conversion is already correct? Thank you!","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMzk3OTAwNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNDQwNDYyNg==,singa,634404626,700,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-05-27T03:23:22Z,2020-05-27T03:23:22Z,"> @joddiy Thank you for the reply, I could find the link to download, and I have completed SqueezeNet. May I ask how do I test if my conversion is already correct? Thank you!

you can use this code to verify the model by using its test data set:
```
    # verifty the test dataset
    from utils import load_dataset
    inputs, ref_outputs = load_dataset(
        os.path.join('/tmp', 'resnet100', 'test_data_set_0'))
    x_batch = tensor.Tensor(device=dev, data=inputs[0])
    outputs = model.forward(x_batch)
    for ref_o, o in zip(ref_outputs, outputs):
        np.testing.assert_almost_equal(ref_o, tensor.to_numpy(o), 4)
```","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNDQwNDYyNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNTMzNDI3MA==,singa,635334270,700,NA,Shashankwer,15552734,Shashank Nigam,shashanknigam40@gmail.com,NA,2020-05-28T12:59:17Z,2020-05-28T12:59:17Z,"Hi, 

Can anyone verify if for SuperResolutionNet, attached notebook would be sufficient? 

Thanks and Regards,
Shashank Nigam
[SuperResolution.zip](https://github.com/apache/singa/files/4695603/SuperResolution.zip)

","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNTMzNDI3MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNjM1MzA3OQ==,singa,636353079,700,NA,Shashankwer,15552734,Shashank Nigam,shashanknigam40@gmail.com,NA,2020-05-30T16:20:24Z,2020-05-30T16:20:24Z,"Hi, 

Shufflenetv2 for average pooling layer the conversion from onnx fails on below error: 
ValueError: Not implemented yet for count_include_pad or ceil_mode 

with below stack trace

ValueError                                Traceback (most recent call last)
<ipython-input-22-f6c52060eea0> in <module>()
----> 1 sg_ir = sonnx.prepare(onnx_model, device=dev)

3 frames
/usr/local/lib/python3.7/site-packages/singa/sonnx.py in prepare(cls, model, device, **kwargs)
   2033                 opset_version = 1
   2034         weights, singa_ops = cls._onnx_model_to_singa_net(
-> 2035             model, init_inputs, device, opset_version)
   2036         return SingaRep(model, weights, singa_ops,
   2037                         cls.keep_initializers_as_inputs)

/usr/local/lib/python3.7/site-packages/singa/sonnx.py in _onnx_model_to_singa_net(cls, model, init_inputs, device, opset_version)
   1971             ]
   1972             handle, forward = cls._onnx_node_to_singa_op(
-> 1973                 node, inputs, opset_version)
   1974             # if it is Constant, we hanlde it as a weight
   1975             # otherwise, we run it and add its output into map for being used by later operators

/usr/local/lib/python3.7/site-packages/singa/sonnx.py in _onnx_node_to_singa_op(cls, onnx_node, inputs, opset_version)
   1816         else:
   1817             translator = cls._common_onnx_node_to_singa_op
-> 1818         return translator(onnx_node, inputs, opset_version)
   1819 
   1820     classmethod

/usr/local/lib/python3.7/site-packages/singa/sonnx.py in _create_max_avg_pool(cls, onnx_node, inputs, opset_version)
   1635         if ""count_include_pad"" in onnx_node.attrs or ""ceil_mode"" in onnx_node.attrs:
   1636             raise ValueError(
-> 1637                 ""Not implemented yet for count_include_pad or ceil_mode"")
   1638 
   1639         # only support 2d

ValueError: Not implemented yet for count_include_pad or ceil_mode.

Kindly let us know the further steps to be taken

Thanks and Regards,
Shashank Nigam","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNjM1MzA3OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNjM1NjMyMg==,singa,636356322,700,NA,agnesnatasya,44172431,Agnes Natasya,agnesnatasya@u.nus.edu,NA,2020-05-30T16:48:29Z,2020-05-30T16:48:29Z,"@Shashankwer I got the same error too, there is a ""not implemented error"" too when I try to run ShufflenetV1

I got a floating point exception: 8 when loading GPT2, does anyone know what causes this?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNjM1NjMyMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNjM1NjcxNg==,singa,636356716,700,NA,agnesnatasya,44172431,Agnes Natasya,agnesnatasya@u.nus.edu,NA,2020-05-30T16:52:02Z,2020-05-30T16:52:02Z,"@joddiy Hi, can I ask, for the other models that is not in ONNX, how do we find the reliable reference for it? I look at the papers, and they usually only discuss about the general idea and comparison between models, but not the details on operations to be done on every layer. ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNjM1NjcxNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNjM1ODQ1Mw==,singa,636358453,700,NA,Shashankwer,15552734,Shashank Nigam,shashanknigam40@gmail.com,NA,2020-05-30T17:07:43Z,2020-05-30T17:07:43Z,"> @Shashankwer I got the same error too, there is a ""not implemented error"" too when I try to run ShufflenetV1
> 
> I got a floating point exception: 8 when loading GPT2, does anyone know what causes this?

Hi @agnesnatasya ,

For ShufflenetV1 issue is it requires cuda gpu for implementation. It makes use of grouped 1x1 convolution which does not seem to be supported by cpu module and is written only for cuda. It refers get_default_device as '-1' and gpu devices starting from 0. For me it failed on the check condition 
device.id()==-1 in sonnx.py. 
Running the same on colab did resolve the issue.

Thanks,
Shashank
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNjM1ODQ1Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNjQxMjk3NA==,singa,636412974,700,NA,agnesnatasya,44172431,Agnes Natasya,agnesnatasya@u.nus.edu,NA,2020-05-31T02:55:07Z,2020-05-31T02:55:07Z,"@Shashankwer Oh, I see, thank you for that!","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNjQxMjk3NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzODE4NzIxOQ==,singa,638187219,700,NA,agnesnatasya,44172431,Agnes Natasya,agnesnatasya@u.nus.edu,NA,2020-06-03T13:11:55Z,2020-06-03T13:11:55Z,"@joddiy  Hi, can I ask, for the other models that is not in ONNX, how do we find the reliable reference for it? I look at the papers, and they usually only discuss about the general idea and comparison between models, but not the details on operations to be done on every layer. If I look at https://modelzoo.co/, there are a lot of different implementations. How do we choose the one that we could reference from? Thank you!","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzODE4NzIxOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzODE5MzY1NQ==,singa,638193655,700,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-06-03T13:22:59Z,2020-06-03T13:22:59Z,"> @joddiy Hi, can I ask, for the other models that is not in ONNX, how do we find the reliable reference for it? I look at the papers, and they usually only discuss about the general idea and comparison between models, but not the details on operations to be done on every layer. If I look at https://modelzoo.co/, there are a lot of different implementations. How do we choose the one that we could reference from? Thank you!

Typically, when an author published his paper, he usually had to release his code at the same time. So, I guess if you cannot find the code on the GitHub, you can try to send an email to the author to ask for the code.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzODE5MzY1NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzODE5NjMzNg==,singa,638196336,700,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-06-03T13:27:32Z,2020-06-03T13:27:32Z,"> @Shashankwer I got the same error too, there is a ""not implemented error"" too when I try to run ShufflenetV1
> 
> I got a floating point exception: 8 when loading GPT2, does anyone know what causes this?

@Shashankwer @agnesnatasya , sorry for the late, I saw this reply just now. Yes, as @agnesnatasya has said, some features in ONNX have not been implemented in SINGA. For these errors, please skip this model. I guess we will implement these features soon.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzODE5NjMzNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzODI2NTU0NQ==,singa,638265545,700,NA,Shashankwer,15552734,Shashank Nigam,shashanknigam40@gmail.com,NA,2020-06-03T15:17:49Z,2020-06-03T15:17:49Z,"Hi @joddiy,

For Shufflenetv2 the model conversion is failing due to use of ceil_mode. Although the value is set to false in onnx model (0) its still failing at a condition. 

I have opened a new issue for the same. If we can split the condition checking 

```
if ""count_include_pad"" in onnx_node.attrs or ""ceil_mode"" in onnx_node.attrs
```
to 
```
if ""ceil_mode"" in onnx_node.attrs and onnx_node.attrs[""ceil_mode""]:
  RaiseError
if ""count_include_pad"" in onnx_node.attrs:
  RaiseError
```
Shufflenetv2 can be successfully converted to singa. ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzODI2NTU0NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzODI2OTg1NA==,singa,638269854,700,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-06-03T15:24:40Z,2020-06-03T15:24:40Z,"> Hi @joddiy,
> 
> For Shufflenetv2 the model conversion is failing due to use of ceil_mode. Although the value is set to false in onnx model (0) its still failing at a condition.
> 
> I have opened a new issue for the same. If we can split the condition checking
> 
> ```
> if ""count_include_pad"" in onnx_node.attrs or ""ceil_mode"" in onnx_node.attrs
> ```
> 
> to
> 
> ```
> if ""ceil_mode"" in onnx_node.attrs and onnx_node.attrs[""ceil_mode""]:
>   RaiseError
> if ""count_include_pad"" in onnx_node.attrs:
>   RaiseError
> ```
> 
> Shufflenetv2 can be successfully converted to singa.

Thanks, @Shashankwer , you can open a PR update like this:
```
ceil_mode = onnx_node.getattr(""ceil_mode"", 0)
count_include_pad = onnx_node.getattr(""count_include_pad"", 0)
if ceil_mode != 0 or count_include_pad != 0:
...
```","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzODI2OTg1NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzODI3NTY2MA==,singa,638275660,700,NA,Shashankwer,15552734,Shashank Nigam,shashanknigam40@gmail.com,NA,2020-06-03T15:34:22Z,2020-06-03T15:34:22Z,"> > @joddiy Hi, can I ask, for the other models that is not in ONNX, how do we find the reliable reference for it? I look at the papers, and they usually only discuss about the general idea and comparison between models, but not the details on operations to be done on every layer. If I look at https://modelzoo.co/, there are a lot of different implementations. How do we choose the one that we could reference from? Thank you!
> 
> Typically, when an author published his paper, he usually had to release his code at the same time. So, I guess if you cannot find the code on the GitHub, you can try to send an email to the author to ask for the code.

Hi @joddiy ,

Do we need to prepare the model architecture or train it as well? For training what dataset should we include? (some models are trained on imagenet where dataset can be huge). 

 ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzODI3NTY2MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzODI3NzcxNw==,singa,638277717,700,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-06-03T15:37:47Z,2020-06-03T15:37:47Z,"> > > @joddiy Hi, can I ask, for the other models that is not in ONNX, how do we find the reliable reference for it? I look at the papers, and they usually only discuss about the general idea and comparison between models, but not the details on operations to be done on every layer. If I look at https://modelzoo.co/, there are a lot of different implementations. How do we choose the one that we could reference from? Thank you!
> > 
> > 
> > Typically, when an author published his paper, he usually had to release his code at the same time. So, I guess if you cannot find the code on the GitHub, you can try to send an email to the author to ask for the code.
> 
> Hi @joddiy ,
> 
> Do we need to prepare the model architecture or train it as well? For training what dataset should we include? (some models are trained on imagenet where dataset can be huge).

Sure, all these works have been done in this PR #703 , if you are interested at it, you can check the new SONNX code.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzODI3NzcxNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzOTk5NTA2Nw==,singa,639995067,700,NA,agnesnatasya,44172431,Agnes Natasya,agnesnatasya@u.nus.edu,NA,2020-06-06T06:38:08Z,2020-06-06T06:38:08Z,"Hi @joddiy I tried to implement InceptionV1, but it involves LRN thus it is not yet supported. I tried to implement InceptionV2 but I received this error
```
F0606 13:54:23.837922 336954816 tensor.cc:1177] Check failed: size == t.Size() / t.shape(axis) (196 vs. 169) The size of all axis should  be the same except the concatenated axis
*** Check failure stack trace: ***
Abort trap: 6
```
May I ask if there is any other model (outside ONNX) that I could implement? Thank you!","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzOTk5NTA2Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0MjQxODY5Mw==,singa,642418693,700,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-06-11T05:34:52Z,2020-06-11T05:34:52Z,"Thanks @agnesnatasya , I'll test the InceptionV2 again to check the error.

And thanks you all for your contribution! @Shashankwer @agnesnatasya @Alvinnyk 

For the next plan, I list some necessary operators we have to implement:

## Type 1
<s>Abs 1h</s>
<s>Floor 1h</s>

## Type 2
<s>Exp 1h</s>
<s>Round 6h</s>
<s>Pad 6h</s>
<s>Expand 6h</s>
<s>Upsample 6h</s>

## Type 3
<s>SpaceToDepth 12h</s>
ScatterElements 12h
RoiAlign 12h
NonMaxSuppression 12h
Resize 12h

## Type 4
TopK 	c++
ReduceMin c++
ReduceMax c++

Type 1 means the operators have been implemented in autograd.py, we only need to add it into the sonnx.py.
Type 2 and Type 3 mean the operators don't exist in autograd.py, we need to implement them first. Type 2 is easier but Type 3 is harder.
Type 4 need to modify the c++ code, we'll consider it later.
Xh means the workload hours.

So the plan is:
1. You should read the code of soonx.py under [dev branch](https://github.com/apache/singa/tree/dev). Because we have updated the soonx to support the re-training, so it's a little different from the old version.
2. You try to add an operator at the `Type 1`, you may add a key in the SingaBackend._rename_operators, and if you need a function to modify the operator, add a key in the SingaBackend._special_operators to indicate such a function.
3. Try to add the test cases to test your new operator, the test cases list at [here](https://github.com/onnx/onnx/tree/master/onnx/backend/test/data/node), and you should check the code in test_onnx_backend.py. There are two patterns, the include pattern means the operators which do not in it will be excluded, and the exclude patterns will exclude the pattern in it.
4. When you finish the Type 1, I guess you must have been familiar with the sonnx, so you can try the Type 2 and Type 3. These need you to add operators in `autograd.py`, you can read the code in it and add test cases in `test_operation.py`. In the `autograd.py`, you need to add a class with forward and backward functions. and you need to add a function to call the class's forward function. Don't forget to add test cases in `test_operation.py`. After you add the operator in the autograd, you can add it to the sonnx following the point 2 and 3.

I know it's a little difficult at first. So I hope you don't be urgent to do, just read the code carefully first and if you have any questions, feel free to ask me.

By the way, please add your code to dev branch. And please skip the frontend code in sonnx.py, only read the backend one. I'm working on the frontend to upgrade it.
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0MjQxODY5Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0Mzc2MDk5OQ==,singa,643760999,700,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-06-14T12:36:56Z,2020-06-14T12:36:56Z,"Hi, you can follow my PR as an example.

https://github.com/apache/singa/pull/734

and

https://github.com/apache/singa/pull/736","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0Mzc2MDk5OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0NDMxNTY5OQ==,singa,644315699,700,NA,Shashankwer,15552734,Shashank Nigam,shashanknigam40@gmail.com,NA,2020-06-15T18:53:58Z,2020-06-15T18:53:58Z,"Hi @joddiy,

For The Type I operator floor is not present in autograd.py can we implement the same in autograd.py on taking the implementation of Ceil as the reference. Also Equal is implemented in the existing code. 

Thanks,
Shashank","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0NDMxNTY5OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0NDQ3NTExMg==,singa,644475112,700,NA,nudles,3797447,Wei Wang,,NA,2020-06-16T01:25:20Z,2020-06-16T01:25:20Z,"Yes. I think you can implement it following Ceil implementation.

On Tue, Jun 16, 2020 at 2:54 AM Shashank Nigam <notifications@github.com>
wrote:

> Hi @joddiy <https://github.com/joddiy>,
>
> For The Type I operator floor is not present in autograd.py can we
> implement the same in autograd.py on taking the implementation of Ceil as
> the reference. Also Equal is implemented in the existing code.
>
> Thanks,
> Shashank
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/apache/singa/issues/700#issuecomment-644315699>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AA47DR635GXS7ZM2PJWUTL3RWZU5LANCNFSM4NDJFC2A>
> .
>
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0NDQ3NTExMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0NDU4NTgyOA==,singa,644585828,700,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-06-16T07:27:54Z,2020-06-16T07:27:54Z,"> Hi @joddiy,
> 
> For The Type I operator floor is not present in autograd.py can we implement the same in autograd.py on taking the implementation of Ceil as the reference. Also Equal is implemented in the existing code.
> 
> Thanks,
> Shashank

Yes, @Shashankwer , you can create a new operator in `autograd.py` by using this func `singa.Floor`","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0NDU4NTgyOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0NTM1NzgyMw==,singa,645357823,700,NA,Shashankwer,15552734,Shashank Nigam,shashanknigam40@gmail.com,NA,2020-06-17T12:59:06Z,2020-06-17T12:59:06Z,"Hi,

Exp operator is already implemented in autograd.py

Thanks and Regards,
Shashank Nigam","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0NTM1NzgyMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0NTgzODU1Nw==,singa,645838557,700,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-06-18T07:36:28Z,2020-06-18T07:36:28Z,"> Hi,
> 
> Exp operator is already implemented in autograd.py
> 
> Thanks and Regards,
> Shashank Nigam

Hi, @Shashankwer , the Type 1 means the operators have been implemented in autograd.py, we only need to add it into the sonnx.py.

You can follow my PR to see how to add an operator to sonnx.py. By the way, you should test the `test_onnx_backend.py`.

@Shashankwer @Alvinnyk @agnesnatasya 
There are two points I should explain a little more:

```
onnx_node.set_attr_inputs(onnx_node.inputs[1], 'depth')
onnx_node.set_weight_inputs(onnx_node.inputs[2], 'scale')
```
`set_attr_inputs` means in [ONNX Operator Schemas](https://github.com/onnx/onnx/blob/master/docs/Operators.md), they regard an element as input, but we regard it as an attribute, so we mark the second input `onnx_node.inputs[1]` as attribute `depth` in SINGA.

`set_weight_inputs` means in [ONNX Operator Schemas](https://github.com/onnx/onnx/blob/master/docs/Operators.md), they regard an element as input and they store its value, but we regard it as a weight in `layer.py`. so we mark the third input `onnx_node.inputs[2]` as weight `scale` in SINGA.
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0NTgzODU1Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0ODk5NTg2Nw==,singa,648995867,700,NA,Shashankwer,15552734,Shashank Nigam,shashanknigam40@gmail.com,NA,2020-06-24T18:38:15Z,2020-06-24T18:38:15Z,"Hi, 

Just one question, does apache singa CTensor support advanced indexing as what numpy supports?

Thanks,
Shashank","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0ODk5NTg2Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0OTI4MTMwOA==,singa,649281308,700,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-06-25T07:00:24Z,2020-06-25T07:00:24Z,"> Hi,
> 
> Just one question, does apache singa CTensor support advanced indexing as what numpy supports?
> 
> Thanks,
> Shashank

cannot yet. I guess for this operator, you can use tensor.to_numpy(tensor.from_raw_tensor(CTensor)) to convert it to numpy array to do it for now. We will consider to implement it at c++ end later.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0OTI4MTMwOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY1NDAyOTQ4OA==,singa,654029488,700,NA,Shashankwer,15552734,Shashank Nigam,shashanknigam40@gmail.com,NA,2020-07-06T05:52:57Z,2020-07-06T05:52:57Z,"Hi,

Will work on RoiAlign. Also can GatherElements be implemented similar to ScatterElements? 

Thanks and Regards,
Shashank Nigam 

 ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY1NDAyOTQ4OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY1NDA0MzM3MQ==,singa,654043371,700,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-07-06T06:35:26Z,2020-07-06T06:35:26Z,"> Hi,
> 
> Will work on RoiAlign. Also can GatherElements be implemented similar to ScatterElements?
> 
> Thanks and Regards,
> Shashank Nigam

Thanks @Shashankwer . I just saw your PR of ScatterElements.

I guess you can implement the NonMaxSuppression firstly, it's easier than RoiAlign. There are some operators we cannot support for RoiAlign, for example, the crop. But the NonMaxSuppression is straightforward now. 

You can follow this one:

https://github.com/pytorch/vision/blob/master/torchvision/ops/boxes.py

And for RoiAlign, we have found an implement on GitHub, we're discussing how to implement on python or c++.

https://github.com/longcw/RoIAlign.pytorch","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY1NDA0MzM3MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/700,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY1NDIyMzc2Mg==,singa,654223762,700,NA,Shashankwer,15552734,Shashank Nigam,shashanknigam40@gmail.com,NA,2020-07-06T13:06:27Z,2020-07-06T13:06:27Z,Thanks for the reference will try implementing NonMaxSuppression first,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY1NDIyMzc2Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/701,https://api.github.com/repos/apache/singa/issues/701,singa,619647944,701,Add a dataset module,nudles,3797447,Wei Wang,,OPEN,2020-05-17T08:55:35Z,2020-05-17T09:02:19Z,"Data loading is an important part of DL training, which could be slow and become a bottleneck if not implemented well.
The tasks include
1. implement dataset classes for common benchmark datasets to make them easy to access within SINGA (e.g., without manual downloading).
2. implement common preprocessing operations
3. implement parallel data loading for higher efficiency","{""url"": ""https://api.github.com/repos/apache/singa/issues/701/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/701,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTc2NTM2OQ==,singa,629765369,701,NA,nudles,3797447,Wei Wang,,NA,2020-05-17T09:02:05Z,2020-05-17T09:02:05Z,Code from the data module may be reused. https://github.com/apache/singa/blob/master/python/singa/data.py,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTc2NTM2OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/701,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTc2NTM5OA==,singa,629765398,701,NA,nudles,3797447,Wei Wang,,NA,2020-05-17T09:02:19Z,2020-05-17T09:02:19Z,And https://github.com/apache/singa/blob/master/python/singa/image_tool.py,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYyOTc2NTM5OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/702,https://api.github.com/repos/apache/singa/issues/702,singa,619668247,702,Update the metric module,nudles,3797447,Wei Wang,,OPEN,2020-05-17T10:40:11Z,2020-07-18T16:07:56Z,"It would be better to implement a metric as a function in the metric.py as metric typically has not states. Therefore, no need to make it as a class. e.g,

```python
def accuracy(y_pred, y_true):
   """"""compute the accuracy.

     Args:
        y_pred(numpy array or tensor): each value is a label index
        y_true(numpy array or tensor): each value is a label index
   """"""
      check shape match
      convert y_pred and y_true to np array     
      return np.sum(y_pred== y_true) / y_true.shape[0]
```
Refer to https://keras.io/api/metrics/","{""url"": ""https://api.github.com/repos/apache/singa/issues/702/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/702,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMDg1NTY3Nw==,singa,630855677,702,NA,nudles,3797447,Wei Wang,,NA,2020-05-19T14:27:15Z,2020-05-19T14:27:15Z,Or we can convert SINGA Tensor to numpy array and use sklearn.metrics to compute the metrics https://scikit-learn.org/stable/modules/model_evaluation.html. ,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMDg1NTY3Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/702,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMDkyMDQ5MQ==,singa,630920491,702,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-05-19T16:06:57Z,2020-05-19T16:06:57Z,"When we use this accuracy:
y_true (each value is a label index) is provided directly by the dataset
y_pred (each value is a label index) needs to be obtained by applying max function to the network output (i.e. logit) BEFORE the softmaxCrossEntropy

so we need a max function to turn the logits into pred label index?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMDkyMDQ5MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/702,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0NTczNTI3NQ==,singa,645735275,702,NA,nudles,3797447,Wei Wang,,NA,2020-06-18T02:42:00Z,2020-06-18T02:42:00Z,"I suggest to use sklearn's functions to evaluate the metrics.
We can them remove the metric.py module.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0NTczNTI3NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/702,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY2MDUwMzg0Nw==,singa,660503847,702,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-07-18T16:07:56Z,2020-07-18T16:07:56Z,"sklearn.metrics.accuracy_score API:
https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY2MDUwMzg0Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/704,https://api.github.com/repos/apache/singa/issues/704,singa,620685938,704,Creation of tensor in 3.0.0 results in NonImplementedError,Shashankwer,15552734,Shashank Nigam,shashanknigam40@gmail.com,CLOSED,2020-05-19T05:19:52Z,2020-05-19T06:33:32Z,"Hi, 

For the creation of Tensor in singa 3.0.0 cpu for py36 results in an error as described below: 

NotImplementedError: Wrong number or type of arguments for overloaded function 'new_Tensor'.
  Possible C/C++ prototypes are:
    singa::Tensor::Tensor()
    singa::Tensor::Tensor(std::vector< size_t,std::allocator< size_t > > const &,singa::DataType)
    singa::Tensor::Tensor(std::vector< size_t,std::allocator< size_t > > const &)
    singa::Tensor::Tensor(std::vector< size_t,std::allocator< size_t > > const &,std::shared_ptr< singa::Device >,singa::DataType)
    singa::Tensor::Tensor(std::vector< size_t,std::allocator< size_t > > const &,std::shared_ptr< singa::Device >)
    singa::Tensor::Tensor(singa::Tensor const &)

The tensor were created from numpy with code implementation as below: 

import numpy as np
from singa import tensor

tensor.from_numpy( np.asarray([[1, 0, 0], [0, 1, 0]], dtype=np.float32) )

Following are the operating system specification: 

OS: MacOS version 10.15.3
python version: 3.6.10
singa: 3.0.0 cpu_py36

The same code seems to work on singa version 3.0.0.rc1              cpu_py36 

","{""url"": ""https://api.github.com/repos/apache/singa/issues/704/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/704,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMDU5Njg3Nw==,singa,630596877,704,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-05-19T05:52:49Z,2020-05-19T05:52:49Z,"could you place the result of ""conda list"" here?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMDU5Njg3Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/704,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMDYwODE4Nw==,singa,630608187,704,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-05-19T06:20:34Z,2020-05-19T06:20:34Z,"You may check the anaconda cloud for the existing version available
https://anaconda.org/nusdbsystem/singa-cpu/files

I have run python 3.7 singa 3.0.0 cpu in ubuntu without any problem, you may see the following log:

```
dcsysh@ncrs:/$ conda create -n singacpu37 python=3.7
Collecting package metadata (current_repodata.json): done
Solving environment: done

==> WARNING: A newer version of conda exists. <==
  current version: 4.8.2
  latest version: 4.8.3

Please update conda by running

    $ conda update -n base -c defaults conda

## Package Plan ##

  environment location: /home/dcsysh/anaconda3/envs/singacpu37

  added / updated specs:
    - python=3.7


The following packages will be downloaded:

    package                    |            build
    ---------------------------|-----------------
    python_abi-3.7             |          1_cp37m           4 KB  conda-forge
    setuptools-46.4.0          |   py37hc8dfbb8_0         633 KB  conda-forge
    ------------------------------------------------------------
                                           Total:         637 KB

The following NEW packages will be INSTALLED:

  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge
  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-0_gnu
  ca-certificates    conda-forge/linux-64::ca-certificates-2020.4.5.1-hecc5488_0
  certifi            conda-forge/linux-64::certifi-2020.4.5.1-py37hc8dfbb8_0
  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.34-h53a641e_0
  libffi             conda-forge/linux-64::libffi-3.2.1-he1b5a44_1007
  libgcc-ng          conda-forge/linux-64::libgcc-ng-9.2.0-h24d8f2e_2
  libgomp            conda-forge/linux-64::libgomp-9.2.0-h24d8f2e_2
  libstdcxx-ng       conda-forge/linux-64::libstdcxx-ng-9.2.0-hdf63c60_2
  ncurses            conda-forge/linux-64::ncurses-6.1-hf484d3e_1002
  openssl            conda-forge/linux-64::openssl-1.1.1g-h516909a_0
  pip                conda-forge/noarch::pip-20.1-pyh9f0ad1d_0
  python             conda-forge/linux-64::python-3.7.6-h8356626_5_cpython
  python_abi         conda-forge/linux-64::python_abi-3.7-1_cp37m
  readline           conda-forge/linux-64::readline-8.0-hf8c457e_0
  setuptools         conda-forge/linux-64::setuptools-46.4.0-py37hc8dfbb8_0
  sqlite             conda-forge/linux-64::sqlite-3.30.1-hcee41ef_0
  tk                 conda-forge/linux-64::tk-8.6.10-hed695b0_0
  wheel              conda-forge/noarch::wheel-0.34.2-py_1
  xz                 conda-forge/linux-64::xz-5.2.5-h516909a_0
  zlib               conda-forge/linux-64::zlib-1.2.11-h516909a_1006


Proceed ([y]/n)? y


Downloading and Extracting Packages
python_abi-3.7       | 4 KB      | ########################################################################################################################## | 100%
setuptools-46.4.0    | 633 KB    | ########################################################################################################################## | 100%
Preparing transaction: done
Verifying transaction: done
Executing transaction: done
#
# To activate this environment, use
#
#     $ conda activate singacpu37
#
# To deactivate an active environment, use
#
#     $ conda deactivate

dcsysh@ncrs:/$ source activate singacpu37
(singacpu37) dcsysh@ncrs:/$ conda install -c nusdbsystem -c conda-forge singa-cpu=3.0.0
Collecting package metadata (current_repodata.json): done
Solving environment: failed with initial frozen solve. Retrying with flexible solve.
Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.
Collecting package metadata (repodata.json): done
Solving environment: done


==> WARNING: A newer version of conda exists. <==
  current version: 4.8.2
  latest version: 4.8.3

Please update conda by running

    $ conda update -n base -c defaults conda



## Package Plan ##

  environment location: /home/dcsysh/anaconda3/envs/singacpu37

  added / updated specs:
    - singa-cpu=3.0.0


The following packages will be downloaded:

    package                    |            build
    ---------------------------|-----------------
    _openmp_mutex-4.5          |           1_llvm           5 KB  conda-forge
    dnnl-1.1                   |            build         3.6 MB  nusdbsystem
    future-0.18.2              |   py37hc8dfbb8_1         712 KB  conda-forge
    libblas-3.8.0              |      16_openblas          10 KB  conda-forge
    libcblas-3.8.0             |      16_openblas          10 KB  conda-forge
    liblapack-3.8.0            |      16_openblas          10 KB  conda-forge
    numpy-1.16.5               |   py37h95a1406_0         4.3 MB  conda-forge
    onnx-1.6.0                 |   py37he1b5a44_0         2.9 MB  conda-forge
    pillow-7.1.2               |   py37h718be6c_0         658 KB  conda-forge
    protobuf-3.9.2             |   py37he1b5a44_1         688 KB  conda-forge
    singa-3.0.0                |         cpu_py37        22.4 MB  nusdbsystem
    singa-cpu-3.0.0            |             py37           4 KB  nusdbsystem
    wrapt-1.12.1               |   py37h8f50634_1          46 KB  conda-forge
    ------------------------------------------------------------
                                           Total:        35.3 MB

The following NEW packages will be INSTALLED:

  deprecated         conda-forge/noarch::deprecated-1.2.7-py_0
  dnnl               nusdbsystem/linux-64::dnnl-1.1-build
  freetype           conda-forge/linux-64::freetype-2.10.2-he06d7ca_0
  future             conda-forge/linux-64::future-0.18.2-py37hc8dfbb8_1
  glog               conda-forge/linux-64::glog-0.3.5-hf484d3e_1001
  jpeg               conda-forge/linux-64::jpeg-9c-h14c3975_1001
  libblas            conda-forge/linux-64::libblas-3.8.0-16_openblas
  libcblas           conda-forge/linux-64::libcblas-3.8.0-16_openblas
  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-7.5.0-hdf63c60_6
  liblapack          conda-forge/linux-64::liblapack-3.8.0-16_openblas
  libopenblas        conda-forge/linux-64::libopenblas-0.3.9-h5ec1e0e_0
  libpng             conda-forge/linux-64::libpng-1.6.37-hed695b0_1
  libprotobuf        conda-forge/linux-64::libprotobuf-3.9.2-h8b12597_0
  libtiff            conda-forge/linux-64::libtiff-4.1.0-hc7e4089_6
  libwebp-base       conda-forge/linux-64::libwebp-base-1.1.0-h516909a_3
  llvm-openmp        conda-forge/linux-64::llvm-openmp-10.0.0-hc9558a2_0
  lz4-c              conda-forge/linux-64::lz4-c-1.9.2-he1b5a44_1
  numpy              conda-forge/linux-64::numpy-1.16.5-py37h95a1406_0
  olefile            conda-forge/noarch::olefile-0.46-py_0
  onnx               conda-forge/linux-64::onnx-1.6.0-py37he1b5a44_0
  pillow             conda-forge/linux-64::pillow-7.1.2-py37h718be6c_0
  protobuf           conda-forge/linux-64::protobuf-3.9.2-py37he1b5a44_1
  singa              nusdbsystem/linux-64::singa-3.0.0-cpu_py37
  singa-cpu          nusdbsystem/linux-64::singa-cpu-3.0.0-py37
  six                conda-forge/noarch::six-1.14.0-py_1
  tqdm               conda-forge/noarch::tqdm-4.46.0-pyh9f0ad1d_0
  wrapt              conda-forge/linux-64::wrapt-1.12.1-py37h8f50634_1
  zstd               conda-forge/linux-64::zstd-1.4.4-h6597ccf_3

The following packages will be DOWNGRADED:

  _openmp_mutex                                   4.5-0_gnu --> 4.5-1_llvm


Proceed ([y]/n)? y


Downloading and Extracting Packages
libblas-3.8.0        | 10 KB     | ########################################################################################################################## | 100%
onnx-1.6.0           | 2.9 MB    | ########################################################################################################################## | 100%
singa-3.0.0          | 22.4 MB   | ########################################################################################################################## | 100%
dnnl-1.1             | 3.6 MB    | ########################################################################################################################## | 100%
_openmp_mutex-4.5    | 5 KB      | ########################################################################################################################## | 100%
wrapt-1.12.1         | 46 KB     | ########################################################################################################################## | 100%
pillow-7.1.2         | 658 KB    | ########################################################################################################################## | 100%
protobuf-3.9.2       | 688 KB    | ########################################################################################################################## | 100%
numpy-1.16.5         | 4.3 MB    | ########################################################################################################################## | 100%
libcblas-3.8.0       | 10 KB     | ########################################################################################################################## | 100%
future-0.18.2        | 712 KB    | ########################################################################################################################## | 100%
singa-cpu-3.0.0      | 4 KB      | ########################################################################################################################## | 100%
liblapack-3.8.0      | 10 KB     | ########################################################################################################################## | 100%
Preparing transaction: done
Verifying transaction: done
Executing transaction: done
(singacpu37) dcsysh@ncrs:/$ python
Python 3.7.6 | packaged by conda-forge | (default, Mar 23 2020, 23:03:20)
[GCC 7.3.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import numpy as np
>>> from singa import tensor
>>>
>>> tensor.from_numpy( np.asarray([[1, 0, 0], [0, 1, 0]], dtype=np.float32) )
[[1. 0. 0.]
 [0. 1. 0.]]
>>>
```
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMDYwODE4Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/704,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMDYxMTcyMQ==,singa,630611721,704,NA,Shashankwer,15552734,Shashank Nigam,shashanknigam40@gmail.com,NA,2020-05-19T06:28:33Z,2020-05-19T06:28:33Z,"Name|Version|Build|Channel
------|-------|-----|---------
appnope|0.1.0|py36h9f0ad1d_1001|conda-forge
attrs|19.3.0|py_0|conda-forge
backcall|0.1.0|py_0|conda-forge
bleach|3.1.5|pyh9f0ad1d_0|conda-forge
ca-certificates|2020.4.5.1|hecc5488_0|conda-forge
certifi|2020.4.5.1|py36h9f0ad1d_0|conda-forge
dbus|1.13.6|h2f22bb5_0|conda-forge
decorator|4.4.2|py_0|conda-forge
defusedxml|0.6.0|py_0|conda-forge
deprecated|1.2.7|py_0|conda-forge
dnnl|1.1|build|nusdbsystem
entrypoints|0.3|py36h9f0ad1d_1001|conda-forge
expat|2.2.9|h4a8c4bd_2|conda-forge
freetype|2.10.2|h8da9a1a_0|conda-forge
future|0.18.2|py36h9f0ad1d_1|conda-forge
gettext|0.19.8.1|h46ab8bc_1002|conda-forge
glib|2.64.2|h577aef8_1|conda-forge
glog|0.3.5|h0a44026_1001|conda-forge
icu|64.2|h6de7cb9_1|conda-forge
importlib-metadata|1.6.0|py36h9f0ad1d_0|conda-forge
importlib_metadata|1.6.0|0|conda-forge
ipykernel|5.2.1|py36h95af2a2_0|conda-forge
ipython|7.14.0|py36h9f0ad1d_0|conda-forge
ipython_genutils|0.2.0|py_1|conda-forge
ipywidgets|7.5.1|py_0|conda-forge
jedi|0.17.0|py36h9f0ad1d_0|conda-forge
jinja2|2.11.2|pyh9f0ad1d_0|conda-forge
jpeg|9c|h1de35cc_1001|conda-forge
jsonschema|3.2.0|py36h9f0ad1d_1|conda-forge
jupyter|1.0.0|py_2|conda-forge
jupyter_client|6.1.3|py_0|conda-forge
jupyter_console|6.1.0|py_1|conda-forge
jupyter_core|4.6.3|py36h9f0ad1d_1|conda-forge
krb5|1.17.1|h1752a42_0|conda-forge
libblas|3.8.0|16_openblas|conda-forge
libcblas|3.8.0|16_openblas|conda-forge
libclang|9.0.1|default_hf57f61e_0|conda-forge
libcxx|10.0.0|h1af66ff_2|conda-forge
libedit|3.1.20170329|hcfe32e1_1001|conda-forge
libffi|3.2.1|h4a8c4bd_1007|conda-forge
libgfortran|4.0.0|2|conda-forge
libiconv|1.15|h0b31af3_1006|conda-forge
liblapack|3.8.0|16_openblas|conda-forge
libllvm9|9.0.1|h7475705_1|conda-forge
libopenblas|0.3.9|h3d69b6c_0|conda-forge
libpng|1.6.37|hbbe82c9_1|conda-forge
libpq|12.2|h489d428_1|conda-forge
libprotobuf|3.10.0|hd174df1_0|conda-forge
libsodium|1.0.17|h01d97ff_0|conda-forge
libtiff|4.1.0|h2ae36a8_6|conda-forge
libwebp-base|1.1.0|h0b31af3_3|conda-forge
llvm-openmp|10.0.0|h28b9765_0|conda-forge
lz4-c|1.9.2|h4a8c4bd_1|conda-forge
markupsafe|1.1.1|py36h37b9a7d_1|conda-forge
mistune|0.8.4|py36h37b9a7d_1001|conda-forge
nbconvert|5.6.1|py36h9f0ad1d_1|conda-forge
nbformat|5.0.6|py_0|conda-forge
ncurses|6.1|h0a44026_1002|conda-forge
notebook|6.0.3|py36h9f0ad1d_0|conda-forge
nspr|4.20|h0a44026_1000|conda-forge
nss|3.47|hc0980d9_0|conda-forge
numpy|1.16.5|py36hde6bac1_0|conda-forge
olefile|0.46|py_0|conda-forge
onnx|1.6.0|py36h4a8c4bd_0|conda-forge
openssl|1.1.1g|h0b31af3_0|conda-forge
packaging|20.1|py_0|conda-forge
pandoc|2.9.2.1|0|conda-forge
pandocfilters|1.4.2|py_1|conda-forge
parso|0.7.0|pyh9f0ad1d_0|conda-forge
pcre|8.44|h4a8c4bd_0|conda-forge
pexpect|4.8.0|py36h9f0ad1d_1|conda-forge
pickleshare|0.7.5|py36h9f0ad1d_1001|conda-forge
pillow|7.1.2|py36h2ae5dfa_0|conda-forge
pip|20.1|pyh9f0ad1d_0|conda-forge
prometheus_client|0.7.1|py_0|conda-forge
prompt-toolkit|3.0.5|py_0|conda-forge
prompt_toolkit|3.0.5|0|conda-forge
protobuf|3.10.0|py36h4a8c4bd_0|conda-forge
ptyprocess|0.6.0|py_1001|conda-forge
pygments|2.6.1|py_0|conda-forge
pyparsing|2.4.7|pyh9f0ad1d_0|conda-forge
pyqt|5.12.3|py36haa9e2f4_3|conda-forge
pyqt5-sip|4.19.18|pypi_0|pypi
pyqtchart|5.12|pypi_0|pypi
pyqtwebengine|5.12.1|pypi_0|pypi
pyrsistent|0.16.0|py36h37b9a7d_0|conda-forge
python|3.6.10|h4334963_1011_cpython|conda-forge
python-dateutil|2.8.1|py_0|conda-forge
python_abi|3.6|1_cp36m|conda-forge
pyzmq|19.0.1|py36h820b253_0|conda-forge
qt|5.12.5|h514805e_3|conda-forge
qtconsole|4.7.4|pyh9f0ad1d_0|conda-forge
qtpy|1.9.0|py_0|conda-forge
readline|8.0|hcfe32e1_0|conda-forge
send2trash|1.5.0|py_0|conda-forge
setuptools|46.4.0|py36h9f0ad1d_0|conda-forge
singa|3.0.0|cpu_py36|nusdbsystem
six|1.14.0|py_1|conda-forge
sqlite|3.30.1|h93121df_0|conda-forge
terminado|0.8.3|py36h9f0ad1d_1|conda-forge
testpath|0.4.4|py_0|conda-forge
tk|8.6.10|hbbe82c9_0|conda-forge
tornado|6.0.4|py36h37b9a7d_1|conda-forge
tqdm|4.46.0|pyh9f0ad1d_0|conda-forge
traitlets|4.3.3|py36h9f0ad1d_1|conda-forge
wcwidth|0.1.9|pyh9f0ad1d_0|conda-forge
webencodings|0.5.1|py_1|conda-forge
wheel|0.34.2|py_1|conda-forge
widgetsnbextension|3.5.1|py36_0|conda-forge
wrapt|1.12.1|py36h37b9a7d_1|conda-forge
xz|5.2.5|h0b31af3_0|conda-forge
zeromq|4.3.2|h6de7cb9_2|conda-forge
zipp|3.1.0|py_0|conda-forge
zlib|1.2.11|h0b31af3_1006|conda-forge
zstd|1.4.4|h4b3e974_3|conda-forge","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMDYxMTcyMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/704,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMDYxMjMwOQ==,singa,630612309,704,NA,Shashankwer,15552734,Shashank Nigam,shashanknigam40@gmail.com,NA,2020-05-19T06:29:46Z,2020-05-19T06:29:46Z,Will check the updated version,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMDYxMjMwOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/704,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMDYxMzg5NA==,singa,630613894,704,NA,Shashankwer,15552734,Shashank Nigam,shashanknigam40@gmail.com,NA,2020-05-19T06:33:31Z,2020-05-19T06:33:31Z,"Updating to 3.7, the version seems to working well. Thank you for the assistance. ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMDYxMzg5NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/705,https://api.github.com/repos/apache/singa/issues/705,singa,620847095,705,Add docstring for each Python module,nudles,3797447,Wei Wang,,OPEN,2020-05-19T10:03:46Z,2020-05-19T10:03:56Z,"1. The module's docstring should explain the classes and functions in this module.
2. Example usages should be given.
3. How to add a new sub-class should be explained, e.g., how to add a new Layer subclass in layer.py, how to add a new Operator subclass in autograd.py.

The docstrings will be used to build the API documentation pages at https://apache-singa.readthedocs.io/en/latest/","{""url"": ""https://api.github.com/repos/apache/singa/issues/705/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/706,https://api.github.com/repos/apache/singa/issues/706,singa,621296468,706,Refactor SONNX,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,CLOSED,2020-05-19T21:28:00Z,2020-05-26T03:57:09Z,"Hi, all, during refactoring SONNX, I found the following issues:

# Input
ONNX prefers to use tensors as input instead of attributes, which may incurs some issues when we create SINGA operators(or layers). There are two cases:
1. SINGA params <- ONNX Initializer
 The params of an operator come from the ONNX Initializer(pre-stored weights). This part is ok now.
2. **SINGA params <- ONNX operator, dynamic graph**
 For some operators of ONNX(OneHot, Tile, Gather, Reshape, Slice, Clip). Some attributes of these operators, they come from other operators' outputs. We cannot handle this case. 
 For example, in BERT, for this Reshape operator, its shape comes from the previous operator:
![image](https://user-images.githubusercontent.com/14108933/82379081-dcc63c00-9a58-11ea-8ba1-ab637dbe417d.png)

# Layers
 for @dcslin 

## BatchNorm2d
- remove num_features
- self.allow_params = [""scale"", ""bias"", ""running_mean"", ""running_var""]

## Conv2d
- remove in_channels, out_channels

## Gemm
In some model, the developer prefers gemm instead of linear, so we need to add gemm to Layer,

# Metaclass
I've checked the metaclass carefully, but It seems I cannot use the metaclass to modify the forward function in this case. The case is, I have a graph written by ONNX, I need to write a forward by using SINGA's operator. In this case, I can call the SINGA's operator by the graph, but I cannot write a forward function automatically from the graph.

This more like the `exec` function.

for example, I have a graph like this:
```
graph = {
    ""op1"" : {""inputs"":[""a1""], outputs:[""a2""]},
    ""op2"" : {""inputs"":[""a2""], outputs:[""a3""]},
}
# what I can do
def forward(x):
    tensors = []
    for op, op_info in graph.items():
        inputs = [tensors[inp] for inp in op_info.inputs]
        outputs = op()
        for (outp, val) in zip(op_info.outputs, outputs):
            tensors[outp] = val
# what I cannot do by metaclass but can with exec
program = parse_graph_to_str(graph)
# 'a2=op1(a1)\na3=op2(a2)'
exec(program)
```

So, the above forward is my current implementation.","{""url"": ""https://api.github.com/repos/apache/singa/issues/706/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/706,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMTE3NzU4OQ==,singa,631177589,706,NA,nudles,3797447,Wei Wang,,NA,2020-05-20T01:22:49Z,2020-05-20T01:22:49Z,"> 
> 
> Hi, all, during refactoring SONNX, I found the following issues:
> # Input
> 
> ONNX prefers to use tensors as input instead of attributes, which may incurs some issues when we create SINGA operators(or layers). There are two cases:
> 
>     1. SINGA params <- ONNX Initializer
>        The params of an operator come from the ONNX Initializer(pre-stored weights). This part is ok now.
> 
>     2. **SINGA params <- ONNX operator, dynamic graph**
>        For some operators of ONNX(OneHot, Tile, Gather, Reshape, Slice, Clip). Some attributes of these operators, they come from other operators' outputs. We cannot handle this case.
>        For example, in BERT, for this Reshape operator, its shape comes from the previous operator:
>        ![image](https://user-images.githubusercontent.com/14108933/82379081-dcc63c00-9a58-11ea-8ba1-ab637dbe417d.png)
> 

can you extract the values for the shape from the tensor and pass them to init Reshape?
> 
> # Layers
> 
> for @dcslin
> ## BatchNorm2d
> 
>     * remove num_features
> 
>     * self.allow_params = [""scale"", ""bias"", ""running_mean"", ""running_var""]
> 

`running_mean` and `running_var` are not params (not updated via sgd).
They are state variables.
> 
> ## Conv2d
> 
>     * remove in_channels, out_channels
> 

out_channel is required. Rename it to nb_kernels.
> 
> ## Gemm
> 
> In some model, the developer prefers gemm instead of linear, so we need to add gemm to Layer,

ok.
> # Metaclass
> 
> I've checked the metaclass carefully, but It seems I cannot use the metaclass to modify the forward function in this case. The case is, I have a graph written by ONNX, I need to write a forward by using SINGA's operator. In this case, I can call the SINGA's operator by the graph, but I cannot write a forward function automatically from the graph.

With SONNXModel, I think we do not need metaclass anymore.
> 
> This more like the `exec` function.
> 
> for example, I have a graph like this:
> 
> ```
> graph = {
>     ""op1"" : {""inputs"":[""a1""], outputs:[""a2""]},
>     ""op2"" : {""inputs"":[""a2""], outputs:[""a3""]},
> }
> # what I can do
> def forward(x):
>     tensors = []
>     for op, op_info in graph.items():
>         inputs = [tensors[inp] for inp in op_info.inputs]
>         outputs = op()
>         for (outp, val) in zip(op_info.outputs, outputs):
>             tensors[outp] = val

The code above is for SONNXModel's forward. 
You just need to consider the `aux_output`
> # what I cannot do by metaclass but can with exec
> program = parse_graph_to_str(graph)
> # 'a2=op1(a1)\na3=op2(a2)'
> exec(program)
> ```
> 
> So, the above forward is my current implementation.

","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMTE3NzU4OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/706,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMTI1NzI4MA==,singa,631257280,706,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-05-20T06:06:27Z,2020-05-20T06:06:27Z,"1. can you extract the values for the shape from the tensor and pass them to init Reshape?
Yes, I'm going to do this.

2. running_mean and running_var are not params (not updated via sgd). They are state variables.
Got it, but I canot see the set_states yet at Layer class.

3. out_channel is required. Rename it to nb_kernels.
Got it, I think I can parse the out_channels from the ONNX's weight.

4. With SONNXModel, I think we do not need metaclass anymore. You just need to consider the aux_output
Yes, this part has been done.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMTI1NzI4MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/707,https://api.github.com/repos/apache/singa/issues/707,singa,621625087,707,Layer mismatch causes session to to terminate abruptly ,Shashankwer,15552734,Shashank Nigam,shashanknigam40@gmail.com,CLOSED,2020-05-20T09:52:27Z,2020-06-30T03:08:07Z,"Hi, 

The issue might be known, however while creating a Neural network layer stack with unmatched layer can cause the current python session to end abruptly, without generating any stack trace. while calculating model.loss(e.g. autograd.mse_loss(y,t) ) 

for example of a simple feed forward neural network:
class MLP():
    def __init__(self):
        self.linear1 = autograd.Linear(3,4)
        self.linear2 = autograd.Linear(4,3)
    def forward(self,x):
        y = self.linear1(x)
        return self.linear2(y) 

if the output does not have a dimension of 3, the current session will terminate without generating any error. 

A stack trace is generated with below warning. 

WARNING: Logging before InitGoogleLogging() is written to STDERR
F0520 17:37:19.265754 288538048 tensor.cc:431] Check failed: shape_.at(m - i) == 1 (3 vs. 1) i= 0
*** Check failure stack trace: ***

This causes to rerun the entire program/notebook again. The same issue is not seen in autograd.backward which generates an assertion error. 

Thanks and Regards,
Shashank 





  ","{""url"": ""https://api.github.com/repos/apache/singa/issues/707/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/707,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNjU3NDY3Ng==,singa,636574676,707,NA,nudles,3797447,Wei Wang,,NA,2020-06-01T02:03:38Z,2020-06-01T02:03:38Z,@dcslin can you help check this issue?,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNjU3NDY3Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/707,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNjU4MTk0Mw==,singa,636581943,707,NA,dcslin,13751447,Shicong,,NA,2020-06-01T02:38:00Z,2020-06-01T02:38:00Z,hi @Shashankwer I am looking into this.,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNjU4MTk0Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/707,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNzI4Njg2OA==,singa,637286868,707,NA,dcslin,13751447,Shicong,,NA,2020-06-02T05:31:34Z,2020-06-02T05:31:34Z,"Hi @Shashankwer , Understand that the error code is not clear enough, but I could not replicate the error without further details(inputs, outputs), would you like to refer to following working example transformed from your code to help you debugging?

```
from singa import autograd
from singa import module
from singa import opt
from singa import tensor

class MLP():
    def __init__(self):
        self.linear1 = autograd.Linear(3,4)
        self.linear2 = autograd.Linear(4,3)
    def forward(self,x):
        y = self.linear1(x)
        return self.linear2(y)
    def loss(self, out, ty):
        return autograd.softmax_cross_entropy(out, ty)
    def optim(self, loss):
        self.optimizer.backward_and_update(loss)
    def set_optimizer(self, optimizer):
        self.optimizer = optimizer


if __name__ == '__main__':
    x=tensor.Tensor((3,3)).gaussian(1,1)
    y=tensor.Tensor((3,3)).gaussian(1,1)

    autograd.training = True
    m = MLP()
    sgd = opt.SGD()
    m.set_optimizer(sgd)
    out = m.forward(x)
    loss = m.loss(out, y)
    m.optim(loss)
    print(loss)
```

","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNzI4Njg2OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/707,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNzQwNDg5Ng==,singa,637404896,707,NA,Shashankwer,15552734,Shashank Nigam,shashanknigam40@gmail.com,NA,2020-06-02T09:10:03Z,2020-06-02T09:10:03Z,"Hi, 

Issue reported here is for handling the error on the python API side and is particularly noticed for autograd.backward function. 

Consider the below example
```
from singa import autograd
from singa import module
from singa import opt
from singa import tensor
from singa import device

class MLP():
    def __init__(self):
        self.linear1 = autograd.Linear(3, 4)
        self.linear2 = autograd.Linear(4, 3)
    def forward(self,x):
        y = self.linear1(x)
        return self.linear2(y)
    def loss(self, out, ty):
        return autograd.softmax_cross_entropy(out, ty)
    def optim(self, loss):
        self.optimizer.backward_and_update(loss)
    def set_optimizer(self, optimizer):
        self.optimizer = optimizer

def train(model, x, t, dev=device.get_default_device(), epochs=100):
    for i in range(epochs):
        y = model.forward(x)
        loss = autograd.mse_loss(y, t)
        print(""loss: "", loss)
        sgd = opt.SGD()
        for p, gp in autograd.backward(loss):
            sgd.update(p, gp)
        sgd.step()


if __name__ == '__main__':
    x=tensor.Tensor((3,3)).gaussian(1,1)
    y=tensor.Tensor((3,3)).gaussian(1,1)
    
    autograd.training = True
    m = MLP()
    sgd = opt.SGD()
    m.set_optimizer(sgd)
    out = m.forward(x)
    loss = m.loss(out, y)
    m.optim(loss)
    print(loss)
    train(m,x,y)
```

The above code will execute without any issues. However if we change the dimension of output tensor such that it does not match the model constructed, the error is noticed. For example 

```
from singa import autograd
from singa import module
from singa import opt
from singa import tensor
from singa import device

class MLP():
    def __init__(self):
        self.linear1 = autograd.Linear(3, 4)
        self.linear2 = autograd.Linear(4, 3)
    def forward(self,x):
        y = self.linear1(x)
        return self.linear2(y)
    def loss(self, out, ty):
        return autograd.softmax_cross_entropy(out, ty)
    def optim(self, loss):
        self.optimizer.backward_and_update(loss)
    def set_optimizer(self, optimizer):
        self.optimizer = optimizer

def train(model, x, t, dev=device.get_default_device(), epochs=100):
    for i in range(epochs):
        y = model.forward(x)
        loss = autograd.mse_loss(y, t)
        print(""loss: "", loss)
        sgd = opt.SGD()
        for p, gp in autograd.backward(loss):
            sgd.update(p, gp)
        sgd.step()


if __name__ == '__main__':
    x=tensor.Tensor((3,3)).gaussian(1,1)
    y=tensor.Tensor((3,4)).gaussian(1,1)
    
    autograd.training = True
    m = MLP()
    sgd = opt.SGD()
    m.set_optimizer(sgd)
    out = m.forward(x)
    loss = m.loss(out, y)
    m.optim(loss)
    print(loss)
    train(m,x,y)
```","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNzQwNDg5Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/707,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0NTg3MzY5Mg==,singa,645873692,707,NA,dcslin,13751447,Shicong,,NA,2020-06-18T08:43:28Z,2020-06-18T08:43:28Z,"Yes We should add input shape check all necessary operators in autograd.py
for example, we should raise exception if input shapes are different:
```
autograd.softmax_cross_entropy(tx, ty)
autograd.mse_loss(tx, ty)
autograd.equal(tx,ty)
```","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0NTg3MzY5Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/707,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0OTMyODk3Mw==,singa,649328973,707,NA,dcslin,13751447,Shicong,,NA,2020-06-25T07:50:06Z,2020-06-25T07:50:06Z,addressed in pr https://github.com/apache/singa/pull/751,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0OTMyODk3Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/710,https://api.github.com/repos/apache/singa/issues/710,singa,624867857,710,CUDA failed with the test case of operations,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,CLOSED,2020-05-26T13:04:32Z,2020-05-28T04:39:23Z,"Hi, @dcslin, as you know, I need to develop and test the new API for onnx, so I have to make sure the new implement of autograd and layers is ok. However, when I test the PR #697 , I have three types of issues of the `test_operation.py`:

# Zero-value tensors

For example, in the test case of `sum`, the value GPU tensor always is zero. But when I remove the conv2d test case, the `sum` case will be fine. It seems the conv2d layer results in the zero GPU tensor issue.

The following cases have the same problem:
- sum
- onehot
- tile
- gather
- split
- slice
- reduce_mean
- reduce_sum
- globalaveragepool
- gemm
- prelu
- less_broadcast
- xor_broadcast
- reciprocal
- xor
- not
- or
- selu
- prelu
- min_3inputs
- min
- shape
- squeeze
- max_1inputs
- max_3inputs
- max
- reshape
- mul
- transpose
- unsqueeze

# CURAND_STATUS_LAUNCH_FAILURE

an issue when I run the Conv2d with odd_padding. As you see, sometimes, I need to padding zeros from only one direction, so I write this function:
```py
def handle_odd_pad_fwd(x, odd_padding):
    """"""
    handle odd padding mode forward
    Args:
        x, the input tensor
        odd_padding, the odd_padding
    Returns: 
        tensor, the output
    """"""
    x_tensor = tensor.from_raw_tensor(x)
    # (axis, left padding if True else right padding)
    flags = [(2, True), (2, False), (3, True), (3, False)]
    for (axis, left), pad in zip(flags, odd_padding):
        if pad == 0:
            continue
        zeros_shape = list(x_tensor.data.shape())
        zeros_shape[axis] = pad
        zero_padding = np.zeros(zeros_shape).astype(np.float32)
        zero_padding = tensor.Tensor(device=x.device(), data=zero_padding)
        if left:
            x_tensor = tensor.concatenate((zero_padding, x_tensor), axis)
        else:
            x_tensor = tensor.concatenate((x_tensor, zero_padding), axis)
    return x_tensor.data
```

But it seems, when I call this func, it'd be fine if I call only one or two times, however, if I call it more times, it will report a error:

> F0526 12:53:40.017063 15641 tensor_math_cuda.h:791] Check failed: status == CURAND_STATUS_SUCCESS (201 vs. 0)  CURAND_STATUS_LAUNCH_FAILURE

I guess, the reason maybe it doesn't release the GPU memory in time?

The following cases have the same problem:
- conv2d
- pooling2d
- div_broadcast

# CUDNN_STATUS_EXECUTION_FAILED
The third error msg is:
> F0526 18:52:07.318809 21112 tensor_math_cuda.h:193] Error on line 193: CUDNN_STATUS_EXECUTION_FAILED

And the following cases have the same problem:
- SeparableConv2d
- mul_broadcast
- sub_broadcast
- add_broadcast
- greater_broadcast
- or_broadcast
- and_broadcast
- negative
- min_1inputs","{""url"": ""https://api.github.com/repos/apache/singa/issues/710/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/710,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNDUyNDE4MA==,singa,634524180,710,NA,dcslin,13751447,Shicong,,NA,2020-05-27T08:54:18Z,2020-05-27T08:54:18Z,"i could reproduce the error, and still checking","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNDUyNDE4MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/719,https://api.github.com/repos/apache/singa/issues/719,singa,629509468,719,Unable to convert maxpool2d from onnx to singa with ceil_mode set as False,Shashankwer,15552734,Shashank Nigam,shashanknigam40@gmail.com,CLOSED,2020-06-02T20:57:21Z,2020-06-04T15:30:19Z,"Hi,

For converting a ONNX model to SINGA, sonnx.py is being used. Different modules are converted using sonnx.py. Current implementation does not support maxpool2d with ceil_mode set to True and count_include_pad attributes. 

For MaxPool2d implemented using PyTorch, ceil_mode is a boolean operator which is default set to false. Sometimes while converting the pytorch model to onnx the atttribute get transferred to onnx implementation as: 

`onnx_node.attrs[""ceil_mode""] = 0` 
 
Which represents a valid context for conversion to singa format. The current code in sonnx however checks only for the presence of attribute **ceil_mode** in **onnx_node.attrs** before raising an exception as illustrated below: 
```
def _create_max_avg_pool(cls, onnx_node, inputs, opset_version):
        """"""
        get the max or avg pool operator from onnx node
        Args:
            onnx_node: a given onnx node
        Args:
            inputs: the input tensor
        Args:
            opset_version: the opset version
        Returns: 
            handle, the handle of singa operator
        Returns: 
            forward, the autograd of singa operator
        """"""
        kernel = tuple(onnx_node.attrs[""kernel_shape""])
        padding = tuple(
            onnx_node.attrs[""pads""]) if ""pads"" in onnx_node.attrs else (0, 0)
        stride = tuple(onnx_node.getattr('strides', (1, 1)))
        # default the odd_padding is 0, once there are same pad mode, we modify it
        # for odd_padding, please refer the autegrade.py
        odd_padding = (0, 0, 0, 0)
        if ""auto_pad"" in onnx_node.attrs:
            auto_pad = utils.force_unicode(onnx_node.attrs['auto_pad'])
            if auto_pad in ('SAME_UPPER', 'SAME_LOWER'):
                padding, odd_padding = utils.get_padding_shape(
                    auto_pad, inputs[0].shape[2:], kernel, stride)

        **# not support count_include_pad and auto_pad
        if ""count_include_pad"" in onnx_node.attrs or ""ceil_mode"" in onnx_node.attrs :
            raise ValueError(
                ""Not implemented yet for count_include_pad or ceil_mode"")**

        # only support 2d
        if len(kernel) != 2:
            raise ValueError(""Not implemented yet"")

        is_max = onnx_node.op_type == 'MaxPool'
        x = inputs[0]
        if x.device.id() == -1:
            handle = singa.PoolingHandle(x.data, kernel, stride, padding,
                                         is_max)
        else:
            handle = singa.CudnnPoolingHandle(x.data, kernel, stride, padding,
                                              is_max)

        _, forward = cls._common_onnx_node_to_singa_op(onnx_node, inputs,
                                                       opset_version)
        return _, forward(handle, odd_padding)
```

The code does not consider if the value of **ceil_mode** is set as **False/0**

The following changes can allow considering this edge case

```
def _create_max_avg_pool(cls, onnx_node, inputs, opset_version):
        """"""
        get the max or avg pool operator from onnx node
        Args:
            onnx_node: a given onnx node
        Args:
            inputs: the input tensor
        Args:
            opset_version: the opset version
        Returns: 
            handle, the handle of singa operator
        Returns: 
            forward, the autograd of singa operator
        """"""
        kernel = tuple(onnx_node.attrs[""kernel_shape""])
        padding = tuple(
            onnx_node.attrs[""pads""]) if ""pads"" in onnx_node.attrs else (0, 0)
        stride = tuple(onnx_node.getattr('strides', (1, 1)))
        # default the odd_padding is 0, once there are same pad mode, we modify it
        # for odd_padding, please refer the autegrade.py
        odd_padding = (0, 0, 0, 0)
        if ""auto_pad"" in onnx_node.attrs:
            auto_pad = utils.force_unicode(onnx_node.attrs['auto_pad'])
            if auto_pad in ('SAME_UPPER', 'SAME_LOWER'):
                padding, odd_padding = utils.get_padding_shape(
                    auto_pad, inputs[0].shape[2:], kernel, stride)

        # not support count_include_pad and auto_pad
        if ""ceil_mode"" in onnx_node.attrs and onnx_node.attrs[""ceil_mode""]:
          raise ValueError(
                ""Not implemented yet for count_include_pad or ceil_mode"")
        if ""count_include_pad"" in onnx_node.attrs:
            raise ValueError(
                ""Not implemented yet for count_include_pad or ceil_mode"")

        # only support 2d
        if len(kernel) != 2:
            raise ValueError(""Not implemented yet"")

        is_max = onnx_node.op_type == 'MaxPool'
        x = inputs[0]
        if x.device.id() == -1:
            handle = singa.PoolingHandle(x.data, kernel, stride, padding,
                                         is_max)
        else:
            handle = singa.CudnnPoolingHandle(x.data, kernel, stride, padding,
                                              is_max)

        _, forward = cls._common_onnx_node_to_singa_op(onnx_node, inputs,
                                                       opset_version)
        return _, forward(handle, odd_padding)
```

The issue is faced while converting shufflenetv2 from  onnx to singa 

Request to let us know if this change is possible

Thanks and Regards,
Shashank Nigam
","{""url"": ""https://api.github.com/repos/apache/singa/issues/719/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/719,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzODkyNjIxOQ==,singa,638926219,719,NA,Shashankwer,15552734,Shashank Nigam,shashanknigam40@gmail.com,NA,2020-06-04T15:30:19Z,2020-06-04T15:30:19Z,Issue can be closed have pushed a changes in latest commit,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDYzODkyNjIxOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/741,https://api.github.com/repos/apache/singa/issues/741,singa,640963609,741,cuda stream destory failed after python test passed  ,dcslin,13751447,Shicong,,CLOSED,2020-06-18T07:06:34Z,2020-06-19T02:52:49Z,"Hi, when running python test scripts, even the test are passing, the cuda stream still fails:

```
python3 test/python/test_operation.py -v TestPythonOperation.test_sum_cpu
test_sum_cpu (__main__.TestPythonOperation) ... ok

----------------------------------------------------------------------
Ran 1 test in 0.002s

OK
WARNING: Logging before InitGoogleLogging() is written to STDERR
F0618 07:06:09.329576 10741 cuda_gpu.cc:48] Check failed: error == cudaSuccess (29 vs. 0)  driver shutting down
*** Check failure stack trace: ***
Aborted (core dumped)
```","{""url"": ""https://api.github.com/repos/apache/singa/issues/741/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/741,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0NTgyNTc5Mw==,singa,645825793,741,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-06-18T07:10:39Z,2020-06-18T07:10:39Z,the cuda stream destory failed is resolved in https://github.com/apache/singa/pull/728,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0NTgyNTc5Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/741,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0NjQwNTkxNw==,singa,646405917,741,NA,dcslin,13751447,Shicong,,NA,2020-06-19T02:52:43Z,2020-06-19T02:52:43Z,ok thanks,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0NjQwNTkxNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/744,https://api.github.com/repos/apache/singa/issues/744,singa,641680098,744,Related to some test_onnx_backend.py test cases,chrishkchris,38325429,Chris Yeung,,CLOSED,2020-06-19T03:34:51Z,2020-10-13T08:12:05Z,"Some updates:
@joddiy is fixing some problem in onnx
```
root@d05828f767ee:~/dcsysh/singa/test/python# python3 test_onnx_backend.py
ss............................ssssssssssssssssssssssssssssssss................ssss..ss..ss......FFFF..ssssssssss..ssssssssssssssss............ssss....................ssssssss........................ssss....ssssssssssssssssssssssssss........ssssssssssssssssssssssssssss..........ssssssssssssss......FsFsssssssssssssssss..................ssss....ssssss..ssss..........ss.s............ssss....ssssssssssssssssssss........ssssssssssss..............ssssssssssssssssssssssss......ss......ssss..ss........FFFF..ssssssssss............ssssssssssssssssssssssssss......ssss....ssssssssssssssssss..................................ss........ssssssssssssssss....ssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss................ssssssssssssssssssssssssssssssss................ssssssssssssssssss....................ssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss..........ssss......ssss........ssss..............ss..........................................ssssssssssss....................ssssssssssssssssssss....ssssssssssssssssssssssssssssss................ssssss................
======================================================================
FAIL: test_averagepool_2d_same_lower_cpu (__main__.OnnxBackendNodeModelTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 248, in device_test_func
    return test_func(*args, device=device, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 313, in run
    atol=model_test.atol)
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 178, in assert_similar_outputs
    atol=atol)
  File ""/usr/local/lib/python3.6/dist-packages/numpy/testing/_private/utils.py"", line 1533, in assert_allclose
    verbose=verbose, header=header, equal_nan=equal_nan)
  File ""/usr/local/lib/python3.6/dist-packages/numpy/testing/_private/utils.py"", line 846, in assert_array_compare
    raise AssertionError(msg)
AssertionError:
Not equal to tolerance rtol=0.001, atol=1e-07

Mismatched elements: 189 / 3072 (6.15%)
Max absolute difference: 1.3230393
Max relative difference: 3.
 x: array([[[[ 1.764052e+00,  1.082105e+00,  6.894476e-01, ...,
           1.501069e+00,  8.121531e-01,  2.665550e-01],
         [ 4.381333e-01, -1.760931e-01, -2.374533e-01, ...,...
 y: array([[[[ 4.410131e-01,  5.410524e-01,  3.447238e-01, ...,
           7.505345e-01,  4.060766e-01,  1.332775e-01],
         [ 2.190667e-01, -1.760931e-01, -2.374533e-01, ...,...

======================================================================
FAIL: test_averagepool_2d_same_lower_cuda (__main__.OnnxBackendNodeModelTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 248, in device_test_func
    return test_func(*args, device=device, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 313, in run
    atol=model_test.atol)
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 178, in assert_similar_outputs
    atol=atol)
  File ""/usr/local/lib/python3.6/dist-packages/numpy/testing/_private/utils.py"", line 1533, in assert_allclose
    verbose=verbose, header=header, equal_nan=equal_nan)
  File ""/usr/local/lib/python3.6/dist-packages/numpy/testing/_private/utils.py"", line 846, in assert_array_compare
    raise AssertionError(msg)
AssertionError:
Not equal to tolerance rtol=0.001, atol=1e-07

Mismatched elements: 189 / 3072 (6.15%)
Max absolute difference: 1.3230393
Max relative difference: 3.
 x: array([[[[ 1.764052e+00,  1.082105e+00,  6.894476e-01, ...,
           1.501069e+00,  8.121531e-01,  2.665550e-01],
         [ 4.381333e-01, -1.760931e-01, -2.374533e-01, ...,...
 y: array([[[[ 4.410131e-01,  5.410524e-01,  3.447238e-01, ...,
           7.505345e-01,  4.060766e-01,  1.332775e-01],
         [ 2.190667e-01, -1.760931e-01, -2.374533e-01, ...,...

======================================================================
FAIL: test_averagepool_2d_same_upper_cpu (__main__.OnnxBackendNodeModelTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 248, in device_test_func
    return test_func(*args, device=device, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 313, in run
    atol=model_test.atol)
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 178, in assert_similar_outputs
    atol=atol)
  File ""/usr/local/lib/python3.6/dist-packages/numpy/testing/_private/utils.py"", line 1533, in assert_allclose
    verbose=verbose, header=header, equal_nan=equal_nan)
  File ""/usr/local/lib/python3.6/dist-packages/numpy/testing/_private/utils.py"", line 846, in assert_array_compare
    raise AssertionError(msg)
AssertionError:
Not equal to tolerance rtol=0.001, atol=1e-07

Mismatched elements: 189 / 3072 (6.15%)
Max absolute difference: 0.9547153
Max relative difference: 3.
 x: array([[[[-0.176093, -0.237453,  0.757017, ...,  0.112902, -0.50158 ,
          -0.67406 ],
         [-0.773234, -1.090172, -0.339745, ...,  0.040076, -0.369122,...
 y: array([[[[-0.176093, -0.237453,  0.757017, ...,  0.112902, -0.50158 ,
          -0.33703 ],
         [-0.773234, -1.090172, -0.339745, ...,  0.040076, -0.369122,...

======================================================================
FAIL: test_averagepool_2d_same_upper_cuda (__main__.OnnxBackendNodeModelTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 248, in device_test_func
    return test_func(*args, device=device, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 313, in run
    atol=model_test.atol)
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 178, in assert_similar_outputs
    atol=atol)
  File ""/usr/local/lib/python3.6/dist-packages/numpy/testing/_private/utils.py"", line 1533, in assert_allclose
    verbose=verbose, header=header, equal_nan=equal_nan)
  File ""/usr/local/lib/python3.6/dist-packages/numpy/testing/_private/utils.py"", line 846, in assert_array_compare
    raise AssertionError(msg)
AssertionError:
Not equal to tolerance rtol=0.001, atol=1e-07

Mismatched elements: 189 / 3072 (6.15%)
Max absolute difference: 0.9547153
Max relative difference: 3.
 x: array([[[[-0.176093, -0.237453,  0.757017, ...,  0.112902, -0.50158 ,
          -0.67406 ],
         [-0.773234, -1.090172, -0.339745, ...,  0.040076, -0.369122,...
 y: array([[[[-0.176093, -0.237453,  0.757017, ...,  0.112902, -0.50158 ,
          -0.33703 ],
         [-0.773234, -1.090172, -0.339745, ...,  0.040076, -0.369122,...

======================================================================
FAIL: test_equal_bcast_cpu (__main__.OnnxBackendNodeModelTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 248, in device_test_func
    return test_func(*args, device=device, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 313, in run
    atol=model_test.atol)
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 178, in assert_similar_outputs
    atol=atol)
  File ""/usr/local/lib/python3.6/dist-packages/numpy/testing/_private/utils.py"", line 1533, in assert_allclose
    verbose=verbose, header=header, equal_nan=equal_nan)
  File ""/usr/local/lib/python3.6/dist-packages/numpy/testing/_private/utils.py"", line 846, in assert_array_compare
    raise AssertionError(msg)
AssertionError:
Not equal to tolerance rtol=0.001, atol=1e-07

Mismatched elements: 1 / 60 (1.67%)
 x: array([[[False, False, False, False, False],
        [False, False, False, False, False],
        [False, False, False, False, False],...
 y: array([[[False, False, False, False, False],
        [False, False, False, False, False],
        [False, False, False, False, False],...

======================================================================
FAIL: test_equal_cpu (__main__.OnnxBackendNodeModelTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 248, in device_test_func
    return test_func(*args, device=device, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 313, in run
    atol=model_test.atol)
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 178, in assert_similar_outputs
    atol=atol)
  File ""/usr/local/lib/python3.6/dist-packages/numpy/testing/_private/utils.py"", line 1533, in assert_allclose
    verbose=verbose, header=header, equal_nan=equal_nan)
  File ""/usr/local/lib/python3.6/dist-packages/numpy/testing/_private/utils.py"", line 846, in assert_array_compare
    raise AssertionError(msg)
AssertionError:
Not equal to tolerance rtol=0.001, atol=1e-07

Mismatched elements: 1 / 60 (1.67%)
 x: array([[[False, False, False, False, False],
        [False, False, False, False, False],
        [False, False, False, False,  True],...
 y: array([[[False, False, False, False, False],
        [False, False, False, False, False],
        [False, False, False, False,  True],...

======================================================================
FAIL: test_maxpool_2d_same_lower_cpu (__main__.OnnxBackendNodeModelTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 248, in device_test_func
    return test_func(*args, device=device, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 313, in run
    atol=model_test.atol)
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 178, in assert_similar_outputs
    atol=atol)
  File ""/usr/local/lib/python3.6/dist-packages/numpy/testing/_private/utils.py"", line 1533, in assert_allclose
    verbose=verbose, header=header, equal_nan=equal_nan)
  File ""/usr/local/lib/python3.6/dist-packages/numpy/testing/_private/utils.py"", line 846, in assert_array_compare
    raise AssertionError(msg)
AssertionError:
Not equal to tolerance rtol=0.001, atol=1e-07

Mismatched elements: 35 / 3072 (1.14%)
Max absolute difference: 1.6961312
Max relative difference: 0.
 x: array([[[[ 1.764052e+00,  1.764052e+00,  9.787380e-01, ...,
           1.532779e+00,  1.469359e+00,  3.781625e-01],
         [ 1.764052e+00,  1.764052e+00,  9.787380e-01, ...,...
 y: array([[[[ 1.764052e+00,  1.764052e+00,  9.787380e-01, ...,
           1.532779e+00,  1.469359e+00,  3.781625e-01],
         [ 1.764052e+00,  1.764052e+00,  9.787380e-01, ...,...

======================================================================
FAIL: test_maxpool_2d_same_lower_cuda (__main__.OnnxBackendNodeModelTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 248, in device_test_func
    return test_func(*args, device=device, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 313, in run
    atol=model_test.atol)
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 178, in assert_similar_outputs
    atol=atol)
  File ""/usr/local/lib/python3.6/dist-packages/numpy/testing/_private/utils.py"", line 1533, in assert_allclose
    verbose=verbose, header=header, equal_nan=equal_nan)
  File ""/usr/local/lib/python3.6/dist-packages/numpy/testing/_private/utils.py"", line 846, in assert_array_compare
    raise AssertionError(msg)
AssertionError:
Not equal to tolerance rtol=0.001, atol=1e-07

Mismatched elements: 35 / 3072 (1.14%)
Max absolute difference: 1.6961312
Max relative difference: 0.
 x: array([[[[ 1.764052e+00,  1.764052e+00,  9.787380e-01, ...,
           1.532779e+00,  1.469359e+00,  3.781625e-01],
         [ 1.764052e+00,  1.764052e+00,  9.787380e-01, ...,...
 y: array([[[[ 1.764052e+00,  1.764052e+00,  9.787380e-01, ...,
           1.532779e+00,  1.469359e+00,  3.781625e-01],
         [ 1.764052e+00,  1.764052e+00,  9.787380e-01, ...,...

======================================================================
FAIL: test_maxpool_2d_same_upper_cpu (__main__.OnnxBackendNodeModelTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 248, in device_test_func
    return test_func(*args, device=device, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 313, in run
    atol=model_test.atol)
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 178, in assert_similar_outputs
    atol=atol)
  File ""/usr/local/lib/python3.6/dist-packages/numpy/testing/_private/utils.py"", line 1533, in assert_allclose
    verbose=verbose, header=header, equal_nan=equal_nan)
  File ""/usr/local/lib/python3.6/dist-packages/numpy/testing/_private/utils.py"", line 846, in assert_array_compare
    raise AssertionError(msg)
AssertionError:
Not equal to tolerance rtol=0.001, atol=1e-07

Mismatched elements: 37 / 3072 (1.2%)
Max absolute difference: 1.2028884
Max relative difference: 0.
 x: array([[[[ 1.764052,  0.978738,  2.240893, ...,  1.469359,  0.378163,
           0.378163],
         [ 0.177426, -0.347912,  0.462782, ...,  0.976639,  0.706573,...
 y: array([[[[ 1.764052,  0.978738,  2.240893, ...,  1.469359,  0.378163,
           0.378163],
         [ 0.177426, -0.347912,  0.462782, ...,  0.976639,  0.706573,...

======================================================================
FAIL: test_maxpool_2d_same_upper_cuda (__main__.OnnxBackendNodeModelTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 248, in device_test_func
    return test_func(*args, device=device, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 313, in run
    atol=model_test.atol)
  File ""/usr/local/lib/python3.6/dist-packages/onnx/backend/test/runner/__init__.py"", line 178, in assert_similar_outputs
    atol=atol)
  File ""/usr/local/lib/python3.6/dist-packages/numpy/testing/_private/utils.py"", line 1533, in assert_allclose
    verbose=verbose, header=header, equal_nan=equal_nan)
  File ""/usr/local/lib/python3.6/dist-packages/numpy/testing/_private/utils.py"", line 846, in assert_array_compare
    raise AssertionError(msg)
AssertionError:
Not equal to tolerance rtol=0.001, atol=1e-07

Mismatched elements: 37 / 3072 (1.2%)
Max absolute difference: 1.2028884
Max relative difference: 0.
 x: array([[[[ 1.764052,  0.978738,  2.240893, ...,  1.469359,  0.378163,
           0.378163],
         [ 0.177426, -0.347912,  0.462782, ...,  0.976639,  0.706573,...
 y: array([[[[ 1.764052,  0.978738,  2.240893, ...,  1.469359,  0.378163,
           0.378163],
         [ 0.177426, -0.347912,  0.462782, ...,  0.976639,  0.706573,...

----------------------------------------------------------------------
Ran 1114 tests in 2.126s

```
","{""url"": ""https://api.github.com/repos/apache/singa/issues/744/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/744,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0NjQxODc5OA==,singa,646418798,744,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-06-19T03:44:48Z,2020-06-19T03:44:48Z,"oh, sorry, some error is too large in some test.

Those test case will need to be fixed, e.g.
test_averagepool_2d_same_lower_cpu
Max absolute difference: 1.3230393
Max relative difference: 3.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0NjQxODc5OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/744,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0NjczMjAwMQ==,singa,646732001,744,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-06-19T16:30:26Z,2020-06-19T16:30:26Z,"@chrishkchris I have fixed the average pool and max pool issues above in  https://github.com/apache/singa/pull/746

However, for the equal, I found this is because there is some error when we do the `sub` operator for int32 input:

for example for input:

```
A = np.array([[[17, 4, 9, 22, 18], [-9, 9, -1, -1, 4], [1, 14, 7, 1, 4],
                [3, 14, -2, 3, -8]],
                [[-25, 6, 8, -7, 22], [-14, 0, -1, 15, 14],
                [1, 3, -8, -19, -3], [1, 12, 12, -3, -3]],
                [[-10, -14, -17, 19, -5], [-4, -12, 7, -16, -2],
                [-8, 3, -5, -11, 0], [4, 0, 3, -6, -3]]],
                    dtype=np.int32)
B = np.array([[[-6, -3, -8, -17, 1], [-4, -16, 4, -9, 0],
                [7, 1, 11, -12, 4], [-6, -8, -5, -3, 0]],
                [[-11, 9, 4, -15, 14], [18, 11, -1, -10, 10],
                [-4, 12, 2, 9, 3], [7, 0, 17, 1, 4]],
                [[18, -13, -12, 9, -11], [19, -4, -7, 19, 14],
                [18, 9, -8, 19, -2], [8, 9, -1, 6, 9]]],
                    dtype=np.int32)
```
The result of `singa.__sub__(a, b)` is:

```
[[[         -6          -3          -8         -17          17]
  [         -9          -3          -1          -1           3]
  [         -6          -3          -8         -17           3]
  [         -6          -3          -2         -17          -8]]

 [[        -25          -3          -8          -7          21]
  [        -14          -3          -1         -17          13]
  [         -6          -3          -8         -19          -3]
  [         -6          -3          -8          -3          -3]]

 [[        -10         -14         -17         -17          -5]
  [         -4         -12          -8         -16          -2]
  [         -8          -3          -5         -11 -2147483647]
  [         -6          -3          -8          -6          -3]]]
Fs[[[         -6          -3          -8         -17          17]
  [         -9         -16          -1          -1           4]
  [-2147483642          13 -2147483644         -12           0]
  [         -6          -8          -2          -3          -8]]

 [[        -25 -2147483645           4          -7           8]
  [        -14 -2147483637          -1         -10           4]
  [         -4 -2147483639          -8         -19          -3]
  [-2147483642          12 -2147483643          -3          -3]]

 [[        -10         -14         -17          10          -5]
  [         -4         -12          -7         -16          -2]
  [         -8 -2147483642          -5         -11          -2]
  [-2147483644 -2147483639          -1          -6          -3]]]
```

The correct result should be:
```
[[[ 23,   7,  17,  39,  17],
        [ -5,  25,  -5,   8,   4],
        [ -6,  13,  -4,  13,   0],
        [  9,  22,   3,   6,  -8]],

       [[-14,  -3,   4,   8,   8],
        [-32, -11,   0,  25,   4],
        [  5,  -9, -10, -28,  -6],
        [ -6,  12,  -5,  -4,  -7]],

       [[-28,  -1,  -5,  10,   6],
        [-23,  -8,  14, -35, -16],
        [-26,  -6,   3, -30,   2],
        [ -4,  -9,   4, -12, -12]]]
```

@dcslin  can we fix it?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY0NjczMjAwMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/744,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY1NzMzOTgzOA==,singa,657339838,744,NA,dcslin,13751447,Shicong,,NA,2020-07-13T03:32:04Z,2020-07-13T03:32:04Z,"> @chrishkchris I have fixed the average pool and max pool issues above in #746
> 
> However, for the equal, I found this is because there is some error when we do the `sub` operator for int32 input:
> 
> for example for input:
> 
> ```
> A = np.array([[[17, 4, 9, 22, 18], [-9, 9, -1, -1, 4], [1, 14, 7, 1, 4],
>                 [3, 14, -2, 3, -8]],
>                 [[-25, 6, 8, -7, 22], [-14, 0, -1, 15, 14],
>                 [1, 3, -8, -19, -3], [1, 12, 12, -3, -3]],
>                 [[-10, -14, -17, 19, -5], [-4, -12, 7, -16, -2],
>                 [-8, 3, -5, -11, 0], [4, 0, 3, -6, -3]]],
>                     dtype=np.int32)
> B = np.array([[[-6, -3, -8, -17, 1], [-4, -16, 4, -9, 0],
>                 [7, 1, 11, -12, 4], [-6, -8, -5, -3, 0]],
>                 [[-11, 9, 4, -15, 14], [18, 11, -1, -10, 10],
>                 [-4, 12, 2, 9, 3], [7, 0, 17, 1, 4]],
>                 [[18, -13, -12, 9, -11], [19, -4, -7, 19, 14],
>                 [18, 9, -8, 19, -2], [8, 9, -1, 6, 9]]],
>                     dtype=np.int32)
> ```
> 
> The result of `singa.__sub__(a, b)` is:
> 
> ```
> [[[         -6          -3          -8         -17          17]
>   [         -9          -3          -1          -1           3]
>   [         -6          -3          -8         -17           3]
>   [         -6          -3          -2         -17          -8]]
> 
>  [[        -25          -3          -8          -7          21]
>   [        -14          -3          -1         -17          13]
>   [         -6          -3          -8         -19          -3]
>   [         -6          -3          -8          -3          -3]]
> 
>  [[        -10         -14         -17         -17          -5]
>   [         -4         -12          -8         -16          -2]
>   [         -8          -3          -5         -11 -2147483647]
>   [         -6          -3          -8          -6          -3]]]
> Fs[[[         -6          -3          -8         -17          17]
>   [         -9         -16          -1          -1           4]
>   [-2147483642          13 -2147483644         -12           0]
>   [         -6          -8          -2          -3          -8]]
> 
>  [[        -25 -2147483645           4          -7           8]
>   [        -14 -2147483637          -1         -10           4]
>   [         -4 -2147483639          -8         -19          -3]
>   [-2147483642          12 -2147483643          -3          -3]]
> 
>  [[        -10         -14         -17          10          -5]
>   [         -4         -12          -7         -16          -2]
>   [         -8 -2147483642          -5         -11          -2]
>   [-2147483644 -2147483639          -1          -6          -3]]]
> ```
> 
> The correct result should be:
> 
> ```
> [[[ 23,   7,  17,  39,  17],
>         [ -5,  25,  -5,   8,   4],
>         [ -6,  13,  -4,  13,   0],
>         [  9,  22,   3,   6,  -8]],
> 
>        [[-14,  -3,   4,   8,   8],
>         [-32, -11,   0,  25,   4],
>         [  5,  -9, -10, -28,  -6],
>         [ -6,  12,  -5,  -4,  -7]],
> 
>        [[-28,  -1,  -5,  10,   6],
>         [-23,  -8,  14, -35, -16],
>         [-26,  -6,   3, -30,   2],
>         [ -4,  -9,   4, -12, -12]]]
> ```
> 
> @dcslin can we fix it?

this int subtraction testing is fixed and added in https://github.com/apache/singa/pull/763","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY1NzMzOTgzOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/744,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY1NzQzMDQzMg==,singa,657430432,744,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-07-13T09:11:50Z,2020-07-13T09:11:50Z,solved by #763,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY1NzQzMDQzMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/756,https://api.github.com/repos/apache/singa/issues/756,singa,648607647,756,Raise and handle exceptions in CPP code,nudles,3797447,Wei Wang,,OPEN,2020-07-01T01:40:59Z,2020-07-01T01:40:59Z,"Currently, we abort the program when any check fails via glog's CHECK functions.
We do not catch any exceptions like memory exception or cudnn exceptions.

As a result, the program will abort or crash whenever there is an error or exception, which sometimes shutdown the jupyter notebook or colab notebook when we run the code in the notebook environment.

This ticket is to raise and handle exceptions in CPP code.

ref: http://www.swig.org/Doc3.0/SWIGDocumentation.html#Customization_exception","{""url"": ""https://api.github.com/repos/apache/singa/issues/756/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/776,https://api.github.com/repos/apache/singa/issues/776,singa,671870663,776,Add Erf operator in c++ end,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,CLOSED,2020-08-03T07:38:20Z,2020-09-07T11:23:37Z,"@dcslin Hi, shicong, there is a new NLP model we can support and it requires a new operator called `Erf`. It looks like the `tanh`. Can you help me to add it to the c++ end? 

I guess you can import the `math.h` to call the `erf`, please refer to this [doc](http://www.cplusplus.com/reference/cmath/erf/)","{""url"": ""https://api.github.com/repos/apache/singa/issues/776/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/776,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY2ODM4NDkzMA==,singa,668384930,776,NA,dcslin,13751447,Shicong,,NA,2020-08-04T05:18:54Z,2020-08-04T05:18:54Z,Hi @joddiy #777 will this work for you?,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY2ODM4NDkzMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/784,https://api.github.com/repos/apache/singa/issues/784,singa,688649395,784,Preparation for V3.1 release,nudles,3797447,Wei Wang,,CLOSED,2020-08-30T04:12:25Z,2020-11-22T10:45:50Z,"I propose to release a minor version to reflect the changes since v3.0.

Please test the following items and check the documentation if they are done.
  - [x] new onnx models and operators   @joddiy 
  - [x] distributed training @chrishkchris 
  - [x] computational graph to support RNN @chrishkchris 
  - [x] website update @nudles
  - [x] pypi package generation @nudles  
  - [x] github workflow for code quality and coverage management @moazreyad 
  - [x] tensor APIs @dcslin 
  - [x] new autograd operators @joddiy 
  - [ ] anything else?

Here is the checklist and [steps](http://www.apache.org/dev/release-publishing.html)
- [ ] Select a release manager. The release manager (RM) is the coordinator for the release process. It is the RM's signature (.asc) that is uploaded together with the release. The RM generates KEY (RSA 4096-bit) and uploads it to a public key server. The RM needs to get his key endorsed (signed) by other Apache user, to be connected to the web of trust. He should first ask the mentor to help signing his key. [How to generate the key](http://www.apache.org/dev/release-signing.html)?

- [ ] Check license. [FAQ](https://www.apache.org/legal/src-headers.html#faq-docs); [SINGA Issue](https://issues.apache.org/jira/projects/SINGA/issues/SINGA-447)
  - [ ] the codebase does not include third-party code which is not compatible to APL;
  - [ ] The dependencies are compatible with APL. GNU-like licenses are NOT compatible; 
  - [ ] All source files written by us MUST include the Apache license header: http://www.apache.org/legal/src-headers.html. There's a script in there which helps propagating the header to all files.
  - [ ] Update the LICENSE file. If we include any third party code in the release package which is not APL, must state it at the end of the [LICENSE](https://github.com/apache/singa/blob/master/LICENSE#L448) file and include the license boilerplate in the original file.

- [ ] Bump the version. Check code and documentation
  - [ ] The build process is error-free.
  - [ ] Unit tests are included (as much as possible)
  - [ ] Conda packages run without errors. 
  - [ ] The online documentation on the Apache website is up to date.

- [ ] Prepare the RELEASE_NOTES file. Include the following items, Introduction, Features, Bugs (link to JIRA or Github PR), Changes, Dependency list, Incompatibility issues. Follow this [example](http://commons.apache.org/proper/commons-digester/commons-digester-3.0/RELEASE-NOTES.txt). 

- [ ] Prepare DISCLAIMER file. Modify from the [template](http://incubator.apache.org/guides/branding.html#disclaimers)

- [x] Package the release candidate. The release should be packaged into : apache-singa-VERSION.tar.gz. The release should not include any binary files including git files. Upload the release to for [stage](https://dist.apache.org/repos/dist/dev/VERSION/). The tar file, signature, KEY and SHA256 checksum file should be included. MD5 is no longer used. Policy is [here](http://www.apache.org/dev/release-distribution#sigs-and-sums)
    * apache-singa-VERSION.tar.gz
    * KEY
    * XX.acs
    * .SHA256

- [x] Call for vote by sending an email
    ``` 
    To: dev@singa.apache.org
    Subject: [VOTE] Release apache-singa-X.Y.Z (release candidate N)

    Hi all,

    I have created a build for Apache SINGA X.Y.Z, release candidate N.
    The artifacts to be voted on are located here:  xxxx
    The hashes of the artifacts are as follows: xxx
    Release artifacts are signed with the following key: xxx
    Please vote on releasing this package. The vote is open for at least 72 hours and passes if a majority of at least three +1 votes are cast.

   [ ] +1 Release this package as Apache SINGA X.Y.Z
   [ ] 0 I don't feel strongly about it, but I'm okay with the release
   [ ] -1 Do not release this package because...

   Here is my vote:
   +1 
    ```

- [x] Wait at least 48 hours for test responses. Any PMC, committer or contributor can test features for releasing, and feedback. Everyone should check these before vote +1. If the vote passes, then send the result email. Otherwise, repeat from the beginning.
    ```
    Subject: [RESULT] [VOTE] Release apache-singa-X.Y.Z (release candidate N)
    To: dev@singa.apache.org
 
    Thanks to everyone who has voted and given their comments. The tally is as follows.
 
    N binding +1s:
    <names>
 
    N non-binding +1s:
    <names>
 
    No 0s or -1s.
 
     I am delighted to announce that the proposal to release Apache SINGA X.Y.Zhas passed.
     ````

- [ ] Upload the package for [distribution](http://www.apache.org/dev/release-publishing.html#distribution) to https://dist.apache.org/repos/dist/release/VERSION/. 

- [ ] Update the Download page of SINGA website. The tar.gz file MUST be downloaded from mirror, using closer.cgi script; other artifacts MUST be downloaded from main Apache site. More details [here](http://www.apache.org/dev/release-download-pages.html). Some feedback we got during the previous releases:  ""Download pages must only link to formal releases, so must not include links to GitHub."",  ""Links to KEYS, sigs and hashes must not use dist.apache.org; instead use https://www.apache.org/dist/singa/...;"", ""Also you only need one KEYS link, and there should be a description of how to use KEYS + sig or hash to verify the downloads.""

- [ ] Remove the RC tag and compile the conda packages.

- [ ] Publish the release information. 
    ```
    To: announce@apache.org, dev@singa.apache.org 
    Subject: [ANNOUNCE] Apache SINGA X.Y.Z released

    We are pleased to announce that SINGA X.Y.Z is released.

    SINGA is a general distributed deep learning platform for training big deep learning models over large datasets. 
    The release is available at: http://singa.apache.org/downloads.html
    The main features of this release include XXX
    We look forward to hearing your feedback, suggestions, and contributions to the project.

    On behalf of the SINGA team, {SINGA Team Member Name}
    ````














","{""url"": ""https://api.github.com/repos/apache/singa/issues/784/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/784,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY4MzM3ODUxNg==,singa,683378516,784,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-08-30T05:28:11Z,2020-08-30T05:28:11Z,"got it, thanks! I will test the distributed training and computational graph to support RNN, also check the corresponding documentation.

update on 9/1: submitted some fix to https://github.com/apache/singa/pull/785 , some test result of the distributed training is pasted on that PR

update on 9/3: worked with Rulin @XJDKC to fix the graph operation in https://github.com/apache/singa/pull/787

update on 9/8: updated the documentation of dist train and comp graph on PR https://github.com/apache/singa-doc/pull/27

update on 9/27: added the documentation of Optimizer, Time Profiling function, and Model Checkpoint Save Load Function on PR https://github.com/apache/singa-doc/pull/31","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY4MzM3ODUxNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/784,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY4Nzk4ODcyMA==,singa,687988720,784,NA,moazreyad,2278792,Moaz Reyad,moazreyad@gmail.com,NA,2020-09-07T02:35:54Z,2020-09-07T02:35:54Z,"The workflow for coverage is ready in #788 and Travis CI can be removed now as discussed in #790.

More workflows can be made to automate packaging (pypi, debian, etc.) and to automate website updates. ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY4Nzk4ODcyMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/784,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY5ODA4ODk5OA==,singa,698088998,784,NA,nudles,3797447,Wei Wang,,NA,2020-09-24T03:26:48Z,2020-09-24T03:26:48Z,"Please add details about the changes that you have made since v3.0.0. Follow the [release note](https://github.com/apache/singa/blob/master/RELEASE_NOTES)
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY5ODA4ODk5OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/784,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY5ODA5MzY4MQ==,singa,698093681,784,NA,dcslin,13751447,Shicong,,NA,2020-09-24T03:46:07Z,2020-09-24T03:46:07Z,"* BiLSTM model on [InsuranceQA](https://github.com/shuzi/insuranceQA) example training script. The baseline model is inspired by Tan, Ming, et al. ""Lstm-based deep learning models for non-factoid answer selection."" arXiv preprint arXiv:1511.04108 (2015).

* Tensor Refactoring and Enhancement
  - Tensor transformation (reshape, transpose) supports up to 6 dimensions.
  - Implemented traverse_unary_transform in Cuda backend, which is similar to CPP backend one.
  - Added tensor operation erf, rounde (round even).
  - Fix Tensor operation Mult on Broadcasting use cases.
  - Gaussian function on Tensor now can run on Tensor with odd size.

* autograd
  - Added some sanity check on autograd input to prevent fatal error caused by unexpected input shape.
  - Updated a testing helper function gradients() in autograd to lookup param gradient by param python object id for testing purpose.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY5ODA5MzY4MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/784,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY5ODk2ODYxNA==,singa,698968614,784,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-09-25T14:40:25Z,2020-09-25T14:40:25Z,"  * 12 new operators are added into the autograd module: CosSim, DepthToSpace, Embedding, Erf, Expand, Floor, Pad, Round, Rounde, SpaceToDepth, UpSample, Where.

  * 2 layers are added into layer module: Embedding, Gemm.

  * 9 new operators are added to sonnx module for both backend and frontend: 
    [DepthToSpace](https://github.com/onnx/onnx/blob/master/docs/Operators.md#DepthToSpace), 
    [Erf](https://github.com/onnx/onnx/blob/master/docs/Operators.md#Erf), 
    [Expand](https://github.com/onnx/onnx/blob/master/docs/Operators.md#Expand), 
    [Floor](https://github.com/onnx/onnx/blob/master/docs/Operators.md#Floor), 
    [Pad](https://github.com/onnx/onnx/blob/master/docs/Operators.md#Pad), 
    [Round](https://github.com/onnx/onnx/blob/master/docs/Operators.md#Round), 
    [SpaceToDepth](https://github.com/onnx/onnx/blob/master/docs/Operators.md#SpaceToDepth), 
    [UpSample](https://github.com/onnx/onnx/blob/master/docs/Operators.md#UpSample), 
    [Where](https://github.com/onnx/onnx/blob/master/docs/Operators.md#Where), 
    Their tests are added as well.

  * Some ONNX models are imported into SINGA, including 
    [DenseNet121](https://github.com/onnx/models/blob/master/vision/classification/densenet-121), 
    [ShuffleNetv1](https://github.com/onnx/models/blob/master/vision/classification/shufflenet), 
    [ShuffleNetv2](https://github.com/onnx/models/blob/master/vision/classification/shufflenet), 
    [SqueezeNet](https://github.com/onnx/models/blob/master/vision/classification/squeezenet), 
    [VGG19](https://github.com/onnx/models/blob/master/vision/classification/vgg), 
    [GPT2](https://github.com/onnx/models/blob/master/text/machine_comprehension/gpt-2), 
    [RoBERTa](https://github.com/onnx/models/blob/master/text/machine_comprehension/roberta),  

  * Reconstruct soonx, 
	- Support creating operators from both `layer` and `autograd`.
	- Re-write `SingaRep` to provide a more powerful intermediate representation of SINGA.
	- Add a `SONNXModel` which implements from `Model` to provide uniform API and features.
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY5ODk2ODYxNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/784,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyNzE2MDYwOQ==,singa,727160609,784,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-11-14T07:30:50Z,2020-11-14T07:30:50Z,3.1 already released,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyNzE2MDYwOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/784,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDczMTYzNDU5Nw==,singa,731634597,784,NA,moazreyad,2278792,Moaz Reyad,moazreyad@gmail.com,NA,2020-11-21T20:47:55Z,2020-11-21T20:47:55Z,"> 3.1 already released

I see that there is [vote result email in singa-dev mail list](https://mail-archives.apache.org/mod_mbox/singa-dev/202010.mbox/%3CCAJz0iLunmJ5pqwggCejG2OgzehvLF%3DogEqDFC-kPziV%2BPB%3D37w%40mail.gmail.com%3E). However, I don't see the `Publish the release information.` step. 

An email ""[ANNOUNCE] Apache SINGA X.Y.Z released"" should be sent to announce@apache.org, dev@singa.apache.org  as given above in the check list of release tasks. This step is required to complete the release process.

Note also that the email body says ""The release is available at: http://singa.apache.org/downloads.html"", however this page does not exist in the new website. We need to have downloads.html page because it is like a standard in Apache projects to have ProjectName.apache.org/downloads.html . The page `http://singa.apache.org/docs/download-singa/` does not follow the standard URLs of the Apache projects, and it also does not contain the 3.1 release.

Finally, it will be nice to update the [wikipedia page of singa](https://en.wikipedia.org/wiki/Apache_SINGA) with the new version information.
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDczMTYzNDU5Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/784,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDczMTY5OTc4NA==,singa,731699784,784,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-11-22T05:15:18Z,2020-11-22T05:15:18Z,"Now I added a redirect link so that http://singa.apache.org/downloads.html is working now. It also has the 3.1 release. Does it look better now?

> Note also that the email body says ""The release is available at: http://singa.apache.org/downloads.html"", however this page does not exist in the new website. We need to have downloads.html page because it is like a standard in Apache projects to have ProjectName.apache.org/downloads.html . The page http://singa.apache.org/docs/download-singa/ does not follow the standard URLs of the Apache projects, and it also does not contain the 3.1 release.

","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDczMTY5OTc4NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/784,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDczMTcwNTMxOQ==,singa,731705319,784,NA,nudles,3797447,Wei Wang,,NA,2020-11-22T06:24:38Z,2020-11-22T06:24:38Z,"I have sent the announcement email.
Thanks for the reminder.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDczMTcwNTMxOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/784,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDczMTcyODYzNg==,singa,731728636,784,NA,moazreyad,2278792,Moaz Reyad,moazreyad@gmail.com,NA,2020-11-22T10:45:50Z,2020-11-22T10:45:50Z,Great. I updated the infobox of the wikipedia page. I think we can close the issue now.,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDczMTcyODYzNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/791,https://api.github.com/repos/apache/singa/issues/791,singa,694725020,791,singa-gpu Anaconda package has no Module class,tinyAdapter,8264895,tinyAdapter,tinyadapter@outlook.com,CLOSED,2020-09-07T05:41:27Z,2020-11-19T10:29:24Z,"I'm trying to test some examples of SINGA. However, when I ran the examples, the `singa-gpu` package throwed an error that it could not find Module class.

I reproduce this error by the following commands:

```bash
(base) user@xgpe3:~$ conda activate sg37
(sg37) user@xgpe3:~$ conda install -c nusdbsystem -c conda-forge singa-gpu=3.0.0
Collecting package metadata (current_repodata.json): done
Solving environment: failed with initial frozen solve. Retrying with flexible solve.
Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.
Collecting package metadata (repodata.json): done
Solving environment: done


==> WARNING: A newer version of conda exists. <==
  current version: 4.8.3
  latest version: 4.8.4

Please update conda by running

    $ conda update -n base -c defaults conda



## Package Plan ##

  environment location: /path/to/miniconda3/envs/sg37

  added / updated specs:
    - singa-gpu=3.0.0


The following packages will be downloaded:

    package                    |            build
    ---------------------------|-----------------
    importlib_metadata-1.7.0   |                0           3 KB  conda-forge
    zipp-3.1.0                 |             py_0          10 KB  conda-forge
    ------------------------------------------------------------
                                           Total:          13 KB

The following NEW packages will be INSTALLED:

  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-1_llvm
  attrs              conda-forge/noarch::attrs-20.2.0-pyh9f0ad1d_0
  cudatoolkit        pkgs/main/linux-64::cudatoolkit-10.0.130-0
  cudnn              pkgs/main/linux-64::cudnn-7.6.5-cuda10.0_0
  deprecated         conda-forge/noarch::deprecated-1.2.7-py_0
  dnnl               nusdbsystem/linux-64::dnnl-1.1-build
  freetype           conda-forge/linux-64::freetype-2.10.2-he06d7ca_0
  future             conda-forge/linux-64::future-0.18.2-py37hc8dfbb8_1
  glog               conda-forge/linux-64::glog-0.3.5-hf484d3e_1001
  importlib-metadata conda-forge/linux-64::importlib-metadata-1.7.0-py37hc8dfbb8_0
  importlib_metadata conda-forge/noarch::importlib_metadata-1.7.0-0
  iniconfig          conda-forge/noarch::iniconfig-1.0.1-pyh9f0ad1d_0
  jpeg               conda-forge/linux-64::jpeg-9d-h516909a_0
  lcms2              conda-forge/linux-64::lcms2-2.11-hbd6801e_0
  libblas            conda-forge/linux-64::libblas-3.8.0-16_openblas
  libcblas           conda-forge/linux-64::libcblas-3.8.0-16_openblas
  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-7.5.0-hdf63c60_16
  liblapack          conda-forge/linux-64::liblapack-3.8.0-16_openblas
  libopenblas        conda-forge/linux-64::libopenblas-0.3.9-h5ec1e0e_0
  libpng             conda-forge/linux-64::libpng-1.6.37-hed695b0_2
  libprotobuf        conda-forge/linux-64::libprotobuf-3.9.2-h8b12597_0
  libtiff            conda-forge/linux-64::libtiff-4.1.0-hc7e4089_6
  libwebp-base       conda-forge/linux-64::libwebp-base-1.1.0-h516909a_3
  llvm-openmp        conda-forge/linux-64::llvm-openmp-10.0.1-hc9558a2_0
  lz4-c              conda-forge/linux-64::lz4-c-1.9.2-he1b5a44_3
  more-itertools     conda-forge/noarch::more-itertools-8.5.0-py_0
  numpy              conda-forge/linux-64::numpy-1.16.5-py37h95a1406_0
  olefile            conda-forge/noarch::olefile-0.46-py_0
  onnx               conda-forge/linux-64::onnx-1.6.0-py37he1b5a44_0
  packaging          conda-forge/noarch::packaging-20.4-pyh9f0ad1d_0
  pillow             conda-forge/linux-64::pillow-7.2.0-py37h718be6c_1
  pluggy             conda-forge/linux-64::pluggy-0.13.1-py37hc8dfbb8_2
  protobuf           conda-forge/linux-64::protobuf-3.9.2-py37he1b5a44_1
  py                 conda-forge/noarch::py-1.9.0-pyh9f0ad1d_0
  pyparsing          conda-forge/noarch::pyparsing-2.4.7-pyh9f0ad1d_0
  pytest             conda-forge/linux-64::pytest-6.0.1-py37hc8dfbb8_0
  python_abi         conda-forge/linux-64::python_abi-3.7-1_cp37m
  singa              nusdbsystem/linux-64::singa-3.0.0-cudnn7.6.5_cuda10.0_py37
  singa-gpu          nusdbsystem/linux-64::singa-gpu-3.0.0-py37
  six                conda-forge/noarch::six-1.15.0-pyh9f0ad1d_0
  toml               conda-forge/noarch::toml-0.10.1-pyh9f0ad1d_0
  tqdm               conda-forge/noarch::tqdm-4.48.2-pyh9f0ad1d_0
  wrapt              conda-forge/linux-64::wrapt-1.12.1-py37h8f50634_1
  zipp               conda-forge/noarch::zipp-3.1.0-py_0
  zstd               conda-forge/linux-64::zstd-1.4.5-h6597ccf_2

The following packages will be UPDATED:

  libgcc-ng           pkgs/main::libgcc-ng-9.1.0-hdf63c60_0 --> conda-forge::libgcc-ng-9.3.0-h24d8f2e_16
  openssl              pkgs/main::openssl-1.1.1g-h7b6447c_0 --> conda-forge::openssl-1.1.1g-h516909a_1

The following packages will be SUPERSEDED by a higher-priority channel:

  _libgcc_mutex           pkgs/main::_libgcc_mutex-0.1-main --> conda-forge::_libgcc_mutex-0.1-conda_forge
  ca-certificates    pkgs/main::ca-certificates-2020.7.22-0 --> conda-forge::ca-certificates-2020.6.20-hecda079_0
  certifi               pkgs/main::certifi-2020.6.20-py37_0 --> conda-forge::certifi-2020.6.20-py37hc8dfbb8_0


Proceed ([y]/n)? y


Downloading and Extracting Packages
importlib_metadata-1 | 3 KB      | #################################################################################### | 100%
zipp-3.1.0           | 10 KB     | #################################################################################### | 100%
Preparing transaction: done
Verifying transaction: done
Executing transaction: done
(sg37) user@xgpe3:~$ python -c ""from singa.module import Module""
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
ModuleNotFoundError: No module named 'singa.module'
(sg37) user@xgpe3:~$
```

By contrast, with `singa-cpu` package, everything seems fine.

```bash
(base) user@xgpe3:~$ conda activate sc37
(sc37) user@xgpe3:~$ conda install -c nusdbsystem -c conda-forge singa-cpu=3.0.0
Collecting package metadata (current_repodata.json): done
Solving environment: failed with initial frozen solve. Retrying with flexible solve.
Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.
Collecting package metadata (repodata.json): done
Solving environment: done


==> WARNING: A newer version of conda exists. <==
  current version: 4.8.3
  latest version: 4.8.4

Please update conda by running

    $ conda update -n base -c defaults conda



## Package Plan ##

  environment location: /path/to/miniconda3/envs/sc37

  added / updated specs:
    - singa-cpu=3.0.0


The following packages will be downloaded:

    package                    |            build
    ---------------------------|-----------------
    singa-3.0.0                |         cpu_py37        22.2 MB  nusdbsystem
    singa-cpu-3.0.0            |             py37           4 KB  nusdbsystem
    ------------------------------------------------------------
                                           Total:        22.2 MB

The following NEW packages will be INSTALLED:

  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-1_llvm
  deprecated         conda-forge/noarch::deprecated-1.2.7-py_0
  dnnl               nusdbsystem/linux-64::dnnl-1.1-build
  freetype           conda-forge/linux-64::freetype-2.10.2-he06d7ca_0
  future             conda-forge/linux-64::future-0.18.2-py37hc8dfbb8_1
  glog               conda-forge/linux-64::glog-0.3.5-hf484d3e_1001
  jpeg               conda-forge/linux-64::jpeg-9d-h516909a_0
  lcms2              conda-forge/linux-64::lcms2-2.11-hbd6801e_0
  libblas            conda-forge/linux-64::libblas-3.8.0-16_openblas
  libcblas           conda-forge/linux-64::libcblas-3.8.0-16_openblas
  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-7.5.0-hdf63c60_16
  liblapack          conda-forge/linux-64::liblapack-3.8.0-16_openblas
  libopenblas        conda-forge/linux-64::libopenblas-0.3.9-h5ec1e0e_0
  libpng             conda-forge/linux-64::libpng-1.6.37-hed695b0_2
  libprotobuf        conda-forge/linux-64::libprotobuf-3.9.2-h8b12597_0
  libtiff            conda-forge/linux-64::libtiff-4.1.0-hc7e4089_6
  libwebp-base       conda-forge/linux-64::libwebp-base-1.1.0-h516909a_3
  llvm-openmp        conda-forge/linux-64::llvm-openmp-10.0.1-hc9558a2_0
  lz4-c              conda-forge/linux-64::lz4-c-1.9.2-he1b5a44_3
  numpy              conda-forge/linux-64::numpy-1.16.5-py37h95a1406_0
  olefile            conda-forge/noarch::olefile-0.46-py_0
  onnx               conda-forge/linux-64::onnx-1.6.0-py37he1b5a44_0
  pillow             conda-forge/linux-64::pillow-7.2.0-py37h718be6c_1
  protobuf           conda-forge/linux-64::protobuf-3.9.2-py37he1b5a44_1
  python_abi         conda-forge/linux-64::python_abi-3.7-1_cp37m
  singa              nusdbsystem/linux-64::singa-3.0.0-cpu_py37
  singa-cpu          nusdbsystem/linux-64::singa-cpu-3.0.0-py37
  six                conda-forge/noarch::six-1.15.0-pyh9f0ad1d_0
  tqdm               conda-forge/noarch::tqdm-4.48.2-pyh9f0ad1d_0
  wrapt              conda-forge/linux-64::wrapt-1.12.1-py37h8f50634_1
  zstd               conda-forge/linux-64::zstd-1.4.5-h6597ccf_2

The following packages will be UPDATED:

  libgcc-ng           pkgs/main::libgcc-ng-9.1.0-hdf63c60_0 --> conda-forge::libgcc-ng-9.3.0-h24d8f2e_16
  openssl              pkgs/main::openssl-1.1.1g-h7b6447c_0 --> conda-forge::openssl-1.1.1g-h516909a_1

The following packages will be SUPERSEDED by a higher-priority channel:

  _libgcc_mutex           pkgs/main::_libgcc_mutex-0.1-main --> conda-forge::_libgcc_mutex-0.1-conda_forge
  ca-certificates    pkgs/main::ca-certificates-2020.7.22-0 --> conda-forge::ca-certificates-2020.6.20-hecda079_0
  certifi               pkgs/main::certifi-2020.6.20-py37_0 --> conda-forge::certifi-2020.6.20-py37hc8dfbb8_0


Proceed ([y]/n)? y


Downloading and Extracting Packages
singa-cpu-3.0.0      | 4 KB      | #################################################################################### | 100%
singa-3.0.0          | 22.2 MB   | #################################################################################### | 100%
Preparing transaction: done
Verifying transaction: done
Executing transaction: done
(sc37) user@xgpe3:~$ python -c ""from singa.module import Module""
(sc37) user@xgpe3:~$
```

Is this a bug or just the way it goes?","{""url"": ""https://api.github.com/repos/apache/singa/issues/791/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/791,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY5MDgxODk1OA==,singa,690818958,791,NA,nudles,3797447,Wei Wang,,NA,2020-09-11T01:29:09Z,2020-09-11T01:29:09Z,"Hi, it is renamed to [Model](https://github.com/apache/singa/blob/dev/python/singa/model.py#L103).

You can try
```
from singa.model import Model
```","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY5MDgxODk1OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/791,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY5MDg0Mzk1OA==,singa,690843958,791,NA,tinyAdapter,8264895,tinyAdapter,tinyadapter@outlook.com,NA,2020-09-11T03:00:09Z,2020-09-11T03:00:09Z,"Thanks. By the way, does this mean that `singa-cpu` package is outdated?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY5MDg0Mzk1OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/791,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDczMDI3OTYzNw==,singa,730279637,791,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-11-19T10:29:23Z,2020-11-19T10:29:23Z,"We have released SINGA version 3.1, you can use the new package that already solved the problem","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDczMDI3OTYzNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/793,https://api.github.com/repos/apache/singa/issues/793,singa,696386086,793,Draft for ASF board report,nudles,3797447,Wei Wang,,CLOSED,2020-09-09T04:00:08Z,2020-09-18T01:44:17Z,"## Issues:
There are no issues requiring board attention

## Membership Data:
Apache SINGA was founded 2019-10-16 (a year ago)
There are currently 22 committers and 16 PMC members in this project.
The Committer-to-PMC ratio is roughly 3:2.

Community changes, past quarter:
- No new PMC members. Last addition was Chris Yeung on 2020-04-17.
- Zhang Zhaoqi was added as committer on 2020-07-01
- Rulin Xing was added as committer on 2020-06-23
- Shicong Lin was added as committer on 2020-06-26

## Project Activity:
The community is working on release v3.1, which include the following
features/changes:
1. generating wheel package for distributing SINGA on PyPI repo and
   simplifying the installation process.
2. moving from Travis CI to Github workflow for better integration with
   Github.
3. improving the computational graph to support RNN models
4. adding new operators to support more ONNX models
5. fixing some bugs.

## Community Health:
Overall, the community has slowed down a bit after releasing version 3.0. We
are still active in development for v3.1, with 52 PRs opened and 53 PRs
closed. The community is growing stably with 3 new committers joined since
last report.","{""url"": ""https://api.github.com/repos/apache/singa/issues/793/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/793,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY4OTM1NDExNg==,singa,689354116,793,NA,moazreyad,2278792,Moaz Reyad,moazreyad@gmail.com,NA,2020-09-09T07:06:37Z,2020-09-09T07:06:37Z,another added feature in this release is integrating C++ and Python code coverage with codecov.io in the development workflow.,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY4OTM1NDExNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/793,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY5NDU5OTI1MA==,singa,694599250,793,NA,nudles,3797447,Wei Wang,,NA,2020-09-18T01:44:17Z,2020-09-18T01:44:17Z,"I will add it in the next report.
thanks!","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY5NDU5OTI1MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/796,https://api.github.com/repos/apache/singa/issues/796,singa,701724472,796,codecov/project fail,nudles,3797447,Wei Wang,,CLOSED,2020-09-15T08:28:07Z,2020-09-18T01:43:08Z,Pls check https://github.com/apache/singa/pull/795/checks?check_run_id=1115935742,"{""url"": ""https://api.github.com/repos/apache/singa/issues/796/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/796,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY5MjYyMDYxMA==,singa,692620610,796,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-09-15T10:17:24Z,2020-09-15T10:17:24Z,@moazreyad It is very strange that the test analyzes the coverage on tensor.h in this PR which is totally unrelated,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY5MjYyMDYxMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/796,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY5MjY1OTEyNQ==,singa,692659125,796,NA,moazreyad,2278792,Moaz Reyad,moazreyad@gmail.com,NA,2020-09-15T11:38:45Z,2020-09-15T11:38:45Z,"There is a problem in this PR because it [installs singa in python 3.6 ](https://github.com/nudles/singa/blob/dev/.github/workflows/conda.yaml#L64) and [executes the test cases from python3.7/site-packages](https://github.com/nudles/singa/blob/dev/.github/workflows/conda.yaml#L66) folder which does not work. Please fix this different python versions problem.

Note also that the project coverage threshold can be set in [.codecov.yml](https://github.com/apache/singa/blob/dev/.codecov.yml) like [this](https://docs.codecov.io/docs/commit-status#project-status):

```
coverage:
  status:
    project:
      default:
        # basic
        target: auto
        threshold: 5%
```
The value of threshold can be chosen by the development team based on the quality needs. In the best case, every PR should not reduce the coverage because this means it either added code without test case or it removed (or disabled) the test cases for existing code. However, if the team think this is too strict requirement, we may choose the threshold to 5% or even more. But this means that a PR can be allowed to pass even if it reduces the code coverage too much. 

The PR #795 reduces the coverage by 4.97%, so setting the threshold to 5% should make it pass. But this is not recommended solution. We can use it only if the team thinks it is too strict to keep the coverage change always zero or positive. In this case, we may allow threshold of 1% or 2% to pass. But 5% seems high to me and it means there is a lot of code that was not tested and there is a problem. And thanks to the strict code coverage, we found the different python versions problem. Without the strict coverage check, may be this problem will be hidden and will cause other problems later.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY5MjY1OTEyNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/796,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY5Mzc4NDQ2MQ==,singa,693784461,796,NA,nudles,3797447,Wei Wang,,NA,2020-09-17T03:21:21Z,2020-09-17T03:21:21Z,"After fixing the python version issue, code coverage fails again..
I didn't change the source code in this PR #795 ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY5Mzc4NDQ2MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/796,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY5Mzc4Nzc0Nw==,singa,693787747,796,NA,nudles,3797447,Wei Wang,,NA,2020-09-17T03:34:09Z,2020-09-17T03:34:09Z,"Seems it does not provide the suggestions on how to improve the code coverage.
for example, #797 ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY5Mzc4Nzc0Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/796,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY5NDEyMTE0MA==,singa,694121140,796,NA,moazreyad,2278792,Moaz Reyad,moazreyad@gmail.com,NA,2020-09-17T09:43:13Z,2020-09-17T09:43:13Z,"> After fixing the python version issue, code coverage fails again..

The coverage is now decreased by 0.01% instead of 4.97%. It still fails because we did not specify a threshold, so any decrease any in the coverage will make test fails. To solve this problem, either add a small threshold like 0.1 % to allow small drops in coverage generally in all PRs, or leave the threshold decision to each pull request reviewer to decide if the decrease in the specific PR is fine and it can be merged or it is not fine and must be fixed.

> Seems it does not provide the suggestions on how to improve the code coverage.

Yes, it just reports the coverage results without suggestions on how to fix. This is similar to all the test cases which report the error but of course they do not usually suggest how to fix it. 

To improve the coverage, the developer needs to investigate more how to create the suitable test cases to cover his new code, or how not to prevent current test cases from running (like the problem that we had in #795). ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY5NDEyMTE0MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/796,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY5NDU5ODk3Mw==,singa,694598973,796,NA,nudles,3797447,Wei Wang,,NA,2020-09-18T01:43:07Z,2020-09-18T01:43:07Z,"Thanks for the explanation. 
I think we can let the reviewer to determine if the newly added code should be covered by unit tests.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDY5NDU5ODk3Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/802,https://api.github.com/repos/apache/singa/issues/802,singa,707938685,802,Adding GPU testing to Github workflows ,moazreyad,2278792,Moaz Reyad,moazreyad@gmail.com,OPEN,2020-09-24T07:43:57Z,2021-06-30T18:37:47Z,"This issue is open to discuss different options for adding GPU build and test to Github workflows. 

To enable this feature, SINGA must provide a real or virtual machine with GPU as host machine for running the workflow. Then use the [self-hosted runner](https://docs.github.com/en/actions/hosting-your-own-runners/about-self-hosted-runners) feature of Github Actions. See also [this MLOps video tutorial](https://www.youtube.com/watch?v=rVq-SCNyxVc).

The team need to take some decisions:

1. Which machine(s) should we use? (e.g. virtual machine(s) on AWS, dedicated server(s) at NUS, ..)
2. Which operating systems we test on? (Only Linux? or also Mac). 
3. When we run the GPU build and test workflow? (with every pull request? once per day at night? once per week? only on master branch?, ...)
4. Should we keep the machines always on? or use them only when the scheduled test is running and shut down them when there is no workflow runs? Assuming we run the GPU build and test only at scheduled time.
5. Should we add workflows to run [examples](https://github.com/apache/singa/tree/master/examples) and test the Jupyter notebooks? note that some examples may take hours or days to complete the training. But automating the test of examples can be very useful to speed up the development.

What do you think?
","{""url"": ""https://api.github.com/repos/apache/singa/issues/802/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/802,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyNzE1NzEzOQ==,singa,727157139,802,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-11-14T06:57:27Z,2020-11-14T06:57:27Z,"I believe that what you propose in this issue is very important for us.
We need to safeguard our codebase, because a wrong PR could destroy the whole system functionality.
Therefore I believe that GPU testing is necessary.

Here are my opinions on the questions:
1. prefer dedicated server at NUS (not prefer cloud service providers because I think they are too expensive)
2. Linux is enough (ubuntu)
3. For every PR we need to run the test workflow (just like the current test settings for CPU versions, but need to upgrade the test to GPUs)
4. Prefer to keep the test server on so when someone submits a PR it will be checked immediately.
5. Maybe consider in the future to run the examples. I think the priority is to enable GPU build and test first.
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyNzE1NzEzOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/802,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyNzE1ODgwNQ==,singa,727158805,802,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-11-14T07:15:11Z,2020-11-14T07:15:11Z,"@naili-xing Naili, since you told us that you would like to contribute in SINGA, could you assist us to implement this (currently we have cpu test, but we also need GPU test)","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyNzE1ODgwNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/802,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyNzE1OTkxMw==,singa,727159913,802,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-11-14T07:23:47Z,2020-11-14T07:23:47Z,"@moazreyad could you please advise us how to achieve the goal? (Adding GPU testing to Github workflows
#802), I will ask some RAs to help me for the implementation. ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyNzE1OTkxMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/802,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyNzE2Mjc1OQ==,singa,727162759,802,NA,NLGithubWP,57171759,prometheus,,NA,2020-11-14T07:53:06Z,2020-11-14T07:53:06Z,"> @naili-xing Naili, since you told us that you would like to contribute in SINGA, could you assist us to implement this (currently we have cpu test, but we also need GPU test)

Ok, i will look into it","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyNzE2Mjc1OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/802,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyNzIxNDY3Ng==,singa,727214676,802,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-11-14T14:25:50Z,2020-11-14T14:25:50Z,"> > @naili-xing Naili, since you told us that you would like to contribute in SINGA, could you assist us to implement this (currently we have cpu test, but we also need GPU test)
> 
> Ok, i will look into it

FYI, the different between CPU version and GPU version in building SINGA is just the flag we used in cmake
GPU version: https://github.com/apache/singa/blob/master/tool/docker/devel/ubuntu/cuda10/Dockerfile#L104
`cmake -DENABLE_TEST=ON -DUSE_CUDA=ON -DUSE_PYTHON3=ON -DUSE_DNNL=ON ..`

CPU version: https://github.com/apache/singa/blob/master/tool/docker/devel/ubuntu/cpu/Dockerfile#L67
`cmake -DENABLE_TEST=ON -DUSE_PYTHON3=ON -DUSE_DNNL=ON ..`

In GPU version, it include all the GPU test case when we run test/python/run.py
In CPU version, it automatically skiped all the GPU test case","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyNzIxNDY3Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/802,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyODIyMTYxMg==,singa,728221612,802,NA,moazreyad,2278792,Moaz Reyad,moazreyad@gmail.com,NA,2020-11-16T17:49:06Z,2020-11-16T17:49:06Z,"> @moazreyad could you please advise us how to achieve the goal? (Adding GPU testing to Github workflows
> #802), I will ask some RAs to help me for the implementation.

To achieve this goal, we will need these steps:

First, we need to get github tokens from by opening a ticket at Apache INFRA. Apache has some information about github self hosted runners [here](https://infra.apache.org/self-hosted-runners.html). They don't recommend using it for some security reasons, so we have to explain that GPU build and test is important for SINGA. We also need to make sure the server which will run the github workflows is secure and that the known vulnerabilities of self-hosted runners will not occur in the NUS server. (for example, someone may login to the NUS server and gain access to SINGA github repository admin tokens.)

To complete this step, we may check [this ticket](https://issues.apache.org/jira/browse/INFRA-19875) by Apache Arrow and open a similar one for SINGA.

Second, we create a docker image for the Runner and configure the workflows. If we use Linux, we need to install the [Runner](https://github.com/actions/runner) and its [pre-reqs](https://github.com/actions/runner/blob/main/docs/start/envlinux.md) in the Linux docker machine. The machine should also have the github tokens from the first step. Check the [Apache Arrow implementation](https://github.com/apache/arrow/pull/6512) for more details.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyODIyMTYxMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/802,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyODcwMzMwOA==,singa,728703308,802,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-11-17T05:53:08Z,2020-11-17T05:53:08Z,"> > @moazreyad could you please advise us how to achieve the goal? (Adding GPU testing to Github workflows
> > #802), I will ask some RAs to help me for the implementation.
> 
> To achieve this goal, we will need these steps:
> 
> First, we need to get github tokens from by opening a ticket at Apache INFRA. Apache has some information about github self hosted runners [here](https://infra.apache.org/self-hosted-runners.html). They don't recommend using it for some security reasons, so we have to explain that GPU build and test is important for SINGA. We also need to make sure the server which will run the github workflows is secure and that the known vulnerabilities of self-hosted runners will not occur in the NUS server. (for example, someone may login to the NUS server and gain access to SINGA github repository admin tokens.)
> 
> To complete this step, we may check [this ticket](https://issues.apache.org/jira/browse/INFRA-19875) by Apache Arrow and open a similar one for SINGA.
> 
> Second, we create a docker image for the Runner and configure the workflows. If we use Linux, we need to install the [Runner](https://github.com/actions/runner) and its [pre-reqs](https://github.com/actions/runner/blob/main/docs/start/envlinux.md) in the Linux docker machine. The machine should also have the github tokens from the first step. Check the [Apache Arrow implementation](https://github.com/apache/arrow/pull/6512) for more details.

@moazreyad thanks a lot for the information, I will consider it. Also I am thinking about if GPU emulator is another option? https://developer.nvidia.com/nvemulate

@naili-xing do you think the github actions can access our server to do gpu test, does it need to connect to nus VPN? ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyODcwMzMwOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/802,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyODcwNTU3OQ==,singa,728705579,802,NA,NLGithubWP,57171759,prometheus,,NA,2020-11-17T05:59:40Z,2020-11-17T05:59:40Z,"

> > > @moazreyad could you please advise us how to achieve the goal? (Adding GPU testing to Github workflows
> > > #802), I will ask some RAs to help me for the implementation.
> > 
> > 
> > To achieve this goal, we will need these steps:
> > First, we need to get github tokens from by opening a ticket at Apache INFRA. Apache has some information about github self hosted runners [here](https://infra.apache.org/self-hosted-runners.html). They don't recommend using it for some security reasons, so we have to explain that GPU build and test is important for SINGA. We also need to make sure the server which will run the github workflows is secure and that the known vulnerabilities of self-hosted runners will not occur in the NUS server. (for example, someone may login to the NUS server and gain access to SINGA github repository admin tokens.)
> > To complete this step, we may check [this ticket](https://issues.apache.org/jira/browse/INFRA-19875) by Apache Arrow and open a similar one for SINGA.
> > Second, we create a docker image for the Runner and configure the workflows. If we use Linux, we need to install the [Runner](https://github.com/actions/runner) and its [pre-reqs](https://github.com/actions/runner/blob/main/docs/start/envlinux.md) in the Linux docker machine. The machine should also have the github tokens from the first step. Check the [Apache Arrow implementation](https://github.com/apache/arrow/pull/6512) for more details.
> 
> @moazreyad thanks a lot for the information, I will consider it. Also I am thinking about if GPU emulator is another option? https://developer.nvidia.com/nvemulate
https://stackoverflow.com/questions/40461823/is-it-possible-to-emulate-a-gpu-for-cuda-opencl-unit-testing-purposes
> 
> @naili-xing do you think the github actions can access our server to do gpu test, does it need to connect to nus VPN?

I think it needs, if accessing the server from outside of nus, it needs vpn, if access from inside, using nus network, i think there is no needs","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyODcwNTU3OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/802,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyODcwOTIxMQ==,singa,728709211,802,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-11-17T06:09:26Z,2020-11-17T06:09:26Z,"@joddiy will help us try if gpu emulator can run our test case first 
https://developer.nvidia.com/nvemulate
https://stackoverflow.com/questions/40461823/is-it-possible-to-emulate-a-gpu-for-cuda-opencl-unit-testing-purposes","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyODcwOTIxMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/802,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyODg3NTA1Mg==,singa,728875052,802,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-11-17T11:47:11Z,2020-11-17T11:47:11Z,"> @joddiy will help us try if gpu emulator can run our test case first
> https://developer.nvidia.com/nvemulate
> https://stackoverflow.com/questions/40461823/is-it-possible-to-emulate-a-gpu-for-cuda-opencl-unit-testing-purposes

Hi, @chrishkchris , these two GPU emulators haven't been updated for more than 5 years. And since we have our own machine, the self-hosted GitHub Actions is a better solution.

The only question is, @naili-xing , we cannot connect our machine from outside without a VPN. So maybe it's more feasible to listen to the update of the commit from our machine, once get such an update, run the test and push the result to the Github Actions.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyODg3NTA1Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/802,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyODg3NzIzMw==,singa,728877233,802,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-11-17T11:52:07Z,2020-11-17T11:52:07Z,"> > @joddiy will help us try if gpu emulator can run our test case first
> > https://developer.nvidia.com/nvemulate
> > https://stackoverflow.com/questions/40461823/is-it-possible-to-emulate-a-gpu-for-cuda-opencl-unit-testing-purposes
> 
> Hi, @chrishkchris , these two GPU emulators haven't been updated for more than 5 years. And science we have our own machine, the self-hosted GitHub Actions is a better solution.
> 
> The only question is, @naili-xing , we cannot connect our machine from outside without a VPN. So maybe it's more feasible to listen to the update of the commit from our machine, once get such an update, run the test and push the result to the Github Actions.

@joddiy  OK, then we go for the solution using our own machine gpu for github actions test first. 

For our reference: communication between our server and github actions
https://docs.github.com/en/free-pro-team@latest/actions/hosting-your-own-runners/about-self-hosted-runners#communication-between-self-hosted-runners-and-github
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyODg3NzIzMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/802,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyODg3OTY5NA==,singa,728879694,802,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-11-17T11:57:27Z,2020-11-17T11:57:27Z,"https://docs.github.com/en/free-pro-team@latest/actions/hosting-your-own-runners/about-self-hosted-runners#communication-between-self-hosted-runners-and-github
FYI
""The self-hosted runner uses a HTTPS long poll that opens a connection to GitHub for 50 seconds"" ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyODg3OTY5NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/802,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyOTM4NjMxOA==,singa,729386318,802,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-11-18T03:48:38Z,2020-11-18T03:48:38Z,"@moazreyad I have opened a ticket to ask the infrastructure and hopes they can give us a solution

https://issues.apache.org/jira/projects/INFRA/issues/INFRA-21115?filter=allopenissues","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyOTM4NjMxOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/802,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyOTQxNDg1OA==,singa,729414858,802,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-11-18T05:01:34Z,2020-11-18T05:01:34Z,"@moazreyad
They told us that we can use the API in the following link to add github secrets (to store token like username and password)
https://developer.github.com/v3/actions/secrets/

@joddiy 
Could you help test the API to see if we can store some random token, and see if we are able to access what we have stored?  
(e.g. you can use postman https://www.postman.com/ to test the restful API)
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcyOTQxNDg1OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/802,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDczMDIyMzExMA==,singa,730223110,802,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-11-19T08:49:03Z,2020-11-19T08:49:03Z,"@naili-xing 

I think before implementation on the SINGA repo, we fork the repo to test the github actions with our own github account first.

Could you follow the following steps for the test
1. fork the singa repo to your github acoount
2. make the forked repo private (throughout the test to ensure the safety of our server), add me as a collaborator of the forked repo so I can also access it
3. implement the github actions code for gpu test:
We create a docker image for the Runner and configure the workflows. If we use Linux, we need to install the [Runner](https://github.com/actions/runner) and its [pre-reqs](https://github.com/actions/runner/blob/main/docs/start/envlinux.md) in the Linux docker machine. The machine should also have the github tokens from the first step. Check the [Apache Arrow implementation](https://github.com/apache/arrow/pull/6512) for more details.

We evaluate the approach first before implementing it in apache/SINGA repo","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDczMDIyMzExMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/802,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDczMDIzMzkyNA==,singa,730233924,802,NA,NLGithubWP,57171759,prometheus,,NA,2020-11-19T09:09:27Z,2020-11-19T09:09:27Z,"ok
Chris Yeung <notifications@github.com>于2020年11月19日 周四下午4:49写道：

> @naili-xing <https://github.com/naili-xing>
>
> I think before implementation on the SINGA repo, we fork the repo to test
> the github actions with our own github account first.
>
> Could you follow the following steps for the test
>
>    1. fork the singa repo to your github acoount
>    2. make the forked repo private (throughout the test to ensure the
>    safety of our server), add me as a collaborator of the forked repo so I can
>    also access it
>    3. implement the github actions code for gpu test:
>    We create a docker image for the Runner and configure the workflows.
>    If we use Linux, we need to install the Runner
>    <https://github.com/actions/runner> and its pre-reqs
>    <https://github.com/actions/runner/blob/main/docs/start/envlinux.md>
>    in the Linux docker machine. The machine should also have the github tokens
>    from the first step. Check the Apache Arrow implementation
>    <https://github.com/apache/arrow/pull/6512> for more details.
>
> We evaluate the approach first before implementing it in Github repo
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/apache/singa/issues/802#issuecomment-730223110>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ANUF6L2MTHEJUBJ33XDZY4DSQTLY5ANCNFSM4RX6WZWQ>
> .
>
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDczMDIzMzkyNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/802,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDczMTYzMjM3MQ==,singa,731632371,802,NA,moazreyad,2278792,Moaz Reyad,moazreyad@gmail.com,NA,2020-11-21T20:27:42Z,2020-11-21T20:27:42Z,"The GPU testing will improve the code coverage and by the way, there is a problem in the current testing workflows: since around two months, the Python tests disappeared from the codecov report in the dev branch and they are never executed in the master branch. Probably a pull request did something that disabled the Python tests. I tried to check quickly, but I think it needs more investigation.

The last codecov report with the Python test is [here](https://codecov.io/gh/apache/singa/tree/7b5a0ab31943928d9601fb1284f8a6ce9d307cdd) with code coverage = 70%. The codecov report of the next commit shows no Python test [here](
https://codecov.io/gh/apache/singa/tree/85fc6a19b4a1ccf4ffe5b987f8f335d227f7bffd
) with code coverage drops to 63.7%. ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDczMTYzMjM3MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/802,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDczMjE0NDQzNw==,singa,732144437,802,NA,moazreyad,2278792,Moaz Reyad,moazreyad@gmail.com,NA,2020-11-23T12:55:20Z,2020-11-23T12:55:20Z,"> The only question is, @naili-xing , we cannot connect our machine from outside without a VPN. So maybe it's more feasible to listen to the update of the commit from our machine, once get such an update, run the test and push the result to the Github Actions.

If the connection between NUS self-hosted runners and Github servers is not possible because of NUS network restrictions, then another solution can be considered: self-hosting Github itself using [Github Enterprise](https://github.com/enterprise). The cost is $21 per user per month, but there are [special discounted licenses for universities](https://enterprise.github.com/faq). In this case both Github and the Github runners are hosted locally in the same network. (But again I guess we need to configure the DNS of the SINGA github repository to point to the locally hosted github, so we must have some NUS network configuration for external access but may be it is easier?). There is a free trail for Github Enterprise if we want to evaluate it on the NUS server.

Otherwise, we just use a cloud-based solution (from Amazon/Microsoft/Google, ..) to execute the GPU Github workflows. There will be a cost for this cloud service time and resources, but it will also save the cost we need to configure and maintain our own GPU testing pipeline.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDczMjE0NDQzNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/802,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDczMjc1NTY3Mw==,singa,732755673,802,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-11-24T09:00:46Z,2020-11-24T09:00:46Z,"umm... cloud service will induce recurrent spending, e.g. if on-demand g4dn.xlarge costs ~0.526USD per hour, every month the recurrent cost seems to be around 0.526USD*24(hour)*30(days)=378USD per month
https://aws.amazon.com/cn/ec2/pricing/on-demand/
correct me if I am wrong, and yet we still need to configure and maintain the GPU testing pipeline ourselves 

> > The only question is, @naili-xing , we cannot connect our machine from outside without a VPN. So maybe it's more feasible to listen to the update of the commit from our machine, once get such an update, run the test and push the result to the Github Actions.
> 
> If the connection between NUS self-hosted runners and Github servers is not possible because of NUS network restrictions, then another solution can be considered: self-hosting Github itself using [Github Enterprise](https://github.com/enterprise). The cost is $21 per user per month, but there are [special discounted licenses for universities](https://enterprise.github.com/faq). In this case both Github and the Github runners are hosted locally in the same network. (But again I guess we need to configure the DNS of the SINGA github repository to point to the locally hosted github, so we must have some NUS network configuration for external access but may be it is easier?). There is a free trail for Github Enterprise if we want to evaluate it on the NUS server.
> 
> Otherwise, we just use a cloud-based solution (from Amazon/Microsoft/Google, ..) to execute the GPU Github workflows. There will be a cost for this cloud service time and resources, but it will also save the cost we need to configure and maintain our own GPU testing pipeline.

","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDczMjc1NTY3Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/802,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDg3MTYyNTk4Mw==,singa,871625983,802,NA,aktech,5647941,Amit Kumar,,NA,2021-06-30T18:17:05Z,2021-06-30T18:17:05Z,"Hi all, I am the creator of Cirun.io, ""GPU Testing"" caught my eye.

FWIW I'll share my two cents. I created a service for problems like these, which is basically running custom machines (including GPUs) in GitHub Actions: https://cirun.io/

It is used in multiple open source projects needing GPU support like the following:

- https://github.com/pystatgen/sgkit/
- https://github.com/qutip/qutip-cupy

It is fairly simple to setup, all you need is a cloud account (AWS or GCP) and a simple yaml file describing what kind of machines you need and Cirun will spin up ephemeral machines on your cloud for GitHub Actions to run. It's native to GitHub ecosystem, which mean you can see logs/trigger in the Github's interface itself, just like any Github Action run.

Also, note that Cirun is free for Open source projects. (You only pay to your cloud provider for machine usage)","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDg3MTYyNTk4Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/802,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDg3MTYzODk4MA==,singa,871638980,802,NA,moazreyad,2278792,Moaz Reyad,moazreyad@gmail.com,NA,2021-06-30T18:37:47Z,2021-06-30T18:37:47Z,"Thank you, but to use Cirun.io we need to install Cirun application in Github. This is not possible because SINGA github account is managed by the Apache foundation that must approve the Cirun application and allow it to be installed in SINGA repo.

","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDg3MTYzODk4MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/807,https://api.github.com/repos/apache/singa/issues/807,singa,719986264,807,AssertionError for the ONNX training testcases?,lijiansong,10958439,Json Lee,jsonlee@whu.edu.cn,CLOSED,2020-10-13T08:11:39Z,2021-02-18T05:15:17Z,"AssertionError with the onnx testcase: <https://github.com/apache/singa/blob/master/examples/onnx/training/train.py>

```
$ cd examples/onnx
$ python3 training/train.py --model vgg16
```
Then I get the following error msg:

```
File ""training/train.py"", line 437, in <module>
    args.onnx_model_path, args.data, sgd, args.graph, args.verbosity)
  File ""training/train.py"", line 295, in run
    model.compile([tx], is_train=True, use_graph=graph, sequential=sequential)
  File ""/home/extend/lijiansong/work-space/anaconda2/envs/intel-caffe/lib/python3.6/site-packages/singa/model.py"", line 177, in compile
    self.forward(*inputs)
  File ""/home/extend/lijiansong/work-space/anaconda2/envs/intel-caffe/lib/python3.6/site-packages/singa/layer.py"", line 63, in wrapper
    return func(self, *args, **kwargs)
  File ""training/train.py"", line 191, in forward
    y = self.linear(y)
  File ""/home/extend/lijiansong/work-space/anaconda2/envs/intel-caffe/lib/python3.6/site-packages/singa/layer.py"", line 110, in __call__
    return self.forward(*args, **kwargs)
  File ""/home/extend/lijiansong/work-space/anaconda2/envs/intel-caffe/lib/python3.6/site-packages/singa/layer.py"", line 61, in wrapper
    self.initialize(*args, **kwargs)
  File ""/home/extend/lijiansong/work-space/anaconda2/envs/intel-caffe/lib/python3.6/site-packages/singa/layer.py"", line 45, in wrapper
    'initialize function expects PlaceHolders or Tensors')
AssertionError: initialize function expects PlaceHolders or Tensors
```

Something maybe wrong with the layer initialization?

singa version: 3100(the latest build from the source code of master branch)
Python version: 3.5.2
ONNX version: 1.5.0

","{""url"": ""https://api.github.com/repos/apache/singa/issues/807/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/807,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNzYxNzU0MQ==,singa,707617541,807,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-10-13T09:30:41Z,2020-10-13T09:30:41Z,"Thanks for the report, let me check.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNzYxNzU0MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/807,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNzY1NTQ5NA==,singa,707655494,807,NA,pinpom,49071226,pinpom,,NA,2020-10-13T10:43:58Z,2020-10-13T10:43:58Z,"@joddiy I got the same issue when do training for examples/onnx models. Only the default model ('resnet18v1') runs, all others failed for the mentioned reason. I think model urls might need to be updated too, since some are out-dated ('vgg19' & 'vgg19bn', for example)","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNzY1NTQ5NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/807,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNzY2NDAyOA==,singa,707664028,807,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-10-13T11:01:28Z,2020-10-13T11:01:28Z,"> AssertionError with the onnx testcase: https://github.com/apache/singa/blob/master/examples/onnx/training/train.py
> 
> ```
> $ cd examples/onnx
> $ python3 training/train.py --model vgg16
> ```
> 
> Then I get the following error msg:
> 
> ```
> File ""training/train.py"", line 437, in <module>
>     args.onnx_model_path, args.data, sgd, args.graph, args.verbosity)
>   File ""training/train.py"", line 295, in run
>     model.compile([tx], is_train=True, use_graph=graph, sequential=sequential)
>   File ""/home/extend/lijiansong/work-space/anaconda2/envs/intel-caffe/lib/python3.6/site-packages/singa/model.py"", line 177, in compile
>     self.forward(*inputs)
>   File ""/home/extend/lijiansong/work-space/anaconda2/envs/intel-caffe/lib/python3.6/site-packages/singa/layer.py"", line 63, in wrapper
>     return func(self, *args, **kwargs)
>   File ""training/train.py"", line 191, in forward
>     y = self.linear(y)
>   File ""/home/extend/lijiansong/work-space/anaconda2/envs/intel-caffe/lib/python3.6/site-packages/singa/layer.py"", line 110, in __call__
>     return self.forward(*args, **kwargs)
>   File ""/home/extend/lijiansong/work-space/anaconda2/envs/intel-caffe/lib/python3.6/site-packages/singa/layer.py"", line 61, in wrapper
>     self.initialize(*args, **kwargs)
>   File ""/home/extend/lijiansong/work-space/anaconda2/envs/intel-caffe/lib/python3.6/site-packages/singa/layer.py"", line 45, in wrapper
>     'initialize function expects PlaceHolders or Tensors')
> AssertionError: initialize function expects PlaceHolders or Tensors
> ```
> 
> Something maybe wrong with the layer initialization?
> 
> singa version: 3100(the latest build from the source code of master branch)
> Python version: 3.5.2
> ONNX version: 1.5.0

Hi, @lijiansong , I cannot reproduce the error, I can see another error like this:
```
WARNING: Logging before InitGoogleLogging() is written to STDERR
W1013 10:55:05.660770  6279 convolution.cc:560] The required memory for workspace (2333081604) is larger than the expected Bytes (1073741824)
F1013 10:55:05.660809  6279 device.cc:88] Check failed: size >= 0 (-1961885692 vs. 0) size is negative, could be caused by the type cast from size_t to int. In that case, the size is too large.
*** Check failure stack trace: ***
Aborted (core dumped)
```

The full log is:
```
root@567b66a2525c:/singa# cd examples/onnx/
root@567b66a2525c:/singa/examples/onnx# python3 training/train.py --model vgg16
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:537] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553437328
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:537] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553437328
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:537] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553437328
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:537] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553438994
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:537] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553438996
WARNING: Logging before InitGoogleLogging() is written to STDERR
W1013 11:00:16.066620  6308 convolution.cc:560] The required memory for workspace (2333081604) is larger than the expected Bytes (1073741824)
F1013 11:00:16.066661  6308 device.cc:88] Check failed: size >= 0 (-1961885692 vs. 0) size is negative, could be caused by the type cast from size_t to int. In that case, the size is too large.
*** Check failure stack trace: ***
Aborted (core dumped)
```","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNzY2NDAyOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/807,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNzY2NDQ4MQ==,singa,707664481,807,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-10-13T11:02:25Z,2020-10-13T11:02:25Z,"> @joddiy I got the same issue when do training for examples/onnx models. Only the default model ('resnet18v1') runs, all others failed for the mentioned reason. I think model urls might need to be updated too, since some are out-dated ('vgg19' & 'vgg19bn', for example)

Hi, @pinpom, can you reproduce the same error or the error like the one I comment above? ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNzY2NDQ4MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/807,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNzcwMTAzNQ==,singa,707701035,807,NA,pinpom,49071226,pinpom,,NA,2020-10-13T12:20:44Z,2020-10-13T12:20:44Z,"@joddiy: FYR as below. i ran on panda13, when GPU memory was enough for the model:
`
$ cd singa
$ python examples/onnx/training/train.py --model resnet152v1
`
Error:
""
`thao@panda13:/hdd2/thao/singa$ python examples/onnx/training/train.py --model resnet152v1`

2020-10-13 20:09:27,800 Downloading https://s3.amazonaws.com/onnx-model-zoo/resnet/resnet152v1/resnet152v1.tar.gz
Traceback (most recent call last):
  File ""examples/onnx/training/train.py"", line 352, in <module>
    args.data, sgd, args.graph, args.verbosity)
  File ""examples/onnx/training/train.py"", line 216, in run
    model.compile([tx], is_train=True, use_graph=graph, sequential=sequential)
  File ""/hdd2/thao/conda/miniconda3/envs/sing/lib/python3.7/site-packages/singa/model.py"", line 177, in compile
    self.forward(*inputs)
  File ""/hdd2/thao/conda/miniconda3/envs/sing/lib/python3.7/site-packages/singa/layer.py"", line 61, in wrapper
    return func(self, *args, **kwargs)
  File ""examples/onnx/training/train.py"", line 119, in forward
    y = self.linear(y)
  File ""/hdd2/thao/conda/miniconda3/envs/sing/lib/python3.7/site-packages/singa/layer.py"", line 108, in __call__
    return self.forward(*args, **kwargs)
  File ""/hdd2/thao/conda/miniconda3/envs/sing/lib/python3.7/site-packages/singa/layer.py"", line 59, in wrapper
    self.initialize(*args, **kwargs)
  File ""/hdd2/thao/conda/miniconda3/envs/sing/lib/python3.7/site-packages/singa/layer.py"", line 43, in wrapper
    'initialize function expects PlaceHolders or Tensors')
AssertionError: initialize function expects PlaceHolders or Tensors""

env:
- python 3.7
- singa 3.1.0.rc1 (conda)
- singa git - dev branch","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNzcwMTAzNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/807,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNzczOTY2MQ==,singa,707739661,807,NA,lijiansong,10958439,Json Lee,jsonlee@whu.edu.cn,NA,2020-10-13T13:30:46Z,2020-10-13T13:30:46Z,"@pinpom If you print the Assertion expression at `/hdd2/thao/conda/miniconda3/envs/sing/lib/python3.7/site-packages/singa/layer.py` of line 43, 

```
assert len(args) > 0 and isinstance(args[0], Tensor), (
                    'initialize function expects PlaceHolders or Tensors')
```
you may find that `args[0]` here is not an instance of singa.tensor.Tensor. Someone else please help to fix this bug?
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNzczOTY2MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/807,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNzc0NDM4NQ==,singa,707744385,807,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-10-13T13:37:56Z,2020-10-13T13:37:56Z,"> @pinpom If you print the Assertion expression at `/hdd2/thao/conda/miniconda3/envs/sing/lib/python3.7/site-packages/singa/layer.py` of line 43,
> 
> ```
> assert len(args) > 0 and isinstance(args[0], Tensor), (
>                     'initialize function expects PlaceHolders or Tensors')
> ```
> 
> you may find that `args[0]` here is not an instance of singa.tensor.Tensor. Someone else please help to fix this bug?

Thanks for the reply, I'm checking it.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNzc0NDM4NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/807,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNzc1Nzg5Nw==,singa,707757897,807,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-10-13T13:58:40Z,2020-10-13T13:58:40Z,"@lijiansong @pinpom 
I guess the problem is here: https://github.com/apache/singa/blob/3654b91e63f8f715f668cf464730fed5ca36a418/examples/onnx/training/train.py#L117-L118

Because each model actually has a different operator's name, before I assume if the user wants to train another model, they should update this name firstly. Let me think how to optimize it.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNzc1Nzg5Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/807,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNzc2NjIxOQ==,singa,707766219,807,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-10-13T14:11:24Z,2020-10-13T14:11:24Z,"@lijiansong @pinpom 
it should be fixed at this PR: #808 ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNzc2NjIxOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/807,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcwODIxOTExOA==,singa,708219118,807,NA,lijiansong,10958439,Json Lee,jsonlee@whu.edu.cn,NA,2020-10-14T07:33:57Z,2020-10-14T07:33:57Z,"@joddiy Thanks for your patch PR at #808, another failure problem occurs(as you mentioned above):

```
$ cd examples/onnx
$ python3 training/train.py --model vgg16 --data cifar10 --bs 1
```
the full log is:
```
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:537] Reading dangerously large protocol message.  If the message turns out to be larger than   2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::           SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
 [libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553512191
 [libprotobuf WARNING google/protobuf/io/coded_stream.cc:537] Reading dangerously large protocol message.  If the message turns out to be larger than   2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::           SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
 [libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553512191
 [libprotobuf WARNING google/protobuf/io/coded_stream.cc:537] Reading dangerously large protocol message.  If the message turns out to be larger than   2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::           SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
 [libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553512191
 [libprotobuf WARNING google/protobuf/io/coded_stream.cc:537] Reading dangerously large protocol message.  If the message turns out to be larger than   2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::           SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
 [libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553514489
 [libprotobuf WARNING google/protobuf/io/coded_stream.cc:537] Reading dangerously large protocol message.  If the message turns out to be larger than   2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::           SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
 [libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553514491
 ^M  0%|          | 0/50000 [00:00<?, ?it/s]WARNING: Logging before InitGoogleLogging() is written to STDERR
 F1014 15:29:10.526221 23807 cuda_gpu.cc:207] Check failed: error == cudaSuccess (700 vs. 0)  an illegal memory access was encountered
 *** Check failure stack trace: ***
```
env:
singa version: 3100(the latest build from the source code of master branch)
Python version: 3.5.2
ONNX version: 1.5.0

> @lijiansong @pinpom
> it should be fixed at this PR: #808

","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcwODIxOTExOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/807,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcwODIyMjM5MA==,singa,708222390,807,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-10-14T07:40:59Z,2020-10-14T07:40:59Z,"> @joddiy Thanks for your patch PR at #808, another failure problem occurs(as you mentioned above):
> 
> ```
> $ cd examples/onnx
> $ python3 training/train.py --model vgg16 --data cifar10 --bs 1
> ```
> 
> the full log is:
> 
> ```
> [libprotobuf WARNING google/protobuf/io/coded_stream.cc:537] Reading dangerously large protocol message.  If the message turns out to be larger than   2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::           SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
>  [libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553512191
>  [libprotobuf WARNING google/protobuf/io/coded_stream.cc:537] Reading dangerously large protocol message.  If the message turns out to be larger than   2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::           SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
>  [libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553512191
>  [libprotobuf WARNING google/protobuf/io/coded_stream.cc:537] Reading dangerously large protocol message.  If the message turns out to be larger than   2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::           SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
>  [libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553512191
>  [libprotobuf WARNING google/protobuf/io/coded_stream.cc:537] Reading dangerously large protocol message.  If the message turns out to be larger than   2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::           SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
>  [libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553514489
>  [libprotobuf WARNING google/protobuf/io/coded_stream.cc:537] Reading dangerously large protocol message.  If the message turns out to be larger than   2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::           SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
>  [libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553514491
>  ^M  0%|          | 0/50000 [00:00<?, ?it/s]WARNING: Logging before InitGoogleLogging() is written to STDERR
>  F1014 15:29:10.526221 23807 cuda_gpu.cc:207] Check failed: error == cudaSuccess (700 vs. 0)  an illegal memory access was encountered
>  *** Check failure stack trace: ***
> ```
> 
> env:
> singa version: 3100(the latest build from the source code of master branch)
> Python version: 3.5.2
> ONNX version: 1.5.0
> 
> > @lijiansong @pinpom
> > it should be fixed at this PR: #808

I found this issue yesterday, however, this is caused by GPU memory, @dcslin has any idea?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcwODIyMjM5MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/807,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDc1MjM3OTE2Ng==,singa,752379166,807,NA,lijiansong,10958439,Json Lee,jsonlee@whu.edu.cn,NA,2020-12-30T08:51:57Z,2020-12-30T08:51:57Z,"In the Singa internal source code, there are 4 enumeration types of Block type, that is `kInput, kParam, kInter, kEnd`. Here` kInput, kParam and kInter` is easy to follow. `kInput` is the input data of DNN workloads, `kParam` is the weight parameters, `kInter` is the intermediate results during DNN workloads. But what does `kEnd` mean here?
https://github.com/apache/singa/blob/f04d197ee15777504bf80a8cb77666b8cacb4b94/include/singa/core/scheduler.h#L55

@joddiy ","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDc1MjM3OTE2Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/807,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDc1MjM4Njk3NQ==,singa,752386975,807,NA,joddiy,14108933,Joddiy Zhang,joddiyzhang@gmail.com,NA,2020-12-30T09:19:50Z,2020-12-30T09:19:50Z,"> In the Singa internal source code, there are 4 enumeration types of Block type, that is `kInput, kParam, kInter, kEnd`. Here` kInput, kParam and kInter` is easy to follow. `kInput` is the input data of DNN workloads, `kParam` is the weight parameters, `kInter` is the intermediate results during DNN workloads. But what does `kEnd` mean here?
> https://github.com/apache/singa/blob/f04d197ee15777504bf80a8cb77666b8cacb4b94/include/singa/core/scheduler.h#L55
> 
> @joddiy

Sorry, I have no idea about the c++ code.

Hi, @chrishkchris, can you help check it?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDc1MjM4Njk3NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/807,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDc1MjM4OTU2OA==,singa,752389568,807,NA,chrishkchris,38325429,Chris Yeung,,NA,2020-12-30T09:28:34Z,2020-12-30T09:28:34Z,"All the blocks are used to construct the computational graph. I think kEnd means the end nodes of the graph
like this example: https://stackoverflow.com/questions/57678534/find-end-node-in-directed-graph

@XJDKC  The code was written by you, so you may know clearer. Did I describe it right?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDc1MjM4OTU2OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/807,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDc1Mjg1MjMwOA==,singa,752852308,807,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-12-31T05:44:02Z,2020-12-31T05:44:02Z,"> All the blocks are used to construct the computational graph. I think kEnd means the end nodes of the graph
> like this example: https://stackoverflow.com/questions/57678534/find-end-node-in-directed-graph
> 
> @XJDKC The code was written by you, so you may know clearer. Did I describe it right?

@chrishkchris @lijiansong It's correct. Take the computational graph below for example:

![FYP](https://user-images.githubusercontent.com/32295829/103396269-32c19d00-4b6d-11eb-850e-ba7f12acde92.png)

The type of the pink block in the picture is kEnd which means this block is not used by any other operators in the graph. This kind of block is considered as the endpoint of the graph. I distinguish it from other types to better optimize the memory footprint of model training.
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDc1Mjg1MjMwOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/807,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDc1Mjg1MzA0Nw==,singa,752853047,807,NA,lijiansong,10958439,Json Lee,jsonlee@whu.edu.cn,NA,2020-12-31T05:47:33Z,2020-12-31T05:47:33Z,"@XJDKC @chrishkchris @joddiy Get it, thanks.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDc1Mjg1MzA0Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/807,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDc1Mjg1MzM3NA==,singa,752853374,807,NA,XJDKC,32295829,Rulin Xing,rulin@apache.org,NA,2020-12-31T05:49:05Z,2020-12-31T05:49:05Z,"> @XJDKC @chrishkchris @joddiy Get it, thanks.

Welcome!","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDc1Mjg1MzM3NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/807,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDc4MTA0ODM2MA==,singa,781048360,807,NA,delphieritas,34205896,,,NA,2021-02-18T04:51:01Z,2021-02-18T04:51:01Z,"Hi Singa team. I also encountered the error info:
      WARNING: Logging before InitGoogleLogging() is written to STDERR                                                                                                                                                                 
      W0217 18:35:53.217267  6606 convolution.cc:560] The required memory for workspace (1192230916) is larger than the expected Bytes (1073741824)                                                                                    
      W0217 18:35:53.218562  6606 convolution.cc:560] The required memory for workspace (2333081604) is larger than the expected Bytes (1073741824)                                                                                    
      F0217 18:35:53.218595  6606 device.cc:88] Check failed: size >= 0 (-1961885692 vs. 0) size is negative, could be caused by the type cast from size_t to int. In that case, the size is too large.                                
      *** Check failure stack trace: ***                                                                                                                                                                                               
      Aborted (core dumped)      
            
My Singa Version is 3.1.0 https://github.com/apache/singa/compare/3.1.0...master . 

I saw this bug related pull request 808 https://github.com/apache/singa/pull/808/files . But this Pull Request seemed not addressing the bug (if it is). So could you guys reopen this issue for solving?","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDc4MTA0ODM2MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/810,https://api.github.com/repos/apache/singa/issues/810,singa,723774476,810,autograd models got AttributeError,pinpom,49071226,pinpom,,CLOSED,2020-10-17T14:46:38Z,2021-02-15T12:45:04Z,"Got AttributeError when running some Autograd models:

`python examples/cnn/autograd/cifar10_multiprocess.py`
AttributeError: module 'singa.singa_wrap' has no attribute 'NcclIdHolder'

`python examples/cnn/autograd/mnist_dist.py`
AttributeError: module 'singa.singa_wrap' has no attribute 'Communicator'

Does it mean that file singa_wrap is not updated? 
","{""url"": ""https://api.github.com/repos/apache/singa/issues/810/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/810,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcxMTEwMjU2Mg==,singa,711102562,810,NA,nudles,3797447,Wei Wang,,NA,2020-10-18T01:17:20Z,2020-10-18T01:17:20Z,this is because the pip/conda package is compiled without the distributed training module.,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDcxMTEwMjU2Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/831,https://api.github.com/repos/apache/singa/issues/831,singa,786922824,831,There are two main branches: master branch and dev branch,chrishkchris,38325429,Chris Yeung,,CLOSED,2021-01-15T14:08:16Z,2021-05-27T11:17:41Z,"There are two branches: master and dev

1. master branch consists of a stable version

2. dev branch consists of a development version

**Normally, when we do the code development, we submit PRs to dev branch. It is because it could take some risk to overwrite a stable version**

**However, sometime we still need to submit PR to master branch, for the purpose of fixing the existing bug in the master branch**

When we release a new version when the dev branch is stable, we will update the master branch from the dev branch, and use the updated master branch as the new release","{""url"": ""https://api.github.com/repos/apache/singa/issues/831/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/831,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDg0OTU0OTMyOA==,singa,849549328,831,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2021-05-27T11:17:40Z,2021-05-27T11:17:40Z,"For the development works of this whole quarter, the development team has agreed and followed the following rules:

1) when we do the code development, we submit PRs to dev branch. 

2) When we release a new version when the dev branch is stable, we will update the master branch from the dev branch, and use the updated master branch as the new release","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDg0OTU0OTMyOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/833,https://api.github.com/repos/apache/singa/issues/833,singa,812978845,833,Obsolete Incubator release directory tree,sebbASF,16689231,Sebb,,CLOSED,2021-02-21T23:21:23Z,2021-02-25T13:17:27Z,"The following directory tree no longer appears to be needed, and should be removed please:

https://dist.apache.org/repos/dist/release/incubator/singa/","{""url"": ""https://api.github.com/repos/apache/singa/issues/833/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/833,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDc4NTg1NjQ4NA==,singa,785856484,833,NA,nudles,3797447,Wei Wang,,NA,2021-02-25T12:21:50Z,2021-02-25T12:21:50Z,It has been removed. Thanks for the reminder.,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDc4NTg1NjQ4NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/833,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDc4NTg4Nzk3Mw==,singa,785887973,833,NA,sebbASF,16689231,Sebb,,NA,2021-02-25T13:17:27Z,2021-02-25T13:17:27Z,Thanks!,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDc4NTg4Nzk3Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/856,https://api.github.com/repos/apache/singa/issues/856,singa,903578548,856,Improve CNN training efficiency by moving augmentation outside of training iterations,lzjpaul,8807719,Zhaojing Luo,,CLOSED,2021-05-27T11:21:15Z,2021-05-29T04:14:59Z,"For benchmark datasets, e.g., CIFAR-10 and ImageNet, the augmentation method is pre-defined before the model training, so the augmentation does not need to be carried out mini-batch wise. 

Instead, the augmentation can be done once before the training begins, in order to save time.","{""url"": ""https://api.github.com/repos/apache/singa/issues/856/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/856,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDg1MDc2NTk2OA==,singa,850765968,856,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2021-05-29T04:14:36Z,2021-05-29T04:14:36Z,"In examples/cifar_distributed_cnn, the data augmentation is moved outside of training iterations for CIFAR-10 dataset","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDg1MDc2NTk2OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/856,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDg1MDc2NjAwOA==,singa,850766008,856,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2021-05-29T04:14:59Z,2021-05-29T04:14:59Z,"In examples/cifar_distributed_cnn, the data augmentation is moved outside of training iterations for CIFAR-10 dataset","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDg1MDc2NjAwOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/857,https://api.github.com/repos/apache/singa/issues/857,singa,906365040,857,Need to disable graph for printing parameters and gradients,zlheui,8085821,Zhu Lei,zlheui2@gmail.com,CLOSED,2021-05-29T05:15:51Z,2021-05-29T07:57:20Z,"When we are running distributed training examples, e.g., examples/cifar_distributed_cnn, examples/cnn, we need to disable graph (adding -g option), so that we can print parameter values or gradients tensors in numpy format","{""url"": ""https://api.github.com/repos/apache/singa/issues/857/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/857,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDg1MDc5MDkxNw==,singa,850790917,857,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2021-05-29T07:56:21Z,2021-05-29T07:56:21Z,"Use the -g option in train_cnn.py, train_mpi.py and train_multiprocess.py solves this issue","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDg1MDc5MDkxNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/857,https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDg1MDc5MTAzNw==,singa,850791037,857,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2021-05-29T07:57:20Z,2021-05-29T07:57:20Z,"Use the -g option in train_cnn.py, train_mpi.py and train_multiprocess.py solves this issue","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/MDEyOklzc3VlQ29tbWVudDg1MDc5MTAzNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/858,https://api.github.com/repos/apache/singa/issues/858,singa,906412674,858,Need to call the distributed training optimizer for CNN benchmark,zlheui,8085821,Zhu Lei,zlheui2@gmail.com,CLOSED,2021-05-29T07:59:12Z,2021-09-06T09:38:48Z,"In examples/cnn, for the benchmark.py, we need to call the DistOpt() in python/singa/opt.py for the distributed training","{""url"": ""https://api.github.com/repos/apache/singa/issues/858/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/875,https://api.github.com/repos/apache/singa/issues/875,singa,988207736,875,Git web site publishing to be done via .asf.yaml,lzjpaul,8807719,Zhaojing Luo,,CLOSED,2021-09-04T04:32:21Z,2021-09-05T13:13:07Z,"Git web site publishing to be done via .asf.yaml

-- need to deploy the website via .asf.yaml, otherwise there is a risk of web site going stale.","{""url"": ""https://api.github.com/repos/apache/singa/issues/875/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/875,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c42bZrj,singa,913152739,875,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2021-09-05T13:13:06Z,2021-09-05T13:13:06Z,resolved by https://github.com/apache/singa-site/pull/18,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c42bZrj/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/876,https://api.github.com/repos/apache/singa/issues/876,singa,988208079,876,Add licence header for process_data.py,lzjpaul,8807719,Zhaojing Luo,,CLOSED,2021-09-04T04:35:10Z,2021-09-05T13:14:21Z,"For the file of examples/largedataset_cnn/process_data.py, need to include the Apache license header:","{""url"": ""https://api.github.com/repos/apache/singa/issues/876/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/876,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c42bZuN,singa,913152909,876,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2021-09-05T13:14:20Z,2021-09-05T13:14:20Z,resolved by https://github.com/apache/singa/pull/865,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c42bZuN/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/880,https://api.github.com/repos/apache/singa/issues/880,singa,988284925,880,Fix test errors,NLGithubWP,57171759,prometheus,,CLOSED,2021-09-04T12:35:50Z,2021-09-05T13:48:50Z,"Fix the python test error due to operations not implemented for some data types.

","{""url"": ""https://api.github.com/repos/apache/singa/issues/880/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/880,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c42bbAE,singa,913158148,880,NA,NLGithubWP,57171759,prometheus,,NA,2021-09-05T13:48:50Z,2021-09-05T13:48:50Z,resolved by https://github.com/apache/singa/pull/872,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c42bbAE/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/881,https://api.github.com/repos/apache/singa/issues/881,singa,988284978,881,Fix issues from building python packages,NLGithubWP,57171759,prometheus,,CLOSED,2021-09-04T12:36:11Z,2021-09-05T13:49:06Z,"Fix issues from building python packages (pypi and conda) due to half float supporting.

","{""url"": ""https://api.github.com/repos/apache/singa/issues/881/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/881,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c42bbAm,singa,913158182,881,NA,NLGithubWP,57171759,prometheus,,NA,2021-09-05T13:49:04Z,2021-09-05T13:49:04Z,resolved by https://github.com/apache/singa/pull/872,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c42bbAm/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/882,https://api.github.com/repos/apache/singa/issues/882,singa,988285034,882,Update the release preparing process,NLGithubWP,57171759,prometheus,,CLOSED,2021-09-04T12:36:30Z,2021-09-05T13:49:13Z,"In step 3, we need to add instructions on building wheel files and uploading them to a public server.","{""url"": ""https://api.github.com/repos/apache/singa/issues/882/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/883,https://api.github.com/repos/apache/singa/issues/883,singa,988422437,883,Clean the svn stage repo,KimballCai,53328716,Qingpeng Cai,,CLOSED,2021-09-05T04:41:59Z,2021-09-05T13:14:50Z,We need to clean the svn stage repo so that there are only two folders at any time.,"{""url"": ""https://api.github.com/repos/apache/singa/issues/883/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/883,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c42bZvJ,singa,913152969,883,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2021-09-05T13:14:49Z,2021-09-05T13:14:49Z,resolved by removing older version folders,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c42bZvJ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/884,https://api.github.com/repos/apache/singa/issues/884,singa,988422480,884,Fix the CI build error,KimballCai,53328716,Qingpeng Cai,,CLOSED,2021-09-05T04:42:21Z,2021-09-06T09:46:43Z, Fix the CI build error by downloading the tbb binaries.,"{""url"": ""https://api.github.com/repos/apache/singa/issues/884/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/884,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c42bcuY,singa,913165208,884,NA,zlheui,8085821,Zhu Lei,zlheui2@gmail.com,NA,2021-09-05T14:29:48Z,2021-09-05T14:29:48Z,resolved by https://github.com/apache/singa/pull/867,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c42bcuY/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/903,https://api.github.com/repos/apache/singa/issues/903,singa,1062149192,903,Add Apache license header,lzjpaul,8807719,Zhaojing Luo,,CLOSED,2021-11-24T08:43:51Z,2021-11-25T02:51:28Z,"All source files written by us MUST include the Apache license header.

Need to add Apache license header to https://github.com/apache/singa/tree/dev/examples/cifar_distributed_cnn/run-rtx.sh","{""url"": ""https://api.github.com/repos/apache/singa/issues/903/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/903,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c46VuZW,singa,978773590,903,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2021-11-25T02:51:28Z,2021-11-25T02:51:28Z,Added Apache license header to https://github.com/apache/singa/tree/dev/examples/cifar_distributed_cnn/run-rtx.sh,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c46VuZW/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/904,https://api.github.com/repos/apache/singa/issues/904,singa,1062153614,904,Move data augmentation outside of training iterations for better training efficiency,lzjpaul,8807719,Zhaojing Luo,,CLOSED,2021-11-24T08:48:55Z,2021-12-01T07:02:52Z,"In examples/largedataset_cnn/train_largedata.py, the augmentation should be moved outside of training iterations.

For benchmark datasets, e.g., CIFAR-10 and ImageNet, the augmentation method is pre-defined before the model training, so the augmentation does not need to be carried out on the fly in each iteration.","{""url"": ""https://api.github.com/repos/apache/singa/issues/904/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/904,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c46VgSK,singa,978715786,904,NA,nudles,3797447,Wei Wang,,NA,2021-11-25T01:25:11Z,2021-11-25T01:25:11Z,"But, the data augmentation is done with some randomness, e.g., random cropping offset and random rotation degrees. If you move it outside of the training iterations, you may lose this randomness. As a result, you may not get much benefit from data augmentation.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c46VgSK/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/904,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c46nLLW,singa,983347926,904,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2021-12-01T07:02:49Z,2021-12-01T07:02:49Z,The data augmentation is remained inside each training iteration for better classification accuracy,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c46nLLW/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/911,https://api.github.com/repos/apache/singa/issues/911,singa,1064221500,911,Standardizing the inline comments for largedataset_cnn and cifar_distributed_cnn examples,lzjpaul,8807719,Zhaojing Luo,,CLOSED,2021-11-26T08:38:20Z,2021-12-01T07:03:47Z,"Standardizing the inline comments for largedataset_cnn and cifar_distributed_cnn examples

The inline comments are standardized to make the first letter capital","{""url"": ""https://api.github.com/repos/apache/singa/issues/911/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/911,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c46nLXv,singa,983348719,911,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2021-12-01T07:03:42Z,2021-12-01T07:03:42Z,These comments have been standardized.,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c46nLXv/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/916,https://api.github.com/repos/apache/singa/issues/916,singa,1070164320,916,Add features in the singa web page,lzjpaul,8807719,Zhaojing Luo,,CLOSED,2021-12-03T02:48:36Z,2022-03-04T09:27:58Z,"Rework on the singa web page to add nine features, e.g., Easy installation, Model zoo, Distributed training, Automatic gradient calculation, Memory optimization, Parameter optimization, Interoperability, Time profiling, Half precision.","{""url"": ""https://api.github.com/repos/apache/singa/issues/916/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/916,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c4_HuwU,singa,1058991124,916,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2022-03-04T09:27:54Z,2022-03-04T09:27:54Z,This has been resolved by https://github.com/apache/singa-doc/commit/74666e04e904bd821b327707896fedb84c509ab0,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c4_HuwU/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/917,https://api.github.com/repos/apache/singa/issues/917,singa,1070349279,917,Update dataset path for the largedataset_cnn example,lzjpaul,8807719,Zhaojing Luo,,CLOSED,2021-12-03T08:40:37Z,2022-03-04T09:28:52Z,"-- Update dataset path for the largedataset_cnn example In https://github.com/apache/singa/blob/dev/examples/largedataset_cnn/process_data.py

-- Need to set the dataset_root path to an argument for more flexibility","{""url"": ""https://api.github.com/repos/apache/singa/issues/917/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/943,https://api.github.com/repos/apache/singa/issues/943,singa,1159435146,943,Update the running script for cnn ,lzjpaul,8807719,Zhaojing Luo,,CLOSED,2022-03-04T09:31:17Z,2022-03-05T07:04:00Z,"For examples/cifar_distributed_cnn/run-rtx.sh, previously, there are only resnet, we also need to add the 
models like 'xceptionnet', 'cnn', 'alexnet'.","{""url"": ""https://api.github.com/repos/apache/singa/issues/943/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/943,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c4_KeEk,singa,1059709220,943,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2022-03-05T06:59:10Z,2022-03-05T06:59:10Z,This has been addressed by pull request: https://github.com/apache/singa/commit/dd1250e89b2116bc92d695417f90517045a1422a,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c4_KeEk/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/943,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c4_KeOP,singa,1059709839,943,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2022-03-05T07:04:00Z,2022-03-05T07:04:00Z,"More CNN models can be added here, e.g., 'xceptionnet', 'cnn', 'alexnet', please refer to https://github.com/apache/singa/tree/dev/examples/cifar_distributed_cnn/model","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c4_KeOP/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/944,https://api.github.com/repos/apache/singa/issues/944,singa,1159435463,944,Add Apache license header for the medical image analysis application,lzjpaul,8807719,Zhaojing Luo,,CLOSED,2022-03-04T09:31:38Z,2022-03-05T06:57:15Z,Need to add Apache license header for source files we have added,"{""url"": ""https://api.github.com/repos/apache/singa/issues/944/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/944,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c4_KeBd,singa,1059709021,944,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2022-03-05T06:57:05Z,2022-03-05T06:57:05Z,This has been addressed by pull request: https://github.com/apache/singa/commit/5ea7551cce5eb4aa574f83f432b678c3752bcbca,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c4_KeBd/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/945,https://api.github.com/repos/apache/singa/issues/945,singa,1160201478,945,Standardize the comments for BloodMnist,lzjpaul,8807719,Zhaojing Luo,,CLOSED,2022-03-05T02:59:59Z,2022-03-06T05:15:19Z,"Standardize the comments for BloodMnist by removing comments like ""# %%"", and reconstructing the docstring describing the contents and usage of the module","{""url"": ""https://api.github.com/repos/apache/singa/issues/945/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/945,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c4_LL-y,singa,1059897266,945,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2022-03-06T05:15:06Z,2022-03-06T05:15:06Z,"Specific pull requests have been made, e.g., https://github.com/apache/singa/commit/33bbc71d8b8b86105e529bbffabe735199f49e33","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c4_LL-y/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/946,https://api.github.com/repos/apache/singa/issues/946,singa,1160201543,946,Add Apache license header for the BloodMnist,lzjpaul,8807719,Zhaojing Luo,,CLOSED,2022-03-05T03:00:19Z,2022-03-06T06:45:22Z,Need to add Apache license header for source files we have added,"{""url"": ""https://api.github.com/repos/apache/singa/issues/946/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/946,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c4_LOIy,singa,1059906098,946,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2022-03-06T06:45:11Z,2022-03-06T06:45:11Z,This has been solved by pull request: https://github.com/apache/singa/commit/40d01e2e305317c181abb7e741cd0933a93a84fe,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c4_LOIy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/947,https://api.github.com/repos/apache/singa/issues/947,singa,1160231222,947,update optimizer for bloodmnist ,lzjpaul,8807719,Zhaojing Luo,,CLOSED,2022-03-05T04:51:37Z,2022-03-06T06:46:38Z,update SGD optimizer with Adam for more stable training,"{""url"": ""https://api.github.com/repos/apache/singa/issues/947/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/947,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c4_LOLW,singa,1059906262,947,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2022-03-06T06:46:19Z,2022-03-06T06:46:19Z,"The optimizer has been updated by pull request: 

https://github.com/apache/singa/commit/6d840e48f385b1fcc1601dfe43fe8a7d3ea5736e
https://github.com/apache/singa/commit/23387f420a49c8bf68e4bb2361bbe84f9d0a2251","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c4_LOLW/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/971,https://api.github.com/repos/apache/singa/issues/971,singa,1288459980,971,update CMakeLists.txt,zlheui,8085821,Zhu Lei,zlheui2@gmail.com,CLOSED,2022-06-29T09:52:42Z,2022-08-25T04:03:55Z,"the CMake compilation depends on the git tag to get the version numbers; to remove this dependency, we need to manually update the CMakeLists.txt file to set the version numbers","{""url"": ""https://api.github.com/repos/apache/singa/issues/971/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/971,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5JHqxe,singa,1226746974,971,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2022-08-25T04:03:44Z,2022-08-25T04:03:44Z,the CMakeLists.txt is updated in commit: https://github.com/apache/singa/commit/fe7515f46e4526515486ab2db27fe252ee385289,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5JHqxe/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/971,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5JHqyf,singa,1226747039,971,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2022-08-25T04:03:51Z,2022-08-25T04:03:51Z,resolved,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5JHqyf/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/972,https://api.github.com/repos/apache/singa/issues/972,singa,1288665952,972,Update the version and compilation commands,KimballCai,53328716,Qingpeng Cai,,CLOSED,2022-06-29T12:40:33Z,2022-08-26T13:27:16Z,Update the version and compilation commands in setup.py for v3.3 release,"{""url"": ""https://api.github.com/repos/apache/singa/issues/972/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/972,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5JMdo_,singa,1228003903,972,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2022-08-26T03:13:40Z,2022-08-26T03:13:40Z,This has been addressed by https://github.com/apache/singa/commit/d5df6b24b14e8d2aeb0bc28eaa5bac9f0cb8e407,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5JMdo_/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/972,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5JOTw-,singa,1228487742,972,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2022-08-26T13:26:59Z,2022-08-26T13:26:59Z,resolved,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5JOTw-/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/972,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5JOT2o,singa,1228488104,972,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2022-08-26T13:27:16Z,2022-08-26T13:27:16Z,this issues has been resolved,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5JOT2o/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/973,https://api.github.com/repos/apache/singa/issues/973,singa,1290049994,973,update the runtime Dockerfile,KimballCai,53328716,Qingpeng Cai,,CLOSED,2022-06-30T12:15:55Z,2022-07-28T09:08:42Z,"update the runtime Dockerfile for v3.3, building singa from pip","{""url"": ""https://api.github.com/repos/apache/singa/issues/973/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/973,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5HZhZU,singa,1197872724,973,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2022-07-28T09:07:00Z,2022-07-28T09:07:00Z,"This has been resolved by 

https://github.com/apache/singa/commit/1e90f1ea1677b646e2acd467826b4a110949731a","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5HZhZU/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/973,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5HZh3G,singa,1197874630,973,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2022-07-28T09:08:42Z,2022-07-28T09:08:42Z,resolved,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5HZh3G/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/974,https://api.github.com/repos/apache/singa/issues/974,singa,1291358757,974,update conda and docker files,zlheui,8085821,Zhu Lei,zlheui2@gmail.com,CLOSED,2022-07-01T12:40:36Z,2022-08-24T09:04:37Z,update the conda_build_config.yaml and meta.yaml for v3.3.0,"{""url"": ""https://api.github.com/repos/apache/singa/issues/974/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/974,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5Hl6X3,singa,1201120759,974,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2022-08-01T12:11:46Z,2022-08-01T12:11:46Z,"This has been addressed in dev branch

https://github.com/apache/singa/commit/d5df6b24b14e8d2aeb0bc28eaa5bac9f0cb8e407","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5Hl6X3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/974,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5Hl6n9,singa,1201121789,974,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2022-08-01T12:12:36Z,2022-08-01T12:12:36Z,This commit has been updated in the master branch in https://github.com/apache/singa/commit/d5df6b24b14e8d2aeb0bc28eaa5bac9f0cb8e407,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5Hl6n9/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/974,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5JCsJq,singa,1225441898,974,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2022-08-24T09:04:33Z,2022-08-24T09:04:33Z,resolved,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5JCsJq/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/975,https://api.github.com/repos/apache/singa/issues/975,singa,1317771155,975,AttributeError: module 'singa.singa_wrap' has no attribute 'Communicator',lalitjain99,58229929,,,CLOSED,2022-07-26T06:40:27Z,2022-08-01T11:54:44Z,"I am trying to implement distribute training using DistOpt but getting error 

sgd = opt.SGD(lr=0.005, momentum=0.9, weight_decay=1e-5)
sgd = opt.DistOpt(sgd)
model.set_optimizer(sgd)
dev = device.create_cuda_gpu_on(sgd.local_rank)


---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
[<ipython-input-8-d0c92a72565d>](https://localhost:8080/#) in <module>()
      1 sgd = opt.SGD(lr=0.005, momentum=0.9, weight_decay=1e-5)
----> 2 sgd = opt.DistOpt(sgd)
      3 model.set_optimizer(sgd)
      4 dev = device.create_cuda_gpu_on(sgd.local_rank)

[/usr/local/lib/python3.7/dist-packages/singa/opt.py](https://localhost:8080/#) in __init__(self, opt, nccl_id, local_rank, world_size, buffSize)
    723         if nccl_id is None:
    724             # constructure for application using MPI
--> 725             self.communicator = singa.Communicator(buffSize)
    726         else:
    727             # constructor for application using python multi-process module

AttributeError: module 'singa.singa_wrap' has no attribute 'Communicator'","{""url"": ""https://api.github.com/repos/apache/singa/issues/975/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/975,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5HZhCp,singa,1197871273,975,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2022-07-28T09:05:40Z,2022-07-28T09:05:40Z,"Hi,

It is advised to use the miniconda 3 with python 3.6 as here:

https://singa.apache.org/docs/3.1.0/installation/

And you can also try installing 3.1.0 using the conda option","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5HZhCp/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/975,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5HlzpT,singa,1201093203,975,NA,lalitjain99,58229929,,,NA,2022-08-01T11:45:25Z,2022-08-01T11:45:25Z,"Hi Team,

I have installed 3.1.0 as per documentation. 
But when I am applying the distopt api , its crashing.
[SINGA_Install_CPU(pip).zip](https://github.com/apache/singa/files/9233644/SINGA_Install_CPU.pip.zip)
Below is the code:-

     from singa import singa_wrap as singa
     from singa import device
     from singa import tensor
     from singa import opt
     import numpy as np
     import time
     import argparse
     from PIL import Image
     from singa import layer
     from singa import model
     from singa import tensor
     from singa import opt
     from singa import device

    class MLP(model.Model):

    def __init__(self, data_size=10, perceptron_size=100, num_classes=10):
        super(MLP, self).__init__()
        self.num_classes = num_classes
        self.dimension = 2

        self.relu = layer.ReLU()
        self.linear1 = layer.Linear(perceptron_size)
        self.linear2 = layer.Linear(num_classes)
        self.softmax_cross_entropy = layer.SoftMaxCrossEntropy()

    def forward(self, inputs):
        y = self.linear1(inputs)
        y = self.relu(y)
        y = self.linear2(y)
        return y

    def train_one_batch(self, x, y, dist_option, spars):
        out = self.forward(x)
        loss = self.softmax_cross_entropy(out, y)

        if dist_option == 'plain':
            self.optimizer(loss)
        elif dist_option == 'half':
            self.optimizer.backward_and_update_half(loss)
        elif dist_option == 'partialUpdate':
            self.optimizer.backward_and_partial_update(loss)
        elif dist_option == 'sparseTopK':
            self.optimizer.backward_and_sparse_update(loss,
                                                      topK=True,
                                                      spars=spars)
        elif dist_option == 'sparseThreshold':
            self.optimizer.backward_and_sparse_update(loss,
                                                      topK=False,
                                                      spars=spars)
        return out, loss

    def set_optimizer(self, optimizer):
        self.optimizer = optimizer


    def create_model(pretrained=False, **kwargs):
       """"""Constructs a CNN model.
       Args:
          pretrained (bool): If True, returns a pre-trained model.
    
       Returns:
         The created CNN model.
      """"""
      model = MLP(**kwargs)

      return model

     __all__ = ['MLP', 'create_model']

     if __name__ == ""__main__"":
        np.random.seed(0)

    # generate the boundary
    f = lambda x: (5 * x + 1)
    bd_x = np.linspace(-1.0, 1, 200)
    bd_y = f(bd_x)

    # generate the training data
    x = np.random.uniform(-1, 1, 400)
    y = f(x) + 2 * np.random.randn(len(x))

  
    # convert training data to 2d space
    label = np.asarray([5 * a + 1 > b for (a, b) in zip(x, y)]).astype(np.int32)
    data = np.array([[a, b] for (a, b) in zip(x, y)], dtype=np.float32)

    dev = device.create_cuda_gpu_on(0)
    sgd = opt.SGD(0.1, 0.9, 1e-5)
    #**sgd = opt.DistOpt(sgd)**
    tx = tensor.Tensor((400, 2), dev, tensor.float32)
    ty = tensor.Tensor((400,), dev, tensor.int32)
    model = MLP(data_size=2, perceptron_size=3, num_classes=2)

    # attach model to graph
    model.set_optimizer(sgd)
    model.compile([tx], is_train=True, sequential=True)
    model.train()

    for i in range(100):
        tx.copy_from_numpy(data)
        ty.copy_from_numpy(label)
        out, loss = model(tx, ty, 'fp32', spars=None)

        if i % 100 == 0:
            print(""training loss = "", tensor.to_numpy(loss)[0])



","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5HlzpT/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/983,https://api.github.com/repos/apache/singa/issues/983,singa,1350289096,983,Update bloodmnist example by refining inline comments,lzjpaul,8807719,Zhaojing Luo,,CLOSED,2022-08-25T04:05:46Z,2022-08-26T03:11:44Z,Unify inline comments of bloodmnist example by making the first word capital,"{""url"": ""https://api.github.com/repos/apache/singa/issues/983/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/983,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5JIZ41,singa,1226939957,983,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2022-08-25T08:22:53Z,2022-08-25T08:22:53Z,"resolved by commits:

https://github.com/apache/singa/commit/1ca75767faec7179fd78e0735504617af56d0f09
https://github.com/apache/singa/commit/7bf8a7e6a5f01d35429dd063dccf93d477e2d62f
https://github.com/apache/singa/commit/9b8e1e94636088346709e9cfa638df512e1d5bc2
https://github.com/apache/singa/commit/35b55acabccf53175a44f8c7c2831891d48f275a","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5JIZ41/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/983,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5JMc4J,singa,1228000777,983,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2022-08-26T03:11:41Z,2022-08-26T03:11:41Z,resolved,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5JMc4J/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/986,https://api.github.com/repos/apache/singa/issues/986,singa,1350517194,986,Update documentation for distributed training,lzjpaul,8807719,Zhaojing Luo,,CLOSED,2022-08-25T08:21:00Z,2022-12-06T03:52:35Z,"need to update documentation for distributed training, https://singa.apache.org/docs/dist-train/

e.g., adding explanations for conda package installation, optimizer selection, explanations for different data copies in different machines","{""url"": ""https://api.github.com/repos/apache/singa/issues/986/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/986,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5Pyvvq,singa,1338702826,986,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2022-12-06T03:52:26Z,2022-12-06T03:52:26Z,this has been resolved in https://github.com/apache/singa-doc/commit/94b83b1bb035ac7a1676bb4361c00e5be9d0162b,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5Pyvvq/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/1018,https://api.github.com/repos/apache/singa/issues/1018,singa,1476174818,1018,Switch between CPU and GPU devices for cnn example,lzjpaul,8807719,Zhaojing Luo,,CLOSED,2022-12-05T10:04:00Z,2024-06-13T14:57:08Z,"For cifar_distributed_cnn and cnn examples, the model is by default run on the GPU. Need to enable it to run on CPU for machines with only CPUs","{""url"": ""https://api.github.com/repos/apache/singa/issues/1018/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1018,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5Vs27g,singa,1437822688,1018,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2023-02-21T03:53:08Z,2023-02-21T03:53:08Z,Add a conditional judgement to decide whether use CPU or GPU and then apply the devices to datasets and models,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5Vs27g/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1018,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5Vs2_9,singa,1437822973,1018,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2023-02-21T03:53:47Z,2023-02-21T03:53:47Z,https://github.com/apache/singa/commit/0a2d9b20c743b7b1501f1b50db32d36b00de85a0,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5Vs2_9/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1018,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5WBGnp,singa,1443129833,1018,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2023-02-24T08:32:14Z,2023-02-24T08:32:14Z,modify line 114 for judging CPU and GPU in https://github.com/apache/singa/blob/dev/examples/cifar_distributed_cnn/train_cnn.py,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5WBGnp/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1018,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c6BGWA4,singa,2165923896,1018,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2024-06-13T14:57:05Z,2024-06-13T14:57:05Z,This has been resolved in https://github.com/apache/singa/blob/dev/examples/cifar_distributed_cnn/train_cnn.py,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c6BGWA4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/1021,https://api.github.com/repos/apache/singa/issues/1021,singa,1478104317,1021,Save the downloaded datasets to local directory,lzjpaul,8807719,Zhaojing Luo,,CLOSED,2022-12-06T03:51:33Z,2024-09-14T10:02:16Z,"In cnn and cifar_distributed_cnn examples, the downloaded files are in the /tmp directory, which may be lost after the machine is restarted.","{""url"": ""https://api.github.com/repos/apache/singa/issues/1021/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1021,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5VkFn1,singa,1435523573,1021,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2023-02-18T08:46:43Z,2023-02-18T08:46:43Z,add an arguments for local directory and then save the downloaded files to this directory,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5VkFn1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1021,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5VlwYy,singa,1435960882,1021,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2023-02-19T11:18:12Z,2023-02-19T11:18:12Z,changed in example folder https://github.com/apache/singa/tree/dev/examples/cnn/data and https://github.com/apache/singa/tree/dev/examples/cifar_distributed_cnn/data,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5VlwYy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1021,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c6MIHVf,singa,2350937439,1021,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2024-09-14T10:02:12Z,2024-09-14T10:02:12Z,resolved,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c6MIHVf/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/1024,https://api.github.com/repos/apache/singa/issues/1024,singa,1481228920,1024,Add running scripts for cnn and cifar_distributed_cnn examples,lzjpaul,8807719,Zhaojing Luo,,CLOSED,2022-12-07T07:35:47Z,2023-09-05T08:41:17Z,"For cnn and cifar_distributed_cnn examples, we need to add running scripts for different models and datasets so that it is easier for users to try out the example.","{""url"": ""https://api.github.com/repos/apache/singa/issues/1024/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1024,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5P68zQ,singa,1340853456,1024,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2022-12-07T11:48:56Z,2022-12-07T11:48:56Z,This has been addressed by files of https://github.com/apache/singa/blob/dev/examples/cifar_distributed_cnn/run-rtx.sh and https://github.com/apache/singa/blob/dev/examples/cnn/run.sh,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5P68zQ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1024,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5P683q,singa,1340853738,1024,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2022-12-07T11:49:13Z,2022-12-07T11:49:13Z,Resolved,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5P683q/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1024,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5WR_ia,singa,1447557274,1024,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2023-02-28T04:25:46Z,2023-02-28T04:25:46Z,"Need to consider different datasets, i.e., mnist, cifar-10 and cifar-100","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5WR_ia/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1024,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5lsmnl,singa,1706191333,1024,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2023-09-05T08:41:16Z,2023-09-05T08:41:16Z,this has been resolved,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5lsmnl/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/1027,https://api.github.com/repos/apache/singa/issues/1027,singa,1483688184,1027,Intermediate information printing,lzjpaul,8807719,Zhaojing Luo,,CLOSED,2022-12-08T05:13:12Z,2024-09-09T08:03:49Z,Need to print intermediate information for cnn and cifar_distributed_cnn examples since it may take quite long for large models to finish one epoch of training,"{""url"": ""https://api.github.com/repos/apache/singa/issues/1027/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1027,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5Vy35J,singa,1439399497,1027,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2023-02-22T03:47:19Z,2023-02-22T03:47:19Z,"in https://github.com/apache/singa/blob/dev/examples/cnn/train_cnn.py, enable line 203-205 for printing the existing batch number","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5Vy35J/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1027,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5WBFX0,singa,1443124724,1027,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2023-02-24T08:30:25Z,2023-02-24T08:30:25Z,enable line 227 to 229 in https://github.com/apache/singa/blob/dev/examples/cifar_distributed_cnn/train_cnn.py,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5WBFX0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1027,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c58mYl5,singa,2090436985,1027,NA,GY-GitCode,165798068,,,NA,2024-05-02T12:56:21Z,2024-05-02T12:56:21Z,resolved in https://github.com/apache/singa/commit/ac7d8565cfd0f843f0afdf845de72758fdfdad38,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c58mYl5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1027,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c6LUgVq,singa,2337408362,1027,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2024-09-09T08:03:49Z,2024-09-09T08:03:49Z,resolved,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c6LUgVq/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/1038,https://api.github.com/repos/apache/singa/issues/1038,singa,1600992148,1038,Adding arguments for weight decay and momentum,lzjpaul,8807719,Zhaojing Luo,,CLOSED,2023-02-27T11:22:48Z,2023-09-08T12:01:42Z,Adding arguments for weight decay and momentum,"{""url"": ""https://api.github.com/repos/apache/singa/issues/1038/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1038,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5WMqiY,singa,1446160536,1038,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2023-02-27T11:24:15Z,2023-02-27T11:24:15Z,"For https://github.com/apache/singa/blob/dev/examples/cifar_distributed_cnn/train_cnn.py#L308

weight decay and momentum are key parameters for SGD, we need to pass in arguments instead of fixing them","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5WMqiY/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1038,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5mBFYc,singa,1711560220,1038,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2023-09-08T12:01:41Z,2023-09-08T12:01:41Z,resolved,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5mBFYc/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/1039,https://api.github.com/repos/apache/singa/issues/1039,singa,1604435962,1039,Increase max epoch for cnn example for better convergence,lzjpaul,8807719,Zhaojing Luo,,CLOSED,2023-03-01T07:48:26Z,2023-09-02T03:31:05Z,Increase max epoch for cnn example for better convergence,"{""url"": ""https://api.github.com/repos/apache/singa/issues/1039/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1039,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5li_wd,singa,1703672861,1039,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2023-09-02T03:30:58Z,2023-09-02T03:30:58Z,This has been resolved in https://github.com/apache/singa/tree/dev-postgresql/examples/cnn,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5li_wd/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1039,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5li_xt,singa,1703672941,1039,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2023-09-02T03:31:05Z,2023-09-02T03:31:05Z,https://github.com/apache/singa/tree/dev-postgresql/examples/cnn,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5li_xt/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/1042,https://api.github.com/repos/apache/singa/issues/1042,singa,1610060423,1042,Update CMakeLists.txt for release 4.0.0,lzjpaul,8807719,Zhaojing Luo,,CLOSED,2023-03-05T05:14:16Z,2023-03-17T07:46:29Z,Update CMakeLists.txt for release 4.0.0,"{""url"": ""https://api.github.com/repos/apache/singa/issues/1042/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1042,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5X0Oh5,singa,1473308793,1042,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2023-03-17T07:46:22Z,2023-03-17T07:46:22Z,Updated by commit: https://github.com/apache/singa/commit/419c16f73427924f44a0373944b077ec8fab8932,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5X0Oh5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/1043,https://api.github.com/repos/apache/singa/issues/1043,singa,1610107568,1043,Check Apache license header for release 4.0.0,lzjpaul,8807719,Zhaojing Luo,,OPEN,2023-03-05T08:39:44Z,2023-03-05T08:39:44Z,All source files written by us MUST include the Apache license header: http://www.apache.org/legal/src-headers.html.,"{""url"": ""https://api.github.com/repos/apache/singa/issues/1043/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/1044,https://api.github.com/repos/apache/singa/issues/1044,singa,1610226456,1044,OpenCL Compilation Fails,ekare,6527935,Emre Ersin,,OPEN,2023-03-05T14:40:57Z,2023-03-05T14:40:57Z,"On master branch cmake compile fails 

Configuration: 

```
root@1cbf9f240cc2:~/singa/build# cmake -DENABLE_TEST=ON -DUSE_PYTHON3=ON -DUSE_DNNL=ON 
-DUSE_OPENCL=ON ..
-- SINGA git Version 3.3.0
-- SINGA Version 3300
-- FOUND GLOG at /usr/include
-- Found ViennaCL include: /usr/include
-- ********************* Found ViennaCL headers at /usr/include
-- Found DNNL at /root/dnnl_lnx_1.1.0_cpu_gomp/include
-- Configuring done
-- Generating done
-- Build files have been written to: /root/singa/build

```

with make -j12

```

[ 25%] Building CXX object src/CMakeFiles/singa_objects.dir/core/tensor/tensor.cc.o
/root/singa/src/core/device/opencl_device.cc: In member function 'void singa::OpenclDevice::BuildPrograms()':
/root/singa/src/core/device/opencl_device.cc:96:46: error: 'distribution_str' is not a member of 'viennacl::backend::opencl'
   ocl::current_context().add_program(opencl::distribution_str,
                                              ^~~~~~~~~~~~~~~~
/root/singa/src/core/device/opencl_device.cc:98:46: error: 'tensormath_str' is not a member of 'viennacl::backend::opencl'
   ocl::current_context().add_program(opencl::tensormath_str,
                                              ^~~~~~~~~~~~~~
/root/singa/src/core/device/opencl_device.cc:100:46: error: 'im2col_str' is not a member of 'viennacl::backend::opencl'
   ocl::current_context().add_program(opencl::im2col_str, ""opencl_im2col"");
                                              ^~~~~~~~~~
/root/singa/src/core/device/opencl_device.cc:101:46: error: 'pooling_str' is not a member of 'viennacl::backend::opencl'
   ocl::current_context().add_program(opencl::pooling_str, ""opencl_pooling"");
                                              ^~~~~~~~~~~
```

and after;

```

/usr/include/c++/7/bits/shared_ptr.h:344:64:   required from 'std::shared_ptr<_Tp>::shared_ptr(std::_Sp_make_shared_tag, const _Alloc&, _Args&& ...) [with _Alloc = std::allocator<singa::OpenclDevice>; _Args = {}; _Tp = singa::OpenclDevice]'
/usr/include/c++/7/bits/shared_ptr.h:690:14:   required from 'std::shared_ptr<_Tp> std::allocate_shared(const _Alloc&, _Args&& ...) [with _Tp = singa::OpenclDevice; _Alloc = std::allocator<singa::OpenclDevice>; _Args = {}]'
/usr/include/c++/7/bits/shared_ptr.h:706:39:   required from 'std::shared_ptr<_Tp> std::make_shared(_Args&& ...) [with _Tp = singa::OpenclDevice; _Args = {}]'
/root/singa/src/core/device/platform.cc:169:41:   required from here
/usr/include/c++/7/ext/new_allocator.h:136:4: error: invalid new-expression of abstract class type 'singa::OpenclDevice'
  { ::new((void *)__p) _Up(std::forward<_Args>(__args)...); }
    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
In file included from /root/singa/src/core/device/platform.cc:22:0:
/root/singa/include/singa/core/device.h:253:7: note:   because the following virtual functions are pure within 'singa::OpenclDevice':
 class OpenclDevice : public singa::Device {
       ^~~~~~~~~~~~
/root/singa/include/singa/core/device.h:134:16: note: 	virtual void singa::Device::TimeProfilingDoExec(std::function<void(singa::_Context*)>&&, int, singa::Node*)
   virtual void TimeProfilingDoExec(function<void(Context*)>&& fn, int executor,
                ^~~~~~~~~~~~~~~~~~~
/root/singa/include/singa/core/device.h:136:16: note: 	virtual void singa::Device::EvaluateTimeElapsed(singa::Node*)
   virtual void EvaluateTimeElapsed(Node* node) = 0;


```

","{""url"": ""https://api.github.com/repos/apache/singa/issues/1044/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/1045,https://api.github.com/repos/apache/singa/issues/1045,singa,1612646225,1045,Upload Release 4.0.0 Package to SVN,lzjpaul,8807719,Zhaojing Luo,,OPEN,2023-03-07T03:24:45Z,2023-03-17T07:44:33Z,Upload Release 4.0.0 Package to SVN,"{""url"": ""https://api.github.com/repos/apache/singa/issues/1045/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1045,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5X0OJQ,singa,1473307216,1045,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2023-03-17T07:44:32Z,2023-03-17T07:44:32Z,release candidate commited to https://dist.apache.org/repos/dist/dev/singa/4.0.0.rc1/,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5X0OJQ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/1054,https://api.github.com/repos/apache/singa/issues/1054,singa,1670770592,1054,Update the NOTICE file for images,lemonviv,9377547,Yuncheng Wu,,CLOSED,2023-04-17T09:26:42Z,2023-04-18T11:42:49Z,"For images created by ourselves, we should explain them in the NOTICE file.","{""url"": ""https://api.github.com/repos/apache/singa/issues/1054/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1054,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5aLYnY,singa,1512933848,1054,NA,lemonviv,9377547,Yuncheng Wu,,NA,2023-04-18T11:42:33Z,2023-04-18T11:42:33Z,addressed by https://github.com/apache/singa/commit/adc72effea359796d1aa2c3e19f4dd2950c099ad,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5aLYnY/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/1055,https://api.github.com/repos/apache/singa/issues/1055,singa,1670943801,1055,gitignore and gitmodules should be removed from the release tar file,NLGithubWP,57171759,prometheus,,CLOSED,2023-04-17T11:14:00Z,2023-04-17T12:48:16Z,"gitignore and gitmodules should be removed from the release tar file, for proper license headers","{""url"": ""https://api.github.com/repos/apache/singa/issues/1055/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1055,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5aElAq,singa,1511149610,1055,NA,NLGithubWP,57171759,prometheus,,NA,2023-04-17T11:14:08Z,2023-04-17T11:14:08Z,We need a PR to solve it,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5aElAq/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1055,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5aFCi_,singa,1511270591,1055,NA,NLGithubWP,57171759,prometheus,,NA,2023-04-17T12:45:42Z,2023-04-17T12:45:42Z,This has been addressed by https://github.com/apache/singa/commit/adc72effea359796d1aa2c3e19f4dd2950c099ad,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5aFCi_/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/1058,https://api.github.com/repos/apache/singa/issues/1058,singa,1708501404,1058,Create a new branch dev-postgresql,zmeihui,11807302,zmeihui,,CLOSED,2023-05-13T07:29:07Z,2023-09-02T03:28:19Z,Add a new branch for models on top of postgresql,"{""url"": ""https://api.github.com/repos/apache/singa/issues/1058/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1058,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5li_nG,singa,1703672262,1058,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2023-09-02T03:28:05Z,2023-09-02T03:28:05Z,The branch has been created,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5li_nG/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1058,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5li_om,singa,1703672358,1058,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2023-09-02T03:28:19Z,2023-09-02T03:28:19Z,"The branch has been created

","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5li_om/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/1077,https://api.github.com/repos/apache/singa/issues/1077,singa,1876897477,1077,Create the SumError New Loss Function,solopku,14588544,Cai Shaofeng,,CLOSED,2023-09-01T07:26:34Z,2024-04-27T13:13:14Z,Need to create the SumError loss function for training-free model evaluation,"{""url"": ""https://api.github.com/repos/apache/singa/issues/1077/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1077,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c58A-N7,singa,2080629627,1077,NA,solopku,14588544,Cai Shaofeng,,NA,2024-04-27T13:13:14Z,2024-04-27T13:13:14Z,resolved,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c58A-N7/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/1079,https://api.github.com/repos/apache/singa/issues/1079,singa,1878495585,1079,Dynamic Creation of Models,solopku,14588544,Cai Shaofeng,,CLOSED,2023-09-02T08:57:31Z,2024-04-02T14:04:22Z,Need to create the model structures dynamically for model selection applications,"{""url"": ""https://api.github.com/repos/apache/singa/issues/1079/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1079,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5luYhD,singa,1706657859,1079,NA,zmeihui,11807302,zmeihui,,NA,2023-09-05T13:46:59Z,2023-09-05T13:46:59Z,Create the ms_model_mlp folder for model creation using a list of hidden layer sizes,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5luYhD/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1079,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c55H_YZ,singa,2032137753,1079,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2024-04-02T14:04:16Z,2024-04-02T14:04:16Z,This has been resolved,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c55H_YZ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/1081,https://api.github.com/repos/apache/singa/issues/1081,singa,1879879897,1081,Need to return the gradients from optimizer,daoducanhc,59494615,Chris,,CLOSED,2023-09-04T09:30:22Z,2023-09-07T09:25:29Z,Need to return the gradients from the optimizer for calculating the training-free metric,"{""url"": ""https://api.github.com/repos/apache/singa/issues/1081/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1081,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5lrWUJ,singa,1705862409,1081,NA,daoducanhc,59494615,Chris,,NA,2023-09-05T02:32:36Z,2023-09-05T02:32:36Z,the gradients are returned in the line 242 of https://github.com/apache/singa/commit/d9831d917ae0918749faacf5a611b161cbdd1fc9#diff-882c3945309d2e5184aa4c29cbbcc2eb0c95911af8319b5332d049ba72f55aecR242,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5lrWUJ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1081,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5lx89s,singa,1707593580,1081,NA,zmeihui,11807302,zmeihui,,NA,2023-09-06T03:16:14Z,2023-09-06T03:16:14Z,"In Line 432 of https://github.com/apache/singa/blob/dev-postgresql/examples/model_selection_psql/ms_mlp/train_mlp.py#L432

the gradients are returned and used in the training process","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5lx89s/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1081,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5l6YhP,singa,1709803599,1081,NA,daoducanhc,59494615,Chris,,NA,2023-09-07T09:25:12Z,2023-09-07T09:25:12Z,"resolved in https://github.com/apache/singa/commit/d9831d917ae0918749faacf5a611b161cbdd1fc9
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5l6YhP/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1081,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5l6YnR,singa,1709803985,1081,NA,daoducanhc,59494615,Chris,,NA,2023-09-07T09:25:29Z,2023-09-07T09:25:29Z,"resolved in https://github.com/apache/singa/commit/d9831d917ae0918749faacf5a611b161cbdd1fc9
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c5l6YnR/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/1084,https://api.github.com/repos/apache/singa/issues/1084,singa,1883045170,1084,Maximum recursion depth exceeded in comparison for string,daoducanhc,59494615,Chris,,CLOSED,2023-09-06T02:25:31Z,2024-04-27T11:28:03Z,"In the remove_creator function of the model wrapper, we need to solve the issue of maximum recursion depth exceeded in comparison, by separately processing for string","{""url"": ""https://api.github.com/repos/apache/singa/issues/1084/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1084,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c58AUnY,singa,2080459224,1084,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2024-04-27T11:27:48Z,2024-04-27T11:27:48Z,Resolved in https://github.com/apache/singa/commit/26deb2c7d750693e6be8eb50b456e4362712786b,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c58AUnY/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/1140,https://api.github.com/repos/apache/singa/issues/1140,singa,2173778220,1140,can sparse all-reduce keep efficiency with large number of gpu workers？  ,Eiji911,137666922,,,OPEN,2024-03-07T12:42:05Z,2024-03-07T12:42:05Z,"in my opinion, when the gpu cluster scaled up to several hundred workers, high sparsification ratios still generate significant communication overheads, which even worst than DenseAllReduce.


","{""url"": ""https://api.github.com/repos/apache/singa/issues/1140/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/1164,https://api.github.com/repos/apache/singa/issues/1164,singa,2267317235,1164,"Python 3.11, Model, ImportError",fengints,64303724,,,OPEN,2024-04-28T03:26:35Z,2024-04-28T03:42:13Z,"Python 3.11.6, Clean install
pip install singa -f http://singa.apache.org/docs/next/wheel-cpu.html --trusted-host singa.apache.org
>>>from singa import model

Error:
python3.11/site-packages/singa/model.py"", line 30, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' 
https://github.com/apache/singa/blob/6d9cd7f9ab6e1ce3caac381db586814464fe5511/python/singa/model.py#L30


I also tried importing Model
>>>from singa import Model

File ""<stdin>"", line 1, in <module>
ImportError: cannot import name 'Model' from 'singa'

","{""url"": ""https://api.github.com/repos/apache/singa/issues/1164/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1164,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c58DkaZ,singa,2081310361,1164,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2024-04-28T03:31:12Z,2024-04-28T03:31:12Z,"May I know did you use conda or other installation tools?

You can send an email to zhaojing@apache.org, we can discuss via email.

Thanks,
Zhaojing.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c58DkaZ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1164,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c58DkcA,singa,2081310464,1164,NA,fengints,64303724,,,NA,2024-04-28T03:31:44Z,2024-04-28T03:31:44Z,"Iam using python and pip, no conda","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c58DkcA/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1164,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c58DkjA,singa,2081310912,1164,NA,fengints,64303724,,,NA,2024-04-28T03:33:55Z,2024-04-28T03:33:55Z,"The Iterable abstract class was removed from collections in Python 3.10


https://docs.python.org/3.8/library/collections.html
Deprecated since version 3.3, will be removed in version 3.10: Moved [Collections Abstract Base Classes](https://docs.python.org/3.8/library/collections.abc.html#collections-abstract-base-classes) to the [collections.abc](https://docs.python.org/3.8/library/collections.abc.html#module-collections.abc) module. For backwards compatibility, they continue to be visible in this module through Python 3.9.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c58DkjA/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1164,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c58DknW,singa,2081311190,1164,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2024-04-28T03:35:05Z,2024-04-28T03:35:05Z,"> Iam using python and pip, no conda

Can you try the conda (miniconda or anaconda) and install the python 3.9. and then in the conda environment, you can try install singa 3.9 version. We provide python versions 3.9, 3.10 and 3.11

Thanks.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c58DknW/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1164,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c58DkyA,singa,2081311872,1164,NA,fengints,64303724,,,NA,2024-04-28T03:38:41Z,2024-04-28T03:38:41Z,i think python 3.9 would pass this error,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c58DkyA/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1164,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c58DkyC,singa,2081311874,1164,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2024-04-28T03:38:41Z,2024-04-28T03:38:41Z,"An easier way is to download the wheel file from https://singa.apache.org/docs/next/wheel-cpu.html, and then install it locally. 

For further enquiries, you can send an email to zhaojing@apache.org, and we can discuss them via email.

Thanks.","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c58DkyC/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1164,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c58Dk1N,singa,2081312077,1164,NA,fengints,64303724,,,NA,2024-04-28T03:39:54Z,2024-04-28T03:39:54Z,"Docs says singa supports python 3.9 , 3.10, 3.11
","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c58Dk1N/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1164,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c58Dk36,singa,2081312250,1164,NA,fengints,64303724,,,NA,2024-04-28T03:40:53Z,2024-04-28T03:40:53Z,"Python 3.10 and 3.11 doesn't have Iterable class in collections
https://docs.python.org/3.11/library/collections.html","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c58Dk36/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1164,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c58Dk5r,singa,2081312363,1164,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2024-04-28T03:41:35Z,2024-04-28T03:41:35Z,"> i think python 3.9 would pass this error

Thanks for your suggestion!","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c58Dk5r/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/1209,https://api.github.com/repos/apache/singa/issues/1209,singa,2511600959,1209,Update the Release 4.3.0 Package to SVN,lzjpaul,8807719,Zhaojing Luo,,CLOSED,2024-09-07T11:16:00Z,2024-09-09T04:10:06Z,"release candidate committed to https://dist.apache.org/repos/dist/dev/singa/4.3.0-rc1/
","{""url"": ""https://api.github.com/repos/apache/singa/issues/1209/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1209,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c6LTOio,singa,2337073320,1209,NA,chrishkchris,38325429,Chris Yeung,,NA,2024-09-09T04:10:05Z,2024-09-09T04:10:05Z,Resolved ,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c6LTOio/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/1210,https://api.github.com/repos/apache/singa/issues/1210,singa,2512173514,1210,Update the online documentations,dcslin,13751447,Shicong,,CLOSED,2024-09-08T03:15:13Z,2024-09-09T03:02:26Z,Update the online documentations for (1) Add the news for the SIGMOD Systems Award (2) Update the information of V 4.3.0,"{""url"": ""https://api.github.com/repos/apache/singa/issues/1210/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1210,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c6LTBP8,singa,2337018876,1210,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2024-09-09T03:02:11Z,2024-09-09T03:02:11Z,"Resolved in 
https://github.com/apache/singa-doc/commit/d7660ff71a00770850de9112beb3ac89a91a4b0a
and
https://github.com/apache/singa-doc/commit/2522ccb7b5fd0055eab8e177c5b8ced6852b0e54","{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c6LTBP8/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/1211,https://api.github.com/repos/apache/singa/issues/1211,singa,2512174175,1211,Extend the matrix multiplication operator to more dimensions,gzrp,118953675,Zhang Rui peng,,CLOSED,2024-09-08T03:17:58Z,2024-09-14T10:32:00Z,"Extend the matrix multiplication operator to more dimensions for the transformer example
https://github.com/apache/singa/tree/master/examples/trans","{""url"": ""https://api.github.com/repos/apache/singa/issues/1211/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/1212,https://api.github.com/repos/apache/singa/issues/1212,singa,2513225560,1212,"Update the wheel files for Python 3.9, 3.10 and 3.11",solopku,14588544,Cai Shaofeng,,CLOSED,2024-09-09T08:06:42Z,2024-09-10T07:53:19Z,"Update the wheel files for Python 3.9, 3.10 and 3.11","{""url"": ""https://api.github.com/repos/apache/singa/issues/1212/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1212,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c6LeH3S,singa,2339929554,1212,NA,chrishkchris,38325429,Chris Yeung,,NA,2024-09-10T07:53:19Z,2024-09-10T07:53:19Z,Resolved in https://github.com/apache/singa/commit/f594f23084f12b7775892ff0c7753bf277bc5787,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c6LeH3S/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/1217,https://api.github.com/repos/apache/singa/issues/1217,singa,2526845002,1217,Fix Github Actions,Zrealshadow,30857435,Lingze,,CLOSED,2024-09-15T10:20:49Z,2024-09-16T10:17:06Z,Fix the github actions for the online code testing,"{""url"": ""https://api.github.com/repos/apache/singa/issues/1217/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1217,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c6MOI_c,singa,2352517084,1217,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2024-09-16T10:17:00Z,2024-09-16T10:17:00Z,Resolved ,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c6MOI_c/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/1218,https://api.github.com/repos/apache/singa/issues/1218,singa,2529882752,1218, Add sparsification version of the model,NLGithubWP,57171759,prometheus,,CLOSED,2024-09-17T03:07:03Z,2024-12-06T11:51:57Z,Ading the sparsification version of the model for the model selection example.,"{""url"": ""https://api.github.com/repos/apache/singa/issues/1218/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/1242,https://api.github.com/repos/apache/singa/issues/1242,singa,2722863469,1242,Restructure the folder structure for the healthcare applications,lzjpaul,8807719,Zhaojing Luo,,CLOSED,2024-12-06T11:50:18Z,2024-12-08T03:53:07Z,"Restructure the folder structure for the healthcare applications

-- seperate into model, data and application","{""url"": ""https://api.github.com/repos/apache/singa/issues/1242/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1242,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c6WhqBp,singa,2525405289,1242,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2024-12-08T03:53:07Z,2024-12-08T03:53:07Z,Resolved,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c6WhqBp/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/1244,https://api.github.com/repos/apache/singa/issues/1244,singa,2724956063,1244,Update data processing for the benchmark dataset,Zrealshadow,30857435,Lingze,,CLOSED,2024-12-08T05:00:59Z,2024-12-14T07:27:57Z,"Update data processing for the benchmark dataset, need to update the path of the cmn dataset for correct data loading","{""url"": ""https://api.github.com/repos/apache/singa/issues/1244/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/singa/issues/1245,https://api.github.com/repos/apache/singa/issues/1245,singa,2726552573,1245,Update the pom.xml file,lzjpaul,8807719,Zhaojing Luo,,CLOSED,2024-12-09T09:58:51Z,2024-12-22T13:53:04Z,Update the pom.xml file to include paths for datasets,"{""url"": ""https://api.github.com/repos/apache/singa/issues/1245/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/singa/issues/1245,https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c6YfxC1,singa,2558464181,1245,NA,lzjpaul,8807719,Zhaojing Luo,,NA,2024-12-22T13:53:01Z,2024-12-22T13:53:01Z,Updated in the commit: https://github.com/apache/singa/commit/294a719887c79ee1f3f26677c0acd143011a34cb,"{""url"": ""https://api.github.com/repos/apache/singa/issues/comments/IC_kwDOAfwH7c6YfxC1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
