type,issue_url,comment_url,repo_name,id,issue_num,title,user_login,user_id,user_name,user_email,issue_state,created_at,updated_at,body,reactions
issue,https://api.github.com/repos/apache/incubator-livy/issues/366,https://api.github.com/repos/apache/incubator-livy/issues/366,incubator-livy,1482079598,366,New livy release request,aabdullah-getguru,113741909,,,CLOSED,2022-12-07T14:39:42Z,2024-09-13T08:24:43Z,"There have been several updates to master recently, including adding support for later Python versions by fixing a bug that would only allow one line per cell.
Can we possibly have a new release of livy? Amongst other things, this would allow AWS EMR to pull in the latest release with all the fixes.","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/366/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/366,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5P-Fzh,incubator-livy,1341676769,366,NA,lmccay,2303672,,larry.mccay@gmail.com,NA,2022-12-07T22:29:17Z,2022-12-07T22:29:17Z,"The dev@livy list has already begun discussing an upcoming 0.8.0 release.
Open JIRAs have been scoped back to a reasonable number and we are working towards getting dependable build instructions and contribution process defined as part of the revived community here for Livy. Stay tuned and consider watching the dev@ list for more info.","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5P-Fzh/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/366,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5cB9a0,incubator-livy,1544017588,366,NA,aabdullah-getguru,113741909,,,NA,2023-05-11T13:31:15Z,2023-05-11T13:31:15Z,"> The dev@livy list has already begun discussing an upcoming 0.8.0 release. Open JIRAs have been scoped back to a reasonable number and we are working towards getting dependable build instructions and contribution process defined as part of the revived community here for Livy. Stay tuned and consider watching the dev@ list for more info.

I'm keeping tuned! Can't access the dev@livy list, just wondering if there are major outstanding issues left before release? Really appreciate everything that the community does!","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5cB9a0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/366,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs6L-NCm,incubator-livy,2348339366,366,NA,gyogal,27883675,György Gál,,NA,2024-09-13T08:24:42Z,2024-09-13T08:24:42Z,"Hi @aabdullah-getguru, I am closing this issue because Apache Livy version 0.8.0 is released. For more details, please see https://livy.apache.org/history/
","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs6L-NCm/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-livy/issues/370,https://api.github.com/repos/apache/incubator-livy/issues/370,incubator-livy,1491163844,370,livy0.7.1 Request failed,zhaoyuxiaoxiao,40681887,,,OPEN,2022-12-12T07:11:27Z,2022-12-12T10:29:06Z,"spark version: 3.2.1
live version:  release-0.7.1
Request failed：
{""msg"":""requirement failed: Cannot find Livy REPL jars.""}。
Can you help me？thanks","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/370/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/370,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5QPfjt,incubator-livy,1346238701,370,NA,yantzu,7855100,Xilang Yan,,NA,2022-12-12T10:29:06Z,2022-12-12T10:29:06Z,"Livy will try to find out repl jars from:
1, livy.repl.jars config
2, if  livy.repl.jars not set, will find from LIVY_HOME/repl_2.11-jars or
LIVY_HOME/repl_2.12-jars
you may check those first.


zhaoyuxiaoxiao ***@***.***> 于2022年12月12日周一 15:11写道：

> spark version: 3.2.1
> live version: release-0.7.1
> Request failed：
> {""msg"":""requirement failed: Cannot find Livy REPL jars.""}。
> Can you help me？thanks
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/apache/incubator-livy/issues/370>, or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AB35X7DUPGDAZERTZEBNBWTWM3F23ANCNFSM6AAAAAAS3SH5RA>
> .
> You are receiving this because you are subscribed to this thread.Message
> ID: ***@***.***>
>
","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5QPfjt/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-livy/issues/379,https://api.github.com/repos/apache/incubator-livy/issues/379,incubator-livy,1507342404,379,"Error[Failed to launch livy session, session status is dead] on connecting to spark through livy using R",rakshitdeshpande,43578097,Rakshit Deshpande,,OPEN,2022-12-22T06:31:51Z,2022-12-22T06:31:51Z,"I am using sparklyr version [1.7.8](https://github.com/sparklyr/sparklyr)
and latest livy version in master branch [incubator-livy](https://github.com/apache/incubator-livy)

On connecting to spark through livy using R

> library(sparklyr)
> sc <- spark_connect(master = ""local"", method = ""livy"", version =""3.1.1"")

Command is throwing an error:

> Error in livy_connection(master, config, app_name, version, hadoop_version, :
> Failed to launch livy session, session status is dead

Could anyone please help me understand what could the issue be.","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/379/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-livy/issues/380,https://api.github.com/repos/apache/incubator-livy/issues/380,incubator-livy,1508517074,380,"Build with scala 2.12.15 is failing, spark3.3.1, hadoop:3.3.4, hive:3.1..3",navneetpr,49400676,,navneet.prabhakar@brightlifecare.com,OPEN,2022-12-22T20:40:38Z,2023-05-17T09:45:14Z,"Exception when compiling 13 sources to /opt/incubator-livy/test-lib/target/classes
java.lang.NoSuchMethodError: scala.tools.nsc.Settings.nowarn()Lscala/tools/nsc/settings/AbsSettings$AbsSetting;","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/380/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/380,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5cc3Jt,incubator-livy,1551069805,380,NA,cocdkl,50688581,,,NA,2023-05-17T09:35:25Z,2023-05-17T09:35:25Z,我也有这个问题，这边需要使用到pyspark 3.2.0之后的新功能pandas，希望能得到解决方案,"{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5cc3Jt/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/380,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5cc6ZD,incubator-livy,1551083075,380,NA,cocdkl,50688581,,,NA,2023-05-17T09:45:13Z,2023-05-17T09:45:13Z,"官网上有问题的解决方案，这是地址https://issues.apache.org/jira/projects/LIVY/issues/LIVY-877?filter=allissues
具体方案是将scala-maven-plugin 插件升级到最新版本，我升级到的是4.8.1。","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5cc6ZD/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-livy/issues/406,https://api.github.com/repos/apache/incubator-livy/issues/406,incubator-livy,1715056334,406,和spark 3.2.0 及以上版本兼容问题,cocdkl,50688581,,,CLOSED,2023-05-18T06:12:49Z,2024-07-16T13:20:53Z,"现在已经可以使用scala 2.12.15成功编译livy 0.8.0，但是在使用 spark3.2 及 3.3 以上版本时，pyspark 3.3 可以在yarn启动spark，但是提交不了任务，这是代码：
from pyspark.sql import SparkSession
spark=SparkSession.builder.appName(""test"").enableHiveSupport().getOrCreate()

spark.sql(""show databases"").show()
这是问题报错：
23/05/18 14:11:34 INFO BlockManagerMasterEndpoint: Registering block manager localhost:41641 with 366.3 MiB RAM, BlockManagerId(2, localhost, 41641, None)
23/05/18 14:11:34 INFO SparkEntries: Spark context finished initialization in 16437ms
23/05/18 14:11:34 INFO SparkEntries: Created Spark session.
23/05/18 14:11:41 ERROR PythonInterpreter: Process has died with 1
23/05/18 14:11:41 ERROR PythonInterpreter: Traceback (most recent call last):
  File ""/tmp/6067082446938324509"", line 722, in <module>
    sys.exit(main())
  File ""/tmp/6067082446938324509"", line 570, in main
    exec('from pyspark.sql import HiveContext', global_dict)
  File ""<string>"", line 1, in <module>
  File ""/home/cocdkl/soft/spark-3.3.0-bin-hadoop3/python/lib/pyspark.zip/pyspark/__init__.py"", line 71
    def since(version: Union[str, float]) -> Callable[[F], F]:
                     ^
SyntaxError: invalid syntax

通过hue提交的代码，希望得到解答","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/406/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/406,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5cjfcr,incubator-livy,1552807723,406,NA,cocdkl,50688581,,,NA,2023-05-18T09:46:27Z,2023-05-18T09:46:27Z,"这是通过spark 3.2.4 提交任务报的错：
23/05/18 17:43:00 INFO SparkEntries: Created Spark session.
23/05/18 17:43:00 INFO BlockManagerMasterEndpoint: Registering block manager localhost:33381 with 912.3 MiB RAM, BlockManagerId(2, localhost, 33381, None)
23/05/18 17:43:25 ERROR PythonInterpreter: Process has died with 1
23/05/18 17:43:25 ERROR PythonInterpreter: Traceback (most recent call last):
  File ""/tmp/8001765088071541442"", line 722, in <module>
    sys.exit(main())
  File ""/tmp/8001765088071541442"", line 570, in main
    exec('from pyspark.sql import HiveContext', global_dict)
  File ""<string>"", line 1, in <module>
  File ""/home/cocdkl/soft/spark-3.2.4-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/__init__.py"", line 53, in <module>
  File ""/home/cocdkl/soft/spark-3.2.4-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/rdd.py"", line 34, in <module>
  File ""/home/cocdkl/soft/spark-3.2.4-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/java_gateway.py"", line 31, in <module>
  File ""/home/cocdkl/soft/spark-3.2.4-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/find_spark_home.py"", line 68
    print(""Could not find valid SPARK_HOME while searching {0}"".format(paths), file=sys.stderr)
                                                                                   ^
SyntaxError: invalid syntax



奇怪的是在yarn ，spark的集群是启动的，但是一提交具体代码作业，就会报错。

希望得到解决，谢谢","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5cjfcr/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/406,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5cv1bs,incubator-livy,1556043500,406,NA,yantzu,7855100,Xilang Yan,,NA,2023-05-20T23:42:38Z,2023-05-20T23:42:38Z,"We haven't tried Spark 3.3 yet, but Spark 3.2 should work. The log show
error happens in Spark's code /pyspark.zip/pyspark/find_spark_home.py which
seems not related to Livy, 2 suggestion:
1, set SPARK_HOME in livy, to avoid find spark home
2, check your python version

cocdkl ***@***.***> 于2023年5月18日周四 17:46写道：

> 这是通过spark 3.2.4 提交任务报的错：
> 23/05/18 17:43:00 INFO SparkEntries: Created Spark session.
> 23/05/18 17:43:00 INFO BlockManagerMasterEndpoint: Registering block
> manager localhost:33381 with 912.3 MiB RAM, BlockManagerId(2, localhost,
> 33381, None)
> 23/05/18 17:43:25 ERROR PythonInterpreter: Process has died with 1
> 23/05/18 17:43:25 ERROR PythonInterpreter: Traceback (most recent call
> last):
> File ""/tmp/8001765088071541442"", line 722, in
> sys.exit(main())
> File ""/tmp/8001765088071541442"", line 570, in main
> exec('from pyspark.sql import HiveContext', global_dict)
> File """", line 1, in
> File
> ""/home/cocdkl/soft/spark-3.2.4-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/
> *init*.py"", line 53, in
> File
> ""/home/cocdkl/soft/spark-3.2.4-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/rdd.py"",
> line 34, in
> File
> ""/home/cocdkl/soft/spark-3.2.4-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/java_gateway.py"",
> line 31, in
> File
> ""/home/cocdkl/soft/spark-3.2.4-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/find_spark_home.py"",
> line 68
> print(""Could not find valid SPARK_HOME while searching {0}"".format(paths),
> file=sys.stderr)
> ^
> SyntaxError: invalid syntax
>
> 奇怪的是在yarn ，spark的集群是启动的，但是一提交具体代码作业，就会报错。
>
> 希望得到解决，谢谢
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/apache/incubator-livy/issues/406#issuecomment-1552807723>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AB35X7DEAC6DHKPA7JR76HDXGXVX7ANCNFSM6AAAAAAYGA2E2I>
> .
> You are receiving this because you are subscribed to this thread.Message
> ID: ***@***.***>
>
","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5cv1bs/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/406,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5cxCS_,incubator-livy,1556358335,406,NA,cocdkl,50688581,,,NA,2023-05-22T00:50:56Z,2023-05-22T00:50:56Z,"感谢您抽出时间帮我解答问题
我在 livy-env.sh中进行了如下配置
SPARK_HOME=/home/cocdkl/soft/spark-3.2.4-bin-hadoop2.7
SPARK_CONF_DIR=/home/cocdkl/soft/spark-3.2.4-bin-hadoop2.7/conf

并且通过python -V 得到的版本为 2.7.16

我尝试过通过spar直接执行 pyspark命令，可以正常操作。

我写改过 /pyspark.zip/pyspark/find_spark_home.py 这个脚本，将这个脚本的返回值固化为我本地的spark_home目录，但是还是会报其他的错误。","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5cxCS_/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/406,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5cxG4l,incubator-livy,1556377125,406,NA,cocdkl,50688581,,,NA,2023-05-22T01:27:53Z,2023-05-22T01:27:53Z,"这是我pom文件修改的地方
 <scala.binary.version>2.12</scala.binary.version>
 <scala.version>2.12.15</scala.version>
    <!-- spark2 -->
 <spark.version>3.2.4</spark.version>




 <groupId>net.alchim31.maven</groupId>
    <artifactId>scala-maven-plugin</artifactId>
    <version>4.8.1</version>

都是对相应的版本信息进行修改","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5cxG4l/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/406,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5dVAuE,incubator-livy,1565789060,406,NA,yantzu,7855100,Xilang Yan,,NA,2023-05-28T01:41:18Z,2023-05-28T01:41:18Z,"你设置了SPARK_HOME就不会执行find_spark_home.py了，所以可以工作，Spark3最好用python 3

cocdkl ***@***.***> 于2023年5月22日周一 08:51写道：

> 感谢您抽出时间帮我解答问题
> 我在 livy-env.sh中进行了如下配置
> SPARK_HOME=/home/cocdkl/soft/spark-3.2.4-bin-hadoop2.7
> SPARK_CONF_DIR=/home/cocdkl/soft/spark-3.2.4-bin-hadoop2.7/conf
>
> 并且通过python -V 得到的版本为 2.7.16
>
> 我尝试过通过spar直接执行 pyspark命令，可以正常操作。
>
> 我写改过 /pyspark.zip/pyspark/find_spark_home.py
> 这个脚本，将这个脚本的返回值固化为我本地的spark_home目录，但是还是会报其他的错误。
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/apache/incubator-livy/issues/406#issuecomment-1556358335>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AB35X7FNTCPXCPIIE3COU5DXHKZ7XANCNFSM6AAAAAAYGA2E2I>
> .
> You are receiving this because you commented.Message ID:
> ***@***.***>
>
","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5dVAuE/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/406,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5dXOGR,incubator-livy,1566368145,406,NA,cocdkl,50688581,,,NA,2023-05-29T01:39:50Z,2023-05-29T01:39:50Z,"再次感谢您回答我的问题
以下是我环境变量的配置
export PATH=/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/sbin:/usr/sbin
export JAVA_HOME=/home/cocdkl/soft/jdk1.8.0_371
export HADOOP_HOME=/home/cocdkl/soft/hadoop-3.3.0
export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop
export HIVE_HOME=/home/cocdkl/soft/apache-hive-3.1.2-bin
export HIVE_CONF_DIR=/home/cocdkl/soft/apache-hive-3.1.2-bin/conf
#export HIVE_HOME=/home/cocdkl/soft/apache-hive-3.1.3-bin
#export HIVE_CONF_DIR=/home/cocdkl/soft/apache-hive-3.1.3-bin/conf
#export SPARK_HOME=/home/cocdkl/soft/spark-3.0.3-bin-hadoop3.2
#export SPARK_HOME=/home/cocdkl/soft/spark-3.3.0-bin-hadoop3
#export SPARK_HOME=/home/cocdkl/soft/spark-2.3.0-bin-hadoop2.7
export SPARK_HOME=/home/cocdkl/soft/spark-3.2.4-bin-hadoop2.7
#export SPARK_HOME=/home/cocdkl/soft/spark-2.4.8-bin-without-hadoop
export SCALA_HOME=/home/cocdkl/soft/scala-2.13.8
export HBASE_HOME=/home/cocdkl/soft/hbase-2.4.15
export ZOOKEEPER_HOME=/home/cocdkl/soft/apache-zookeeper-3.7.1-bin
export PATH=$JAVA_HOME/bin:$PATH
export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
export PATH=$HIVE_HOME/bin:$PATH
export PATH=$SPARK_HOME/bin:$PATH
export PATH=$SCALA_HOME/bin:$PATH
export PATH=$HBASE_HOME/bin:$PATH
export PATH=$ZOOKEEPER_HOME/bin:$PATH
export CLASSPATH=''
export HADOOP_CLASSPATH=`hadoop classpath`
#export HADOOP_CLASSPATH=/home/cocdkl/soft/HADOOP_CLASSPATH/*

已经设置了SPARK_HOME，但是还是执行find_spark_home.py，这也是我奇怪的地方。","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5dXOGR/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/406,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5dXRzq,incubator-livy,1566383338,406,NA,cocdkl,50688581,,,NA,2023-05-29T01:59:43Z,2023-05-29T01:59:43Z,或者您有编译好的可以支持spark3.2的livy吗，可以提供一下或者更新一下官网下载包吗？我看官网还是0.7.1。,"{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5dXRzq/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/406,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5d5QBV,incubator-livy,1575288917,406,NA,yantzu,7855100,Xilang Yan,,NA,2023-06-04T00:34:58Z,2023-06-04T00:34:58Z,"对Spark3.2的支持我我们没改过代码，就是支持的。
你设置的环境变量里很多都是Livy不需要的吧，我不确定有没有影响，你可以本地debug一下livy，看看Livy里的Spark启动类（
*SparkProcessBuilder或者**ContextLaunche*r）在提交任务的时候环境变量对不对。

cocdkl ***@***.***> 于2023年5月29日周一 09:59写道：

> 或者您有编译好的可以支持spark3.2的livy吗，可以提供一下或者更新一下官网下载包吗？我看官网还是0.7.1。
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/apache/incubator-livy/issues/406#issuecomment-1566383338>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AB35X7EVHZRLQPEWMKWHDM3XIP7JVANCNFSM6AAAAAAYGA2E2I>
> .
> You are receiving this because you commented.Message ID:
> ***@***.***>
>
","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5d5QBV/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/406,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5d5Q2k,incubator-livy,1575292324,406,NA,cocdkl,50688581,,,NA,2023-06-04T00:40:02Z,2023-06-04T00:40:02Z,"首先感谢您的回答。
然后是通过源码查看还是在哪里配置debug选项？
最后，您说没有修改代码，那您的pom有修改吗？我看默认的pom是配置的是spark2.4.5和Scala2.11。您能否分享一下你那边支持spark3.2.0的pom文件？","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5d5Q2k/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/406,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5fAqNx,incubator-livy,1594008433,406,NA,yantzu,7855100,Xilang Yan,,NA,2023-06-16T02:36:21Z,2023-06-16T02:36:21Z,"debug就是正常的java程序debug。
livy代码里对scala 2.11和scala2.12分别有支持，需要兼容的地方有两个maven模块

cocdkl ***@***.***> 于2023年6月4日周日 08:40写道：

> 首先感谢您的回答。
> 然后是通过源码查看还是在哪里配置debug选项？
>
> 最后，您说没有修改代码，那您的pom有修改吗？我看默认的pom是配置的是spark2.4.5和Scala2.11。您能否分享一下你那边支持spark3.2.0的pom文件？
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/apache/incubator-livy/issues/406#issuecomment-1575292324>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AB35X7D42USCDEB6POBQ5BLXJPKOZANCNFSM6AAAAAAYGA2E2I>
> .
> You are receiving this because you commented.Message ID:
> ***@***.***>
>
","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5fAqNx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/406,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5kWaic,incubator-livy,1683597468,406,NA,cocdkl,50688581,,,NA,2023-08-18T09:02:48Z,2023-08-18T09:02:48Z,抱歉，我还是没有解决，您是否能提供一下支持spark3.2.0的pom文件呢？,"{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5kWaic/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/406,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs6E-HrV,incubator-livy,2230876885,406,NA,cocdkl,50688581,,,NA,2024-07-16T13:20:52Z,2024-07-16T13:20:52Z,已经解决了，是python版本的问题，需要python3，但是我这边配置的是python2,"{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs6E-HrV/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-livy/issues/408,https://api.github.com/repos/apache/incubator-livy/issues/408,incubator-livy,1771355265,408,Dockerfile build fails on `livy-server` step,brunolnetto,13961685,Bruno Peixoto,brunolnetto@gmail.com,CLOSED,2023-06-23T12:12:34Z,2025-01-26T10:27:52Z,"Hi,

I try host locally this solution for apache spark on its language flavors with command run `docker build -t livy-ci dev/docker/livy-dev-base/`. After some installation steps, the error log appers on terminal. I attempt on Linux Ubuntu 20.04. 

```
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Livy Project Parent POM ............................ SUCCESS [01:26 min]
[INFO] livy-api ........................................... SUCCESS [03:30 min]
[INFO] livy-client-common ................................. SUCCESS [  4.819 s]
[INFO] livy-test-lib ...................................... SUCCESS [  2.996 s]
[INFO] multi-scala-project-root ........................... SUCCESS [  1.042 s]
[INFO] livy-core-parent ................................... SUCCESS [  0.177 s]
[INFO] livy-core_2.11 ..................................... SUCCESS [  9.340 s]
[INFO] livy-rsc ........................................... SUCCESS [ 50.358 s]
[INFO] livy-repl-parent ................................... SUCCESS [ 25.652 s]
[INFO] livy-repl_2.11 ..................................... SUCCESS [04:05 min]
[INFO] livy-server ........................................ FAILURE [ 48.405 s]
[INFO] livy-assembly ...................................... SKIPPED
[INFO] livy-client-http ................................... SKIPPED
[INFO] livy-scala-api-parent .............................. SKIPPED
[INFO] livy-scala-api_2.11 ................................ SKIPPED
[INFO] livy-integration-test .............................. SKIPPED
[INFO] livy-coverage-report ............................... SKIPPED
[INFO] livy-examples ...................................... SKIPPED
[INFO] livy-python-api .................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 11:26 min
[INFO] Finished at: 2023-06-22T21:17:57+00:00
[INFO] Final Memory: 108M/1364M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal on project livy-server: Could not resolve dependencies for project org.apache.livy:livy-server:jar:0.8.0-incubating-SNAPSHOT: Failed to collect dependencies at io.dropwizard.metrics:metrics-healthchecks:jar:3.1.0: Failed to read artifact descriptor for io.dropwizard.metrics:metrics-healthchecks:jar:3.1.0: Could not transfer artifact io.dropwizard.metrics:metrics-healthchecks:pom:3.1.0 from/to central (https://repo1.maven.org/maven2): Connection reset -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/DependencyResolutionException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :livy-server
```","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/408/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/408,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5nlyJ-,incubator-livy,1737958014,408,NA,mvanderlee,918128,,,NA,2023-09-27T19:27:07Z,2023-09-27T19:27:07Z,"I'm running into the same issue. These are 2 failing tests:
```
BatchSessionSpec:                                                                                                                                                                                                                                                                 
A Batch process                                                                                                                                                                                                                                                                   
- should create a process *** FAILED *** (1 second, 30 milliseconds)                                                                                                                                                                                                              
  false was not true (BatchSessionSpec.scala:94)


BatchServletSpec:
Batch Servlet
- should create and tear down a batch *** FAILED *** (1 second, 118 milliseconds)
  false was not true (BatchServletSpec.scala:121)
```","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5nlyJ-/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/408,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5nl_6W,incubator-livy,1738014358,408,NA,mvanderlee,918128,,,NA,2023-09-27T20:13:39Z,2023-09-27T20:13:39Z,"@brunolnetto I found the issue.
The tests include Python2 code that doesn't work in Python3. 
i.e: `print ""hello world""` instead of `print(""hello world"")`

The fix is to write the lines for Python3:
https://github.com/apache/incubator-livy/blob/master/server/src/test/scala/org/apache/livy/server/batch/BatchSessionSpec.scala#L51
https://github.com/apache/incubator-livy/blob/master/server/src/test/scala/org/apache/livy/server/batch/BatchServletSpec.scala#L46
","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5nl_6W/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/408,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5nmCPG,incubator-livy,1738023878,408,NA,brunolnetto,13961685,Bruno Peixoto,brunolnetto@gmail.com,NA,2023-09-27T20:21:26Z,2023-09-27T20:21:26Z,"Noice! Someone should notify Apache, Python 2 is being deprecated","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5nmCPG/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/408,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs6b00oJ,incubator-livy,2614315529,408,NA,gyogal,27883675,György Gál,,NA,2025-01-26T10:27:52Z,2025-01-26T10:27:52Z,This was fixed in #424 (many thanks to @mvanderlee),"{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs6b00oJ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-livy/issues/413,https://api.github.com/repos/apache/incubator-livy/issues/413,incubator-livy,1854530202,413,The SparkStreaming operator fails to execute,zenvzenv,26618341,zenv,zw30522@live.com,CLOSED,2023-08-17T08:36:05Z,2024-10-22T09:33:11Z,"> kafka as SparkStreaming input and output
1. Use `spark.readStream.format(""kafka"")` read kafka data and decode binary data to string
2. Use `df.map(_.Seq.foldLeft(""""))(_ + separtor + _).writeStream(""kafka"")`  output data to kafka
3. If I fail to output to kafka, then no matter how I change the kafka topic later, the stream computing will fail,`ArrayIndexOutOfBoundsException: 1` exception will report.If I only output to the console there will be no error
4. If I run the same code snippet directly in spark-shell without using livy, the effect is the same as 3","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/413/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-livy/issues/415,https://api.github.com/repos/apache/incubator-livy/issues/415,incubator-livy,1864932051,415,Escape backtick from spark-submit arguments,s0nskar,11391128,Sanskar Modi,sanskarmodi97@gmail.com,OPEN,2023-08-24T11:13:50Z,2024-02-14T15:17:44Z,"Currently, livy does not escape backticks from user-provided spark-submit arguments. So if a customer is passing any arguments that contain backticks, it will be considered as command substitution during spark-submit causing that argument to become blank or invalid.

Example:
```
--query 'select * from test_db.`test_table`' 
```
will become
```
--query 'select * from test_db.' 
```","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/415/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/415,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5k0fqM,incubator-livy,1691482764,415,NA,s0nskar,11391128,Sanskar Modi,sanskarmodi97@gmail.com,NA,2023-08-24T11:14:00Z,2023-08-24T11:14:00Z,cc: @pralabhkumar ,"{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5k0fqM/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/415,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5k1rdD,incubator-livy,1691793219,415,NA,s0nskar,11391128,Sanskar Modi,sanskarmodi97@gmail.com,NA,2023-08-24T14:28:41Z,2023-08-24T14:28:41Z,I'm working on this.,"{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5k1rdD/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/415,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5z377R,incubator-livy,1944043217,415,NA,RonZhang724,22732137,Morty,,NA,2024-02-14T15:17:43Z,2024-02-14T15:17:43Z,"@s0nskar Thank you for working on this. My company uses AWS EMR for our data processing tasks. EMR uses livy to handle job submissions, and we noticed the same issue when submitting queries with backticks. This has resulted us having to change the queries on our side. And it prevented us from using dot notations in our query ALIAS. 

For example, the following will not work 
```
  COALESCE(
    `measure`.`region`,
  ) AS `measure_alias.region_alias`
```

It would be nice if we could have this change included in the up coming livy releases.
","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5z377R/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-livy/issues/422,https://api.github.com/repos/apache/incubator-livy/issues/422,incubator-livy,1916283754,422,Build fails when using -Pscala-2.12,mvanderlee,918128,,,OPEN,2023-09-27T20:40:14Z,2024-04-20T08:46:07Z,"Build fails on assembly module due to scala-2.11 dependencies. 
I think this is due to the `${scala.binary.version}` being used in the `modules` sections, and it's populated before the profiles are loaded.
When I ensure that scala-2.12 is the default in the `<properties>` then it works fine. ","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/422/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/422,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs57PSyF,incubator-livy,2067606661,422,NA,javiroman,1099214,Javi Roman,javiroman@apache.org,NA,2024-04-20T08:46:06Z,2024-04-20T08:46:06Z,"The same problem, more information about the error here:

```
$ podman run --rm -it -v $(pwd):/workspace -v $HOME/.m2:/root/.m2 livy-ci mvn clean package -Pscala-2.12 -Pspark3 -DskipTests -DskipITs -Dmaven.javadoc.skip=true

[...]
[INFO] livy-server ........................................ SUCCESS [ 37.986 s]                                                                   
[INFO] livy-assembly ...................................... FAILURE [  0.065 s]                                                                   
[INFO] livy-client-http ................................... SKIPPED                                                                               
[INFO] livy-scala-api-parent .............................. SKIPPED                                                                               
[INFO] livy-scala-api_2.12 ................................ SKIPPED                                                                               
[INFO] livy-integration-test .............................. SKIPPED                                                                               
[INFO] livy-coverage-report ............................... SKIPPED                                                                               
[INFO] livy-examples ...................................... SKIPPED                                                                               
[INFO] livy-python-api .................................... SKIPPED                                                                               
[INFO] ------------------------------------------------------------------------                                                                   
[INFO] BUILD FAILURE                                                                                                                              
[INFO] ------------------------------------------------------------------------                                                                   
[INFO] Total time: 01:34 min                                                                                                                      
[INFO] Finished at: 2024-04-20T08:44:36+00:00                                                                                                     
[INFO] Final Memory: 212M/3879M                                                                                                                   
[INFO] ------------------------------------------------------------------------                                                                   
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-remote-resources-plugin:1.5:process (process-resource-bundles) on project livy-assem
bly: Failed to resolve dependencies for one or more projects in the reactor. Reason: Missing:                                                     
[ERROR] ----------                                                                                                                                
[ERROR] 1) org.apache.livy:livy-core_2.11:jar:0.9.0-incubating-SNAPSHOT  
[...]
```","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs57PSyF/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-livy/issues/427,https://api.github.com/repos/apache/incubator-livy/issues/427,incubator-livy,1936717186,427,Does Livy support Flink,smileyboy2019,59221294,,,OPEN,2023-10-11T03:15:19Z,2023-10-11T03:15:19Z,"Does it support FlinkSQL, PyFlink, and Flinkml","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/427/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-livy/issues/428,https://api.github.com/repos/apache/incubator-livy/issues/428,incubator-livy,1936723509,428,livy:What are the plans for the later stage,smileyboy2019,59221294,,,OPEN,2023-10-11T03:24:06Z,2023-10-11T03:24:06Z,"What are the plans for the later stage, whether they support more engines, whether it is better for tenants, isolation, and context support。
What are the advantages and differences compared to Apache Linkis","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/428/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-livy/issues/430,https://api.github.com/repos/apache/incubator-livy/issues/430,incubator-livy,1986846726,430,【livy-8.0-2.12 spark3.2.1】kerberos认证问题,ziwuse,59003075,,,OPEN,2023-11-10T04:20:28Z,2023-11-10T04:20:28Z,"livy.conf
```
livy.server.launch.kerberos.keytab=xxx.keytab
livy.server.launch.kerberos.principal=xxx@HADOOP.COM
```
我确定keytab文件和principal是正确的，但是在创建interactive sesison时报错
```
23/11/10 11:43:22 INFO rpc.RpcServer: Connected to the port 10000
23/11/10 11:43:22 WARN common.ClientConf: Your hostname, into5, resolves to a loopback address, but we couldn't find any external IP address!
23/11/10 11:43:22 WARN common.ClientConf: Set livy.rsc.rpc.server.address if you need to bind to another address.
23/11/10 11:43:22 INFO sessions.InteractiveSessionManager: Registering new session 4
23/11/10 11:43:22 INFO sessions.InteractiveSessionManager: Registered new session 4
23/11/10 11:43:22 WARN ipc.Client: Exception encountered while connecting to the server : javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mec
hanism level: Failed to find any Kerberos tgt)]
23/11/10 11:43:25 INFO utils.LineBufferedStream: SLF4J: Class path contains multiple SLF4J bindings.
23/11/10 11:43:25 INFO utils.LineBufferedStream: SLF4J: Found binding in [jar:file:/app/spark-3.2.1-bin-hadoop2.7/jars/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]
23/11/10 11:43:25 INFO utils.LineBufferedStream: SLF4J: Found binding in [jar:file:/app/spark-3.2.1-bin-hadoop2.7/jars/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]
23/11/10 11:43:25 INFO utils.LineBufferedStream: SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
23/11/10 11:43:25 INFO utils.LineBufferedStream: SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
23/11/10 11:43:27 INFO utils.LineBufferedStream: 23/11/10 11:43:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/11/10 11:43:29 INFO utils.LineBufferedStream: 23/11/10 11:43:29 WARN DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.
23/11/10 11:43:30 INFO utils.LineBufferedStream: 23/11/10 11:43:30 WARN Client: Exception encountered while connecting to the server : javax.security.sasl.SaslException: GSS initiate failed [Caused by GSS
Exception: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
23/11/10 11:43:30 INFO utils.LineBufferedStream: Exception in thread ""main"" java.io.IOException: Failed on local exception: java.io.IOException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]; Host Details : local host is: ""into5/192.168.1.65""; destination host is: ""into1"":8020; 
23/11/10 11:43:30 INFO utils.LineBufferedStream:        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:776)
23/11/10 11:43:30 INFO utils.LineBufferedStream:        at org.apache.hadoop.ipc.Client.call(Client.java:1480)
23/11/10 11:43:30 INFO utils.LineBufferedStream:        at org.apache.hadoop.ipc.Client.call(Client.java:1413)
23/11/10 11:43:30 INFO utils.LineBufferedStream:        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
23/11/10 11:43:30 INFO utils.LineBufferedStream:        at com.sun.proxy.$Proxy10.getFileInfo(Unknown Source)
```
若在spark-default.conf中增加
```
spark.kerberos.keytab=xxx.keytab
spark.kerberos.principal=xxx@HADOOP.COM
```
则以上问题解决，但是，livy server日志中一直在输出
```
23/11/10 11:43:52 WARN ipc.Client: Exception encountered while connecting to the server : javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
23/11/10 11:44:22 WARN ipc.Client: Exception encountered while connecting to the server : javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
23/11/10 11:44:52 WARN ipc.Client: Exception encountered while connecting to the server : javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
23/11/10 11:45:22 WARN ipc.Client: Exception encountered while connecting to the server : javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
```
请给我提供一些帮助，谢谢！","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/430/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-livy/issues/432,https://api.github.com/repos/apache/incubator-livy/issues/432,incubator-livy,1989855529,432,can user auto run the init script when the livy session is created?,BiyuHuang,14238518,Wallace Huang,h417652303@163.com,OPEN,2023-11-13T04:12:45Z,2023-11-13T04:12:45Z,"e.g:  I have a script: `init.scala `, created some common functions inside this script. `init.scala` should run first when I started livy session","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/432/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-livy/issues/441,https://api.github.com/repos/apache/incubator-livy/issues/441,incubator-livy,2192710883,441,"{”msg”:“Rejected, Reason: Blacklisted configuration values in session config: spark.submit.deployMode”}",datavisorrunziyang,93511740,Runzi,,OPEN,2024-03-18T16:35:27Z,2024-03-18T16:35:27Z,"spark  version 3.5.1 
livy version. 0.8.0

Requesting through the Api gets the following return

org.springframework.web.client.HttpClientErrorException$BadRequest: 400 Bad Request: ""{""msg"":""Rejected, Reason: Blacklisted configuration values in session config: spark.submit.deployMode""}""

But I don't see any error reported in the logs, is it incompatible with spark 3.5.1

BTW, I also set up`conf/spark-blacklist.conf` and it doesn't seem to be taking effect","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/441/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-livy/issues/442,https://api.github.com/repos/apache/incubator-livy/issues/442,incubator-livy,2212616748,442,livy 传参问题,smileyboy2019,59221294,,,OPEN,2024-03-28T08:15:54Z,2024-05-30T07:28:54Z,怎么用有两个代码片段，一个session ，通过sql 执行的结果数据集，传递给下一个片段，参数怎么传递，另外spark 3.5.1版本是否支持,"{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/442/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/442,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5_fGq9,incubator-livy,2138860221,442,NA,jieyu-lin,51392682,Jie-Yu LIN,,NA,2024-05-30T07:28:53Z,2024-05-30T07:28:53Z,@smileyboy2019 I personally test spark 3.5.1 and it works with livy 0.8.0 in my environment. Your scala version has to be aligned (which is 2.12) and livy installed with spark-submit based on Java 8 (at least 8u371).,"{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs5_fGq9/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-livy/issues/443,https://api.github.com/repos/apache/incubator-livy/issues/443,incubator-livy,2214467861,443,Can Livy not rely on Spark,smileyboy2019,59221294,,,OPEN,2024-03-29T02:01:08Z,2024-03-29T02:01:08Z,"Livy can interface with Java, Python, Shell, SQL, etc., not necessarily Spark, so it can integrate many languages through jdbc, hive, MySQL, Python, etc","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/443/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-livy/issues/446,https://api.github.com/repos/apache/incubator-livy/issues/446,incubator-livy,2348202076,446,是否可以支持flink,smileyboy2019,59221294,,,CLOSED,2024-06-12T08:53:11Z,2024-06-15T18:21:23Z,是否可以支持flink 的代码和上下文处理,"{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/446/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-livy/issues/455,https://api.github.com/repos/apache/incubator-livy/issues/455,incubator-livy,2500978800,455,Livy could intermittently returns batch job status as SUCCEED even Spark on Kubernetes actually fails,nitishtw,23567081,Nitish Tiwari ,kumarnitish1996@gmail.com,OPEN,2024-09-02T13:24:55Z,2024-09-02T13:24:55Z,"I run a Livy server on Kubernetes to submit Spark batch jobs via Airflow using the Livy REST API. However, even when Spark jobs fail due to driver or executor issues, Livy incorrectly shows the status as ""SUCCEED"" and returns a successful response. This leads Airflow to mark failed jobs as successful mistakenly.

One related issue I found was this - https://issues.apache.org/jira/browse/LIVY-896 which got fixed in the next release 0.8.0
We upgraded our Livy cluster from 0.7.0 to 0.8.0 but it didn't fix the issue in the Kubernetes ecosystem.

While reviewing the Livy code, we found that it returns an exit code of 0 (success) even when the driver pod fails in cluster mode. Ideally, the main pod should transition to an 'Error' state if the application fails.","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/455/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-livy/issues/458,https://api.github.com/repos/apache/incubator-livy/issues/458,incubator-livy,2554857830,458,Failed to connect to context,jhao104,15058920,J_hao104,j_hao104@163.com,OPEN,2024-09-29T10:23:54Z,2024-09-29T10:23:54Z,"livy log
```
24/09/29 18:17:21 WARN [ContextLauncher-1] ContextLauncher: Child process exited with code 1.
24/09/29 18:17:21 ERROR [RPC-Handler-6] RSCClient: Failed to connect to context.
java.io.IOException: Child process exited with code 1.
        at org.apache.livy.rsc.ContextLauncher$ChildProcess$1.run(ContextLauncher.java:397)
        at org.apache.livy.rsc.ContextLauncher$ChildProcess$2.run(ContextLauncher.java:448)
        at java.lang.Thread.run(Thread.java:750)
24/09/29 18:17:21 INFO [RPC-Handler-6] RSCClient: Failing pending job d501f792-6a0c-47e2-aff6-d6ba04d50f97 due to shutdown.
24/09/29 18:17:21 INFO [scala-execution-context-global-63] InteractiveSession: Stopping InteractiveSession 11787...
24/09/29 18:17:21 INFO [RPC-Handler-6] InteractiveSession: Failed to ping RSC driver for session 11787. Killing application.
24/09/29 18:17:22 INFO [RPC-Handler-6] RSCClient: Job d501f792-6a0c-47e2-aff6-d6ba04d50f97 already failed.
java.lang.IllegalStateException: spark-submit start failed
        at org.apache.livy.utils.SparkYarnApp.getAppIdFromTag(SparkYarnApp.scala:196)
        at org.apache.livy.utils.SparkYarnApp.$anonfun$yarnAppMonitorThread$3(SparkYarnApp.scala:271)
        at scala.Option.getOrElse(Option.scala:189)
        at org.apache.livy.utils.SparkYarnApp.$anonfun$yarnAppMonitorThread$1(SparkYarnApp.scala:268)
        at org.apache.livy.Utils$$anon$1.run(Utils.scala:97)
24/09/29 18:17:22 ERROR [yarnAppMonitorThread-org.apache.livy.utils.SparkYarnApp@7433857e] SparkYarnApp: Error whiling refreshing YARN state
java.lang.IllegalStateException: spark-submit start failed
        at org.apache.livy.utils.SparkYarnApp.getAppIdFromTag(SparkYarnApp.scala:196)
        at org.apache.livy.utils.SparkYarnApp.$anonfun$yarnAppMonitorThread$3(SparkYarnApp.scala:271)
        at scala.Option.getOrElse(Option.scala:189)
        at org.apache.livy.utils.SparkYarnApp.$anonfun$yarnAppMonitorThread$1(SparkYarnApp.scala:268)
        at org.apache.livy.Utils$$anon$1.run(Utils.scala:97)
24/09/29 18:17:22 WARN [scala-execution-context-global-71] InteractiveSession: Fail to get rsc uri
java.util.concurrent.ExecutionException: java.io.IOException: Child process exited with code 1.
        at io.netty.util.concurrent.DefaultPromise.get(DefaultPromise.java:351)
        at org.apache.livy.server.interactive.InteractiveSession.$anonfun$start$5(InteractiveSession.scala:474)
        at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
        at scala.util.Success.$anonfun$map$1(Try.scala:255)
        at scala.util.Success.map(Try.scala:213)
        at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
        at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
        at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
        at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
        at java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1402)
        at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
        at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:175)
Caused by: java.io.IOException: Child process exited with code 1.
        at org.apache.livy.rsc.ContextLauncher$ChildProcess$1.run(ContextLauncher.java:397)
        at org.apache.livy.rsc.ContextLauncher$ChildProcess$2.run(ContextLauncher.java:448)
        at java.lang.Thread.run(Thread.java:750)
```
session log
```
24/09/29 18:17:21 INFO Client: Deleted staging directory hdfs://**:9000/user/livy/.sparkStaging/application_1727350308711_11779
Exception in thread ""main"" java.lang.IllegalArgumentException: Attempt to add (file:///etc/taihao-apps/spark-conf/hive-site.xml) multiple times to the distributed cache.
	at org.apache.spark.deploy.yarn.Client.$anonfun$prepareLocalResources$26(Client.scala:717)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.deploy.yarn.Client.$anonfun$prepareLocalResources$25(Client.scala:707)
	at org.apache.spark.deploy.yarn.Client.$anonfun$prepareLocalResources$25$adapted(Client.scala:706)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at org.apache.spark.deploy.yarn.Client.prepareLocalResources(Client.scala:706)
	at org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:983)
	at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:220)
	at org.apache.spark.deploy.yarn.Client.run(Client.scala:1310)
	at org.apache.spark.deploy.yarn.YarnClusterApplication.start(Client.scala:1758)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1020)
	at org.apache.spark.deploy.SparkSubmit$$anon$1.run(SparkSubmit.scala:176)
	at org.apache.spark.deploy.SparkSubmit$$anon$1.run(SparkSubmit.scala:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:174)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:215)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1111)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1120)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
24/09/29 18:17:21 INFO ShutdownHookManager: Shutdown hook called
```

livy: 0.8.0 spark 3.4.2","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/458/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-livy/issues/461,https://api.github.com/repos/apache/incubator-livy/issues/461,incubator-livy,2662049604,461,Spark on Kubernetes job fails if service account doesn't have permission to all namespaces.,ashokkumarrathore,30638343,,,OPEN,2024-11-15T13:53:48Z,2025-01-23T21:07:31Z,"In a multi tenant Kubernetes cluster, it will not always be the case that livy service account has access to all namespaces. Since Livy currently looks for job in all namespaces, it fails if the permission is not there for some namespace in cluster. 

Ideally we should only look for job in the namespace it was submitted to. Relevant code is here, i think : https://github.com/apache/incubator-livy/blob/1f6bd7ab55db3e5b08ff133d554b32db83a23890/server/src/main/scala/org/apache/livy/utils/SparkKubernetesApp.scala#L446
Also this, 
https://github.com/apache/incubator-livy/blob/1f6bd7ab55db3e5b08ff133d554b32db83a23890/server/src/main/scala/org/apache/livy/utils/SparkKubernetesApp.scala#L689","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/461/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/461,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs6TwO0T,incubator-livy,2478894355,461,NA,ashokkumarrathore,30638343,,,NA,2024-11-15T13:55:03Z,2024-11-15T13:55:03Z,@askhatri @jahstreet  fyi,"{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs6TwO0T/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/461,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs6Tw677,incubator-livy,2479075067,461,NA,askhatri,123077165,Asif Khatri,,NA,2024-11-15T14:55:34Z,2024-11-15T14:55:34Z,"Thank you @ashokkumarrathore for the findings. @jahstreet, please review and share your insights.","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs6Tw677/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/461,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs6YAoBy,incubator-livy,2550300786,461,NA,ashokkumarrathore,30638343,,,NA,2024-12-18T04:21:50Z,2024-12-18T04:21:50Z,"The potential fix is to provide a namespace argument and use that in GetApplications() from Kubernetes. So, rather than looking for app in any namespace [here](https://github.com/apache/incubator-livy/blob/1f6bd7ab55db3e5b08ff133d554b32db83a23890/server/src/main/scala/org/apache/livy/utils/SparkKubernetesApp.scala#L689), it should be namespaced.

The namespace need to be passed from here:
https://github.com/apache/incubator-livy/blob/1f6bd7ab55db3e5b08ff133d554b32db83a23890/server/src/main/scala/org/apache/livy/server/batch/BatchSession.scala#L109

There are couple of options on how we do this:
1. Add a namespace argument to SparkApp.create() call. This changes the create() function definition which is generic for both YarnApp and KubernetesApp. 
2. To avoid modifying create() call, we can put namespace as part of LivyConf and pass a copy of this rather than actual ref. This will have minimal changes but technically namespace should not be part of LivyConf. 

@jahstreet @askhatri Please let me know your thoughts and i can implement it accordingly. ","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs6YAoBy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/461,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs6YArZC,incubator-livy,2550314562,461,NA,askhatri,123077165,Asif Khatri,,NA,2024-12-18T04:34:33Z,2024-12-18T04:34:33Z,"Hi @ashokkumarrathore,
Thank you for your efforts. I agree with the suggested fix.
CC: @jahstreet , @gyogal ","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs6YArZC/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/461,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs6ZAWR2,incubator-livy,2567005302,461,NA,ashokkumarrathore,30638343,,,NA,2025-01-01T13:13:55Z,2025-01-01T13:13:55Z,"@askhatri @jahstreet Changes for namespace support in Livy for Spark on k8s. https://github.com/apache/incubator-livy/pull/462
Can you guys please take a look?
Also, currently no builds are running for this, can you please approve the workflow to run build/test?","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs6ZAWR2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-livy/issues/461,https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs6boPaD,incubator-livy,2611017347,461,NA,jahstreet,19328972,Alex Sasnouskikh,jahstreetlove@gmail.com,NA,2025-01-23T21:06:15Z,2025-01-23T21:06:15Z,"Reviewed the MR. Valid point 👍 

> can you please approve the workflow to run build/test

I cannot, I don't have write permissions to the repo. You can check with maintainers, I usually find them in the closed MRs.","{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/comments/IC_kwDOBa7VOs6boPaD/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-livy/issues/463,https://api.github.com/repos/apache/incubator-livy/issues/463,incubator-livy,2776750181,463,Is there any latest update available,smileyboy2019,59221294,,,OPEN,2025-01-09T03:24:09Z,2025-01-09T03:24:09Z,Is there any latest update available,"{""url"": ""https://api.github.com/repos/apache/incubator-livy/issues/463/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
