type,issue_url,comment_url,repo_name,id,issue_num,title,user_login,user_id,user_name,user_email,issue_state,created_at,updated_at,body,reactions
issue,https://api.github.com/repos/apache/polaris/issues/1,https://api.github.com/repos/apache/polaris/issues/1,polaris,2351737770,1,"Congrats on the open source, but where is code and issues?",JunpingDu,888093,Junping Du,junping_du@apache.org,CLOSED,2024-06-13T17:50:50Z,2024-07-30T15:05:36Z,Hope to see the code ASAP.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/1,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6BIvM1,polaris,2166551349,1,NA,skashmeri,8323990,Shamil Kashmeri,skashmeri@gmail.com,NA,2024-06-13T18:51:21Z,2024-06-13T18:51:21Z,"> Hope to see the code ASAP.

`Polaris Catalog will be open sourced under an Apache 2.0 license in the **next 90 days**. In the meantime:`","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6BIvM1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/5,https://api.github.com/repos/apache/polaris/issues/5,polaris,2438097536,5,Upgrade to Apache Iceberg 1.6.0,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,CLOSED,2024-07-30T15:18:56Z,2024-09-11T15:36:37Z,,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/11,https://api.github.com/repos/apache/polaris/issues/11,polaris,2438133585,11,Fix `PolarisServiceImplIntegrationTest` failures,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,CLOSED,2024-07-30T15:36:41Z,2024-07-31T14:27:55Z,"`PolarisServiceImplIntegrationTest` is failed on:

* `testCreateCatalogWithoutStorageConfig()`
* `testCreateCatalogWithoutProperties()`

At least, on my box (MBP M2/arm).","{""url"": ""https://api.github.com/repos/apache/polaris/issues/11/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/11,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6GoTSf,polaris,2258711711,11,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2024-07-30T16:09:14Z,2024-07-30T16:09:14Z,"OK, found the issue: the test assertion depends of locale. I will propose a PR to ""force"" the locale to avoid issue.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6GoTSf/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/12,https://api.github.com/repos/apache/polaris/issues/12,polaris,2438137259,12,Remove implementation of `/v1/oauth/tokens` endpoint,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,OPEN,2024-07-30T15:38:36Z,2024-08-06T01:03:57Z,The oauth/tokens endpoint is already deprecated for removal due to security concerns. The path forward is described in [this doc](https://docs.google.com/document/d/1Xi5MRk8WdBWFC3N_eSmVcrLhk3yu5nJ9x_wC0ec6kVQ/).,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/12/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/12,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HT-Sp,polaris,2270160041,12,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-08-06T00:48:07Z,2024-08-06T00:48:07Z,"We don't recommend anyone to use it in a prod env, but it's a nice feature to allow people to try Polaris out easily, otherwise they have to hook a third-party token service before doing anything else. What we can do here is to remove it while providing an private endpoint with the same functionality for test purpose. In that case, the real prod user can hook their token service, while we still use the private endpoint for testing.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HT-Sp/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/12,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HT_EE,polaris,2270163204,12,NA,dimas-b,40603221,Dmitri Bourlatchkov,,NA,2024-08-06T00:52:27Z,2024-08-06T00:52:27Z,"It is pretty easy to setup Keycloak, for example, as an IdP for ""getting started"" environments. 

Nessie has an example here: https://github.com/projectnessie/nessie/tree/main/docker/authn-keycloak","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HT_EE/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/12,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HT_4D,polaris,2270166531,12,NA,dimas-b,40603221,Dmitri Bourlatchkov,,NA,2024-08-06T00:56:59Z,2024-08-06T00:56:59Z,"> providing an private endpoint with the same functionality for test purpose

I'm not sure it is as easy as it sounds. A proper OAuth2 implementation is not a small effort. On the other hand, a test impl. that has gaps wrt to the OAuth2 RFC can lead to bugs in production code because it would be tested against a non-compliant OAuth2 server.

I believe it is preferable to reuse existing OSS implementations that provide OAuth2.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HT_4D/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/12,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HUAHT,polaris,2270167507,12,NA,dimas-b,40603221,Dmitri Bourlatchkov,,NA,2024-08-06T00:58:24Z,2024-08-06T00:58:24Z,"A tangential point: if Quarkus were used as the server platform, it provides easy ways to test authN/Z in CI without requiring a full OAuth2/OIDC implementation.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HUAHT/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/12,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HUBK1,polaris,2270171829,12,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-08-06T01:03:56Z,2024-08-06T01:03:56Z,"Agreed, it's great to reuse an existing OAuth2 implementation. We will need to see how integration works to choose between them.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HUBK1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/13,https://api.github.com/repos/apache/polaris/issues/13,polaris,2438193108,13,[DOC] Expand Quickstart documentation to include Trino examples,annafil,7892219,Anna Filippova,,CLOSED,2024-07-30T16:07:56Z,2024-11-07T21:01:31Z,"Because Polaris Catalog is built on top of Apache Iceberg's REST protocol, it should [natively support Trino's Iceberg connector.](https://trino.io/docs/current/connector/iceberg.html) ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/13/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/13,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HauD4,polaris,2271928568,13,NA,annafil,7892219,Anna Filippova,,NA,2024-08-06T18:47:19Z,2024-08-06T18:47:19Z,Is being worked on in https://github.com/polaris-catalog/polaris/pull/44 ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HauD4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/13,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6S0Y9y,polaris,2463207282,13,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-11-07T21:01:31Z,2024-11-07T21:01:31Z,"We now have these docs [here](https://github.com/apache/polaris/tree/main/getting-started/trino), so I'm closing this out ðŸ‘","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6S0Y9y/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/19,https://api.github.com/repos/apache/polaris/issues/19,polaris,2438587698,19,[FEATURE REQUEST] Build and publish wheel for python client,collado-mike,40346148,Michael Collado,,OPEN,2024-07-30T20:04:25Z,2024-09-13T10:37:22Z,"**Is your feature request related to a problem? Please describe.**

Users need an easy way to install the python client into their applications


**Describe the solution you'd like**
Publish a wheel for the python client
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/19/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/19,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6L_R0_,polaris,2348621119,19,NA,jotarada,35892383,,,NA,2024-09-13T10:37:21Z,2024-09-13T10:37:21Z,+1,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6L_R0_/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/20,https://api.github.com/repos/apache/polaris/issues/20,polaris,2438589511,20,[FEATURE REQUEST] Add regression tests for Flink,collado-mike,40346148,Michael Collado,,OPEN,2024-07-30T20:05:13Z,2024-07-30T20:05:13Z,"**Is your feature request related to a problem? Please describe.**

We need to validate that the catalog works for Flink in a regression test


**Describe the solution you'd like**
Tests running flink against a dockerized instance of Polaris

","{""url"": ""https://api.github.com/repos/apache/polaris/issues/20/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/21,https://api.github.com/repos/apache/polaris/issues/21,polaris,2438590713,21,Move all regression tests to pytests,collado-mike,40346148,Michael Collado,,OPEN,2024-07-30T20:05:59Z,2024-12-15T05:50:13Z,"**Is your feature request related to a problem? Please describe.**

Several of the existing regression tests simply do output diff checking. We should migrate them to python tests so we can do better assertions and print more clear error messages when tests fail


**Describe the solution you'd like**
Move all regression tests to pytests","{""url"": ""https://api.github.com/repos/apache/polaris/issues/21/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/21,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XRXjo,polaris,2537912552,21,NA,MonkeyCanCode,29619290,,,NA,2024-12-12T06:19:37Z,2024-12-12T06:19:37Z,Thinking to take this one if no one else starts the work yet.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XRXjo/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/21,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Xmhu0,polaris,2543459252,21,NA,MonkeyCanCode,29619290,,,NA,2024-12-15T05:50:12Z,2024-12-15T05:50:12Z,"> Thinking to take this one if no one else starts the work yet.

@collado-mike here is the PR for this: https://github.com/apache/polaris/pull/545","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Xmhu0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/22,https://api.github.com/repos/apache/polaris/issues/22,polaris,2438594396,22,[FEATURE REQUEST] Trino getting started docker compose,collado-mike,40346148,Michael Collado,,CLOSED,2024-07-30T20:08:28Z,2024-09-13T20:56:56Z,"**Is your feature request related to a problem? Please describe.**

It would be great to have a docker-compose setup for Trino as we do for Spark


**Describe the solution you'd like**
A docker-compose setup with Trino and Polaris","{""url"": ""https://api.github.com/repos/apache/polaris/issues/22/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/22,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6GxFxR,polaris,2261015633,22,NA,kevinjqliu,9057843,Kevin Liu,,NA,2024-07-31T17:30:09Z,2024-07-31T17:30:09Z,"@collado-mike I can take a look at this. 

Is the Spark setup referred to here the [quickstart](https://github.com/polaris-catalog/polaris/blob/main/docs/quickstart.md#connecting-with-spark) doc?

","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6GxFxR/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/22,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G1OcM,polaris,2262099724,22,NA,collado-mike,40346148,Michael Collado,,NA,2024-08-01T05:55:17Z,2024-08-01T05:55:17Z,"> @collado-mike I can take a look at this. 
> 
> 
> 
> Is the Spark setup referred to here the [quickstart](https://github.com/polaris-catalog/polaris/blob/main/docs/quickstart.md#connecting-with-spark) doc?
> 

Yeah, that's what I was thinking of. 
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G1OcM/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/22,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HUe5z,polaris,2270293619,22,NA,kevinjqliu,9057843,Kevin Liu,,NA,2024-08-06T03:03:10Z,2024-08-06T03:03:10Z,"Great! I opened #42 for Trino. 
We can extend the same solution to Spark. It'll be nice to just docker-compose a Spark setup instead of installing Spark manually","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HUe5z/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/23,https://api.github.com/repos/apache/polaris/issues/23,polaris,2438595936,23,Add test coverage report/badges,collado-mike,40346148,Michael Collado,,OPEN,2024-07-30T20:09:28Z,2025-01-03T05:42:14Z,"**Is your feature request related to a problem? Please describe.**

We should publish badges for the state of the build

**Describe the solution you'd like**
Badges on the front page of the repo","{""url"": ""https://api.github.com/repos/apache/polaris/issues/23/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/23,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JeiNU,polaris,2306483028,23,NA,snazy,957468,Robert Stupp,,NA,2024-08-23T07:38:24Z,2024-08-23T07:38:24Z,"@collado-mike there's a badge in #180 for the state of CI.
Not sure whether this issue is about the badge or test-coverage (aka jacoco)?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JeiNU/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/23,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZG4hI,polaris,2568718408,23,NA,MonkeyCanCode,29619290,,,NA,2025-01-03T05:42:13Z,2025-01-03T05:42:13Z,"@snazy / @collado-mike as we have other workflows as well, should we add those status as well (or create a main workflow then links those to that then get status from main workflow instead?)","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZG4hI/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/28,https://api.github.com/repos/apache/polaris/issues/28,polaris,2438879871,28,[Improvement] Lack of documentation on non-default backend,MonkeyCanCode,29619290,,,CLOSED,2024-07-31T00:28:34Z,2024-08-04T21:12:09Z,"By default, Polaris will be using in-memory backend as defined in https://github.com/polaris-catalog/polaris/blob/main/polaris-server.yml#L90. However, there is no documentation on what are the allowed values as well as how to use eclipselink (https://github.com/polaris-catalog/polaris/tree/main/extension/persistence/eclipselink) to switch to non-default backend.

","{""url"": ""https://api.github.com/repos/apache/polaris/issues/28/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/28,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6GxsNw,polaris,2261173104,28,NA,guitcastro,1149991,Guilherme Torres Castro,,NA,2024-07-31T18:39:48Z,2024-07-31T18:39:48Z,"Is there a reason why eclipselink is not a dependency of polaris-service? It seems that eclipselink lists polaris-service as a dependency, but it should be the other way around. I downloaded the project, removed eclipselink from the dependencies, and it worked.

When I tried to change the metastore to eclipselink, I encountered the following issue:

```
2024-07-31 15:12:59 io.dropwizard.configuration.ConfigurationParsingException: polaris-server.yml has an error:
2024-07-31 15:12:59   * Failed to parse configuration at: metaStoreManager; Could not resolve type id 'eclipse-link' as a subtype of `io.polaris.core.persistence.MetaStoreManagerFactory`: known type ids = [in-memory] (for POJO property 'metaStoreManager')
2024-07-31 15:12:59  at [Source: UNKNOWN; byte offset: #UNKNOWN] (through reference chain: io.polaris.service.config.PolarisApplicationConfig[""metaStoreManager""])
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6GxsNw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/28,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Gz2Gt,polaris,2261737901,28,NA,MonkeyCanCode,29619290,,,NA,2024-08-01T00:57:50Z,2024-08-01T00:57:50Z,"> Is there a reason why eclipselink is not a dependency of polaris-service? It seems that eclipselink lists polaris-service as a dependency, but it should be the other way around. I downloaded the project, removed eclipselink from the dependencies, and it worked.
> 
> When I tried to change the metastore to eclipselink, I encountered the following issue:
> 
> ```
> 2024-07-31 15:12:59 io.dropwizard.configuration.ConfigurationParsingException: polaris-server.yml has an error:
> 2024-07-31 15:12:59   * Failed to parse configuration at: metaStoreManager; Could not resolve type id 'eclipse-link' as a subtype of `io.polaris.core.persistence.MetaStoreManagerFactory`: known type ids = [in-memory] (for POJO property 'metaStoreManager')
> 2024-07-31 15:12:59  at [Source: UNKNOWN; byte offset: #UNKNOWN] (through reference chain: io.polaris.service.config.PolarisApplicationConfig[""metaStoreManager""])
> ```

So eclipse-link is not getting loaded into the final JAR (thus not enabled) as of now. A modification of gradle.build is needed to enable it (include it in the final JAR).

Sample PR created for using H2 as backend metastore via eclipselink: https://github.com/polaris-catalog/polaris/pull/47","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Gz2Gt/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/28,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HG2As,polaris,2266718252,28,NA,cgpoh,11516015,CG,,NA,2024-08-03T13:49:40Z,2024-08-03T13:49:40Z,"I tried to use H2 as backend metastore via eclipselink and face this error when I send an auth token request:
```
Realm is not bootstrapped, please run server in bootstrap mode.
```
How to run the server in bootstrap mode?
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HG2As/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/28,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HG6i_,polaris,2266736831,28,NA,MonkeyCanCode,29619290,,,NA,2024-08-03T14:34:56Z,2024-08-03T14:34:56Z,"> I tried to use H2 as backend metastore via eclipselink and face this error when I send an auth token request:
> 
> ```
> Realm is not bootstrapped, please run server in bootstrap mode.
> ```
> 
> How to run the server in bootstrap mode?

@cgpoh , you can do this:
```
java -jar polaris-service/build/libs/polaris-service-1.0.0-all.jar bootstrap polaris-server.yml
```

This is documented in the open PR: https://github.com/polaris-catalog/polaris/pull/43","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HG6i_/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/28,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HHR1-,polaris,2266832254,28,NA,cgpoh,11516015,CG,,NA,2024-08-03T15:38:31Z,2024-08-03T15:38:31Z,"@MonkeyCanCode , thanks! After running the bootstrap command and running `./gradlew runApp`, I can't find client id and secret in stdout on initial startup anymore. Without the credentials, how to send OAuth2 requests?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HHR1-/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/28,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HHVCb,polaris,2266845339,28,NA,MonkeyCanCode,29619290,,,NA,2024-08-03T15:44:03Z,2024-08-03T15:44:03Z,"> @MonkeyCanCode , thanks! After running the bootstrap command and running `./gradlew runApp`, I can't find client id and secret in stdout on initial startup anymore. Without the credentials, how to send OAuth2 requests?

So with the eclipse link extension, the credentials will be stored in the backend metastore after bootstrap (in this case, it will be in h2 files on your local file system...the location will be /tmp/eclipse-link/). You will need h2 client to read the content. It is also possible to replace h2 with other backends (e.g. Postgres), but modifications of Gradle file (used by eclipse link) will be needed as well as the connection info within persistent.xml under resources directory under polaris-service.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HHVCb/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/28,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HHgJ-,polaris,2266890878,28,NA,cgpoh,11516015,CG,,NA,2024-08-03T16:02:42Z,2024-08-03T16:02:42Z,"@MonkeyCanCode , thanks! I'm trying out Postgres, will try to figure out where the credentials are stored for Postgres.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HHgJ-/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/28,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HHo9O,polaris,2266926926,28,NA,MonkeyCanCode,29619290,,,NA,2024-08-03T16:17:01Z,2024-08-03T16:17:01Z,"> @MonkeyCanCode , thanks! I'm trying out Postgres, will try to figure out where the credentials are stored for Postgres.

For postgres, it will be under xxxxx_credential table. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HHo9O/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/28,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HHw3Y,polaris,2266959320,28,NA,cgpoh,11516015,CG,,NA,2024-08-03T16:30:08Z,2024-08-03T16:30:08Z,@MonkeyCanCode thanks! Just found out that the secrets are in `principal_secrets` table. Everything is working properly now.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HHw3Y/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/28,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HKgX9,polaris,2267678205,28,NA,MonkeyCanCode,29619290,,,NA,2024-08-04T21:12:09Z,2024-08-04T21:12:09Z,Closed this issue as https://github.com/polaris-catalog/polaris/pull/47 is merged.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HKgX9/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/31,https://api.github.com/repos/apache/polaris/issues/31,polaris,2439388141,31,[DOC] Quickstart guide link leads to non-existent file,kferenc3,48920829,Ferenc Kiss,,CLOSED,2024-07-31T07:55:52Z,2024-08-06T18:45:07Z,"The Bootstrapping Polaris section has the following sentence with a link:
""For more information on how to configure Polaris for production usage, see the [docs]."" The link leads to the following page, but it doesn't exist: https://github.com/polaris-catalog/polaris/blob/main/docs/configuring-polaris-for-production.md","{""url"": ""https://api.github.com/repos/apache/polaris/issues/31/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/31,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HDl9-,polaris,2265866110,31,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-08-02T17:45:48Z,2024-08-02T17:45:48Z,Thanks @kferenc3 -- I'm hoping to resolve this with https://github.com/polaris-catalog/polaris/pull/43/commits,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HDl9-/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/31,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HatLe,polaris,2271924958,31,NA,annafil,7892219,Anna Filippova,,NA,2024-08-06T18:45:06Z,2024-08-06T18:45:06Z,Fixed by https://github.com/polaris-catalog/polaris/pull/43/! Thanks @eric-maynard for getting the fix in and @kferenc3 for reporting this ðŸ™ ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HatLe/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/32,polaris,2439403859,32,[FEATURE REQUEST] On-Premise S3 & Remote Signing,c-thiel,12560027,Christian,,OPEN,2024-07-31T08:04:22Z,2025-01-11T00:09:11Z,"**Is your feature request related to a problem? Please describe.**
Currently Polaris only works for AWS S3. It would be great to get support for on-prem deployments as well!

**Describe the solution you'd like**
Add an additional storage profile similar to the [AWS one](https://github.com/polaris-catalog/polaris/blob/bb544239f0ca3bcd076cf2e93116b2747e289e10/spec/polaris-management-service.yml#L880) which allows custom Endpoint configuration. Test with MinIO or Ceph. Grant access via remote signing.

**Describe alternatives you've considered**
I don't think there is any?

**Additional context**
Remote signing spec: https://github.com/apache/iceberg/blob/main/aws/src/main/resources/s3-signer-open-api.yaml
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/32/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G3F4s,polaris,2262588972,32,NA,mjf-89,1841657,Marco Jacopo Ferrarotti,marco.ferrarotti@gmail.com,NA,2024-08-01T09:32:13Z,2024-08-01T09:32:13Z,It would be great to know if such feature is already on the roadmap or not. I would be personally interested in contributing here because currently I'm working for a company where we have everything on-premise. We are using Iceberg with a legacy Hive Standalone Metastore and we are looking for a REST alternative. Polaris is really promising but the lack of support for on premise S3 provider will hinder its adoption.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G3F4s/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G5XLL,polaris,2263184075,32,NA,chris922,3875742,Christian Bandowski,,NA,2024-08-01T14:11:15Z,2024-08-01T14:11:15Z,"When I watched the demo on Snowflake site this was the first thing I noticed - where to configure the S3 endpoint etc.

I can also support here, maybe in development but also testing it with some S3 alternatives. I've got access to Dell ECS, NetApp StorageGRID, MinIO","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G5XLL/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G7NVy,polaris,2263668082,32,NA,guitcastro,1149991,Guilherme Torres Castro,,NA,2024-08-01T18:09:48Z,2024-08-01T18:09:48Z,The main point is that only few S3 compatible services have support for Security Token Service (STS). Minio does have support for it. ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G7NVy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HIg-1,polaris,2267156405,32,NA,mjf-89,1841657,Marco Jacopo Ferrarotti,marco.ferrarotti@gmail.com,NA,2024-08-03T21:14:03Z,2024-08-03T21:14:03Z,@guitcastro It might be possible to implement remote signing for on prem S3 implementations other than minio. But that would mean implement also the remote signing open API spec and that is probably outside the scope of polaris?,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HIg-1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HQO4-,polaris,2269179454,32,NA,guitcastro,1149991,Guilherme Torres Castro,,NA,2024-08-05T14:11:56Z,2024-08-05T14:11:56Z,"@mjf-89 I don't know more than you. I am not maintainer, my comment is just based on how the S3 auth are implemented.  ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HQO4-/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HQbT6,polaris,2269230330,32,NA,dimas-b,40603221,Dmitri Bourlatchkov,,NA,2024-08-05T14:34:48Z,2024-08-05T14:34:48Z,@mjf-89 : could you provide more details (perhaps a link) about the `remote signing open API spec` that you mentioned above?,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HQbT6/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HQp1c,polaris,2269289820,32,NA,snazy,957468,Robert Stupp,,NA,2024-08-05T15:01:31Z,2024-08-05T15:01:31Z,"> The main point is that only few S3 compatible services have support for Security Token Service (STS). Minio does have support for it.

STS is needed for credential-vending, as currently implement.

The actual request signing doesn't interact w/ any remote service. The client (in this case Iceberg) asks the resource (Polaris) to return a signed URL for every particular S3 request.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HQp1c/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HTtke,polaris,2270091550,32,NA,mjf-89,1841657,Marco Jacopo Ferrarotti,marco.ferrarotti@gmail.com,NA,2024-08-05T23:30:27Z,2024-08-05T23:30:27Z,"@dimas-b sure, in the openapi spec of the rest catalog you can see that there are currently two supported delegated access mechanisms, vended credentials and remote signing:

https://github.com/apache/iceberg/blob/e9364faabcc67eef6c61af2ecdf7bcf9a3fef602/open-api/rest-catalog-open-api.yaml#L1488

And here you can find the openapi spec for the remote signing service:

https://github.com/apache/iceberg/blob/e9364faabcc67eef6c61af2ecdf7bcf9a3fef602/aws/src/main/resources/s3-signer-open-api.yaml

I don't know of any open source implemention of that openapi spec, however I think that Tabular is based on such a thing. Or at least that is what I guessed reading their blog posts: 

https://tabular.io/blog/securing-the-data-lake-part-1/

Where I have interpreted the ""authorized file access request"" as a presigned url that the remote signing service is giving back to the engine to access the data files.
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HTtke/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Hd_Ao,polaris,2272784424,32,NA,c-thiel,12560027,Christian,,NA,2024-08-07T07:14:59Z,2024-08-07T07:14:59Z,"I agree that STS is the better solution if available, but not all S3 Services support it. It would be nice to add it at a fallback for on-premise deployments. 
@mjf-89 there are currently two open-source catalogs that support it, [Project Nessie](https://github.com/projectnessie/nessie/blob/081eb047c9e212d110ca9660be12facd475e539f/catalog/service/rest/src/main/java/org/projectnessie/catalog/service/rest/IcebergS3SignParams.java#L236) and the  [TIP Iceberg Catalog](https://github.com/hansetag/iceberg-catalog/blob/bec3966b8ef39dd4bb6bc80834ae69718b7f1464/crates/iceberg-catalog/src/catalog/s3_signer.rs#L180) - links go roughly to the corresponding code sections.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Hd_Ao/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Hhv8R,polaris,2273771281,32,NA,mjf-89,1841657,Marco Jacopo Ferrarotti,marco.ferrarotti@gmail.com,NA,2024-08-07T15:40:14Z,2024-08-07T15:40:14Z,"@c-thiel thank you very much, last time that I checked on Nessie the iceberg rest api was still not implemented and S3 remote signing was definitely not there, TIP was completely outside my radar but it seem really promising, especially for the customization freedom on the authz side. Happy to see that the landscape of iceberg rest catalog is evolving so rapidly. 

As for Polaris I hope that remote signing can be implemented as a fallback for those S3 implementations that do not have an sts endpoint like you have said.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Hhv8R/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6IfqjT,polaris,2290002131,32,NA,dimas-b,40603221,Dmitri Bourlatchkov,,NA,2024-08-14T22:06:58Z,2024-08-14T22:06:58Z,"Remote Signing can be a useful feature. I'd support adding it to Polaris.
1. The catalog does not expose any long of mid-term credentials to the client (reduces risk of credential leaks and makes access revocation is immediate, if/when it happens).
2. Client session runtime is not limited by STS session restrictions (extremely long client sessions are possible at the expense of slightly slower storage I/O calls).
3. The catalog can (hypothetically) make finer-grained access decisions that are not expressible in terms of STS policies.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6IfqjT/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Ifrjr,polaris,2290006251,32,NA,dimas-b,40603221,Dmitri Bourlatchkov,,NA,2024-08-14T22:10:11Z,2024-08-14T22:10:11Z,"@mjf-89 :
> I don't know of any open source implemention of that openapi spec

Just FYI: Nessie [supports](https://github.com/projectnessie/nessie/blob/bbc09b5007ed5cf88209aa00933a99c47e0d34c9/catalog/service/rest/src/main/java/org/projectnessie/catalog/service/rest/AccessDelegation.java#L26) that.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Ifrjr/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Irwtz,polaris,2293173107,32,NA,mjf-89,1841657,Marco Jacopo Ferrarotti,marco.ferrarotti@gmail.com,NA,2024-08-16T09:34:31Z,2024-08-16T09:34:31Z,"@dimas-b thank you, as @c-thiel already mentioned both Nessie and TIP actually support that feature. 

One question that I have regards the performance implications of remote signing. I feel like it could introduce quite a bit of latency to the queries, of course mich depend on the implementation of both the runtime and the catalog. 

Another thing to be noted is that not all the runtimes actually support such feature. As an example I think that currently trino lacks such support: https://github.com/trinodb/trino/issues/21189
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Irwtz/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6QKxed,polaris,2418743197,32,NA,heartblast,11475217,,,NA,2024-10-17T07:12:34Z,2024-10-17T07:12:34Z,"Since the temporary credential feature provided by S3 differs from that of MinIO, adjustments are required to support MinIO. Specifically, the Polaris Catalog must obtain a security token from an OAuth service such as Keycloak to utilize MinIO's temporary credential feature, and the configuration must allow for STS (Security Token Service) endpoint settings to enable this integration.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6QKxed/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6QRpbL,polaris,2420545227,32,NA,mmgaggle,697371,Kyle Bader,kbader@ibm.com,NA,2024-10-17T20:48:01Z,2024-10-17T20:48:01Z,"Ceph supports IAM/STS, both AssumeRole and AssumeRoleWithWebIdentity. I can test to make sure this works as expected in that context.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6QRpbL/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Qazrn,polaris,2422946535,32,NA,lefebsy,16388647,,,NA,2024-10-18T17:39:33Z,2024-10-18T17:39:33Z,"> Since the temporary credential feature provided by S3 differs from that of MinIO, adjustments are required to support MinIO. Specifically, the Polaris Catalog must obtain a security token from an OAuth service such as Keycloak to utilize MinIO's temporary credential feature, and the configuration must allow for STS (Security Token Service) endpoint settings to enable this integration.

Hello,
In fact MinIO support STS assumeRole API out of the box. The documentation explain you can setup an external idp like keycloak, but it will work with MinIO alone. I have done a quick test after forking polaris.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Qazrn/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Qa7sg,polaris,2422979360,32,NA,lefebsy,16388647,,,NA,2024-10-18T18:02:36Z,2024-10-18T18:02:36Z,"Hello,

I can try to contribute to this feature request.
I have coded a polaris core storage implementation, copy of the aws, without the required arnRole parameter, replaced by endpoint, path style, and credentials.
You can choose a strategy for the client calling catalog : 
- ""vending token"" with default STS assume role like aws. It is working with MinIO, and should works also with Dell ECS, NetApp StorageGRID, etc...
- ""vending keys"" : 
- if you do not care a lot about security the catalog can send his own keys to the client
- you can also store in catalog keys dedicated to clients. You can then revoke them externally without breaking the catalog.

You can also choose a strategy during the creation of the catalog (cli, curl api) by passing catalog & or client keys by direct value, or  environnement name variable.
In case of the variable name, you have to be sure that Polaris can find them inside is running environnement, of course. A kubernetes production deployment should be suited for this configuration (envFromSecrets deployed to Polaris pods)

Let me know your opinion about this design. The code is ready, I still have to read the ""PR guide"" and check requirements.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Qa7sg/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6RteR0,polaris,2444616820,32,NA,mmgaggle,697371,Kyle Bader,kbader@ibm.com,NA,2024-10-29T15:30:12Z,2024-10-29T15:30:12Z,"@lefebsy If you can point me to a branch, I can try it against Ceph","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6RteR0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6SgGkL,polaris,2457889035,32,NA,lefebsy,16388647,,,NA,2024-11-05T18:29:52Z,2024-11-05T18:29:52Z,"> @lefebsy If you can point me to a branch, I can try it against Ceph

Thank you ! I have no access to a rados gateway it could be a good test.
https://github.com/lefebsy/polaris/tree/refs/heads/s3compatible
The PR is under review https://github.com/apache/polaris/pull/389 

@mmgaggle  If you need specific modification to be compliant with Ceph-rgw tell me :)
(Curiosity : Is it a Ceph supporting NVMe over Fabrics ? I've heard perfs are awsome...)","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6SgGkL/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XAjQk,polaris,2533504036,32,NA,ang6300,58575062,,,NA,2024-12-11T02:46:16Z,2024-12-11T02:46:16Z,"@lefebsy I tried with this
https://github.com/lefebsy/polaris/tree/refs/heads/s3compatible

I am testing it against on premise s3 storage but did not find what option to specify custom s3 and sts endpoint.  Tried to add these to spark-default.conf but not working.
  
spark.hadoop.fs.s3a.endpoint
spark.hadoop.fs.s3a.assumed.role.sts.endpoint
spark.hadoop.fs.s3a.aws.credentials.provider
spark.hadoop.fs.s3a.assumed.role.credentials.provider
spark.hadoop.fs.s3a.access.key
spark.hadoop.fs.s3a.secret.key
spark.hadoop.fs.s3a.path.style.access

Further testing shows spark_sql loads AWS credential from environment variables.  Set up all the variables and able to write metadata to on premise s3 bucket but failed to write the parquet file.
s3://polaris-sg/sg_db1/table1/data/00000-0-49bf02f5-8632-45b1-be33-95e1658e3a33-0-00001.parquet

24/12/11 23:35:52 ERROR DataWritingSparkTask: Aborting commit for partition 0 (task 0, attempt 0, stage 0.0)
24/12/11 23:35:53 WARN S3FileIO: Encountered failure when deleting batch
software.amazon.awssdk.services.s3.model.S3Exception: The AWS Access Key Id you provided does not exist in our records. (Service: S3, Status Code: 403, Request ID: P25DMBEE3XBK20XP, Extended Request ID: iXnMbkU52j2tRqGjmIARh2tttxdcNBl0RhlTrLSXapP/250/Mlms0dH2K0OMoawTldRdt37pHAfZWRSXoFm/fw==)

I believe it is expecting to get temporary access key/STS token from AWS STS endpoint using the assumerole ARN provided to run_spark_sql.sh.
 
It does not use this environment variable:
export AWS_ENDPOINT_URL_STS=""https://sts.example.com""

Can you update your code to allow custom STS endpoint? 

Appreciate any help.  Thank you. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XAjQk/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XP189,polaris,2537512765,32,NA,lefebsy,16388647,,,NA,2024-12-12T00:56:54Z,2024-12-12T00:56:54Z,"Hello @ang6300 ,

Parameters are described here :
https://github.com/lefebsy/polaris/blob/refs/heads/s3compatible/spec/polaris-management-service.yml#L906

You can have a look to the non-regression tests script to find example to create catalog and how to configure spark-sql :
https://github.com/lefebsy/polaris/blob/refs/heads/s3compatible/regtests/run_spark_sql_s3compatible.sh

You tried to setup S3 in spark confs, but it's useless : S3 endpoint and S3 keys are defined in the catalog inside Polaris.
Spark will retrieve the endpoint from Polaris catalog response, alongside the STS, during vended-credential negotiation with the catalog.

TL;DR :


Create the catalog :
```
curl -s -i -X POST -H ""Authorization: Bearer ${POLARIS_BEARER_TOKEN}"" \
      -H 'Accept: application/json' \
      -H 'Content-Type: application/json' \
      http://${POLARIS_HOST:-localhost}:8181/api/management/v1/catalogs \
      -d ""{
            \""name\"": \""my-minio-wh\"",
            \""id\"": 100,
            \""type\"": \""INTERNAL\"",
            \""readOnly\"": false,
            \""properties\"": {
              \""default-base-location\"": \""${S3_LOCATION}\""
            },
            \""storageConfigInfo\"": {
              \""storageType\"": \""S3_COMPATIBLE\"",
              \""allowedLocations\"": [\""${S3_LOCATION}/\""],
              \""s3.endpoint\"": \""https://localhost:9000\""
              \""s3.path-style-access\"": true,
              \""s3.credentials.catalog.access-key-id\"": \""S3_ACCESS_KEY_VAR_NAME\"",
              \""s3.credentials.catalog.secret-access-key\"": \""S3_SECRET_KEY_VAR_NAME\""
            }
          }""
```
Use the catalog :
```
${SPARK_HOME}/bin/spark-sql \
  --conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions \
  --conf spark.sql.catalog.polaris=org.apache.iceberg.spark.SparkCatalog \
  --conf spark.sql.catalog.polaris.type=rest \
  --conf spark.sql.catalog.polaris.uri=http://${POLARIS_HOST:-localhost}:8181/api/catalog \
  --conf spark.sql.catalog.polaris.header.X-Iceberg-Access-Delegation=vended-credentials \
  --conf spark.sql.catalog.polaris.token=""${POLARIS_BEARER_TOKEN}"" \
  --conf spark.sql.catalog.polaris.warehouse=my-minio-wh \
  --conf spark.sql.defaultCatalog=polaris
```

Et voilÃ  :)","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XP189/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XP9dk,polaris,2537543524,32,NA,ang6300,58575062,,,NA,2024-12-12T01:26:09Z,2024-12-12T01:26:09Z,"Hello @lefebsy 

Thank you for all the details. 
If I read it correctly, the run_spark_sql_s3compatible.sh does not use role arn.  

Is it possible to use role-arn but with custom sts endpoint

[trino-user@trino-m regtests]$ grep role run_spark_sql.sh
#   ./run_spark_sql.sh [S3-location AWS-IAM-role]
#       - [AWS-IAM-role] - The AWS IAM role for catalog to assume when accessing the S3 location.
#     ./run_spark_sql.sh s3://my-bucket/path arn:aws:iam::123456789001:role/my-role
  echo ""Usage: ./run_spark_sql.sh [S3-location AWS-IAM-role]""
 
 Currently I am able to use run_spark_sql.sh with S3-location AWS-IAM-role with on premise s3 compatible storage.  
 It creates the metadata object but not the parquet. 
 
 aws s3 ls --recursive s3://polaris-sg/sg_db1
2024-12-11 23:34:03       1072 sg_db1/table1/metadata/00000-e77a2d71-ee13-4bd7-89a8-2450650d5249.metadata.json

failed to write the parquet file.
s3://polaris-sg/sg_db1/table1/data/00000-0-49bf02f5-8632-45b1-be33-95e1658e3a33-0-00001.parquet

The polaris-sg bucket is on s3 compatible storage, not on AWS S3.  

","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XP9dk/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XYtUs,polaris,2539836716,32,NA,lefebsy,16388647,,,NA,2024-12-12T19:24:48Z,2024-12-12T19:24:48Z,"Correct, the RoleArn is not used/implemented.
The STS will still be valid only for the ressource queried by spark from the catalog (a dedicated policy is build for each query).

Could you explain what's the purpose of roleArn in your use case outside AWS ?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XYtUs/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XZyMc,polaris,2540118812,32,NA,ang6300,58575062,,,NA,2024-12-12T22:15:12Z,2024-12-12T22:15:12Z,"Thank you lefebsy. 
End user wants to use roleArn for security reason.   ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XZyMc/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Xcben,polaris,2540812199,32,NA,lefebsy,16388647,,,NA,2024-12-13T07:56:40Z,2024-12-13T07:56:40Z,"Hello @ang6300,

Roles are always for security reasons ;)
I am asking this to understand wich test could be ok to check global security behavior expected, in case I add roleArn in this implementation.
Adding this parameter is quite easy. Testing if it's correctly done is harder.

You can try again.

I have updated the code with roleArn. Be carefull I've also reformated parameters in CamelCase :

- specs : https://github.com/lefebsy/polaris/blob/refs/heads/s3compatible/spec/polaris-management-service.yml#L910

- ex : https://github.com/lefebsy/polaris/blob/refs/heads/s3compatible/regtests/run_spark_sql_s3compatible.sh#L171","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Xcben/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Xjlew,polaris,2542688176,32,NA,ang6300,58575062,,,NA,2024-12-14T02:50:04Z,2024-12-14T02:50:04Z,"Hello @lefebsy,
Thank you very much for making the changes.
I will redo the testing next week. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Xjlew/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6X0sj3,polaris,2547173623,32,NA,ang6300,58575062,,,NA,2024-12-16T23:56:40Z,2024-12-16T23:56:40Z,"Hi @lefebsy 
Thank you for taking time to modify your code and responding to my question/request. 
Update - I read the ./regtests/run_spark_sql_s3compatible.sh again and I need to do another testing re roleARN.  Will update the result again. 



","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6X0sj3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6X1EW_,polaris,2547271103,32,NA,metadaddy,723517,Pat Patterson,metadaddy@gmail.com,NA,2024-12-17T00:51:50Z,2024-12-17T00:51:50Z,Hi @lefebsy - thanks for your work on #389! I'm interested in getting Polaris working with [Backblaze B2 Cloud Storage](https://www.backblaze.com/cloud-storage) - it looks like your PR might do just that. I'll give it a quick test as soon as I can and let you know.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6X1EW_/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6X1WxR,polaris,2547346513,32,NA,metadaddy,723517,Pat Patterson,metadaddy@gmail.com,NA,2024-12-17T02:07:53Z,2024-12-17T02:07:53Z,"It mostly works. I can `CREATE TABLE ... AS`, `SELECT` the data and metadata, but when I try to `INSERT` another row, Polaris gets a 400 error from Backblaze B2. I'll turn on AWS SDK request logging and see what's going on.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6X1WxR/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6X1jvj,polaris,2547399651,32,NA,ang6300,58575062,,,NA,2024-12-17T02:58:38Z,2024-12-17T02:58:38Z,"@lefebsy, 
The run_spark_sql_s3compatible.sh execute this 'queries-for-spark.sql'. However, the query has problem with this statement:
CREATE OR REPLACE VIEW db1.ns2.view1 ( line_count COMMENT 'Count of lines') AS SELECT COUNT(1) as qty FROM db1.ns1.table1;

Error:
Polaris catalog does not support views. 

I removed below lines from queries-for-spark.sql so that it can proceed to create db2 in warehouse2 bucket. 

CREATE OR REPLACE VIEW db1.ns2.view1 ( line_count COMMENT 'Count of lines') AS SELECT COUNT(1) as qty FROM db1.ns1.table1;
SELECT * FROM db1.ns2.view1;
INSERT INTO db1.ns1.table1 VALUES (13, 23);
SELECT * FROM db1.ns2.view1;
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6X1jvj/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6X5Zns,polaris,2548406764,32,NA,lefebsy,16388647,,,NA,2024-12-17T13:03:06Z,2024-12-17T13:03:06Z,"> It mostly works. I can `CREATE TABLE ... AS`, `SELECT` the data and metadata, but when I try to `INSERT` another row, Polaris gets a 400 error from Backblaze B2. I'll turn on AWS SDK request logging and see what's going on.

Hello,
400 bad request... What will log says ðŸ¤žðŸ™„
Polaris logs can also be set in debug level","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6X5Zns/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6X5hBX,polaris,2548437079,32,NA,lefebsy,16388647,,,NA,2024-12-17T13:16:55Z,2024-12-17T13:16:55Z,"> @lefebsy, The run_spark_sql_s3compatible.sh execute this 'queries-for-spark.sql'. However, the query has problem with this statement: CREATE OR REPLACE VIEW db1.ns2.view1 ( line_count COMMENT 'Count of lines') AS SELECT COUNT(1) as qty FROM db1.ns1.table1;
> 
> Error: Polaris catalog does not support views.
> 
> I removed below lines from queries-for-spark.sql so that it can proceed to create db2 in warehouse2 bucket.
> 
> CREATE OR REPLACE VIEW db1.ns2.view1 ( line_count COMMENT 'Count of lines') AS SELECT COUNT(1) as qty FROM db1.ns1.table1; SELECT * FROM db1.ns2.view1; INSERT INTO db1.ns1.table1 VALUES (13, 23); SELECT * FROM db1.ns2.view1;

Hello,
Thank you for this feedback.
Do you think that the problem about views could be related to some restriction in the RoleArn you are testing ?
Because this PR is focusing on storage implementation, it is far from Polaris or Iceberg code related to view support (and views are supported by Polaris)
#225 quote the same message but was related to missing iceberg spark extension..","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6X5hBX/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6X9bE4,polaris,2549461304,32,NA,metadaddy,723517,Pat Patterson,metadaddy@gmail.com,NA,2024-12-17T19:45:07Z,2024-12-17T19:45:07Z,"@lefebsy I'm not sure why it wasn't working before, but my basic sanity check script runs without errors now. Great job!

Please do let me know if there's anything I can do to help get this PR merged.

```bash
export POLARIS_BEARER_TOKEN=""principal:root;realm:default-realm""
export S3_LOCATION=""s3://metadaddy-polaris/""
export AWS_ENDPOINT_URL=""https://s3.us-west-004.backblazeb2.com""
export WAREHOUSE=""my-b2-warehouse""

curl -s -i -X POST -H ""Authorization: Bearer ${POLARIS_BEARER_TOKEN}"" \
      -H 'Accept: application/json' \
      -H 'Content-Type: application/json' \
      http://${POLARIS_HOST:-localhost}:8181/api/management/v1/catalogs \
      -d ""{
            \""name\"": \""${WAREHOUSE}\"",
            \""id\"": 100,
            \""type\"": \""INTERNAL\"",
            \""readOnly\"": false,
            \""properties\"": {
              \""default-base-location\"": \""${S3_LOCATION}\""
            },
            \""storageConfigInfo\"": {
              \""storageType\"": \""S3_COMPATIBLE\"",
              \""allowedLocations\"": [\""${S3_LOCATION}\""],
              \""s3.endpoint\"": \""${AWS_ENDPOINT_URL}\"",
              \""s3.credentials.catalog.access-key-id\"": \""AWS_ACCESS_KEY_ID\"",
              \""s3.credentials.catalog.secret-access-key\"": \""AWS_SECRET_ACCESS_KEY\"",
              \""s3.credentials.client.access-key-id\"": \""AWS_ACCESS_KEY_ID\"",
              \""s3.credentials.client.secret-access-key\"": \""AWS_SECRET_ACCESS_KEY\""
            }
          }""
```

```sql
SHOW CATALOGS;
SHOW SCHEMAS FROM iceberg;
SHOW TABLES FROM iceberg.information_schema;
DESCRIBE iceberg.information_schema.tables;

CREATE SCHEMA IF NOT EXISTS iceberg.my_schema;
CREATE TABLE iceberg.my_schema.test_polaris AS SELECT 1 x;
SELECT * FROM iceberg.my_schema.test_polaris;

INSERT INTO iceberg.my_schema.test_polaris VALUES (2);
SELECT * FROM iceberg.my_schema.test_polaris;

UPDATE iceberg.my_schema.test_polaris SET x = 3 WHERE x = 2;
SELECT * FROM iceberg.my_schema.test_polaris;

DELETE FROM iceberg.my_schema.test_polaris WHERE x = 1;
SELECT * FROM iceberg.my_schema.test_polaris;
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6X9bE4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6X9in3,polaris,2549492215,32,NA,ang6300,58575062,,,NA,2024-12-17T20:01:15Z,2024-12-17T20:01:15Z,"@lefebsy   

Test running the SQL query manually using local storage (not s3), same problem, cannot create view.

I ran ./regtests/run_spark_sql.sh

spark-sql ()> CREATE DATABASE IF NOT EXISTS db1;
**spark-sql ()> CREATE DATABASE IF NOT EXISTS db1.ns1;
spark-sql ()> CREATE DATABASE IF NOT EXISTS db1.ns2;**
spark-sql ()> CREATE OR REPLACE TABLE db1.ns1.table1 ( f1 int, f2 int );
spark-sql ()> INSERT INTO db1.ns1.table1 VALUES (10, 20);
spark-sql ()> INSERT INTO db1.ns1.table1 VALUES (11, 21);
spark-sql ()> INSERT INTO db1.ns1.table1 VALUES (12, 22);
spark-sql ()> select * from db1.ns1.table1;
11      21
12      22
10      20
spark-sql ()> CREATE OR REPLACE VIEW db1.ns2.view1 ( line_count COMMENT 'Count of lines') AS SELECT COUNT(1) as qty FROM db1.ns1.table1;
Catalog polaris does not support views.


spark-sql ()> show databases;
db1
spark-sql ()> use db1;
spark-sql (db1)> show tables;
spark-sql (db1)> use db1.ns1;
spark-sql (db1.ns1)> show tables;
table1
spark-sql (db1.ns1)> use db1.ns2;
spark-sql (db1.ns2)> show tables;

spark-sql (db1.ns1)> show schemas in db1;
db1.ns1
db1.ns2
spark-sql (db1.ns1)> show tables in db1.ns1;
table1
spark-sql (db1.ns1)> show tables in db1.ns2;

This database/table is stored in /tmp/polaris
ls -lR /tmp/polaris
/tmp/polaris:
total 0
drwxr-xr-x. 3 trino-user trino-user 17 Dec 17 20:54 db1

/tmp/polaris/db1:
total 0
drwxr-xr-x. 3 trino-user trino-user 20 Dec 17 20:54 ns1

/tmp/polaris/db1/ns1:
total 0
drwxr-xr-x. 4 trino-user trino-user 34 Dec 17 20:54 table1

/tmp/polaris/db1/ns1/table1:
total 8
drwxr-xr-x. 2 trino-user trino-user 4096 Dec 17 20:54 data
drwxr-xr-x. 2 trino-user trino-user 4096 Dec 17 20:54 metadata

/tmp/polaris/db1/ns1/table1/data:
total 12
-rw-r--r--. 1 trino-user trino-user 599 Dec 17 20:54 00000-0-52fe2151-228a-4f9b-bc2a-607935bc61d3-0-00001.parquet
-rw-r--r--. 1 trino-user trino-user 599 Dec 17 20:54 00000-1-5d2dfdbb-17dd-429f-9267-812851654f8e-0-00001.parquet
-rw-r--r--. 1 trino-user trino-user 599 Dec 17 20:54 00000-2-1f9c2f04-27bc-454a-9e41-1468069961c8-0-00001.parquet

/tmp/polaris/db1/ns1/table1/metadata:
total 68
-rw-r--r--. 1 trino-user trino-user 1072 Dec 17 20:54 00000-0839c306-81f7-421a-8faa-b2bde642c4d3.metadata.json
-rw-r--r--. 1 trino-user trino-user 2131 Dec 17 20:54 00001-fcb2e801-dd1b-40a2-bb76-a01d2e039739.metadata.json
-rw-r--r--. 1 trino-user trino-user 3135 Dec 17 20:54 00002-57ec7ad9-fbc4-46e4-a22b-fa91ba03834b.metadata.json
-rw-r--r--. 1 trino-user trino-user 4139 Dec 17 20:54 00003-38c2c61e-ca49-4cef-8b74-2144c6ffb08a.metadata.json
-rw-r--r--. 1 trino-user trino-user 6661 Dec 17 20:54 16109ef1-dfdc-4d89-ad8a-ef58aafab90a-m0.avro
-rw-r--r--. 1 trino-user trino-user 6660 Dec 17 20:54 4adaaf4b-94b7-4e3f-94c4-d4d9f57fafb0-m0.avro
-rw-r--r--. 1 trino-user trino-user 6661 Dec 17 20:54 4d5609be-0f49-4de9-9ece-ee30b3313ff4-m0.avro
-rw-r--r--. 1 trino-user trino-user 4222 Dec 17 20:54 snap-6785593917781477189-1-4adaaf4b-94b7-4e3f-94c4-d4d9f57fafb0.avro
-rw-r--r--. 1 trino-user trino-user 4293 Dec 17 20:54 snap-7487473443867003837-1-4d5609be-0f49-4de9-9ece-ee30b3313ff4.avro
-rw-r--r--. 1 trino-user trino-user 4337 Dec 17 20:54 snap-8394070144254410066-1-16109ef1-dfdc-4d89-ad8a-ef58aafab90a.avro
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6X9in3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YCUPo,polaris,2550744040,32,NA,lefebsy,16388647,,,NA,2024-12-18T09:01:06Z,2024-12-18T09:01:06Z,"> @lefebsy I'm not sure why it wasn't working before, but my basic sanity check script runs without errors now. Great job! 
> Please do let me know if there's anything I can do to help get this PR merged.
> 

Thank you very much @metadaddy  for your 'B2 Backblaze' tests and feedback !
You should try to add a :+1:  on the PR #389  ðŸ˜‰
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YCUPo/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YLgRC,polaris,2553152578,32,NA,lefebsy,16388647,,,NA,2024-12-19T09:13:56Z,2024-12-19T09:13:56Z,"> @lefebsy
> Test running the SQL query manually using local storage (not s3), same problem, cannot create view.
> I ran ./regtests/run_spark_sql.sh
> spark-sql ()> CREATE DATABASE IF NOT EXISTS db1; **spark-sql ()> CREATE DATABASE IF 
> ...

Hello, same problem with different storage implementation, seems you have a local problem in your conf (spark iceberg extension?)...
Sorry @ang6300  no other ideaðŸ’¡ with so few clue.. ðŸ¤”
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YLgRC/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZEz-V,polaris,2568175509,32,NA,ryanovas,5014918,Ryan Ovas,,NA,2025-01-02T18:12:50Z,2025-01-02T18:12:50Z,Would also love to see this so we can use Polaris in Digital Ocean,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZEz-V/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Z3N1m,polaris,2581388646,32,NA,mmgaggle,697371,Kyle Bader,kbader@ibm.com,NA,2025-01-09T22:47:05Z,2025-01-09T22:47:05Z,"I'm finally getting around to testing this, I'm hitting this error:

https://gist.github.com/mmgaggle/6e37d367bc5ccdb1c2e7b7c0fbf9235c

I think you might need to pull in https://github.com/apache/polaris/pull/581","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Z3N1m/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/32,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6aEw3t,polaris,2584940013,32,NA,mmgaggle,697371,Kyle Bader,kbader@ibm.com,NA,2025-01-11T00:09:09Z,2025-01-11T00:09:09Z,I added that fix and now have credential vending working great with Ceph (AssumeRole).,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6aEw3t/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/37,https://api.github.com/repos/apache/polaris/issues/37,polaris,2440344588,37,[BUG] Getting the client-id and client-secret from stdout,AlexMercedCoder,52634838,Alex Merced,alex@alexmerced.dev,CLOSED,2024-07-31T15:32:16Z,2024-08-08T18:55:29Z,"A couple issues I had running through the quickstart, which just may documentation issues.

1. I deployed using Docker Compose

Looking at the stdout output I did not find what the docs asked me to look for:

```
**Bootstrapped with credentials: {""client-id"": ""XXXX"", ""client-secret"": ""YYYY""}**
```

But I did find this which I assumed was what I was looking for:

```
  realm: default-realm root principal credentials: fa44645a04410a0e:f1b82a42de2295da466682d3cfdbb0f1
```

I assume the format in this case was `id:secret`

So then ran the CLI command

```
./polaris \
  --client-id fa44645a04410a0e \
  --client-secret f1b82a42de2295da466682d3cfdbb0f1 \
  catalogs \
  create \
  --storage-type s3 \
  --default-base-location s3://some-example-bucket/folder/ \
  --role-arn arn:aws:iam::###########:role/polaris-storage \
  first-polaris-catalog
```

I ran into a few issues:

1. The Polaris CLI startup script did still needed Pydantic and dateutil to be installed, so I had to install those manually, assuming probably poetry. I do see them in the pyproject.toml, so I'm assuming that's more a ""my system"" problem, so Installed them in the virtual environment that was created and all seems to work fine now.

2. I ran the command above and got a JSON parsing error

```
Traceback (most recent call last):
  File ""/home/alexmerced/development/developmentwork/dremio/repos/polaris/regtests/client/python/cli/polaris_cli.py"", line 73, in <module>
    PolarisCli.execute()
  File ""/home/alexmerced/development/developmentwork/dremio/repos/polaris/regtests/client/python/cli/polaris_cli.py"", line 45, in execute
    error = json.loads(e.body)['error']
            ^^^^^^^^^^^^^^^^^^
  File ""/home/alexmerced/.pyenv/versions/3.11.2/lib/python3.11/json/__init__.py"", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/alexmerced/.pyenv/versions/3.11.2/lib/python3.11/json/decoder.py"", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/alexmerced/.pyenv/versions/3.11.2/lib/python3.11/json/decoder.py"", line 355, in raw_decode
    raise JSONDecodeError(""Expecting value"", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
```

3. This wasn't super helpful so I modified polaris_cli.py to get me more detail

```py
from cli.options.parser import Parser
from polaris.management import ApiClient, Configuration, ApiException
from polaris.management import PolarisDefaultApi

class PolarisCli:
    """"""
    Implements a basic Command-Line Interface (CLI) for interacting with a Polaris service. The CLI can be used to
    manage entities like catalogs, principals, and grants within Polaris and can perform most operations that are
    available in the Python client API.

    Example usage:
    * ./polaris --client-id ${id} --client-secret ${secret} --host ${hostname} principals create example_user
    * ./polaris --client-id ${id} --client-secret ${secret} --host ${hostname} principal-roles create example_role
    * ./polaris --client-id ${id} --client-secret ${secret} --host ${hostname} catalog-roles list
    """"""

    @staticmethod
    def execute():
        options = Parser.parse()
        client_builder = PolarisCli._get_client_builder(options)
        with client_builder() as api_client:
            try:
                from cli.command import Command
                admin_api = PolarisDefaultApi(api_client)
                command = Command.from_options(options)
                command.execute(admin_api)
            except ApiException as e:
                import json
                print(f'Exception when communicating with the Polaris server. Status code: {e.status}')
                print(f'Response headers: {e.headers}')
                print(f'Response body: {e.body}')
                try:
                    error = json.loads(e.body)['error']
                    print(f'{error[""type""]}: {error[""message""]}')
                except (json.JSONDecodeError, KeyError):
                    print('Error parsing response as JSON. Raw response body:')
                    print(e.body)

    @staticmethod
    def _get_client_builder(options):
        # Validate
        has_access_token = options.access_token is not None
        has_client_secret = options.client_id is not None and options.client_secret is not None
        if has_access_token and has_client_secret:
            raise Exception(""Please provide credentials via either --client-id / --client-secret or ""
                            ""--access-token, but not both"")

        # Authenticate accordingly
        polaris_catalog_url = f'http://{options.host}:{options.port}/api/management/v1'
        if has_access_token:
            return lambda: ApiClient(
                Configuration(host=polaris_catalog_url, access_token=options.access_token),
            )
        elif has_client_secret:
            return lambda: ApiClient(
                Configuration(host=polaris_catalog_url, username=options.client_id, password=options.client_secret),
            )
        else:
            raise Exception(""Please provide credentials via --client-id & --client-secret or via --access-token"")


if __name__ == '__main__':
    PolarisCli.execute()
```

3. So running this version of python_cli.py I got the following output:

```
Exception when communicating with the Polaris server. Status code: 401
Response headers: HTTPHeaderDict({'Date': 'Wed, 31 Jul 2024 15:16:14 GMT', 'Vary': 'Origin', 'WWW-Authenticate': 'Bearer realm=""realm""', 'Content-Type': 'text/plain', 'Content-Length': '49'})
Response body: Credentials are required to access this resource.
Error parsing response as JSON. Raw response body:
Credentials are required to access this resource.
```

So I'm assuming the client-id and client-secret aren't what I thought they were or I passed them incorrectly, any guidance on this would be helpful.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/37/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/37,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6GyAJ2,polaris,2261254774,37,NA,AlexMercedCoder,52634838,Alex Merced,alex@alexmerced.dev,NA,2024-07-31T19:17:31Z,2024-07-31T19:17:31Z,"Upon deeper exploration, based on the code I am correct that the values I thought were client and secret are, but when I started printing the headers/body/params of the request in the CLI it seemed that the client_id value and client_secret weren't being passed anywhere in the request. But when I printed (options.client_id) and (options.client_secret) in python_cli.py it did log the right values they just don't seem to be making it to the API call when I log the request details from `rest.py` .

Still working on it, if I can figure out the fix I'll make a PR.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6GyAJ2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/37,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6GyFrE,polaris,2261277380,37,NA,AlexMercedCoder,52634838,Alex Merced,alex@alexmerced.dev,NA,2024-07-31T19:31:03Z,2024-07-31T19:31:03Z,"Ok, so in rest.py I've logged

- params
- headers
- body
- the request object being sent here is what I get

```
##Params
{}
##Header
{'Content-Type': 'application/json', 'User-Agent': 'OpenAPI-Generator/1.0.0/python'}
## Body
{""catalog"": {""type"": ""INTERNAL"", ""name"": ""first-polaris-catalog"", ""properties"": {""default-base-location"": ""s3://somebucket/folder/""}, ""storageConfigInfo"": {""storageType"": ""S3"", ""roleArn"": ""arn:aws:iam::xxxxxxxxxx:role/polaris-storage""}}}
##Request Object
r1 {'headers': HTTPHeaderDict({'Date': 'Wed, 31 Jul 2024 19:26:42 GMT', 'Vary': 'Origin', 'WWW-Authenticate': 'Bearer realm=""realm""', 'Content-Type': 'text/plain', 'Content-Length': '49'}), 'status': 401, 'version': 11, 'reason': 'Unauthorized', 'strict': 0, 'decode_content': True, 'retries': Retry(total=3, connect=None, read=None, redirect=None, status=None), 'enforce_content_length': False, 'auto_close': True, '_decoder': None, '_body': None, '_fp': <http.client.HTTPResponse object at 0x75ec46e41840>, '_original_response': <http.client.HTTPResponse object at 0x75ec46e41840>, '_fp_bytes_read': 0, 'msg': None, '_request_url': 'http://localhost:8181/api/management/v1/catalogs', '_pool': <urllib3.connectionpool.HTTPConnectionPool object at 0x75ec46e785d0>, '_connection': <urllib3.connection.HTTPConnection object at 0x75ec47525750>, 'chunked': False, 'chunk_left': None, 'length_remaining': 49}
```

the `r1` was print for me identify which request block in rest.py this was coming from which means it ran through this:

```
# no content type provided or payload is json
                content_type = headers.get('Content-Type')
                if (
                    not content_type
                    or re.search('json', content_type, re.IGNORECASE)
                ):
                    request_body = None
                    if body is not None:
                        request_body = json.dumps(body)
                        print(request_body)
                    r = self.pool_manager.request(
                        method,
                        url,
                        body=request_body,
                        timeout=timeout,
                        headers=headers,
                        preload_content=False
                    )
                    print(""r1"", r.__dict__)
```

Weird that the body was labeled as NONE cause when I logged `request_body` I got the right value and it's clearly assigned to body but when I log the request the body is not there.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6GyFrE/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/37,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G3Sy1,polaris,2262641845,37,NA,cgpoh,11516015,CG,,NA,2024-08-01T09:59:24Z,2024-08-01T09:59:24Z,"Hi @AlexMercedCoder , I have the same error when I'm trying to create a catalog using CLI and following the readme doesn't help for me too. After digging further, I'm able to create my catalog using the following curl command:
```
curl -i -X POST -H ""Authorization: Bearer $PRINCIPAL_TOKEN"" -H 'Accept: application/json' -H 'Content-Type: application/json' \
  http://${POLARIS_HOST:-localhost}:8181/api/management/v1/catalogs \
  -d '{""name"": ""polaris"", ""type"": ""INTERNAL"", ""properties"": {
        ""default-base-location"": ""abfss://mycontainer@storageaccount.dfs.core.windows.net/test/""
    },""storageConfigInfo"": {
        ""tenantId"": ""long-tenant-id"",
        ""storageType"": ""AZURE"",
        ""allowedLocations"": [
            ""abfss://mycontainer@storageaccount.dfs.core.windows.net/test/""
        ]
    } }'
``` ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G3Sy1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/37,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G30pN,polaris,2262780493,37,NA,AlexMercedCoder,52634838,Alex Merced,alex@alexmerced.dev,NA,2024-08-01T11:13:25Z,2024-08-01T11:13:25Z,"@cgpoh is the principal token just `id:secret` or do I have to make another curl request for the token cause I was working on trying to get the token endpoint to return me a token and hadn't successfully done that yet.

But this is super helpful, thank you!","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G30pN/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/37,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G4Db6,polaris,2262841082,37,NA,cgpoh,11516015,CG,,NA,2024-08-01T11:48:08Z,2024-08-01T11:48:08Z,"@AlexMercedCoder, I have to make a curl request to get the token:
```
curl -i -X POST \
  http://localhost:8181/api/catalog/v1/oauth/tokens \
  -d 'grant_type=client_credentials&client_id=client_id_obtained_when_boot_up&client_secret=client_secret_obtained_when_boot_up&scope=PRINCIPAL_ROLE:ALL'
```
After getting the token: 
```
{
    ""access_token"": ""principal:root;password:af88b69c4f1215a1e62202ceb45f5a92;realm:default-realm;role:ALL"",
    ""scope"": ""PRINCIPAL_ROLE:ALL"",
    ""token_type"": ""bearer"",
    ""expires_in"": 3600
}
```
I export the access_token:
```
export PRINCIPAL_TOKEN=""principal:root;password:af88b69c4f1215a1e62202ceb45f5a92;realm:default-realm;role:ALL""
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G4Db6/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/37,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G6cp2,polaris,2263468662,37,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-08-01T16:22:48Z,2024-08-01T16:22:48Z,"I think many of these issues should be fixed by:
https://github.com/polaris-catalog/polaris/pull/30","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G6cp2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/37,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G7xGS,polaris,2263814546,37,NA,AlexMercedCoder,52634838,Alex Merced,alex@alexmerced.dev,NA,2024-08-01T19:29:32Z,2024-08-01T19:29:32Z,"Just in case anyone want to go through the steps I did get it all going here is write up:
https://www.dremio.com/blog/getting-hands-on-with-polaris-oss-apache-iceberg-and-apache-spark/","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G7xGS/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/37,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Hcae7,polaris,2272372667,37,NA,collado-mike,40346148,Michael Collado,,NA,2024-08-07T00:05:37Z,2024-08-07T00:05:37Z,@AlexMercedCoder can you confirm the linked PR did solve your issue? Can we close this?,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Hcae7/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/37,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HsBBI,polaris,2276462664,37,NA,collado-mike,40346148,Michael Collado,,NA,2024-08-08T18:55:29Z,2024-08-08T18:55:29Z,I'll close for now. Feel free to reopen if this is still an issue,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HsBBI/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/38,https://api.github.com/repos/apache/polaris/issues/38,polaris,2440388526,38,[BUG] Integration Test fails (PolarisSparkIntegrationTest),mths1,68608970,,,CLOSED,2024-07-31T15:54:50Z,2024-08-02T21:12:04Z,"**Describe the bug**

./gradlew build

results in a test failure 

![image](https://github.com/user-attachments/assets/ac8e616f-90c7-4a4c-ad54-99908cd0fec0)

RHEL 9
java --version
```
openjdk 21.0.4 2024-07-16 LTS
OpenJDK Runtime Environment (Red_Hat-21.0.4.0.7-1) (build 21.0.4+7-LTS)
OpenJDK 64-Bit Server VM (Red_Hat-21.0.4.0.7-1) (build 21.0.4+7-LTS, mixed mode, sharing)
```

javac --version
```
javac 21.0.4
```



**Is this a possible security vulnerability?** 
- [ ] yes -- if yes, stop here and contact security@polaris.io instead
- [x] no 

**To Reproduce**
./gradlew build
See error

**Expected behavior**
Builds without test failures

**Screenshots**
If applicable, add screenshots to help explain your problem.

**System info (please complete the following information):**
 - OS:  RHEL 9
 - Polaris Catalog Version [e.g. 0.3.0] main branch

**Additional context**
Add any other context about the problem here.
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/38/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/38,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6GwqI7,polaris,2260902459,38,NA,RussellSpitzer,413025,Russell Spitzer,,NA,2024-07-31T16:22:16Z,2024-07-31T16:22:16Z,Is Docker running on your machine? The Spark integration tests require Docker.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6GwqI7/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/38,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Gwvkl,polaris,2260924709,38,NA,mths1,68608970,,,NA,2024-07-31T16:34:34Z,2024-07-31T16:34:34Z,"Thanks for your support. There is ""docker"", as in docker -v

docker -v
```
Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg.
podman version 4.9.4-rhel
```

(btw: in the readme, docker is only mentioned ""If you want to run the project in a containerized environment."", not for ./gradlew build)","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Gwvkl/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/38,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Gw4t_,polaris,2260962175,38,NA,RussellSpitzer,413025,Russell Spitzer,,NA,2024-07-31T16:57:00Z,2024-07-31T16:57:00Z,"I'm using Docker for Desktop in OSX, I'm not sure what the RHEL equivalent would be. We should probably add details of that to the documentation. When I wasn't running docker, the Spark suite failed. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Gw4t_/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/38,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6GySbD,polaris,2261329603,38,NA,AlexMercedCoder,52634838,Alex Merced,alex@alexmerced.dev,NA,2024-07-31T19:50:50Z,2024-07-31T19:50:50Z,"I also had the tests fail when I used the built in docker-compose.yml here is my docker version:
```
Docker version 20.10.14, build a224086
```
I'm working off an ubuntu based OS","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6GySbD/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/38,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HDiT4,polaris,2265851128,38,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-08-02T17:35:05Z,2024-08-02T17:35:05Z,"Hit the same issue in MacOS. It has gone once I started the docker.

I am using `Docker version 27.0.3`, which is a pretty new one, the latest version is 27.1.  So I assume it fails on certain old versions. I can add a docker version suggestion in the readme.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HDiT4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/40,https://api.github.com/repos/apache/polaris/issues/40,polaris,2440678597,40,[FEATURE REQUEST] Add ErrorProne Plugin for Gradle,RussellSpitzer,413025,Russell Spitzer,,CLOSED,2024-07-31T18:32:07Z,2024-08-06T19:39:28Z,"- [ ] **Is your feature request related to a problem? Please describe.**
There are a lot of common Java bugs/mistakes that even experienced coders make and [ErrorProne](https://errorprone.info/) is a fun tool from Google which automatically detects some of these. Adding it to our build would help developers to clean up their code before merging.

**Describe the solution you'd like**
Within the Iceberg project we've been using the [Palantir basline gradle plugin ](https://github.com/palantir/gradle-baseline) which has worked well for me.
We have some other options like this [plugin](https://github.com/tbroyer/gradle-errorprone-plugin) recommended by the ErrorProne project


**Additional context**
From the Errorprone site:

> Testimonials
> Doug Lea, on learning of [a bug we discovered in ConcurrentHashMap](https://bugs.openjdk.java.net/browse/JDK-8176402):
> 
> ""Definitely embarrassing. I guess Iâ€™m back to liking Error Prone even though it sometimes annoys me :-)""
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/40/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/45,https://api.github.com/repos/apache/polaris/issues/45,polaris,2441179002,45,[DOCUMENTATION]: missing documentation on how to load conf-file from other locations,MonkeyCanCode,29619290,,,CLOSED,2024-08-01T00:29:09Z,2024-08-07T00:02:03Z,"With eclipse-link extension enabled, an end-user will be able to update `polaris-server.yml` to the following to use a persistent backend:
```
metaStoreManager:
    type: eclipse-link
    conf-file: xxx
    persistence-unit: xxx
```

However, this seems to be only able to read off files from META-INF dirs. As those dirs will get packed into the JAR, it is not ideal for prod deployment as well as source code check-in for version control. Is there any way for an end-user to set the conf-file location to other path instead (e.g. /etc/polaris/config/persistence.xml)?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/45/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/45,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HE745,polaris,2266218041,45,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-08-02T22:31:50Z,2024-08-02T22:31:50Z,@MonkeyCanCode can you confirm if https://github.com/polaris-catalog/polaris/pull/79 addresses this issue for you?,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HE745/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/45,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HFPW4,polaris,2266297784,45,NA,MonkeyCanCode,29619290,,,NA,2024-08-03T00:25:55Z,2024-08-03T00:25:55Z,"> @MonkeyCanCode can you confirm if #79 addresses this issue for you?

Hello,

This I tried locally couple days back after got the EclipseLink to work but later on this will fail on following line (u can try the same, it will failed on bootstrap as well):
```
emf = Persistence.createEntityManagerFactory(persistenceUnitName, properties);
```
This will raise error regarding unable to find persistence-unit (with FileStream, it does allows us to load file from other location but the above code will abort about not able to find persistenceUnitName. I am assuming this is specific to Jakarta. I am not very familiar with Java framework. Let me know if help is needed to test it again if you think this will work?
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HFPW4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/45,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HUqKZ,polaris,2270339737,45,NA,aihuaxu,26491691,Aihua Xu,aihuaxu@gmail.com,NA,2024-08-06T04:04:55Z,2024-08-06T04:04:55Z,@MonkeyCanCode There is a limitation that enforces the configuration to be in a jar. I made it to workaround in #88 to configure as as /tmp/conf.jar!/persistence.xml. Please take a look.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HUqKZ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/45,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HU7jh,polaris,2270410977,45,NA,MonkeyCanCode,29619290,,,NA,2024-08-06T05:25:44Z,2024-08-06T05:25:44Z,"> @MonkeyCanCode There is a limitation that enforces the configuration to be in a jar. I made it to workaround in #88 to configure as as /tmp/conf.jar!/persistence.xml. Please take a look.

Yes @aihuaxu, I took a look at that this morning. Seems to be a pretty odd limitation. However, it is usable for the time being. I can volume mount a config over then update the jar in pod to generate the new jar file with this external config. Thanks for the info. I will give that a try tomorrow.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HU7jh/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/48,https://api.github.com/repos/apache/polaris/issues/48,polaris,2441421535,48,[DOCS] Ensure Apache Trademarks are correctly attributed in documentation,annafil,7892219,Anna Filippova,,CLOSED,2024-08-01T04:15:58Z,2024-08-15T23:56:06Z,"This issue affects

- [x] the README.md file 
- [ ] docs/overview.md
- [ ] docs/quickstart.md
- [ ] docs/entities.md
- [ ] docs/access-control.md
- [ ] docs/img/overview.svg
- [ ] (possibly?) docs/img/example-workflow.svg
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/48/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/56,https://api.github.com/repos/apache/polaris/issues/56,polaris,2442864211,56,[BUG] Exceptions (thread race conditions) when trying to create many tables with JDBC extension,TomerHeber,12767692,Tomer Heber,,CLOSED,2024-08-01T16:18:54Z,2024-09-25T18:09:51Z,"**Describe the bug**
When running stress load, we are trying to create multiple tables.
We receive an exception from Polaris with 5xx error.

**Is this a possible security vulnerability?** 
yes

**To Reproduce**
Steps to reproduce the behavior:
1. Use the JDBC eclipse link connector.
2. Create many tables in parallel.

**Expected behavior**
No errors.


**System info (please complete the following information):**
 - OS: Docker image on K8s.
 - Polaris Catalog Version: main.

**Additional context**
Server error:

```
WARN  [2024-08-01 16:09:08,890 - 1656812] [pool-3-thread-41 - POST /api/catalog/v1/polaris/namespaces/pyspark_sample/tables] [] org.apache.iceberg.util.Tasks: Retrying task after failure: Encountered a null value when resolving configuration attributes. This is commonly caused by concurrent modifications to non-thread-safe types. Ensure you're synchronizing access to all non-thread-safe types.
java.lang.NullPointerException: Encountered a null value when resolving configuration attributes. This is commonly caused by concurrent modifications to non-thread-safe types. Ensure you're synchronizing access to all non-thread-safe types.
	at software.amazon.awssdk.utils.Validate.notNull(Validate.java:119)
	at software.amazon.awssdk.utils.AttributeMap$Builder.resolveValue(AttributeMap.java:396)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at software.amazon.awssdk.utils.AttributeMap$Builder.build(AttributeMap.java:362)
	at software.amazon.awssdk.core.client.config.SdkClientConfiguration$Builder.build(SdkClientConfiguration.java:232)
	at software.amazon.awssdk.core.client.builder.SdkDefaultClientBuilder.syncClientConfiguration(SdkDefaultClientBuilder.java:187)
	at software.amazon.awssdk.services.sts.DefaultStsClientBuilder.buildClient(DefaultStsClientBuilder.java:36)
	at software.amazon.awssdk.services.sts.DefaultStsClientBuilder.buildClient(DefaultStsClientBuilder.java:25)
	at software.amazon.awssdk.core.client.builder.SdkDefaultClientBuilder.build(SdkDefaultClientBuilder.java:164)
	at io.polaris.service.storage.PolarisStorageIntegrationProviderImpl.getStorageIntegrationForConfig(PolarisStorageIntegrationProviderImpl.java:61)
	at io.polaris.extension.persistence.impl.eclipselink.PolarisEclipseLinkMetaStoreSessionImpl.loadPolarisStorageIntegration(PolarisEclipseLinkMetaStoreSessionImpl.java:683)
	at io.polaris.core.persistence.PolarisMetaStoreManagerImpl.getSubscopedCredsForEntity(PolarisMetaStoreManagerImpl.java:2078)
	at io.polaris.core.storage.cache.StorageCredentialCache.lambda$getOrGenerateSubScopeCreds$0(StorageCredentialCache.java:130)
	at com.github.benmanes.caffeine.cache.BoundedLocalCache.lambda$doComputeIfAbsent$14(BoundedLocalCache.java:2688)
	at java.base/java.util.concurrent.ConcurrentHashMap.compute(ConcurrentHashMap.java:1955)
	at com.github.benmanes.caffeine.cache.BoundedLocalCache.doComputeIfAbsent(BoundedLocalCache.java:2686)
	at com.github.benmanes.caffeine.cache.BoundedLocalCache.computeIfAbsent(BoundedLocalCache.java:2669)
	at com.github.benmanes.caffeine.cache.LocalCache.computeIfAbsent(LocalCache.java:112)
	at com.github.benmanes.caffeine.cache.LocalManualCache.get(LocalManualCache.java:62)
	at io.polaris.core.storage.cache.StorageCredentialCache.getOrGenerateSubScopeCreds(StorageCredentialCache.java:148)
	at io.polaris.service.catalog.BasePolarisCatalog.refreshCredentials(BasePolarisCatalog.java:815)
	at io.polaris.service.catalog.BasePolarisCatalog.lambda$refreshIOWithCredentials$21(BasePolarisCatalog.java:1515)
	at java.base/java.util.Optional.map(Optional.java:260)
	at io.polaris.service.catalog.BasePolarisCatalog.refreshIOWithCredentials(BasePolarisCatalog.java:1513)
	at io.polaris.service.catalog.BasePolarisCatalog$BasePolarisTableOperations.lambda$doRefresh$0(BasePolarisCatalog.java:1148)
	at org.apache.iceberg.BaseMetastoreTableOperations.lambda$refreshFromMetadataLocation$1(BaseMetastoreTableOperations.java:208)
	at org.apache.iceberg.util.Tasks$Builder.runTaskWithRetry(Tasks.java:413)
	at org.apache.iceberg.util.Tasks$Builder.runSingleThreaded(Tasks.java:219)
	at org.apache.iceberg.util.Tasks$Builder.run(Tasks.java:203)
	at org.apache.iceberg.util.Tasks$Builder.run(Tasks.java:196)
	at org.apache.iceberg.BaseMetastoreTableOperations.refreshFromMetadataLocation(BaseMetastoreTableOperations.java:208)
	at io.polaris.service.catalog.BasePolarisCatalog$BasePolarisTableOperations.doRefresh(BasePolarisCatalog.java:1134)
	at org.apache.iceberg.BaseMetastoreTableOperations.refresh(BaseMetastoreTableOperations.java:97)
	at org.apache.iceberg.BaseMetastoreTableOperations.current(BaseMetastoreTableOperations.java:80)
	at org.apache.iceberg.BaseMetastoreCatalog$BaseMetastoreCatalogTableBuilder.create(BaseMetastoreCatalog.java:191)
	at org.apache.iceberg.rest.CatalogHandlers.createTable(CatalogHandlers.java:228)
	at io.polaris.service.catalog.PolarisCatalogHandlerWrapper.lambda$createTableDirect$12(PolarisCatalogHandlerWrapper.java:549)
	at io.polaris.service.catalog.PolarisCatalogHandlerWrapper.doCatalogOperation(PolarisCatalogHandlerWrapper.java:478)
	at io.polaris.service.catalog.PolarisCatalogHandlerWrapper.createTableDirect(PolarisCatalogHandlerWrapper.java:549)
	at io.polaris.service.catalog.IcebergCatalogAdapter.createTable(IcebergCatalogAdapter.java:197)
	at io.polaris.service.catalog.api.IcebergRestCatalogApi.createTable(IcebergRestCatalogApi.java:195)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:146)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:189)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:93)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:478)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:400)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:256)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:764)
	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1665)
	at io.dropwizard.servlets.ThreadNameFilter.doFilter(ThreadNameFilter.java:36)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
	at io.dropwizard.jersey.filter.AllowedMethodsFilter.handle(AllowedMethodsFilter.java:46)
	at io.dropwizard.jersey.filter.AllowedMethodsFilter.doFilter(AllowedMethodsFilter.java:40)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
	at io.polaris.service.tracing.TracingFilter.doFilter(TracingFilter.java:91)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
	at org.eclipse.jetty.servlets.CrossOriginFilter.handle(CrossOriginFilter.java:314)
	at org.eclipse.jetty.servlets.CrossOriginFilter.doFilter(CrossOriginFilter.java:267)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
	at io.polaris.service.PolarisApplication$ContextResolverFilter.doFilter(PolarisApplication.java:373)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:527)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:221)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1381)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:176)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:484)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:174)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1303)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:129)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
	at io.dropwizard.metrics.jetty11.InstrumentedHandler.handle(InstrumentedHandler.java:313)
	at io.dropwizard.jetty.RoutingHandler.handle(RoutingHandler.java:52)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:822)
	at io.dropwizard.jetty.ZipExceptionHandlingGzipHandler.handle(ZipExceptionHandlingGzipHandler.java:26)
	at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:46)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
	at org.eclipse.jetty.server.Server.handle(Server.java:563)
	at org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:501)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100)
	at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)
	at java.base/java.lang.Thread.run(Thread.java:1583)
```

Client error:
```
Traceback (most recent call last):
  File ""/usr/local/lib/python3.11/site-packages/pyiceberg/catalog/rest.py"", line 470, in create_table
    response.raise_for_status()
  File ""/usr/local/lib/python3.11/site-packages/requests/models.py"", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 500 Server Error: Server Error for url: http://polaris.yzheng.svc.cluster.local:8181/api/catalog/v1/polaris/namespaces/pyspark_sample/tables
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/56/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/56,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G6sLn,polaris,2263532263,56,NA,TomerHeber,12767692,Tomer Heber,,NA,2024-08-01T16:57:50Z,2024-08-01T16:57:50Z,"After a while Polaris will stop working.
Restarting the pods seem to help.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G6sLn/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/56,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HaWcS,polaris,2271831826,56,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-08-06T17:51:40Z,2024-08-06T17:51:40Z,Likely resolved by https://github.com/polaris-catalog/polaris/pull/82,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HaWcS/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/56,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HbZ7y,polaris,2272108274,56,NA,TomerHeber,12767692,Tomer Heber,,NA,2024-08-06T20:39:09Z,2024-08-06T20:39:09Z,"@eric-maynard - that's correct.
Let me know if I should close it. (You may also close it).","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HbZ7y/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/57,https://api.github.com/repos/apache/polaris/issues/57,polaris,2442904330,57,"[BUG] Calling oauth API to get bearer token, freezes intermittently",TomerHeber,12767692,Tomer Heber,,CLOSED,2024-08-01T16:41:05Z,2024-08-05T21:53:34Z,"**Describe the bug**
When calling the catalog oauth API, it often freezes.
We are using eclipse-link JDBC connector.

Retrying the request after a minute or two usually helps.

**Is this a possible security vulnerability?** 
no

**To Reproduce**
Steps to reproduce the behavior:
1. Connect polaris to a JDBC based server (We are using RDS - Postgres).
2. Request a token via Oauth API - scope is PRINCIPAL_ROLE:ALL.
3. Observe that it sometimes freezes/struck (API call remains hanging).

**Expected behavior**
No freeze.


**System info (please complete the following information):**
 - OS: Docker
 - Polaris Catalog Version: main

**Additional context**
This is what we observe in the Polaris logs:

```
WARN  [2024-08-01 16:35:21,931 - 3229853] [pool-3-thread-108 - POST /api/catalog/v1/oauth/tokens] [] o.g.j.servlet.WebComponent: A servlet request to the URI http://localhost:8181/api/catalog/v1/oauth/tokens contains form parameters in the request body but the request body has been consumed by the servlet or a servlet filter accessing the request parameters. Only resource methods using @FormParam will work as expected. Resource methods consuming the request body by other means will not work as expected. 
DEBUG [2024-08-01 16:35:21,947 - 3229869] [pool-3-thread-108 - POST /api/catalog/v1/oauth/tokens] [] i.p.s.c.a.IcebergRestOAuth2Api: Invoking OAuth2Api with params operation=""getToken""
DEBUG [2024-08-01 16:35:21,948 - 3229870] [pool-3-thread-108 - POST /api/catalog/v1/oauth/tokens] [] i.p.s.c.RealmEntityManagerFactory: Looking up PolarisEntityManager for realm default-realm 
DEBUG [2024-08-01 16:35:29,616 - 3237538] [pool-3-thread-109] [] i.p.s.c.DefaultContextResolver: Resolving RealmContext for method: POST, path: api/catalog/v1/oauth/tokens, queryParams: {grant_type=client_credentials, scope=PRINCIPAL_ROLE:ALL, client_secret=4a607ecef65e2d209a513764440a1eaa, client_id=e4fb285413a8ce8d}, headers: {Accept=application/json, Cache-Control=no-cache, User-Agent=PostmanRuntime/7.40.0, Connection=keep-alive, Postman-Token=9d73afa8-43f1-418c-bf8e-2101bcd0f05c, Host=localhost:8181, Accept-Encoding=gzip, deflate, br, Content-Length=130, Content-Type=application/x-www-form-urlencoded} 
WARN  [2024-08-01 16:35:29,617 - 3237539] [pool-3-thread-109] [] i.p.s.c.DefaultContextResolver: Failed to parse realm from headers; using default-realm 
DEBUG [2024-08-01 16:35:29,617 - 3237539] [pool-3-thread-109] [] i.p.s.c.DefaultContextResolver: Resolving CallContext realmContext=""default-realm"" method=""POST"" path=""api/catalog/v1/oauth/tokens"" queryParams=""{grant_type=client_credentials, scope=PRINCIPAL_ROLE:ALL, client_secret=4a607ecef65e2d209a513764440a1eaa, client_id=e4fb285413a8ce8d}"" headers=""{Accept=application/json, Cache-Control=no-cache, User-Agent=PostmanRuntime/7.40.0, Connection=keep-alive, Postman-Token=9d73afa8-43f1-418c-bf8e-2101bcd0f05c, Host=localhost:8181, Accept-Encoding=gzip, deflate, br, Content-Length=130, Content-Type=application/x-www-form-urlencoded}""
WARN  [2024-08-01 16:35:29,617 - 3237539] [pool-3-thread-109] [] i.p.s.c.DefaultContextResolver: Failed to parse principal from headers ({Accept=application/json, Cache-Control=no-cache, User-Agent=PostmanRuntime/7.40.0, Connection=keep-alive, Postman-Token=9d73afa8-43f1-418c-bf8e-2101bcd0f05c, Host=localhost:8181, Accept-Encoding=gzip, deflate, br, Content-Length=130, Content-Type=application/x-www-form-urlencoded}); using default-principal 
DEBUG [2024-08-01 16:35:29,617 - 3237539] [pool-3-thread-109] [] i.p.s.c.RealmEntityManagerFactory: Looking up PolarisEntityManager for realm default-realm 
DEBUG [2024-08-01 16:35:29,617 - 3237539] [pool-3-thread-109] [] i.p.e.p.i.e.PolarisEclipseLinkMetaStoreSessionImpl: Create EclipseLink Meta Store Session for default-realm 
INFO  [2024-08-01 16:35:29,617 - 3237539] [pool-3-thread-109] [] i.p.s.tracing.TracingFilter: Started span with parent spanId=""f6f246d5755084c0"" traceId=""5430250fd210cf274db2167da1fe05f4"" parentContext=""{}""
WARN  [2024-08-01 16:35:29,618 - 3237540] [pool-3-thread-109 - POST /api/catalog/v1/oauth/tokens] [] o.g.j.servlet.WebComponent: A servlet request to the URI http://localhost:8181/api/catalog/v1/oauth/tokens contains form parameters in the request body but the request body has been consumed by the servlet or a servlet filter accessing the request parameters. Only resource methods using @FormParam will work as expected. Resource methods consuming the request body by other means will not work as expected. 
DEBUG [2024-08-01 16:35:29,618 - 3237540] [pool-3-thread-109 - POST /api/catalog/v1/oauth/tokens] [] i.p.s.c.a.IcebergRestOAuth2Api: Invoking OAuth2Api with params operation=""getToken""
DEBUG [2024-08-01 16:35:29,618 - 3237540] [pool-3-thread-109 - POST /api/catalog/v1/oauth/tokens] [] i.p.s.c.RealmEntityManagerFactory: Looking up PolarisEntityManager for realm default-realm
```
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/57/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/57,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HTTfV,polaris,2269984725,57,NA,TomerHeber,12767692,Tomer Heber,,NA,2024-08-05T21:53:34Z,2024-08-05T21:53:34Z,This may be an internal issue on our side. I will close it for now.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HTTfV/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/58,https://api.github.com/repos/apache/polaris/issues/58,polaris,2442945874,58,[BUG] gradlew build and assemble fail,avriiil,68642378,Avril Aysha,,CLOSED,2024-08-01T17:03:35Z,2024-09-18T20:17:54Z,"**Describe the bug**
I'm following the quickstart. Both `./gradlew build` and `./gradlew assemble` fail with

```
Deprecated Gradle features were used in this build, making it incompatible with Gradle 9.0.
```

more context from traceback below. I'm running OpenJDK 22.0.1 on MacOS


**To Reproduce**
Steps to reproduce the behavior:
1. clone `polaris`
2. run `./gradlew build` or `... assemble`

**System info (please complete the following information):**
 - OS: [e.g. Windows] MacOS
 - Polaris Catalog Version [e.g. 0.3.0] 

**Additional context**
partial traceback from `./gradlew build`

```
> Task :polaris-service:test FAILED

FAILURE: Build failed with an exception.

* What went wrong:
Execution failed for task ':polaris-service:test'.
> There were failing tests. See the report at: file:///Users/rpelgrim/Documents/git/my-forks/polaris/polaris-service/build/reports/tests/test/index.html

* Try:
> Run with --scan to get full insights.

Deprecated Gradle features were used in this build, making it incompatible with Gradle 9.0.

You can use '--warning-mode all' to show the individual deprecation warnings and determine if they come from your own scripts or plugins.

For more on this, please refer to https://docs.gradle.org/8.9/userguide/command_line_interface.html#sec:command_line_warnings in the Gradle documentation.
```

Running with build scan yields:

<img width=""839"" alt=""image"" src=""https://github.com/user-attachments/assets/97371f91-ab09-483f-b918-f3d12c45eb60"">
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/58/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/58,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G65MH,polaris,2263585543,58,NA,snazy,957468,Robert Stupp,,NA,2024-08-01T17:25:46Z,2024-08-01T17:25:46Z,"Hey @avriiil how does the build fail?
I don't see a build _failure_?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G65MH/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/58,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G7XyF,polaris,2263710853,58,NA,avriiil,68642378,Avril Aysha,,NA,2024-08-01T18:31:58Z,2024-08-01T18:31:58Z,"@snazy -- `build` fails with

```
polaris â¯ ./gradlew build

> Task :polaris-service:test

PolarisSparkIntegrationTest > initializationError FAILED
    java.lang.IllegalStateException at PolarisSparkIntegrationTest.java:78

428 tests completed, 1 failed, 6 skipped

> Task :polaris-service:test FAILED

FAILURE: Build failed with an exception.

* What went wrong:
Execution failed for task ':polaris-service:test'.
> There were failing tests. See the report at: file:///Users/rpelgrim/Documents/git/my-forks/polaris/polaris-service/build/reports/tests/test/index.html

* Try:
> Run with --scan to get full insights.

Deprecated Gradle features were used in this build, making it incompatible with Gradle 9.0.

You can use '--warning-mode all' to show the individual deprecation warnings and determine if they come from your own scripts or plugins.

For more on this, please refer to https://docs.gradle.org/8.9/userguide/command_line_interface.html#sec:command_line_warnings in the Gradle documentation.

BUILD FAILED in 38s
39 actionable tasks: 7 executed, 32 up-to-date
```

I just tried `assemble` again and that does work, so it may be a failing test. But I'm a total `gradle` noob so not sure ðŸ˜… ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G7XyF/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/58,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G7c8i,polaris,2263732002,58,NA,avriiil,68642378,Avril Aysha,,NA,2024-08-01T18:43:53Z,2024-08-01T18:43:53Z,"tried `./gradlew runApp` after the `assemble` but it looks like it's hanging on spinning up the app. or is this expected behaviour?

<img width=""909"" alt=""image"" src=""https://github.com/user-attachments/assets/73d49c8d-da70-45a3-a090-d5afc87b45a2"">
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G7c8i/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/58,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HDmvE,polaris,2265869252,58,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-08-02T17:47:55Z,2024-08-02T17:47:55Z,@avriiil That looks like it's running. Are you able to interact with the service using the CLI?,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HDmvE/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/58,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6I1dDO,polaris,2295713998,58,NA,findepi,144328,Piotr Findeisen,,NA,2024-08-19T05:44:34Z,2024-08-19T05:44:34Z,"The build works for me on Java 22, but the log suggests i have to have Java 21 installed as well, as it is being picked up e.g. for Kotlin. 

```
polaris main$ jenv shell 22
```

```
polaris main$ ./gradlew --version

------------------------------------------------------------
Gradle 8.9
------------------------------------------------------------

Build time:    2024-07-11 14:37:41 UTC
Revision:      d536ef36a19186ccc596d8817123e5445f30fef8

Kotlin:        1.9.23
Groovy:        3.0.21
Ant:           Apache Ant(TM) version 1.10.13 compiled on January 4 2023
Launcher JVM:  22.0.2 (Azul Systems, Inc. 22.0.2+9)
Daemon JVM:    /Library/Java/JavaVirtualMachines/zulu-22.jdk/Contents/Home (no JDK specified, using current Java home)
OS:            Mac OS X 14.5 aarch64
```

```
polaris main$ ./gradlew build
Starting a Gradle Daemon, 1 incompatible Daemon could not be reused, use --status for details
Configuration on demand is an incubating feature.

> Configure project :
Kotlin does not yet support 22 JDK target, falling back to Kotlin JVM_21 JVM target

> Task :polaris-build-logic:compileKotlin
Kotlin does not yet support 22 JDK target, falling back to Kotlin JVM_21 JVM target
w: Inconsistent JVM-target compatibility detected for tasks 'compileJava' (22) and 'compileKotlin' (21).
This will become an error in Gradle 8.0.
Consider using JVM Toolchain: https://kotl.in/gradle/jvm/toolchain
Learn more about JVM-target validation: https://kotl.in/gradle/jvm/target-validation

OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended
OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended
OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended
OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended
OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended
OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended
INFO  [2024-08-19 07:40:46,783] org.apache.spark.util.ShutdownHookManager: Shutdown hook called
INFO  [2024-08-19 07:40:46,784] org.apache.spark.util.ShutdownHookManager: Deleting directory /private/var/folders/6y/4x3jpqj54r3c3316sdxn_p400000gn/T/spark-24f9422a-3264-4593-b459-1cdbd69d7b44

Deprecated Gradle features were used in this build, making it incompatible with Gradle 9.0.

You can use '--warning-mode all' to show the individual deprecation warnings and determine if they come from your own scripts or plugins.

For more on this, please refer to https://docs.gradle.org/8.9/userguide/command_line_interface.html#sec:command_line_warnings in the Gradle documentation.

BUILD SUCCESSFUL in 1m 34s
62 actionable tasks: 27 executed, 35 up-to-date
```
```
polaris main$ ./gradlew assemble
Configuration on demand is an incubating feature.

> Task :polaris-build-logic:compileKotlin UP-TO-DATE
Kotlin does not yet support 22 JDK target, falling back to Kotlin JVM_21 JVM target

> Configure project :
Kotlin does not yet support 22 JDK target, falling back to Kotlin JVM_21 JVM target

Deprecated Gradle features were used in this build, making it incompatible with Gradle 9.0.

You can use '--warning-mode all' to show the individual deprecation warnings and determine if they come from your own scripts or plugins.

For more on this, please refer to https://docs.gradle.org/8.9/userguide/command_line_interface.html#sec:command_line_warnings in the Gradle documentation.

BUILD SUCCESSFUL in 860ms
28 actionable tasks: 1 executed, 27 up-to-date
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6I1dDO/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/58,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KtBcl,polaris,2327058213,58,NA,collado-mike,40346148,Michael Collado,,NA,2024-09-03T17:24:19Z,2024-09-03T17:24:19Z,"The original build likely failed because you didn't have Docker running. That particular test requires Docker, but you wouldn't see that without enabling `--info` and `--stacktrace`","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KtBcl/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/58,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6MoINB,polaris,2359329601,58,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-09-18T20:17:53Z,2024-09-18T20:17:53Z,"This issue doesn't seem relevant anymore, closed it.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6MoINB/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/60,https://api.github.com/repos/apache/polaris/issues/60,polaris,2443040646,60,[FEATURE REQUEST] Support for S3 compatible services,guitcastro,1149991,Guilherme Torres Castro,,CLOSED,2024-08-01T17:52:15Z,2024-08-01T18:04:35Z,"**Is your feature request related to a problem? Please describe.**
Support for S3 compatible services like min.io, cloudflare r2 and etc. 

**Describe the solution you'd like**
Allow other services compatible with S3 instead of just AWS. 

**Describe alternatives you've considered**
Only options are use one of the supported storage.

**Additional context**

You might want to try do add a generic implementation to handle all S3 compatibles generic services, but will not be possible to have specific credentials per principal. 

Or try to keep different implementations, per example use cloudflare R2 api token to generate new access_key and secrets for each principal with a limited scoped.   

I am using cloudflare, thus I have interest in implement this feature. Just wanna know if do you have plans to create a generic S3 support or I should focus on a specific implementation (R2) to allow principal credentials revocation.   
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/60/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/60,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G7F42,polaris,2263637558,60,NA,snazy,957468,Robert Stupp,,NA,2024-08-01T17:53:55Z,2024-08-01T17:53:55Z,Isn't this a duplicate of #32?,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G7F42/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/60,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G7LGa,polaris,2263658906,60,NA,guitcastro,1149991,Guilherme Torres Castro,,NA,2024-08-01T18:04:35Z,2024-08-01T18:04:35Z,@snazy Yes it is. Sorry about that. ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G7LGa/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/62,https://api.github.com/repos/apache/polaris/issues/62,polaris,2443079477,62,[BUG] Link on site appears broken,snazy,957468,Robert Stupp,,CLOSED,2024-08-01T18:11:00Z,2024-08-08T18:54:41Z,"On the ""Overview"" page, I see this
![image](https://github.com/user-attachments/assets/2167d04e-9a39-47a8-b9af-0122b2c4a097)
but the markdown in `overview.md` is fine: `For example, to install Java 21 via [homebrew](https://brew.sh/) and `","{""url"": ""https://api.github.com/repos/apache/polaris/issues/62/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/62,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G9AfF,polaris,2264139717,62,NA,annafil,7892219,Anna Filippova,,NA,2024-08-01T22:41:07Z,2024-08-01T22:41:07Z,"Docs need to be regenerated using redocly anytime we make a change to the markdown. Working on getting that automated, but in the meantime these instructions should help anyone who wants to start a PR to close this issue :) https://github.com/polaris-catalog/polaris/blob/main/README.md#api-docs

Going to mark this as a good first issue to encourage folks to contribute ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G9AfF/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/62,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G_PLo,polaris,2264724200,62,NA,snazy,957468,Robert Stupp,,NA,2024-08-02T07:12:40Z,2024-08-02T07:12:40Z,"I suspect it's a bug in the redocly tool, because it looks the same when the site's regenerated :(","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6G_PLo/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/62,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HDH_t,polaris,2265743341,62,NA,annafil,7892219,Anna Filippova,,NA,2024-08-02T16:23:29Z,2024-08-02T16:23:29Z,Oh interesting!! Let me take a look then ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HDH_t/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/62,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Hbze0,polaris,2272212916,62,NA,suyashkumar2409,10911412,Suyash Kumar,suyashkumar2409@gmail.com,NA,2024-08-06T21:51:12Z,2024-08-06T21:51:12Z,"I am unable to reproduce the issue. Link doesn't seem to be broken for me here. https://polaris.io/index.html#section/Quick-Start/Prerequisites

Is this still an issue?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Hbze0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/62,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HsAsJ,polaris,2276461321,62,NA,collado-mike,40346148,Michael Collado,,NA,2024-08-08T18:54:40Z,2024-08-08T18:54:40Z,Looks like this is fixed,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HsAsJ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/69,https://api.github.com/repos/apache/polaris/issues/69,polaris,2443943818,69,[FEATURE REQUEST] Add option to use environment variables for ADLS Subscoped credentials,cgpoh,11516015,CG,,OPEN,2024-08-02T03:46:46Z,2024-08-12T03:53:27Z,"**Is your feature request related to a problem? Please describe.**
My organization does not allow getting user delegation key in Azure and the only option for us to authenticate with Azure is to use service principal. When my spark job tries to write to Azure, I will get the following exception at Polaris server:
```
c.a.s.f.d.DataLakeServiceClient: If you are using a StorageSharedKeyCredential, and the server returned an error message that says 'Signature did not match', you can compare the string to sign with the one generated by the SDK. To log the string to sign, pass in the context key value pair 'Azure-Storage-Log-String-To-Sign': true to the appropriate method call. If you are using a SAS token, and the server returned an error message that says 'Signature did not match', you can compare the string to sign with the one generated by the SDK. To log the string to sign, pass in the context key value pair 'Azure-Storage-Log-String-To-Sign': true to the appropriate generateSas method call. Please remember to disable 'Azure-Storage-Log-String-To-Sign' before going to production as this string can potentially contain PII.""
```
```xml
<?xml version=""1.0"" encoding=""utf-8""?><Error><Code>AuthorizationPermissionMismatch</Code><Message>This request is not authorized to perform this operation using this permission.</Message></Error>""
```

**Describe the solution you'd like**
Since `ADLSFileIO` fall back to use `DefaultAzureCredentialBuilder` when there are no `SAS token` or `Storage Shared Key credential`, we can have a default catalog option to use environment as authentication type e.g.:
```json
{
    ""name"": ""test"",
    ""type"": ""INTERNAL"",
    ""properties"": {
        ""default-base-location"": ""abfss://container@storageaccount.dfs.core.windows.net/test/""
    },
    ""storageConfigInfo"": {
        ""tenantId"": ""tenant-id"",
        ""storageType"": ""AZURE"",
        ""allowedLocations"": [
            ""abfss://container@storageaccount.dfs.core.windows.net/test/""
        ],
        ""authType"": ""APPLICATION_DEFAULT""
    }
}
```
so that any query engine can abstract away the credential and the main credential still being govern by Polaris Catalog for Azure.
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/69/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/69,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6IFN_2,polaris,2283069430,69,NA,dennishuo,7410123,Dennis Huo,,NA,2024-08-12T03:53:26Z,2024-08-12T03:53:26Z,"Thanks for bringing this up @cgpoh ! There are a few considerations worth discussing and soliciting some input from additional folks to identify the best way forward:

1. Would there ever be scenarios where we want a single deployment to use the credential-vending SAS_TOKEN pattern for some catalogs/storageConfigs, while short-circuiting it to use ""application defaults"" for other catalogs, or would the choice of whether to use credential-vending semantics typically be a server-wide setting?
2. Is it better to convey the concept of ""fallthrough to application defaults for credentials"" with a single common syntax across all cloud providers or explicitly have such an APPLICATION_DEFAULT type separately defined for each cloud provider's storage configuration?
3. How should the server-level configuration expose the controls for whether to allow setting certain AuthTypes at a per-catalog level at all? For example, if the Polaris server is running in a more sensitive/privileged context, it may need to be configured to block the ability for individual catalogs to choose APPLICATION_DEFAULT credentials
4. Should the ""fallthrough"" behavior go further to allow propagating static credential config settings in the catalog `properties` map directly into the initialization of a FileIO? Should the behavior just skip going through the whole StorageConfigurationInfo/StorageIntegration stack entirely, including skipping allowed-location validations?
5. What are the semantics for returned vended credentials to the processing engine making the call? Should APPLICATION_DEFAULT only mean the Polaris itself uses local application defaults for interacting with files while ignoring any `X-Iceberg-Access-Delegation` settings and letting the caller engine fend for itself, or should the server be able to translate something that comes from APPLICATION_DEFAULT credentials into returned `config` settings that the remote engine can then use to access files?

At a high level we at least need to have a strict separation of effective privileges between the personas who can configure and run the Polaris server itself and those who can call `createCatalog`. In a mutual-trust setting, it makes sense to have relaxed constraints on the server-level configuration, but it needs to be possible to run the server in a secure mode as well where catalog creators are in a different realm of trust than the admins of the server.

One possibility that may require fewer changes to the management API and persistence model itself would be to have some server-level configuration settings that basically just short-circuit the storage validation/subscoping logic in `BasePolarisCatalog::refreshCredentials` and allow the FileIO initialization to fallback to default behaviors in how it looks for credentials from the environment.

@jbonofre @snazy @flyrain @RussellSpitzer @collado-mike ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6IFN_2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/76,https://api.github.com/repos/apache/polaris/issues/76,polaris,2445105308,76,[BUG] polaris-core has hard compile-time dependencies on JDK 21,adutra,463876,Alexandre Dutra,,CLOSED,2024-08-02T14:38:42Z,2024-08-07T18:35:21Z,"**Describe the bug**

While Polaris build requires Java 21+, the polaris-core module is built with source and target level = 11. 

I suppose that this has been decided in order to make it possible to include polaris-core in applications running with Java 11.

However, the code in main sources makes frequent usage of JDK methods that were introduced after Java 11, such as:

* `Stream.toList()` (Java 16)
* `List.getFirst()` and `List.getLast()` (Java 21)

This makes the compiled artifact effectively unusable, if included in an application running with Java 11.

**Is this a possible security vulnerability?** 
- [ ] yes -- if yes, stop here and contact security@polaris.io instead
- [x] no 

**Expected behavior**

The polaris-core module should not make use of any JDK API that was introduced after Java 11. Ideally, there should be a build task verifying this.

Alternatively, we should consider lifting the restriction of level 11 in polaris-core.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/76/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/76,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HCjoV,polaris,2265594389,76,NA,adutra,463876,Alexandre Dutra,,NA,2024-08-02T14:59:26Z,2024-08-02T14:59:26Z,There is also `List.reversed()` (Java 21).,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HCjoV/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/76,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HaVfc,polaris,2271827932,76,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-08-06T17:49:24Z,2024-08-06T17:49:24Z,@snazy Did we decide to just raise the version to 21? Or how do we want to handle this?,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HaVfc/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/76,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HaWaw,polaris,2271831728,76,NA,snazy,957468,Robert Stupp,,NA,2024-08-06T17:51:37Z,2024-08-06T17:51:37Z,"We haven't decided anything yet. Naively, I'd suggest 21 and opt for 11 for code that can be pulled in by clients.
I'll open a discussion.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HaWaw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/76,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HaYuw,polaris,2271841200,76,NA,snazy,957468,Robert Stupp,,NA,2024-08-06T17:57:09Z,2024-08-06T17:57:09Z,#100 ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HaYuw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/85,https://api.github.com/repos/apache/polaris/issues/85,polaris,2446313668,85,[FEATURE REQUEST] Add basic HDFS storage option for catalogs,rdsarvar,10821555,Raman Sarvaria,,OPEN,2024-08-03T11:43:28Z,2025-01-21T22:26:25Z,"**Is your feature request related to a problem? Please describe.**
Currently it appears that the storage options are geared towards cloud providers. To support companies running on premise I would like to request HDFS support.

**Describe the solution you'd like**
Catalog R/W support HDFS as a storage option.

For the first implementation we would like something basic:

- The service is able to R/W against a HDFS cluster without authentication/authorization required.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/85/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/85,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HT4jl,polaris,2270136549,85,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-08-06T00:18:32Z,2024-08-06T00:18:32Z,"We can add HDFS support, but handling credentials might be difficult. @sfc-gh-schen, can you provide more insight? I think it may not be possible for credential vending.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HT4jl/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/85,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6IM_md,polaris,2285107613,85,NA,rdsarvar,10821555,Raman Sarvaria,,NA,2024-08-13T00:12:04Z,2024-08-13T00:12:04Z,"Would permissive HDFS be a simpler first ask with potential evolutions in the future to support credentials? Aka start off assuming that the HDFS cluster is open (no Kerberos, etc), running on-premise protected by networking, and then consider a proper strategy in the future?

Sorry if I'm off the mark on what you meant by your last comment but I assumed it's relating to authn/authz against HDFS (and not mapping to an internal strategy in Polaris).","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6IM_md/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/85,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6INB1Y,polaris,2285116760,85,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-08-13T00:20:14Z,2024-08-13T00:20:14Z,"Yup, it's reasonable to start with non-authentication and non-authorization for HDFS.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6INB1Y/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/85,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6IzGmz,polaris,2295097779,85,NA,rdsarvar,10821555,Raman Sarvaria,,NA,2024-08-18T03:37:11Z,2024-08-18T03:37:11Z,"I don't mind trying my hand at this for the simple case and provide a baseline for people to extend in the future.

I think in order for this to work, due to the DFS is created inside of Iceberg core with the Hadoop configuration object we initialize, we'll need to rely on the `HADOOP_USER_NAME` environment variable (which will mean all DFS interaction would be under the same username). Otherwise it'll default access to be the user running the service.

I can see if I find time one of these days to throw something together in a PR (as an non-tested PoC) just to get feedback on if it's something we want to move forward","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6IzGmz/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/85,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JoQ0i,polaris,2309033250,85,NA,rdsarvar,10821555,Raman Sarvaria,,NA,2024-08-25T23:13:02Z,2024-08-25T23:13:02Z,"@flyrain QQ about the repo which I noticed starting to write the changes required by this MR:

1. Do the regtests have Open API Python templates that aren't commit into the repo? When I generate the files with the provided commands in the README it results in generated Python files without the license header and in some cases it breaks the functionality. An example diff of `regtests/client/python/polaris/management/models/aws_storage_config_info.py`:
```
         _obj = cls.model_validate({
             ""storageType"": obj.get(""storageType""),
-            ""allowedLocations"": obj.get(""allowedLocations""),
-            ""roleArn"": obj.get(""roleArn"")
+            ""allowedLocations"": obj.get(""allowedLocations"")
         })
```

2. I was thinking about how to add integration / e2e tests and noticed that there isn't really any integration tests (outside of polaris-service/src/test/java/io/polaris/service/catalog/PolarisSparkIntegrationTest.java), do we rely on the e2e tests for testing against the storage providers? -- Curious to what your preference would be for this repo","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JoQ0i/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/85,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Kuqbw,polaris,2327488240,85,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-09-03T21:39:44Z,2024-09-03T21:39:44Z,"cc @dennishuo @collado-mike @eric-maynard for the first question.

for 2, we cannot really do that without a sponsor of cloud environments. We have discussed using minIO to simulate it. But for HDFS, it should be OK to add integration tests. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Kuqbw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/85,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bUkbi,polaris,2605860578,85,NA,idantepper,65827206,Idan Tepper,,NA,2025-01-21T22:22:25Z,2025-01-21T22:22:25Z,hi is there someone working on this issue,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bUkbi/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/85,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bUl2J,polaris,2605866377,85,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2025-01-21T22:26:23Z,2025-01-21T22:26:23Z,"@idantepper , I don't think anybody is working on it. Feel free to take it.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bUl2J/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/92,https://api.github.com/repos/apache/polaris/issues/92,polaris,2449030796,92,"[BUG] regtests set the wrong HTTP header, `Accept` not `Accepts",kevinjqliu,9057843,Kevin Liu,,CLOSED,2024-08-05T16:59:11Z,2024-08-05T18:38:31Z,"**Describe the bug**
Scripts in `regtests` running `curl` command specifies header as `Accepts`, whereas the proper header should be `Accept` 
https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept


**Is this a possible security vulnerability?** 
- [ ] yes -- if yes, stop here and contact security@polaris.io instead
- [x] no 

**To Reproduce**
N/A

**Expected behavior**
N/A

**Screenshots**
N/A

**System info (please complete the following information):**
N/A

**Additional context**
Add any other context about the problem here.
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/92/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/96,https://api.github.com/repos/apache/polaris/issues/96,polaris,2449888775,96,pyiceberg always return false for catalog.table_exists when using Snowflake managed Polaris service,djouallah,12554469,Mimoune,,CLOSED,2024-08-06T04:03:37Z,2024-09-25T18:09:39Z,"using polaris managed offering and pyiceberg 0.7, catalog.table_exists will return false even if the table exist

<img width=""527"" alt=""image"" src=""https://github.com/user-attachments/assets/265ce6d7-2c05-4488-904e-9f93da88c9e5"">
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/96/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/96,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HaRy0,polaris,2271812788,96,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-08-06T17:40:57Z,2024-08-06T17:40:57Z,"Hi @djouallah, this project is for OSS Polaris and not any vendor-managed deployment of Polaris. Having said that, I'm interested in taking a look -- can you share your code? I was not able to reproduce this.

I created a config file `pyiceberg.json`:
```
{
  ""type"": ""rest"",
  ""base_uri"": ""http://localhost:8181/api/catalog"",
  ""warehouse"": ""issue_96_catalog"",
  ""credential"": ""XXXX:YYYY"",
  ""scope"": ""PRINCIPAL_ROLE:ALL""
}
```

I used the CLI to create the catalog, and used another engine to create a namespace and table in the catalog.

I then ran this Python script using PyIceberg:
```
from pyiceberg.catalog.rest import RestCatalog
import json

with open('pyiceberg.json', 'r') as f:
    config = json.load(f)

catalog = RestCatalog(
    name='issue_96_catalog',
    uri=config['base_uri'],
    warehouse=config['warehouse'],
    credential=config['credential'],
    scope=config['scope']
)

print(catalog.list_namespaces())
print(catalog.list_tables('ns'))
print(catalog.table_exists('ns.t1'))

```

I saw that the `table_exists` call behaved as expected:
```
$ python -m test
[('ns',)]
[('ns', 't1')]
True
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HaRy0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/96,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HbwJw,polaris,2272199280,96,NA,djouallah,12554469,Mimoune,,NA,2024-08-06T21:40:41Z,2024-08-06T21:40:41Z,"all good, I will open a ticket i guess. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HbwJw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/96,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Hb8I8,polaris,2272248380,96,NA,kevinjqliu,9057843,Kevin Liu,,NA,2024-08-06T22:21:37Z,2024-08-06T22:21:37Z,"Chiming into this, PyIceberg currently has an issue when parsing the table identifier with the ""catalog name"".

How did you initialize the `catalog` object in PyIceberg? The catalog name must match the one in the config. 
For example, the config value (`""warehouse"": ""issue_96_catalog""`) in the config file must matches the `RestCatalog`'s parameter (`name='issue_96_catalog'`).
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Hb8I8/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/96,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HcE5q,polaris,2272284266,96,NA,djouallah,12554469,Mimoune,,NA,2024-08-06T22:43:47Z,2024-08-06T22:43:47Z,"
<img width=""365"" alt=""polaris"" src=""https://github.com/user-attachments/assets/7b59e67d-f295-459e-a98e-9ab12a88b504"">

    




```
case 'polaris':
     catalog = load_catalog(
          'default',
           uri='https://xxxxxxxxxxxxxxxxxxxxxxxxxxxxx.snowflakecomputing.com/polaris/api/catalog',
           warehouse='s3',
           scope = 'PRINCIPAL_ROLE:no' ,
           credential= userdata.get(""polaris_key"")
        )
```





","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HcE5q/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/96,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HcF-I,polaris,2272288648,96,NA,kevinjqliu,9057843,Kevin Liu,,NA,2024-08-06T22:48:35Z,2024-08-06T22:48:35Z,"In PyIceberg, the catalog is named `default`. I'm not familiar with the Polaris UI, but I assume it's named `s3`.

If you rename the PyIceberg catalog to `s3` and retry the code above, it might work. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HcF-I/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/96,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HcG52,polaris,2272292470,96,NA,djouallah,12554469,Mimoune,,NA,2024-08-06T22:52:42Z,2024-08-06T22:52:42Z,no luck :(,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HcG52/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/96,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HcIee,polaris,2272298910,96,NA,kevinjqliu,9057843,Kevin Liu,,NA,2024-08-06T22:59:07Z,2024-08-06T22:59:07Z,"Weird, I'll try to repro","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HcIee/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/96,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HczQj,polaris,2272474147,96,NA,TomerHeber,12767692,Tomer Heber,,NA,2024-08-07T01:58:38Z,2024-08-07T01:58:38Z,"To check table existence pyiceberg calls ""HEAD"" via the API.

In OSS Polaris it currently works as expected.

If I had to guess, the managed Polaris may not be listening to HEAD requests and therefore might be returning 404 which translates to False.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HczQj/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/96,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Hc4p9,polaris,2272496253,96,NA,kevinjqliu,9057843,Kevin Liu,,NA,2024-08-07T02:25:57Z,2024-08-07T02:25:57Z,"@TomerHeber good catch! `table_exists` returns True only for 200 and 204

https://github.com/apache/iceberg-python/blob/8432b111aaa339b0fee2ac68345232c6f3b1d36b/pyiceberg/catalog/rest.py#L794-L808
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Hc4p9/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/96,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Hc-iI,polaris,2272520328,96,NA,kevinjqliu,9057843,Kevin Liu,,NA,2024-08-07T02:55:59Z,2024-08-07T02:55:59Z,"@eric-maynard which credentials are you using?

I tried to reproduce with a local docker deployment of Polaris
```
catalog = RestCatalog(
    name='polaris',
    uri='http://localhost:8181/api/catalog',
    warehouse='polaris',
    credential='e9b1a9c3ceeafcfc:885e8a756af4ebe383774877ea774b34',
    scope='PRINCIPAL_ROLE:ALL',
)
```
the credentials are from the logs
```
2024-08-05 11:39:38 realm: default-realm root principal credentials: e9b1a9c3ceeafcfc:885e8a756af4ebe383774877ea774b34
```


I cannot create a table due to permission issues
```
ForbiddenError: ForbiddenException: Principal 'root' with activated PrincipalRoles '[]' and activated ids '[2, 4]' is not authorized for op CREATE_TABLE_DIRECT_WITH_WRITE_DELEGATION
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Hc-iI/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/96,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HdOl4,polaris,2272586104,96,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-08-07T04:18:11Z,2024-08-07T04:18:11Z,"@kevinjqliu it shouldn't matter so long as the credentials you're using have `CREATE_TABLE_DIRECT_WITH_WRITE_DELEGATION` for the table you're trying to create. You should be able to use the root credentials or those of any principal with the appropriate grants.

Using those same credentials, can you create a table with Spark?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HdOl4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/96,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HiO30,polaris,2273897972,96,NA,kevinjqliu,9057843,Kevin Liu,,NA,2024-08-07T16:49:07Z,2024-08-07T16:49:07Z,"With the root credentials, I was able to create tables using Pyspark, but not with PyIceberg

# Repro
### Run a new Polaris instance in docker
`docker-compose -f docker-compose.yml up`

### Create a new catalog in Polaris
```
PRINCIPAL_TOKEN=""principal:root;realm:default-realm""

# Use local filesystem by default
curl -i -X POST -H ""Authorization: Bearer $PRINCIPAL_TOKEN"" -H 'Accept: application/json' -H 'Content-Type: application/json' \
  http://localhost:8181/api/management/v1/catalogs \
  -d '{
        ""catalog"": {
          ""name"": ""polaris"",
          ""type"": ""INTERNAL"",
          ""readOnly"": false,
          ""properties"": {
            ""default-base-location"": ""file:///tmp/polaris/""
          },
          ""storageConfigInfo"": {
            ""storageType"": ""FILE"",
            ""allowedLocations"": [
              ""file:///tmp""
            ]
          }
        }
      }'
```
### Get the root credentials in Polaris log

### Edit the `ROOT_CREDENTIAL` variable inside jupyter notebook

### Run jupyter notebook
[Polaris <> PyIceberg.ipynb](https://gist.github.com/kevinjqliu/14ef9508fdded5bf4a9e62f539994b5e#file-polaris-pyiceberg-ipynb)
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HiO30/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/96,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HtkHZ,polaris,2276868569,96,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-08-08T23:16:46Z,2024-08-08T23:16:46Z,"Hi @kevinjqliu, I was able to reproduce this -- I can't create tables with PyIceberg using root credentials. The error I see is:
```
pyiceberg.exceptions.ForbiddenError: ForbiddenException: Principal 'root' with activated PrincipalRoles '[]' and activated ids '[63449, 63549]' is not authorized for op CREATE_TABLE_DIRECT_WITH_WRITE_DELEGATION
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HtkHZ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/96,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Hty4J,polaris,2276929033,96,NA,sfc-gh-dhuo,99215334,Dennis Huo,dennis.huo@snowflake.com,NA,2024-08-09T00:14:59Z,2024-08-09T00:14:59Z,"It's a bit unintuitive, but due to the intentional segmentation of ""metadata management"" and ""content management"", the default `ROOT` actually does *not* automatically have `TABLE_WRITE_DATA` or `TABLE_READ_DATA` privileges, which are required for `xIcebergAccessDelegation`. My guess here when Spark is able to `createTable` but not PyIceberg is that PyIceberg got configured to send the `X-Iceberg-Access-Delegation` header which is interpreted as requesting credential-vending, which requires `TABLE_WRITE_DATA`, while perhaps PySpark wasn't configured with `spark.sql.catalog.polaris.header.X-Iceberg-Access-Delegation=true`.

Some of the distinction between CONTENT and METADATA is called out here: https://polaris.io/#tag/Access-Control/Access-control-privileges

The initialization where the `catalog_admin` default role per-catalog is assigned privileges is here: https://github.com/polaris-catalog/polaris/blob/32eebae59fe953057a6d60d4eeaf4c1bb7e9c0b9/polaris-core/src/main/java/io/polaris/core/persistence/PolarisMetaStoreManagerImpl.java#L588 -- it only gets assigned `CATALOG_MANAGE_ACCESS` and `CATALOG_MANAGE_METADATA` without `CATALOG_MANAGE_CONTENT`.

This can be solved by either omitting the `X-Iceberg-Access-Delegation` header when creating the table or granting the `catalog_admin` (which is granted to the default `root` via the `service_admin` PrincipalRole by default) with the privilege `CATALOG_MANAGE_CONTENT`.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Hty4J/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/96,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HuPjY,polaris,2277046488,96,NA,kevinjqliu,9057843,Kevin Liu,,NA,2024-08-09T02:51:28Z,2024-08-09T02:51:28Z,"Thanks for taking a look at this. 

@sfc-gh-dhuo I think your theory is correct. PyIceberg's REST client sets the `X-Iceberg-Access-Delegation` header by default 
https://github.com/apache/iceberg-python/blob/eca98707f30bdaf1ffd19f039058cc7e18c5f9cb/pyiceberg/catalog/rest.py#L535

Everything works after I comment that out","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HuPjY/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/96,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HuPyg,polaris,2277047456,96,NA,kevinjqliu,9057843,Kevin Liu,,NA,2024-08-09T02:52:44Z,2024-08-09T02:52:44Z,Seems to me that PyIceberg should set the `X-Iceberg-Access-Delegation` header only when accessing the underlying table's data. ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HuPyg/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/96,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HuSoC,polaris,2277059074,96,NA,kevinjqliu,9057843,Kevin Liu,,NA,2024-08-09T03:08:14Z,2024-08-09T03:08:14Z,"Reading the spec for `X-Iceberg-Access-Delegation`
https://github.com/apache/iceberg/blob/main/open-api/rest-catalog-open-api.yaml#L1488-L1512

It sounds like clients are free to send that header on requests, as a way to signal the server of its capabilities.

> PyIceberg got configured to send the X-Iceberg-Access-Delegation header which is interpreted as requesting credential-vending, which requires TABLE_WRITE_DATA

I'm interpreting the header as a signal for credential vending or remote signing capabilities. Perhaps the Polaris permission model is making the assumption that setting the header means requesting for table access. 


","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HuSoC/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/96,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HuWcA,polaris,2277074688,96,NA,kevinjqliu,9057843,Kevin Liu,,NA,2024-08-09T03:30:33Z,2024-08-09T03:30:33Z,"I guess the ultimate question is, what permission is required to run a `create_table` statement? 
`create_table` operation does two things; it writes an entry to the metadata store and also writes a metadata JSON file to the metadata location","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HuWcA/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/96,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HvDsw,polaris,2277260080,96,NA,dennishuo,7410123,Dennis Huo,,NA,2024-08-09T06:48:21Z,2024-08-09T06:48:21Z,"@kevinjqliu Good question! This is an area that's probably worth adding more explicit documentation for. The ground truth for privilege requirements can be found in [PolarisAuthorizableOperation.java](https://github.com/polaris-catalog/polaris/blob/32eebae59fe953057a6d60d4eeaf4c1bb7e9c0b9/polaris-core/src/main/java/io/polaris/core/auth/PolarisAuthorizableOperation.java#L92):

      CREATE_TABLE_DIRECT(TABLE_CREATE),
      CREATE_TABLE_DIRECT_WITH_WRITE_DELEGATION(EnumSet.of(TABLE_CREATE, TABLE_WRITE_DATA)),

And the relationship between direct privileges vs inheritance through ""super-privileges"" can be found in [PolarisAuthorizer.java](https://github.com/polaris-catalog/polaris/blob/32eebae59fe953057a6d60d4eeaf4c1bb7e9c0b9/polaris-core/src/main/java/io/polaris/core/auth/PolarisAuthorizer.java#L137):

    SUPER_PRIVILEGES.putAll(
        TABLE_CREATE,
        List.of(
            CATALOG_MANAGE_CONTENT, CATALOG_MANAGE_METADATA, TABLE_CREATE, TABLE_FULL_METADATA));
    ....
    SUPER_PRIVILEGES.putAll(TABLE_WRITE_DATA, List.of(CATALOG_MANAGE_CONTENT, TABLE_WRITE_DATA));


So you need only `TABLE_CREATE` ""or better"" to `createTable` without setting `X-Iceberg-Access-Delegation`.

And you need both `TABLE_CREATE` and `TABLE_WRITE` (""or better"") to `createTable` if you *do* set `X-Iceberg-Access-Delegation`.

In both cases Polaris will be able to write to the metadata store and write the metadata JSON file itself, but the difference is that if you specify `X-Iceberg-Access-Delegation`, Polaris will also return a storage credential directly in the `createTable` response, the same way it would for `loadTable`. This is because in some scenarios when Spark creates the Iceberg table, it will rely on the credential in the response to then subsequently perform further actions on the table, instead of doing a separate `loadTable` request after creation to obtain storage credentials.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HvDsw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/96,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HzXtD,polaris,2278390595,96,NA,kevinjqliu,9057843,Kevin Liu,,NA,2024-08-09T17:14:10Z,2024-08-09T17:14:10Z,"@dennishuo thanks for the explanation. 

> This is because in some scenarios when Spark creates the Iceberg table, it will rely on the credential in the response to then subsequently perform further actions on the table, instead of doing a separate loadTable request after creation to obtain storage credentials.

This is an interesting behavior. In this case, Polaris must vend credentials with the `createTable` response for the metadata JSON file, which requires additional permissions. 
I found the branching logic for with/without the `X-Iceberg-Access-Delegation` header in the [`createTable` function](https://github.com/polaris-catalog/polaris/blob/32eebae59fe953057a6d60d4eeaf4c1bb7e9c0b9/polaris-service/src/main/java/io/polaris/service/catalog/IcebergCatalogAdapter.java#L171-L202)

...

Regarding the original error message. I confirmed that setting `X-Iceberg-Access-Delegation` in Spark also causes the same error, so the behavior is consistent across Spark and PyIceberg.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HzXtD/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/96,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Hzif1,polaris,2278434805,96,NA,kevinjqliu,9057843,Kevin Liu,,NA,2024-08-09T17:43:38Z,2024-08-09T17:43:38Z,"(Looks like `CREATE_TABLE_DIRECT_WITH_WRITE_DELEGATION` is a new change from #27)

To summarize, this boils down to the set of permissions the `ROOT` principal has by default. 
The `ROOT` principal has `TABLE_CREATE` permission but not `TABLE_WRITE_DATA` permission, which means only `createTable` without `X-Iceberg-Access-Delegation` is allowed.
* `createTable` without `X-Iceberg-Access-Delegation` requires only `TABLE_CREATE`
* `createTable` with `X-Iceberg-Access-Delegation` requires `TABLE_CREATE` and `TABLE_WRITE_DATA`
Source:
https://github.com/polaris-catalog/polaris/blob/be5c29af3332e2a77a3432661626cd3f443d5f4a/polaris-core/src/main/java/io/polaris/core/auth/PolarisAuthorizableOperation.java#L91-L92

### `ROOT` permissions 
`ROOT` is granted the following permissions 
* `CATALOG_MANAGE_METADATA`
* `CATALOG_MANAGE_ACCESS`
Source: 
https://github.com/polaris-catalog/polaris/blob/32eebae59fe953057a6d60d4eeaf4c1bb7e9c0b9/polaris-core/src/main/java/io/polaris/core/persistence/PolarisMetaStoreManagerImpl.java#L582-L589

But not `CATALOG_MANAGE_CONTENT` permission, as you mentioned above. 

`TABLE_CREATE` is allowed since `ROOT` has `CATALOG_MANAGE_METADATA` permission.
https://github.com/polaris-catalog/polaris/blob/be5c29af3332e2a77a3432661626cd3f443d5f4a/polaris-core/src/main/java/io/polaris/core/auth/PolarisAuthorizer.java#L136-L139


`TABLE_WRITE_DATA` is not allowed since `ROOT` has neither `CATALOG_MANAGE_CONTENT` or `TABLE_WRITE_DATA` permissions.
https://github.com/polaris-catalog/polaris/blob/be5c29af3332e2a77a3432661626cd3f443d5f4a/polaris-core/src/main/java/io/polaris/core/auth/PolarisAuthorizer.java#L238

(I'm probably butchering the semantics of privileges/permissions, but the gist is there :) )","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Hzif1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/96,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HzkLC,polaris,2278441666,96,NA,kevinjqliu,9057843,Kevin Liu,,NA,2024-08-09T17:48:15Z,2024-08-09T17:48:15Z,"From an access control perspective, we probably don't want to grant `ROOT` with `CATALOG_MANAGE_CONTENT` permission by default, right?
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HzkLC/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/96,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Jmp85,polaris,2308611897,96,NA,djouallah,12554469,Mimoune,,NA,2024-08-25T01:34:10Z,2024-08-25T01:34:10Z,"nice it seems pyiceberg deployed a fix,  who thoughts having multiple catalog implementation is a good thing !!!
https://github.com/apache/iceberg-python/pull/1096","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Jmp85/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/99,https://api.github.com/repos/apache/polaris/issues/99,polaris,2451133188,99,[DOC] Directions to run mini-deployment reference k8 directory that does not exist,bzillins,7536639,Brenton Zillins,,CLOSED,2024-08-06T15:12:03Z,2024-08-07T18:44:50Z,"**Describe the bug**
The first step of ""Running in Kubernetes"" instruct you to execute setup.sh
setup.sh tries to apply [k8/deployment.yaml](kubectl delete -f k8/deployment.yaml --ignore-not-found) and that dir does not exist

**Is this a possible security vulnerability?** 
no

**To Reproduce**
Attempt to navigate to the k8 dir in the repo

**Additional context**
Thank you for all the work that has gone into releasing this so far! Based on the commit from Dennis Huo that references another polaris-k8-config repo my assumption is that a few files were missed.

The docker compose file has enough context to put together a replacement for now.

A search for ""k8"" and ""k8s"" didn't show any related issues.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/99/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/99,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Hbk_N,polaris,2272153549,99,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-08-06T21:06:49Z,2024-08-06T21:06:49Z,That's right. The file `deployment.yaml` is missing. ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Hbk_N/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/99,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Hb4Kn,polaris,2272232103,99,NA,MonkeyCanCode,29619290,,,NA,2024-08-06T22:06:58Z,2024-08-06T22:06:58Z,"If the file doesn't exist, I can take it over and create a PR for it.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Hb4Kn/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/99,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HcJlZ,polaris,2272303449,99,NA,MonkeyCanCode,29619290,,,NA,2024-08-06T23:03:28Z,2024-08-06T23:03:28Z,Sample PR up in https://github.com/polaris-catalog/polaris/pull/102,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HcJlZ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/101,https://api.github.com/repos/apache/polaris/issues/101,polaris,2451567164,101,[DOC] documentation for increasing number of connection in connection pool used by eclipse link ,MonkeyCanCode,29619290,,,CLOSED,2024-08-06T19:39:23Z,2024-08-06T20:08:57Z,"When using eclipse link as backend metastore, I noticed it is using default connection pool (32 connections or so) per pod regardless the size of the pod. To avoid too many small pods, it will be nice to increase the number of connections allowed per pod. I tired the following settings but they doesn't seem to be taking effect:
```
<property name=""eclipselink.connection-pool.default.initial"" value=""1""/>
<property name=""eclipselink.connection-pool.default.min"" value=""64""/>
<property name=""eclipselink.connection-pool.default.max"" value=""64""/>
```

Here is how I validated:
1. Updated persistence.xml to include these 3 settings
2. Rebuilt the docker image with updated persistence.xml
3. Spun up X number of pods
4. Checked the number of established connection on the backend database

With the above setting, it should keep a connection pool of 64 connections per pods, however, that is not I observed with the steps mentioned above. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/101/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/101,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HbM7n,polaris,2272055015,101,NA,MonkeyCanCode,29619290,,,NA,2024-08-06T20:04:43Z,2024-08-06T20:04:43Z,"The above settings are actually working. Once the upload is up, it will then build the connection pooling. Ref: https://eclipse.dev/eclipselink/documentation/3.0/jpa/extensions/persistenceproperties_ref.htm","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HbM7n/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/107,https://api.github.com/repos/apache/polaris/issues/107,polaris,2453777828,107,[BUG] Connection pool seems to be gone after sometime and Polaris doesn't create a new connection pool after that (possible deadlock),MonkeyCanCode,29619290,,,CLOSED,2024-08-07T15:31:01Z,2024-08-08T20:01:36Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

We noticed after have Polaris running for sometime with Eclipse Link, the connection pool created by Polaris got tear down and Polaris is not trying to create a new connection pool after that.



### To Reproduce

Have Polaris with Eclipse link and Postgres backend running for sometime (sent couple requests in to bring up the connection pool then have it sit idle for sometime), once the connection on the backend is all gone (somehow keepalive is not happening or it is working but potential deadlock blocked there),  we will then be able to see the following:

Sample curl request:
```
curl --location 'http://localhost:8181/api/management/v1/principals' \
--header 'Authorization: Bearer principal:root;password:2c81396d261e1970c1527475e7ae7807;realm:default-realm;role:ALL'
```

Logs on the server side after submitted this request (stuck here until curl timed out):
```
DEBUG [2024-08-07 14:43:57,372 - 6224858] [pool-3-thread-9] [] i.p.s.c.DefaultContextResolver: Resolving RealmContext for method: GET, path: api/management/v1/principals, queryParams: {}, headers: {Authorization=Bearer principal:root;password:2c81396d261e1970c1527475e7ae7807;realm:default-realm;role:ALL, Accept=*/*, User-Agent=curl/8.7.1, Host=localhost:8181}
DEBUG [2024-08-07 14:43:57,372 - 6224858] [pool-3-thread-9] [] i.p.s.c.DefaultContextResolver: Resolving CallContext realmContext=""default-realm"" method=""GET"" path=""api/management/v1/principals"" queryParams=""{}"" headers=""{Authorization=Bearer principal:root;password:2c81396d261e1970c1527475e7ae7807;realm:default-realm;role:ALL, Accept=*/*, User-Agent=curl/8.7.1, Host=localhost:8181}""
DEBUG [2024-08-07 14:43:57,372 - 6224858] [pool-3-thread-9] [] i.p.s.c.RealmEntityManagerFactory: Looking up PolarisEntityManager for realm default-realm
DEBUG [2024-08-07 14:43:57,373 - 6224859] [pool-3-thread-9] [] i.p.e.p.i.e.PolarisEclipseLinkMetaStoreSessionImpl: Create EclipseLink Meta Store Session for default-realm
INFO  [2024-08-07 14:43:57,373 - 6224859] [pool-3-thread-9] [] i.p.s.tracing.TracingFilter: Started span with parent spanId=""d93e2ab7fa0e30bc"" traceId=""d56f42a0cd2df9acbff22f21cd7dc1be"" parentContext=""{}""
DEBUG [2024-08-07 14:43:57,373 - 6224859] [pool-3-thread-9 - GET /api/management/v1/principals] [] i.p.s.c.RealmEntityManagerFactory: Looking up PolarisEntityManager for realm default-realm
INFO  [2024-08-07 14:43:57,373 - 6224859] [pool-3-thread-9 - GET /api/management/v1/principals] [] i.p.s.a.TestInlineBearerTokenPolarisAuthenticator: Checking for existence of principal root in map {principal=root, password=2c81396d261e1970c1527475e7ae7807, realm=default-realm, role=ALL}
```

Check the backend database to see if there are any established connections and it shows none:
```
SELECT pid, age(clock_timestamp(), query_start), usename, query 
FROM pg_stat_activity 
WHERE query != '<IDLE>' AND query NOT ILIKE '%pg_stat_activity%' and application_name = 'PostgreSQL JDBC Driver'
ORDER BY query_start desc;
```

This leads me to think somehow the connection pool created by Polaris got teared down and Polaris is unable to recreate the connection pool. However, from the following steps, I verified connection pool recreation is for sure there under happy path:
1. Redeploy polaris to clear the deadlock state
2. Submitted a request to bring up the connection pool
3. Restarted backend metastore
4. Verified connection pool is gone on backend metastore
5. Submitted a request to bring up the connection pool and got connection pool being gone. Then at the same time, Polaris will then try to bring up a new connection pool based on log messages
6. Submitted another request and this time it goes through

With above steps, for sure the connection pooling recreation is working. However, when the poential deadlock came, the connection pooling recreation became no longer possible.

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

Here are a couple of log lines that came before the shared logs above (generated by background thread I am assuming also indicated it is trying to keep connection alive but failed to do so:
```
[EL Fine]: sql: 2024-08-07 14:42:29.219--ServerSession(1501064238)--SELECT 1
[EL Info]: query: 2024-08-07 14:42:29.219--UnitOfWork(885977653)--Communication failure detected when attempting to perform read query outside of a transaction. Attempting to retry query. Error was: Exception [EclipseLink-4002] (Eclipse Persistence Services - 4.0.3.v202405220658): org.eclipse.persistence.exceptions.DatabaseException
Internal Exception: org.postgresql.util.PSQLException: This connection has been closed.
Error Code: 0
Call: SELECT PRINCIPALCLIENTID, MAINSECRET, PRINCIPALID, SECONDARYSECRET, VERSION FROM PRINCIPAL_SECRETS WHERE (PRINCIPALCLIENTID = ?)
    bind => [root]
Query: ReadObjectQuery(referenceClass=ModelPrincipalSecrets sql=""SELECT PRINCIPALCLIENTID, MAINSECRET, PRINCIPALID, SECONDARYSECRET, VERSION FROM PRINCIPAL_SECRETS WHERE (PRINCIPALCLIENTID = ?)"").
[EL Fine]: sql: 2024-08-07 14:42:29.219--ServerSession(1501064238)--SELECT 1
[EL Fine]: sql: 2024-08-07 14:42:29.219--ServerSession(1501064238)--SELECT 1
[EL Fine]: sql: 2024-08-07 14:42:29.219--ServerSession(1501064238)--SELECT 1
```

Here is a java trace that happened earlier as well (not caused by the curl command):
```
Call: SELECT PRINCIPALCLIENTID, MAINSECRET, PRINCIPALID, SECONDARYSECRET, VERSION FROM PRINCIPAL_SECRETS WHERE (PRINCIPALCLIENTID = ?)
    bind => [root]
Query: ReadObjectQuery(referenceClass=ModelPrincipalSecrets sql=""SELECT PRINCIPALCLIENTID, MAINSECRET, PRINCIPALID, SECONDARYSECRET, VERSION FROM PRINCIPAL_SECRETS WHERE (PRINCIPALCLIENTID = ?)"")
DEBUG [2024-08-07 14:20:22,032 - 4809518] [pool-3-thread-10 - GET /api/catalog/v1/config?warehouse=polaris] [] i.p.e.p.i.e.PolarisEclipseLinkMetaStoreSessionImpl: transaction rolled back: {}
jakarta.persistence.PersistenceException: Exception [EclipseLink-4002] (Eclipse Persistence Services - 4.0.3.v202405220658): org.eclipse.persistence.exceptions.DatabaseException
Internal Exception: org.postgresql.util.PSQLException: An I/O error occurred while sending to the backend.
Error Code: 0
Call: SELECT PRINCIPALCLIENTID, MAINSECRET, PRINCIPALID, SECONDARYSECRET, VERSION FROM PRINCIPAL_SECRETS WHERE (PRINCIPALCLIENTID = ?)
    bind => [root]
Query: ReadObjectQuery(referenceClass=ModelPrincipalSecrets sql=""SELECT PRINCIPALCLIENTID, MAINSECRET, PRINCIPALID, SECONDARYSECRET, VERSION FROM PRINCIPAL_SECRETS WHERE (PRINCIPALCLIENTID = ?)"")
    at org.eclipse.persistence.internal.jpa.QueryImpl.getDetailedException(QueryImpl.java:392)
    at org.eclipse.persistence.internal.jpa.QueryImpl.executeReadQuery(QueryImpl.java:265)
    at org.eclipse.persistence.internal.jpa.QueryImpl.getResultList(QueryImpl.java:475)
    at jakarta.persistence.TypedQuery.getResultStream(TypedQuery.java:87)
    at io.polaris.extension.persistence.impl.eclipselink.PolarisEclipseLinkStore.lookupPrincipalSecrets(PolarisEclipseLinkStore.java:385)
    at io.polaris.extension.persistence.impl.eclipselink.PolarisEclipseLinkMetaStoreSessionImpl.loadPrincipalSecrets(PolarisEclipseLinkMetaStoreSessionImpl.java:558)
    at io.polaris.core.persistence.PolarisMetaStoreManagerImpl.loadPrincipalSecrets(PolarisMetaStoreManagerImpl.java:972)
    at io.polaris.core.persistence.PolarisMetaStoreManagerImpl.lambda$loadPrincipalSecrets$7(PolarisMetaStoreManagerImpl.java:984)
    at io.polaris.extension.persistence.impl.eclipselink.PolarisEclipseLinkMetaStoreSessionImpl.runInTransaction(PolarisEclipseLinkMetaStoreSessionImpl.java:168)
    at io.polaris.core.persistence.PolarisMetaStoreManagerImpl.loadPrincipalSecrets(PolarisMetaStoreManagerImpl.java:984)
    at io.polaris.service.auth.TestInlineBearerTokenPolarisAuthenticator.authenticate(TestInlineBearerTokenPolarisAuthenticator.java:72)
    at io.polaris.service.auth.TestInlineBearerTokenPolarisAuthenticator.authenticate(TestInlineBearerTokenPolarisAuthenticator.java:45)
    at io.dropwizard.auth.AuthFilter.authenticate(AuthFilter.java:144)
    at io.dropwizard.auth.oauth.OAuthCredentialAuthFilter.filter(OAuthCredentialAuthFilter.java:37)
    at org.glassfish.jersey.server.ContainerFilteringStage.apply(ContainerFilteringStage.java:108)
    at org.glassfish.jersey.server.ContainerFilteringStage.apply(ContainerFilteringStage.java:44)
    at org.glassfish.jersey.process.internal.Stages.process(Stages.java:173)
    at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:248)
    at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
    at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
    at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
    at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
    at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
    at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
    at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
    at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
    at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
    at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
    at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)
    at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)
    at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
    at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:764)
    at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1665)
    at io.dropwizard.servlets.ThreadNameFilter.doFilter(ThreadNameFilter.java:36)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at io.dropwizard.jersey.filter.AllowedMethodsFilter.handle(AllowedMethodsFilter.java:46)
    at io.dropwizard.jersey.filter.AllowedMethodsFilter.doFilter(AllowedMethodsFilter.java:40)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at io.polaris.service.tracing.TracingFilter.doFilter(TracingFilter.java:91)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at org.eclipse.jetty.servlets.CrossOriginFilter.handle(CrossOriginFilter.java:314)
    at org.eclipse.jetty.servlets.CrossOriginFilter.doFilter(CrossOriginFilter.java:267)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at io.polaris.service.PolarisApplication$ContextResolverFilter.doFilter(PolarisApplication.java:366)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:527)
    at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:221)
    at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1381)
    at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:176)
    at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:484)
    at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:174)
    at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1303)
    at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:129)
    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
    at io.dropwizard.metrics.jetty11.InstrumentedHandler.handle(InstrumentedHandler.java:313)
    at io.dropwizard.jetty.RoutingHandler.handle(RoutingHandler.java:52)
    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
    at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:822)
    at io.dropwizard.jetty.ZipExceptionHandlingGzipHandler.handle(ZipExceptionHandlingGzipHandler.java:26)
    at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:46)
    at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
    at org.eclipse.jetty.server.Server.handle(Server.java:563)
    at org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598)
    at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753)
    at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:501)
    at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287)
    at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314)
    at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100)
    at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53)
    at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)
    at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.eclipse.persistence.exceptions.DatabaseException:
Internal Exception: org.postgresql.util.PSQLException: An I/O error occurred while sending to the backend.
Error Code: 0
```

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/107/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/107,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HhrOg,polaris,2273751968,107,NA,MonkeyCanCode,29619290,,,NA,2024-08-07T15:32:00Z,2024-08-07T15:32:00Z,"Here is the thread dump:
```
2024-08-07 14:49:43
Full thread dump OpenJDK 64-Bit Server VM (21+35-2513 mixed mode, sharing):

Threads class SMR info:
_java_thread_list=0x00007fe0840038b0, length=37, elements={
0x00007fe1780f9540, 0x00007fe1780fab90, 0x00007fe1780fc670, 0x00007fe1780fdcb0,
0x00007fe1780ff250, 0x00007fe178100d90, 0x00007fe178102450, 0x00007fe178110520,
0x00007fe178113cb0, 0x00007fe1789ddee0, 0x00007fe1789d6c10, 0x00007fe178c554e0,
0x00007fe178c561f0, 0x00007fe178c5d840, 0x00007fe178c5e9c0, 0x00007fe178c5fb10,
0x00007fe178c60c70, 0x00007fe178c61ea0, 0x00007fe178c630e0, 0x00007fe178c65570,
0x00007fe178c667c0, 0x00007fe178c67950, 0x00007fe178fa4c30, 0x00007fe178fa69a0,
0x00007fe178027e90, 0x00007fe0a40584f0, 0x00007fe09c7920a0, 0x00007fe088000e70,
0x00007fe09c6f3370, 0x00007fe0980cdbe0, 0x00007fe09c5442d0, 0x00007fe084001690,
0x00007fe06c001dd0, 0x00007fe084003a40, 0x00007fe0e800c650, 0x00007fe06c01d3a0,
0x00007fe06c023a90
}

""Reference Handler"" #9 [15] daemon prio=10 os_prio=0 cpu=11.68ms elapsed=6571.53s tid=0x00007fe1780f9540 nid=15 waiting on condition  [0x00007fe15195d000]
   java.lang.Thread.State: RUNNABLE
    at java.lang.ref.Reference.waitForReferencePendingList(java.base@21/Native Method)
    at java.lang.ref.Reference.processPendingReferences(java.base@21/Reference.java:246)
    at java.lang.ref.Reference$ReferenceHandler.run(java.base@21/Reference.java:208)

""Finalizer"" #10 [16] daemon prio=8 os_prio=0 cpu=59.30ms elapsed=6571.53s tid=0x00007fe1780fab90 nid=16 in Object.wait()  [0x00007fe15185c000]
   java.lang.Thread.State: WAITING (on object monitor)
    at java.lang.Object.wait0(java.base@21/Native Method)
    - waiting on <no object reference available>
    at java.lang.Object.wait(java.base@21/Object.java:366)
    at java.lang.Object.wait(java.base@21/Object.java:339)
    at java.lang.ref.NativeReferenceQueue.await(java.base@21/NativeReferenceQueue.java:48)
    at java.lang.ref.ReferenceQueue.remove0(java.base@21/ReferenceQueue.java:158)
    at java.lang.ref.NativeReferenceQueue.remove(java.base@21/NativeReferenceQueue.java:89)
    - locked <0x00000000c00000f0> (a java.lang.ref.NativeReferenceQueue$Lock)
    at java.lang.ref.Finalizer$FinalizerThread.run(java.base@21/Finalizer.java:173)

""Signal Dispatcher"" #11 [17] daemon prio=9 os_prio=0 cpu=0.27ms elapsed=6571.53s tid=0x00007fe1780fc670 nid=17 waiting on condition  [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

""Service Thread"" #12 [18] daemon prio=9 os_prio=0 cpu=23.83ms elapsed=6571.53s tid=0x00007fe1780fdcb0 nid=18 runnable  [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

""Monitor Deflation Thread"" #13 [19] daemon prio=9 os_prio=0 cpu=430.59ms elapsed=6571.53s tid=0x00007fe1780ff250 nid=19 runnable  [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

""C2 CompilerThread0"" #14 [20] daemon prio=9 os_prio=0 cpu=25631.96ms elapsed=6571.53s tid=0x00007fe178100d90 nid=20 waiting on condition  [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE
   No compile task

""C1 CompilerThread0"" #16 [21] daemon prio=9 os_prio=0 cpu=5045.00ms elapsed=6571.53s tid=0x00007fe178102450 nid=21 waiting on condition  [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE
   No compile task

""Notification Thread"" #17 [22] daemon prio=9 os_prio=0 cpu=0.04ms elapsed=6571.52s tid=0x00007fe178110520 nid=22 runnable  [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

""Common-Cleaner"" #18 [23] daemon prio=8 os_prio=0 cpu=10.85ms elapsed=6571.52s tid=0x00007fe178113cb0 nid=23 waiting on condition  [0x00007fe151085000]
   java.lang.Thread.State: TIMED_WAITING (parking)
    at jdk.internal.misc.Unsafe.park(java.base@21/Native Method)
    - parking to wait for  <0x00000000c0000218> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
    at java.util.concurrent.locks.LockSupport.parkNanos(java.base@21/LockSupport.java:269)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(java.base@21/AbstractQueuedSynchronizer.java:1847)
    at java.lang.ref.ReferenceQueue.await(java.base@21/ReferenceQueue.java:71)
    at java.lang.ref.ReferenceQueue.remove0(java.base@21/ReferenceQueue.java:143)
    at java.lang.ref.ReferenceQueue.remove(java.base@21/ReferenceQueue.java:218)
    at jdk.internal.ref.CleanerImpl.run(java.base@21/CleanerImpl.java:140)
    at java.lang.Thread.runWith(java.base@21/Thread.java:1596)
    at java.lang.Thread.run(java.base@21/Thread.java:1583)
    at jdk.internal.misc.InnocuousThread.run(java.base@21/InnocuousThread.java:186)

""AsyncAppender-Worker-async-console-appender"" #24 [31] daemon prio=5 os_prio=0 cpu=1251.94ms elapsed=6570.49s tid=0x00007fe1789ddee0 nid=31 waiting on condition  [0x00007fe150b80000]
   java.lang.Thread.State: WAITING (parking)
    at jdk.internal.misc.Unsafe.park(java.base@21/Native Method)
    - parking to wait for  <0x00000000c053ba38> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
    at java.util.concurrent.locks.LockSupport.park(java.base@21/LockSupport.java:371)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(java.base@21/AbstractQueuedSynchronizer.java:519)
    at java.util.concurrent.ForkJoinPool.unmanagedBlock(java.base@21/ForkJoinPool.java:3780)
    at java.util.concurrent.ForkJoinPool.managedBlock(java.base@21/ForkJoinPool.java:3725)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(java.base@21/AbstractQueuedSynchronizer.java:1707)
    at java.util.concurrent.ArrayBlockingQueue.take(java.base@21/ArrayBlockingQueue.java:420)
    at ch.qos.logback.core.AsyncAppenderBase$Worker.run(AsyncAppenderBase.java:298)

""AsyncAppender-Worker-async-file-appender"" #25 [32] daemon prio=5 os_prio=0 cpu=2379.54ms elapsed=6570.47s tid=0x00007fe1789d6c10 nid=32 waiting on condition  [0x00007fe150a7f000]
   java.lang.Thread.State: WAITING (parking)
    at jdk.internal.misc.Unsafe.park(java.base@21/Native Method)
    - parking to wait for  <0x00000000c0969ef0> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
    at java.util.concurrent.locks.LockSupport.park(java.base@21/LockSupport.java:371)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(java.base@21/AbstractQueuedSynchronizer.java:519)
    at java.util.concurrent.ForkJoinPool.unmanagedBlock(java.base@21/ForkJoinPool.java:3780)
    at java.util.concurrent.ForkJoinPool.managedBlock(java.base@21/ForkJoinPool.java:3725)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(java.base@21/AbstractQueuedSynchronizer.java:1707)
    at java.util.concurrent.ArrayBlockingQueue.take(java.base@21/ArrayBlockingQueue.java:420)
    at ch.qos.logback.core.AsyncAppenderBase$Worker.run(AsyncAppenderBase.java:298)

""AsyncAppender-Worker-async-console-appender"" #26 [33] daemon prio=5 os_prio=0 cpu=91.66ms elapsed=6570.23s tid=0x00007fe178c554e0 nid=33 waiting on condition  [0x00007fe15097e000]
   java.lang.Thread.State: WAITING (parking)
    at jdk.internal.misc.Unsafe.park(java.base@21/Native Method)
    - parking to wait for  <0x00000000c053e288> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
    at java.util.concurrent.locks.LockSupport.park(java.base@21/LockSupport.java:371)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(java.base@21/AbstractQueuedSynchronizer.java:519)
    at java.util.concurrent.ForkJoinPool.unmanagedBlock(java.base@21/ForkJoinPool.java:3780)
    at java.util.concurrent.ForkJoinPool.managedBlock(java.base@21/ForkJoinPool.java:3725)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(java.base@21/AbstractQueuedSynchronizer.java:1707)
    at java.util.concurrent.ArrayBlockingQueue.take(java.base@21/ArrayBlockingQueue.java:420)
    at ch.qos.logback.core.AsyncAppenderBase$Worker.run(AsyncAppenderBase.java:298)

""AsyncAppender-Worker-async-file-appender"" #27 [34] daemon prio=5 os_prio=0 cpu=82.06ms elapsed=6570.23s tid=0x00007fe178c561f0 nid=34 waiting on condition  [0x00007fe15087d000]
   java.lang.Thread.State: WAITING (parking)
    at jdk.internal.misc.Unsafe.park(java.base@21/Native Method)
    - parking to wait for  <0x00000000c053bbd8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
    at java.util.concurrent.locks.LockSupport.park(java.base@21/LockSupport.java:371)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(java.base@21/AbstractQueuedSynchronizer.java:519)
    at java.util.concurrent.ForkJoinPool.unmanagedBlock(java.base@21/ForkJoinPool.java:3780)
    at java.util.concurrent.ForkJoinPool.managedBlock(java.base@21/ForkJoinPool.java:3725)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(java.base@21/AbstractQueuedSynchronizer.java:1707)
    at java.util.concurrent.ArrayBlockingQueue.take(java.base@21/ArrayBlockingQueue.java:420)
    at ch.qos.logback.core.AsyncAppenderBase$Worker.run(AsyncAppenderBase.java:298)

""pool-3-thread-1 - GET /api/management/v1/principals"" #28 [35] prio=5 os_prio=0 cpu=58.78ms elapsed=6570.22s tid=0x00007fe178c5d840 nid=35 waiting for monitor entry  [0x00007fe150779000]
   java.lang.Thread.State: BLOCKED (on object monitor)
    at org.eclipse.persistence.sessions.server.ConnectionPool.acquireConnection(ConnectionPool.java:130)
    - waiting to lock <0x00000000c0ac2788> (a org.eclipse.persistence.sessions.server.ConnectionPool)
    at org.eclipse.persistence.sessions.server.ServerSession.getAccessors(ServerSession.java:580)
    at org.eclipse.persistence.sessions.server.ServerSession.executeCall(ServerSession.java:598)
    at org.eclipse.persistence.sessions.server.ClientSession.executeCall(ClientSession.java:263)
    at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:280)
    at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:266)
    at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.selectOneRow(DatasourceCallQueryMechanism.java:813)
    at org.eclipse.persistence.internal.queries.ExpressionQueryMechanism.selectOneRowFromTable(ExpressionQueryMechanism.java:2912)
    at org.eclipse.persistence.internal.queries.ExpressionQueryMechanism.selectOneRow(ExpressionQueryMechanism.java:2865)
    at org.eclipse.persistence.queries.ReadObjectQuery.executeObjectLevelReadQuery(ReadObjectQuery.java:563)
    at org.eclipse.persistence.queries.ObjectLevelReadQuery.executeDatabaseQuery(ObjectLevelReadQuery.java:1236)
    at org.eclipse.persistence.queries.DatabaseQuery.execute(DatabaseQuery.java:913)
    at org.eclipse.persistence.queries.ObjectLevelReadQuery.execute(ObjectLevelReadQuery.java:1195)
    at org.eclipse.persistence.queries.ReadObjectQuery.execute(ReadObjectQuery.java:448)
    at org.eclipse.persistence.queries.ObjectLevelReadQuery.executeInUnitOfWork(ObjectLevelReadQuery.java:1283)
    at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.internalExecuteQuery(UnitOfWorkImpl.java:3025)
    at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1841)
    at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1823)
    at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1788)
    at org.eclipse.persistence.internal.jpa.QueryImpl.executeReadQuery(QueryImpl.java:263)
    at org.eclipse.persistence.internal.jpa.QueryImpl.getResultList(QueryImpl.java:475)
    at jakarta.persistence.TypedQuery.getResultStream(TypedQuery.java:87)
    at io.polaris.extension.persistence.impl.eclipselink.PolarisEclipseLinkStore.lookupPrincipalSecrets(PolarisEclipseLinkStore.java:385)
    at io.polaris.extension.persistence.impl.eclipselink.PolarisEclipseLinkMetaStoreSessionImpl.loadPrincipalSecrets(PolarisEclipseLinkMetaStoreSessionImpl.java:558)
    at io.polaris.core.persistence.PolarisMetaStoreManagerImpl.loadPrincipalSecrets(PolarisMetaStoreManagerImpl.java:972)
    at io.polaris.core.persistence.PolarisMetaStoreManagerImpl.lambda$loadPrincipalSecrets$7(PolarisMetaStoreManagerImpl.java:984)
    at io.polaris.core.persistence.PolarisMetaStoreManagerImpl$$Lambda/0x00007fe10474bd68.get(Unknown Source)
    at io.polaris.extension.persistence.impl.eclipselink.PolarisEclipseLinkMetaStoreSessionImpl.runInTransaction(PolarisEclipseLinkMetaStoreSessionImpl.java:168)
    at io.polaris.core.persistence.PolarisMetaStoreManagerImpl.loadPrincipalSecrets(PolarisMetaStoreManagerImpl.java:984)
    at io.polaris.service.auth.TestInlineBearerTokenPolarisAuthenticator.authenticate(TestInlineBearerTokenPolarisAuthenticator.java:72)
    at io.polaris.service.auth.TestInlineBearerTokenPolarisAuthenticator.authenticate(TestInlineBearerTokenPolarisAuthenticator.java:45)
    at io.dropwizard.auth.AuthFilter.authenticate(AuthFilter.java:144)
    at io.dropwizard.auth.oauth.OAuthCredentialAuthFilter.filter(OAuthCredentialAuthFilter.java:37)
    at org.glassfish.jersey.server.ContainerFilteringStage.apply(ContainerFilteringStage.java:108)
    at org.glassfish.jersey.server.ContainerFilteringStage.apply(ContainerFilteringStage.java:44)
    at org.glassfish.jersey.process.internal.Stages.process(Stages.java:173)
    at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:248)
    at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
    at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
    at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
    at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
    at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
    at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
    at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
    at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
    at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
    at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
    at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)
    at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)
    at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
    at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:764)
    at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1665)
    at io.dropwizard.servlets.ThreadNameFilter.doFilter(ThreadNameFilter.java:36)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at io.dropwizard.jersey.filter.AllowedMethodsFilter.handle(AllowedMethodsFilter.java:46)
    at io.dropwizard.jersey.filter.AllowedMethodsFilter.doFilter(AllowedMethodsFilter.java:40)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at io.polaris.service.tracing.TracingFilter.doFilter(TracingFilter.java:91)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at org.eclipse.jetty.servlets.CrossOriginFilter.handle(CrossOriginFilter.java:314)
    at org.eclipse.jetty.servlets.CrossOriginFilter.doFilter(CrossOriginFilter.java:267)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at io.polaris.service.PolarisApplication$ContextResolverFilter.doFilter(PolarisApplication.java:366)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:527)
    at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:221)
    at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1381)
    at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:176)
    at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:484)
    at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:174)
    at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1303)
    at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:129)
    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
    at io.dropwizard.metrics.jetty11.InstrumentedHandler.handle(InstrumentedHandler.java:313)
    at io.dropwizard.jetty.RoutingHandler.handle(RoutingHandler.java:52)
    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
    at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:822)
    at io.dropwizard.jetty.ZipExceptionHandlingGzipHandler.handle(ZipExceptionHandlingGzipHandler.java:26)
    at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:46)
    at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
    at org.eclipse.jetty.server.Server.handle(Server.java:563)
    at org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598)
    at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753)
    at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:501)
    at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287)
    at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314)
    at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100)
    at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53)
    at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)
    at java.lang.Thread.runWith(java.base@21/Thread.java:1596)
    at java.lang.Thread.run(java.base@21/Thread.java:1583)

""pool-3-thread-2 - GET /api/management/v1/principals"" #29 [36] prio=5 os_prio=0 cpu=67.84ms elapsed=6570.22s tid=0x00007fe178c5e9c0 nid=36 waiting for monitor entry  [0x00007fe150678000]
   java.lang.Thread.State: BLOCKED (on object monitor)
    at org.eclipse.persistence.sessions.server.ConnectionPool.acquireConnection(ConnectionPool.java:130)
    - waiting to lock <0x00000000c0ac2788> (a org.eclipse.persistence.sessions.server.ConnectionPool)
    at org.eclipse.persistence.sessions.server.ServerSession.getAccessors(ServerSession.java:580)
    at org.eclipse.persistence.sessions.server.ServerSession.executeCall(ServerSession.java:598)
    at org.eclipse.persistence.sessions.server.ClientSession.executeCall(ClientSession.java:263)
    at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:280)
    at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:266)
    at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.selectOneRow(DatasourceCallQueryMechanism.java:813)
    at org.eclipse.persistence.internal.queries.ExpressionQueryMechanism.selectOneRowFromTable(ExpressionQueryMechanism.java:2912)
    at org.eclipse.persistence.internal.queries.ExpressionQueryMechanism.selectOneRow(ExpressionQueryMechanism.java:2865)
    at org.eclipse.persistence.queries.ReadObjectQuery.executeObjectLevelReadQuery(ReadObjectQuery.java:563)
    at org.eclipse.persistence.queries.ObjectLevelReadQuery.executeDatabaseQuery(ObjectLevelReadQuery.java:1236)
    at org.eclipse.persistence.queries.DatabaseQuery.execute(DatabaseQuery.java:913)
    at org.eclipse.persistence.queries.ObjectLevelReadQuery.execute(ObjectLevelReadQuery.java:1195)
    at org.eclipse.persistence.queries.ReadObjectQuery.execute(ReadObjectQuery.java:448)
    at org.eclipse.persistence.queries.ObjectLevelReadQuery.executeInUnitOfWork(ObjectLevelReadQuery.java:1283)
    at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.internalExecuteQuery(UnitOfWorkImpl.java:3025)
    at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1841)
    at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1823)
    at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1788)
    at org.eclipse.persistence.internal.jpa.QueryImpl.executeReadQuery(QueryImpl.java:263)
    at org.eclipse.persistence.internal.jpa.QueryImpl.getResultList(QueryImpl.java:475)
    at jakarta.persistence.TypedQuery.getResultStream(TypedQuery.java:87)
    at io.polaris.extension.persistence.impl.eclipselink.PolarisEclipseLinkStore.lookupPrincipalSecrets(PolarisEclipseLinkStore.java:385)
    at io.polaris.extension.persistence.impl.eclipselink.PolarisEclipseLinkMetaStoreSessionImpl.loadPrincipalSecrets(PolarisEclipseLinkMetaStoreSessionImpl.java:558)
    at io.polaris.core.persistence.PolarisMetaStoreManagerImpl.loadPrincipalSecrets(PolarisMetaStoreManagerImpl.java:972)
    at io.polaris.core.persistence.PolarisMetaStoreManagerImpl.lambda$loadPrincipalSecrets$7(PolarisMetaStoreManagerImpl.java:984)
    at io.polaris.core.persistence.PolarisMetaStoreManagerImpl$$Lambda/0x00007fe10474bd68.get(Unknown Source)
    at io.polaris.extension.persistence.impl.eclipselink.PolarisEclipseLinkMetaStoreSessionImpl.runInTransaction(PolarisEclipseLinkMetaStoreSessionImpl.java:168)
    at io.polaris.core.persistence.PolarisMetaStoreManagerImpl.loadPrincipalSecrets(PolarisMetaStoreManagerImpl.java:984)
    at io.polaris.service.auth.TestInlineBearerTokenPolarisAuthenticator.authenticate(TestInlineBearerTokenPolarisAuthenticator.java:72)
    at io.polaris.service.auth.TestInlineBearerTokenPolarisAuthenticator.authenticate(TestInlineBearerTokenPolarisAuthenticator.java:45)
    at io.dropwizard.auth.AuthFilter.authenticate(AuthFilter.java:144)
    at io.dropwizard.auth.oauth.OAuthCredentialAuthFilter.filter(OAuthCredentialAuthFilter.java:37)
    at org.glassfish.jersey.server.ContainerFilteringStage.apply(ContainerFilteringStage.java:108)
    at org.glassfish.jersey.server.ContainerFilteringStage.apply(ContainerFilteringStage.java:44)
    at org.glassfish.jersey.process.internal.Stages.process(Stages.java:173)
    at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:248)
    at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
    at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
    at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
    at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
    at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
    at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
    at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
    at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
    at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
    at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
    at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)
    at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)
    at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
    at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:764)
    at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1665)
    at io.dropwizard.servlets.ThreadNameFilter.doFilter(ThreadNameFilter.java:36)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at io.dropwizard.jersey.filter.AllowedMethodsFilter.handle(AllowedMethodsFilter.java:46)
    at io.dropwizard.jersey.filter.AllowedMethodsFilter.doFilter(AllowedMethodsFilter.java:40)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at io.polaris.service.tracing.TracingFilter.doFilter(TracingFilter.java:91)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at org.eclipse.jetty.servlets.CrossOriginFilter.handle(CrossOriginFilter.java:314)
    at org.eclipse.jetty.servlets.CrossOriginFilter.doFilter(CrossOriginFilter.java:267)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at io.polaris.service.PolarisApplication$ContextResolverFilter.doFilter(PolarisApplication.java:366)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:527)
    at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:221)
    at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1381)
    at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:176)
    at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:484)
    at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:174)
    at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1303)
    at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:129)
    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
    at io.dropwizard.metrics.jetty11.InstrumentedHandler.handle(InstrumentedHandler.java:313)
    at io.dropwizard.jetty.RoutingHandler.handle(RoutingHandler.java:52)
    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
    at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:822)
    at io.dropwizard.jetty.ZipExceptionHandlingGzipHandler.handle(ZipExceptionHandlingGzipHandler.java:26)
    at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:46)
    at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
    at org.eclipse.jetty.server.Server.handle(Server.java:563)
    at org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598)
    at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753)
    at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:501)
    at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287)
    at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314)
    at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100)
    at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53)
    at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)
    at java.lang.Thread.runWith(java.base@21/Thread.java:1596)
    at java.lang.Thread.run(java.base@21/Thread.java:1583)

""pool-3-thread-3-acceptor-0@70d8c228-application@1e58512c{HTTP/1.1, (http/1.1)}{0.0.0.0:8181}"" #30 [37] prio=3 os_prio=0 cpu=3.82ms elapsed=6570.22s tid=0x00007fe178c5fb10 nid=37 runnable  [0x00007fe15057a000]
   java.lang.Thread.State: RUNNABLE
    at sun.nio.ch.Net.accept(java.base@21/Native Method)
    at sun.nio.ch.ServerSocketChannelImpl.implAccept(java.base@21/ServerSocketChannelImpl.java:433)
    at sun.nio.ch.ServerSocketChannelImpl.accept(java.base@21/ServerSocketChannelImpl.java:399)
    at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:409)
    at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:748)
    at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)
    at java.lang.Thread.runWith(java.base@21/Thread.java:1596)
    at java.lang.Thread.run(java.base@21/Thread.java:1583)

""pool-3-thread-4"" #31 [38] prio=5 os_prio=0 cpu=12339.31ms elapsed=6570.22s tid=0x00007fe178c60c70 nid=38 runnable  [0x00007fe150479000]
   java.lang.Thread.State: RUNNABLE
    at sun.nio.ch.EPoll.wait(java.base@21/Native Method)
    at sun.nio.ch.EPollSelectorImpl.doSelect(java.base@21/EPollSelectorImpl.java:121)
    at sun.nio.ch.SelectorImpl.lockAndDoSelect(java.base@21/SelectorImpl.java:130)
    - locked <0x00000000c323e120> (a sun.nio.ch.Util$2)
    - locked <0x00000000c323e0d0> (a sun.nio.ch.EPollSelectorImpl)
    at sun.nio.ch.SelectorImpl.select(java.base@21/SelectorImpl.java:147)
    at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:181)
    at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:188)
    at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
    at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:542)
    at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.produceTask(AdaptiveExecutionStrategy.java:455)
    at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:248)
    at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199)
    at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411)
    at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)
    at java.lang.Thread.runWith(java.base@21/Thread.java:1596)
    at java.lang.Thread.run(java.base@21/Thread.java:1583)

""pool-3-thread-5 - GET /api/management/v1/principals"" #32 [39] prio=5 os_prio=0 cpu=1959.69ms elapsed=6570.22s tid=0x00007fe178c61ea0 nid=39 waiting for monitor entry  [0x00007fe150374000]
   java.lang.Thread.State: BLOCKED (on object monitor)
    at org.eclipse.persistence.sessions.server.ConnectionPool.acquireConnection(ConnectionPool.java:130)
    - waiting to lock <0x00000000c0ac2788> (a org.eclipse.persistence.sessions.server.ConnectionPool)
    at org.eclipse.persistence.sessions.server.ServerSession.getAccessors(ServerSession.java:580)
    at org.eclipse.persistence.sessions.server.ServerSession.executeCall(ServerSession.java:598)
    at org.eclipse.persistence.sessions.server.ClientSession.executeCall(ClientSession.java:263)
    at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:280)
    at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:266)
    at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.selectOneRow(DatasourceCallQueryMechanism.java:813)
    at org.eclipse.persistence.internal.queries.ExpressionQueryMechanism.selectOneRowFromTable(ExpressionQueryMechanism.java:2912)
    at org.eclipse.persistence.internal.queries.ExpressionQueryMechanism.selectOneRow(ExpressionQueryMechanism.java:2865)
    at org.eclipse.persistence.queries.ReadObjectQuery.executeObjectLevelReadQuery(ReadObjectQuery.java:563)
    at org.eclipse.persistence.queries.ObjectLevelReadQuery.executeDatabaseQuery(ObjectLevelReadQuery.java:1236)
    at org.eclipse.persistence.queries.DatabaseQuery.execute(DatabaseQuery.java:913)
    at org.eclipse.persistence.queries.ObjectLevelReadQuery.execute(ObjectLevelReadQuery.java:1195)
    at org.eclipse.persistence.queries.ReadObjectQuery.execute(ReadObjectQuery.java:448)
    at org.eclipse.persistence.queries.ObjectLevelReadQuery.executeInUnitOfWork(ObjectLevelReadQuery.java:1283)
    at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.internalExecuteQuery(UnitOfWorkImpl.java:3025)
    at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1841)
    at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1823)
    at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1788)
    at org.eclipse.persistence.internal.jpa.QueryImpl.executeReadQuery(QueryImpl.java:263)
    at org.eclipse.persistence.internal.jpa.QueryImpl.getResultList(QueryImpl.java:475)
    at jakarta.persistence.TypedQuery.getResultStream(TypedQuery.java:87)
    at io.polaris.extension.persistence.impl.eclipselink.PolarisEclipseLinkStore.lookupPrincipalSecrets(PolarisEclipseLinkStore.java:385)
    at io.polaris.extension.persistence.impl.eclipselink.PolarisEclipseLinkMetaStoreSessionImpl.loadPrincipalSecrets(PolarisEclipseLinkMetaStoreSessionImpl.java:558)
    at io.polaris.core.persistence.PolarisMetaStoreManagerImpl.loadPrincipalSecrets(PolarisMetaStoreManagerImpl.java:972)
    at io.polaris.core.persistence.PolarisMetaStoreManagerImpl.lambda$loadPrincipalSecrets$7(PolarisMetaStoreManagerImpl.java:984)
    at io.polaris.core.persistence.PolarisMetaStoreManagerImpl$$Lambda/0x00007fe10474bd68.get(Unknown Source)
    at io.polaris.extension.persistence.impl.eclipselink.PolarisEclipseLinkMetaStoreSessionImpl.runInTransaction(PolarisEclipseLinkMetaStoreSessionImpl.java:168)
    at io.polaris.core.persistence.PolarisMetaStoreManagerImpl.loadPrincipalSecrets(PolarisMetaStoreManagerImpl.java:984)
    at io.polaris.service.auth.TestInlineBearerTokenPolarisAuthenticator.authenticate(TestInlineBearerTokenPolarisAuthenticator.java:72)
    at io.polaris.service.auth.TestInlineBearerTokenPolarisAuthenticator.authenticate(TestInlineBearerTokenPolarisAuthenticator.java:45)
    at io.dropwizard.auth.AuthFilter.authenticate(AuthFilter.java:144)
    at io.dropwizard.auth.oauth.OAuthCredentialAuthFilter.filter(OAuthCredentialAuthFilter.java:37)
    at org.glassfish.jersey.server.ContainerFilteringStage.apply(ContainerFilteringStage.java:108)
    at org.glassfish.jersey.server.ContainerFilteringStage.apply(ContainerFilteringStage.java:44)
    at org.glassfish.jersey.process.internal.Stages.process(Stages.java:173)
    at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:248)
    at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
    at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
    at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
    at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
    at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
    at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
    at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
    at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
    at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
    at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
    at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)
    at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)
    at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
    at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:764)
    at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1665)
    at io.dropwizard.servlets.ThreadNameFilter.doFilter(ThreadNameFilter.java:36)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at io.dropwizard.jersey.filter.AllowedMethodsFilter.handle(AllowedMethodsFilter.java:46)
    at io.dropwizard.jersey.filter.AllowedMethodsFilter.doFilter(AllowedMethodsFilter.java:40)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at io.polaris.service.tracing.TracingFilter.doFilter(TracingFilter.java:91)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at org.eclipse.jetty.servlets.CrossOriginFilter.handle(CrossOriginFilter.java:314)
    at org.eclipse.jetty.servlets.CrossOriginFilter.doFilter(CrossOriginFilter.java:267)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at io.polaris.service.PolarisApplication$ContextResolverFilter.doFilter(PolarisApplication.java:366)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:527)
    at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:221)
    at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1381)
    at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:176)
    at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:484)
    at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:174)
    at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1303)
    at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:129)
    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
    at io.dropwizard.metrics.jetty11.InstrumentedHandler.handle(InstrumentedHandler.java:313)
    at io.dropwizard.jetty.RoutingHandler.handle(RoutingHandler.java:52)
    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
    at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:822)
    at io.dropwizard.jetty.ZipExceptionHandlingGzipHandler.handle(ZipExceptionHandlingGzipHandler.java:26)
    at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:46)
    at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
    at org.eclipse.jetty.server.Server.handle(Server.java:563)
    at org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598)
    at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753)
    at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:501)
    at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287)
    at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314)
    at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100)
    at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53)
    at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.runTask(AdaptiveExecutionStrategy.java:421)
    at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.consumeTask(AdaptiveExecutionStrategy.java:390)
    at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:277)
    at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199)
    at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411)
    at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)
    at java.lang.Thread.runWith(java.base@21/Thread.java:1596)
    at java.lang.Thread.run(java.base@21/Thread.java:1583)

""pool-3-thread-6"" #33 [40] prio=5 os_prio=0 cpu=14128.56ms elapsed=6570.22s tid=0x00007fe178c630e0 nid=40 runnable  [0x00007fe150277000]
   java.lang.Thread.State: RUNNABLE
    at sun.nio.ch.EPoll.wait(java.base@21/Native Method)
    at sun.nio.ch.EPollSelectorImpl.doSelect(java.base@21/EPollSelectorImpl.java:121)
    at sun.nio.ch.SelectorImpl.lockAndDoSelect(java.base@21/SelectorImpl.java:130)
    - locked <0x00000000c323e810> (a sun.nio.ch.Util$2)
    - locked <0x00000000c323e7c0> (a sun.nio.ch.EPollSelectorImpl)
    at sun.nio.ch.SelectorImpl.select(java.base@21/SelectorImpl.java:147)
    at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:181)
    at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:188)
    at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
    at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:542)
    at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.produceTask(AdaptiveExecutionStrategy.java:455)
    at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:248)
    at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199)
    at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411)
    at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)
    at java.lang.Thread.runWith(java.base@21/Thread.java:1596)
    at java.lang.Thread.run(java.base@21/Thread.java:1583)

""pool-3-thread-8"" #35 [42] prio=5 os_prio=0 cpu=7.76ms elapsed=6570.22s tid=0x00007fe178c65570 nid=42 waiting on condition  [0x00007fe0feffe000]
   java.lang.Thread.State: TIMED_WAITING (parking)
    at jdk.internal.misc.Unsafe.park(java.base@21/Native Method)
    - parking to wait for  <0x00000000c053bcd8> (a java.util.concurrent.SynchronousQueue$TransferStack)
    at java.util.concurrent.locks.LockSupport.parkNanos(java.base@21/LockSupport.java:269)
    at java.util.concurrent.SynchronousQueue$TransferStack.transfer(java.base@21/SynchronousQueue.java:401)
    at java.util.concurrent.SynchronousQueue.poll(java.base@21/SynchronousQueue.java:903)
    at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.reservedWait(ReservedThreadExecutor.java:325)
    at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:401)
    at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)
    at java.lang.Thread.runWith(java.base@21/Thread.java:1596)
    at java.lang.Thread.run(java.base@21/Thread.java:1583)

""pool-3-thread-9 - GET /api/management/v1/principals"" #36 [43] prio=5 os_prio=0 cpu=12.62ms elapsed=6570.22s tid=0x00007fe178c667c0 nid=43 waiting for monitor entry  [0x00007fe0feefa000]
   java.lang.Thread.State: BLOCKED (on object monitor)
    at org.eclipse.persistence.sessions.server.ConnectionPool.acquireConnection(ConnectionPool.java:130)
    - waiting to lock <0x00000000c0ac2788> (a org.eclipse.persistence.sessions.server.ConnectionPool)
    at org.eclipse.persistence.sessions.server.ServerSession.getAccessors(ServerSession.java:580)
    at org.eclipse.persistence.sessions.server.ServerSession.executeCall(ServerSession.java:598)
    at org.eclipse.persistence.sessions.server.ClientSession.executeCall(ClientSession.java:263)
    at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:280)
    at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:266)
    at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.selectOneRow(DatasourceCallQueryMechanism.java:813)
    at org.eclipse.persistence.internal.queries.ExpressionQueryMechanism.selectOneRowFromTable(ExpressionQueryMechanism.java:2912)
    at org.eclipse.persistence.internal.queries.ExpressionQueryMechanism.selectOneRow(ExpressionQueryMechanism.java:2865)
    at org.eclipse.persistence.queries.ReadObjectQuery.executeObjectLevelReadQuery(ReadObjectQuery.java:563)
    at org.eclipse.persistence.queries.ObjectLevelReadQuery.executeDatabaseQuery(ObjectLevelReadQuery.java:1236)
    at org.eclipse.persistence.queries.DatabaseQuery.execute(DatabaseQuery.java:913)
    at org.eclipse.persistence.queries.ObjectLevelReadQuery.execute(ObjectLevelReadQuery.java:1195)
    at org.eclipse.persistence.queries.ReadObjectQuery.execute(ReadObjectQuery.java:448)
    at org.eclipse.persistence.queries.ObjectLevelReadQuery.executeInUnitOfWork(ObjectLevelReadQuery.java:1283)
    at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.internalExecuteQuery(UnitOfWorkImpl.java:3025)
    at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1841)
    at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1823)
    at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1788)
    at org.eclipse.persistence.internal.jpa.QueryImpl.executeReadQuery(QueryImpl.java:263)
    at org.eclipse.persistence.internal.jpa.QueryImpl.getResultList(QueryImpl.java:475)
    at jakarta.persistence.TypedQuery.getResultStream(TypedQuery.java:87)
    at io.polaris.extension.persistence.impl.eclipselink.PolarisEclipseLinkStore.lookupPrincipalSecrets(PolarisEclipseLinkStore.java:385)
    at io.polaris.extension.persistence.impl.eclipselink.PolarisEclipseLinkMetaStoreSessionImpl.loadPrincipalSecrets(PolarisEclipseLinkMetaStoreSessionImpl.java:558)
    at io.polaris.core.persistence.PolarisMetaStoreManagerImpl.loadPrincipalSecrets(PolarisMetaStoreManagerImpl.java:972)
    at io.polaris.core.persistence.PolarisMetaStoreManagerImpl.lambda$loadPrincipalSecrets$7(PolarisMetaStoreManagerImpl.java:984)
    at io.polaris.core.persistence.PolarisMetaStoreManagerImpl$$Lambda/0x00007fe10474bd68.get(Unknown Source)
    at io.polaris.extension.persistence.impl.eclipselink.PolarisEclipseLinkMetaStoreSessionImpl.runInTransaction(PolarisEclipseLinkMetaStoreSessionImpl.java:168)
    at io.polaris.core.persistence.PolarisMetaStoreManagerImpl.loadPrincipalSecrets(PolarisMetaStoreManagerImpl.java:984)
    at io.polaris.service.auth.TestInlineBearerTokenPolarisAuthenticator.authenticate(TestInlineBearerTokenPolarisAuthenticator.java:72)
    at io.polaris.service.auth.TestInlineBearerTokenPolarisAuthenticator.authenticate(TestInlineBearerTokenPolarisAuthenticator.java:45)
    at io.dropwizard.auth.AuthFilter.authenticate(AuthFilter.java:144)
    at io.dropwizard.auth.oauth.OAuthCredentialAuthFilter.filter(OAuthCredentialAuthFilter.java:37)
    at org.glassfish.jersey.server.ContainerFilteringStage.apply(ContainerFilteringStage.java:108)
    at org.glassfish.jersey.server.ContainerFilteringStage.apply(ContainerFilteringStage.java:44)
    at org.glassfish.jersey.process.internal.Stages.process(Stages.java:173)
    at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:248)
    at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
    at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
    at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
    at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
    at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
    at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
    at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
    at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
    at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
    at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
    at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)
    at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)
    at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
    at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:764)
    at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1665)
    at io.dropwizard.servlets.ThreadNameFilter.doFilter(ThreadNameFilter.java:36)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at io.dropwizard.jersey.filter.AllowedMethodsFilter.handle(AllowedMethodsFilter.java:46)
    at io.dropwizard.jersey.filter.AllowedMethodsFilter.doFilter(AllowedMethodsFilter.java:40)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at io.polaris.service.tracing.TracingFilter.doFilter(TracingFilter.java:91)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at org.eclipse.jetty.servlets.CrossOriginFilter.handle(CrossOriginFilter.java:314)
    at org.eclipse.jetty.servlets.CrossOriginFilter.doFilter(CrossOriginFilter.java:267)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at io.polaris.service.PolarisApplication$ContextResolverFilter.doFilter(PolarisApplication.java:366)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:527)
    at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:221)
    at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1381)
    at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:176)
    at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:484)
    at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:174)
    at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1303)
    at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:129)
    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
    at io.dropwizard.metrics.jetty11.InstrumentedHandler.handle(InstrumentedHandler.java:313)
    at io.dropwizard.jetty.RoutingHandler.handle(RoutingHandler.java:52)
    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
    at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:822)
    at io.dropwizard.jetty.ZipExceptionHandlingGzipHandler.handle(ZipExceptionHandlingGzipHandler.java:26)
    at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:46)
    at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
    at org.eclipse.jetty.server.Server.handle(Server.java:563)
    at org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598)
    at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753)
    at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:501)
    at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287)
    at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314)
    at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100)
    at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53)
    at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)
    at java.lang.Thread.runWith(java.base@21/Thread.java:1596)
    at java.lang.Thread.run(java.base@21/Thread.java:1583)

""pool-3-thread-10 - GET /api/management/v1/principals"" #37 [44] prio=5 os_prio=0 cpu=3102.88ms elapsed=6570.22s tid=0x00007fe178c67950 nid=44 runnable  [0x00007fe0fedf8000]
   java.lang.Thread.State: RUNNABLE
    at sun.nio.ch.Net.poll(java.base@21/Native Method)
    at sun.nio.ch.NioSocketImpl.park(java.base@21/NioSocketImpl.java:191)
    at sun.nio.ch.NioSocketImpl.park(java.base@21/NioSocketImpl.java:201)
    at sun.nio.ch.NioSocketImpl.implRead(java.base@21/NioSocketImpl.java:309)
    at sun.nio.ch.NioSocketImpl.read(java.base@21/NioSocketImpl.java:346)
    at sun.nio.ch.NioSocketImpl$1.read(java.base@21/NioSocketImpl.java:796)
    at java.net.Socket$SocketInputStream.read(java.base@21/Socket.java:1099)
    at sun.security.ssl.SSLSocketInputRecord.read(java.base@21/SSLSocketInputRecord.java:489)
    at sun.security.ssl.SSLSocketInputRecord.readHeader(java.base@21/SSLSocketInputRecord.java:483)
    at sun.security.ssl.SSLSocketInputRecord.bytesInCompletePacket(java.base@21/SSLSocketInputRecord.java:70)
    at sun.security.ssl.SSLSocketImpl.readApplicationRecord(java.base@21/SSLSocketImpl.java:1461)
    at sun.security.ssl.SSLSocketImpl$AppInputStream.read(java.base@21/SSLSocketImpl.java:1066)
    at org.postgresql.core.VisibleBufferedInputStream.readMore(VisibleBufferedInputStream.java:162)
    at org.postgresql.core.VisibleBufferedInputStream.ensureBytes(VisibleBufferedInputStream.java:129)
    at org.postgresql.core.VisibleBufferedInputStream.ensureBytes(VisibleBufferedInputStream.java:114)
    at org.postgresql.core.VisibleBufferedInputStream.read(VisibleBufferedInputStream.java:74)
    at org.postgresql.core.PGStream.receiveChar(PGStream.java:467)
    at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2166)
    at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371)
    at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502)
    at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419)
    at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:194)
    at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:137)
    at org.eclipse.persistence.internal.databaseaccess.DatabasePlatform.wasFailureCommunicationBased(DatabasePlatform.java:3222)
    at org.eclipse.persistence.platform.server.ServerPlatformBase.wasFailureCommunicationBased(ServerPlatformBase.java:580)
    at org.eclipse.persistence.sessions.server.ConnectionPool.acquireConnection(ConnectionPool.java:175)
    - locked <0x00000000c0ac2788> (a org.eclipse.persistence.sessions.server.ConnectionPool)
    at org.eclipse.persistence.sessions.server.ServerSession.getAccessors(ServerSession.java:580)
    at org.eclipse.persistence.sessions.server.ServerSession.executeCall(ServerSession.java:598)
    at org.eclipse.persistence.sessions.server.ClientSession.executeCall(ClientSession.java:263)
    at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:280)
    at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:266)
    at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.selectOneRow(DatasourceCallQueryMechanism.java:813)
    at org.eclipse.persistence.internal.queries.ExpressionQueryMechanism.selectOneRowFromTable(ExpressionQueryMechanism.java:2912)
    at org.eclipse.persistence.internal.queries.ExpressionQueryMechanism.selectOneRow(ExpressionQueryMechanism.java:2865)
    at org.eclipse.persistence.queries.ReadObjectQuery.executeObjectLevelReadQuery(ReadObjectQuery.java:563)
    at org.eclipse.persistence.queries.ObjectLevelReadQuery.executeDatabaseQuery(ObjectLevelReadQuery.java:1236)
    at org.eclipse.persistence.queries.DatabaseQuery.execute(DatabaseQuery.java:913)
    at org.eclipse.persistence.queries.ObjectLevelReadQuery.execute(ObjectLevelReadQuery.java:1195)
    at org.eclipse.persistence.queries.ReadObjectQuery.execute(ReadObjectQuery.java:448)
    at org.eclipse.persistence.queries.ObjectLevelReadQuery.executeInUnitOfWork(ObjectLevelReadQuery.java:1283)
    at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.internalExecuteQuery(UnitOfWorkImpl.java:3025)
    at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1841)
    at org.eclipse.persistence.internal.sessions.AbstractSession.retryQuery(AbstractSession.java:1912)
    at org.eclipse.persistence.sessions.server.ClientSession.retryQuery(ClientSession.java:704)
    at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.retryQuery(UnitOfWorkImpl.java:5824)
    at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1878)
    at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1823)
    at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1788)
    at org.eclipse.persistence.internal.jpa.QueryImpl.executeReadQuery(QueryImpl.java:263)
    at org.eclipse.persistence.internal.jpa.QueryImpl.getResultList(QueryImpl.java:475)
    at jakarta.persistence.TypedQuery.getResultStream(TypedQuery.java:87)
    at io.polaris.extension.persistence.impl.eclipselink.PolarisEclipseLinkStore.lookupPrincipalSecrets(PolarisEclipseLinkStore.java:385)
    at io.polaris.extension.persistence.impl.eclipselink.PolarisEclipseLinkMetaStoreSessionImpl.loadPrincipalSecrets(PolarisEclipseLinkMetaStoreSessionImpl.java:558)
    at io.polaris.core.persistence.PolarisMetaStoreManagerImpl.loadPrincipalSecrets(PolarisMetaStoreManagerImpl.java:972)
    at io.polaris.core.persistence.PolarisMetaStoreManagerImpl.lambda$loadPrincipalSecrets$7(PolarisMetaStoreManagerImpl.java:984)
    at io.polaris.core.persistence.PolarisMetaStoreManagerImpl$$Lambda/0x00007fe10474bd68.get(Unknown Source)
    at io.polaris.extension.persistence.impl.eclipselink.PolarisEclipseLinkMetaStoreSessionImpl.runInTransaction(PolarisEclipseLinkMetaStoreSessionImpl.java:168)
    at io.polaris.core.persistence.PolarisMetaStoreManagerImpl.loadPrincipalSecrets(PolarisMetaStoreManagerImpl.java:984)
    at io.polaris.service.auth.TestInlineBearerTokenPolarisAuthenticator.authenticate(TestInlineBearerTokenPolarisAuthenticator.java:72)
    at io.polaris.service.auth.TestInlineBearerTokenPolarisAuthenticator.authenticate(TestInlineBearerTokenPolarisAuthenticator.java:45)
    at io.dropwizard.auth.AuthFilter.authenticate(AuthFilter.java:144)
    at io.dropwizard.auth.oauth.OAuthCredentialAuthFilter.filter(OAuthCredentialAuthFilter.java:37)
    at org.glassfish.jersey.server.ContainerFilteringStage.apply(ContainerFilteringStage.java:108)
    at org.glassfish.jersey.server.ContainerFilteringStage.apply(ContainerFilteringStage.java:44)
    at org.glassfish.jersey.process.internal.Stages.process(Stages.java:173)
    at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:248)
    at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
    at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
    at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
    at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
    at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
    at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
    at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
    at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
    at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
    at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
    at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)
    at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)
    at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
    at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:764)
    at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1665)
    at io.dropwizard.servlets.ThreadNameFilter.doFilter(ThreadNameFilter.java:36)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at io.dropwizard.jersey.filter.AllowedMethodsFilter.handle(AllowedMethodsFilter.java:46)
    at io.dropwizard.jersey.filter.AllowedMethodsFilter.doFilter(AllowedMethodsFilter.java:40)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at io.polaris.service.tracing.TracingFilter.doFilter(TracingFilter.java:91)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at org.eclipse.jetty.servlets.CrossOriginFilter.handle(CrossOriginFilter.java:314)
    at org.eclipse.jetty.servlets.CrossOriginFilter.doFilter(CrossOriginFilter.java:267)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at io.polaris.service.PolarisApplication$ContextResolverFilter.doFilter(PolarisApplication.java:366)
    at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
    at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
    at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:527)
    at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:221)
    at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1381)
    at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:176)
    at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:484)
    at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:174)
    at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1303)
    at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:129)
    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
    at io.dropwizard.metrics.jetty11.InstrumentedHandler.handle(InstrumentedHandler.java:313)
    at io.dropwizard.jetty.RoutingHandler.handle(RoutingHandler.java:52)
    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
    at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:822)
    at io.dropwizard.jetty.ZipExceptionHandlingGzipHandler.handle(ZipExceptionHandlingGzipHandler.java:26)
    at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:46)
    at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
    at org.eclipse.jetty.server.Server.handle(Server.java:563)
    at org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598)
    at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753)
    at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:501)
    at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287)
    at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314)
    at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100)
    at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53)
    at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)
    at java.lang.Thread.runWith(java.base@21/Thread.java:1596)
    at java.lang.Thread.run(java.base@21/Thread.java:1583)

""pool-4-thread-3-acceptor-0@1d6ca12f-admin@210308d5{HTTP/1.1, (http/1.1)}{0.0.0.0:8182}"" #41 [47] prio=3 os_prio=0 cpu=1.41ms elapsed=6569.85s tid=0x00007fe178fa4c30 nid=47 runnable  [0x00007fe0feaf9000]
   java.lang.Thread.State: RUNNABLE
    at sun.nio.ch.Net.accept(java.base@21/Native Method)
    at sun.nio.ch.ServerSocketChannelImpl.implAccept(java.base@21/ServerSocketChannelImpl.java:433)
    at sun.nio.ch.ServerSocketChannelImpl.accept(java.base@21/ServerSocketChannelImpl.java:399)
    at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:409)
    at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:748)
    at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)
    at java.lang.Thread.runWith(java.base@21/Thread.java:1596)
    at java.lang.Thread.run(java.base@21/Thread.java:1583)

""dw-awaiter"" #42 [48] prio=5 os_prio=0 cpu=0.11ms elapsed=6569.85s tid=0x00007fe178fa69a0 nid=48 waiting on condition  [0x00007fe0fe9f8000]
   java.lang.Thread.State: WAITING (parking)
    at jdk.internal.misc.Unsafe.park(java.base@21/Native Method)
    - parking to wait for  <0x00000000c053c240> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
    at java.util.concurrent.locks.LockSupport.park(java.base@21/LockSupport.java:371)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(java.base@21/AbstractQueuedSynchronizer.java:519)
    at java.util.concurrent.ForkJoinPool.unmanagedBlock(java.base@21/ForkJoinPool.java:3780)
    at java.util.concurrent.ForkJoinPool.managedBlock(java.base@21/ForkJoinPool.java:3725)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(java.base@21/AbstractQueuedSynchronizer.java:1707)
    at org.eclipse.jetty.util.thread.AutoLock$WithCondition.await(AutoLock.java:126)
    at org.eclipse.jetty.util.thread.QueuedThreadPool.join(QueuedThreadPool.java:822)
    at org.eclipse.jetty.server.Server.join(Server.java:662)
    at io.dropwizard.core.cli.ServerCommand.lambda$run$0(ServerCommand.java:55)
    at io.dropwizard.core.cli.ServerCommand$$Lambda/0x00007fe104465420.run(Unknown Source)
    at java.lang.Thread.runWith(java.base@21/Thread.java:1596)
    at java.lang.Thread.run(java.base@21/Thread.java:1583)

""DestroyJavaVM"" #43 [7] prio=5 os_prio=0 cpu=1648.09ms elapsed=6569.85s tid=0x00007fe178027e90 nid=7 waiting on condition  [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

""Scheduler-1741007954-1"" #44 [49] prio=5 os_prio=0 cpu=27.57ms elapsed=6543.16s tid=0x00007fe0a40584f0 nid=49 waiting on condition  [0x00007fe150f84000]
   java.lang.Thread.State: TIMED_WAITING (parking)
    at jdk.internal.misc.Unsafe.park(java.base@21/Native Method)
    - parking to wait for  <0x00000000c323f260> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
    at java.util.concurrent.locks.LockSupport.parkNanos(java.base@21/LockSupport.java:269)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(java.base@21/AbstractQueuedSynchronizer.java:1758)
    at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(java.base@21/ScheduledThreadPoolExecutor.java:1182)
    at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(java.base@21/ScheduledThreadPoolExecutor.java:899)
    at java.util.concurrent.ThreadPoolExecutor.getTask(java.base@21/ThreadPoolExecutor.java:1070)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(java.base@21/ThreadPoolExecutor.java:1130)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(java.base@21/ThreadPoolExecutor.java:642)
    at java.lang.Thread.runWith(java.base@21/Thread.java:1596)
    at java.lang.Thread.run(java.base@21/Thread.java:1583)

""PostgreSQL-JDBC-Cleaner"" #45 [51] daemon prio=5 os_prio=0 cpu=11.76ms elapsed=6542.48s tid=0x00007fe09c7920a0 nid=51 waiting on condition  [0x00007fe0fe3d7000]
   java.lang.Thread.State: TIMED_WAITING (parking)
    at jdk.internal.misc.Unsafe.park(java.base@21/Native Method)
    - parking to wait for  <0x00000000c323f858> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
    at java.util.concurrent.locks.LockSupport.parkNanos(java.base@21/LockSupport.java:269)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(java.base@21/AbstractQueuedSynchronizer.java:1847)
    at java.lang.ref.ReferenceQueue.await(java.base@21/ReferenceQueue.java:71)
    at java.lang.ref.ReferenceQueue.remove0(java.base@21/ReferenceQueue.java:143)
    at java.lang.ref.ReferenceQueue.remove(java.base@21/ReferenceQueue.java:218)
    at org.postgresql.util.LazyCleaner$1.run(LazyCleaner.java:129)
    at java.lang.Thread.runWith(java.base@21/Thread.java:1596)
    at java.lang.Thread.run(java.base@21/Thread.java:1583)

""pool-3-thread-11"" #46 [52] prio=5 os_prio=0 cpu=6.59ms elapsed=6509.69s tid=0x00007fe088000e70 nid=52 waiting on condition  [0x00007fe0fe8f7000]
   java.lang.Thread.State: TIMED_WAITING (parking)
    at jdk.internal.misc.Unsafe.park(java.base@21/Native Method)
    - parking to wait for  <0x00000000c053e388> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
    at java.util.concurrent.locks.LockSupport.parkNanos(java.base@21/LockSupport.java:269)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(java.base@21/AbstractQueuedSynchronizer.java:1758)
    at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:219)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:1124)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1141)
    at java.lang.Thread.runWith(java.base@21/Thread.java:1596)
    at java.lang.Thread.run(java.base@21/Thread.java:1583)

""PostgreSQL-JDBC-SharedTimer-1"" #47 [53] daemon prio=5 os_prio=0 cpu=251.21ms elapsed=6500.01s tid=0x00007fe09c6f3370 nid=53 in Object.wait()  [0x00007fe0fe2d6000]
   java.lang.Thread.State: WAITING (on object monitor)
    at java.lang.Object.wait0(java.base@21/Native Method)
    - waiting on <no object reference available>
    at java.lang.Object.wait(java.base@21/Object.java:366)
    at java.lang.Object.wait(java.base@21/Object.java:339)
    at java.util.TimerThread.mainLoop(java.base@21/Timer.java:537)
    - locked <0x00000000c2b9f790> (a java.util.TaskQueue)
    at java.util.TimerThread.run(java.base@21/Timer.java:516)

""org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner"" #49 [57] daemon prio=5 os_prio=0 cpu=0.24ms elapsed=6498.70s tid=0x00007fe0980cdbe0 nid=57 waiting on condition  [0x00007fe0fdfd3000]
   java.lang.Thread.State: WAITING (parking)
    at jdk.internal.misc.Unsafe.park(java.base@21/Native Method)
    - parking to wait for  <0x00000000c28524d8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
    at java.util.concurrent.locks.LockSupport.park(java.base@21/LockSupport.java:371)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(java.base@21/AbstractQueuedSynchronizer.java:519)
    at java.util.concurrent.ForkJoinPool.unmanagedBlock(java.base@21/ForkJoinPool.java:3780)
    at java.util.concurrent.ForkJoinPool.managedBlock(java.base@21/ForkJoinPool.java:3725)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(java.base@21/AbstractQueuedSynchronizer.java:1707)
    at java.lang.ref.ReferenceQueue.await(java.base@21/ReferenceQueue.java:67)
    at java.lang.ref.ReferenceQueue.remove0(java.base@21/ReferenceQueue.java:158)
    at java.lang.ref.ReferenceQueue.remove(java.base@21/ReferenceQueue.java:234)
    at org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner.run(FileSystem.java:4159)
    at java.lang.Thread.runWith(java.base@21/Thread.java:1596)
    at java.lang.Thread.run(java.base@21/Thread.java:1583)

""idle-connection-reaper"" #100 [125] daemon prio=5 os_prio=0 cpu=10.38ms elapsed=5811.59s tid=0x00007fe09c5442d0 nid=125 waiting on condition  [0x00007fe0fded2000]
   java.lang.Thread.State: TIMED_WAITING (sleeping)
    at java.lang.Thread.sleep0(java.base@21/Native Method)
    at java.lang.Thread.sleep(java.base@21/Thread.java:509)
    at software.amazon.awssdk.http.apache.internal.conn.IdleConnectionReaper$ReaperTask.run(IdleConnectionReaper.java:151)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(java.base@21/ThreadPoolExecutor.java:1144)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(java.base@21/ThreadPoolExecutor.java:642)
    at java.lang.Thread.runWith(java.base@21/Thread.java:1596)
    at java.lang.Thread.run(java.base@21/Thread.java:1583)

""pool-4-thread-4"" #101 [127] prio=5 os_prio=0 cpu=19.71ms elapsed=1297.92s tid=0x00007fe084001690 nid=127 waiting on condition  [0x00007fe0fe0d4000]
   java.lang.Thread.State: TIMED_WAITING (parking)
    at jdk.internal.misc.Unsafe.park(java.base@21/Native Method)
    - parking to wait for  <0x00000000c322f9d0> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
    at java.util.concurrent.locks.LockSupport.parkNanos(java.base@21/LockSupport.java:269)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(java.base@21/AbstractQueuedSynchronizer.java:1758)
    at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:219)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:1124)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1141)
    at java.lang.Thread.runWith(java.base@21/Thread.java:1596)
    at java.lang.Thread.run(java.base@21/Thread.java:1583)

""Scheduler-1351247295-1"" #102 [128] prio=5 os_prio=0 cpu=0.45ms elapsed=1297.91s tid=0x00007fe06c001dd0 nid=128 waiting on condition  [0x00007fe150176000]
   java.lang.Thread.State: WAITING (parking)
    at jdk.internal.misc.Unsafe.park(java.base@21/Native Method)
    - parking to wait for  <0x00000000c0a083f8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
    at java.util.concurrent.locks.LockSupport.park(java.base@21/LockSupport.java:371)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(java.base@21/AbstractQueuedSynchronizer.java:519)
    at java.util.concurrent.ForkJoinPool.unmanagedBlock(java.base@21/ForkJoinPool.java:3780)
    at java.util.concurrent.ForkJoinPool.managedBlock(java.base@21/ForkJoinPool.java:3725)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(java.base@21/AbstractQueuedSynchronizer.java:1707)
    at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(java.base@21/ScheduledThreadPoolExecutor.java:1170)
    at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(java.base@21/ScheduledThreadPoolExecutor.java:899)
    at java.util.concurrent.ThreadPoolExecutor.getTask(java.base@21/ThreadPoolExecutor.java:1070)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(java.base@21/ThreadPoolExecutor.java:1130)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(java.base@21/ThreadPoolExecutor.java:642)
    at java.lang.Thread.runWith(java.base@21/Thread.java:1596)
    at java.lang.Thread.run(java.base@21/Thread.java:1583)

""pool-4-thread-7"" #105 [132] prio=5 os_prio=0 cpu=11.01ms elapsed=689.51s tid=0x00007fe084003a40 nid=132 runnable  [0x00007fe0fecfb000]
   java.lang.Thread.State: RUNNABLE
    at sun.nio.ch.EPoll.wait(java.base@21/Native Method)
    at sun.nio.ch.EPollSelectorImpl.doSelect(java.base@21/EPollSelectorImpl.java:121)
    at sun.nio.ch.SelectorImpl.lockAndDoSelect(java.base@21/SelectorImpl.java:130)
    - locked <0x00000000c323e370> (a sun.nio.ch.Util$2)
    - locked <0x00000000c323e320> (a sun.nio.ch.EPollSelectorImpl)
    at sun.nio.ch.SelectorImpl.select(java.base@21/SelectorImpl.java:147)
    at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:181)
    at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:188)
    at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
    at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:542)
    at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.produceTask(AdaptiveExecutionStrategy.java:455)
    at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:248)
    at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199)
    at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411)
    at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)
    at java.lang.Thread.runWith(java.base@21/Thread.java:1596)
    at java.lang.Thread.run(java.base@21/Thread.java:1583)

""Attach Listener"" #108 [213] daemon prio=9 os_prio=0 cpu=0.51ms elapsed=525.21s tid=0x00007fe0e800c650 nid=213 waiting on condition  [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

""pool-4-thread-10"" #109 [214] prio=5 os_prio=0 cpu=9.54ms elapsed=194.35s tid=0x00007fe06c01d3a0 nid=214 runnable  [0x00007fe0fddd1000]
   java.lang.Thread.State: RUNNABLE
    at sun.nio.ch.EPoll.wait(java.base@21/Native Method)
    at sun.nio.ch.EPollSelectorImpl.doSelect(java.base@21/EPollSelectorImpl.java:121)
    at sun.nio.ch.SelectorImpl.lockAndDoSelect(java.base@21/SelectorImpl.java:130)
    - locked <0x00000000c323e6d8> (a sun.nio.ch.Util$2)
    - locked <0x00000000c323e688> (a sun.nio.ch.EPollSelectorImpl)
    at sun.nio.ch.SelectorImpl.select(java.base@21/SelectorImpl.java:147)
    at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:181)
    at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:188)
    at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
    at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:542)
    at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.produceTask(AdaptiveExecutionStrategy.java:455)
    at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:248)
    at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199)
    at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411)
    at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)
    at java.lang.Thread.runWith(java.base@21/Thread.java:1596)
    at java.lang.Thread.run(java.base@21/Thread.java:1583)

""pool-4-thread-12"" #111 [216] prio=5 os_prio=0 cpu=1.30ms elapsed=193.18s tid=0x00007fe06c023a90 nid=216 waiting on condition  [0x00007fe0fdcd0000]
   java.lang.Thread.State: TIMED_WAITING (parking)
    at jdk.internal.misc.Unsafe.park(java.base@21/Native Method)
    - parking to wait for  <0x00000000c322f9d0> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
    at java.util.concurrent.locks.LockSupport.parkNanos(java.base@21/LockSupport.java:269)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(java.base@21/AbstractQueuedSynchronizer.java:1758)
    at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:219)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:1124)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1141)
    at java.lang.Thread.runWith(java.base@21/Thread.java:1596)
    at java.lang.Thread.run(java.base@21/Thread.java:1583)

""VM Thread"" os_prio=0 cpu=258.58ms elapsed=6571.53s tid=0x00007fe1780e9ca0 nid=14 runnable

""GC Thread#0"" os_prio=0 cpu=559.30ms elapsed=6571.54s tid=0x00007fe178062d00 nid=8 runnable

""GC Thread#1"" os_prio=0 cpu=543.52ms elapsed=6571.27s tid=0x00007fe0f8006860 nid=25 runnable

""GC Thread#2"" os_prio=0 cpu=562.83ms elapsed=6571.27s tid=0x00007fe0f800b860 nid=26 runnable

""GC Thread#3"" os_prio=0 cpu=551.38ms elapsed=6571.01s tid=0x00007fe0f800ab50 nid=27 runnable

""G1 Main Marker"" os_prio=0 cpu=13.26ms elapsed=6571.54s tid=0x00007fe17806c2f0 nid=9 runnable

""G1 Conc#0"" os_prio=0 cpu=2381.05ms elapsed=6571.54s tid=0x00007fe17806d290 nid=10 runnable

""G1 Refine#0"" os_prio=0 cpu=993.27ms elapsed=6571.54s tid=0x00007fe1780b4b10 nid=11 runnable

""G1 Service"" os_prio=0 cpu=131.94ms elapsed=6571.54s tid=0x00007fe1780b5ac0 nid=12 runnable

""VM Periodic Task Thread"" os_prio=0 cpu=1985.42ms elapsed=6571.54s tid=0x00007fe1780cf980 nid=13 waiting on condition

JNI global refs: 16, weak refs: 0
```

According to the thread dump, there are couple blocked threads and there seems to be a potential of deadlock. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HhrOg/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/107,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HsYbl,polaris,2276558565,107,NA,MonkeyCanCode,29619290,,,NA,2024-08-08T20:01:35Z,2024-08-08T20:01:35Z,This was not caused by Polaris nor backend but something else. ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6HsYbl/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/108,https://api.github.com/repos/apache/polaris/issues/108,polaris,2453872641,108,Do not package test jar in the code base,sfc-gh-aixu,109547839,Aihua Xu,,CLOSED,2024-08-07T16:22:41Z,2024-08-08T10:34:12Z,"### Is your feature request related to a problem? Please describe.

#88 adds a jar for testing purpose. In general it's not a good idea to add binary in the code base.

### Describe the solution you'd like

We will generate the jar and place in the temp folder.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/108/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/110,https://api.github.com/repos/apache/polaris/issues/110,polaris,2454257853,110,[FEATURE REQUEST] Quick Start: Spark via docker,kevinjqliu,9057843,Kevin Liu,,CLOSED,2024-08-07T20:09:59Z,2024-10-15T21:56:45Z,"### Is your feature request related to a problem? Please describe.

Not a problem. Enhancements to the ""Quick Start"" guide.

### Describe the solution you'd like

Include Spark docker container instead of cloning the Spark GitHub repo as described in the ""Quick Start"" guide

### Describe alternatives you've considered

Possibly use PySpark or other engines (Trino, PyIceberg, etc)

### Additional context

Modelled after the [Spark and Iceberg Quickstart](https://iceberg.apache.org/spark-quickstart/#spark-and-iceberg-quickstart) guide, which is defined in https://github.com/tabular-io/docker-spark-iceberg/tree/main","{""url"": ""https://api.github.com/repos/apache/polaris/issues/110/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/110,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KtHET,polaris,2327081235,110,NA,collado-mike,40346148,Michael Collado,,NA,2024-09-03T17:38:03Z,2024-09-03T17:38:03Z,"There is a jupyter notebook example using docker-compose at https://github.com/apache/polaris/blob/main/docker-compose-jupyter.yml . It's not in the quickstart guide, though.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KtHET/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/110,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KtR3R,polaris,2327125457,110,NA,kevinjqliu,9057843,Kevin Liu,,NA,2024-09-03T18:06:01Z,2024-09-03T18:06:01Z,"@collado-mike wdyt about moving that to the `getting-started/` folder as part of #42
alternatively, we can create a new example with just spark","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KtR3R/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/110,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6MLS6u,polaris,2351771310,110,NA,kevinjqliu,9057843,Kevin Liu,,NA,2024-09-15T19:54:32Z,2024-09-15T19:54:32Z,Possibly include #192 as setup script,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6MLS6u/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/110,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6MoMAk,polaris,2359345188,110,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-09-18T20:27:52Z,2024-09-18T20:27:52Z,"Other than the docker option, `./regtest/run_spark_sql.sh` is even a faster option to connect to Polaris with Spark. Here is the usage:
```
# Usage:
#   ./run_spark_sql.sh [S3-location AWS-IAM-role]
#
# Description:
#   - Without arguments: Runs against a catalog backed by the local filesystem.
#   - With two arguments: Runs against a catalog backed by AWS S3.
#       - [S3-location]  - The S3 path to use as the default base location for the catalog.
#       - [AWS-IAM-role] - The AWS IAM role for catalog to assume when accessing the S3 location.
#
# Examples:
#   - Run against local filesystem:
#     ./run_spark_sql.sh
#
#   - Run against AWS S3:
#     ./run_spark_sql.sh s3://my-bucket/path arn:aws:iam::123456789001:role/my-role
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6MoMAk/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/110,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Modn7,polaris,2359417339,110,NA,kevinjqliu,9057843,Kevin Liu,,NA,2024-09-18T21:14:34Z,2024-09-18T21:14:34Z,"`run_spark_sql.sh` requires a running Polaris service, right? I want to include it as part of the ""getting-started"" for Spark. 
One option is jupyter, the other is this script which spawns a spark sql shell ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Modn7/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/110,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6MoieN,polaris,2359437197,110,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-09-18T21:27:50Z,2024-09-18T21:27:50Z,"> run_spark_sql.sh requires a running Polaris service, right?

Yes. Feel free to add it in the doc, and thank you for doing this!","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6MoieN/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/112,https://api.github.com/repos/apache/polaris/issues/112,polaris,2454403966,112,[BUG] delete catalog fails when there are existing tables and namespaces.,TomerHeber,12767692,Tomer Heber,,CLOSED,2024-08-07T21:40:00Z,2024-09-12T17:55:44Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

This is the description of delete catalog:
```
Delete an existing catalog. This is a cascading operation that deletes all metadata, including principals, roles and grants. If the catalog is an internal catalog, all tables and namespaces are dropped without purge.
```

However, when there are existing namespaces and tables, the request fails (instead of cascading).

### To Reproduce

1. Create a catalog.
2. Add namespaces and tables.
3. Try to delete the catalog.

### Actual Behavior

Request fails:

```
{
    ""error"": {
        ""message"": ""Catalog 'zfab-test-1' cannot be dropped, it is not empty"",
        ""type"": ""BadRequestException"",
        ""code"": 400
    }
}
```

### Expected Behavior

The catalog should be deleted including all namespaces and tables. (without purge).

### Additional context

_No response_

### System information

N/A","{""url"": ""https://api.github.com/repos/apache/polaris/issues/112/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/113,https://api.github.com/repos/apache/polaris/issues/113,polaris,2454467209,113,[FEATURE REQUEST] add support for random prefixes (MURMUR3 S3 hash),TomerHeber,12767692,Tomer Heber,,CLOSED,2024-08-07T22:38:13Z,2024-08-29T03:37:17Z,"### Is your feature request related to a problem? Please describe.

AWS S3 has hard limits for each prefix index.
The best way to scale with S3 is to create a random prefix for each object/file.

This is described here:
https://aws.amazon.com/blogs/big-data/improve-operational-efficiencies-of-apache-iceberg-tables-built-on-amazon-s3-data-lakes/ (`write.object-storage.enabled'=true`).

Setting this option in Polaris, returns a ""temporarily unsupported"" error.





### Describe the solution you'd like

Below is an example:

bucket/<MURMUR3 S3 hash>/catalog/namespace/table/file1
bucket/<MURMUR3 S3 hash>/catalog/namespace/table/file2
etc...

This  strategy removes any hard limits concerns with S3 buckets.

### Describe alternatives you've considered

For each catalog generate set random location prefix:
bucket/<random_location_prefix>/namespace/table

### Additional context

The current limitation may be due to RBAC concerns.
However, I could be wrong, but the desired solution may still be able support RBAC as required.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/113/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/113,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Hk3x9,polaris,2274589821,113,NA,sfc-gh-ygu,175990617,Yufei Gu,,NA,2024-08-08T00:16:07Z,2024-08-08T00:16:07Z,"It's pretty hard to support pattern `bucket/<random_location_prefix>/namespace/table` as s3 policy used by RBAC depends on the path prefix(I might be wrong). Although, I think it is possible to support the following randomization prefix pattern.
`bucket/namespace/table/data/<random_location_prefix>`","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Hk3x9/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/113,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Hlmph,polaris,2274781793,113,NA,TomerHeber,12767692,Tomer Heber,,NA,2024-08-08T01:51:09Z,2024-08-08T01:51:09Z,"@sfc-gh-ygu - thank you for the response.

I would argue (and of course depends on the exact implementation details) that this should be possible (in theory).

Let's assume the catalog generates MURMUR3 hash (8 hex characters).
Wouldn't the catalog be able to ignore the first 8 characters and '/'.

`bucket/<random_location_prefix>/namespace/table` is not going to work - agreed.

but how about:
`bucket/<random_prefix>/catalog/namespace/table`

I see no reason why RBAC cannot be enforced with this approach. 

Please let me know what I'm missing here.

Thanks!","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Hlmph/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/113,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6IVks1,polaris,2287356725,113,NA,sfc-gh-ygu,175990617,Yufei Gu,,NA,2024-08-13T23:04:21Z,2024-08-13T23:04:21Z,"@TomerHeber , it has two implications: 
1. The credential vending needs a fixed prefix. The random prefix (no matter if the length is fixed or not) will post a security risk for credential vending. 
2. It is a challenge for the table maintenance job like RemoveOrphanfile.

Instead, we can put the the hash string after the table location, like the following example shows. This may be not as effective as the one you proposed in terms of path randomness, but it's still effective per our experience.
```
bucket/namespace/table/<hash_string>
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6IVks1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/126,https://api.github.com/repos/apache/polaris/issues/126,polaris,2456753180,126,[BUG] Polaris will not build with Dockerfile on Windows 11,zielyn,10735548,,,CLOSED,2024-08-08T22:34:52Z,2024-08-17T15:54:03Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

I'm on windows 11 with Docker Desktop v4.33.1

Running the command `docker build -t localhost:5001/polaris:latest .` results in an error after the change to the image was done in commit https://github.com/polaris-catalog/polaris/commit/0f2c2a8acde387a8a107d30631a6496cc43abb13

If i revert the Dockerfile to the code before this commit, I can build the image. I've been able to reproduce this error along with a colleague where we are all on windows 11 using docker desktop to build the image.

### To Reproduce

1. Have Windows 11 as your base OS.
2. Have Docker Desktop installed. 
3. Open Terminal and traverse to the git repo location with the latest commit.
4. Run the command `docker build -t localhost:5001/polaris:latest .`

### Actual Behavior

Error Message:

```
 => ERROR [build 5/5] RUN ./gradlew --no-daemon --info clean shadowJar                                                                                               0.5s
------
 > [build 5/5] RUN ./gradlew --no-daemon --info clean shadowJar:
0.416 /bin/sh: ./gradlew: /bin/sh^M: bad interpreter: No such file or directory
------

 1 warning found (use docker --debug to expand):
 - FromAsCasing: 'as' and 'FROM' keywords' casing do not match (line 19)
Dockerfile:29
```

### Expected Behavior

The docker image should build without error.

### Additional context

_No response_

### System information

OS Name:                   Microsoft Windows 11 
OS Version:                10.0.22631 N/A Build 22631

Docker Desktop Personal v4.33.1 with wsl 2 based engine enabled.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/126/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/126,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6IFARq,polaris,2283013226,126,NA,MonkeyCanCode,29619290,,,NA,2024-08-12T02:21:26Z,2024-08-12T02:21:26Z,"@zielyn This is actually not a bug of the program but rather how diff OS handing line endings. Here is what you can do to be able to build on Windows:
1. Delete the repo you just cloned
2. Run `git config --global core.autocrlf input`
3. Clone down repo again ` git clone https://github.com/polaris-catalog/polaris.git`
4. Build it ` docker build -t localhost:5001/polaris -f Dockerfile .`

Here is the reasoning: Windows use carriage return and line feed (CRLF) while Unix/Linux use line feed (LF) for line endings. With the git config listed on item 2, it will automatically convert `CRLF` to `LF` before pushing the files into docker. By doing so, the container will then read the file as its and the file will be using LF for for line endings which won't raise the issue listed above. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6IFARq/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/133,https://api.github.com/repos/apache/polaris/issues/133,polaris,2458527671,133,[BUG] CLI not passing through service account when using GCS to create catalog,lrichards-etsy,81712933,,,CLOSED,2024-08-09T19:17:32Z,2024-08-20T01:09:31Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

When using the cli to create a catalog for GCS it shows that the `gcsServiceAccount` being passed in the API call as null. 



### To Reproduce

```./polaris \
  --client-id <> \
  --client-secret <> \
  catalogs \
  create \
  --storage-type gcs \
  --default-base-location gs://bucket \
  --service-account 'some_email@google-service.com' \
  quickstart_catalog
```

### Actual Behavior

```
polaris-1  | DEBUG [2024-08-09 18:46:48,424 - 1963779] [pool-3-thread-7 - POST /api/management/v1/catalogs] [] i.p.s.a.api.PolarisCatalogsApi: Invoking catalogs with params operation=""createCatalog"" createCatalogRequest=""class CreateCatalogRequest {
polaris-1  |     catalog: class PolarisCatalog {
polaris-1  |         class Catalog {
polaris-1  |             type: INTERNAL
polaris-1  |             name: quickstart_catalog
polaris-1  |             properties: class CatalogProperties {
polaris-1  |                 {}
polaris-1  |                 defaultBaseLocation: gs://bucket/
polaris-1  |             }
polaris-1  |             createTimestamp: null
polaris-1  |             lastUpdateTimestamp: null
polaris-1  |             entityVersion: null
polaris-1  |             storageConfigInfo: class GcpStorageConfigInfo {
polaris-1  |                 class StorageConfigInfo {
polaris-1  |                     storageType: GCS
polaris-1  |                     allowedLocations: []
polaris-1  |                 }
polaris-1  |                 gcsServiceAccount: null
polaris-1  |             }
polaris-1  |         }
polaris-1  |     }
polaris-1  | }""
```

### Expected Behavior

A non-null `gcsServiceAccount` 

### Additional context

It looks like the CLI code for setting up a [GCS Storage Config](https://github.com/polaris-catalog/polaris/blob/main/regtests/client/python/cli/command/catalogs.py#L125-L131) has the parameters for Auzure, instead of setting the service-account

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/133/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/137,https://api.github.com/repos/apache/polaris/issues/137,polaris,2459065987,137,[FEATURE REQUEST] Add Row Level and Column Level access control.,silwalanish,24623971,Anish Silwal Khatri,silwalanish@gmail.com,OPEN,2024-08-10T12:33:21Z,2024-10-23T02:16:03Z,"### Is your feature request related to a problem? Please describe.

Is there a way to define row/column level access control through the RBAC defined [here](https://polaris.io/#tag/Access-Control/RBAC-example)?


### Describe the solution you'd like

With row level access control, I would like to filter certain rows from result set for a given Role.
With column level access control, I would like to add data masking to certain columns for a given Role.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/137/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/137,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6IC2Ra,polaris,2282447962,137,NA,shohamyamin,45430879,Shoham Yamin,,NA,2024-08-11T04:21:32Z,2024-08-11T04:21:32Z,"I think that the catalog should return when a resource is requested the row filter expression and the column mask expression that way the Trino/spark will be able to force the row filter/column mask.

the catalog itself cannot make the filter/masking because he isnâ€™t the one that access to the object storage and do the compute","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6IC2Ra/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/137,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JegKa,polaris,2306474650,137,NA,snazy,957468,Robert Stupp,,NA,2024-08-23T07:33:13Z,2024-08-23T07:33:13Z,"RLAC/CLAC is IMO a very useful functionality/feature to restrict access to sensitive information to trusted client (e.g. query engines). Masking/hiding is technically probably the more straght-forward part, but getting ""trust"" right is tricky.

A table (or view referencing such a table directly or indirectly) that has CLAC/RLAC enabled, must not be accessible to untrusted clients, simply because once you give those access, they technically see everything. Or the catalog would have to intercept (and rewrite) manifest-lists, manifest-files and data/delete files according to the user's privileges and R/CLAC rules (masking) - that's quite expensive.

However, if you have an engine/client that you _really trust_ to securely apply the CLAC/RLAC filters, the catalog can grant access to it and rely on the engine/client to do the right thing.

""Trust"" itself has very different meanings for different people. Some say they're fine with running queries only on that engine X, Y or Z. Others say that the engine must run on extremely locked down hardware, ensuring that malicious users must not even be able to use side-channel attacks to get (some) knowledge of the protected data.

Don't get me wrong, definitely don't wanna shoot this down or so - it's the opposite. Just saying, that there's a lot of work to do.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JegKa/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/137,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Q4UBu,polaris,2430681198,137,NA,johnnysohn,55504589,,,NA,2024-10-23T02:15:52Z,2024-10-23T02:15:52Z,@snazy there's an [open proposal](https://github.com/apache/iceberg/issues/10395) for extending Iceberg rest spec to support both row and column level access. Once that proposal is accepted maybe you guys can implement it on Polaris?,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Q4UBu/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/138,https://api.github.com/repos/apache/polaris/issues/138,polaris,2459417117,138,[FEATURE REQUEST] Support OPA integration,shohamyamin,45430879,Shoham Yamin,,OPEN,2024-08-11T04:33:01Z,2024-08-11T04:33:01Z,"### Is your feature request related to a problem? Please describe.

Currently Polaris catalog only support RBAC that a problem when the authorization logic fits to ABAC.


### Describe the solution you'd like

My solution for that is making an OPA(Open Policy Agent) Plugin such that the catalog for every access control decision will retrieve from an opa server if this request should be allow or not. 

That will also make the catalog more suitable for different use cases regarding access control

### Describe alternatives you've considered

Iâ€™ve considered using the RBAC as ABAC but that will be complicate and not easy thing to do

### Additional context

There is such plugin for Trino called Trino-opa plugin and the idea is come from there. It works really well and allow the user to control every feature of access control that the Trino has","{""url"": ""https://api.github.com/repos/apache/polaris/issues/138/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/139,https://api.github.com/repos/apache/polaris/issues/139,polaris,2459682211,139,[FEATURE REQUEST] Use Github Action to check Markdown links,kevinjqliu,9057843,Kevin Liu,,CLOSED,2024-08-11T17:15:56Z,2024-08-22T02:15:14Z,"### Is your feature request related to a problem? Please describe.

Use [github-action-markdown-link-check](https://github.com/gaurav-nelson/github-action-markdown-link-check) Github Action to check for dead links in Markdown files. 

Similar to [iceberg-python#324](https://github.com/apache/iceberg-python/pull/324)

### Describe the solution you'd like

_No response_

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/139/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/139,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6IEU_O,polaris,2282835918,139,NA,bbrewington,10573749,Brent Brewington,brent.brewington@gmail.com,NA,2024-08-11T17:42:30Z,2024-08-11T17:42:30Z,"I'm working on this on a fork, and will PR in

Just read CONTRIBUTING.md, and emailing over my ICLA now","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6IEU_O/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/139,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6IEVOl,polaris,2282836901,139,NA,kevinjqliu,9057843,Kevin Liu,,NA,2024-08-11T17:46:27Z,2024-08-11T17:46:27Z,"I had a PR started, but feel free to work on this! Feel free to add me as a reviewer

Should cover both `docs/` and `regtests/client/python/docs`
![Screenshot 2024-08-11 at 10 45 34â€¯AM](https://github.com/user-attachments/assets/f254e085-bb03-45cc-8138-1d625a1311d0)

","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6IEVOl/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/139,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JTVCT,polaris,2303545491,139,NA,kevinjqliu,9057843,Kevin Liu,,NA,2024-08-22T02:15:13Z,2024-08-22T02:15:13Z,"As a follow up, enable this github action for all MD files and for all PRs
See comment: https://github.com/apache/polaris/pull/141#discussion_r1726148135","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JTVCT/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/140,https://api.github.com/repos/apache/polaris/issues/140,polaris,2459717281,140,[FEATURE REQUEST] Add #polaris channel in Iceberg Slack,kevinjqliu,9057843,Kevin Liu,,CLOSED,2024-08-11T18:52:27Z,2024-08-17T00:30:10Z,"### Is your feature request related to a problem? Please describe.

A way to discuss Polaris in the Iceberg slack. 
See https://apache-iceberg.slack.com/archives/C025PH0G1D4/p1723227474343279


### Describe the solution you'd like

_No response_

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/140/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/140,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Iofi5,polaris,2292316345,140,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-08-15T21:42:28Z,2024-08-15T21:42:28Z,I don't have the permission to create new channel. I remember I was able to do so :-(. ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Iofi5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/140,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6IphEV,polaris,2292584725,140,NA,kevinjqliu,9057843,Kevin Liu,,NA,2024-08-16T01:49:23Z,2024-08-16T01:49:23Z,I think we need to ask a slack workspace admin to add a channel,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6IphEV/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/140,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Iw0Ex,polaris,2294497585,140,NA,kevinjqliu,9057843,Kevin Liu,,NA,2024-08-17T00:30:10Z,2024-08-17T00:30:10Z,"Added! (thanks ryan)
https://apache-iceberg.slack.com/archives/C07HADW86HZ
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Iw0Ex/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/144,https://api.github.com/repos/apache/polaris/issues/144,polaris,2460292577,144,[BUG] Internal Server Error 500 Error when running Polaris locally - Possibly Oauth Issue,sfc-gh-adlee,83939151,Adrian Lee,,CLOSED,2024-08-12T07:56:57Z,2024-08-24T05:01:45Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

Currently, I managed to deploy polaris locally (with gradlew) and my storage  in S3 as per the link here: https://polaris.io/#section/Quick-Start/Defining-a-Catalog 

I created a catalog as per the instructions and I can see the catalog is registered successfully inside the catalog. 

```
./polaris \
  --client-id ${CLIENT_ID} \
  --client-secret ${CLIENT_SECRET} \
  catalogs \
  create \
  --storage-type s3 \
  --default-base-location  s3://test-iceberg-us-demo/ \
  --role-arn arn:aws:iam::xxxxx:role/xxxxxx \
  quickstart_catalog
```

However, when I try to do a `spark.sql(""USE quickstart_catalog"")`, I get a 

```
DEBUG [2024-08-12 21:42:16,890 - 110453538] [pool-3-thread-25 - POST /api/catalog/v1/oauth/tokens] [] i.p.s.c.a.IcebergRestOAuth2Api: Invoking OAuth2Api with params operation=""getToken""
DEBUG [2024-08-12 21:42:16,890 - 110453538] [pool-3-thread-25 - POST /api/catalog/v1/oauth/tokens] [] i.p.s.c.RealmEntityManagerFactory: Looking up PolarisEntityManager for realm default-realm
INFO  [2024-08-12 21:42:16,900 - 110453548] [pool-3-thread-25 - POST /api/catalog/v1/oauth/tokens] [] i.p.s.IcebergExceptionMapper: Handling runtimeException null
ERROR [2024-08-12 21:42:16,903 - 110453551] [pool-3-thread-25 - POST /api/catalog/v1/oauth/tokens] [] i.p.s.IcebergExceptionMapper: Unhandled exception returning INTERNAL_SERVER_ERROR
INFO  [2024-08-12 21:42:16,911 - 110453559] [pool-3-thread-25] [] i.o.e.l.LoggingSpanExporter: 'POST /api/catalog/v1/oauth/tokens' : 9256b7d7c6d1e1f4ddb9779c543cb12d 6dab9df56c97fed6 SERVER [tracer: /api/catalog/v1/oauth/tokens:] AttributesMap{data={http.request.method=POST, server.address=localhost, url.path=/api/catalog/v1/oauth/tokens, url.scheme=http, realm=default-realm}, capacity=128, totalAddedValues=5}
127.0.0.1 - - [12/Aug/2024:13:42:16 +0000] ""POST /api/catalog/v1/oauth/tokens HTTP/1.1"" 500 67 ""-"" ""Apache-HttpClient/5.3.1 (Java/11.0.13)"" 118

```


It seems from the logs of Polaris, I am hitting an OAUTH issue with Polaris (internal 500). 

```
DEBUG [2024-08-12 08:22:35,772 - 62472420] [pool-3-thread-22 - POST /api/catalog/v1/oauth/tokens] [] i.p.s.c.a.IcebergRestOAuth2Api: Invoking OAuth2Api with params operation=""getToken""
DEBUG [2024-08-12 08:22:35,772 - 62472420] [pool-3-thread-22 - POST /api/catalog/v1/oauth/tokens] [] i.p.s.c.RealmEntityManagerFactory: Looking up PolarisEntityManager for realm default-realm
INFO  [2024-08-12 08:22:35,773 - 62472421] [pool-3-thread-22 - POST /api/catalog/v1/oauth/tokens] [] i.p.s.IcebergExceptionMapper: Handling runtimeException null
ERROR [2024-08-12 08:22:35,773 - 62472421] [pool-3-thread-22 - POST /api/catalog/v1/oauth/tokens] [] i.p.s.IcebergExceptionMapper: Unhandled exception returning INTERNAL_SERVER_ERROR
DEBUG [2024-08-12 21:42:16,905 - 110453553] [pool-3-thread-25 - POST /api/catalog/v1/oauth/tokens] [] i.p.s.IcebergExceptionMapper: Mapped exception to errorResp: OutboundJaxrsResponse{status=500, reason=Internal Server Error, hasEntity=true, closed=false, buffered=false}
```

This is my configuration setup:

```
spark = (
    SparkSession
    .builder
    .appName('iceberg_lab')
    .config('spark.jars.packages', 'org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.2,org.apache.hadoop:hadoop-aws:3.4.0')
    .config('spark.sql.extensions', 'org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions')
    .config('spark.sql.defaultCatalog','quickstart_catalog')

    #configure quickstart_catalog as an iceberg rest catalog
    .config('spark.sql.catalog.quickstart_catalog.type', 'rest')
    .config('spark.sql.catalog.quickstart_catalog','org.apache.iceberg.spark.SparkCatalog')

    #configure rest endpoint
    .config('spark.sql.catalog.quickstart_catalog.uri','http://localhost:8181/api/catalog')
    # Enable token refresh
    .config('spark.sql.catalog.quickstart_catalog.token-refresh-enabled', 'true')

    # specify the client_id:client_secret pair
    .config('spark.sql.catalog.quickstart_catalog.credential','XXX.YYY')

    # Set the warehouse to the name of the catalog we created
    .config('spark.sql.catalog.quickstart_catalog.warehouse','quickstart_catalog')
    .config('spark.sql.catalog.quickstart_catalog.scope','PRINCIPAL_ROLE:ALL')
    .config('spark.sql.catalog.quickstart_catalog.token-refresh-enabled','true')

    # Enable access credential delegation
    .config('spark.sql.catalog.quickstart_catalog.header.X-Iceberg-Access-Delegation', 'true')
    
    .config('spark.sql.catalog.quickstart_catalog.io-impl', 'org.apache.iceberg.io.ResolvingFileIO')
    .config('spark.sql.catalog.quickstart_catalog.s3.region', 'us-west-2')
    .getOrCreate()
)
```

### To Reproduce

1. Go to https://polaris.io/#section/Quick-Start/Defining-a-Catalog
2. Follow the set up
3. when you run the spark.sql(""USE quickstart_catalog"")
4. When you check the polaris logs, the internal error message is surfaced

### Actual Behavior

Should not error out and inform me I can use the quickstart_catalog

### Expected Behavior

Should not error out and inform me I can use the quickstart_catalog

### Additional context

Should not error out and inform me I can use the quickstart_catalog

### System information

MacOS","{""url"": ""https://api.github.com/repos/apache/polaris/issues/144/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/144,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JSN3g,polaris,2303253984,144,NA,MonkeyCanCode,29619290,,,NA,2024-08-21T22:58:20Z,2024-08-21T22:58:20Z,"@sfc-gh-adlee are you still seeing this issue? I am able to run those locally. If the issue is reproducible, I can debug to see if there are any diffs. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JSN3g/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/144,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JSQ_D,polaris,2303266755,144,NA,sfc-gh-adlee,83939151,Adrian Lee,,NA,2024-08-21T23:11:20Z,2024-08-21T23:11:20Z,"Hello Apache/Polaris


1) If I use the default realm principal client ID and client secret, i
don't hit the 500 error. I was able to go until the step ""create or replace
table""

It throws a Principal 'root' with activated PrincipalRoles '[]' and
activated ids '[2, 4]' is not authorized.


 2) But if i use the  quickstart_user client ID and client secret (as per
the guide), it doesnt work (hits the nullpointer still) .

 Using the curl command works with the quickstart_user client ID and client
secret.

curl -v -X POST http://localhost:8181/api/catalog/v1/oauth/tokens \
      -d
'grant_type=client_credentials&client_id=XXXX&client_secret=YYYY&scope=PRINCIPAL_ROLE:ALL'


Can I check also for the IAM role and S3 resource did u use a IAM role and
S3 from aws? Because if so how do we bind inside the S3 role ARN the
snowflake_user_arn or snowflake_external_id from my catalog running locally?

This is based on the gradlew run. I haven't tried the docker method one.



On Thu, Aug 22, 2024, 6:58â€¯AM MonkeyCanCode ***@***.***>
wrote:

> @sfc-gh-adlee <https://github.com/sfc-gh-adlee> are you still seeing this
> issue? I am able to run those locally. If the issue is reproducible, I can
> debug to see if there are any diffs.
>
> â€”
> Reply to this email directly, view it on GitHub
> <https://github.com/apache/polaris/issues/144#issuecomment-2303253984>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AUAM6T2OQUSHQHQLYK6EFO3ZSULSFAVCNFSM6AAAAABMLUE3KGVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGMBTGI2TGOJYGQ>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JSQ_D/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/144,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JTMDt,polaris,2303508717,144,NA,MonkeyCanCode,29619290,,,NA,2024-08-22T01:48:09Z,2024-08-22T01:48:09Z,"> Hello Apache/Polaris 1) If I use the default realm principal client ID and client secret, i don't hit the 500 error. I was able to go until the step ""create or replace table"" It throws a Principal 'root' with activated PrincipalRoles '[]' and activated ids '[2, 4]' is not authorized. 2) But if i use the quickstart_user client ID and client secret (as per the guide), it doesnt work (hits the nullpointer still) . Using the curl command works with the quickstart_user client ID and client secret. curl -v -X POST http://localhost:8181/api/catalog/v1/oauth/tokens \ -d 'grant_type=client_credentials&client_id=XXXX&client_secret=YYYY&scope=PRINCIPAL_ROLE:ALL' Can I check also for the IAM role and S3 resource did u use a IAM role and S3 from aws? Because if so how do we bind inside the S3 role ARN the snowflake_user_arn or snowflake_external_id from my catalog running locally? This is based on the gradlew run. I haven't tried the docker method one.
> [â€¦](#)
> On Thu, Aug 22, 2024, 6:58â€¯AM MonkeyCanCode ***@***.***> wrote: @sfc-gh-adlee <https://github.com/sfc-gh-adlee> are you still seeing this issue? I am able to run those locally. If the issue is reproducible, I can debug to see if there are any diffs. â€” Reply to this email directly, view it on GitHub <[#144 (comment)](https://github.com/apache/polaris/issues/144#issuecomment-2303253984)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AUAM6T2OQUSHQHQLYK6EFO3ZSULSFAVCNFSM6AAAAABMLUE3KGVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGMBTGI2TGOJYGQ> . You are receiving this because you were mentioned.Message ID: ***@***.***>

Thanks for the info. Will rerun the spark setup and see if I have this issue (didn't hit this one earlier and current workflow is also working). Will share details a bit later tonight.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JTMDt/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/144,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JTp5o,polaris,2303630952,144,NA,MonkeyCanCode,29619290,,,NA,2024-08-22T04:04:40Z,2024-08-22T04:04:40Z,"@sfc-gh-adlee So what I refers to as working was https://github.com/apache/polaris/blob/main/docker-compose-jupyter.yml

Then back to your question regarding AWS ARN and S3 access. Here are what you will needed on AWS side:
1. S3 bucket
2. IAM policy that defined access to the S3 bucket in item 1
3. IAM role that is associated with the IAM policy created in item 2 with self trust relation when using same AWS account (aka self-assuming/self-trusting IAM role)
4. IAM user that is associated with IAM role created in item 3

Here is the reasoning, when Spark is accessing S3 via Polaris, it is using assume role instead of using `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` directly after successfully authed with Polaris with sufficient RBAC access (no needed to provide key and secret to spark but Polaris itself will need those). It is using the provided  `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` for user created in item 4 to invoke assumeRole which then use AWS Security Token Service (AWS STS) to generate temporary token to assume that role created in item 3. Thus, Spark can access S3 without needing to have the actual key/secret that has access to S3.

Here is the code that is doing this: https://github.com/apache/polaris/blob/e89ff19dc18c3cd5a357461222a52b91e682f5d0/polaris-core/src/main/java/io/polaris/core/storage/aws/AwsCredentialsStorageIntegration.java#L40

Then for your specific error, I am assuming you didn't grant the RBAC correctly for that new principal. The curl command is just return a dummy OAUTH2 token after hitting the backend metastore (so as long as the auth is correct, it will return).

Then for `root` user, you won't be able to use that to create table by default as the `root` user doesn't have that type access. Out of box, `root` user has access to manage RBAC as well as managing catalogs. However, `root` user doesn't have access to create tables under catalog. 

You can use the following procedures to get a working setup (all steps are required as the following steps will create a new catalog, principle, catalog role, principle role, and associated all of those resources together...original source: https://polaris.io/#section/Quick-Start/Bootstrapping-Polaris):
```
cd ~/polaris

./polaris \
  --client-id ${CLIENT_ID} \
  --client-secret ${CLIENT_SECRET} \
  catalogs \
  create \
  --storage-type s3 \
  --default-base-location ${DEFAULT_BASE_LOCATION} \
  --role-arn ${ROLE_ARN} \
  quickstart_catalog

./polaris \
  --client-id ${CLIENT_ID} \
  --client-secret ${CLIENT_SECRET} \
  principals \
  create \
  quickstart_user

./polaris \
  --client-id ${CLIENT_ID} \
  --client-secret ${CLIENT_SECRET} \
  principal-roles \
  create \
  quickstart_user_role

./polaris \
  --client-id ${CLIENT_ID} \
  --client-secret ${CLIENT_SECRET} \
  catalog-roles \
  create \
  --catalog quickstart_catalog \
  quickstart_catalog_role

./polaris \
  --client-id ${CLIENT_ID} \
  --client-secret ${CLIENT_SECRET} \
  principal-roles \
  grant \
  --principal quickstart_user \
  quickstart_user_role

./polaris \
  --client-id ${CLIENT_ID} \
  --client-secret ${CLIENT_SECRET} \
  catalog-roles \
  grant \
  --catalog quickstart_catalog \
  --principal-role quickstart_user_role \
  quickstart_catalog_role

./polaris \
  --client-id ${CLIENT_ID} \
  --client-secret ${CLIENT_SECRET} \
  privileges \
  catalog \
  grant \
  --catalog quickstart_catalog \
  --catalog-role quickstart_catalog_role \
  CATALOG_MANAGE_CONTENT
```
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JTp5o/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/144,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Jg4Am,polaris,2307096614,144,NA,sfc-gh-adlee,83939151,Adrian Lee,,NA,2024-08-23T13:27:59Z,2024-08-23T13:27:59Z,"Hi team, thank you for this. I did actually follow this https://polaris.io/#section/Quick-Start/Bootstrapping-Polaris in fact. Didnt do any deviation but hit into the 500. I will try the docker-compose one instead. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Jg4Am/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/144,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JktXi,polaris,2308101602,144,NA,sfc-gh-adlee,83939151,Adrian Lee,,NA,2024-08-24T05:01:45Z,2024-08-24T05:01:45Z,"I managed to get it working with the docker version and I was able to persist my data into my S3 bucket via polaris catalog. 

So it seems the gradlew one locally was the only one so far that i had some slight issues. However all good since can get the docker one running. 

I will close the issue. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JktXi/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/145,https://api.github.com/repos/apache/polaris/issues/145,polaris,2461031858,145,Support  for Deltalake format,tpang-cxl,116722302,,,OPEN,2024-08-12T13:35:47Z,2024-12-12T13:37:11Z,"### Is your feature request related to a problem? Please describe.

Polaris catalog seems to be very good. We are thinking to replace HMS with another open source data catalog. Is there any plan that you ass Delta table format?

### Describe the solution you'd like

_No response_

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/145/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/145,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6PQFiM,polaris,2403358860,145,NA,chimerasaurus,425799,James Malone,,NA,2024-10-09T20:20:57Z,2024-10-09T20:20:57Z,"I am a proponent of this idea. 

From my personal point of view, I think having Polaris support multiple formats, to become a format-agnostic all-purpose catalog makes a lot of sense. 

@tpang-cxl You have an amusing but unfortunate typo. :) ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6PQFiM/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/146,https://api.github.com/repos/apache/polaris/issues/146,polaris,2461976057,146,[BUG] Incorrect usage of the X-Iceberg-Access-Delegation header,dimas-b,40603221,Dmitri Bourlatchkov,,CLOSED,2024-08-12T22:09:37Z,2024-11-07T21:45:35Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

[Iceberg REST spec defines](https://github.com/apache/iceberg/blob/apache-iceberg-1.6.0/open-api/rest-catalog-open-api.yaml#L1489) the following two values for the `X-Iceberg-Access-Delegation` HTTP header:
* `vended-credentials`
* `remote-signing`

However, current Polaris examples / docs use the value of `true`, which does not match anything in the Iceberg REST spec.

Current code appears to treat any non-empty header as `vended-credentials`, which is not exactly correct.

### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

* `vended-credentials` value is respected. 
* `remote-signing` is clearly reported as an error (for now, cf. #32).

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/146/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/146,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JTZ8Y,polaris,2303565592,146,NA,dennishuo,7410123,Dennis Huo,,NA,2024-08-22T02:40:10Z,2024-08-22T02:40:10Z,"This was definitely an unfortunate oversight; good catch!

Luckily, since the bug wasn't that the request handlers actually expected to parse `true` from the String, just that they only checked `!isNullOrEmpty` to assume it meant vended-credentials, it's forward-compatible if anyone is using the ""correct"" syntax.

We should try to update docs as quickly as possible to reduce the degree to which `X-Iceberg-Access-Delegation: true` gets entrenched into various workflows or test scripts of anyone integrating with Polaris.

At this point it may already be prudent to have an option for still falling back to the `vended-credentials` behavior if none of the comma-separated list of supported mechanisms is recognized (including the string ""true"").","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JTZ8Y/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/146,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6NjPtW,polaris,2374826838,146,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-09-25T18:09:09Z,2024-09-25T18:09:09Z,"Hey @dimas-b , I think you fixed this in #211, right?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6NjPtW/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/146,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6S0YYy,polaris,2463204914,146,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-11-07T21:00:09Z,2024-11-07T21:00:09Z,This seems fixed so I'm closing it out for now -- please re-open if need be.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6S0YYy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/146,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6S0s2O,polaris,2463288718,146,NA,dimas-b,40603221,Dmitri Bourlatchkov,,NA,2024-11-07T21:45:33Z,2024-11-07T21:45:33Z,"Yes, #211 fixes this... not sure how I forgot to cross-reference :facepalm: ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6S0s2O/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/147,https://api.github.com/repos/apache/polaris/issues/147,polaris,2463302617,147,[BUG]Pagination is not working for List namespaces,shraddhagrawal,102943021,Shraddha Agrawal,,OPEN,2024-08-13T13:01:16Z,2024-08-15T17:54:38Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

Even if we specify page size api is returning all namespaces
In docs it is mentioned ""servers that support pagination"" can you please elaborate what this means?

### To Reproduce

curl --location 'http://localhost:8181/api/catalog/v1/polaris/namespaces?parent=accounting&pageSize=1&pageToken=null' \
--header 'Authorization: Bearer principal:root;password:xxxxxxxxxxxxxxxx;realm:default-realm;role:ALL' \
--data ''

### Actual Behavior

returned all namespaces

### Expected Behavior

return only one namespace

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/147/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/147,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6IZUh3,polaris,2288339063,147,NA,ebyhr,6237050,Yuya Ebihara,,NA,2024-08-14T09:57:42Z,2024-08-14T09:57:42Z,"Polaris doesn't support pagination yet in my understanding. You can see `pageToken` and `pageSize` parameters are unused:

https://github.com/polaris-catalog/polaris/blob/167f71bf9ce33cb9cda24c8ebb8a8a00bd19a367/polaris-service/src/main/java/io/polaris/service/catalog/IcebergCatalogAdapter.java#L117-L128","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6IZUh3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/149,https://api.github.com/repos/apache/polaris/issues/149,polaris,2464040254,149,[FEATURE REQUEST] Switch the tests against EclipseLink with H2 database,aihuaxu,26491691,Aihua Xu,aihuaxu@gmail.com,CLOSED,2024-08-13T19:14:03Z,2024-09-11T21:40:49Z,"### Is your feature request related to a problem? Please describe.

Currently, the tests are tested against InMemoryPolarisMetaStoreManagerFactory and PolarisTreeMapMetaStoreSessionImpl implementation only and only a unit test is covering for EclipseLinkPolarisMetaStoreManagerFactory. To be closer to the production with database backed EclipseLinkPolarisMetaStoreManagerFactory and PolarisEclipseLinkMetaStoreSessionImpl, we should also consider adding all the tests against EclipseLinkPolarisMetaStoreManagerFactory. 

### Describe the solution you'd like

_No response_

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/149/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/149,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6IWylT,polaris,2287675731,149,NA,TomerHeber,12767692,Tomer Heber,,NA,2024-08-14T01:47:59Z,2024-08-14T01:47:59Z,"I think the tests are running against h2 (in addition to the memory variant).
At least, that's what I'm observing.

For example, if you remove h2 from gradle (testImplementation), the tests will fail.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6IWylT/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/149,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6I6kCr,polaris,2297053355,149,NA,aihuaxu,26491691,Aihua Xu,aihuaxu@gmail.com,NA,2024-08-19T17:15:16Z,2024-08-19T17:15:16Z,"> I think the tests are running against h2 (in addition to the memory variant). At least, that's what I'm observing.
> 
> For example, if you remove h2 from gradle (testImplementation), the tests will fail.

Currently there is a unit test which test against H2 but not regression tests.  I think it would good to test H2 for regression tests as well. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6I6kCr/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/152,https://api.github.com/repos/apache/polaris/issues/152,polaris,2468189961,152,[FEATURE REQUEST] Hosted docker image,lrichards-etsy,81712933,,,OPEN,2024-08-15T14:36:11Z,2024-10-15T01:37:54Z,"### Is your feature request related to a problem? Please describe.

_No response_

### Describe the solution you'd like

Having a Polaris docker image hosted in [docker.io, ghcr.io, quay.io] so developing & build pipelines can use `docker pull <polaris image>`.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/152/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/152,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JealL,polaris,2306451787,152,NA,snazy,957468,Robert Stupp,,NA,2024-08-23T07:17:59Z,2024-08-23T07:17:59Z,"Hi @lrichards-etsy!
Yes, that's definitely useful for releases.

From personal experience, I'd prefer ghcr.io (extremely easy in GH workflows, but with some caveats for new repos/images) and/or quay.io.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JealL/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/152,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6PvrBW,polaris,2411638870,152,NA,rhasson,1313604,Roy Hasson,,NA,2024-10-14T15:44:59Z,2024-10-14T15:44:59Z,Please also provide a pre-built image for CLI tools or include it pre-built in the server image,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6PvrBW/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/152,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Pzfu0,polaris,2412641204,152,NA,MonkeyCanCode,29619290,,,NA,2024-10-15T01:37:54Z,2024-10-15T01:37:54Z,"> Please also provide a pre-built image for CLI tools or include it pre-built in the server image

For the pre-build image, it doesn't have the driver jars out of box. Thus, it may not be very useful at the moment in my option (the out of box one will only allow user to use in-memory DB. a diff build will be needed to be able to use other DBs as backend).","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Pzfu0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/156,https://api.github.com/repos/apache/polaris/issues/156,polaris,2471669516,156,register_table: RESTException: Unable to process: Failed to get subscoped credentials,ambaricloud,76875925,Satya KONDAPALLI,skondapalli@ambaricloud.com,CLOSED,2024-08-17T21:00:04Z,2024-08-26T17:31:52Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

Hi All
Able to create, and add data to the Polaris catalog/namespace table. Branching, FastFarward, and all maintenance procedures are working fine. In the Test Undo Drop Table use case, the below procedure failed. 

spark.sql(""""""CALL polaris.system.register_table(table => 'polaris.market.ksnâ€™,metadata_file => 's3://<>/market/ksn/metadata/00001-b5616bb5-d382-4cd7-8ce3-235cd702c0c0.metadata.json')"""""")


py4j.protocol.Py4JJavaError: An error occurred while calling o76.sql.
: org.apache.iceberg.exceptions.RESTException: Unable to process: Failed to get subscoped credentials: Unable to load credentials from any of the providers in the chain AwsCredentialsProviderChain(credentialsProviders=[SystemPropertyCredentialsProvider(), EnvironmentVariableCredentialsProvider(), WebIdentityTokenCredentialsProvider(), ProfileCredentialsProvider(profileName=default, profileFile=ProfileFile(sections=[])), ContainerCredentialsProvider(), InstanceProfileCredentialsProvider()]) : [SystemPropertyCredentialsProvider(): Unable to load credentials from system settings. Access key must be specified either via environment variable (AWS_ACCESS_KEY_ID) or system property (aws.accessKeyId)., EnvironmentVariableCredentialsProvider(): Unable to load credentials from system settings. Access key must be specified either via environment variable (AWS_ACCESS_KEY_ID) or system property (aws.accessKeyId)., WebIdentityTokenCredentialsProvider(): Either the environment variable AWS_WEB_IDENTITY_TOKEN_FILE or the javaproperty aws.webIdentityTokenFile must be set., ProfileCredentialsProvider(profileName=default, profileFile=ProfileFile(sections=[])): Profile file contained no credentials for profile 'default': ProfileFile(sections=[]), ContainerCredentialsProvider(): Cannot fetch credentials from container - neither AWS_CONTAINER_CREDENTIALS_FULL_URI or AWS_CONTAINER_CREDENTIALS_RELATIVE_URI environment variables are set., InstanceProfileCredentialsProvider(): Failed to load credentials from IMDS.].

### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/156/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/156,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JOIN8,polaris,2302182268,156,NA,mayankvadariya,48036907,Mayank Vadariya,,NA,2024-08-21T14:24:08Z,2024-08-21T14:24:08Z,"Further stack trace.

```java
Caused by: org.apache.iceberg.exceptions.ServiceFailureException: Server error: SdkClientException: Unable to load credentials from any of the providers in the chain AwsCredentialsProviderChain(credentialsProviders=[SystemPropertyCredentialsProvider(), EnvironmentVariableCredentialsProvider(), WebIdentityTokenCredentialsProvider(), ProfileCredentialsProvider(profileName=default, profileFile=ProfileFile(sections=[])), ContainerCredentialsProvider(), InstanceProfileCredentialsProvider()]) : [SystemPropertyCredentialsProvider(): Unable to load credentials from system settings. Access key must be specified either via environment variable (AWS_ACCESS_KEY_ID) or system property (aws.accessKeyId)., EnvironmentVariableCredentialsProvider(): Unable to load credentials from system settings. Access key must be specified either via environment variable (AWS_ACCESS_KEY_ID) or system property (aws.accessKeyId)., WebIdentityTokenCredentialsProvider(): Either the environment variable AWS_WEB_IDENTITY_TOKEN_FILE or the javaproperty aws.webIdentityTokenFile must be set., ProfileCredentialsProvider(profileName=default, profileFile=ProfileFile(sections=[])): Profile file contained no credentials for profile 'default': ProfileFile(sections=[]), ContainerCredentialsProvider(): Cannot fetch credentials from container - neither AWS_CONTAINER_CREDENTIALS_FULL_URI or AWS_CONTAINER_CREDENTIALS_RELATIVE_URI environment variables are set., InstanceProfileCredentialsProvider(): Failed to load credentials from IMDS.]
	at org.apache.iceberg.rest.ErrorHandlers$DefaultErrorHandler.accept(ErrorHandlers.java:217)
	at org.apache.iceberg.rest.ErrorHandlers$TableErrorHandler.accept(ErrorHandlers.java:118)
	at org.apache.iceberg.rest.ErrorHandlers$TableErrorHandler.accept(ErrorHandlers.java:102)
	at org.apache.iceberg.rest.HTTPClient.throwFailure(HTTPClient.java:211)
	at org.apache.iceberg.rest.HTTPClient.execute(HTTPClient.java:323)
	at org.apache.iceberg.rest.HTTPClient.execute(HTTPClient.java:262)
	at org.apache.iceberg.rest.HTTPClient.post(HTTPClient.java:368)
	at org.apache.iceberg.rest.RESTClient.post(RESTClient.java:112)
	at org.apache.iceberg.rest.RESTSessionCatalog.registerTable(RESTSessionCatalog.java:509)
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JOIN8/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/156,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JRrIt,polaris,2303111725,156,NA,mayankvadariya,48036907,Mayank Vadariya,,NA,2024-08-21T22:18:37Z,2024-08-21T22:18:37Z,Possibly `BaseMetastoreCatalog#registerTable` requires overridden in `BasePolarisCatalog` to have `BasePolarisCatalog#refreshIOWithCredentials` or `refreshCredentials` considered before making s3 call.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JRrIt/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/156,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JeTw7,polaris,2306423867,156,NA,dennishuo,7410123,Dennis Huo,,NA,2024-08-23T06:59:36Z,2024-08-23T06:59:36Z,"Thanks for the report! Indeed, it looks like the problem is that `registerTable` is the only thing in `BaseMetastoreCatalog` that tries to directly use the `ops.io()` immediately after building `ops = newTableOps(identifier)`.

Whereas other flows either deal with an existing Table entity and by calling `current()` will trigger a `doRefresh()` which will properly initialize the FileIO with StorageConfiguration-based credentials, or else will go through a `doCommit` which also initializes the FileIO with the right credentials, this `registerTable` flow will revert to the catalog's ""default"" FileIO.

The catalog's ""default"" FileIO is in some ways vestigial to make it easy for ""Local FileSystem"" based Java tests to work without having to mock out a fake credential-vending flow. We might want to refactor `BasePolarisCatalog` a bit to fast-fail if `BasePolarisTableOperations::io()` is ever used without being initialized with a `refreshIOWithCredentials` one way or another.

This will also require some consideration for how the `validateNoLocationOverlap` enforcement works, and also `validateLocationForTableLike` so that it can't be abused to load metadata JSON files residing outside of the StorageConfiguration's ALLOWED_LOCATIONS.

I'll try to draft a fix for this tomorrow.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JeTw7/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/156,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JoSwY,polaris,2309041176,156,NA,dennishuo,7410123,Dennis Huo,,NA,2024-08-25T23:33:45Z,2024-08-25T23:33:45Z,"Got a bit delayed from working on this, but I think I've at least gotten to a clear picture of how we might want to segregate scenarios for how callers can interact with `BasePolarisCatalog` to obtain a `FileIO` instance.

Mostly just thinking out loud here for posterity - one problem is that since we wanted to leverage `BaseMetastoreCatalog` to avoid re-implementing all the `TableOperations` logic, there's potential for conflating things that are supposed to happen logically on the ""client-side"" vs on the ""service-side"".

Basically we run the base Iceberg CatalogTests and View equivalents in two modes:

- `PolarisRestCatalogIntegrationTest` - end-to-end logic that plumbs `CatalogTests` through a `RESTSessionCatalog` so that `BasePolarisCatalog` is only ever used for ""server-side"" actions (e.g. only needs to interact with metadata JSON files)
- `BasePolarisCatalogTest` - directly points `CatalogTests` at the `BasePolarisCatalog` as if it's a traditional client-side-defined Iceberg catalog where ""local"" Transaction objects are used and `TableOperations::io()` is used for the FileIOs that potentially interact with manifest files and manifest-list files

Roughly, there are three categories of tests to consider:

1. Tests that use the `BasePolarisCatalog` to obtain a ""client-local"" FileIO -- these should either manually create a FileIO for pre-creating data or can go through a config setting that forces `BasePolarisCatalog` to create a ""defaultFileIO"" using `catalogProperties`.
2. Tests which go through the full REST plumbing but need the ""server-side"" Catalog to still use special or mocked FileIO settings. For example, `PolarisSparkIntegrationTest` uses `S3MockContainer` and needs to be able to set `s3.endpoint` int he catalog config
3. Tests which go through the full REST plumbing and fully cooperate with ""standard"" credential-vending semantics and/or use only `file:///` paths. These should work without needing to fall back to `catalogProperties` nor rely on `defaultFileIO`

Right now these rely on a lot of silent fallthrough behaviors, but we should make them more explicit. Supporting (2) more explicitly may also be the key to supporting https://github.com/apache/polaris/issues/69 in a cleaner way.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JoSwY/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/156,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JurHO,polaris,2310713806,156,NA,ambaricloud,76875925,Satya KONDAPALLI,skondapalli@ambaricloud.com,NA,2024-08-26T17:31:51Z,2024-08-26T17:31:51Z,Can we test this in snowflake-managed Polaris account?,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JurHO/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/166,https://api.github.com/repos/apache/polaris/issues/166,polaris,2474755581,166,[BUG]Data folder is not getting listed with storage type FILE,shraddhagrawal,102943021,Shraddha Agrawal,,CLOSED,2024-08-20T05:34:48Z,2024-11-07T20:58:13Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

We are not able to see data folder created with storage type file and metadata folder have only metadata files and manifest list and manifest files are also not getting listed.
I am able to query table 
https://github.com/polaris-catalog/polaris?tab=readme-ov-file#connecting-from-an-engine


### To Reproduce

1. https://github.com/polaris-catalog/polaris?tab=readme-ov-file#building-and-running
2. https://github.com/polaris-catalog/polaris?tab=readme-ov-file#connecting-from-an-engine
3. create namespace and table using spark 
4. check temp folder and check files in metadata folder

### Actual Behavior

data folder is missing for table

### Expected Behavior

data folder and manifest list and manifest files should be listed and visible

### Additional context

_No response_

### System information

macOs","{""url"": ""https://api.github.com/repos/apache/polaris/issues/166/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/166,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JxgHq,polaris,2311455210,166,NA,MonkeyCanCode,29619290,,,NA,2024-08-27T02:37:15Z,2024-08-27T02:37:15Z,"Hello,

I am able to run this locally and here are what I did:
```
# (on terminal 1) start the application
./gradlew runApp

# (on terminal 2) create catalog, catalog role, principal, principal, grant, and namespace
export CLIENT_ID=xxxxx
export CLIENT_SECRET=xxxxx
./polaris catalogs create --storage-type file --default-base-location file:///tmp/test quickstart_catalog
./polaris principals create quickstart_user
./polaris principal-roles create quickstart_user_role
./polaris catalog-roles create --catalog quickstart_catalog quickstart_catalog_role
./polaris principal-roles grant --principal quickstart_user quickstart_user_role
./polaris catalog-roles grant --catalog quickstart_catalog --principal-role quickstart_user_role quickstart_catalog_role
./polaris privileges catalog grant --catalog quickstart_catalog --catalog-role quickstart_catalog_role CATALOG_MANAGE_CONTENT
./polaris namespaces create --catalog quickstart_catalog quickstart_namespace

# (on terminal 2) setup spark and default spark conf (sample spark conf below with credential from principal quickstart_user obtain from previous step)
spark.sql.catalog.spark_catalog org.apache.iceberg.spark.SparkSessionCatalog
spark.jars.packages org.apache.iceberg:iceberg-spark-runtime-3.5_2.13:1.5.0,org.apache.hadoop:hadoop-aws:3.4.0,software.amazon.awssdk:bundle:2.23.19,software.amazon.awssdk:url-connection-client:2.23.19
spark.sql.iceberg.vectorization.enabled false
spark.sql.catalog.polaris.type rest
spark.sql.catalog.polaris org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.polaris.uri http://localhost:8181/api/catalog
spark.sql.catalog.polaris.token-refresh-enabled true
spark.sql.catalog.polaris.credential xxxxx:xxxxx
spark.sql.catalog.polaris.warehouse quickstart_catalog
spark.sql.catalog.polaris.scope PRINCIPAL_ROLE:ALL
spark.sql.catalog.polaris.header.X-Iceberg-Access-Delegation true
spark.sql.catalog.polaris.io-impl org.apache.iceberg.io.ResolvingFileIO

# (on terminal 2) create table via pyspark
>>> spark.sql(""use polaris"")
DataFrame[]
>>> spark.sql(""use quickstart_namespace"")
DataFrame[]
>>> spark.sql(""create table test_tbl (id int, value int)"")
DataFrame[]

# (on terminal 3) check fs path
xxxxx@DESKTOP:~/polaris(main)$ ls -l /tmp/test
total 4
drwxr-xr-x 3 yong yong 4096 Aug 26 21:30 quickstart_namespace
xxxxx@DESKTOP:~/polaris(main)$ ls -l /tmp/test/quickstart_namespace/
total 4
drwxr-xr-x 3 yong yong 4096 Aug 26 21:30 test_tbl
xxxxx@DESKTOP:~/polaris(main)$ ls -l /tmp/test/quickstart_namespace/test_tbl/
total 4
drwxr-xr-x 2 yong yong 4096 Aug 26 21:30 metadata

# (on terminal 2) insert dummy record
>>> spark.sql(""insert into test_tbl values(1,2)"")
DataFrame[]

# (on terminal 3) check fs path
xxxxx@DESKTOP:~/polaris(main)$ ls -l /tmp/test/quickstart_namespace/test_tbl/data/
total 4
-rw-r--r-- 1 yong yong 608 Aug 26 21:31 00000-0-063831d9-208d-4cc0-9cae-f316edff15c1-0-00001.parquet
xxxxx@DESKTOP:~/polaris(main)$ ls -l /tmp/test/quickstart_namespace/test_tbl/metadata/
total 24
-rw-r--r-- 1 yong yong 1028 Aug 26 21:30 00000-16559417-6d2b-481e-a4df-72cf8a17f9f6.metadata.json
-rw-r--r-- 1 yong yong 2111 Aug 26 21:31 00001-5124a0c6-6ebd-420f-a6e7-5c3b78b2f3c2.metadata.json
-rw-r--r-- 1 yong yong 6669 Aug 26 21:31 8a607974-9597-48ea-9471-3299891dd0a0-m0.avro
-rw-r--r-- 1 yong yong 4234 Aug 26 21:31 snap-7058842161523378569-1-8a607974-9597-48ea-9471-3299891dd0a0.avro
```

@shraddhagrawal can u try the step above and see if u still see the issue?
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JxgHq/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/166,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6OxUJd,polaris,2395292253,166,NA,MonkeyCanCode,29619290,,,NA,2024-10-06T04:45:24Z,2024-10-06T04:45:24Z,"@shraddhagrawal is this still a problem? If not, should we close the issue ticket (@flyrain)?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6OxUJd/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/166,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6S0WzQ,polaris,2463198416,166,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-11-07T20:58:08Z,2024-11-07T20:58:08Z,"Closing for now, but @shraddhagrawal please re-open if you're still seeing an issue here. Thanks for reporting, and thanks @MonkeyCanCode for looking into this!","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6S0WzQ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/171,https://api.github.com/repos/apache/polaris/issues/171,polaris,2478745194,171,[FEATURE REQUEST] Update the access boundary rules limit,flyrain,1322359,Yufei Gu,yufei@apache.org,OPEN,2024-08-21T18:36:11Z,2024-08-23T16:41:59Z,"### Is your feature request related to a problem? Please describe.

_No response_

### Describe the solution you'd like

Update the limit to 10 per google's doc, https://cloud.google.com/iam/docs/downscoping-short-lived-credentials, and the related comment.

> A Credential Access Boundary can contain up to 10 access boundary rules. You can apply only one Credential Access Boundary to each short-lived credential.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/171/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/171,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JQMVs,polaris,2302723436,171,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-08-21T18:37:23Z,2024-08-21T18:37:23Z,The original slack thread: https://apache-iceberg.slack.com/archives/C07HADW86HZ/p1724091181546359,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JQMVs/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/171,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JeZWC,polaris,2306446722,171,NA,snazy,957468,Robert Stupp,,NA,2024-08-23T07:14:27Z,2024-08-23T07:14:27Z,@flyrain is this a problem in the implementation?,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JeZWC/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/171,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JiME7,polaris,2307440955,171,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-08-23T16:41:58Z,2024-08-23T16:41:58Z,"The current limit(8) is fine, as it is less than the real limit(10).","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JiME7/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/194,https://api.github.com/repos/apache/polaris/issues/194,polaris,2482021034,194,[FEATURE REQUEST]Service Connection Per namespace in a catalog,chetan-habu,107653462,chetan urkudkar,,CLOSED,2024-08-23T00:31:21Z,2024-10-04T21:14:19Z,"### Is your feature request related to a problem? Please describe.

Restrict access to tables in a namespace to a service connection

### Describe the solution you'd like

I want to create one catalog and multiple child namespaces under a parent namespace. Each namespace will have their own service connection and individual service connection can only talk to catalog data in the namespace.

### Describe alternatives you've considered

I would have to create a catalog ,namespace and service connection inorder to provide limited access to a single service connection

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/194/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/194,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JkJ-A,polaris,2307956608,194,NA,sfc-gh-ygu,175990617,Yufei Gu,,NA,2024-08-24T00:32:43Z,2024-08-24T00:32:43Z,"I'm not sure I understand completely, but you can create the `catalog roles` with specific privileges on a single namespace. The concept `catalog role` can be a group of privileges on namespace/table/view/catalog. Here is the RBAC example for reference, https://polaris.io/#tag/Access-Control/RBAC-example
 
![image](https://github.com/user-attachments/assets/45cda16c-8d6d-4ecd-b0b3-6181be4f408b)


For example, you can create catalog roles like `ns1_admin`,  `ns1_readonly`, `ns2_admin`, etc.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JkJ-A/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/194,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JtG9n,polaris,2310303591,194,NA,chetan-habu,107653462,chetan urkudkar,,NA,2024-08-26T14:05:21Z,2024-08-26T14:05:21Z,"Thanks . Creating catalog roles per namespace should help take care of our usecases. Are there any limits to the number of principal roles, catalog roles and catalog per polaris instance or per catalog.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JtG9n/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/194,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JudLb,polaris,2310656731,194,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-08-26T16:59:40Z,2024-08-26T16:59:40Z,I don't think there will be limitations on these numbers. cc @dennishuo @collado-mike @eric-maynard  for more details.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JudLb/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/194,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JwnaN,polaris,2311222925,194,NA,chetan-habu,107653462,chetan urkudkar,,NA,2024-08-26T22:33:03Z,2024-08-26T22:33:03Z,"@flyrain I was able to use your suggestion and create catalog role per namespace and then map it later to a principal role and service principal. I am using Snowflake managed polaris to create all the desired configurations. Do you have any idea how I could get the service admin credentials. I want to use APIs to create catalog ,namespace and other polaris related configurations but the only way I am able to do that is get the token from the network tab and use that to invoke APIs.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6JwnaN/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/194,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Jwt8U,polaris,2311249684,194,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-08-26T22:56:49Z,2024-08-26T22:56:49Z,"Hey @chetan-habu, if you have questions about a vendor-managed offering please reach out to that vendor. With Apache Polaris, you can view the root credentials during bootstrapping.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Jwt8U/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/194,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6J6i59,polaris,2313825917,194,NA,collado-mike,40346148,Michael Collado,,NA,2024-08-28T00:30:30Z,2024-08-28T00:30:30Z,"Snowflake's Polaris doesn't yet let you do this, but the functionality exists in the OSS project. Unsure when the feature will be released in the managed Polaris offering.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6J6i59/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/194,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KBcmr,polaris,2315635115,194,NA,chetan-habu,107653462,chetan urkudkar,,NA,2024-08-28T15:10:26Z,2024-08-28T15:10:26Z,"Thanks team. Can you help provide some more insights to the following questions if any.

- limits to the number of catalogs we can create in a polaris instance
- Number of namespaces/sub namespaces a catalog can have
- catalog roles per namespace
- service principals.

We plan to create a catalog and then namespaces are our logical grouping . Each namespace would be associated with a catalog role which allows access to the namespace tables only. the catalog role will have an associated service principal. We would leverage the apis from the documentation to create the whole piece and hence the ask on the limits .","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KBcmr/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/194,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Olyjh,polaris,2392271073,194,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-10-03T20:26:28Z,2024-10-03T20:26:28Z,"Hey @chetan-habu, following up on the above:

* limits to the number of catalogs we can create in a polaris instance
  - Currently, there is no limit. You might hit practical limits on the metastore side depending on your implementation

* Number of namespaces/sub namespaces a catalog can have
  - Same as the above

* catalog roles per namespace
  - Same as the above

* service principals.
  - Currently, Polaris doesn't really have a concept of a service principal, but you can create as many principals as you wish.

As you can see, Polaris itself doesn't have hard limits on the number of entities you can create right now. But since everything is stored in the metastore, there could be practical limits on some entities. In particular, some checks we do to ensure path uniqueness or that catalog paths don't overlap are linear or worse time in the eclipse-link metastore.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Olyjh/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/194,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Ou-qg,polaris,2394679968,194,NA,chetan-habu,107653462,chetan urkudkar,,NA,2024-10-04T21:14:19Z,2024-10-04T21:14:19Z,"Thank you , this helps. Closing the issue","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Ou-qg/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/196,https://api.github.com/repos/apache/polaris/issues/196,polaris,2483475864,196,[DOCS] Rename Polaris Catalog to Apache Polaris in .md docs,sfc-gh-annafilippova,153564718,Anna Filippova,,CLOSED,2024-08-23T16:25:48Z,2024-08-26T09:05:20Z,"### Is your feature request related to a problem? Please describe.

Markdown docs still reference Polaris Catalog. We need to rename these references to Apache Polaris instead for page titles and most important references, or Polaris in subsequent references, based on https://www.apache.org/foundation/marks/pmcs#branding 

### Describe the solution you'd like

_No response_

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/196/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/214,https://api.github.com/repos/apache/polaris/issues/214,polaris,2488327127,214,[FEATURE REQUEST] Add Support for S3A prefix,TheerachotTle,77727884,Theerachot,,OPEN,2024-08-27T05:40:46Z,2024-09-05T00:04:32Z,"### Is your feature request related to a problem? Please describe.

I have set the allowed location of the created catalog to S3 storage type using `s3://` prefix. When I run `remove_orphan_files` procedure in Spark, it results in an error message: `No FileSystem for scheme ""s3""`.  To solve this problem, I attempted to create the catalog with the `s3a://` prefix, but I received a 400 Bad Request error with the message: `Location prefix not allowed`.
Here's my spark configuration
```
spark = SparkSession.builder \
            .config(""spark.jars.packages"",""org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.2,org.apache.iceberg:iceberg-aws-bundle:1.5.2,org.apache.hadoop:hadoop-aws:3.4.0,org.apache.hadoop:hadoop-common:3.4.0"") \
            .config(""spark.sql.extensions"", ""org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions"") \
            .config('spark.sql.catalog.polaris.header.X-Iceberg-Access-Delegation', 'true') \
            .config(""spark.sql.catalog.polaris.uri"", POLARIS_URI) \
            .config(""spark.sql.catalog.polaris.type"", ""rest"") \
            .config(""spark.sql.catalog.polaris"", ""org.apache.iceberg.spark.SparkCatalog"") \
            .config(""spark.sql.catalog.polaris.warehouse"", POLARIS_CATALOG_NAME) \
            .config(""spark.sql.catalog.polaris.io-impl"", ""org.apache.iceberg.aws.s3.S3FileIO"") \
            .config(""spark.hadoop.fs.s3a.impl"", ""org.apache.hadoop.fs.s3a.S3AFileSystem"") \
            .config('spark.sql.catalog.polaris.credential', POLARIS_CREDENTIALS) \
            .config('spark.sql.catalog.polaris.scope', POLARIS_SCOPE) \
            .config('spark.sql.catalog.polaris.token-refresh-enabled', 'true') \
            .getOrCreate()
```

### Describe the solution you'd like

Probably add the s3a:// prefix as an alternative for the S3 storage type.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/214/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/214,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6J3ViQ,polaris,2312984720,214,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-08-27T16:10:45Z,2024-08-27T16:10:45Z,"Do other DMLs(e.g., insert, delete)work? Can you share the stack of the error?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6J3ViQ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/214,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6J3WwO,polaris,2312989710,214,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-08-27T16:13:00Z,2024-08-27T16:13:00Z,"Can you remove this config and try again?
```
            .config(""spark.sql.catalog.polaris.io-impl"", ""org.apache.iceberg.aws.s3.S3FileIO"") 
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6J3WwO/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/214,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6J4Upv,polaris,2313243247,214,NA,TheerachotTle,77727884,Theerachot,,NA,2024-08-27T18:29:32Z,2024-08-27T18:29:32Z,"Yes, the other DML commands work as expected, and I also removed the config above, but it still results in an error. This is the code I ran
`spark.sql(""""""CALL polaris.system.remove_orphan_files(table => 'polaris.namespace.table')"""""").show()`
Here's the error.
```
Py4JJavaError: An error occurred while calling o48.sql.
: java.io.UncheckedIOException: org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme ""s3""
at org.apache.iceberg.spark.actions.DeleteOrphanFilesSparkAction.listDirRecursively(DeleteOrphanFilesSparkAction.java:386)
at org.apache.iceberg.spark.actions.DeleteOrphanFilesSparkAction.listedFileDS(DeleteOrphanFilesSparkAction.java:311)
at org.apache.iceberg.spark.actions.DeleteOrphanFilesSparkAction.actualFileIdentDS(DeleteOrphanFilesSparkAction.java:296)
at org.apache.iceberg.spark.actions.DeleteOrphanFilesSparkAction.doExecute(DeleteOrphanFilesSparkAction.java:247)
at org.apache.iceberg.spark.JobGroupUtils.withJobGroupInfo(JobGroupUtils.java:59)
at org.apache.iceberg.spark.JobGroupUtils.withJobGroupInfo(JobGroupUtils.java:51)
at org.apache.iceberg.spark.actions.BaseSparkAction.withJobGroupInfo(BaseSparkAction.java:130)
at org.apache.iceberg.spark.actions.DeleteOrphanFilesSparkAction.execute(DeleteOrphanFilesSparkAction.java:223)
at org.apache.iceberg.spark.procedures.RemoveOrphanFilesProcedure.lambda$call$3(RemoveOrphanFilesProcedure.java:185)
at org.apache.iceberg.spark.procedures.BaseProcedure.execute(BaseProcedure.java:107)
at org.apache.iceberg.spark.procedures.BaseProcedure.withIcebergTable(BaseProcedure.java:96)
at org.apache.iceberg.spark.procedures.RemoveOrphanFilesProcedure.call(RemoveOrphanFilesProcedure.java:139)
at org.apache.spark.sql.execution.datasources.v2.CallExec.run(CallExec.scala:34)
at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)
at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)
at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)
at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)
at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)
at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)
at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)
at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)
at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)
at org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)
at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)
at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
at java.base/java.lang.reflect.Method.invoke(Method.java:580)
at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
at py4j.Gateway.invoke(Gateway.java:282)
at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
at py4j.commands.CallCommand.execute(CallCommand.java:79)
at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme ""s3""
at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3443)
at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)
at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)
at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)
at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)
at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)
at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)
at org.apache.iceberg.spark.actions.DeleteOrphanFilesSparkAction.listDirRecursively(DeleteOrphanFilesSparkAction.java:356)
... 55 more
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6J4Upv/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/214,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6J4z5T,polaris,2313371219,214,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-08-27T19:42:49Z,2024-08-27T19:42:49Z,"@TheerachotTle I think the issue is this config:
```
            .config(""spark.hadoop.fs.s3a.impl"", ""org.apache.hadoop.fs.s3a.S3AFileSystem"") \
```

If you refer to the [quickstart guide](https://github.com/apache/polaris/blob/main/docs/quickstart.md#connecting-with-spark), it gives an example of Spark configs that can be used to connect to an Iceberg REST catalog.

Having said that, I think `s3a` support is a reasonable feature request
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6J4z5T/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/214,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6J6zhF,polaris,2313893957,214,NA,mayankvadariya,48036907,Mayank Vadariya,,NA,2024-08-28T01:14:38Z,2024-08-28T01:14:38Z,">the other DML commands work as expected

if this is specific to `remove_orphan_files`, lets change the title to reflect it.
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6J6zhF/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/214,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KAWeO,polaris,2315347854,214,NA,TheerachotTle,77727884,Theerachot,,NA,2024-08-28T13:38:44Z,2024-08-28T13:38:44Z,"> If you refer to the [quickstart guide](https://github.com/apache/polaris/blob/main/docs/quickstart.md#connecting-with-spark), it gives an example of Spark configs that can be used to connect to an Iceberg REST catalog.

Removing the config and it still doesn't work. From my understanding, the remove_orphan_files operation involves file listing to determine which files should be removed, and the Spark procedure uses Hadoop FS to perform listing operations.

> if this is specific to `remove_orphan_files`, lets change the title to reflect it.

I have tried this procedure with other Iceberg catalogs, and it has the same problem when using the s3:// prefix. I'm not sure if the title should be changed to be about this procedure?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KAWeO/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/214,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KCTzo,polaris,2315861224,214,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-08-28T17:04:57Z,2024-08-28T17:04:57Z,"> the Spark procedure uses Hadoop FS to perform listing operations.

Yup, I'm guessing the failure is triggered due to procedure is using the Spark Hadoop FS while other DML commands use the FileIO from the iceberg catalog. It more likely a config thing than a bug, but I need to take a close look. Would you share a way to to reproduce it? for example, the spark version and config, and the command used to call the procedure.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KCTzo/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/214,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KCycq,polaris,2315986730,214,NA,TheerachotTle,77727884,Theerachot,,NA,2024-08-28T18:18:13Z,2024-08-28T18:18:13Z,"I'm using spark 3.5.0
create catalog with POST request
```
{""name"": ""testcatalog"", ""type"": ""INTERNAL"", ""properties"": {
        ""default-base-location"": ""s3://bucket/folder/""
    },""storageConfigInfo"": {
        ""roleArn"": ""arn:aws:iam::xxxxxxxxx:role/demo-polaris"",
        ""storageType"": ""S3"",
        ""allowedLocations"": [
            ""s3://bucket/folder""
        ]
    } }
```
config of spark
```
spark = SparkSession.builder \
            .config(""spark.jars.packages"",""org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.2,org.apache.iceberg:iceberg-aws-bundle:1.5.2,org.apache.hadoop:hadoop-aws:3.4.0,org.apache.hadoop:hadoop-common:3.4.0"") \
            .config(""spark.sql.extensions"", ""org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions"") \
            .config('spark.sql.catalog.polaris.header.X-Iceberg-Access-Delegation', 'true') \
            .config(""spark.sql.catalog.polaris.uri"", POLARIS_URI) \
            .config(""spark.sql.catalog.polaris.type"", ""rest"") \
            .config(""spark.sql.catalog.polaris"", ""org.apache.iceberg.spark.SparkCatalog"") \
            .config(""spark.sql.catalog.polaris.warehouse"", POLARIS_CATALOG_NAME) \
            .config(""spark.sql.catalog.polaris.io-impl"", ""org.apache.iceberg.aws.s3.S3FileIO"") \
            .config(""spark.hadoop.fs.s3a.impl"", ""org.apache.hadoop.fs.s3a.S3AFileSystem"") \
            .config('spark.sql.catalog.polaris.credential', POLARIS_CREDENTIALS) \
            .config('spark.sql.catalog.polaris.scope', POLARIS_SCOPE) \
            .config('spark.sql.catalog.polaris.token-refresh-enabled', 'true') \
            .getOrCreate()
```
code to reproduce
```
spark.sql(""USE polaris"")
spark.sql(""USE NAMESPACE namespace1"")
spark.sql(""""""CREATE TABLE IF NOT EXISTS table1 (
    id bigint NOT NULL COMMENT 'unique id',
    data string)
USING iceberg
LOCATION ""s3://bucket/folder/namespace1/table1""
"""""")
spark.sql(""INSERT INTO table1 VALUES (1,'test')"")
spark.sql(""""""CALL polaris.system.remove_orphan_files(
  table => 'polaris.namespace1.table1'
  )
"""""").show()
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KCycq/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/214,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KDu8G,polaris,2316234502,214,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-08-28T20:54:18Z,2024-08-28T20:54:18Z,"This is an Iceberg issue instead of a Polaris one. To summarize, DML commands and procedures usually use `FileIO` object provided by the catalog for read and write files. However, the procedure `RemoveOrphanFile` uses the [Spark configuration](https://github.com/apache/iceberg/blob/79620e198009fa243c278c66fd442d107b46206a/spark/v3.5/spark/src/main/java/org/apache/iceberg/spark/actions/DeleteOrphanFilesSparkAction.java#L356-L356) to get the FileSystem object for listing, which is a Hadoop s3a File System. It couldn't recognize the `s3://`. Solutions would be 
1. Using catalog `FileIO` instead of the File System from Spark config. `ResolvingFileIO` is the default one used by REST catalog, which delegates to `S3FileIO` in this case, [it supports `listPrefix`](https://github.com/apache/iceberg/blob/79620e198009fa243c278c66fd442d107b46206a/aws/src/main/java/org/apache/iceberg/aws/s3/S3FileIO.java#L299-L299). This requires code change in the procedure.
2. Using aws s3 client instead of Hadoop s3a client in Spark, I guess this only needs a config change, I'm not familiar with that though. Recommend to check with the Iceberg community.

","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KDu8G/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/214,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KIinq,polaris,2317494762,214,NA,anuragmantri,13743212,Anurag Mantripragada,,NA,2024-08-29T12:20:02Z,2024-08-29T12:20:02Z,"Here is another old thread on Iceberg slack about this issue 

https://apache-iceberg.slack.com/archives/C025PH0G1D4/p1636652647457600?thread_ts=1636639133.442800&cid=C025PH0G1D4

> RemoveOrphanFiles is probably the only procedure that requires HadoopFileSystem in Iceberg, because it has to scan the entire storage and Icebergâ€™s FileIO interface as of today does not have a list-flavor API

Since listPrefix is now available, maybe we can update the procedure to use FileIO. I will create an issue in Iceberg.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KIinq/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/214,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KImfD,polaris,2317510595,214,NA,anuragmantri,13743212,Anurag Mantripragada,,NA,2024-08-29T12:27:01Z,2024-08-29T12:27:01Z,"Oh great! There is already a PR for this.
https://github.com/apache/iceberg/pull/7914","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KImfD/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/214,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KLMdp,polaris,2318190441,214,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-08-29T15:44:21Z,2024-08-29T15:44:21Z,"Thanks @anuragmantri for chiming in. It'd be ideal to use Iceberg `FileIO` in `removeOrphanFile`, so that we don't have to config Spark file system differently, which is a duplication to avoid. I will take a look at the Iceberg PR. 

We will still need a workaround at this moment though, as the Iceberg change and release will take a while. You can customize your iceberg lib of course, but not every user is able to do that. @dennishuo mentioned a workaround [here](https://apache-iceberg.slack.com/archives/C07HADW86HZ/p1724909442884259?thread_ts=1724680467.488829&cid=C07HADW86HZ).  It doesn't work for me locally, but worth to try. cc @TheerachotTle 
```
spark.hadoop.fs.s3.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.AbstractFileSystem.s3.impl=org.apache.hadoop.fs.s3a.S3A
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KLMdp/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/214,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KLv8e,polaris,2318335774,214,NA,yassan,1228531,yassan,,NA,2024-08-29T16:42:24Z,2024-08-29T16:42:24Z,How about replacing `s3://` with `s3a://` and configuring `spark.sql.catalog.polaris.io-imp` to use `org.apache.iceberg.io.ResolvingFileIO` ?,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KLv8e/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/214,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KWRHp,polaris,2321093097,214,NA,TheerachotTle,77727884,Theerachot,,NA,2024-08-30T12:30:48Z,2024-08-30T12:30:48Z,">How about replacing s3:// with s3a:// 

Polaris doesn't allow me to create a catalog with this prefix.
> spark.hadoop.fs.s3.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
> spark.hadoop.fs.AbstractFileSystem.s3.impl=org.apache.hadoop.fs.s3a.S3A

With this config, I can use remove_orphan_files without any error.

","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KWRHp/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/214,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6K5kzH,polaris,2330348743,214,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-09-05T00:04:30Z,2024-09-05T00:04:30Z,"Let's document it before it is fixed in the Iceberg side, actually it should be documented in Iceberg side. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6K5kzH/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/217,https://api.github.com/repos/apache/polaris/issues/217,polaris,2490437055,217,[BUG] The existing local derby directory fails the catalog creation,flyrain,1322359,Yufei Gu,yufei@apache.org,CLOSED,2024-08-27T21:52:32Z,2024-09-02T12:42:48Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

Here are stack traces. The issue is resolved by deleting the derby dir. We may clean up it very time we run the app.
```
Caused by: java.sql.SQLException: Failed to create database 'metastore_db', see the next exception for details.
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.createDatabase(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
	... 92 more
Caused by: ERROR XJ041: Failed to create database 'metastore_db', see the next exception for details.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
	... 108 more
Caused by: ERROR XBM0A: The database directory '/private/tmp/derby/metastore_db' exists. However, it does not contain the expected 'service.properties' file. Perhaps Derby was brought down in the middle of creating this database. You may want to delete this directory and try creating the database again.
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
	at org.apache.derby.impl.services.monitor.StorageFactoryService.vetService(Unknown Source)
	at org.apache.derby.impl.services.monitor.StorageFactoryService.access$900(Unknown Source)
	at org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
	at org.apache.derby.impl.services.monitor.StorageFactoryService.createServiceRoot(Unknown Source)
	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
	at org.apache.derby.impl.services.monitor.BaseMonitor.createPersistentService(Unknown Source)
	at org.apache.derby.impl.services.monitor.FileMonitor.createPersistentService(Unknown Source)
	at org.apache.derby.iapi.services.monitor.Monitor.createPersistentService(Unknown Source)
	at org.apache.derby.impl.jdbc.EmbedConnection$5.run(Unknown Source)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
	at org.apache.derby.impl.jdbc.EmbedConnection.createPersistentService(Unknown Source)
	... 105 more
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/217/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/217,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KFPzv,polaris,2316631279,217,NA,MonkeyCanCode,29619290,,,NA,2024-08-29T03:12:56Z,2024-08-29T03:12:56Z,"@flyrain here is  a sample fix: https://github.com/apache/polaris/pull/228

So derby is used by spark by default for metastore management. I am assuming u ran the setup.sh under regtests dir and aborted it in between thus caused an incomplete derby dir to get created. Thus, the following runs with spark will all fail until a manual cleanup is being performed. This PR will cleanup derby home dir if existed.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KFPzv/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/225,https://api.github.com/repos/apache/polaris/issues/225,polaris,2492078482,225,[BUG] Create View command is failing with Spark console,nk1506,4146188,Naveen Kumar,nk1506@gmail.com,CLOSED,2024-08-28T13:26:17Z,2024-09-05T11:07:34Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

`spark-sql ()> create view db1.v1 as select * from db1.table1;

Catalog polaris does not support views.`

","{""url"": ""https://api.github.com/repos/apache/polaris/issues/225/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/225,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KEa6G,polaris,2316414598,225,NA,ebyhr,6237050,Yuya Ebihara,,NA,2024-08-28T23:41:32Z,2024-08-28T23:41:32Z,Does this issue happen even after https://github.com/apache/polaris/pull/216? ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KEa6G/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/225,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KFh5W,polaris,2316705366,225,NA,nk1506,4146188,Naveen Kumar,nk1506@gmail.com,NA,2024-08-29T04:44:21Z,2024-08-29T04:44:21Z,"@ebyhr ,Surprisingly, Iâ€™m still encountering this error with SparkCLI. Iâ€™m currently investigating it. Iâ€™m not sure how to assign this bug to myself. Could you help? ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KFh5W/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/225,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Ks97w,polaris,2327043824,225,NA,collado-mike,40346148,Michael Collado,,NA,2024-09-03T17:15:47Z,2024-09-03T17:15:47Z,You need to enable Iceberg's spark extensions to create views: see https://github.com/apache/polaris/blob/main/regtests/t_pyspark/src/iceberg_spark.py#L97 for example configuration,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Ks97w/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/225,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6K8_RP,polaris,2331243599,225,NA,nk1506,4146188,Naveen Kumar,nk1506@gmail.com,NA,2024-09-05T11:07:34Z,2024-09-05T11:07:34Z,"Thanks @collado-mike for the response. I just tried `./regtests/run_spark_sql.sh` and the following script:
```
create database db1;
show databases;
create table db1.table1 (id int, name string);
insert into db1.table1 values (1, 'a');
select * from db1.table1;
create view db1.v1 as select * from db1.table1;
 ```
 
 But it seems working now. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6K8_RP/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/226,https://api.github.com/repos/apache/polaris/issues/226,polaris,2492461658,226,[BUG] creating an existing principal role assignment returns 500 instead of 409,TomerHeber,12767692,Tomer Heber,,CLOSED,2024-08-28T15:47:10Z,2024-10-03T20:13:59Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

When I try to assign between a principal role and a principal I get 2xx.
If I try to run the same assignment again (conflict) I will get 5xx.

### To Reproduce

1. Create a principal.
2. Create a principal role.
3. Assign role to principal.
4. Assign role to principal (again).

### Actual Behavior

500 error.

```
{
    ""error"": {
        ""message"": ""Exception [EclipseLink-4002] (Eclipse Persistence Services - 4.0.3.v202405220658): org.eclipse.persistence.exceptions.DatabaseException\nInternal Exception: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \""grant_records_pkey\""\n  Detail: Key (granteecatalogid, privilegecode, granteeid, securableid, securablecatalogid)=(0, 4, 1599, 1149, 0) already exists.\nError Code: 0\nCall: INSERT INTO GRANT_RECORDS (GRANTEECATALOGID, PRIVILEGECODE, GRANTEEID, SECURABLEID, SECURABLECATALOGID, VERSION) VALUES (?, ?, ?, ?, ?, ?)\n\tbind => [0, 4, 1599, 1149, 0, 1]\nQuery: InsertObjectQuery(org.apache.polaris.core.persistence.models.ModelGrantRecord@5780643b)"",
        ""type"": ""PersistenceException"",
        ""code"": 500
    }
}
```

### Expected Behavior

409 - conflict.

### Additional context

_No response_

### System information

N/A","{""url"": ""https://api.github.com/repos/apache/polaris/issues/226/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/226,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Ksz_Q,polaris,2327003088,226,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-09-03T16:52:37Z,2024-09-03T16:52:37Z,"Can you share more details on how you hit this?

I configured my Polaris to use a local Postgres instance, purge+bootstrapped it, and then ran the following without seeing an error:

```
./polaris \
	--access-token 'principal:root;realm:default-realm' \
	catalogs \
	create example_catalog \
	--storage-type file \
	--default-base-location 'file:///tmp/example'

./polaris \
	--access-token 'principal:root;realm:default-realm' \
	principals \
	create \
	example_user

./polaris \
	--access-token 'principal:root;realm:default-realm' \
	principal-roles \
	create \
	example_user_role

./polaris \
	--access-token 'principal:root;realm:default-realm' \
	principal-roles \
	grant \
	--principal example_user \
	example_user_role

./polaris \
	--access-token 'principal:root;realm:default-realm' \
	principal-roles \
	grant \
	--principal example_user \
	example_user_role
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Ksz_Q/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/226,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KtHaX,polaris,2327082647,226,NA,TomerHeber,12767692,Tomer Heber,,NA,2024-09-03T17:38:55Z,2024-09-03T17:38:55Z,"Hi @eric-maynard - my apologies .
I did not mention it.

This is with the EclipseLink plugin.
By the way, the same error occurs with other resources.
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KtHaX/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/226,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KtZxF,polaris,2327157829,226,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-09-03T18:25:59Z,2024-09-03T18:25:59Z,"Thanks for clarifying @TomerHeber, I don't know how I missed that. I pushed a PR that should be a simple fix, but I'm going to look at see if there are other places we need a similar fix too. Thanks for filing this!","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KtZxF/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/230,https://api.github.com/repos/apache/polaris/issues/230,polaris,2495157346,230,[FEATURE REQUEST] Add the doc on how to configure Postgres as the backend database,aihuaxu,26491691,Aihua Xu,aihuaxu@gmail.com,CLOSED,2024-08-29T17:37:57Z,2024-09-17T23:26:54Z,"### Is your feature request related to a problem? Please describe.

Currently we don't have instruction on how to configure Postgres right now.

### Describe the solution you'd like

_No response_

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/230/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/230,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KPWEZ,polaris,2319278361,230,NA,loicalleyne,6126243,,,NA,2024-08-29T23:02:13Z,2024-08-29T23:02:13Z,"Slight modification of [https://github.com/apache/polaris/blob/main/extension/persistence/eclipselink/src/main/resources/META-INF/persistence.xml](https://github.com/apache/polaris/blob/main/extension/persistence/eclipselink/src/main/resources/META-INF/persistence.xml)

```
<?xml version=""1.0"" encoding=""UTF-8""?>
<persistence version=""2.0"" xmlns=""http://java.sun.com/xml/ns/persistence""
  xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
  xsi:schemaLocation=""http://java.sun.com/xml/ns/persistence http://java.sun.com/xml/ns/persistence/persistence_2_0.xsd"">

  <persistence-unit name=""polaris"" transaction-type=""RESOURCE_LOCAL"">
    <provider>org.eclipse.persistence.jpa.PersistenceProvider</provider>
    <class>org.apache.polaris.core.persistence.models.ModelEntity</class>
    <class>org.apache.polaris.core.persistence.models.ModelEntityActive</class>
    <class>org.apache.polaris.core.persistence.models.ModelEntityChangeTracking</class>
    <class>org.apache.polaris.core.persistence.models.ModelEntityDropped</class>
    <class>org.apache.polaris.core.persistence.models.ModelGrantRecord</class>
    <class>org.apache.polaris.core.persistence.models.ModelPrincipalSecrets</class>
    <class>org.apache.polaris.core.persistence.models.ModelSequenceId</class>
    <shared-cache-mode>NONE</shared-cache-mode>
    <properties>
      <property name=""jakarta.persistence.jdbc.url""
        value=""jdbc:postgres://enter_your_db_host_here:5432/{realm}""/>
      <property name=""jakarta.persistence.jdbc.user"" value=""enter_your_postgres_user""/>
      <property name=""jakarta.persistence.jdbc.password"" value=""enter_your_postgres_user_password""/>
      <property name=""jakarta.persistence.schema-generation.database.action"" value=""create""/>
      <property name=""eclipselink.logging.level.sql"" value=""FINE""/>
      <property name=""eclipselink.logging.parameters"" value=""true""/>
      <property name=""eclipselink.persistence-context.flush-mode"" value=""auto""/>
    </properties>
  </persistence-unit>
</persistence>
```
Change the following in polaris-server.yml
```
metaStoreManager:
  # type: in-memory
  type: eclipse-link # uncomment to use eclipse-link as metastore
  persistence-unit: polaris
```
Add the following to polaris\extension\persistence\eclipselink\build.gradle.kts under `dependencies`:
```
implementation(""org.postgresql:postgresql:42.7.4"")
```
Build with `ECLIPSELINK=true` (I changed this in the Dockerfile but there may be a better way)

Remember to run the bootstrap after to create the required tables in the persistence store
```java -jar /path/to/jar/polaris-service-all.jar bootstrap polaris-server.yml```

Afterwards, Polaris can be launched normally:
```java -jar /path/to/jar/polaris-service-all.jar server polaris-server.yml```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KPWEZ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/230,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KQutu,polaris,2319641454,230,NA,MonkeyCanCode,29619290,,,NA,2024-08-30T01:36:27Z,2024-08-30T01:36:27Z,"@aihuaxu @loicalleyne so by default, eclipselink is using 32 max connections. From the testing I done local, the min/init/max connection settings seems to be not working (it will set to max and not scale down as connection sitting idles for long time). I am using following sample settings:
```
<property name=""eclipselink.connection-pool.default.initial"" value=""1""/>
<property name=""eclipselink.connection-pool.default.min"" value=""10""/>
<property name=""eclipselink.connection-pool.default.max"" value=""64""/>
```

I am not sure if that is bug with this version of eclipselink or not. As your guys are adding this example for support, can we check above as well? 

Also, psql driver jar is not part of eclipselink extension, we may want to add a note for this as well. Even better, what if we add support for allow people to load the jars they want dynamically via argument during build? E.g.
```
if (project.properties.get(""additionalDependencies"")) {
  dependencies { implementation(project(project.properties.get(""additionalDependencies""))) }
}
```
then we can do following:
```
./gradlew --no-daemon --info -PeclipseLink=$ECLIPSELINK -PadditionalDependencies=org.postgresql:postgresql:42.7.4 clean shadowJar startScripts
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KQutu/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/230,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KdkLP,polaris,2323006159,230,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-08-31T18:23:42Z,2024-08-31T18:23:42Z,related slack thread: https://apache-iceberg.slack.com/archives/C07HADW86HZ/p1724965902423649,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KdkLP/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/230,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KtHmn,polaris,2327083431,230,NA,aihuaxu,26491691,Aihua Xu,aihuaxu@gmail.com,NA,2024-09-03T17:39:22Z,2024-09-03T17:39:22Z,@MonkeyCanCode Thanks for the detailed information. I haven't tried those connection-pool configuration myself yet. I will do some checks around that.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KtHmn/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/230,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6MUaW3,polaris,2354161079,230,NA,loicalleyne,6126243,,,NA,2024-09-16T22:47:11Z,2024-09-16T22:47:11Z,"I've written a short script to make the changes easier to apply after pulling the repository
requires yq be installed to edit XML and YML files in-place
```
POLARIS_DEFAULT_REALM=polaris
PGSERVER=""jdbc:postgresql://postgres-host:5432/{realm}""
POLARIS_PG_USER=polarisadmin
POLARIS_PG_PASS=polarispassword

yq -i '.persistence.persistence-unit.properties.property[0].+@value = strenv(PGSERVER) | .persistence.persistence-unit.properties.property[1].+@value = strenv(POLARIS_PG_USER) | .persistence.persistence-unit.properties.property[2].+@value = strenv(POLARIS_PG_PASS) | .persistence.persistence-unit.properties.property += { ""+@name"":""jakarta.persistence.jdbc.driver"",""+@value"":""org.postgresql.Driver""}' extension/persistence/eclipselink/src/main/resources/META-INF/persistence.xml

yq -i '.metaStoreManager.type = ""eclipse-link"" | .metaStoreManager += {""persistence-unit"": ""polaris""} | .defaultRealms[0] = strenv(POLARIS_DEFAULT_REALM)' polaris-server.yml

./gradlew --no-daemon --info -PeclipseLink=true -PeclipseLinkDeps=org.postgresql:postgresql:42.7.4 clean prepareDockerDist
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6MUaW3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/233,https://api.github.com/repos/apache/polaris/issues/233,polaris,2495671556,233,[FEATURE REQUEST]Support AI/ML Models,RamachandranSitaraman-IB,150775448,,,OPEN,2024-08-29T22:14:58Z,2024-08-29T22:14:58Z,"### Is your feature request related to a problem? Please describe.

No

### Describe the solution you'd like

Extend the support in a catalog from Data to AI/ML models. The Polaris catalog could facilitate
1.  Storing metadata about models aiding in model discovery
2. Integration with MLFlow client
3. Model provenance
4. Mapping of Models to the data it operates on
5. Storing model performance metrics snapshots
6. Access control on models
7. Model and its data versioning
8. Custom properties associated with models
9. Integration with feature stores
10. Storage and access of policies associated with model usage
11.  Integration with workflow engines

### Describe alternatives you've considered

Have briefly looked at unity catalog, would like to see Polaris supporting AI/ML models too

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/233/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/234,https://api.github.com/repos/apache/polaris/issues/234,polaris,2495882391,234,[BUG]Failed to call procedures in Spark,flyrain,1322359,Yufei Gu,yufei@apache.org,CLOSED,2024-08-30T00:23:45Z,2024-08-30T21:42:19Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

Failed to call procedures in Spark as the following message shows. It is due to a scala version mismatch between Spark and Iceberg lib.
```
scala> spark.sql(""""""call polaris.system.remove_orphan_files(table => 'db1.t1', dry_run => true)"""""").show();
org.apache.spark.sql.catalyst.parser.ParseException:
[PARSE_SYNTAX_ERROR] Syntax error at or near 'call'.(line 1, pos 0)

== SQL ==
call polaris.system.remove_orphan_files(table => 'db1.t1', dry_run => true)
^^^

  at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:257)
  at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:98)
  at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:54)
  at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:68)
  at org.apache.spark.sql.SparkSession.$anonfun$sql$5(SparkSession.scala:684)
  at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
  at org.apache.spark.sql.SparkSession.$anonfun$sql$4(SparkSession.scala:683)
  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
  at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:682)
  at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:713)
  at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:744)
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/234/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/234,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KbCgv,polaris,2322343983,234,NA,ebyhr,6237050,Yuya Ebihara,,NA,2024-08-30T21:12:07Z,2024-08-30T21:12:07Z,https://github.com/apache/polaris/pull/235 is merged. Can we close this issue now? ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6KbCgv/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/241,https://api.github.com/repos/apache/polaris/issues/241,polaris,2503348216,241,[BUG]Bootstrapping errors for MySQL,lrichards-etsy,81712933,,,CLOSED,2024-09-03T16:53:52Z,2024-09-16T20:07:27Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

When running `/app/bin/polaris-service bootstrap polaris-server.yml` against a remote MySQL DB I get the following error:

`Internal Exception: java.sql.SQLSyntaxErrorException: Column length too big for column 'INTERNALPROPERTIES' (max = 16383); use BLOB or TEXT instead`

and nothing gets created in the DB. 
I got past that error by setting a smaller VARCHAR limit for those columns, but hit a second error:

`Internal Exception: java.sql.SQLSyntaxErrorException: FUNCTION <database>.NEXTVAL does not exist` 

### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

Bootstrapping to run without issue 

### Additional context

_No response_

### System information

Connected to a CloudSQL MySQL - version 8

Dependencies needed
```
implementation(""com.google.cloud.sql:mysql-socket-factory-connector-j-8:1.20.0"")
implementation(""com.mysql:mysql-connector-j:8.4.0"")
```
persistence.xml info
```
<property name=""jakarta.persistence.jdbc.url"" value=""jdbc:mysql://google/<database>?cloudSqlInstance=<connection info>&amp;socketFactory=com.google.cloud.sql.mysql.SocketFactory""/>
      <property name=""jakarta.persistence.jdbc.user"" value=""<user>""/>
      <property name=""jakarta.persistence.jdbc.password"" value=""<password>""/>
      <property name=""jakarta.persistence.schema-generation.database.action"" value=""create""/>
      <property name=""eclipselink.logging.level.sql"" value=""FINE""/>
      <property name=""eclipselink.logging.parameters"" value=""true""/>
      <property name=""eclipselink.persistence-context.flush-mode"" value=""auto""/>
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/241/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/241,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Ks8Mo,polaris,2327036712,241,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-09-03T17:11:56Z,2024-09-03T17:11:56Z,"I was able to reproduce this, dumping the full error here:
```
DEBUG [2024-09-03 10:11:25,631 - 536   ] [main] [] o.a.p.e.p.i.e.PolarisEclipseLinkMetaStoreSessionImpl: Create EclipseLink Meta Store Session for default-realm 
[EL Warning]: metadata: 2024-09-03 10:11:25.748--ServerSession(136011184)--You have specified multiple ids for the entity class [org.apache.polaris.core.persistence.models.ModelEntityChangeTracking] without specifying an @IdClass. By doing this you may lose the ability to find by identity, distributed cache support etc. Note: You may however use EntityManager find operations by passing a list of primary key fields. Else, you will have to use JPQL queries to read your entities. For other id options see @PrimaryKey.
[EL Warning]: metadata: 2024-09-03 10:11:25.751--ServerSession(136011184)--You have specified multiple ids for the entity class [org.apache.polaris.core.persistence.models.ModelGrantRecord] without specifying an @IdClass. By doing this you may lose the ability to find by identity, distributed cache support etc. Note: You may however use EntityManager find operations by passing a list of primary key fields. Else, you will have to use JPQL queries to read your entities. For other id options see @PrimaryKey.
[EL Warning]: metadata: 2024-09-03 10:11:25.752--ServerSession(136011184)--You have specified multiple ids for the entity class [org.apache.polaris.core.persistence.models.ModelEntityDropped] without specifying an @IdClass. By doing this you may lose the ability to find by identity, distributed cache support etc. Note: You may however use EntityManager find operations by passing a list of primary key fields. Else, you will have to use JPQL queries to read your entities. For other id options see @PrimaryKey.
[EL Warning]: metadata: 2024-09-03 10:11:25.753--ServerSession(136011184)--You have specified multiple ids for the entity class [org.apache.polaris.core.persistence.models.ModelEntity] without specifying an @IdClass. By doing this you may lose the ability to find by identity, distributed cache support etc. Note: You may however use EntityManager find operations by passing a list of primary key fields. Else, you will have to use JPQL queries to read your entities. For other id options see @PrimaryKey.
[EL Warning]: metadata: 2024-09-03 10:11:25.753--ServerSession(136011184)--You have specified multiple ids for the entity class [org.apache.polaris.core.persistence.models.ModelEntityActive] without specifying an @IdClass. By doing this you may lose the ability to find by identity, distributed cache support etc. Note: You may however use EntityManager find operations by passing a list of primary key fields. Else, you will have to use JPQL queries to read your entities. For other id options see @PrimaryKey.
[EL Info]: 2024-09-03 10:11:25.792--ServerSession(136011184)--EclipseLink, version: Eclipse Persistence Services - 4.0.3.v202405220658
[EL Fine]: sql: 2024-09-03 10:11:26.007--ServerSession(136011184)--Connection(2027363825)--CREATE TABLE ENTITIES (CATALOGID BIGINT NOT NULL, ID BIGINT NOT NULL, CREATETIMESTAMP BIGINT, DROPTIMESTAMP BIGINT, ENTITYVERSION INTEGER, GRANTRECORDSVERSION INTEGER, INTERNALPROPERTIES VARCHAR(65535), LASTUPDATETIMESTAMP BIGINT, NAME VARCHAR(255), PARENTID BIGINT, PROPERTIES VARCHAR(65535), PURGETIMESTAMP BIGINT, SUBTYPECODE INTEGER, TOPURGETIMESTAMP BIGINT, TYPECODE INTEGER, VERSION BIGINT, PRIMARY KEY (CATALOGID, ID))
[EL Fine]: sql: 2024-09-03 10:11:26.024--ServerSession(136011184)--SELECT 1
[EL Warning]: 2024-09-03 10:11:26.026--ServerSession(136011184)--Exception [EclipseLink-4002] (Eclipse Persistence Services - 4.0.3.v202405220658): org.eclipse.persistence.exceptions.DatabaseException
Internal Exception: java.sql.SQLSyntaxErrorException: Column length too big for column 'INTERNALPROPERTIES' (max = 16383); use BLOB or TEXT instead
Error Code: 1074
Call: CREATE TABLE ENTITIES (CATALOGID BIGINT NOT NULL, ID BIGINT NOT NULL, CREATETIMESTAMP BIGINT, DROPTIMESTAMP BIGINT, ENTITYVERSION INTEGER, GRANTRECORDSVERSION INTEGER, INTERNALPROPERTIES VARCHAR(65535), LASTUPDATETIMESTAMP BIGINT, NAME VARCHAR(255), PARENTID BIGINT, PROPERTIES VARCHAR(65535), PURGETIMESTAMP BIGINT, SUBTYPECODE INTEGER, TOPURGETIMESTAMP BIGINT, TYPECODE INTEGER, VERSION BIGINT, PRIMARY KEY (CATALOGID, ID))
Query: DataModifyQuery(sql=""CREATE TABLE ENTITIES (CATALOGID BIGINT NOT NULL, ID BIGINT NOT NULL, CREATETIMESTAMP BIGINT, DROPTIMESTAMP BIGINT, ENTITYVERSION INTEGER, GRANTRECORDSVERSION INTEGER, INTERNALPROPERTIES VARCHAR(65535), LASTUPDATETIMESTAMP BIGINT, NAME VARCHAR(255), PARENTID BIGINT, PROPERTIES VARCHAR(65535), PURGETIMESTAMP BIGINT, SUBTYPECODE INTEGER, TOPURGETIMESTAMP BIGINT, TYPECODE INTEGER, VERSION BIGINT, PRIMARY KEY (CATALOGID, ID))"")
[EL Fine]: sql: 2024-09-03 10:11:26.031--ServerSession(136011184)--Connection(2027363825)--CREATE TABLE ENTITIES_ACTIVE (CATALOGID BIGINT NOT NULL, ID BIGINT NOT NULL, PARENTID BIGINT NOT NULL, TYPECODE INTEGER NOT NULL, NAME VARCHAR(255), SUBTYPECODE INTEGER, PRIMARY KEY (CATALOGID, ID, PARENTID, TYPECODE))
[EL Fine]: sql: 2024-09-03 10:11:26.046--ServerSession(136011184)--Connection(2027363825)--CREATE TABLE ENTITIES_CHANGE_TRACKING (CATALOGID BIGINT NOT NULL, ID BIGINT NOT NULL, ENTITYVERSION INTEGER, GRANTRECORDSVERSION INTEGER, VERSION BIGINT, PRIMARY KEY (CATALOGID, ID))
[EL Fine]: sql: 2024-09-03 10:11:26.055--ServerSession(136011184)--Connection(2027363825)--CREATE TABLE ENTITIES_DROPPED (CATALOGID BIGINT NOT NULL, SUBTYPECODE INTEGER NOT NULL, DROPTIMESTAMP BIGINT NOT NULL, NAME VARCHAR(255) NOT NULL, PARENTID BIGINT NOT NULL, TYPECODE INTEGER NOT NULL, ID BIGINT, TOPURGETIMESTAMP BIGINT, VERSION BIGINT, PRIMARY KEY (CATALOGID, SUBTYPECODE, DROPTIMESTAMP, NAME, PARENTID, TYPECODE))
[EL Fine]: sql: 2024-09-03 10:11:26.065--ServerSession(136011184)--Connection(2027363825)--CREATE TABLE GRANT_RECORDS (GRANTEECATALOGID BIGINT NOT NULL, PRIVILEGECODE INTEGER NOT NULL, GRANTEEID BIGINT NOT NULL, SECURABLEID BIGINT NOT NULL, SECURABLECATALOGID BIGINT NOT NULL, VERSION BIGINT, PRIMARY KEY (GRANTEECATALOGID, PRIVILEGECODE, GRANTEEID, SECURABLEID, SECURABLECATALOGID))
[EL Fine]: sql: 2024-09-03 10:11:26.072--ServerSession(136011184)--Connection(2027363825)--CREATE INDEX GRANT_RECORDS_BY_GRANTEE_INDEX ON GRANT_RECORDS (granteeCatalogId, granteeId, securableCatalogId, securableId, privilegeCode)
[EL Fine]: sql: 2024-09-03 10:11:26.08--ServerSession(136011184)--Connection(2027363825)--CREATE TABLE PRINCIPAL_SECRETS (PRINCIPALCLIENTID VARCHAR(255) NOT NULL, MAINSECRET VARCHAR(255), PRINCIPALID BIGINT, SECONDARYSECRET VARCHAR(255), VERSION BIGINT, PRIMARY KEY (PRINCIPALCLIENTID))
[EL Fine]: sql: 2024-09-03 10:11:26.087--ServerSession(136011184)--Connection(2027363825)--CREATE TABLE POLARIS_SEQUENCE (ID BIGINT AUTO_INCREMENT NOT NULL, PRIMARY KEY (ID))
[EL Fine]: sql: 2024-09-03 10:11:26.138--ServerSession(136011184)--Connection(2027363825)--SELECT CATALOGID, ID, PARENTID, TYPECODE, NAME, SUBTYPECODE FROM ENTITIES_ACTIVE WHERE ((((CATALOGID = ?) AND (PARENTID = ?)) AND (TYPECODE = ?)) AND (NAME = ?))
	bind => [0, 0, 2, root]
DEBUG [2024-09-03 10:11:26,140 - 1045  ] [main] [] o.a.p.e.p.i.e.PolarisEclipseLinkMetaStoreSessionImpl: transaction committed 
[EL Fine]: sql: 2024-09-03 10:11:26.146--ServerSession(136011184)--Connection(2027363825)--SELECT CATALOGID, ID, CREATETIMESTAMP, DROPTIMESTAMP, ENTITYVERSION, GRANTRECORDSVERSION, INTERNALPROPERTIES, LASTUPDATETIMESTAMP, NAME, PARENTID, PROPERTIES, PURGETIMESTAMP, SUBTYPECODE, TOPURGETIMESTAMP, TYPECODE, VERSION FROM ENTITIES WHERE ((CATALOGID = ?) AND (ID = ?))
	bind => [0, 0]
[EL Fine]: sql: 2024-09-03 10:11:26.147--ServerSession(136011184)--SELECT 1
[EL Warning]: 2024-09-03 10:11:26.147--UnitOfWork(1152991394)--Exception [EclipseLink-4002] (Eclipse Persistence Services - 4.0.3.v202405220658): org.eclipse.persistence.exceptions.DatabaseException
Internal Exception: java.sql.SQLSyntaxErrorException: Table 'db.ENTITIES' doesn't exist
Error Code: 1146
Call: SELECT CATALOGID, ID, CREATETIMESTAMP, DROPTIMESTAMP, ENTITYVERSION, GRANTRECORDSVERSION, INTERNALPROPERTIES, LASTUPDATETIMESTAMP, NAME, PARENTID, PROPERTIES, PURGETIMESTAMP, SUBTYPECODE, TOPURGETIMESTAMP, TYPECODE, VERSION FROM ENTITIES WHERE ((CATALOGID = ?) AND (ID = ?))
	bind => [0, 0]
Query: ReadObjectQuery(referenceClass=ModelEntity sql=""SELECT CATALOGID, ID, CREATETIMESTAMP, DROPTIMESTAMP, ENTITYVERSION, GRANTRECORDSVERSION, INTERNALPROPERTIES, LASTUPDATETIMESTAMP, NAME, PARENTID, PROPERTIES, PURGETIMESTAMP, SUBTYPECODE, TOPURGETIMESTAMP, TYPECODE, VERSION FROM ENTITIES WHERE ((CATALOGID = ?) AND (ID = ?))"")
jakarta.persistence.PersistenceException: Exception [EclipseLink-4002] (Eclipse Persistence Services - 4.0.3.v202405220658): org.eclipse.persistence.exceptions.DatabaseException
Internal Exception: java.sql.SQLSyntaxErrorException: Table 'db.ENTITIES' doesn't exist
Error Code: 1146
Call: SELECT CATALOGID, ID, CREATETIMESTAMP, DROPTIMESTAMP, ENTITYVERSION, GRANTRECORDSVERSION, INTERNALPROPERTIES, LASTUPDATETIMESTAMP, NAME, PARENTID, PROPERTIES, PURGETIMESTAMP, SUBTYPECODE, TOPURGETIMESTAMP, TYPECODE, VERSION FROM ENTITIES WHERE ((CATALOGID = ?) AND (ID = ?))
	bind => [0, 0]
Query: ReadObjectQuery(referenceClass=ModelEntity sql=""SELECT CATALOGID, ID, CREATETIMESTAMP, DROPTIMESTAMP, ENTITYVERSION, GRANTRECORDSVERSION, INTERNALPROPERTIES, LASTUPDATETIMESTAMP, NAME, PARENTID, PROPERTIES, PURGETIMESTAMP, SUBTYPECODE, TOPURGETIMESTAMP, TYPECODE, VERSION FROM ENTITIES WHERE ((CATALOGID = ?) AND (ID = ?))"")
DEBUG [2024-09-03 10:11:26,147 - 1052  ] [main] [] o.a.p.e.p.i.e.PolarisEclipseLinkMetaStoreSessionImpl: transaction rolled back 
jakarta.persistence.PersistenceException: Exception [EclipseLink-4002] (Eclipse Persistence Services - 4.0.3.v202405220658): org.eclipse.persistence.exceptions.DatabaseException
Internal Exception: java.sql.SQLSyntaxErrorException: Table 'db.ENTITIES' doesn't exist
Error Code: 1146
Call: SELECT CATALOGID, ID, CREATETIMESTAMP, DROPTIMESTAMP, ENTITYVERSION, GRANTRECORDSVERSION, INTERNALPROPERTIES, LASTUPDATETIMESTAMP, NAME, PARENTID, PROPERTIES, PURGETIMESTAMP, SUBTYPECODE, TOPURGETIMESTAMP, TYPECODE, VERSION FROM ENTITIES WHERE ((CATALOGID = ?) AND (ID = ?))
	bind => [0, 0]
Query: ReadObjectQuery(referenceClass=ModelEntity sql=""SELECT CATALOGID, ID, CREATETIMESTAMP, DROPTIMESTAMP, ENTITYVERSION, GRANTRECORDSVERSION, INTERNALPROPERTIES, LASTUPDATETIMESTAMP, NAME, PARENTID, PROPERTIES, PURGETIMESTAMP, SUBTYPECODE, TOPURGETIMESTAMP, TYPECODE, VERSION FROM ENTITIES WHERE ((CATALOGID = ?) AND (ID = ?))"")
	at org.eclipse.persistence.internal.jpa.QueryImpl.getDetailedException(QueryImpl.java:392)
	at org.eclipse.persistence.internal.jpa.QueryImpl.executeReadQuery(QueryImpl.java:265)
	at org.eclipse.persistence.internal.jpa.QueryImpl.getResultList(QueryImpl.java:475)
	at jakarta.persistence.TypedQuery.getResultStream(TypedQuery.java:87)
	at org.apache.polaris.extension.persistence.impl.eclipselink.PolarisEclipseLinkStore.lookupEntity(PolarisEclipseLinkStore.java:213)
	at org.apache.polaris.extension.persistence.impl.eclipselink.PolarisEclipseLinkStore.writeToEntities(PolarisEclipseLinkStore.java:74)
	at org.apache.polaris.extension.persistence.impl.eclipselink.PolarisEclipseLinkMetaStoreSessionImpl.writeToEntities(PolarisEclipseLinkMetaStoreSessionImpl.java:330)
	at org.apache.polaris.core.persistence.PolarisMetaStoreManagerImpl.writeEntity(PolarisMetaStoreManagerImpl.java:120)
	at org.apache.polaris.core.persistence.PolarisMetaStoreManagerImpl.persistNewEntity(PolarisMetaStoreManagerImpl.java:189)
	at org.apache.polaris.core.persistence.PolarisMetaStoreManagerImpl.bootstrapPolarisService(PolarisMetaStoreManagerImpl.java:652)
	at org.apache.polaris.core.persistence.PolarisMetaStoreManagerImpl.lambda$bootstrapPolarisService$2(PolarisMetaStoreManagerImpl.java:706)
	at org.apache.polaris.extension.persistence.impl.eclipselink.PolarisEclipseLinkMetaStoreSessionImpl.runActionInTransaction(PolarisEclipseLinkMetaStoreSessionImpl.java:275)
	at org.apache.polaris.core.persistence.PolarisMetaStoreManagerImpl.bootstrapPolarisService(PolarisMetaStoreManagerImpl.java:706)
	at org.apache.polaris.core.persistence.LocalPolarisMetaStoreManagerFactory.bootstrapServiceAndCreatePolarisPrincipalForRealm(LocalPolarisMetaStoreManagerFactory.java:185)
	at org.apache.polaris.core.persistence.LocalPolarisMetaStoreManagerFactory.bootstrapRealms(LocalPolarisMetaStoreManagerFactory.java:87)
	at org.apache.polaris.service.BootstrapRealmsCommand.run(BootstrapRealmsCommand.java:69)
	at org.apache.polaris.service.BootstrapRealmsCommand.run(BootstrapRealmsCommand.java:40)
	at io.dropwizard.core.cli.ConfiguredCom	at org.eclipse.persistence.internal.jpa.QueryImpl.getDetailedException(QueryImpl.java:392)
mand.run(ConfiguredCommand.java:98)
	at io.dropwizard.core.cli.Cli.run(Cli.java:78)
	at io.dropwizard.core.Application.run(Application.java:94)
	at org.apache.polaris.service.PolarisApplication.main(PolarisApplication.java:121)
Caused by: org.eclipse.persistence.exceptions.DatabaseException: 
Internal Exception: java.sql.SQLSyntaxErrorException: Table 'db.ENTITIES' doesn't exist
Error Code: 1146
Call: SELECT CATALOGID, ID, CREATETIMESTAMP, DROPTIMESTAMP, ENTITYVERSION, GRANTRECORDSVERSION, INTERNALPROPERTIES, LASTUPDATETIMESTAMP, NAME, PARENTID, PROPERTIES, PURGETIMESTAMP, SUBTYPECODE, TOPURGETIMESTAMP, TYPECODE, VERSION FROM ENTITIES WHERE ((CATALOGID = ?) AND (ID = ?))
	bind => [0, 0]
Query: ReadObjectQuery(referenceClass=ModelEntity sql=""SELECT CATALOGID, ID, CREATETIMESTAMP, DROPTIMESTAMP, ENTITYVERSION, GRANTRECORDSVERSION, INTERNALPROPERTIES, LASTUPDATETIMESTAMP, NAME, PARENTID, PROPERTIES, PURGETIMESTAMP, SUBTYPECODE, TOPURGETIMESTAMP, TYPECODE, VERSION FROM ENTITIES WHERE ((CATALOGID = ?) AND (ID = ?))"")
	at org.eclipse.persistence.exceptions.DatabaseException.sqlException(DatabaseException.java:343)
	at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.basicExecuteCall(DatabaseAccessor.java:702)
	at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.executeCall(DatabaseAccessor.java:569)
	at org.eclipse.persistence.internal.sessions.AbstractSession.basicExecuteCall(AbstractSession.java:2048)
	at org.eclipse.persistence.sessions.server.ServerSession.executeCall(ServerSession.java:611)
	at org.eclipse.persistence.sessions.server.ClientSession.executeCall(ClientSession.java:263)
	at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:280)
	at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:266)
	at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.selectOneRow(DatasourceCallQueryMechanism.java:813)
	at org.eclipse.persistence.internal.queries.ExpressionQueryMechanism.selectOneRowFromTable(ExpressionQueryMechanism.java:2912)
	at org.eclipse.persistence.internal.queries.ExpressionQueryMechanism.selectOneRow(ExpressionQueryMechanism.java:2865)
	at org.eclipse.persistence.queries.ReadObjectQuery.executeObjectLevelReadQuery(ReadObjectQuery.java:563)
	at org.eclipse.persistence.queries.ObjectLevelReadQuery.executeDatabaseQuery(ObjectLevelReadQuery.java:1236)
	at org.eclipse.persistence.queries.DatabaseQuery.execute(DatabaseQuery.java:913)
	at org.eclipse.persistence.queries.ObjectLevelReadQuery.execute(ObjectLevelReadQuery.java:1195)
	at org.eclipse.persistence.queries.ReadObjectQuery.execute(ReadObjectQuery.java:448)
	at org.eclipse.persistence.queries.ObjectLevelReadQuery.executeInUnitOfWork(ObjectLevelReadQuery.java:1283)
	at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.internalExecuteQuery(UnitOfWorkImpl.java:3025)
	at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(Abstrac	at org.eclipse.persistence.internal.jpa.QueryImpl.executeReadQuery(QueryImpl.java:265)
tSession.java:1841)
	at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1823)
	at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1788)
	at org.eclipse.persistence.internal.jpa.QueryImpl.executeReadQuery(QueryImpl.java:263)
	... 19 common frames omitted
Caused by: java.sql.SQLSyntaxErrorException: Table 'db.ENTITIES' doesn't exist
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:112)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:113)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:938)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeQuery(ClientPreparedStatement.java:1004)
	at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.executeSelect(DatabaseAccessor.java:1026)
	at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.basicExecuteCall(DatabaseAccessor.java:662)
	... 39 common frames omitted
	at org.eclipse.persistence.internal.jpa.QueryImpl.getResultList(QueryImpl.java:475)
	at jakarta.persistence.TypedQuery.getResultStream(TypedQuery.java:87)
	at org.apache.polaris.extension.persistence.impl.eclipselink.PolarisEclipseLinkStore.lookupEntity(PolarisEclipseLinkStore.java:213)
	at org.apache.polaris.extension.persistence.impl.eclipselink.PolarisEclipseLinkStore.writeToEntities(PolarisEclipseLinkStore.java:74)
	at org.apache.polaris.extension.persistence.impl.eclipselink.PolarisEclipseLinkMetaStoreSessionImpl.writeToEntities(PolarisEclipseLinkMetaStoreSessionImpl.java:330)
	at org.apache.polaris.core.persistence.PolarisMetaStoreManagerImpl.writeEntity(PolarisMetaStoreManagerImpl.java:120)
	at org.apache.polaris.core.persistence.PolarisMetaStoreManagerImpl.persistNewEntity(PolarisMetaStoreManagerImpl.java:189)
	at org.apache.polaris.core.persistence.PolarisMetaStoreManagerImpl.bootstrapPolarisService(PolarisMetaStoreManagerImpl.java:652)
	at org.apache.polaris.core.persistence.PolarisMetaStoreManagerImpl.lambda$bootstrapPolarisService$2(PolarisMetaStoreManagerImpl.java:706)
	at org.apache.polaris.extension.persistence.impl.eclipselink.PolarisEclipseLinkMetaStoreSessionImpl.runActionInTransaction(PolarisEclipseLinkMetaStoreSessionImpl.java:275)
	at org.apache.polaris.core.persistence.PolarisMetaStoreManagerImpl.bootstrapPolarisService(PolarisMetaStoreManagerImpl.java:706)
	at org.apache.polaris.core.persistence.LocalPolarisMetaStoreManagerFactory.bootstrapServiceAndCreatePolarisPrincipalForRealm(LocalPolarisMetaStoreManagerFactory.java:185)
	at org.apache.polaris.core.persistence.LocalPolarisMetaStoreManagerFactory.bootstrapRealms(LocalPolarisMetaStoreManagerFactory.java:87)
	at org.apache.polaris.service.BootstrapRealmsCommand.run(BootstrapRealmsCommand.java:69)
	at org.apache.polaris.service.BootstrapRealmsCommand.run(BootstrapRealmsCommand.java:40)
	at io.dropwizard.core.cli.ConfiguredCommand.run(ConfiguredCommand.java:98)
	at io.dropwizard.core.cli.Cli.run(Cli.java:78)
	at io.dropwizard.core.Application.run(Application.java:94)
	at org.apache.polaris.service.PolarisApplication.main(PolarisApplication.java:121)
Caused by: Exception [EclipseLink-4002] (Eclipse Persistence Services - 4.0.3.v202405220658): org.eclipse.persistence.exceptions.DatabaseException
Internal Exception: java.sql.SQLSyntaxErrorException: Table 'db.ENTITIES' doesn't exist
Error Code: 1146
Call: SELECT CATALOGID, ID, CREATETIMESTAMP, DROPTIMESTAMP, ENTITYVERSION, GRANTRECORDSVERSION, INTERNALPROPERTIES, LASTUPDATETIMESTAMP, NAME, PARENTID, PROPERTIES, PURGETIMESTAMP, SUBTYPECODE, TOPURGETIMESTAMP, TYPECODE, VERSION FROM ENTITIES WHERE ((CATALOGID = ?) AND (ID = ?))
	bind => [0, 0]
Query: ReadObjectQuery(referenceClass=ModelEntity sql=""SELECT CATALOGID, ID, CREATETIMESTAMP, DROPTIMESTAMP, ENTITYVERSION, GRANTRECORDSVERSION, INTERNALPROPERTIES, LASTUPDATETIMESTAMP, NAME, PARENTID, PROPERTIES, PURGETIMESTAMP, SUBTYPECODE, TOPURGETIMESTAMP, TYPECODE, VERSION FROM ENTITIES WHERE ((CATALOGID = ?) AND (ID = ?))"")
	at org.eclipse.persistence.exceptions.DatabaseException.sqlException(DatabaseException.java:343)
	at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.basicExecuteCall(DatabaseAccessor.java:702)
	at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.executeCall(DatabaseAccessor.java:569)
	at org.eclipse.persistence.internal.sessions.AbstractSession.basicExecuteCall(AbstractSession.java:2048)
	at org.eclipse.persistence.sessions.server.ServerSession.executeCall(ServerSession.java:611)
	at org.eclipse.persistence.sessions.server.ClientSession.executeCall(ClientSession.java:263)
	at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:280)
	at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.executeCall(DatasourceCallQueryMechanism.java:266)
	at org.eclipse.persistence.internal.queries.DatasourceCallQueryMechanism.selectOneRow(DatasourceCallQueryMechanism.java:813)
	at org.eclipse.persistence.internal.queries.ExpressionQueryMechanism.selectOneRowFromTable(ExpressionQueryMechanism.java:2912)
	at org.eclipse.persistence.internal.queries.ExpressionQueryMechanism.selectOneRow(ExpressionQueryMechanism.java:2865)
	at org.eclipse.persistence.queries.ReadObjectQuery.executeObjectLevelReadQuery(ReadObjectQuery.java:563)
	at org.eclipse.persistence.queries.ObjectLevelReadQuery.executeDatabaseQuery(ObjectLevelReadQuery.java:1236)
	at org.eclipse.persistence.queries.DatabaseQuery.execute(DatabaseQuery.java:913)
	at org.eclipse.persistence.queries.ObjectLevelReadQuery.execute(ObjectLevelReadQuery.java:1195)
	at org.eclipse.persistence.queries.ReadObjectQuery.execute(ReadObjectQuery.java:448)
	at org.eclipse.persistence.queries.ObjectLevelReadQuery.executeInUnitOfWork(ObjectLevelReadQuery.java:1283)
	at org.eclipse.persistence.internal.sessions.UnitOfWorkImpl.internalExecuteQuery(UnitOfWorkImpl.java:3025)
	at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1841)
	at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1823)
	at org.eclipse.persistence.internal.sessions.AbstractSession.executeQuery(AbstractSession.java:1788)
	at org.eclipse.persistence.internal.jpa.QueryImpl.executeReadQuery(QueryImpl.java:263)
	... 19 more
Caused by: java.sql.SQLSyntaxErrorException: Table 'db.ENTITIES' doesn't exist
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:112)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:113)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:938)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeQuery(ClientPreparedStatement.java:1004)
	at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.executeSelect(DatabaseAccessor.java:1026)
	at org.eclipse.persistence.internal.databaseaccess.DatabaseAccessor.basicExecuteCall(DatabaseAccessor.java:662)
	... 39 more

```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Ks8Mo/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/241,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Ks_Oj,polaris,2327049123,241,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-09-03T17:18:49Z,2024-09-03T17:18:49Z,"For the issue with too-long strings, I think this can be fixed by setting the character encoding when connecting to the DB. e.g. `...?characterEncoding=latin1&useUnicode=false`. That said, I am supportive of just changing these.
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Ks_Oj/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/262,https://api.github.com/repos/apache/polaris/issues/262,polaris,2505712499,262,[BUG] GCS buckets with underscores are resolved as null,almazgalievisl,28739116,Almaz Galiev,,CLOSED,2024-09-04T15:37:08Z,2024-09-09T22:02:13Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

Underscores is a valid symbol in the bucket name, [the doc ](https://cloud.google.com/storage/docs/buckets#naming)

> Bucket names can only contain lowercase letters, numeric characters, dashes (-), underscores (_), and dots (.). Spaces are not allowed. Names containing dots require [verification](https://cloud.google.com/storage/docs/domain-name-verification).

The current approach uses  `java.net.URI`, which is not allowing to have underscores in the host name of URI. It leads to wrongly requested access boundaries, because the bucket name is being set as `null`.

### To Reproduce

```
|  Welcome to JShell -- Version 11.0.22
|  For an introduction type: /help intro

jshell> String location = ""gs://test_bucket/iceberg/data""
location ==> ""gs://test_bucket/iceberg/data""

jshell> URI uri = uri.create(location);
uri ==> gs://test_bucket/iceberg/data

jshell> uri.getHost()
$3 ==> null
```

### Actual Behavior

The bucket name is set as `null`

### Expected Behavior

The bucket name is set as `test_bucket`

### Additional context

I guess this [class](https://cloud.google.com/java/docs/reference/google-cloud-storage/latest/com.google.cloud.storage.BlobId#com_google_cloud_storage_BlobId_fromGsUtilUri_java_lang_String_) from `com.google.cloud.storage` can be used instead
```
import com.google.cloud.storage.BlobId;
...
BlobId blob = BlobId.fromGsUtilUri(location);
String bucket = blob.getBucket();
String path = blob.getName();
...
```

### System information

Object storage: GCS","{""url"": ""https://api.github.com/repos/apache/polaris/issues/262/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/262,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6K24wk,polaris,2329644068,262,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-09-04T17:43:37Z,2024-09-04T17:43:37Z,Thanks for filing this! I opened a small PR which seems to resolve the issue.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6K24wk/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/265,https://api.github.com/repos/apache/polaris/issues/265,polaris,2506716160,265,[BUILD] Change repositories mode when using gradle init scripts,anuragmantri,13743212,Anurag Mantripragada,,CLOSED,2024-09-05T04:01:48Z,2024-11-07T16:27:59Z,"Polaris uses  [RepositoriesMode.FAIL_ON_PROJECT_REPOS](https://github.com/apache/polaris/blob/0a539dbd47a99d9c50ef3598d0ee8ee770a864ea/settings.gradle.kts#L66) setting for dependency management. For companies using gradle init scripts with internal repository declarations, this will fail to build with below error 

```
Build was configured to prefer settings repositories over project repositories but repository 'maven' was added by initialization script '/Users/anurag/.gradle/init.gradle' 
```

Should we remove this mode or set it to [PREFER_SETTINGS](https://docs.gradle.org/current/javadoc/org/gradle/api/initialization/resolve/RepositoriesMode.html#PREFER_SETTINGS) instead? 

What are your thoughts @flyrain @aihuaxu ?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/265/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/265,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6LCXYE,polaris,2332653060,265,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-09-05T21:23:57Z,2024-09-05T21:23:57Z,"I'm OK with that, as it will make it easy for companies to integrate with internal libs. Feel free to file an PR. Also, this property is introduced by #53, cc @snazy for that.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6LCXYE/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/265,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6LWhSK,polaris,2337936522,265,NA,snazy,957468,Robert Stupp,,NA,2024-09-09T12:02:50Z,2024-09-09T12:02:50Z,I'm okay to remove the setting (use the default).,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6LWhSK/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/265,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6SwLQ6,polaris,2462102586,265,NA,aniket-s-kulkarni,7376200,Aniket Kulkarni,,NA,2024-11-07T12:22:37Z,2024-11-07T12:22:37Z,This is a small enough PR - I don't see that one has been submitted. I will create one if you don't mind.. ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6SwLQ6/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/265,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6SxB2K,polaris,2462326154,265,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2024-11-07T14:06:23Z,2024-11-07T14:06:23Z,It makes sense to me. ðŸ‘ ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6SxB2K/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/265,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6SyG_S,polaris,2462609362,265,NA,aniket-s-kulkarni,7376200,Aniket Kulkarni,,NA,2024-11-07T16:00:39Z,2024-11-07T16:00:39Z,@jbonofre - https://github.com/apache/polaris/pull/434 ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6SyG_S/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/269,https://api.github.com/repos/apache/polaris/issues/269,polaris,2508534756,269,[BUG] DROP WITH PURGE tasks are not guaranteed to complete,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,CLOSED,2024-09-05T19:11:06Z,2024-09-09T21:52:58Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

When dropTable is called with `purgeRequested`, the Polaris server will create `Task`s in order to delete data files associated with the table being dropped. However, if the service dies before the tasks are completed they may not resume gracefully on startup. Some of that table's data files may not be cleaned up.

### To Reproduce

Call `dropTable` with `purgeRequested`, and kill the Polaris service before the relevant `Task`s complete.

### Actual Behavior

`Task`s are not resumed on startup

### Expected Behavior

`Task`s associated with a purge should reliably complete, or the user should be made aware that they cannot be completed

### Additional context

I've met with @collado-mike and others to discuss a long-term solution here, but it may take some time. In the interim, we discussed some workarounds and stopgaps.

### System information

n/a","{""url"": ""https://api.github.com/repos/apache/polaris/issues/269/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/274,https://api.github.com/repos/apache/polaris/issues/274,polaris,2512523824,274,[FEATURE REQUEST] Develop Apache Ranger Plugin for Polaris to Enhance Access Control for Apache Iceberg,dbosco,2311778,Don Bosco Durai,,OPEN,2024-09-08T18:52:59Z,2025-01-16T17:33:17Z,"### Is your feature request related to a problem? Please describe.

_No response_

### Describe the solution you'd like

Apache Polaris provides metadata management for Apache Iceberg. From the authorization point of view, key features of Polaris include:

 - *RBAC (Role-Based Access Control):*Â Polaris supports RBAC for table and view-level operations. [See Documentation](https://polaris.io/#tag/Access-Control)
 - *Role Management:*Â Polaris allows the creation of Principals with roles like Data Engineer, Data Scientist, etc.
 - *Catalog Roles:*Â Specialized roles like Catalog Administrators, Catalog Readers, and Catalog Contributors can be defined to manage access to different parts of the data catalog.
 - *Granular Privileges:*Â Polaris provides fine-grained privileges for operations on Tables, Views, Namespaces, and Catalogs. Examples include `TABLE_CREATE`, `TABLE_READ_DATA`, `TABLE_WRITE_DATA`, `VIEW_CREATE`, `NAMESPACE_CREATE`, `CATALOG_MANAGE_CONTENT`, and more.
 - *Credential Vending:*Â Polaris vends credentials based on the specific table the user is trying to access.
 - *API for Role Management:*Â Polaris offers an API to manage grants for roles, allowing fine-tuned control over data access.

*Objective:*

To enhance the usability and security of Polaris for Apache Iceberg users, the request is to develop an Apache Ranger plugin that integrates Polaris' access control features with Apache Ranger. This integration will allow for centralized and consistent management of access policies, audit logging, and fine-grained access control across different tools used with Apache Iceberg.

*Use Cases:*

1. *Centralized Access Policy Management:*
 - Implement centralized and consistent management of access policies for data stored using Apache Iceberg across multiple tools and environments.

2. *Access Control for Data Engineering Workloads:*
 - Manage and control access to datasets used by Data Engineering workloads (e.g., Apache Spark) with a coarser-grained approach at the table level.

3. *Fine-Grained Access Control for Data Analysts:*
 - Provide fine-grained access control for Data Analysts using compute engines like Trino. This control can be enforced by leveraging the native Ranger Plugin in Trino, allowing for more granular control over data access at the table, view, or even column level.

4. *Centralized Access Auditing:*
 - Enable centralized collection and analysis of access audit logs across all tools used to access datasets in Iceberg, ensuring comprehensive auditing and compliance.

*Expected Deliverables:*
 - A fully functional Apache Ranger plugin for Polaris that supports the outlined use cases.
 - Documentation on how to configure and deploy the plugin.
 - Integration tests to ensure the plugin works as expected with Apache Iceberg and other tools like Apache Spark and Trino.
 - A detailed user guide explaining how to use the plugin for managing access control in various scenarios.

### Describe alternatives you've considered

_No response_

### Additional context

*References*

[PolarisAuthorizer Class on GitHub](https://github.com/apache/polaris/blob/main/polaris-core/src/main/java/org/apache/polaris/core/auth/PolarisAuthorizer.java): The `PolarisAuthorizer` class provides the core authorization logic in Polaris, which can be leveraged by the Apache Ranger plugin.

Most Apache projects and Open Source projects like Presto (https://prestodb.io/docs/current/connector/hive-security.html#ranger-based-authorization) , Trino (https://github.com/trinodb/trino/issues/22674), Apache Hive (https://github.com/apache/ranger/tree/master/hive-agent), Apache Kafka (https://cwiki.apache.org/confluence/display/RANGER/Kafka+Plugin have native integration with Apache Ranger. Some of these might also benefit with this integration

A corresponding tracking JIRA is also created in the Apache Ranger project. https://issues.apache.org/jira/browse/RANGER-4910
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/274/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/274,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6QY_CK,polaris,2422468746,274,NA,csi-mboero,48022605,Marco Boero,,NA,2024-10-18T13:22:41Z,2024-10-18T13:22:41Z,"Hello all,
I share a strong interest in this issue and I'm looking forward to any updates or insights. Thanks for addressing it!","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6QY_CK/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/274,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Q4fBx,polaris,2430726257,274,NA,sankalp-vairat,16849293,Sankalp Vairat,,NA,2024-10-23T02:59:19Z,2024-10-23T02:59:19Z,"Hello,
This feature would be extremely beneficial for implementing fine-grained access control for Apache Iceberg. Looking forward to updates !","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Q4fBx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/274,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Q5FHg,polaris,2430882272,274,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2024-10-23T04:45:41Z,2024-10-23T04:45:41Z,Clearly a great proposal (and planned to be honest). We love contribution ;),"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Q5FHg/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/274,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6RFeuU,polaris,2434132884,274,NA,dbosco,2311778,Don Bosco Durai,,NA,2024-10-24T02:52:20Z,2024-10-24T02:52:20Z,"@jbonofre  I am happy to start working on some design considerations. Let me know if Polaris is following any design template that I can follow, or I start with an initial document and we can then iterate over it. Thanks","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6RFeuU/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/275,https://api.github.com/repos/apache/polaris/issues/275,polaris,2512542387,275,[BUG] Typo in Copyright in https://polaris.apache.org/,dbosco,2311778,Don Bosco Durai,,CLOSED,2024-09-08T19:39:55Z,2024-09-10T07:42:05Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

The `Copyright` in https://polaris.apache.org/ has a typo. It is `Copyyright`.

> **Copyyright** ï¿½ 2024 The Apache Software Foundation, Licensed under the Apache License, Version 2.0.




### To Reproduce

1. Go to https://polaris.apache.org/
2. Check the bottom of the page

### Actual Behavior

This is what we have now:
> **Copyyright** ï¿½ 2024 The Apache Software Foundation, Licensed under the Apache License, Version 2.0.


### Expected Behavior

It should be 
> **Copyright** ï¿½ 2024 The Apache Software Foundation, Licensed under the Apache License, Version 2.0.


### Additional context

Given the instructions, I am happy to update it. Thanks

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/275/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/275,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6LcSs1,polaris,2339449653,275,NA,dbosco,2311778,Don Bosco Durai,,NA,2024-09-10T01:48:14Z,2024-09-10T01:48:14Z,Can this be assigned to me? Thanks. ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6LcSs1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/275,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6LeCXB,polaris,2339907009,275,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2024-09-10T07:42:04Z,2024-09-10T07:42:04Z,This issue should have been created on the polaris-site repo.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6LeCXB/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/280,https://api.github.com/repos/apache/polaris/issues/280,polaris,2519838833,280,[BUG] docker build fails when ECLIPSELINK arg is set to true,manojmukkamala,27603459,Manoj Mukkamala,,CLOSED,2024-09-11T13:59:20Z,2024-09-12T17:02:29Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

Context: I am trying to use postgres as backend.

docker build fails when ECLIPSELINK arg is set to true. 

I've added `persistence-new.xml` under `polaris-service/src/main/resources/META-INF/persistence-new.xml` and updated `polaris-server.yml` as follows:
```
metaStoreManager:
  # type: in-memory
  type: eclipse-link # uncomment to use eclipse-link as metastore
  conf-file: META-INF/persistence-new.xml
  persistence-unit: polaris-dev
  ```

When I remove the build-arg, the build was successful but the container cannot start with error:
```
io.dropwizard.configuration.ConfigurationParsingException: polaris-server.yml has an error:
 * Failed to parse configuration at: metaStoreManager; Could not resolve type id 'eclipse-link' as a subtype of `org.apache.polaris.core.persistence.MetaStoreManagerFactory`: known type ids = [in-memory] (for POJO property 'metaStoreManager')
at [Source: UNKNOWN; byte offset: #UNKNOWN] (through reference chain: org.apache.polaris.service.config.PolarisApplicationConfig[""metaStoreManager""])
```

### To Reproduce

`docker build . -t polaris_local_metastore --build-arg ECLIPSELINK=true`

### Actual Behavior

```
77.81 All projects evaluated.
77.81 
77.81 FAILURE: Build failed with an exception.
77.81 
77.81 * What went wrong:
77.81 10 actionable tasks: 10 executed
77.81 Circular dependency between the following tasks:
77.81 :polaris-service:jar
77.81 \--- :polaris-service:shadowJar
77.81      \--- :polaris-service:jar (*)
77.81 
77.81 (*) - details omitted (listed previously)
77.81 
77.81 
77.81 * Try:
77.81 > Run with --stacktrace option to get the stack trace.
77.81 > Run with --debug option to get more log output.
77.81 > Run with --scan to get full insights.
77.81 > Get more help at https://help.gradle.org.
77.81 
77.81 BUILD FAILED in 1m 17s
77.87 Some of the file system contents retained in the virtual file system are on file systems that Gradle doesn't support watching. The relevant state was discarded to ensure changes to these locations are properly detected. You can override this by explicitly enabling file system watching.
------

 1 warning found (use docker --debug to expand):
 - FromAsCasing: 'as' and 'FROM' keywords' casing do not match (line 23)
Dockerfile:34
--------------------
  32 |     
  33 |     # Build the rest catalog
  34 | >>> RUN ./gradlew --no-daemon --info -PeclipseLink=$ECLIPSELINK clean prepareDockerDist
  35 |     
  36 |     FROM registry.access.redhat.com/ubi9/openjdk-21-runtime:1.20-2.1721752928
--------------------
ERROR: failed to solve: process ""/bin/sh -c ./gradlew --no-daemon --info -PeclipseLink=$ECLIPSELINK clean prepareDockerDist"" did not complete successfully: exit code: 1
```

### Expected Behavior

A successful build.

### Additional context

NA

### System information

Host: Mac OS
Docker Desktop: v4.34.0","{""url"": ""https://api.github.com/repos/apache/polaris/issues/280/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/280,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Lt2qf,polaris,2344053407,280,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-09-11T15:53:50Z,2024-09-11T15:53:50Z,I think #227 might be relevant here?,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Lt2qf/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/280,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6LwAM8,polaris,2344616764,280,NA,manojmukkamala,27603459,Manoj Mukkamala,,NA,2024-09-11T20:12:57Z,2024-09-11T20:12:57Z,"I see the PR is still open so I took the code from run.sh in that PR and copied it to my local. Tried running the build again but ran into same error. I apologize if that's not how it should be done, I am novice in Java.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6LwAM8/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/280,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Lwlvs,polaris,2344770540,280,NA,MonkeyCanCode,29619290,,,NA,2024-09-11T21:54:25Z,2024-09-11T21:54:25Z,@manojmukkamala will check later today and see what is causing it.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Lwlvs/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/280,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Lwppp,polaris,2344786537,280,NA,loicalleyne,6126243,,,NA,2024-09-11T22:07:28Z,2024-09-11T22:07:28Z,"I also tried to work around it and it seems like some changes in the gradle build files is causing a circular dependency, I wasn't able to isolate it though. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Lwppp/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/280,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Lwwz-,polaris,2344815870,280,NA,MonkeyCanCode,29619290,,,NA,2024-09-11T22:29:18Z,2024-09-11T22:29:18Z,"So https://github.com/apache/polaris/commit/99d8eb7fe383c6283db3d042e17dec33c3bfbd11 is the one that caused this issue. 

You can use the following to do a build:
```
git checkout -b new_branch d3bfa05
docker build . -t polaris_local_metastore --build-arg ECLIPSELINK=true
```

I can look into where the circular dependencies is happening later tonight.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Lwwz-/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/280,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6LxEAu,polaris,2344894510,280,NA,manojmukkamala,27603459,Manoj Mukkamala,,NA,2024-09-11T23:13:55Z,2024-09-11T23:13:55Z,"that worked, thanks a lot @MonkeyCanCode 
can you help how to perform a bootstrap when running polaris as a container?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6LxEAu/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/280,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6LxVyV,polaris,2344967317,280,NA,MonkeyCanCode,29619290,,,NA,2024-09-11T23:31:14Z,2024-09-11T23:31:14Z,"@manojmukkamala sure thing. So I raised a PR for helm in the past which I am using job to perform bootstrap: https://github.com/apache/polaris/pull/135/files#diff-922229e69535a3fb282010bf5c16aa261f558539c874ac0cf8205b5762790cf4

Now back to your question, the container will be running in `server` mode by default. Then with persisted backend, your backend won't be bootstrapped out of box. To bootstrap it, you will need to ssh into the container and run the following wrapper command (which is what I am using in the helm chart above):
```
/app/bin/polaris-service bootstrap polaris-server.yml
```

Alternative, you can use the following java -jar command as well:
```
java -jar /path/to/jar/polaris-service-all.jar bootstrap polaris-server.yml
```
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6LxVyV/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/280,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Lxna5,polaris,2345039545,280,NA,manojmukkamala,27603459,Manoj Mukkamala,,NA,2024-09-12T00:47:58Z,2024-09-12T00:47:58Z,"thanks for the inputs. I entered the container `docker exec -it -u 0 <<container-name>> bash` and ran `/app/bin/polaris-service bootstrap polaris-server.yml` but it threw `Internal Exception: java.sql.SQLException: No suitable driver found for jdbc:postgres://postgres_metastore:5433/polaris`

I tried downloading the postgres jar from `https://repo1.maven.org/maven2/org/postgresql/postgresql/42.7.4/postgresql-42.7.4.jar` into `/app/lib` but no luck. Is that the right location to place the jar file?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Lxna5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/280,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Lxv88,polaris,2345074492,280,NA,MonkeyCanCode,29619290,,,NA,2024-09-12T01:28:40Z,2024-09-12T01:28:40Z,"> thanks for the inputs. I entered the container `docker exec -it -u 0 <<container-name>> bash` and ran `/app/bin/polaris-service bootstrap polaris-server.yml` but it threw `Internal Exception: java.sql.SQLException: No suitable driver found for jdbc:postgres://postgres_metastore:5433/polaris`
> 
> I tried downloading the postgres jar from `https://repo1.maven.org/maven2/org/postgresql/postgresql/42.7.4/postgresql-42.7.4.jar` into `/app/lib` but no luck. Is that the right location to place the jar file?

Hello, so this error is expected as Polaris itself doesn't package any jdbc driver which is actually needed when using a jdbc backend via eclipse link. This needs to be added as part of the EclipseLink build file instead. 

See more details in https://github.com/apache/polaris/issues/230. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Lxv88/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/280,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6LyIZr,polaris,2345174635,280,NA,manojmukkamala,27603459,Manoj Mukkamala,,NA,2024-09-12T03:04:43Z,2024-09-12T03:04:43Z,ok so that means I have to wait a bit before I can start using the container based deployment with PG backend?,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6LyIZr/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/280,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6LyI0x,polaris,2345176369,280,NA,MonkeyCanCode,29619290,,,NA,2024-09-12T03:06:43Z,2024-09-12T03:06:43Z,"> ok so that means I have to wait a bit before I can start using the container based deployment with PG backend?

Not really, here is what you can do:
```
# update extension/persistence/eclipselink/build.gradle.kts
## add the following within dependencies block
implementation(""org.postgresql:postgresql:42.7.4"")
```

Then build the image again. By doing so, your local image will then include the needed driver (in this case psql driver).","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6LyI0x/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/280,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6LyJVH,polaris,2345178439,280,NA,MonkeyCanCode,29619290,,,NA,2024-09-12T03:09:02Z,2024-09-12T03:09:02Z,"Also, I think I found where the circular dependency is coming from. Let me run couple more validations before I raised a PR to ensure nothing break in between.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6LyJVH/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/280,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6LyKSi,polaris,2345182370,280,NA,manojmukkamala,27603459,Manoj Mukkamala,,NA,2024-09-12T03:14:03Z,2024-09-12T03:14:03Z,"cool! appreciate your prompt responses. 
It worked this time btw, huge thanks for all the help!","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6LyKSi/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/280,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6LyNKM,polaris,2345194124,280,NA,MonkeyCanCode,29619290,,,NA,2024-09-12T03:28:17Z,2024-09-12T03:28:17Z,@eric-maynard here is the PR for fixing this issue: https://github.com/apache/polaris/pull/284,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6LyNKM/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/280,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6LyVib,polaris,2345228443,280,NA,MonkeyCanCode,29619290,,,NA,2024-09-12T04:08:27Z,2024-09-12T04:08:27Z,"> cool! appreciate your prompt responses. It worked this time btw, huge thanks for all the help!

Anytime. Here is a sample PR to avoid manual edit as additional dependencies are needed when using ecliselink: https://github.com/apache/polaris/pull/285/files","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6LyVib/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/281,https://api.github.com/repos/apache/polaris/issues/281,polaris,2520596788,281,[BUG] DefaultContextResolver is not using defaultRealm value from the PolarisApplicationConfig,almazgalievisl,28739116,Almaz Galiev,,CLOSED,2024-09-11T19:26:55Z,2024-10-19T01:03:55Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

[PolarisApplicationConfig](https://github.com/apache/polaris/blob/cc58730a0c626dba574c2577b32081b17b97b7a8/polaris-service/src/main/java/org/apache/polaris/service/config/PolarisApplicationConfig.java#L117) defines defaultRealm and allows overriding it trough configuration file. [DefaultContextResolver](https://github.com/apache/polaris/blob/cc58730a0c626dba574c2577b32081b17b97b7a8/polaris-service/src/main/java/org/apache/polaris/service/context/DefaultContextResolver.java#L52) ignores a value from the configuration. 

### To Reproduce

0. Setup an eclipse link with a database name which is different from `default-realm`
1. Set `defaultRealm`  in the configuration yaml file
2. Try to connect to get the token without setting `realm` explicitly in the request's headers
3. Polaris returns an error: 
```
FATAL: database 'default-realm' does not exist
```

### Actual Behavior

Configuration setting is not a source of truth for the all components

### Expected Behavior

Configuration setting defines a default value for the all components

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/281/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/281,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6LyZe5,polaris,2345244601,281,NA,loicalleyne,6126243,,,NA,2024-09-12T04:26:12Z,2024-09-12T04:26:12Z,"I came across the same issue, but since this error is thrown when the realm is incorrect or the bearer token is missing perhaps it could also indicate an attempt at unauthorized access. Either way the message returned could be clearer. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6LyZe5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/288,https://api.github.com/repos/apache/polaris/issues/288,polaris,2523012616,288,[Task] Remove the generated yaml files,flyrain,1322359,Yufei Gu,yufei@apache.org,CLOSED,2024-09-12T17:54:42Z,2024-10-02T18:20:30Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe 

More details in this comment, https://github.com/apache/polaris/pull/201/files#r1736832543","{""url"": ""https://api.github.com/repos/apache/polaris/issues/288/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/288,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Oayz2,polaris,2389388534,288,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-10-02T18:20:30Z,2024-10-02T18:20:30Z,This has been fixed along with the Hugo changes #279 ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Oayz2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/289,https://api.github.com/repos/apache/polaris/issues/289,polaris,2523390481,289,DROP TABLE with PURGE does not delete metadata.json files,loicalleyne,6126243,,,CLOSED,2024-09-12T21:27:23Z,2024-12-07T17:42:29Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

When dropping a table, the data folder is deleted but the metadata folder remains with the metadata.json files it contains.

### To Reproduce

Using postgres as the metadata store, and GCS for storage.

The queries below (executed in Trino) create a schema/namespace in the catalog, creates a table from some sample data in BigQuery(the data can be from anywhere really), copies the data to a second table, then drops the second table.

```
CREATE SCHEMA IF NOT EXISTS polarisgcs.test_schema1 WITH (location = 'gs://bucket-iceberg-polaris/polaris/test_schema1');

CREATE TABLE IF NOT EXISTS polarisgcs.test_schema1.test1 WITH (format='PARQUET', partitioning = ARRAY['domain_id', 

'day(date)']) AS SELECT date, domain_id, country, resource_id, metric1 FROM bq.sample.table1;

CREATE TABLE IF NOT EXISTS polarisgcs.test_schema1.test2 WITH (format='PARQUET', partitioning = ARRAY['domain_id', 'day(date)']) AS SELECT date, domain_id, country, resource_id, metric1 FROM polarisgcs.test_schema1.test1;

DROP TABLE polarisgcs.test_schema1.test2;
```

### Actual Behavior

files in `{table name}/metadata`  are not deleted
```
>gsutil ls gs://bucket-iceberg-polaris/polaris/test_schema1/test2*/**
gs://bucket-iceberg-polaris/polaris/test_schema1/test2-139045f9cbde4d1f9ef643141621a208/metadata/00000-af991efc-4628-4703-95c4-338a721eada7.metadata.json
gs://bucket-iceberg-polaris/polaris/test_schema1/test2-139045f9cbde4d1f9ef643141621a208/metadata/20240912_202545_00006_ft2jx-d05107ef-d9c4-4021-a450-2ecb4c796c2f.stats
gs://bucket-iceberg-polaris/polaris/test_schema1/test2-139045f9cbde4d1f9ef643141621a208/metadata/snap-789093043791680477-1-f9449a04-12db-4360-a6fe-f577830d075a.avro
```

### Expected Behavior

All files in the dropped table's path are deleted.

### Additional context

postgres as backing metadata store
GCS storage

```{""timestamp"":1726172836631,""level"":""DEBUG"",""thread"":""pool-3-thread-58 - DELETE /api/catalog/v1/polaris/namespaces/test_schema1/tables/test2?purgeRequested=true"",""logger"":""org.apache.polaris.service.config.RealmEntityManagerFactory"",""message"":""Looking up PolarisEntityManager for realm polaris_iceberg"",""mdc"":{""spanId"":""0da7f8369a5be134"",""traceId"":""ad635ef2168e9224e25bcb4cfeb587b6"",""realm"":""polaris_iceberg"",""request_id"":null},""params"":{}}
{""timestamp"":1726172836631,""level"":""INFO"",""thread"":""pool-3-thread-58 - DELETE /api/catalog/v1/polaris/namespaces/test_schema1/tables/test2?purgeRequested=true"",""logger"":""org.apache.polaris.service.auth.TestInlineBearerTokenPolarisAuthenticator"",""message"":""Checking for existence of principal polarisTester in map {principal=polarisTester, realm=polaris_iceberg}"",""mdc"":{""spanId"":""0da7f8369a5be134"",""traceId"":""ad635ef2168e9224e25bcb4cfeb587b6"",""realm"":""polaris_iceberg"",""request_id"":null},""params"":{}}
{""timestamp"":1726172836631,""level"":""WARN"",""thread"":""pool-3-thread-58 - DELETE /api/catalog/v1/polaris/namespaces/test_schema1/tables/test2?purgeRequested=true"",""logger"":""org.apache.polaris.service.auth.TestInlineBearerTokenPolarisAuthenticator"",""message"":""Failed to load secrets for principal polarisTester"",""mdc"":{""spanId"":""0da7f8369a5be134"",""traceId"":""ad635ef2168e9224e25bcb4cfeb587b6"",""realm"":""polaris_iceberg"",""request_id"":null},""params"":{}}
{""timestamp"":1726172836631,""level"":""DEBUG"",""thread"":""pool-3-thread-58 - DELETE /api/catalog/v1/polaris/namespaces/test_schema1/tables/test2?purgeRequested=true"",""logger"":""org.apache.polaris.service.auth.BasePolarisAuthenticator"",""message"":""Resolving principal for tokenInfo client_id=null"",""mdc"":{""spanId"":""0da7f8369a5be134"",""traceId"":""ad635ef2168e9224e25bcb4cfeb587b6"",""realm"":""polaris_iceberg"",""request_id"":null},""params"":{}}
{""timestamp"":1726172836631,""level"":""DEBUG"",""thread"":""pool-3-thread-58 - DELETE /api/catalog/v1/polaris/namespaces/test_schema1/tables/test2?purgeRequested=true"",""logger"":""org.apache.polaris.service.config.RealmEntityManagerFactory"",""message"":""Looking up PolarisEntityManager for realm polaris_iceberg"",""mdc"":{""spanId"":""0da7f8369a5be134"",""traceId"":""ad635ef2168e9224e25bcb4cfeb587b6"",""realm"":""polaris_iceberg"",""request_id"":null},""params"":{}}
{""timestamp"":1726172836631,""level"":""DEBUG"",""thread"":""pool-3-thread-58 - DELETE /api/catalog/v1/polaris/namespaces/test_schema1/tables/test2?purgeRequested=true"",""logger"":""org.apache.polaris.service.auth.BasePolarisAuthenticator"",""message"":""Resolved principal: name=polarisTester;id=7;parentId=0;entityVersion=1;type=PRINCIPAL;subType=NULL_SUBTYPE;internalProperties={client_id=15454eed974a106b}"",""mdc"":{""spanId"":""0da7f8369a5be134"",""traceId"":""ad635ef2168e9224e25bcb4cfeb587b6"",""realm"":""polaris_iceberg"",""request_id"":null},""params"":{}}
{""timestamp"":1726172836631,""level"":""DEBUG"",""thread"":""pool-3-thread-58 - DELETE /api/catalog/v1/polaris/namespaces/test_schema1/tables/test2?purgeRequested=true"",""logger"":""org.apache.polaris.service.auth.BasePolarisAuthenticator"",""message"":""Populating authenticatedPrincipal into CallContext: principalEntity=name=polarisTester;id=7;parentId=0;entityVersion=1;type=PRINCIPAL;subType=NULL_SUBTYPE;internalProperties={client_id=15454eed974a106b};activatedPrincipalRoleNames=[];activatedPrincipalRoles=null"",""mdc"":{""spanId"":""0da7f8369a5be134"",""traceId"":""ad635ef2168e9224e25bcb4cfeb587b6"",""realm"":""polaris_iceberg"",""request_id"":null},""params"":{}}
{""timestamp"":1726172836633,""level"":""DEBUG"",""thread"":""pool-3-thread-58 - DELETE /api/catalog/v1/polaris/namespaces/test_schema1/tables/test2?purgeRequested=true"",""logger"":""org.apache.polaris.service.catalog.api.IcebergRestCatalogApi"",""message"":""Invoking CatalogApi with params"",""mdc"":{""spanId"":""0da7f8369a5be134"",""traceId"":""ad635ef2168e9224e25bcb4cfeb587b6"",""realm"":""polaris_iceberg"",""request_id"":null},""params"":{""purgeRequested"":true,""prefix"":""polaris"",""namespace"":""test_schema1"",""operation"":""dropTable"",""table"":""test2""}}
{""timestamp"":1726172836633,""level"":""DEBUG"",""thread"":""pool-3-thread-58 - DELETE /api/catalog/v1/polaris/namespaces/test_schema1/tables/test2?purgeRequested=true"",""logger"":""org.apache.polaris.service.config.RealmEntityManagerFactory"",""message"":""Looking up PolarisEntityManager for realm polaris_iceberg"",""mdc"":{""spanId"":""0da7f8369a5be134"",""traceId"":""ad635ef2168e9224e25bcb4cfeb587b6"",""realm"":""polaris_iceberg"",""request_id"":null},""params"":{}}
{""timestamp"":1726172836633,""level"":""DEBUG"",""thread"":""pool-3-thread-58 - DELETE /api/catalog/v1/polaris/namespaces/test_schema1/tables/test2?purgeRequested=true"",""logger"":""org.apache.polaris.core.auth.PolarisAuthorizer"",""message"":""Satisfied privilege TABLE_DROP with grantRecord PolarisGrantRec{securableCatalogId=0, securableId=11, granteeCatalogId=11, granteeId=12, privilegeCode=31} from securable entity:name=polaris;id=11;parentId=0;entityVersion=1;type=CATALOG;subType=NULL_SUBTYPE;internalProperties={catalogType=INTERNAL, storage_configuration_info={\""@type\"":\""GcpStorageConfigurationInfo\"",\""allowedLocations\"":[\""gs://bucket-iceberg-polaris/polaris\""],\""storageType\"":\""GCS\"",\""fileIoImplClassName\"":\""org.apache.iceberg.gcp.gcs.GCSFileIO\""}};grantRecordsAsGrantee:[];grantRecordsAsSecurable:[PolarisGrantRec{securableCatalogId=0, securableId=11, granteeCatalogId=11, granteeId=12, privilegeCode=2}, PolarisGrantRec{securableCatalogId=0, securableId=11, granteeCatalogId=11, granteeId=12, privilegeCode=31}, PolarisGrantRec{securableCatalogId=0, securableId=11, granteeCatalogId=11, granteeId=12, privilegeCode=32}] for principalName polarisTester and activatedIds [2, 12]"",""mdc"":{""spanId"":""0da7f8369a5be134"",""traceId"":""ad635ef2168e9224e25bcb4cfeb587b6"",""realm"":""polaris_iceberg"",""request_id"":null},""params"":{}}
{""timestamp"":1726172836633,""level"":""DEBUG"",""thread"":""pool-3-thread-58 - DELETE /api/catalog/v1/polaris/namespaces/test_schema1/tables/test2?purgeRequested=true"",""logger"":""org.apache.polaris.core.auth.PolarisAuthorizer"",""message"":""Satisfied privilege TABLE_WRITE_DATA with grantRecord PolarisGrantRec{securableCatalogId=0, securableId=11, granteeCatalogId=11, granteeId=12, privilegeCode=32} from securable entity:name=polaris;id=11;parentId=0;entityVersion=1;type=CATALOG;subType=NULL_SUBTYPE;internalProperties={catalogType=INTERNAL, storage_configuration_info={\""@type\"":\""GcpStorageConfigurationInfo\"",\""allowedLocations\"":[\""gs://bucket-iceberg-polaris/polaris\""],\""storageType\"":\""GCS\"",\""fileIoImplClassName\"":\""org.apache.iceberg.gcp.gcs.GCSFileIO\""}};grantRecordsAsGrantee:[];grantRecordsAsSecurable:[PolarisGrantRec{securableCatalogId=0, securableId=11, granteeCatalogId=11, granteeId=12, privilegeCode=2}, PolarisGrantRec{securableCatalogId=0, securableId=11, granteeCatalogId=11, granteeId=12, privilegeCode=31}, PolarisGrantRec{securableCatalogId=0, securableId=11, granteeCatalogId=11, granteeId=12, privilegeCode=32}] for principalName polarisTester and activatedIds [2, 12]"",""mdc"":{""spanId"":""0da7f8369a5be134"",""traceId"":""ad635ef2168e9224e25bcb4cfeb587b6"",""realm"":""polaris_iceberg"",""request_id"":null},""params"":{}}
{""timestamp"":1726172836634,""level"":""INFO"",""thread"":""pool-3-thread-58 - DELETE /api/catalog/v1/polaris/namespaces/test_schema1/tables/test2?purgeRequested=true"",""logger"":""org.apache.polaris.service.context.PolarisCallContextCatalogFactory"",""message"":""Initializing new BasePolarisCatalog for key: polaris_iceberg/polaris"",""mdc"":{""spanId"":""0da7f8369a5be134"",""traceId"":""ad635ef2168e9224e25bcb4cfeb587b6"",""realm"":""polaris_iceberg"",""request_id"":null},""params"":{}}
{""timestamp"":1726172836634,""level"":""DEBUG"",""thread"":""pool-3-thread-58 - DELETE /api/catalog/v1/polaris/namespaces/test_schema1/tables/test2?purgeRequested=true"",""logger"":""org.apache.polaris.service.config.RealmEntityManagerFactory"",""message"":""Looking up PolarisEntityManager for realm polaris_iceberg"",""mdc"":{""spanId"":""0da7f8369a5be134"",""traceId"":""ad635ef2168e9224e25bcb4cfeb587b6"",""realm"":""polaris_iceberg"",""request_id"":null},""params"":{}}
{""timestamp"":1726172836634,""level"":""INFO"",""thread"":""pool-3-thread-58 - DELETE /api/catalog/v1/polaris/namespaces/test_schema1/tables/test2?purgeRequested=true"",""logger"":""org.apache.polaris.service.context.PolarisCallContextCatalogFactory"",""message"":""Looked up defaultBaseLocation gs://bucket-iceberg-polaris/polaris for catalog polaris_iceberg/polaris"",""mdc"":{""spanId"":""0da7f8369a5be134"",""traceId"":""ad635ef2168e9224e25bcb4cfeb587b6"",""realm"":""polaris_iceberg"",""request_id"":null},""params"":{}}
{""timestamp"":1726172836634,""level"":""DEBUG"",""thread"":""pool-3-thread-58 - DELETE /api/catalog/v1/polaris/namespaces/test_schema1/tables/test2?purgeRequested=true"",""logger"":""org.apache.polaris.service.catalog.BasePolarisCatalog"",""message"":""Resolved ioImplClassName org.apache.iceberg.gcp.gcs.GCSFileIO for storageConfiguration GcpStorageConfigurationInfo{storageType=GCS, allowedLocation=[gs://bucket-iceberg-polaris/polaris], gcpServiceAccount=null}"",""mdc"":{""spanId"":""0da7f8369a5be134"",""traceId"":""ad635ef2168e9224e25bcb4cfeb587b6"",""realm"":""polaris_iceberg"",""request_id"":null},""params"":{}}
{""timestamp"":1726172836634,""level"":""DEBUG"",""thread"":""pool-3-thread-58 - DELETE /api/catalog/v1/polaris/namespaces/test_schema1/tables/test2?purgeRequested=true"",""logger"":""org.apache.polaris.service.catalog.BasePolarisCatalog"",""message"":""Not initializing default catalogFileIO"",""mdc"":{""spanId"":""0da7f8369a5be134"",""traceId"":""ad635ef2168e9224e25bcb4cfeb587b6"",""realm"":""polaris_iceberg"",""request_id"":null},""params"":{}}
{""timestamp"":1726172836634,""level"":""DEBUG"",""thread"":""pool-3-thread-58 - DELETE /api/catalog/v1/polaris/namespaces/test_schema1/tables/test2?purgeRequested=true"",""logger"":""org.apache.polaris.service.catalog.BasePolarisCatalog"",""message"":""new BasePolarisTableOperations for test_schema1.test2"",""mdc"":{""spanId"":""0da7f8369a5be134"",""traceId"":""ad635ef2168e9224e25bcb4cfeb587b6"",""realm"":""polaris_iceberg"",""request_id"":null},""params"":{}}
{""timestamp"":1726172836634,""level"":""DEBUG"",""thread"":""pool-3-thread-58 - DELETE /api/catalog/v1/polaris/namespaces/test_schema1/tables/test2?purgeRequested=true"",""logger"":""org.apache.polaris.service.catalog.BasePolarisCatalog"",""message"":""doRefresh for tableIdentifier test_schema1.test2"",""mdc"":{""spanId"":""0da7f8369a5be134"",""traceId"":""ad635ef2168e9224e25bcb4cfeb587b6"",""realm"":""polaris_iceberg"",""request_id"":null},""params"":{}}
{""timestamp"":1726172836635,""level"":""DEBUG"",""thread"":""pool-3-thread-58 - DELETE /api/catalog/v1/polaris/namespaces/test_schema1/tables/test2?purgeRequested=true"",""logger"":""org.apache.polaris.core.persistence.resolver.PolarisResolutionManifest"",""message"":""Returning resolvedEntities from getPassthroughResolvedPath: [entity:name=polaris;id=11;parentId=0;entityVersion=1;type=CATALOG;subType=NULL_SUBTYPE;internalProperties={catalogType=INTERNAL, storage_configuration_info={\""@type\"":\""GcpStorageConfigurationInfo\"",\""allowedLocations\"":[\""gs://bucket-iceberg-polaris/polaris\""],\""storageType\"":\""GCS\"",\""fileIoImplClassName\"":\""org.apache.iceberg.gcp.gcs.GCSFileIO\""}};grantRecordsAsGrantee:[];grantRecordsAsSecurable:[PolarisGrantRec{securableCatalogId=0, securableId=11, granteeCatalogId=11, granteeId=12, privilegeCode=2}, PolarisGrantRec{securableCatalogId=0, securableId=11, granteeCatalogId=11, granteeId=12, privilegeCode=31}, PolarisGrantRec{securableCatalogId=0, securableId=11, granteeCatalogId=11, granteeId=12, privilegeCode=32}], entity:name=test_schema1;id=13;parentId=11;entityVersion=1;type=NAMESPACE;subType=NULL_SUBTYPE;internalProperties={};grantRecordsAsGrantee:[];grantRecordsAsSecurable:[], entity:name=test2;id=15;parentId=13;entityVersion=2;type=TABLE_LIKE;subType=TABLE;internalProperties={metadata-location=gs://bucket-iceberg-polaris/polaris/test_schema1/test2-139045f9cbde4d1f9ef643141621a208/metadata/00001-89250289-fa69-4a2a-870e-441a9f4ad873.metadata.json, parent-namespace=test_schema1};grantRecordsAsGrantee:[];grantRecordsAsSecurable:[]]"",""mdc"":{""spanId"":""0da7f8369a5be134"",""traceId"":""ad635ef2168e9224e25bcb4cfeb587b6"",""realm"":""polaris_iceberg"",""request_id"":null},""params"":{}}
{""timestamp"":1726172836635,""level"":""DEBUG"",""thread"":""pool-3-thread-58 - DELETE /api/catalog/v1/polaris/namespaces/test_schema1/tables/test2?purgeRequested=true"",""logger"":""org.apache.polaris.service.catalog.BasePolarisCatalog"",""message"":""Refreshing latestLocation: gs://bucket-iceberg-polaris/polaris/test_schema1/test2-139045f9cbde4d1f9ef643141621a208/metadata/00001-89250289-fa69-4a2a-870e-441a9f4ad873.metadata.json"",""mdc"":{""spanId"":""0da7f8369a5be134"",""traceId"":""ad635ef2168e9224e25bcb4cfeb587b6"",""realm"":""polaris_iceberg"",""request_id"":null},""params"":{}}
{""timestamp"":1726172836636,""level"":""INFO"",""thread"":""pool-3-thread-58 - DELETE /api/catalog/v1/polaris/namespaces/test_schema1/tables/test2?purgeRequested=true"",""logger"":""org.apache.iceberg.BaseMetastoreTableOperations"",""message"":""Refreshing table metadata from new version: gs://bucket-iceberg-polaris/polaris/test_schema1/test2-139045f9cbde4d1f9ef643141621a208/metadata/00001-89250289-fa69-4a2a-870e-441a9f4ad873.metadata.json"",""mdc"":{""spanId"":""0da7f8369a5be134"",""traceId"":""ad635ef2168e9224e25bcb4cfeb587b6"",""realm"":""polaris_iceberg"",""request_id"":null},""params"":{}}
{""timestamp"":1726172836636,""level"":""INFO"",""thread"":""pool-3-thread-58 - DELETE /api/catalog/v1/polaris/namespaces/test_schema1/tables/test2?purgeRequested=true"",""logger"":""org.apache.iceberg.CatalogUtil"",""message"":""Loading custom FileIO implementation: org.apache.iceberg.gcp.gcs.GCSFileIO"",""mdc"":{""spanId"":""0da7f8369a5be134"",""traceId"":""ad635ef2168e9224e25bcb4cfeb587b6"",""realm"":""polaris_iceberg"",""request_id"":null},""params"":{}}
{""timestamp"":1726172836734,""level"":""INFO"",""thread"":""pool-3-thread-58 - DELETE /api/catalog/v1/polaris/namespaces/test_schema1/tables/test2?purgeRequested=true"",""logger"":""org.apache.polaris.service.catalog.BasePolarisCatalog"",""message"":""Scheduled cleanup task 16 for table test_schema1.test2"",""mdc"":{""spanId"":""0da7f8369a5be134"",""traceId"":""ad635ef2168e9224e25bcb4cfeb587b6"",""realm"":""polaris_iceberg"",""request_id"":null},""params"":{}}
{""timestamp"":1726172836742,""level"":""DEBUG"",""thread"":""pool-3-thread-58 - DELETE /api/catalog/v1/polaris/namespaces/test_schema1/tables/test2?purgeRequested=true"",""logger"":""org.apache.polaris.service.catalog.api.IcebergRestCatalogApi"",""message"":""Completed execution of dropTable API with status code 200"",""mdc"":{""spanId"":""0da7f8369a5be134"",""traceId"":""ad635ef2168e9224e25bcb4cfeb587b6"",""realm"":""polaris_iceberg"",""request_id"":null},""params"":{}}
{""timestamp"":1726172836743,""level"":""INFO"",""thread"":""pool-3-thread-58"",""logger"":""io.opentelemetry.exporter.logging.LoggingSpanExporter"",""message"":""'DELETE /api/catalog/v1/polaris/namespaces/test_schema1/tables/test2' : ad635ef2168e9224e25bcb4cfeb587b6 0da7f8369a5be134 SERVER [tracer: /api/catalog/v1/polaris/namespaces/test_schema1/tables/test2:] AttributesMap{data={realm=polaris_iceberg, url.scheme=http, server.address=polaris, url.path=/api/catalog/v1/polaris/namespaces/test_schema1/tables/test2, http.request.method=DELETE}, capacity=128, totalAddedValues=5}"",""mdc"":{""request_id"":null,""realm"":""polaris_iceberg""},""params"":{}}
{""timestamp"":1726172836746,""level"":""DEBUG"",""thread"":""taskHandler-2"",""logger"":""org.apache.polaris.core.storage.cache.StorageCredentialCache"",""message"":""StorageCredentialCache::load"",""params"":{}}
{""timestamp"":1726172837097,""level"":""INFO"",""thread"":""taskHandler-2"",""logger"":""org.apache.iceberg.CatalogUtil"",""message"":""Loading custom FileIO implementation: org.apache.iceberg.gcp.gcs.GCSFileIO"",""params"":{}}
{""timestamp"":1726172837587,""level"":""INFO"",""thread"":""taskHandler-3"",""logger"":""org.apache.iceberg.CatalogUtil"",""message"":""Loading custom FileIO implementation: org.apache.iceberg.gcp.gcs.GCSFileIO"",""params"":{}}
{""timestamp"":1726172837671,""level"":""INFO"",""thread"":""taskHandler-2"",""logger"":""org.apache.polaris.service.task.TaskExecutorImpl"",""message"":""Task successfully handled"",""params"":{""handlerClass"":""org.apache.polaris.service.task.TableCleanupTaskHandler"",""taskEntityId"":16}}
{""timestamp"":1726172837976,""level"":""DEBUG"",""thread"":""taskHandler-3"",""logger"":""org.apache.polaris.service.task.ManifestFileCleanupTaskHandler"",""message"":""Scheduled 4 data files to be deleted from manifest gs://bucket-iceberg-polaris/polaris/test_schema1/test2-139045f9cbde4d1f9ef643141621a208/metadata/f9449a04-12db-4360-a6fe-f577830d075a-m0.avro"",""params"":{}}
{""timestamp"":1726172838303,""level"":""INFO"",""thread"":"""",""logger"":""org.apache.polaris.service.task.ManifestFileCleanupTaskHandler"",""message"":""All data files in manifest deleted - deleting manifest"",""params"":{""manifestFile"":""gs://bucket-iceberg-polaris/polaris/test_schema1/test2-139045f9cbde4d1f9ef643141621a208/metadata/f9449a04-12db-4360-a6fe-f577830d075a-m0.avro""}}
{""timestamp"":1726172838478,""level"":""INFO"",""thread"":""taskHandler-3"",""logger"":""org.apache.polaris.service.task.TaskExecutorImpl"",""message"":""Task successfully handled"",""params"":{""handlerClass"":""org.apache.polaris.service.task.ManifestFileCleanupTaskHandler"",""taskEntityId"":18}}
```

### System information

Trino 449
Polaris git: 6fcf5ccaebd7ca13a0cb96c96adca699a24080a0
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/289/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/289,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6L6VL2,polaris,2347324150,289,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-09-12T22:04:05Z,2024-09-12T22:04:05Z,The delete is supposed to happen [here](https://github.com/apache/polaris/blob/19c82588199e69ed5fdddb9b42900c53d9889149/polaris-service/src/main/java/org/apache/polaris/service/task/TableCleanupTaskHandler.java#L161). Can you share the steps you used to reproduce this with Trino?,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6L6VL2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/289,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6L6dfU,polaris,2347358164,289,NA,loicalleyne,6126243,,,NA,2024-09-12T22:35:43Z,2024-09-12T22:35:43Z,"@eric-maynard I ran the queries listed in the **To Reproduce** of the OP in Trino. Do you need Trino configuration information in addition to this?
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6L6dfU/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/289,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6L6mC_,polaris,2347393215,289,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-09-12T23:13:06Z,2024-09-12T23:13:06Z,"Sure, or if you can reproduce this any other way (via calls to the CLI, or another engine) that works too! Just hoping to create a small minimally reproducing example to debug. A unit test would be ideal.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6L6mC_/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/289,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6L6tbr,polaris,2347423467,289,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-09-12T23:50:07Z,2024-09-12T23:50:07Z,"Polaris does not delete any historical metadata.json files, only the current one will be deleted. 
This Iceberg [PR](https://github.com/apache/iceberg/pull/9305) you posted fixed it in Iceberg class `CatalogUtil`, but Polaris doesn't use it due to some reasons, like async deletion. To fix it, we can follow the approach in the PR to get a full set of file to delete in Polaris.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6L6tbr/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/289,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6L6u16,polaris,2347429242,289,NA,sfc-gh-ygu,175990617,Yufei Gu,,NA,2024-09-12T23:58:02Z,2024-09-12T23:58:02Z,"specifically, we need the following two methods to get all metadata.json files and stats files
```
  private static Set<String> metadataLocations(TableMetadata tableMetadata) {
    Set<String> metadataLocations =
        tableMetadata.previousFiles().stream()
            .map(TableMetadata.MetadataLogEntry::file)
            .collect(Collectors.toSet());
    metadataLocations.add(tableMetadata.metadataFileLocation());
    return metadataLocations;
  }

  private static Set<String> statsLocations(TableMetadata tableMetadata) {
    return tableMetadata.statisticsFiles().stream()
        .map(StatisticsFile::path)
        .collect(Collectors.toSet());
  }
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6L6u16/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/289,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6L7nRg,polaris,2347660384,289,NA,loicalleyne,6126243,,,NA,2024-09-13T00:39:18Z,2024-09-13T00:39:18Z,"I've been building an Iceberg playground using my fork of insta-infra to bring up containerized Polaris, postgres, minio and more.
I'll push a repro setup to a repo tomorrow and post the link here. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6L7nRg/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/289,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6MCeXP,polaris,2349458895,289,NA,loicalleyne,6126243,,,NA,2024-09-13T17:04:01Z,2024-09-13T17:04:01Z,I've just remembered that Polaris doesn't work with Minio due to lack of STS support. Do you know of any other service that can provide local S3 with STS? Or are you ok to use your own S3/GCS credentials for testing?,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6MCeXP/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/289,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6MCqUe,polaris,2349507870,289,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-09-13T17:14:14Z,2024-09-13T17:14:14Z,"> Do you know of any other service that can provide local S3 with STS? 

Not as I know. May @snazy and @dimas-b know more options. BTW, can you open another issue for this question? It's a bit off-topic here.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6MCqUe/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/289,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6MfZAF,polaris,2357039109,289,NA,mayankvadariya,48036907,Mayank Vadariya,,NA,2024-09-17T22:24:52Z,2024-09-17T22:24:52Z,"> I've just remembered that Polaris doesn't work with Minio due to lack of STS support. Do you know of any other service that can provide local S3 with STS? Or are you ok to use your own S3/GCS credentials for testing?

It appears Localstack has STS support.
https://docs.localstack.cloud/user-guide/aws/sts/
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6MfZAF/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/289,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Mqxjx,polaris,2360023281,289,NA,danielhumanmod,135958699,Daniel Tu,,NA,2024-09-19T05:40:38Z,2024-09-19T05:40:38Z,"Hi @flyrain, I am new to Polaris community and this task seems good to start with, may I work on this issue?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Mqxjx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/289,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6MwQur,polaris,2361461675,289,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-09-19T16:19:57Z,2024-09-19T16:19:57Z,"Feel free to take it, @danielhumanmod.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6MwQur/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/289,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6NFeau,polaris,2367022766,289,NA,danielhumanmod,135958699,Daniel Tu,,NA,2024-09-22T23:49:05Z,2024-09-22T23:49:05Z,"Hi @flyrain (@sfc-gh-ygu ) @eric-maynard, thank you for all the valuable context in the discussion. I have created a [draft PR](https://github.com/apache/polaris/pull/312) for this issue. Before it's ready for review, I list some points that need to be discussed in the ""To be discussed"" section in the PR, greatly appreciate it if you could provide some insight about these questions!","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6NFeau/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/289,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6NQSuK,polaris,2369858442,289,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-09-24T00:30:55Z,2024-09-24T00:30:55Z,Thanks @danielhumanmod for working on it. We will only need to add support for the historical metadata.json files and stats files. Others are token care already.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6NQSuK/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/289,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6WgAiU,polaris,2524973204,289,NA,danielhumanmod,135958699,Daniel Tu,,NA,2024-12-07T06:45:40Z,2024-12-07T06:45:40Z,"Hi Team, For this feature, we have some potential future improvements to work on:
1. [Refactoring] Separate manifest files and metadata file batches, using a common base class.
2. [Feature] Implement async deletion for partition statistics files.

Iâ€™m happy to keep working on these improvements if youâ€™re okay with it :)","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6WgAiU/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/289,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6WhF6Z,polaris,2525257369,289,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-12-07T17:42:27Z,2024-12-07T17:42:27Z,"Hi @danielhumanmod, thanks for the contribution. Please feel free to do so. Don't hesitate to make small changes. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6WhF6Z/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/291,https://api.github.com/repos/apache/polaris/issues/291,polaris,2526215192,291,"[BUG] polaris-service:test, two tests fails",sreev,441385,Sree Vaddi,,CLOSED,2024-09-14T10:26:44Z,2024-10-18T16:24:17Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

**Update Documentation:**
start iceberg spark docker (for rest api 8181, 8182 ports) before running the polaris full build with tests.



**WHY:**

1. What version of Apache Polaris are you using?
main branch

2. What operating system and processor architecture are you using?
macOS 14.6.1 (23G93)

3. What did you do?
very first build on git clone
% ./gradlew build

4. What did you expect to see?
successful build

5. What did you see instead?
two tests failed in polaris-service module

port 8181 and/or 8182 connection timeout



% git clone https://github.com/sreev/polaris.git
% cd polaris
% ./gradlew build
...
...
...
Successfully generated code to ~/polaris/polaris-service/build/generated
OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended
OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended

> Task :polaris-service:javadoc
~/polaris/polaris-service/build/generated/src/main/java/org/apache/polaris/service/catalog/api/IcebergRestCatalogApi.java:489: warning: invalid input: '<'
   * Load a table from the catalog.  The response contains both configuration and table metadata. The configuration, if non-empty is used as additional configuration for the table that overrides catalog configuration. For example, this configuration may change the FileIO implementation to be used for the table.  The response also contains the table's full metadata, matching the table metadata JSON file.  The catalog configuration may contain credentials that should be used for subsequent requests for the table. The configuration key \""token\"" is used to pass an access token to be used as a bearer token for table requests. Otherwise, a token may be passed using a RFC 8693 token type as a configuration key. For example, \""urn:ietf:params:oauth:token-type:jwt=<JWT-token>\"".
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ^
~/polaris/polaris-service/build/generated/src/main/java/org/apache/polaris/service/catalog/api/IcebergRestCatalogApi.java:527: warning: invalid input: '<'
   * Load a view from the catalog.  The response contains both configuration and view metadata. The configuration, if non-empty is used as additional configuration for the view that overrides catalog configuration.  The response also contains the view's full metadata, matching the view metadata JSON file.  The catalog configuration may contain credentials that should be used for subsequent requests for the view. The configuration key \""token\"" is used to pass an access token to be used as a bearer token for view requests. Otherwise, a token may be passed using a RFC 8693 token type as a configuration key. For example, \""urn:ietf:params:oauth:token-type:jwt=<JWT-token>\"".
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ^
2 warnings
OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended
OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended

> Task :polaris-service:test

PolarisApplicationIntegrationTest > testIcebergCreateNamespaceInExternalCatalog(TestInfo) FAILED
    jakarta.ws.rs.ProcessingException at PolarisApplicationIntegrationTest.java:236
        Caused by: java.net.SocketTimeoutException at PolarisApplicationIntegrationTest.java:236

PolarisOverlappingTableTest > Test restrictions on table locations > [1] extension=strict, catalog=default, status=Forbidden FAILED
    jakarta.ws.rs.ProcessingException at PolarisOverlappingTableTest.java:206
        Caused by: java.net.SocketTimeoutException at PolarisOverlappingTableTest.java:206

OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended
INFO  [2024-09-14 01:18:57,518] org.apache.spark.util.ShutdownHookManager: Shutdown hook called
INFO  [2024-09-14 01:18:57,519] org.apache.spark.util.ShutdownHookManager: Deleting directory /private/var/folders/qf/1xhrknbj7f33hz2wry75k3_m0000gn/T/spark-75985dac-f980-4164-83ef-01217f28b076

> Task :polaris-service:test

467 tests completed, 2 failed, 6 skipped

> Task :polaris-service:test FAILED

FAILURE: Build failed with an exception.

* What went wrong:
Execution failed for task ':polaris-service:test'.
> There were failing tests. See the report at: file:///~/polaris/polaris-service/build/reports/tests/test/index.html

* Try:
> Run with --scan to get full insights.

BUILD FAILED in 11m 27s
75 actionable tasks: 73 executed, 1 from cache, 1 up-to-date











testIcebergCreateNamespaceInExternalCatalog(TestInfo)

jakarta.ws.rs.ProcessingException: java.net.SocketTimeoutException: Read timed out
	at app//org.glassfish.jersey.apache5.connector.Apache5Connector.apply(Apache5Connector.java:544)
	at app//org.glassfish.jersey.client.ClientRuntime.invoke(ClientRuntime.java:300)
	at app//org.glassfish.jersey.client.JerseyInvocation.lambda$invoke$0(JerseyInvocation.java:674)
	at app//org.glassfish.jersey.client.JerseyInvocation.call(JerseyInvocation.java:709)
	at app//org.glassfish.jersey.client.JerseyInvocation.lambda$runInScope$3(JerseyInvocation.java:703)
	at app//org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at app//org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at app//org.glassfish.jersey.internal.Errors.process(Errors.java:205)
	at app//org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:390)
	at app//org.glassfish.jersey.client.JerseyInvocation.runInScope(JerseyInvocation.java:703)
	at app//org.glassfish.jersey.client.JerseyInvocation.invoke(JerseyInvocation.java:673)
	at app//org.glassfish.jersey.client.JerseyInvocation$Builder.method(JerseyInvocation.java:439)
	at app//org.glassfish.jersey.client.JerseyInvocation$Builder.post(JerseyInvocation.java:345)
	at app//org.apache.polaris.service.PolarisApplicationIntegrationTest.createCatalog(PolarisApplicationIntegrationTest.java:236)
	at app//org.apache.polaris.service.PolarisApplicationIntegrationTest.createCatalog(PolarisApplicationIntegrationTest.java:190)
	at app//org.apache.polaris.service.PolarisApplicationIntegrationTest.lambda$before$0(PolarisApplicationIntegrationTest.java:184)
	at java.base@22.0.2/java.util.Optional.ifPresent(Optional.java:178)
	at app//org.apache.polaris.service.PolarisApplicationIntegrationTest.before(PolarisApplicationIntegrationTest.java:180)
	at java.base@22.0.2/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base@22.0.2/java.util.ArrayList.forEach(ArrayList.java:1597)
	at java.base@22.0.2/java.util.ArrayList.forEach(ArrayList.java:1597)
Caused by: java.net.SocketTimeoutException: Read timed out
	at java.base/sun.nio.ch.NioSocketImpl.timedRead(NioSocketImpl.java:278)
	at java.base/sun.nio.ch.NioSocketImpl.implRead(NioSocketImpl.java:304)
	at java.base/sun.nio.ch.NioSocketImpl.read(NioSocketImpl.java:346)
	at java.base/sun.nio.ch.NioSocketImpl$1.read(NioSocketImpl.java:796)
	at java.base/java.net.Socket$SocketInputStream.implRead(Socket.java:1108)
	at java.base/java.net.Socket$SocketInputStream.read(Socket.java:1095)
	at org.apache.hc.core5.http.impl.io.SessionInputBufferImpl.fillBuffer(SessionInputBufferImpl.java:149)
	at org.apache.hc.core5.http.impl.io.SessionInputBufferImpl.readLine(SessionInputBufferImpl.java:280)
	at org.apache.hc.core5.http.impl.io.AbstractMessageParser.parse(AbstractMessageParser.java:247)
	at org.apache.hc.core5.http.impl.io.AbstractMessageParser.parse(AbstractMessageParser.java:54)
	at org.apache.hc.core5.http.impl.io.DefaultBHttpClientConnection.receiveResponseHeader(DefaultBHttpClientConnection.java:299)
	at org.apache.hc.core5.http.impl.io.HttpRequestExecutor.execute(HttpRequestExecutor.java:175)
	at org.apache.hc.core5.http.impl.io.HttpRequestExecutor.execute(HttpRequestExecutor.java:218)
	at org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager$InternalConnectionEndpoint.execute(PoolingHttpClientConnectionManager.java:717)
	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.execute(InternalExecRuntime.java:216)
	at org.apache.hc.client5.http.impl.classic.MainClientExec.execute(MainClientExec.java:116)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:188)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:113)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:116)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:170)
	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:87)
	at org.glassfish.jersey.apache5.connector.Apache5Connector.apply(Apache5Connector.java:496)








[1] extension=strict, catalog=default, status=Forbidden

jakarta.ws.rs.ProcessingException: java.net.SocketTimeoutException: Read timed out
	at app//org.glassfish.jersey.apache5.connector.Apache5Connector.apply(Apache5Connector.java:544)
	at app//org.glassfish.jersey.client.ClientRuntime.invoke(ClientRuntime.java:300)
	at app//org.glassfish.jersey.client.JerseyInvocation.lambda$invoke$0(JerseyInvocation.java:674)
	at app//org.glassfish.jersey.client.JerseyInvocation.call(JerseyInvocation.java:709)
	at app//org.glassfish.jersey.client.JerseyInvocation.lambda$runInScope$3(JerseyInvocation.java:703)
	at app//org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at app//org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at app//org.glassfish.jersey.internal.Errors.process(Errors.java:205)
	at app//org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:390)
	at app//org.glassfish.jersey.client.JerseyInvocation.runInScope(JerseyInvocation.java:703)
	at app//org.glassfish.jersey.client.JerseyInvocation.invoke(JerseyInvocation.java:673)
	at app//org.glassfish.jersey.client.JerseyInvocation$Builder.method(JerseyInvocation.java:439)
	at app//org.glassfish.jersey.client.JerseyInvocation$Builder.post(JerseyInvocation.java:345)
	at app//org.apache.polaris.service.admin.PolarisOverlappingTableTest.createTable(PolarisOverlappingTableTest.java:206)
	at app//org.apache.polaris.service.admin.PolarisOverlappingTableTest.testTableLocationRestrictions(PolarisOverlappingTableTest.java:237)
	at java.base@22.0.2/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base@22.0.2/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base@22.0.2/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:212)
	at java.base@22.0.2/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:194)
	at java.base@22.0.2/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:212)
	at java.base@22.0.2/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base@22.0.2/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:212)
	at java.base@22.0.2/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:212)
	at java.base@22.0.2/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:212)
	at java.base@22.0.2/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base@22.0.2/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:212)
	at java.base@22.0.2/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base@22.0.2/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:782)
	at java.base@22.0.2/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:291)
	at java.base@22.0.2/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:212)
	at java.base@22.0.2/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:212)
	at java.base@22.0.2/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:212)
	at java.base@22.0.2/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base@22.0.2/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:556)
	at java.base@22.0.2/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:546)
	at java.base@22.0.2/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base@22.0.2/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base@22.0.2/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:265)
	at java.base@22.0.2/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:611)
	at java.base@22.0.2/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:291)
	at java.base@22.0.2/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:212)
	at java.base@22.0.2/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:212)
	at java.base@22.0.2/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:212)
	at java.base@22.0.2/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1709)
	at java.base@22.0.2/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:556)
	at java.base@22.0.2/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:546)
	at java.base@22.0.2/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base@22.0.2/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base@22.0.2/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:265)
	at java.base@22.0.2/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:611)
	at java.base@22.0.2/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:291)
	at java.base@22.0.2/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1709)
	at java.base@22.0.2/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:556)
	at java.base@22.0.2/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:546)
	at java.base@22.0.2/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base@22.0.2/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base@22.0.2/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:265)
	at java.base@22.0.2/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:611)
	at java.base@22.0.2/java.util.ArrayList.forEach(ArrayList.java:1597)
	at java.base@22.0.2/java.util.ArrayList.forEach(ArrayList.java:1597)
Caused by: java.net.SocketTimeoutException: Read timed out
	at java.base/sun.nio.ch.NioSocketImpl.timedRead(NioSocketImpl.java:278)
	at java.base/sun.nio.ch.NioSocketImpl.implRead(NioSocketImpl.java:304)
	at java.base/sun.nio.ch.NioSocketImpl.read(NioSocketImpl.java:346)
	at java.base/sun.nio.ch.NioSocketImpl$1.read(NioSocketImpl.java:796)
	at java.base/java.net.Socket$SocketInputStream.implRead(Socket.java:1108)
	at java.base/java.net.Socket$SocketInputStream.read(Socket.java:1095)
	at org.apache.hc.core5.http.impl.io.SessionInputBufferImpl.fillBuffer(SessionInputBufferImpl.java:149)
	at org.apache.hc.core5.http.impl.io.SessionInputBufferImpl.readLine(SessionInputBufferImpl.java:280)
	at org.apache.hc.core5.http.impl.io.AbstractMessageParser.parse(AbstractMessageParser.java:247)
	at org.apache.hc.core5.http.impl.io.AbstractMessageParser.parse(AbstractMessageParser.java:54)
	at org.apache.hc.core5.http.impl.io.DefaultBHttpClientConnection.receiveResponseHeader(DefaultBHttpClientConnection.java:299)
	at org.apache.hc.core5.http.impl.io.HttpRequestExecutor.execute(HttpRequestExecutor.java:175)
	at org.apache.hc.core5.http.impl.io.HttpRequestExecutor.execute(HttpRequestExecutor.java:218)
	at org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager$InternalConnectionEndpoint.execute(PoolingHttpClientConnectionManager.java:717)
	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.execute(InternalExecRuntime.java:216)
	at org.apache.hc.client5.http.impl.classic.MainClientExec.execute(MainClientExec.java:116)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:188)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:113)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:116)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:170)
	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:87)
	at org.glassfish.jersey.apache5.connector.Apache5Connector.apply(Apache5Connector.java:496)
	... 59 more



### To Reproduce

1. What version of Apache Polaris are you using?
main branch

% git clone https://github.com/sreev/polaris.git
% cd polaris
% ./gradlew build

### Actual Behavior

5. What did you see instead?
two tests failed in polaris-service module

port 8181 and/or 8182 connection timeout

### Expected Behavior

4. What did you expect to see?
successful build

### Additional context

% git clone https://github.com/sreev/docker-spark-iceberg.git
% code docker-spark-iceberg
docker-spark-iceberg % docker-compose up



% ./gradlew build
Configuration on demand is an incubating feature.

> Task :polaris-build-logic:compileKotlin UP-TO-DATE
Kotlin does not yet support 22 JDK target, falling back to Kotlin JVM_21 JVM target

> Configure project :
Kotlin does not yet support 22 JDK target, falling back to Kotlin JVM_21 JVM target
OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended
OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended
OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended
INFO  [2024-09-14 03:18:37,554] org.apache.spark.util.ShutdownHookManager: Shutdown hook called
INFO  [2024-09-14 03:18:37,555] org.apache.spark.util.ShutdownHookManager: Deleting directory /private/var/folders/qf/1xhrknbj7f33hz2wry75k3_m0000gn/T/spark-72409bf0-7ebd-425e-b656-956504834fa4

BUILD SUCCESSFUL in 3m 56s
76 actionable tasks: 13 executed, 63 up-to-date

### System information

2. What operating system and processor architecture are you using?
macOS 14.6.1 (23G93)","{""url"": ""https://api.github.com/repos/apache/polaris/issues/291/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/291,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6MJSyw,polaris,2351246512,291,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-09-15T00:28:15Z,2024-09-15T00:28:15Z,The above failed tests don't fail in github pipelines and my local. I suspect it is related to network setting/status in your MacOS. Can you run two test cases separately to check it works? ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6MJSyw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/291,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6O553c,polaris,2397543900,291,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-10-07T17:52:38Z,2024-10-07T17:52:38Z,"Hi @sreev, are you still able to reproduce this?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6O553c/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/291,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6QaXsv,polaris,2422831919,291,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-10-18T16:24:16Z,2024-10-18T16:24:16Z,"Closing for now, but please feel free to re-open if this is still occurring. Thanks!","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6QaXsv/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/299,https://api.github.com/repos/apache/polaris/issues/299,polaris,2528938639,299,[BUG] Build failure with task `rat` ,aihuaxu,26491691,Aihua Xu,aihuaxu@gmail.com,CLOSED,2024-09-16T16:34:29Z,2024-09-16T17:00:14Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

When I run When you run `java -jar polaris-service/build/libs/polaris-service-999-SNAPSHOT.jar server`, logs are generated in` logs/ `folder and the build  `./gradlew build` would fail with license check.


### To Reproduce

* What went wrong:
Execution failed for task ':rat'.
> A failure occurred while executing org.nosphere.apache.rat.RatWork
   > Apache Rat audit failure - 2 unapproved licenses
        See file:///Users/aixu/polaris/build/reports/rat/index.html

Seems it's complaining the following two files:

Printing headers for files without AL header...

/Users/aixu/polaris/logs/request.log
/Users/aixu/polaris/logs/polaris.log

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/299/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/301,https://api.github.com/repos/apache/polaris/issues/301,polaris,2529098030,301,[BUG] Test failures when testing against H2 database,sfc-gh-aixu,109547839,Aihua Xu,,OPEN,2024-09-16T17:52:31Z,2024-09-16T17:52:31Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

Update metaStoreManager configuration in  polaris-service/src/test/resources/polaris-server-integrationtest.yml to

```
 metaStoreManager:
  type: eclipse-link
```
and then run `./gradlew build`.

Some tests in PolarisOverlappingTableTest.java would fail due to initialization conflict. 

### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/301/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/303,https://api.github.com/repos/apache/polaris/issues/303,polaris,2529354373,303,[FEATURE REQUEST] External catalog via REST delegation,jkolash,801170,Joshua Kolash,jkolash@toasttab.com,OPEN,2024-09-16T19:59:48Z,2024-11-05T18:47:38Z,"### Is your feature request related to a problem? Please describe.

I would like to ideally only configure 1 endpoint for all of my iceberg catalog readers and delegate through polaris.



### Describe the solution you'd like

I would like to be able to support external catalog delegating via rest endpoints. This would allow all external iceberg catalog locations to be managed in polaris but not have to directly integrate with multiple catalog endpoints client side.

Once an external catalog rest endpoint location is added to the polaris catalog, any existing integrations immediately are able to read that data if they have permission to do so. It may be possible to simply forward exiting oauth credentials or give polaris new credentials to use to talk to the external catalog.

### Describe alternatives you've considered

In spark for example you'd need to individually register each catalog endpoint namespace config among multiple clients or code bases. Doing it once on the polaris catalog would simplify integration.

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/303/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/303,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6SgOCS,polaris,2457919634,303,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-11-05T18:47:36Z,2024-11-05T18:47:36Z,"Hi @jkolash, this is being discussed on the mailing list:
https://lists.apache.org/thread/xb1ptmk80d39p5d6b4crq8dyqohr2580

One key issue is how auth should work if Polaris delegates to another REST catalog.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6SgOCS/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/304,https://api.github.com/repos/apache/polaris/issues/304,polaris,2529750181,304,[BUG] expired JWT token returns 5xx instead of 401,TomerHeber,12767692,Tomer Heber,,CLOSED,2024-09-17T01:09:12Z,2024-11-05T18:45:31Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

When sending an http request with an expired token, 5xx is returned instead of 401.

### To Reproduce

1. Enable JWTBroker.
2. Generate a token with credentials.
3. Wait 60 minutes.
4. Send a request with the expired token. Returns 5xx instead of 401.

```
oauth2:
  # type: test
  type: default
  tokenBroker:
    type: symmetric-key
    secret: polaris

authenticator:
  # class: org.apache.polaris.service.auth.TestInlineBearerTokenPolarisAuthenticator
  class: org.apache.polaris.service.auth.DefaultPolarisAuthenticator
  tokenBroker:
    type: symmetric-key
    secret: polaris
```

### Actual Behavior

5xx http response.

### Expected Behavior

401 http reposne.

### Additional context

The issue is with this code snippet:
https://github.com/apache/polaris/blob/main/polaris-service/src/main/java/org/apache/polaris/service/auth/JWTBroker.java#L59
```
 JWTVerifier verifier = JWT.require(getAlgorithm()).build();
  DecodedJWT decodedJWT = verifier.verify(token);
  Boolean isActive = decodedJWT.getClaim(CLAIM_KEY_ACTIVE).asBoolean();
  if (isActive == null || !isActive) {
      throw new NotAuthorizedException(""Token is not active"");
    }
    if (decodedJWT.getExpiresAtAsInstant().isBefore(Instant.now())) {
      throw new NotAuthorizedException(""Token has expired"");
    }
```

verifier.verify throws `JWTVerificationException` if the token verification fails.
https://github.com/auth0/java-jwt/blob/fb6d00ad9773c6e7624c518feb2d06ed191287fa/lib/src/main/java/com/auth0/jwt/JWTVerifier.java#L346

This is an uncaught exception.
The exception `NotAuthorizedException` should have been returned instead.



### System information

N/A","{""url"": ""https://api.github.com/repos/apache/polaris/issues/304/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/304,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6MU_WK,polaris,2354312586,304,NA,TomerHeber,12767692,Tomer Heber,,NA,2024-09-17T01:16:26Z,2024-09-17T01:16:26Z,"Consider using the decode function instead:
https://javadoc.io/doc/com.auth0/java-jwt/latest/com/auth0/jwt/JWT.html","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6MU_WK/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/304,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6SgNJD,polaris,2457915971,304,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-11-05T18:45:31Z,2024-11-05T18:45:31Z,"Should be fixed by #530, but please re-open if that's not the case","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6SgNJD/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/308,https://api.github.com/repos/apache/polaris/issues/308,polaris,2531887248,308,"[FEATURE REQUEST] Document how to setup, configure and use multi-realms",aihuaxu,26491691,Aihua Xu,aihuaxu@gmail.com,OPEN,2024-09-17T19:05:19Z,2025-01-16T17:33:46Z,"### Is your feature request related to a problem? Please describe.

Currently there is no document for multi-realms and it's not clear to me how we setup and bootstrap. 

### Describe the solution you'd like

_No response_

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/308/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/308,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6T36aT,polaris,2480907923,308,NA,Pranathi-star,52571012,Pranathi Kodicherla,,NA,2024-11-17T03:21:26Z,2024-11-17T03:21:26Z,I would like to take up this feature :) Can anyone share some inputs regarding this?,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6T36aT/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/316,https://api.github.com/repos/apache/polaris/issues/316,polaris,2547043917,316,[FEATURE REQUEST] Support endpoints field in the config endpoint,flyrain,1322359,Yufei Gu,yufei@apache.org,CLOSED,2024-09-25T06:21:34Z,2024-12-20T00:37:43Z,"### Is your feature request related to a problem? Please describe.

_No response_

### Describe the solution you'd like

The endpoints field was introduced in Iceberg REST spec recently to describe the server capabilities. 
https://github.com/apache/iceberg/blob/c0d73f4ef5c16401bdfd62e1745faf2fbbf62177/open-api/rest-catalog-open-api.yaml#L150

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/316/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/316,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6P9zIm,polaris,2415342118,316,NA,danielhumanmod,135958699,Daniel Tu,,NA,2024-10-15T23:33:46Z,2024-10-15T23:33:46Z,"Hi @flyrain , I am interested in working on this feature :)","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6P9zIm/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/316,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6P_inC,polaris,2415798722,316,NA,danielhumanmod,135958699,Daniel Tu,,NA,2024-10-16T05:56:47Z,2024-10-16T05:56:47Z,"And I have a question about the rule for adding API endpoints: do we mainly based on the access control privileges? 

For example: 
- if a user with `NAMESPACE_LIST` privilege, add these into endpoints
  - `GET /v1/{prefix}/namespaces` 
  - `GET /v1/{prefix}/namespaces/{namespace}`
  - `GET /v1/{prefix}/namespaces/{namespace}/tables`
  - `GET /v1/{prefix}/namespaces/{namespace}/tables/{table}`
- if a user with `NAMESPACE_CREATE`, add this into endpoints
   - `POST /v1/{prefix}/namespaces`
- if a user with `NAMESPACE_DROP `, add this into endpoints
  -  `DELETE /v1/{prefix}/namespaces'
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6P_inC/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/316,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6QGab_,polaris,2417600255,316,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-10-16T18:28:08Z,2024-10-16T18:28:08Z,"I don't believe it emits endpoints based on privileges; it should simply list all available endpoints. Even if a client lacks the privilege for a specific endpoint, they would still receive the full capabilities of the server.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6QGab_/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/316,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6QGfiv,polaris,2417621167,316,NA,danielhumanmod,135958699,Daniel Tu,,NA,2024-10-16T18:38:20Z,2024-10-16T18:38:20Z,"> I don't believe it emits endpoints based on privileges; it should simply list all available endpoints. Even if a client lacks the privilege for a specific endpoint, they would still receive the full capabilities of the server.

Thanks for the clarification! That approach makes a lot more sense, my earlier approach was overcomplicating it.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6QGfiv/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/316,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6QS-WK,polaris,2420893066,316,NA,danielhumanmod,135958699,Daniel Tu,,NA,2024-10-18T00:03:50Z,2024-10-18T00:03:50Z,"Hi @flyrain, I created a draft PR as the POC of this feature. However, Iâ€™d like your suggestion on one thing: the endpoints-related feature in Iceberg hasnâ€™t been released yet (current version 1.6.1) and is planned for 1.7.0. Iâ€™ve temporarily extended some necessary classes as a workaround. Would you suggest we proceed with the current approach, or would it be better to pause development and continue once 1.7.0 is released and integrated with Polaris?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6QS-WK/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/316,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6QTVIx,polaris,2420986417,316,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-10-18T00:44:12Z,2024-10-18T00:44:12Z, I'd recommend to wait for iceberg 1.7.0. It's not urgent as clients probably also wait for 1.7.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6QTVIx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/316,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6W1OLo,polaris,2530534120,316,NA,danielhumanmod,135958699,Daniel Tu,,NA,2024-12-10T06:10:38Z,2024-12-10T06:10:38Z,"Hi team, we can close this issue as it has been solved in #442 ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6W1OLo/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/318,https://api.github.com/repos/apache/polaris/issues/318,polaris,2548418971,318,[FEATURE REQUEST] Pre-auth rate limiter,andrew4699,7133966,Andrew Guterman,andrew.guterman1@gmail.com,OPEN,2024-09-25T16:17:16Z,2024-09-25T16:17:16Z,"### Is your feature request related to a problem? Please describe.

In https://github.com/apache/polaris/pull/278 we added a post-auth rate limiter. We discussed that there should also likely be a pre-auth one because Polaris will have already done some work by the time that rate limiter runs.

### Describe the solution you'd like

A pre-auth rate limiter. This doesn't necessarily have to be implemented _in_ Polaris, but could also be in the form of Docker/Kubernetes config for rate limiting at Envoy/Nginx.

### Describe alternatives you've considered

N/A

### Additional context

https://github.com/apache/polaris/pull/278/files#r1770776479","{""url"": ""https://api.github.com/repos/apache/polaris/issues/318/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/319,https://api.github.com/repos/apache/polaris/issues/319,polaris,2548549902,319,[FEATURE REQUEST] Update Polaris doc site with new getting started examples,kevinjqliu,9057843,Kevin Liu,,OPEN,2024-09-25T17:15:20Z,2024-09-25T17:15:20Z,"### Is your feature request related to a problem? Please describe.

Context: https://github.com/apache/polaris/pull/295#issuecomment-2353450842

https://polaris.apache.org/docs/quickstart

Update with new ""getting started guide"" for both Trino & Spark



### Describe the solution you'd like

_No response_

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/319/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/327,https://api.github.com/repos/apache/polaris/issues/327,polaris,2555351160,327,[BUG] Potential Unhandled exception in PolarisEntityResolver.java ,dbosco,2311778,Don Bosco Durai,,OPEN,2024-09-30T01:46:58Z,2024-10-10T21:52:50Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

In the following code:

https://github.com/apache/polaris/blob/b0eb0250c9ea564dfd85b101707e12341d9a723e/polaris-core/src/main/java/org/apache/polaris/core/persistence/PolarisEntityResolver.java#L291

```java
for (PolarisEntityCore resolveEntity : toResolve) {
  // get associate active record
  PolarisEntityActiveRecord activeEntityRecord = activeRecordIt.next();

  // if this entity has been dropped (null) or replaced (<> ids), then fail validation
  if (activeEntityRecord == null || activeEntityRecord.getId() != resolveEntity.getId()) {
    return false;
  }
}
```

If there are no elements in `activeRecordIt`, calling `.next()` will throw an exception before reaching the `activeEntityRecord == null` check.

Should we add a `.hasNext()` check before calling `.next()`? 

If this is indeed an issue, it seems like a trivial fix, and Iâ€™d be happy to address it.



https://github.com/apache/polaris/blob/b0eb0250c9ea564dfd85b101707e12341d9a723e/polaris-core/src/main/java/org/apache/polaris/core/persistence/PolarisEntityResolver.java#L291

`    for (PolarisEntityCore resolveEntity : toResolve) {
      // get associate active record
      PolarisEntityActiveRecord activeEntityRecord = activeRecordIt.next();

      // if this entity has been dropped (null) or replaced (<> ids), then fail validation
      if (activeEntityRecord == null || activeEntityRecord.getId() != resolveEntity.getId()) {
        return false;
      }
    }`

If there are no elements in activeRecordIt, then the .next() will throw an exception before reaching below. 
`      activeEntityRecord == null 
`
Should we check for `.hasNext()` before calling `.next()`. 

If it is indeed an issue, it seems to be an trivial fix and I am happy to do it. Please assign it to me. 


### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/327/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/327,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6OFTpq,polaris,2383755882,327,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-09-30T17:17:57Z,2024-09-30T17:17:57Z,"I think the issue goes a little deeper than a missing `hasNext`. The code seems to assume that `toResolve` will always have the same length as  `activeRecordIt` and that they will always be aligned (e.g. the Nth element in one corresponds to the Nth element in the other).

If this assumption is true, then we don't need the `hasNext` check, though we could maybe clarify this with a comment or improve readability.

If this assumption isn't true, the code needs to be fixed in more ways than with just a `hasNext` check.

I think the issue is this: whether or not the above assumption is true depends on the metastore implementation. Perhaps we could make  `lookupEntityActiveBatch` return a `Map`, but I'm not sure whether or not we want to change the interface for this. Another approach we could take is adding a test to ensure the assumption is always true.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6OFTpq/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/327,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ORLgc,polaris,2386868252,327,NA,dbosco,2311778,Don Bosco Durai,,NA,2024-10-01T19:42:01Z,2024-10-01T19:42:01Z,"@eric-maynard yes your correct. Assuming, the below call returns everything in the same order and length, it should be fine.
`    // now lookup all these entities by name
    Iterator<PolarisEntityActiveRecord> activeRecordIt =
        ms.lookupEntityActiveBatch(callCtx, entityActiveKeys).iterator();
`
If there is anything you want me to do, then let know. Thanks
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ORLgc/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/327,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6OlekM,polaris,2392189196,327,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-10-03T19:38:37Z,2024-10-03T19:38:37Z,"Personally I like the idea of making `lookupEntityActiveBatch` return a `Map` (or some other associative data structure) but I am probably more comfortable breaking APIs than some others. Without doing this, I'm not sure if there's any fix we can do right now.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6OlekM/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/327,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6PakEt,polaris,2406105389,327,NA,dbosco,2311778,Don Bosco Durai,,NA,2024-10-10T21:52:49Z,2024-10-10T21:52:49Z,"@eric-maynard I agree, the risk is too low. We could close this for now and revisit this at a later time.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6PakEt/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/329,https://api.github.com/repos/apache/polaris/issues/329,polaris,2557774382,329,[BUG] docker build failure,manojmukkamala,27603459,Manoj Mukkamala,,CLOSED,2024-09-30T22:43:24Z,2024-10-03T12:50:10Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

Running a fresh docker build based off of main branch:
`docker build . -t polaris:v20240930 --build-arg ECLIPSELINK=true --build-arg ECLIPSELINK_DEPS=org.postgresql:postgresql:42.7.4`

I tried removing the build args but same fate.

Error trace:
```
[+] Building 20.8s (12/15)                                                                                                                                                                                                                                                     docker:desktop-linux
 => [internal] load build definition from Dockerfile                                                                                                                                                                                                                                           0.0s
 => => transferring dockerfile: 1.85kB                                                                                                                                                                                                                                                         0.0s
 => [internal] load metadata for registry.access.redhat.com/ubi9/openjdk-21-runtime:1.20-2.1726695169                                                                                                                                                                                          0.4s
 => [internal] load metadata for registry.access.redhat.com/ubi9/openjdk-21:1.20-2.1726695192                                                                                                                                                                                                  0.2s
 => [internal] load .dockerignore                                                                                                                                                                                                                                                              0.0s
 => => transferring context: 906B                                                                                                                                                                                                                                                              0.0s
 => [internal] load build context                                                                                                                                                                                                                                                              0.3s
 => => transferring context: 1.93MB                                                                                                                                                                                                                                                            0.3s
 => [stage-1 1/5] FROM registry.access.redhat.com/ubi9/openjdk-21-runtime:1.20-2.1726695169@sha256:4c90561565a199aeec97bad3628030c0deede8b797f3899c45c3761d3e242604                                                                                                                            0.0s
 => => resolve registry.access.redhat.com/ubi9/openjdk-21-runtime:1.20-2.1726695169@sha256:4c90561565a199aeec97bad3628030c0deede8b797f3899c45c3761d3e242604                                                                                                                                    0.0s
 => CACHED [build 1/5] FROM registry.access.redhat.com/ubi9/openjdk-21:1.20-2.1726695192@sha256:7666303e9b1463b3a42fd43b18367be1a932b4c9aac4684a011332ae1f2840bd                                                                                                                               0.0s
 => => resolve registry.access.redhat.com/ubi9/openjdk-21:1.20-2.1726695192@sha256:7666303e9b1463b3a42fd43b18367be1a932b4c9aac4684a011332ae1f2840bd                                                                                                                                            0.0s
 => CACHED [stage-1 2/5] WORKDIR /app                                                                                                                                                                                                                                                          0.0s
 => [build 2/5] COPY --chown=default:root . /app                                                                                                                                                                                                                                               1.0s
 => [build 3/5] WORKDIR /app                                                                                                                                                                                                                                                                   0.1s
 => [build 4/5] RUN rm -rf build                                                                                                                                                                                                                                                               0.1s
 => ERROR [build 5/5] RUN ./gradlew --no-daemon --info ""-PeclipseLinkDeps=org.postgresql:postgresql:42.7.4"" -PeclipseLink=true clean prepareDockerDist                                                                                                                                        18.9s
------                                                                                                                                                                                                                                                                                              
 > [build 5/5] RUN ./gradlew --no-daemon --info ""-PeclipseLinkDeps=org.postgresql:postgresql:42.7.4"" -PeclipseLink=true clean prepareDockerDist:                                                                                                                                                    
0.120   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current                                                                                                                                                                                                               
0.120                                  Dload  Upload   Total   Spent    Left  Speed                                                                                                                                                                                                                 
100   167  100   167    0     0   1546      0 --:--:-- --:--:-- --:--:--  1546                                                                                                                                                                                                                      
100    64  100    64    0     0    226      0 --:--:-- --:--:-- --:--:--   226                                                                                                                                                                                                                      
0.419   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
0.419                                  Dload  Upload   Total   Spent    Left  Speed
100 43583  100 43583    0     0   409k      0 --:--:-- --:--:-- --:--:--  409k
0.587 Downloading https://services.gradle.org/distributions/gradle-8.10.2-bin.zip
1.098 .............10%.............20%.............30%.............40%.............50%.............60%.............70%.............80%.............90%.............100%
3.771 Initialized native services in: /home/default/.gradle/native
3.775 Initialized jansi services in: /home/default/.gradle/native
3.881 
3.881 Welcome to Gradle 8.10.2!
3.881 
3.881 Here are the highlights of this release:
3.881  - Support for Java 23
3.881  - Faster configuration cache
3.881  - Better configuration cache reports
3.881 
3.881 For more details see https://docs.gradle.org/8.10.2/release-notes.html
3.881 
3.882 Received JVM installation metadata from '/usr/lib/jvm/java-21-openjdk-21.0.4.0.7-1.el9.aarch64': {JAVA_HOME=/usr/lib/jvm/java-21-openjdk-21.0.4.0.7-1.el9.aarch64, JAVA_VERSION=21.0.4, JAVA_VENDOR=Red Hat, Inc., RUNTIME_NAME=OpenJDK Runtime Environment, RUNTIME_VERSION=21.0.4+7-LTS, VM_NAME=OpenJDK 64-Bit Server VM, VM_VERSION=21.0.4+7-LTS, VM_VENDOR=Red Hat, Inc., OS_ARCH=aarch64}
3.882 To honour the JVM settings for this build a single-use Daemon process will be forked. For more on this, please refer to https://docs.gradle.org/8.10.2/userguide/gradle_daemon.html#sec:disabling_the_daemon in the Gradle documentation.
3.883 Starting process 'Gradle build daemon'. Working directory: /home/default/.gradle/daemon/8.10.2 Command: /usr/lib/jvm/java-21-openjdk-21.0.4.0.7-1.el9.aarch64/bin/java -XX:MaxMetaspaceSize=768m --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.prefs/java.util.prefs=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.api=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-opens=java.base/java.nio.charset=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED -Xms2g -Xmx4g -Dfile.encoding=UTF-8 -Duser.country -Duser.language=en -Duser.variant -cp /home/default/.gradle/wrapper/dists/gradle-8.10.2-bin/a04bxjujx95o3nb99gddekhwo/gradle-8.10.2/lib/gradle-daemon-main-8.10.2.jar -javaagent:/home/default/.gradle/wrapper/dists/gradle-8.10.2-bin/a04bxjujx95o3nb99gddekhwo/gradle-8.10.2/lib/agents/gradle-instrumentation-agent-8.10.2.jar org.gradle.launcher.daemon.bootstrap.GradleDaemon 8.10.2
3.883 Successfully started process 'Gradle build daemon'
4.381 An attempt to start the daemon took 0.446 secs.
4.381 The client will now receive all logging from the daemon (pid: 67). The daemon log file: /home/default/.gradle/daemon/8.10.2/daemon-67.out.log
4.381 Daemon will be stopped at the end of the build 
4.581 Using 8 worker leases.
4.581 Configuration on demand is an incubating feature.
4.681 Received JVM installation metadata from '/usr/lib/jvm/java-21-openjdk-21.0.4.0.7-1.el9.aarch64': {JAVA_HOME=/usr/lib/jvm/java-21-openjdk-21.0.4.0.7-1.el9.aarch64, JAVA_VERSION=21.0.4, JAVA_VENDOR=Red Hat, Inc., RUNTIME_NAME=OpenJDK Runtime Environment, RUNTIME_VERSION=21.0.4+7-LTS, VM_NAME=OpenJDK 64-Bit Server VM, VM_VERSION=21.0.4+7-LTS, VM_VENDOR=Red Hat, Inc., OS_ARCH=aarch64}
4.881 Watching the file system is configured to be enabled if available
4.881 Not watching /app since the file system is not supported
4.881 File system watching is active
5.181 Starting Build
5.181 Generating /home/default/.gradle/caches/8.10.2/generated-gradle-jars/gradle-api-8.10.2.jar
9.581 Cannot use Kotlin build script compile avoidance with /home/default/.gradle/caches/8.10.2/generated-gradle-jars/gradle-api-8.10.2.jar: class org/gradle/internal/extensions/stdlib/AutoCloseableExtensionsKt: inline fun useToRun(): compile avoidance is not supported with public inline functions
10.28 Cannot use Kotlin build script compile avoidance with /home/default/.gradle/wrapper/dists/gradle-8.10.2-bin/a04bxjujx95o3nb99gddekhwo/gradle-8.10.2/lib/gradle-kotlin-dsl-extensions-8.10.2.jar: class org/gradle/kotlin/dsl/GradleApiKotlinDslExtensions_1cbh1oqkvm762j10e96dawuh5Kt: inline fun domainObjectContainer(): compile avoidance is not supported with public inline functions
10.28 Cannot use Kotlin build script compile avoidance with /home/default/.gradle/wrapper/dists/gradle-8.10.2-bin/a04bxjujx95o3nb99gddekhwo/gradle-8.10.2/lib/gradle-kotlin-dsl-8.10.2.jar: class org/gradle/kotlin/dsl/ArtifactHandlerScope: inline fun invoke(): compile avoidance is not supported with public inline functions
10.28 Caching disabled for Kotlin DSL script compilation (Settings/TopLevel/stage1) because:
10.28   Build cache is disabled
12.88 Caching disabled for Kotlin DSL accessors for settings 'app' because:
12.88   Build cache is disabled
12.88 Caching disabled for Kotlin DSL script compilation (Settings/TopLevel/stage2) because:
12.88   Build cache is disabled
13.48 Settings evaluated using settings file '/app/settings.gradle.kts'.
13.48 Using local directory build cache for the root build (location = /home/default/.gradle/caches/build-cache-1, removeUnusedEntriesAfter = 7 days).
13.48 Not watching /app/build-logic since the file system is not supported
13.48 Build cache key for Kotlin DSL script compilation (Settings/TopLevel/stage1) is 6aa17b1080677be63df300480b821639
13.68 Stored cache entry for Kotlin DSL script compilation (Settings/TopLevel/stage1) with cache key 6aa17b1080677be63df300480b821639
13.98 Caching disabled for generation of dependency accessors for libs because:
13.98   Not worth caching.
14.38 Projects loaded. Root project using build file '/app/build.gradle.kts'.
14.38 Included projects: [root project 'polaris', project ':aggregated-license-report', project ':polaris-core', project ':polaris-eclipselink', project ':polaris-service']
14.38 Caching disabled for generation of dependency accessors for baselibs because:
14.38   Not worth caching.
16.38 
16.38 > Configure project :polaris-build-logic
16.38 Evaluating project ':polaris-build-logic' using build file '/app/build-logic/build.gradle.kts'.
16.38 Build cache key for Kotlin DSL version catalog plugin accessors for classpath '2ee43e102ed4fdc1dd4a677bc6789b28' is d3b7baac27edb22bc2ba587695972932
16.38 Stored cache entry for Kotlin DSL version catalog plugin accessors for classpath '2ee43e102ed4fdc1dd4a677bc6789b28' with cache key d3b7baac27edb22bc2ba587695972932
16.38 Build cache key for Kotlin DSL plugin specs accessors for classpath '2ee43e102ed4fdc1dd4a677bc6789b28' is 923ba3c2e79d5e01d44b179e4732be86
16.38 Stored cache entry for Kotlin DSL plugin specs accessors for classpath '2ee43e102ed4fdc1dd4a677bc6789b28' with cache key 923ba3c2e79d5e01d44b179e4732be86
16.38 Build cache key for Kotlin DSL script compilation (Project/TopLevel/stage1) is fcede9bb8ec1e674dce20772f0ca7286
16.38 Stored cache entry for Kotlin DSL script compilation (Project/TopLevel/stage1) with cache key fcede9bb8ec1e674dce20772f0ca7286
16.38 Downloading https://plugins.gradle.org/m2/org/gradle/kotlin/kotlin-dsl/org.gradle.kotlin.kotlin-dsl.gradle.plugin/4.5.0/org.gradle.kotlin.kotlin-dsl.gradle.plugin-4.5.0.pom to /home/default/.gradle/.tmp/gradle_download3112339139151883249bin
16.38 Resource missing. [HTTP HEAD: https://plugins.gradle.org/m2/org/gradle/kotlin/kotlin-dsl/org.gradle.kotlin.kotlin-dsl.gradle.plugin/4.5.0/org.gradle.kotlin.kotlin-dsl.gradle.plugin-4.5.0.jar]
16.38 Downloading https://plugins.gradle.org/m2/org/gradle/kotlin/gradle-kotlin-dsl-plugins/4.5.0/gradle-kotlin-dsl-plugins-4.5.0.pom to /home/default/.gradle/.tmp/gradle_download3695938197964340704bin
16.38 Downloading https://plugins.gradle.org/m2/org/gradle/kotlin/gradle-kotlin-dsl-plugins/4.5.0/gradle-kotlin-dsl-plugins-4.5.0.module to /home/default/.gradle/.tmp/gradle_download10322050199855592695bin
16.38 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-sam-with-receiver/1.9.24/kotlin-sam-with-receiver-1.9.24.pom to /home/default/.gradle/.tmp/gradle_download11949809010877956493bin
16.38 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-assignment/1.9.24/kotlin-assignment-1.9.24.pom to /home/default/.gradle/.tmp/gradle_download17883712733665927144bin
16.38 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-gradle-plugin-api/1.9.24/kotlin-gradle-plugin-api-1.9.24.pom to /home/default/.gradle/.tmp/gradle_download8193870129122698104bin
16.38 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-gradle-plugins-bom/1.9.24/kotlin-gradle-plugins-bom-1.9.24.pom to /home/default/.gradle/.tmp/gradle_download15222335843229725045bin
16.38 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-gradle-plugin/1.9.24/kotlin-gradle-plugin-1.9.24.pom to /home/default/.gradle/.tmp/gradle_download9297164589882175696bin
16.38 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-gradle-plugins-bom/1.9.24/kotlin-gradle-plugins-bom-1.9.24.module to /home/default/.gradle/.tmp/gradle_download13212458152838886551bin
16.38 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-gradle-plugin-api/1.9.24/kotlin-gradle-plugin-api-1.9.24.module to /home/default/.gradle/.tmp/gradle_download278097712508080219bin
16.38 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-sam-with-receiver/1.9.24/kotlin-sam-with-receiver-1.9.24.module to /home/default/.gradle/.tmp/gradle_download9457988935737615887bin
16.38 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-gradle-plugin/1.9.24/kotlin-gradle-plugin-1.9.24.module to /home/default/.gradle/.tmp/gradle_download12049029137647872691bin
16.38 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-assignment/1.9.24/kotlin-assignment-1.9.24.module to /home/default/.gradle/.tmp/gradle_download2226569815217624424bin
16.38 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-stdlib/1.9.24/kotlin-stdlib-1.9.24.pom to /home/default/.gradle/.tmp/gradle_download5921974846685211172bin
16.38 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-stdlib/1.9.24/kotlin-stdlib-1.9.24.module to /home/default/.gradle/.tmp/gradle_download11851102621664158044bin
16.38 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-gradle-plugin-model/1.9.24/kotlin-gradle-plugin-model-1.9.24.pom to /home/default/.gradle/.tmp/gradle_download16311308074617018549bin
16.38 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-gradle-plugin-idea/1.9.24/kotlin-gradle-plugin-idea-1.9.24.pom to /home/default/.gradle/.tmp/gradle_download6706188642938625162bin
16.38 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-gradle-plugin-idea-proto/1.9.24/kotlin-gradle-plugin-idea-proto-1.9.24.pom to /home/default/.gradle/.tmp/gradle_download14343641585127724024bin
16.38 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-util-klib/1.9.24/kotlin-util-klib-1.9.24.pom to /home/default/.gradle/.tmp/gradle_download12287098580248076280bin
16.38 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-android-extensions/1.9.24/kotlin-android-extensions-1.9.24.pom to /home/default/.gradle/.tmp/gradle_download13233118845108098454bin
16.38 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-gradle-plugin-model/1.9.24/kotlin-gradle-plugin-model-1.9.24.module to /home/default/.gradle/.tmp/gradle_download294429433384495583bin
16.38 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-build-tools-api/1.9.24/kotlin-build-tools-api-1.9.24.pom to /home/default/.gradle/.tmp/gradle_download13375492019072527741bin
16.38 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-klib-commonizer-api/1.9.24/kotlin-klib-commonizer-api-1.9.24.pom to /home/default/.gradle/.tmp/gradle_download11722063507335706315bin
16.38 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-scripting-compiler-embeddable/1.9.24/kotlin-scripting-compiler-embeddable-1.9.24.pom to /home/default/.gradle/.tmp/gradle_download13867558230683456307bin
16.38 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-compiler-runner/1.9.24/kotlin-compiler-runner-1.9.24.pom to /home/default/.gradle/.tmp/gradle_download9235890318813288376bin
16.38 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-scripting-compiler-impl-embeddable/1.9.24/kotlin-scripting-compiler-impl-embeddable-1.9.24.pom to /home/default/.gradle/.tmp/gradle_download1741272193494537552bin
16.38 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-gradle-plugin-idea/1.9.24/kotlin-gradle-plugin-idea-1.9.24.module to /home/default/.gradle/.tmp/gradle_download4117774219261155166bin
16.39 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-compiler-embeddable/1.9.24/kotlin-compiler-embeddable-1.9.24.pom to /home/default/.gradle/.tmp/gradle_download12967859305948933807bin
16.39 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-tooling-core/1.9.24/kotlin-tooling-core-1.9.24.pom to /home/default/.gradle/.tmp/gradle_download12888143910735555608bin
16.39 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-gradle-plugin-annotations/1.9.24/kotlin-gradle-plugin-annotations-1.9.24.pom to /home/default/.gradle/.tmp/gradle_download6211815101419842665bin
16.39 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-native-utils/1.9.24/kotlin-native-utils-1.9.24.pom to /home/default/.gradle/.tmp/gradle_download14596785842292576370bin
16.39 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-project-model/1.9.24/kotlin-project-model-1.9.24.pom to /home/default/.gradle/.tmp/gradle_download13943615200448557468bin
16.39 Downloading https://plugins.gradle.org/m2/org/jetbrains/annotations/13.0/annotations-13.0.pom to /home/default/.gradle/.tmp/gradle_download9287559426630444869bin
16.48 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-util-io/1.9.24/kotlin-util-io-1.9.24.pom to /home/default/.gradle/.tmp/gradle_download1449150428559909651bin
16.48 Downloading https://plugins.gradle.org/m2/org/jetbrains/intellij/deps/trove4j/1.0.20200330/trove4j-1.0.20200330.pom to /home/default/.gradle/.tmp/gradle_download4045467202652162498bin
16.48 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-daemon-embeddable/1.9.24/kotlin-daemon-embeddable-1.9.24.pom to /home/default/.gradle/.tmp/gradle_download9153006733725273986bin
16.58 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-daemon-client/1.9.24/kotlin-daemon-client-1.9.24.pom to /home/default/.gradle/.tmp/gradle_download113468790370614351bin
16.58 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlinx/kotlinx-coroutines-core-jvm/1.5.0/kotlinx-coroutines-core-jvm-1.5.0.pom to /home/default/.gradle/.tmp/gradle_download6965714205455364711bin
16.58 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlinx/kotlinx-coroutines-core-jvm/1.5.0/kotlinx-coroutines-core-jvm-1.5.0.module to /home/default/.gradle/.tmp/gradle_download14951138953296544452bin
16.68 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-scripting-jvm/1.9.24/kotlin-scripting-jvm-1.9.24.pom to /home/default/.gradle/.tmp/gradle_download3728612862775480221bin
16.68 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-scripting-common/1.9.24/kotlin-scripting-common-1.9.24.pom to /home/default/.gradle/.tmp/gradle_download17973510997940386114bin
16.78 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-gradle-plugin-model/1.9.24/kotlin-gradle-plugin-model-1.9.24.jar to /home/default/.gradle/.tmp/gradle_download13378767687543044236bin
16.78 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-gradle-plugin-api/1.9.24/kotlin-gradle-plugin-api-1.9.24.jar to /home/default/.gradle/.tmp/gradle_download2594969307892263867bin
16.78 Downloading https://plugins.gradle.org/m2/org/jetbrains/annotations/13.0/annotations-13.0.jar to /home/default/.gradle/.tmp/gradle_download9929171418549424072bin
16.78 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-gradle-plugin-api/1.9.24/kotlin-gradle-plugin-api-1.9.24-gradle82.jar to /home/default/.gradle/.tmp/gradle_download5906126424216510023bin
16.78 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-stdlib/1.9.24/kotlin-stdlib-1.9.24.jar to /home/default/.gradle/.tmp/gradle_download2244876487343464927bin
16.78 Downloading https://plugins.gradle.org/m2/org/gradle/kotlin/gradle-kotlin-dsl-plugins/4.5.0/gradle-kotlin-dsl-plugins-4.5.0.jar to /home/default/.gradle/.tmp/gradle_download13067204508280929669bin
16.78 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-assignment/1.9.24/kotlin-assignment-1.9.24-gradle82.jar to /home/default/.gradle/.tmp/gradle_download9189519252899499680bin
16.78 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-sam-with-receiver/1.9.24/kotlin-sam-with-receiver-1.9.24-gradle82.jar to /home/default/.gradle/.tmp/gradle_download1554770205080505574bin
16.88 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-gradle-plugin-idea-proto/1.9.24/kotlin-gradle-plugin-idea-proto-1.9.24.jar to /home/default/.gradle/.tmp/gradle_download14776933299966322185bin
16.88 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-gradle-plugin-idea/1.9.24/kotlin-gradle-plugin-idea-1.9.24.jar to /home/default/.gradle/.tmp/gradle_download14656447612151380924bin
16.88 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-gradle-plugin/1.9.24/kotlin-gradle-plugin-1.9.24-gradle82.jar to /home/default/.gradle/.tmp/gradle_download12117535565642791322bin
16.88 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-klib-commonizer-api/1.9.24/kotlin-klib-commonizer-api-1.9.24.jar to /home/default/.gradle/.tmp/gradle_download9547921332311467276bin
16.88 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-native-utils/1.9.24/kotlin-native-utils-1.9.24.jar to /home/default/.gradle/.tmp/gradle_download4725588246713908083bin
16.88 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-util-klib/1.9.24/kotlin-util-klib-1.9.24.jar to /home/default/.gradle/.tmp/gradle_download10622467134972617615bin
16.88 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-build-tools-api/1.9.24/kotlin-build-tools-api-1.9.24.jar to /home/default/.gradle/.tmp/gradle_download15066236650491773265bin
16.88 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-android-extensions/1.9.24/kotlin-android-extensions-1.9.24.jar to /home/default/.gradle/.tmp/gradle_download1102191297881475458bin
16.98 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-compiler-runner/1.9.24/kotlin-compiler-runner-1.9.24.jar to /home/default/.gradle/.tmp/gradle_download6902559500743983442bin
16.98 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-compiler-embeddable/1.9.24/kotlin-compiler-embeddable-1.9.24.jar to /home/default/.gradle/.tmp/gradle_download4048797024190950753bin
16.98 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-scripting-compiler-embeddable/1.9.24/kotlin-scripting-compiler-embeddable-1.9.24.jar to /home/default/.gradle/.tmp/gradle_download7953171791306251031bin
16.98 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-scripting-compiler-impl-embeddable/1.9.24/kotlin-scripting-compiler-impl-embeddable-1.9.24.jar to /home/default/.gradle/.tmp/gradle_download7941226915023705954bin
17.08 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-gradle-plugin-annotations/1.9.24/kotlin-gradle-plugin-annotations-1.9.24.jar to /home/default/.gradle/.tmp/gradle_download6231797195657365145bin
17.08 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-util-io/1.9.24/kotlin-util-io-1.9.24.jar to /home/default/.gradle/.tmp/gradle_download9069724537314452069bin
17.08 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-project-model/1.9.24/kotlin-project-model-1.9.24.jar to /home/default/.gradle/.tmp/gradle_download13253287141369947462bin
17.08 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-tooling-core/1.9.24/kotlin-tooling-core-1.9.24.jar to /home/default/.gradle/.tmp/gradle_download9718147108627998807bin
17.08 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-daemon-embeddable/1.9.24/kotlin-daemon-embeddable-1.9.24.jar to /home/default/.gradle/.tmp/gradle_download16852661795046375815bin
17.18 Downloading https://plugins.gradle.org/m2/org/jetbrains/intellij/deps/trove4j/1.0.20200330/trove4j-1.0.20200330.jar to /home/default/.gradle/.tmp/gradle_download14316440318324639185bin
17.18 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-scripting-jvm/1.9.24/kotlin-scripting-jvm-1.9.24.jar to /home/default/.gradle/.tmp/gradle_download5824309605794783409bin
17.18 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlinx/kotlinx-coroutines-core-jvm/1.5.0/kotlinx-coroutines-core-jvm-1.5.0.jar to /home/default/.gradle/.tmp/gradle_download14620608413889637754bin
17.18 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-daemon-client/1.9.24/kotlin-daemon-client-1.9.24.jar to /home/default/.gradle/.tmp/gradle_download7281271361885742428bin
17.28 Downloading https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-scripting-common/1.9.24/kotlin-scripting-common-1.9.24.jar to /home/default/.gradle/.tmp/gradle_download15230286539963177485bin
18.68 
18.68 FAILURE: Build failed with an exception.
18.68 
18.68 * What went wrong:
18.68 A problem occurred configuring project ':polaris-build-logic'.
18.68 > Could not resolve all artifacts for configuration ':polaris-build-logic:classpath'.
18.68    > Could not download kotlin-gradle-plugin-1.9.24-gradle82.jar (org.jetbrains.kotlin:kotlin-gradle-plugin:1.9.24)
18.68       > Could not get resource 'https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-gradle-plugin/1.9.24/kotlin-gradle-plugin-1.9.24-gradle82.jar'.
18.68          > Failed to move file '/home/default/.gradle/.tmp/gradle_download12117535565642791322bin' into filestore at 'org.jetbrains.kotlin/kotlin-gradle-plugin/1.9.24/b6f5f875b19f9240f2e83e00f6f2b9dff1ebc2c3/kotlin-gradle-plugin-1.9.24-gradle82.jar' 
18.68             > Failed to create directory '/home/default/.gradle/caches/modules-2/files-2.1/org.jetbrains.kotlin/kotlin-gradle-plugin/1.9.24/b6f5f875b19f9240f2e83e00f6f2b9dff1ebc2c3'
18.68    > Could not download kotlin-compiler-embeddable-1.9.24.jar (org.jetbrains.kotlin:kotlin-compiler-embeddable:1.9.24)
18.68       > Could not get resource 'https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-compiler-embeddable/1.9.24/kotlin-compiler-embeddable-1.9.24.jar'.
18.68          > Failed to move file '/home/default/.gradle/.tmp/gradle_download4048797024190950753bin' into filestore at 'org.jetbrains.kotlin/kotlin-compiler-embeddable/1.9.24/78dab849090e6c5e2eadb6e59a11cdc28fb67a08/kotlin-compiler-embeddable-1.9.24.jar' 
18.68             > Failed to create directory '/home/default/.gradle/caches/modules-2/files-2.1/org.jetbrains.kotlin/kotlin-compiler-embeddable/1.9.24/78dab849090e6c5e2eadb6e59a11cdc28fb67a08'
18.68    > Could not download kotlin-scripting-jvm-1.9.24.jar (org.jetbrains.kotlin:kotlin-scripting-jvm:1.9.24)
18.68       > Could not get resource 'https://plugins.gradle.org/m2/org/jetbrains/kotlin/kotlin-scripting-jvm/1.9.24/kotlin-scripting-jvm-1.9.24.jar'.
18.68          > Failed to move file '/home/default/.gradle/.tmp/gradle_download5824309605794783409bin' into filestore at 'org.jetbrains.kotlin/kotlin-scripting-jvm/1.9.24/f179cc31fb89102c0e229c23b7d852d9840e13c7/kotlin-scripting-jvm-1.9.24.jar' 
18.68             > Failed to create directory '/home/default/.gradle/caches/modules-2/files-2.1/org.jetbrains.kotlin/kotlin-scripting-jvm/1.9.24/f179cc31fb89102c0e229c23b7d852d9840e13c7'
18.68 
18.68 * Try:
18.68 > Run with --stacktrace option to get the stack trace.
18.68 > Run with --debug option to get more log output.
18.68 > Run with --scan to get full insights.
18.68 > Get more help at https://help.gradle.org.
18.68 
18.68 BUILD FAILED in 18s
18.68 Some of the file system contents retained in the virtual file system are on file systems that Gradle doesn't support watching. The relevant state was discarded to ensure changes to these locations are properly detected. You can override this by explicitly enabling file system watching.
------
Dockerfile:35
--------------------
  33 |     
  34 |     # Build the rest catalog
  35 | >>> RUN ./gradlew --no-daemon --info ${ECLIPSELINK_DEPS+""-PeclipseLinkDeps=$ECLIPSELINK_DEPS""} -PeclipseLink=$ECLIPSELINK clean prepareDockerDist
  36 |     
  37 |     FROM registry.access.redhat.com/ubi9/openjdk-21-runtime:1.20-2.1726695169
--------------------
ERROR: failed to solve: process ""/bin/sh -c ./gradlew --no-daemon --info ${ECLIPSELINK_DEPS+\""-PeclipseLinkDeps=$ECLIPSELINK_DEPS\""} -PeclipseLink=$ECLIPSELINK clean prepareDockerDist"" did not complete successfully: exit code: 1
```

### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/329/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/329,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6OZyK9,polaris,2389123773,329,NA,MonkeyCanCode,29619290,,,NA,2024-10-02T16:39:46Z,2024-10-02T16:39:46Z,@manojmukkamala quick test on local with latest code show it is working for my machine. May need more info to debug this.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6OZyK9/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/329,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6OaGbi,polaris,2389206754,329,NA,manojmukkamala,27603459,Manoj Mukkamala,,NA,2024-10-02T17:20:54Z,2024-10-02T17:20:54Z,oh! let me try pruning by docker build cache.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6OaGbi/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/329,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6OaPMd,polaris,2389242653,329,NA,manojmukkamala,27603459,Manoj Mukkamala,,NA,2024-10-02T17:38:16Z,2024-10-02T17:38:16Z,"I apologize, this was an issue on my side. clearing docker build cache and starting from scratch fixed it. Thanks for looking into it though. 

Btw, it would be cool if there is a hosted docker image for polaris so we don't have to deal with building stuff locally.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6OaPMd/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/329,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Oh-Xu,polaris,2391270894,329,NA,ebyhr,6237050,Yuya Ebihara,,NA,2024-10-03T12:15:44Z,2024-10-03T12:15:44Z,">  it would be cool if there is a hosted docker image for polaris

@manojmukkamala I totally agree with you! Can we close this issue and continue in https://github.com/apache/polaris/issues/152? ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Oh-Xu/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/329,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6OiPa4,polaris,2391340728,329,NA,manojmukkamala,27603459,Manoj Mukkamala,,NA,2024-10-03T12:50:10Z,2024-10-03T12:50:10Z,sure!,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6OiPa4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/336,https://api.github.com/repos/apache/polaris/issues/336,polaris,2561124886,336,[FEATURE REQUEST] External IdP / Token Service,danyel-g,137864970,Danyel G.,,OPEN,2024-10-02T09:50:24Z,2024-10-02T09:50:24Z,"### Is your feature request related to a problem? Please describe.

As most companies, we already have a central identity management system. All enterprise systems must integrate with this IdP.
 
Currently we are missing a guide on how to configure Polaris with an external IdP / Token Service. Having guides for standard IdPs such as Entra ID would be great.

### Describe the solution you'd like

Provide a straight forward way to configure Polaris with standard IdPs and provide documentation on a minimal configuration for commonly used IdPs. 

### Describe alternatives you've considered

There is no alternative. Enterprises require an IdP integration.

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/336/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/342,https://api.github.com/repos/apache/polaris/issues/342,polaris,2563210469,342,[FEATURE REQUEST] support for returning client region in the loadTable response for S3,munendrasn,9696252,S N Munendra,,CLOSED,2024-10-03T06:15:03Z,2024-12-12T11:34:24Z,"### Is your feature request related to a problem? Please describe.

AWS s3 by default fails when making cross region calls. Latest version of AWS s3 sdk support crossRegionAccess but Iceberg doesn't yet support this [functionality](https://github.com/apache/iceberg/pull/9804). 
Any cross region calls are failing 

### Describe the solution you'd like

It would be great to specify the client.region as part of loadTableResponse in `config` block along with Credentials. This is property defined by RESTCatalog openAPI [spec](https://github.com/apache/iceberg/blob/b1d38b3cac326da296b770c8ab9219bc4f791666/open-api/rest-catalog-open-api.yaml#L3127)


### Describe alternatives you've considered

Using the crossRegionAccess property. Maybe once Iceberg add support, it would be great to add this property to the spec too

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/342/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/342,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6OoEWd,polaris,2392868253,342,NA,munendrasn,9696252,S N Munendra,,NA,2024-10-04T05:45:54Z,2024-10-04T05:45:54Z,FYI @dennishuo ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6OoEWd/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/345,https://api.github.com/repos/apache/polaris/issues/345,polaris,2567580587,345,[BUG] CLI doesn't work when just providing --host,lrichards-etsy,81712933,,,CLOSED,2024-10-05T01:16:31Z,2024-10-07T23:50:25Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

When using a host where the port can be inferred the CLI still tries to put the default 8181 at the end, which makes the call error/hang.

### To Reproduce

`./polaris --host some.hosted.url --client-id <client-id> --client-secret <client-secret> catalogs list`


### Actual Behavior

Returns back `http://some.hosted.url:8181/api/management/v1` & `http://some.hosted.url:8181/api/catalog/v1`


### Expected Behavior

Expecting the urls to be `http://some.hosted.url/api/management/v1` & `http://some.hosted.url/api/catalog/v1`

### Additional context

The CLI code that needs updating is here - https://github.com/apache/polaris/blob/main/regtests/client/python/cli/polaris_cli.py#L110-L112

If a host is added but no port is given it should not try and use the default one. 

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/345/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/345,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6OxUD5,polaris,2395291897,345,NA,MonkeyCanCode,29619290,,,NA,2024-10-06T04:43:11Z,2024-10-06T04:43:11Z,"@lrichards-etsy I think this is controlled by optional parameter `--port`. Here is the usage page:
```
./polaris --help
...
usage: polaris_cli.py [-h] [--host HOST] [--port PORT] [--client-id CLIENT_ID] [--client-secret CLIENT_SECRET]
                      [--access-token ACCESS_TOKEN]
                      {catalogs,principals,principal-roles,catalog-roles,privileges,namespaces} ...
```

This line set the default port to 8181: https://github.com/apache/polaris/blob/main/regtests/client/python/cli/options/parser.py#L41

Now back to the issue mentioned above, here will be the right command to use (assuming the target port to be 443):
```
./polaris --host some.hosted.url --port 443 --client-id <client-id> --client-secret <client-secret> catalogs list
```
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6OxUD5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/345,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Oy-NM,polaris,2395726668,345,NA,lrichards-etsy,81712933,,,NA,2024-10-07T01:37:16Z,2024-10-07T01:37:16Z,"@MonkeyCanCode thanks for the reply! 

I can get the CLI working if I pass in the target port, but the host URL for the ingress service that I created for my K8 cluster can also be used without passing in the port and it was that pathway that I was trying to get to work. The only way it did was by removing the need for the port in the URL created by the CLI.

Wondering if just using the host without the port is a big enough use case to update the CLI code? Or if people think its too small to warrant a code update to handle it. 
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Oy-NM/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/345,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6OzIwL,polaris,2395769867,345,NA,MonkeyCanCode,29619290,,,NA,2024-10-07T02:31:48Z,2024-10-07T02:31:48Z,"> @MonkeyCanCode thanks for the reply! 
> 
> I can get the CLI working if I pass in the target port, but the host URL for the ingress service that I created for my K8 cluster can also be used without passing in the port and it was that pathway that I was trying to get to work. The only way it did was by removing the need for the port in the URL created by the CLI.
> 
> Wondering if just using the host without the port is a big enough use case to update the CLI code? Or if people think its too small to warrant a code update to handle it. 
> 

I am not quite sure I am following. For k8s Ingress, you will only be able to use port 80 or 443 (don't think it is allowed to be changed). Now assuming we are using 443 and have a path that is mapped to the service 8181 for Polaris, you should still be able to access Polaris on port 443 via CLI when hitting the ingress instead of the pod directly. Maybe I am missing something here. Do you mind adding in a bit more details such as the sample ingress config etc. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6OzIwL/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/345,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6O3VLf,polaris,2396869343,345,NA,lrichards-etsy,81712933,,,NA,2024-10-07T13:02:03Z,2024-10-07T13:02:03Z,"@MonkeyCanCode Sorry for the confusion. 

The following works fine - `./polaris --host some.hosted.url --port 80 --client-id <client-id> --client-secret <client-secret> catalogs list` for me. So this really isn't a bug anymore. 

What I was trying to explain (pretty badly ðŸ˜† ) is that the above creates a URL like so `http://some.hosted.url:80/api/catalog/v1` -- but the URL `http://some.hosted.url/api/catalog/v1` also works for talking to Polaris for my setup (which I've tested). The later configuration isn't supported in the CLI as it always need a port. I thought maybe it would be worth handling that use case, but passing in the port is fine. 

I'm fine with closing this bug report :) ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6O3VLf/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/345,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6O5tbZ,polaris,2397492953,345,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-10-07T17:24:33Z,2024-10-07T17:24:33Z,"So the default port is 8181, but are you basically suggesting we should default to 80 if the host is provided?

I think we should still treat 8181 as the Polaris port; you can imagine using the CLI with two Polaris instances and wanting to connect to both but not wanting to have to specify a port.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6O5tbZ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/345,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6O8W10,polaris,2398186868,345,NA,lrichards-etsy,81712933,,,NA,2024-10-07T23:45:21Z,2024-10-07T23:45:21Z,Closing this bug issue -- CLI works when a port is given.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6O8W10/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/345,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6O8ZZ1,polaris,2398197365,345,NA,lrichards-etsy,81712933,,,NA,2024-10-07T23:49:47Z,2024-10-07T23:49:47Z,"> So the default port is 8181, but are you basically suggesting we should default to 80 if the host is provided?

Defaulting to 8181 makes sense. I was suggesting a way to use the CLI if you had a URL where the port didn't need to be provided. Buts its all good. I've closed the bug and will pass in the port for my use case going forward.  ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6O8ZZ1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/349,https://api.github.com/repos/apache/polaris/issues/349,polaris,2570259532,349,[BUG] Failed to Mount Local Volume During Quick Start Guide Execution,chukei2,165863102,,,CLOSED,2024-10-07T12:10:17Z,2024-10-18T16:22:33Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

When following the quick start guide in the Polaris catalog document (https://polaris.io/#section/Quick-Start/Deploying-Polaris) after cloning the repository, the following error occurs:

Error response from daemon: failed to mount local volume: mount /host_mnt/Users/<username>/documents/polaris/regtests/output:/var/lib/docker/volumes/polaris_local_output/_data, flags: 0x1000: no such file or directory


### To Reproduce


Follow the quick start guide in the Polaris catalog document (https://polaris.io/#section/Quick-Start/Deploying-Polaris).

1. `cd ~git` 
`clone https://github.com/apache/polaris.git` 
1. `brew install --cask docker`
1. `cd ~/polaris`
`brew install openjdk@21 jenv`
`jenv add $(brew --prefix openjdk@21)`
`jenv local 21`
1. `cd ~/polaris'
'docker compose -f docker-compose.yml up --build`

### Actual Behavior

The process fails with the error message indicating that the local volume could not be mounted because the specified directory does not exist.

### Expected Behavior

Docker should start up without any errors.

### Additional context

![image](https://github.com/user-attachments/assets/5acb3cd2-47e3-4403-9e6f-3647fb9f3bd7)


### System information

OS: macOS
Polaris catalog version: Latest
Cloud service used: AWS S3","{""url"": ""https://api.github.com/repos/apache/polaris/issues/349/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/349,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6O5cGc,polaris,2397421980,349,NA,adutra,463876,Alexandre Dutra,,NA,2024-10-07T16:46:37Z,2024-10-07T16:46:37Z,"I could easily reproduce, FYI.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6O5cGc/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/349,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6O-57f,polaris,2398854879,349,NA,MonkeyCanCode,29619290,,,NA,2024-10-08T05:13:12Z,2024-10-08T05:13:12Z,"I recalled this used to work an there is no change for the mount part for likes 3 months or so. Then I found https://github.com/docker/for-mac/issues/7227 which seems to be related. 

Here is a sample PR to fix this issue for now in case if we can't have docker issue fix: https://github.com/apache/polaris/pull/356","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6O-57f/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/358,https://api.github.com/repos/apache/polaris/issues/358,polaris,2572913727,358,[BUG]  Inability to Create Catalog via REST API Without Using Polaris CLI First,mouadk,32769487,,,CLOSED,2024-10-08T11:26:42Z,2025-01-03T08:29:59Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

When creating a catalog using the CLI, a CreateCatalogRequest is created, and a CatalogEntity gets persisted in the underlying storage. During this process, the IcebergCatalogAdapter#getConfig (corresponding to the api/v1/config) is invoked, which fetches the catalog name surfaced in the warehouse field and returns properties (https://iceberg.apache.org/docs/latest/configuration/#catalog-properties) for overrides if applicable.

However, when creating a catalog for the first time (assuming it was not done using the Polaris CLI), there is no existing catalog unless you bypass the api/v1/config call and directly invoke catalog creation, similar to the CLI (as seen in regtests). For example, when using the Java core API, the process first fetches the config during catalog build (org.apache.iceberg.rest.RESTSessionCatalog.initialize) to determine if any overrides are required. This results in the error:


`Exception in thread ""main"" org.apache.iceberg.exceptions.RESTException: Unable to process: Unable to find warehouse XXXX 
`

I am forced to first create the catalog using the Polaris CLI and cannot achieve the same via the REST endpoint by specifying the warehouse location in the configuration.

Would returning something like {""defaults"":{},""overrides"":{}} be a solution in this case? Also, why is it that the warehouse field requires the catalog name instead of allowing a direct reference to locations like S3 or Blob storage?

Is this expected behavior; where we must first create the catalog using the Polaris CLI? 
Or did I overlook something?

Thanks in advance.


### To Reproduce

Use Java Core API to create a Catalog. 

### Actual Behavior

If Catalog unknown to Polaris, Error is raised when creating a new catalog (NOT FOUND)

### Expected Behavior

Empty Result ? 

### Additional context

_No response_

### System information

MacBook Pro: 2.9 GHz Quad-Core Intel Core i7
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/358/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/358,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6PJRCx,polaris,2401570993,358,NA,mouadk,32769487,,,NA,2024-10-09T07:39:13Z,2024-10-09T07:39:13Z,Also it looks like the implementation is not matching the API Spec https://github.com/apache/iceberg/blob/208ab20dc9ab8bcab3ee525d0ddaba80eeae7609/open-api/rest-catalog-open-api.yaml#L75,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6PJRCx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/358,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Uuvve,polaris,2495282142,358,NA,MonkeyCanCode,29619290,,,NA,2024-11-23T03:53:13Z,2024-11-23T03:53:13Z,Something seems to be off. I do recalled I can do those via REST directly. Will set up a test environment then provide an update. ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Uuvve/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/358,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6UxpZG,polaris,2496042566,358,NA,MonkeyCanCode,29619290,,,NA,2024-11-24T14:46:58Z,2024-11-24T14:46:58Z,"@mouadk 

Here is the steps I performed to create catalog via REST directly without going through CLI:

show current catalogs if any:
```sh
yong@DESKTOP:~$ curl -X GET -H ""Authorization: Bearer principal:root;realm:default-realm"" http://localhost:8181/api/management/v1/catalogs
{""catalogs"":[]}
```

create a new catalog with file as storage backend (file is only for local testing purpose):
```sh
yong@DESKTOP:~$ curl -X POST -H ""Authorization: Bearer principal:root;realm:default-realm"" ""http://localhost:8181/api/management/v1/catalogs"" \
>   -H ""Content-Type: application/json"" \
>   -d '{
>         ""catalog"": {
>           ""name"": ""polaris"",
>           ""type"": ""INTERNAL"",
>           ""readOnly"": false,
>           ""properties"": {
>             ""default-base-location"": ""file:///tmp/polaris/""
>           },
>           ""storageConfigInfo"": {
>             ""storageType"": ""FILE"",
>             ""allowedLocations"": [
>               ""file:///tmp""
>             ]
>           }
>         }
>       }'
```

list the catalogs again:
```sh
yong@DESKTOP:~$ curl -X GET -H ""Authorization: Bearer principal:root;realm:default-realm"" http://localhost:8181/api/management/v1/catalogs
{""catalogs"":[{""type"":""INTERNAL"",""type"":""INTERNAL"",""name"":""polaris"",""properties"":{""default-base-location"":""file:///tmp/polaris/""},""createTimestamp"":1732459417891,""lastUpdateTimestamp"":1732459417891,""entityVersion"":1,""storageConfigInfo"":{""storageType"":""FILE"",""storageType"":""FILE"",""allowedLocations"":[""file:///tmp"",""file:///tmp/polaris/""]}}]}
```

Let me know if is still causing issue for your setup.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6UxpZG/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/358,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZG16r,polaris,2568707755,358,NA,MonkeyCanCode,29619290,,,NA,2025-01-03T05:21:59Z,2025-01-03T05:21:59Z,@flyrain should we close this one as the above snippets show it can be done without CLI (via curl)?,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZG16r/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/358,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZHIZW,polaris,2568783446,358,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2025-01-03T07:16:08Z,2025-01-03T07:16:08Z,"@mouadk This behavior is expected. The Iceberg REST specification is intentionally scoped to operate at the table and namespace level, treating any concepts beyond that as implementation-specific details.

Catalog server implementations, such as Polaris, may introduce additional layers(e.g., catalog) beyond namespaces. While these layers can be inferred from the `warehouse` field in the `config` endpoint, such implementations are neither standardized nor mandated by the Iceberg REST specification.

With that, users cannot rely on the Iceberg REST client to create a Polaris catalog, as it does not have knowledge of Polaris-specific concepts or higher-level abstractions. To create Polaris catalogs, the Polaris REST API or CLI should be used. This separation ensures that implementation-specific details remain decoupled from the standardized REST API.

Thanks @MonkeyCanCode for pinging me here. I think we can close this one.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZHIZW/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/358,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZHX-V,polaris,2568847253,358,NA,mouadk,32769487,,,NA,2025-01-03T08:28:01Z,2025-01-03T08:28:01Z,"Hello @MonkeyCanCode, I was using the iceberg core client to create the catalog, what @flyrain said makes sense, thanks for the explanation and sorry for my late response. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZHX-V/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/358,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZHYdN,polaris,2568849229,358,NA,MonkeyCanCode,29619290,,,NA,2025-01-03T08:29:58Z,2025-01-03T08:29:58Z,"> Hello @MonkeyCanCode, I was using the iceberg core client to create the catalog, what @flyrain said makes sense, thanks for the explanation and sorry for my late response. 

All good, thanks for the clarification. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZHYdN/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/359,https://api.github.com/repos/apache/polaris/issues/359,polaris,2573629919,359,[BUG] CatalogAdmin cannot grant catalog roles to principal roles,collado-mike,40346148,Michael Collado,,CLOSED,2024-10-08T16:04:12Z,2024-10-09T21:06:04Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

The `catalog_admin` catalog role is intended to manage access privileges within a given catalog. The `catalog_admin` can create CatalogRoles and grant those roles privileges. However, as is, the `catalog_admin` cannot grant those CatalogRoles to PrincipalRoles.

The `service_admin` principal role manages Principals and PrincipalRoles, but is intended to be distinct from the `catalog_admin` in that the `service_admin` cannot grant privileges to catalog-level entities. This includes granting CatalogRoles to PrincipalRoles.

Thus, the only way to grant PrincipalRoles to catalog-level entities is for the `service_admin` to also be the `catalog_admin` for every catalog. This defeats the entire purpose of keeping these roles separate, which was to allow admins to separate responsibilities and prevent a single set of credentials from having the ability to access all data in any catalog within a realm. 

### To Reproduce

1. As `service_admin`, create a Catalog and grant the `catalog_admin` role to another PrincipalRole
2. As a member of this PrincipalRole, create a CatalogRole and attempt to grant it to a third PrincipalRole

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/359/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/363,https://api.github.com/repos/apache/polaris/issues/363,polaris,2576957845,363,[FEATURE REQUEST] CatalogAdmin should be able to list principal roles,collado-mike,40346148,Michael Collado,,OPEN,2024-10-09T21:05:49Z,2024-10-09T21:06:02Z,"### Is your feature request related to a problem? Please describe.

By default, a principal that has a `catalog_admin` role in a catalog cannot list principal roles using the API. The `catalog_admin`'s responsibility is managing privileges and access to the catalog roles in a catalog. After fixing https://github.com/apache/polaris/issues/359 , the `catalog_admin` has the ability to grant a catalog role to a principal role, but has no ability to see the list of available principal roles. This may be ok for cases where a principal has both the `service_admin` and the `catalog_admin` roles, but if there's an enforced separation, the lack of privilege to list principal roles is a hindrance.

### Describe the solution you'd like

The authorization model typically requires a catalog to be in the scope of a request in order to detect that user has `catalog_admin` on the specified catalog. However, PrincipalRoles are not tied to a catalog, so it's difficult for the current authorization workflow to know if the current user does have admin privilege on any catalog. We can consider a separate API, where the `/principal_roles` endpoint is prefixed by catalog, but that feels cumbersome - especially if the caller is an admin on multiple catalogs.

A more likely solution would be to manage a special PrincipalRole that has limited privileges on PrincipalRoles (and possibly Principals) that a user is automatically added to when granted `catalog_admin`. 

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/363/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/365,https://api.github.com/repos/apache/polaris/issues/365,polaris,2580122193,365,"[FEATURE REQUEST] A Docker image, and a helm chart that uses this image",hakan-77,34558050,Hakan,,OPEN,2024-10-11T00:23:21Z,2024-10-15T01:38:45Z,"### Is your feature request related to a problem? Please describe.

I located a helm chart in the repo, but 
1) it's not packaged and deployed 
2) uses an image from a local registry of localhost:5001/polaris (??)

### Describe the solution you'd like

Have a helm chart and a docker image.

### Describe alternatives you've considered

We already use Nessie (through the official helm chart) and wanted to give polaris a shot.

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/365/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/365,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6PduPt,polaris,2406933485,365,NA,czy006,28348735,ConradJam,jam.gzczy@gmail.com,NA,2024-10-11T08:46:51Z,2024-10-11T08:46:51Z,"I'm interested in it, and I think I can do it. @hakan-77 ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6PduPt/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/365,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Phj8R,polaris,2407939857,365,NA,hakan-77,34558050,Hakan,,NA,2024-10-11T18:35:41Z,2024-10-11T18:35:41Z,"@czy006 just saw this: https://github.com/apache/polaris/issues/152 
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Phj8R/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/365,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Pzf4_,polaris,2412641855,365,NA,MonkeyCanCode,29619290,,,NA,2024-10-15T01:38:45Z,2024-10-15T01:38:45Z,"Yeah, it is not hard to publish this. However, i haven't done so with Apache project. I am assuming we will need to use some specialize account then update CI pipeline to package those and update?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Pzf4_/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/368,https://api.github.com/repos/apache/polaris/issues/368,polaris,2586644445,368,[BUG] - AWS_REGION mandatory - AWS STS client instantiated inside PolarisService not in PolarisCore,lefebsy,16388647,,,OPEN,2024-10-14T17:31:10Z,2024-10-18T17:28:40Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

Hello,
Maybe I am wrong and this is an expected behavior.

If there is no AWS_REGION setted in the environnement where Polaris is running (inMemory), the action of creating a catalog throw an error during the initialization of the STS Client. 



### To Reproduce

- Do not have AWS_REGION setted in environnement running Polaris
- start Polaris in mode ""InMemory"" (metaStoreManagerFactory == InMemoryPolarisMetaStoreManagerFactory)
- after Polaris is started with success
- create a catalog (with curl by example)
- STSClient fail during instantiation in polaris-service/src/main/java/org/apache/polaris/service/PolarisApplication.java line 160 (metaStoreManagerFactory)



### Actual Behavior

- In polaris-service/src/main/java/org/apache/polaris/service/PolarisApplication.java
- line 160 the PolarisStorageIntegrationProviderImpl will try to intantiate by default a AWS stsClient
- without AWS_REGION setted, it's failing

### Expected Behavior

- Maybe let the ""Polaris Core"" storage implementation fully manage this STS client (why is it instantiated in the ""Polaris Service"" ?)
- Maybe set a default Region in the STSbuilder to avoid an error ?


### Additional context

In case of a GCP or Azure deployment, AWS_REGION should not be mandatory.

### System information

Dev mode","{""url"": ""https://api.github.com/repos/apache/polaris/issues/368/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/379,https://api.github.com/repos/apache/polaris/issues/379,polaris,2594028422,379,[BUG] SKIP_CREDENTIAL_SUBSCOPING_INDIRECTION is ignored in TaskFileIOSupplier,alessandro-nori,26811266,Alessandro Nori,,CLOSED,2024-10-17T08:37:32Z,2024-12-18T17:46:45Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

The TaskFileIOSupplier class always tries to get subscoped credentials and doesn't take into consideration the SKIP_CREDENTIAL_SUBSCOPING_INDIRECTION configuration parameter.
In certain setups, we should be able to load a FileIO without credentials.

### To Reproduce

Assuming you're using AWS s3 as storage type for your catalog: 
1. Set SKIP_CREDENTIAL_SUBSCOPING_INDIRECTION to true and run polaris
2. Send a Purge request from a client that doesn't try to delete the files on the client side (e.g. pyiceberg)
3. Look at the traces and see the call to aws.AssumeRole coming from TaskFileIOSupplier

### Actual Behavior

Polaris tries to get subscoped credentials for the FileIO

### Expected Behavior

Polaris should load a FileIO without credentials

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/379/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/390,https://api.github.com/repos/apache/polaris/issues/390,polaris,2603955111,390,[BUG] Credential vending not happening when remove_orphan_files in Spark,MonkeyCanCode,29619290,,,CLOSED,2024-10-22T00:44:04Z,2024-10-25T03:42:12Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

With proper settings, spark can fail on credential vending when performing `remove_orphan_files`. This seems to be related to https://github.com/apache/iceberg/pull/7914. 

Here is the slack thread for this discussion: https://apache-iceberg.slack.com/archives/C07HADW86HZ/p1729527019849439

Also, this operation works when using Trino with vended-credentials-enabled enabled.

### To Reproduce

1. Setup proper settings for Spark to work with Polaris
2. Ensure spark client can perform DDL/DML and couple data ops on Iceberg table based on settings from step 1
3. Perform remove_orphan_files within spark

### Actual Behavior

Spark will first reported `No FileSystem for scheme ""s3""` as it is trying to use HadoopFileIO. After manually set the `spark.hadoop.fs.s3.impl` to `org.apache.hadoop.fs.s3a.S3AFileSystem`. If the client has S3 credential with needed access, it will work. However, if through credential vending from Polars, it can fail (in this case, client doesn't have S3 credential).



### Expected Behavior

Spark should use credential vending then perform remove_orphan_files and no manual specify of `spark.hadoop.fs.s3.impl` should be needed. 

### Additional context

_No response_

### System information

Polaris version: latest
Iceberg version: 1.6.1
Spark version: 3.5.2","{""url"": ""https://api.github.com/repos/apache/polaris/issues/390/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/390,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Q3eKd,polaris,2430460573,390,NA,collado-mike,40346148,Michael Collado,,NA,2024-10-22T22:52:38Z,2024-10-22T22:52:38Z,"This is well-described in the linked Iceberg issue, but the TL;DR here is that Iceberg itself isn't using the credentials returned from Polaris. This isn't something we can fix on the Polaris side","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Q3eKd/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/390,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Q315O,polaris,2430557774,390,NA,MonkeyCanCode,29619290,,,NA,2024-10-23T00:28:04Z,2024-10-23T00:28:04Z,"Yes, understand. But it is something worth mentioning in our doc so people won't think credential vending will apply to all operations? ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Q315O/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/390,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Q4kt2,polaris,2430749558,390,NA,collado-mike,40346148,Michael Collado,,NA,2024-10-23T03:07:05Z,2024-10-23T03:07:05Z,"I think there's a lot missing in our docs about credential vending ðŸ˜‚

A doc update sounds good to me. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Q4kt2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/390,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Q4xAM,polaris,2430799884,390,NA,MonkeyCanCode,29619290,,,NA,2024-10-23T03:44:03Z,2024-10-23T03:44:03Z,Thanks for confirmation. I will run some tests tomorrow to come up with a full list of ops that are not currently supported with credential vending then raise a PR for doc update.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Q4xAM/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/390,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Q41T_,polaris,2430817535,390,NA,MonkeyCanCode,29619290,,,NA,2024-10-23T03:57:49Z,2024-10-23T03:57:49Z,Here is a sample PR for the purposed changes in doc: https://github.com/apache/polaris/pull/398,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Q41T_/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/390,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6RPfVw,polaris,2436756848,390,NA,MonkeyCanCode,29619290,,,NA,2024-10-25T03:40:31Z,2024-10-25T03:40:31Z,Close this one as the issue is in Apache Iceberg side and the doc for Apache Polaris had been updated to reflect which operation is not supposed via credentials vending. ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6RPfVw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/392,https://api.github.com/repos/apache/polaris/issues/392,polaris,2604384035,392,Enhanced Apache Polaris runtime,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,CLOSED,2024-10-22T06:18:23Z,2025-01-14T10:38:41Z,"Quarkus is an open source framework for Java (https://quarkus.io/) with a great ecosystem (e.g. extensions) and high performances (with a focus on build time resolution).
It's a good framework for cloud deployment, especially on Kubernetes.

I will open a proposal PR (draft first) providing `polaris-service-quarkus` as a proposal to use Quarkus instead of Dropwizard.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/392/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/392,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6RA6Zd,polaris,2432935517,392,NA,wfrank2509,498202,Wolfgang,,NA,2024-10-23T17:22:28Z,2024-10-23T17:22:28Z,"Great enhancement request. 

We switched to Quarkus quite some time ago using it in many large scale scenarios. It was/is a great improvement not only for the products but also for the developer joy :) 


The icing on the cake for us was also switching from Java to Kotlin + Quarkus running on the JVM.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6RA6Zd/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/392,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6RzYZ7,polaris,2446165627,392,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2024-10-30T08:26:37Z,2024-10-30T08:26:37Z,"As shared on the mailing list, the branch is here: https://github.com/jbonofre/polaris/tree/QUARKUS

As reminder, the purpose of Quarkus (for Polaris):
- CDI model powered by annotations
- More friendly pluggable mechanism
- Extensions ecosystem
- Performance boost ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6RzYZ7/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/392,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6U2a0O,polaris,2497293582,392,NA,adutra,463876,Alexandre Dutra,,NA,2024-11-25T08:47:58Z,2024-11-25T08:47:58Z,"Effort is now being tracked here:

https://github.com/apache/polaris/pull/469","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6U2a0O/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/392,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XTe5R,polaris,2538466897,392,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2024-12-12T10:19:27Z,2024-12-12T10:19:27Z,Proposal document: https://docs.google.com/document/d/1C7E0ma6OvHGvWMJlZVkQHBsvPg8Pe9aroDtQ_79SIXY/edit?usp=sharing,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XTe5R/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/399,https://api.github.com/repos/apache/polaris/issues/399,polaris,2607142058,399,[BUG] ClassCastException on linux/amd64 build,shantanu-dahiya,70563548,Shantanu Dahiya,,CLOSED,2024-10-23T04:05:02Z,2024-11-11T21:34:45Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

## Overview
Polaris server docker container built for the amd64 (x64) architecture errors out with code 500 on receiving a catalog creation request.

### Error Message
```
java.lang.ClassCastException: Cannot cast java.util.ImmutableCollections$List12 to java.util.ImmutableCollections$ListN
```

### Create Catalog Request Body
```
{
    ""name"": ""catalog-name"",
    ""type"": ""INTERNAL"",
    ""readOnly"": false,
    ""storageConfigInfo"": {
        ""storageType"": ""AZURE"",
        ""tenantId"": ""<azure-tenant-id>""
    },
    ""properties"": {
        ""default-base-location"": ""abfss://<path-to-catalog-directory>""
    }
}
```

## Additional Facts
- Running it with or without persistence has no effect.
- The build for arm64 (same code) handles the create catalog request just fine (201 created).
- The last time I built a Polaris container for amd64 that didn't have this problem was on 13th September 2024. I can't find out precisely which commit it was. My guess is that a later commit has caused this bug.

## Stack trace
```
ERROR [2024-10-23 03:32:30,681 - 79990 ] [pool-3-thread-8 - POST /api/management/v1/catalogs] [] o.a.p.s.e.IcebergExceptionMapper: Unhandled exception returning INTERNAL_SERVER_ERROR
java.lang.ClassCastException: Cannot cast java.util.ImmutableCollections$List12 to java.util.ImmutableCollections$ListN
	at java.base/java.lang.Class.cast(Class.java:4067)
	at org.apache.polaris.core.PolarisConfiguration.cast(PolarisConfiguration.java:55)
	at org.apache.polaris.core.PolarisConfigurationStore.tryCast(PolarisConfigurationStore.java:79)
	at org.apache.polaris.core.PolarisConfigurationStore.getConfiguration(PolarisConfigurationStore.java:95)
	at org.apache.polaris.service.admin.PolarisServiceImpl.validateStorageConfig(PolarisServiceImpl.java:121)
	at org.apache.polaris.service.admin.PolarisServiceImpl.createCatalog(PolarisServiceImpl.java:107)
	at org.apache.polaris.service.admin.api.PolarisCatalogsApi.createCatalog(PolarisCatalogsApi.java:139)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:146)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:189)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:93)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:478)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:400)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:256)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:397)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:349)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:379)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:312)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:764)
	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1665)
	at io.dropwizard.servlets.ThreadNameFilter.doFilter(ThreadNameFilter.java:36)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
	at io.dropwizard.jersey.filter.AllowedMethodsFilter.handle(AllowedMethodsFilter.java:46)
	at io.dropwizard.jersey.filter.AllowedMethodsFilter.doFilter(AllowedMethodsFilter.java:40)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
	at org.apache.polaris.service.tracing.TracingFilter.doFilter(TracingFilter.java:94)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
	at org.eclipse.jetty.servlets.CrossOriginFilter.handle(CrossOriginFilter.java:314)
	at org.eclipse.jetty.servlets.CrossOriginFilter.doFilter(CrossOriginFilter.java:267)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
	at org.apache.polaris.service.PolarisApplication$ContextResolverFilter.doFilter(PolarisApplication.java:401)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:527)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:221)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1381)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:176)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:484)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:174)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1303)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:129)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
	at io.dropwizard.metrics.jetty11.InstrumentedHandler.handle(InstrumentedHandler.java:313)
	at io.dropwizard.jetty.RoutingHandler.handle(RoutingHandler.java:52)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:822)
	at io.dropwizard.jetty.ZipExceptionHandlingGzipHandler.handle(ZipExceptionHandlingGzipHandler.java:26)
	at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:46)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
	at org.eclipse.jetty.server.Server.handle(Server.java:563)
	at org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:501)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100)
	at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.runTask(AdaptiveExecutionStrategy.java:421)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.consumeTask(AdaptiveExecutionStrategy.java:390)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:277)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)
	at java.base/java.lang.Thread.run(Thread.java:1583)
INFO  [2024-10-23 03:32:30,682 - 79991 ] [pool-3-thread-8] [] i.o.e.l.LoggingSpanExporter: 'POST /api/management/v1/catalogs' : 8e20483d4e5a7d374f3964304afcc288 a79f2ecd53db1132 SERVER [tracer: /api/management/v1/catalogs:] AttributesMap{data={http.request.method=POST, server.address=localhost, url.path=/api/management/v1/catalogs, url.scheme=http, realm=default-realm}, capacity=128, totalAddedValues=5}
127.0.0.1 - root [23/Oct/2024:03:32:30 +0000] ""POST /api/management/v1/catalogs HTTP/1.1"" 500 152 ""-"" ""PostmanRuntime/7.42.0"" 5
INFO  [2024-10-23 03:32:31,581 - 80890 ] [pool-3-thread-7] [] o.a.p.s.tracing.TracingFilter: Started span with parent spanId=""e8e122f36ce0820b"" traceId=""043c79bb96ca41a9b98b31b217bbc709"" parentContext=""{}""
INFO  [2024-10-23 03:32:31,582 - 80891 ] [pool-3-thread-7 - POST /api/management/v1/catalogs] [] o.a.p.s.a.TestInlineBearerTokenPolarisAuthenticator: Checking for existence of principal root in map {principal=root, password=9ef04654ccdcdcec1436b0661ccd0d90, realm=default-realm, role=ALL}
WARN  [2024-10-23 03:32:31,582 - 80891 ] [pool-3-thread-7 - POST /api/management/v1/catalogs] [] o.a.p.s.a.TestInlineBearerTokenPolarisAuthenticator: Failed to load secrets for principal root
INFO  [2024-10-23 03:32:31,584 - 80893 ] [pool-3-thread-7 - POST /api/management/v1/catalogs] [] o.a.p.s.e.IcebergExceptionMapper: Handling runtimeException Cannot cast java.util.ImmutableCollections$List12 to java.util.ImmutableCollections$ListN
ERROR [2024-10-23 03:32:31,584 - 80893 ] [pool-3-thread-7 - POST /api/management/v1/catalogs] [] o.a.p.s.e.IcebergExceptionMapper: Unhandled exception returning INTERNAL_SERVER_ERROR
java.lang.ClassCastException: Cannot cast java.util.ImmutableCollections$List12 to java.util.ImmutableCollections$ListN
	at java.base/java.lang.Class.cast(Class.java:4067)
	at org.apache.polaris.core.PolarisConfiguration.cast(PolarisConfiguration.java:55)
	at org.apache.polaris.core.PolarisConfigurationStore.tryCast(PolarisConfigurationStore.java:79)
	at org.apache.polaris.core.PolarisConfigurationStore.getConfiguration(PolarisConfigurationStore.java:95)
	at org.apache.polaris.service.admin.PolarisServiceImpl.validateStorageConfig(PolarisServiceImpl.java:121)
	at org.apache.polaris.service.admin.PolarisServiceImpl.createCatalog(PolarisServiceImpl.java:107)
	at org.apache.polaris.service.admin.api.PolarisCatalogsApi.createCatalog(PolarisCatalogsApi.java:139)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:146)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:189)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:93)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:478)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:400)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:256)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:397)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:349)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:379)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:312)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:764)
	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1665)
	at io.dropwizard.servlets.ThreadNameFilter.doFilter(ThreadNameFilter.java:36)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
	at io.dropwizard.jersey.filter.AllowedMethodsFilter.handle(AllowedMethodsFilter.java:46)
	at io.dropwizard.jersey.filter.AllowedMethodsFilter.doFilter(AllowedMethodsFilter.java:40)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
	at org.apache.polaris.service.tracing.TracingFilter.doFilter(TracingFilter.java:94)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
	at org.eclipse.jetty.servlets.CrossOriginFilter.handle(CrossOriginFilter.java:314)
	at org.eclipse.jetty.servlets.CrossOriginFilter.doFilter(CrossOriginFilter.java:267)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
	at org.apache.polaris.service.PolarisApplication$ContextResolverFilter.doFilter(PolarisApplication.java:401)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:527)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:221)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1381)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:176)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:484)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:174)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1303)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:129)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
	at io.dropwizard.metrics.jetty11.InstrumentedHandler.handle(InstrumentedHandler.java:313)
	at io.dropwizard.jetty.RoutingHandler.handle(RoutingHandler.java:52)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:822)
	at io.dropwizard.jetty.ZipExceptionHandlingGzipHandler.handle(ZipExceptionHandlingGzipHandler.java:26)
	at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:46)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
	at org.eclipse.jetty.server.Server.handle(Server.java:563)
	at org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:501)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100)
	at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.runTask(AdaptiveExecutionStrategy.java:421)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.consumeTask(AdaptiveExecutionStrategy.java:390)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:277)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)
	at java.base/java.lang.Thread.run(Thread.java:1583)
```

### To Reproduce

- Fetch latest `main` branch of `apache/polaris`
- Build the docker container for `amd64` arch
  ```
  cd polaris
  docker build --platform linux/amd64 .
  ```
- Run Polaris server
  ```
  docker run -p 8181:8181 <image-id>
  ```
- Send a create catalog request with cURL
  ```
  curl --location 'http://localhost:8181/api/management/v1/catalogs' \
  --header 'Authorization: Bearer <token>' \
  --header 'Accept: application/json' \
  --header 'Content-Type: application/json' \
  --data-raw '{
      ""name"": ""catalog-name"",
      ""type"": ""INTERNAL"",
      ""readOnly"": false,
      ""storageConfigInfo"": {
          ""storageType"": ""AZURE"",
          ""tenantId"": ""<azure-tenant-id>""
      },
      ""properties"": {
          ""default-base-location"": ""abfss://<path-to-catalog-directory>""
      }
  }'
  ```

### Actual Behavior

Polaris server returns error code 500 with the stack trace printed above.

### Expected Behavior

Polaris server should create the catalog normally and return code 201 (created).

### Additional context

_No response_

### System information

Docker version: 27.1.1
JDK version: OpenJDK 21.0.4, Temurin 21.0.5, Microsoft OpenJDK 21
Machine: MacBook Pro M2 (arm64), Github runner `ubuntu-latest` that [runs on x64](https://github.com/orgs/community/discussions/25319#discussioncomment-3247468).","{""url"": ""https://api.github.com/repos/apache/polaris/issues/399/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/399,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Q5EXl,polaris,2430879205,399,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2024-10-23T04:43:22Z,2024-10-23T04:43:22Z,It looks like a amd64 issue but weird as it's related to classloader. I gonna take a look. Did you try to run locally (not in docker) ?,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Q5EXl/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/399,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6RBGzz,polaris,2432986355,399,NA,shantanu-dahiya,70563548,Shantanu Dahiya,,NA,2024-10-23T17:44:57Z,2024-10-23T17:44:57Z,"@jbonofre thanks for looking into this. Yes, I ran Polaris server locally (without Docker) on my M2 Mac and it was working fine, i.e. catalog was created successfully.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6RBGzz/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/399,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6RVree,polaris,2438379422,399,NA,shantanu-dahiya,70563548,Shantanu Dahiya,,NA,2024-10-25T17:14:43Z,2024-10-25T17:14:43Z,@jbonofre did you get a chance to look into this bug?,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6RVree/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/399,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Rxo6W,polaris,2445708950,399,NA,MonkeyCanCode,29619290,,,NA,2024-10-30T02:44:24Z,2024-10-30T02:44:24Z,Managed to reproduce this bug and have a working workaround. Will share details a bit later tonight. ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Rxo6W/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/399,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6RyNdH,polaris,2445858631,399,NA,MonkeyCanCode,29619290,,,NA,2024-10-30T05:03:47Z,2024-10-30T05:03:47Z,"So here is what I observed:
1. this issue can happen to any image architecture
2. this issue only happen when I changed the value of `SUPPORTED_CATALOG_STORAGE_TYPES`

So here is the procedure on how to reproduce this:

happy path:
```
# start app in terminal 1
 ./gradlew runApp

# create catalog in terminal 2
export CLIENT_ID=xxxxx
export CLIENT_SECRET=xxxxx
xxxxx@DESKTOP:~/k8s/polaris(main)$ ./polaris catalogs create --storage-type file --default-base-location file:///tmp/test quickstart_catalog
xxxxx@DESKTOP:~/k8s/polaris(main)$ ./polaris catalogs list
{""type"": ""INTERNAL"", ""name"": ""quickstart_catalog"", ""properties"": {""default-base-location"": ""file:///tmp/test""}, ""createTimestamp"": 1730263971558, ""lastUpdateTimestamp"": 1730263971558, ""entityVersion"": 1, ""storageConfigInfo"": {""storageType"": ""FILE"", ""allowedLocations"": [""file:///tmp/test""]}}
```

unhappy path:
```
# update featureConfiguration.SUPPORTED_CATALOG_STORAGE_TYPES to only keep `FILE`:
featureConfiguration:
  ENFORCE_PRINCIPAL_CREDENTIAL_ROTATION_REQUIRED_CHECKING: false
  SUPPORTED_CATALOG_STORAGE_TYPES:
    - FILE

# start app in terminal 1
 ./gradlew runApp

# create catalog in terminal 2
export CLIENT_ID=xxxxx
export CLIENT_SECRET=xxxxx
xxxxx@DESKTOP:~/k8s/polaris(main)$ ./polaris catalogs create --storage-type file --default-base-location file:///tmp/test quickstart_catalog
Exception when communicating with the Polaris server. ClassCastException: Cannot cast java.util.ImmutableCollections$List12 to java.util.ImmutableCollections$ListN
xxxxx@DESKTOP:~/k8s/polaris(main)$ ./polaris catalogs list
```

Here is the full trace on the log with the unhappy path:
```
ERROR [2024-10-29 23:53:50,205 - 25607 ] [pool-3-thread-3 - POST /api/management/v1/catalogs] [] o.a.p.s.e.IcebergExceptionMapper: Unhandled exception returning INTERNAL_SERVER_ERROR
java.lang.ClassCastException: Cannot cast java.util.ImmutableCollections$List12 to java.util.ImmutableCollections$ListN
        at java.base/java.lang.Class.cast(Class.java:4067)
        at org.apache.polaris.core.PolarisConfiguration.cast(PolarisConfiguration.java:55)
        at org.apache.polaris.core.PolarisConfigurationStore.tryCast(PolarisConfigurationStore.java:79)
        at org.apache.polaris.core.PolarisConfigurationStore.getConfiguration(PolarisConfigurationStore.java:95)
        at org.apache.polaris.service.admin.PolarisServiceImpl.validateStorageConfig(PolarisServiceImpl.java:121)
        at org.apache.polaris.service.admin.PolarisServiceImpl.createCatalog(PolarisServiceImpl.java:107)
        at org.apache.polaris.service.admin.api.PolarisCatalogsApi.createCatalog(PolarisCatalogsApi.java:139)
        at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
        at java.base/java.lang.reflect.Method.invoke(Method.java:580)
        at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
        at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:146)
        at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:189)
        at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
        at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:93)
        at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:478)
        at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:400)
        at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
        at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:256)
        at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
        at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
        at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
        at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
        at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
        at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
        at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
        at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
        at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:397)
        at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:349)
        at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:379)
        at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:312)
        at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
        at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:764)
        at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1665)
        at io.dropwizard.servlets.ThreadNameFilter.doFilter(ThreadNameFilter.java:36)
        at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
        at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
        at io.dropwizard.jersey.filter.AllowedMethodsFilter.handle(AllowedMethodsFilter.java:46)
        at io.dropwizard.jersey.filter.AllowedMethodsFilter.doFilter(AllowedMethodsFilter.java:40)
        at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
        at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
        at org.apache.polaris.service.ratelimiter.RateLimiterFilter.doFilter(RateLimiterFilter.java:54)
        at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
        at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
        at org.apache.polaris.service.tracing.TracingFilter.doFilter(TracingFilter.java:94)
        at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
        at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
        at org.eclipse.jetty.servlets.CrossOriginFilter.handle(CrossOriginFilter.java:314)
        at org.eclipse.jetty.servlets.CrossOriginFilter.doFilter(CrossOriginFilter.java:267)
        at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
        at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
        at org.apache.polaris.service.PolarisApplication$ContextResolverFilter.doFilter(PolarisApplication.java:401)
        at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:202)
        at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1635)
        at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:527)
        at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:221)
        at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1381)
        at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:176)
        at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:484)
        at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:174)
        at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1303)
        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:129)
        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
        at io.dropwizard.metrics.jetty11.InstrumentedHandler.handle(InstrumentedHandler.java:313)
        at io.dropwizard.jetty.RoutingHandler.handle(RoutingHandler.java:52)
        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
        at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:822)
        at io.dropwizard.jetty.ZipExceptionHandlingGzipHandler.handle(ZipExceptionHandlingGzipHandler.java:26)
        at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:46)
        at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
        at org.eclipse.jetty.server.Server.handle(Server.java:563)
        at org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598)
        at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753)
        at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:501)
        at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287)
        at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314)
        at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100)
        at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53)
        at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.runTask(AdaptiveExecutionStrategy.java:421)
        at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.consumeTask(AdaptiveExecutionStrategy.java:390)
        at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:277)
        at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.produce(AdaptiveExecutionStrategy.java:193)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)
        at java.base/java.lang.Thread.run(Thread.java:1583)
```

@shantanu-dahiya I am assuming when you said it is not working in amd64, that is probably running on a remote server with modify configure such as the one mentioned above. 

This seems to be from https://github.com/apache/polaris/commit/413eca7147fc239d7748ae8c3b9a336e6174b956#diff-bdd5439826dd8ef9b7999590b9756ba570967ece75f9467b26af201b4c88ab18 where we are doing casting:
```
    if (config.defaultValue instanceof Boolean) {
      return config.cast(Boolean.valueOf(String.valueOf(value)));
    } else if (config.defaultValue instanceof List<?>) {
      return config.cast(List.copyOf((List<?>) value));
    } else {
      return config.cast(value);
    }
```

@eric-maynard  @jbonofre ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6RyNdH/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/399,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6R5Ejr,polaris,2447657195,399,NA,TomerHeber,12767692,Tomer Heber,,NA,2024-10-30T16:05:35Z,2024-10-30T16:05:35Z,"Java has two implementations for List.
List12 - for short lists.
ListN - for longer lists.

For some reason it's the JDK (Maybe OpenJDK issue?) is trying to cast between the implementations.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6R5Ejr/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/399,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6TDXCR,polaris,2467131537,399,NA,MonkeyCanCode,29619290,,,NA,2024-11-11T02:53:43Z,2024-11-11T02:53:43Z,Sample PR for fixing this problem: https://github.com/apache/polaris/pull/443,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6TDXCR/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/411,https://api.github.com/repos/apache/polaris/issues/411,polaris,2621901307,411,Use VirtualThreads for Polaris TaskExecutor,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,OPEN,2024-10-29T17:22:29Z,2024-10-31T18:09:33Z,"VirtualThreads have been added in JDK19+. It's good improvement on ""regular"" threads. The Polaris `TaskExecutor` is using regular threads for now. Using virtual threads should provide a performance boost.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/411/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/411,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6R1K6H,polaris,2446634631,411,NA,snazy,957468,Robert Stupp,,NA,2024-10-30T11:08:47Z,2024-10-30T11:08:47Z,"IMHO we should be really careful with Java virtual threads, because those are not a ""just turn it on and everything's faster & better"" thing. VTs come with quite some fine-print. In a nutshell: everything that runs on a VT **must** meet a bunch of criteria - otherwise the stability of the whole process is at risk, likely not in every environment (""number of CPUs"").

Few posts that discuss this topic:
* [Quarkus - five things to know before using VTs](https://quarkus.io/blog/virtual-thread-1/#five-things-you-need-to-know-before-using-virtual-threads-for-everything)
* [Oracle - practical advice](https://docs.oracle.com/en/java/javase/20/core/virtual-threads.html#GUID-4A63E9EA-B16A-4633-87D8-C3DC08A3277C)
* [Netflix - locking issues w/ VTs](https://netflixtechblog.com/java-21-virtual-threads-dude-wheres-my-lock-3052540e231d)
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6R1K6H/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/411,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6SEAsz,polaris,2450524979,411,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-10-31T18:09:32Z,2024-10-31T18:09:32Z,"Agreed that we should look into optimizing this, though I don't know enough about virtual threads to have a strong opinion about the implementation. @snazy's concerns above seem valid.

Long-term, I am hoping that @flyrain's recent [proposal](https://docs.google.com/document/d/1Pd_mzZcfvnUvcH98IbwsIYf4eryet1lQDfclKYx-t-M/edit?tab=t.0#heading=h.7ic5c343eju1) will let us fully delegate this kind of work to an external service and make this problem moot.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6SEAsz/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/418,https://api.github.com/repos/apache/polaris/issues/418,polaris,2627669116,418,"[BUG] Some clients, PyIceberg, need more ADLS properties for Vended Credentials to work",sfc-gh-tbenroeck,107080514,Tim Benroeck,,OPEN,2024-10-31T19:30:36Z,2024-11-07T20:57:15Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

The adls.sas-token key:value being emitted is adls.sas-token.{account_host}:{sas-token} which works in Spark client but not other clients like PyIceberg [#1146](https://github.com/apache/iceberg-python/issues/1146#issuecomment-2421306564). 

To support more clients Polaris should also set: 
 - adls.sas-token (without the account-host) 
 - adls.account-name
 - adls.account_host


### To Reproduce

1. Use PyIceberg 

```python
from pyiceberg.catalog import load_catalog
import pyarrow as pa
import pyarrow.compute as pc
import pyarrow.parquet as pq

catalog = load_catalog(
    **{
        ""type"": ""rest"",
        ""header.X-Iceberg-Access-Delegation"": ""vended-credentials"",
        ""uri"": f""https://{account}.snowflakecomputing.com/polaris/api/catalog"",
        ""credential"": f""{principal_client_id}:{principal_secret}"",
        ""warehouse"": catalog_name,
        ""scope"": role,
        ""token-refresh-enabled"": ""true"",
        ""py-io-impl"": ""pyiceberg.io.fsspec.FsspecFileIO"",
    }
)

table = catalog.load_table(f""{catalog_namespace}.{catalog_namespace_tablename}"")
tablescan = table.scan()
df = tablescan.to_arrow()
```
```bash
Traceback (most recent call last):
  File ""/Users/tbenroeck/Documents/code/polaris_testing/.venv/lib/python3.12/site-packages/pyiceberg/catalog/rest.py"", line 375, in _fetch_access_token
    response.raise_for_status()
  File ""/Users/tbenroeck/Documents/code/polaris_testing/.venv/lib/python3.12/site-packages/requests/models.py"", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://tv23016.west-us-2.azure.snowflakecomputing.com/polaris/api/catalog/v1/oauth/tokens

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/Users/tbenroeck/Documents/code/polaris_testing/simple_polaris.py"", line 21, in <module>
    catalog = load_catalog(
              ^^^^^^^^^^^^^
  File ""/Users/tbenroeck/Documents/code/polaris_testing/.venv/lib/python3.12/site-packages/pyiceberg/catalog/__init__.py"", line 261, in load_catalog
    return AVAILABLE_CATALOGS[catalog_type](name, cast(Dict[str, str], conf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/tbenroeck/Documents/code/polaris_testing/.venv/lib/python3.12/site-packages/pyiceberg/catalog/__init__.py"", line 136, in load_rest
    return RestCatalog(name, **conf)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/tbenroeck/Documents/code/polaris_testing/.venv/lib/python3.12/site-packages/pyiceberg/catalog/rest.py"", line 263, in __init__
    self._fetch_config()
  File ""/Users/tbenroeck/Documents/code/polaris_testing/.venv/lib/python3.12/site-packages/pyiceberg/catalog/rest.py"", line 386, in _fetch_config
    with self._create_session() as session:
         ^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/tbenroeck/Documents/code/polaris_testing/.venv/lib/python3.12/site-packages/pyiceberg/catalog/rest.py"", line 280, in _create_session
    self._refresh_token(session, self.properties.get(TOKEN))
  File ""/Users/tbenroeck/Documents/code/polaris_testing/.venv/lib/python3.12/site-packages/pyiceberg/catalog/rest.py"", line 546, in _refresh_token
    self.properties[TOKEN] = self._fetch_access_token(session, self.properties[CREDENTIAL])
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/tbenroeck/Documents/code/polaris_testing/.venv/lib/python3.12/site-packages/pyiceberg/catalog/rest.py"", line 377, in _fetch_access_token
    self._handle_non_200_response(exc, {400: OAuthError, 401: OAuthError})
  File ""/Users/tbenroeck/Documents/code/polaris_testing/.venv/lib/python3.12/site-packages/pyiceberg/catalog/rest.py"", line 471, in _handle_non_200_response
    raise exception(response) from exc
pyiceberg.exceptions.OAuthError: unauthorized_client: The client is not authorized
```

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

I created a custom FileIO fix as a temporary workaround
```
catalog = load_catalog(
    **{
        ""type"": ""rest"",
        ""header.X-Iceberg-Access-Delegation"": ""vended-credentials"",
        ""uri"": f""https://{account}.snowflakecomputing.com/polaris/api/catalog"",
        ""credential"": f""{principal_client_id}:{principal_secret}"",
        ""warehouse"": catalog_name,
        ""scope"": role,
        ""token-refresh-enabled"": ""true"",
        ""py-io-impl"": ""custom_fsspec.CustomFsspecFileIO"",
    }
)
```

```python
from pyiceberg.io.fsspec import FsspecFileIO, _adls
from urllib.parse import urlparse
from pyiceberg.io import (ADLS_ACCOUNT_NAME,ADLS_SAS_TOKEN, ADLFS_ACCOUNT_NAME, ADLFS_SAS_TOKEN)
from pyiceberg.utils.properties import get_first_property_value
from fsspec import AbstractFileSystem
from pyiceberg.typedef import Properties

class CustomFsspecFileIO(FsspecFileIO):
    def __init__(self, properties):
        # Short term fix for https://github.com/apache/iceberg-python/issues/961 and https://github.com/apache/iceberg-python/issues/1146
        base_location = properties.get('default-base-location')
        if base_location and base_location.startswith('abfs'):
            account_name = get_first_property_value(properties,ADLS_ACCOUNT_NAME,ADLFS_ACCOUNT_NAME)
            sas_token = get_first_property_value(properties,ADLS_SAS_TOKEN,ADLFS_SAS_TOKEN)

            if sas_token is None:
                for key, value in properties.items():
                    key = key.replace('adlfs.', 'adls.')
                    if key.startswith(ADLS_SAS_TOKEN):
                        properties[ADLS_SAS_TOKEN] = value
                        if key.endswith('.windows.net'):
                            if account_name is None:
                                account_host = key.removeprefix(f""{ADLS_SAS_TOKEN}."")
                                account_name = account_host.split('.')[0]
                                properties[ADLS_ACCOUNT_NAME] = account_name
                                properties['adls.account-host'] = account_host
                        break  # Exit loop after finding the first match
        super().__init__(properties)

    def _get_fs(self, scheme: str):
        if scheme in [""abfs"", ""abfss"", ""wasb"", ""wasbs""]:
            if scheme in [""wasb""]:
                scheme = 'abfs'
            if scheme in [""wasbs""]:
                scheme = 'abfss'
            adls_fs = _adls(self.properties)
            return adls_fs

        # If not adls proceed with the original behavior
        return super()._get_fs(scheme)

    def new_input(self, location: str):
        # Replace wasb(s):// with adfs(s):// in the location
        uri = urlparse(location)
        if uri.scheme in [""wasb""]:
            location = location.replace(f""{uri.scheme}://"", ""abfs://"")
        if uri.scheme in [""wasbs""]:
            location = location.replace(f""{uri.scheme}://"", ""abfss://"")
        return super().new_input(location)

    def new_output(self, location: str):
        # Replace wasb(s):// with adfs:// in the location
        uri = urlparse(location)
        if uri.scheme in [""wasb""]:
            location = location.replace(f""{uri.scheme}://"", ""abfs://"")
        if uri.scheme in [""wasbs""]:
            location = location.replace(f""{uri.scheme}://"", ""abfss://"")
        return super().new_output(location)

def _adls(properties: Properties) -> AbstractFileSystem:
    from adlfs import AzureBlobFileSystem
    return AzureBlobFileSystem(
        account_host = properties['adls.account-host'],
        account_name=properties[ADLS_ACCOUNT_NAME],
        sas_token=properties[ADLS_SAS_TOKEN]
    )
```

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/418/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/418,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6S0WLS,polaris,2463195858,418,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-11-07T20:57:14Z,2024-11-07T20:57:14Z,"@sfc-gh-tbenroeck do you think we can just fix it in pyiceberg? From the linked thread, the community over there seems receptive to it","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6S0WLS/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/425,https://api.github.com/repos/apache/polaris/issues/425,polaris,2636004830,425,[FEATURE REQUEST] Support for OpenLineage,collado-mike,40346148,Michael Collado,,OPEN,2024-11-05T16:59:44Z,2024-12-19T23:47:17Z,"### Is your feature request related to a problem? Please describe.

[OpenLineage](https://openlineage.io/) is an open standard for reporting and collecting lineage information about processing jobs (i.e., which data sets were inputs to a processing job and which datasets were output). OpenLineage libraries are typically modeled as listeners or before/after hooks that are triggered by running processing jobs and have engine-specific code that collects information about the job and the datasets. That information is serialized as JSON and transmitted to a well-defined endpoint that either processes and stores that information or modifies and relays it to another endpoint.

### Describe the solution you'd like

Polaris is a good candidate for a proxying lineage endpoint because it has a canonical view of the datasets being processed and can augment the lineage payload with useful data. This is especially true when Polaris is used to access External catalogs, where the authoritative metadata lives somewhere else. 

Spark or other OpenLineage clients can only report information about the datasets that can be gleaned from the client - e.g., the namespace of the data will be the Polaris endpoint that was used to access the data. The name of the catalog will be whatever name assigned to the catalog in that particular application (e.g., a user might configure the catalog as either `spark.sql.catalog.polaris` or `spark.sql.catalog.iceberg`). A table might have been renamed or moved from another catalog.

Polaris, however, knows exactly where the dataset originated and can use the table metadata's UUID field to uniquely identify the dataset. It also knows the snapshot information (datasets can be versioned in OpenLineage) as well as the schema, table properties, and other information that could be reported as an OpenLineage facet. 

Polaris doesn't make sense as a container for lineage information, as parsing and storing that information is not cheap. However, there is already precedence for an [OpenLineage proxy](https://openlineage.io/docs/development/ol-proxy/), which can be used to augument the lineage information and pass it on to another service ([Marquez](https://github.com/MarquezProject/marquez) is the reference implementation of the OpenLineage server endpoint). 

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/425/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/441,https://api.github.com/repos/apache/polaris/issues/441,polaris,2645273441,441,[FEATURE REQUEST] SSO / Federated User/Role support,collado-mike,40346148,Michael Collado,,OPEN,2024-11-08T22:21:21Z,2025-01-16T17:34:05Z,"### Is your feature request related to a problem? Please describe.

User management is complicated and can scale to thousands or tens of thousands of users for large enterprises. Group membership is frequently dynamic and privileges tied to group membership needs to be able to reflect group membership changes immediately.

Large enterprises typically use identity provider services, such as Okta, LDAP, or Google, to manage users and roles. These central IdPs are typically relied upon to communicate user authentication and group membership so that an administrator needs to make changes in a single central location and know that all peripheral applications will see those changes immediately. 

### Describe the solution you'd like

SSO and support for Federated Users and Federated Roles would allow defining users and roles as ""federated"" so that token generation and role membership is disallowed through the Polaris management APIs. I see the following changes being implemented:

1. Support for multiple `Authenticator`s to be configured - an admin could potentially have multiple IdPs that should be trusted to generate auth tokens. These tokens need to be inspected and validated in Polaris, potentially by making an API call to the IdP or by validating an encryption signature in a JWT.
2. Extending the authentication flow to support just-in-time Principal creation - when a `TokenBroker` parses a token and returns a user that doesn't have a principal entity, one should be created from the token info. The Principal should be marked as `federated`  in its `internal_properties`. A `federated` Principal does not have any clientId/secret stored and cannot generate a token in the `/tokens` API.
3. Extending the authentication flow to support just-in-time PrincipalRole creation and assignment - when a `TokenBroker` parses a token, the scopes defined in the token should translate into PrincipalRole membership. These roles may not exist in Polaris, so should be created. The `AuthenticatedPrincipal` will implicitly have membership in these `PrincipalRole`s. The `PrincipalRole` should be marked as `federated` in its `internal_properties`. A `federated` PrincipalRole cannot be granted to non-`federated` Principals. 
4. `federated` Principals also cannot be granted membership to a non-`federated` PrincipalRoles - the tokens generated by the IdP will never include a non-`federated` PrincipalRole, so granting membership doesn't make sense.
5. Both `federated` Principals and PrincipalRoles must have a `federation_source` - a `federated` Principal should only be granted access to PrincipalRoles that are defined for the same `federation_source`. A naming convention, such as a source prefix, should be considered to avoid name clashing of Principals and PrincipalRoles. It would be necessary to map scopes and usernames present in the token to the expected name of the created Principal/PrincipalRole.


### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/441/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/448,https://api.github.com/repos/apache/polaris/issues/448,polaris,2659173077,448,[FEATURE REQUEST] Allow list permissions in vended credentials,jasonf20,1601106,Jason,,OPEN,2024-11-14T15:31:07Z,2024-11-14T15:31:07Z,"### Is your feature request related to a problem? Please describe.

We are interested in using the vended credentials for Orphan File cleanup. However it seems that currently the provided vended credentials never allow listing. 
I see the infrastructure supports passing PolarisStorageActions.LIST which would allow this, but no caller seems to pass this in from what I can tell.

### Describe the solution you'd like

Allow users to add a permission to the catalog role that enables file listing which will then ensure the vended credentials include the list operation permissions. 

### Describe alternatives you've considered

_No response_

### Additional context

I believe spark also doesn't use the vended credentials at the moment and this might be the reason. Though I'm not sure if there is another reason for this. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/448/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/450,https://api.github.com/repos/apache/polaris/issues/450,polaris,2661316975,450,[BUG] Potential eclipselink schema upgrade issue,snazy,957468,Robert Stupp,,OPEN,2024-11-15T09:05:59Z,2024-11-19T19:28:38Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

The change #438 changes the database schema. However, there seems to be an issue that the schema is _not_ properly updated - at least not via `PolarisEclipseLinkMetaStoreManagerTest`, see repro steps below.

/cc @eric-maynard 

### To Reproduce

1. `git checkout e232b000760da335721e9112f9d52fe041289613` (commit before #438)
2. `rm -rf extension/persistence/eclipselink/build` (just get a clean state)
3. `./gradlew :polaris-eclipselink:test --rerun` (passes fine)
4. `git checkout ab095cfab84e5b4e694c72011f4166589eb25f38` (#438) 
5. `./gradlew :polaris-eclipselink:test --rerun` (fails)
6. `rm -rf extension/persistence/eclipselink/build/test_data` (database state)
7. `./gradlew :polaris-eclipselink:test --rerun` (passes fine)


### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/450/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/450,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6T83E5,polaris,2482204985,450,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-11-18T08:01:04Z,2024-11-18T08:01:04Z,"I'm able to repro this using the steps provided. 

I believe that the simplest fix is to enable automatic schema migrations in eclipselink by setting:
```
<property name=""eclipselink.ddl-generation"" value=""create-or-extend-tables""/>
```

By adding this between steps (4) and (5) in your instructions, I am able to get the tests in step (5) to _mostly_ pass -- `PolarisEclipseLinkMetaStoreManagerTest.testPrivileges` still fails, but I think that's a different issue.

I've noted this down this on [the PR that caused this](https://github.com/apache/polaris/pull/438#issuecomment-2482186090), as well.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6T83E5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/450,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6T8367,polaris,2482208443,450,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-11-18T08:02:53Z,2024-11-18T08:02:53Z,"For the time being, shall we revert the offending PR?

I am also happy to fix-forward with the config suggested above. In any case, I think this is a good indicator that cross-version tests would be a good idea.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6T8367/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/450,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6T9QBi,polaris,2482307170,450,NA,snazy,957468,Robert Stupp,,NA,2024-11-18T08:50:11Z,2024-11-18T08:50:11Z,"Honestly, I don't think that reverting is an option.

Cross-version tests (or backwards/forwards/migration compatibility tests)  are a good idea!
SQL schema migration however complicates things, especially in a distributed / horizontally scalable system w/ rolling upgrades.

Re cross-version tests (backwards/forwards compatibility + rolling upgrades), we do have something like that in Nessie, where we run REST services from older releases and test the newest client (on `main`) against it, and older clients against the newest REST service (on `main`). It requires quite a bit of class-loading trickery though. With Iceberg/Java (which we don't use in those tests in Nessie) it would be quite hard, because Iceberg/Java and especially the Azure SDK keep resources like threads and thread-locals around, which cause class leaks that then cause OOMs - not great.

However, testing relevant things (persistence is one) in isolation should be doable - as dedicated / isolated tests.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6T9QBi/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/450,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6T9VT8,polaris,2482328828,450,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-11-18T08:59:08Z,2024-11-18T08:59:08Z,"I see. Yeah, I think it will be complicated to set up true cross-version tests. However since we do have a persistence layer I think it will be important to ensure that upgrades/downgrades can work with various states in the persistence layer. Other stuff, like cross-version notification compatibility, could come later.

Filed this PR to fix-forward: #456 

I want to look more closely at the one test that's failing; I think that's a legitimate issue with #438. Perhaps the ID sequence does not get preserved when the schema is automatically upgraded. 

","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6T9VT8/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/450,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6UE-sD,polaris,2484333315,450,NA,collado-mike,40346148,Michael Collado,,NA,2024-11-18T23:09:45Z,2024-11-18T23:09:45Z,"> Honestly, I don't think that reverting is an option.

Why is this not an option?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6UE-sD/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/450,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6UFLd3,polaris,2484385655,450,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-11-18T23:32:37Z,2024-11-18T23:32:37Z,"cc @jbonofre -- with the release coming up, how do you want to approach this?

Currently, anyone who was using EclipseLink-backed Polaris prior to #438 (who has not configured EclipseLink for automatic schema migrations) will not be able to upgrade to 0.9.0 without a manual schema migration. On the other hand, if we revert, anyone who created a metastore between #438 merging and being reverted will be stuck.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6UFLd3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/450,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ULZ5G,polaris,2486017606,450,NA,adutra,463876,Alexandre Dutra,,NA,2024-11-19T15:22:38Z,2024-11-19T15:22:38Z,"> anyone who was using EclipseLink-backed Polaris prior to https://github.com/apache/polaris/pull/438 (who has not configured EclipseLink for automatic schema migrations) will not be able to upgrade to 0.9.0 without a manual schema migration

If they haven't set up schema migration, that's expected right? Couldn't we just mention this fact in the release notes and keep #438 in 0.9.0?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ULZ5G/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/450,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6UNht4,polaris,2486573944,450,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-11-19T19:27:55Z,2024-11-19T19:27:55Z,"@adutra that would be reasonable, too. I guess the question is whether we want to force users to do schema migrations (maybe only across minor/major versions?) or whether we want this to be something Polaris itself handles.

In either case I think it should be an explicit decision. If we want users to do this manually, we should _not_ merge #456 ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6UNht4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/453,https://api.github.com/repos/apache/polaris/issues/453,polaris,2663425355,453,[FEATURE REQUEST] Public Roadmap,RussellSpitzer,413025,Russell Spitzer,,OPEN,2024-11-15T23:05:04Z,2024-11-25T05:28:57Z,"### Is your feature request related to a problem? Please describe.

Lots of folks are interested in what is going on with the project but there is currently no clear way to see what folks are working on and what they plan to working on next

### Describe the solution you'd like

Either we start using milestones or perhaps some projects to help folks to understand what is going on and who is working on what, as well as potential timelines

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/453/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/453,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6T34Ox,polaris,2480898993,453,NA,Pranathi-star,52571012,Pranathi Kodicherla,,NA,2024-11-17T02:42:44Z,2024-11-17T02:42:44Z,I would like to work on this feature :) Do we want to create a dashboard of sorts for displaying all action items?,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6T34Ox/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/453,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6T41uI,polaris,2481150856,453,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2024-11-17T10:21:20Z,2024-11-17T10:21:20Z,"We discussed about that during the last community meeting.

My proposal is to use GitHub projects (I enabled it) to store the proposals and link to a milestone. Then, milestone can host the roadmap.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6T41uI/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/453,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6UkUa2,polaris,2492548790,453,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-11-21T23:18:23Z,2024-11-21T23:18:23Z,"I'd suggest following steps
1. Raise an issue
2. Circulate the idea with the community, dev list and/or community sync
3. Create a GitHub project for the topic once a consensus has been reached","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6UkUa2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/453,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6UlfLo,polaris,2492855016,453,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2024-11-22T04:32:15Z,2024-11-22T04:32:15Z,"@flyrain fully agree, that's also my suggestion.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6UlfLo/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/453,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6UnIec,polaris,2493286300,453,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2024-11-22T09:16:33Z,2024-11-22T09:16:33Z,"As reminder, we already have a ""plug"" on the website: https://polaris.apache.org/community/proposals/

So, we should be able to easily populate the public roadmap on the website here.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6UnIec/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/453,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6UzqQC,polaris,2496570370,453,NA,Pranathi-star,52571012,Pranathi Kodicherla,,NA,2024-11-25T02:53:39Z,2024-11-25T02:53:39Z,"Based on the suggestions here, I believe we can work on this in two simultaneous phases. First would be creating a placeholder issue circulated in the community where we ask contributors to comment on what major features they are working on and manually populating the ones with high votes in the project section.

Second phase would be to fetch the listed tasks in the project section using the GitHub API and displaying in the community proposals section of the Polaris site. 

Does this sound correct?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6UzqQC/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/463,https://api.github.com/repos/apache/polaris/issues/463,polaris,2680257145,463,Remove and ban usage of `[Inheritable]ThreadLocal`,snazy,957468,Robert Stupp,,OPEN,2024-11-21T17:13:12Z,2025-02-08T21:36:15Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

While `[Inheritable]ThreadLocal`s are relatively easy to start with to pass along request related information, `ThreadLocal`s come with a non-negligible cost and maintenance burden:

* TLs can cause very hard to detect memory leaks as objects (and classes!) are (often permanently) attached to a thread.
* TLs and their usage are hard to test
* (The use of) TLs can accidentally share data across requests
* Use of TLs becomes complex and hard to reason about

The proper way of sharing _request_ related information is to use CDI's `@RequestScoped` beans.

### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/463/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/463,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dC5gS,polaris,2634782738,463,NA,adutra,463876,Alexandre Dutra,,NA,2025-02-04T18:43:59Z,2025-02-04T18:43:59Z,Reopening since #589 will be reverted soon.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dC5gS/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/463,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dC5nI,polaris,2634783176,463,NA,adutra,463876,Alexandre Dutra,,NA,2025-02-04T18:44:12Z,2025-02-04T18:44:12Z,"A few datapoints:

https://quarkus.io/guides/duplicated-context:

> When using a traditional, blocking, and synchronous framework, processing of each request is performed in a dedicated thread. So, the same thread is used for the entire processing. [...] When you need to propagate data along the processing [...] you can use ThreadLocals. [...] When using a reactive and asynchronous execution model [...] the same thread can be used to handle multiple concurrent processing. Thus, you cannot use ThreadLocals as the values would be leaked between the various concurrent processing.

https://quarkus.io/guides/context-propagation:

> Traditional blocking code uses [ThreadLocal](https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/ThreadLocal.html) variables to store contextual objects in order to avoid passing them as parameters everywhere [...] If you write reactive/async code [...] try/finally blocks as well as ThreadLocal variables stop working, because your reactive code gets executed in another thread, after the caller ran its finally block.

https://stackoverflow.com/questions/76468966/requestscope-vs-threadlocal-for-mutlti-tenant-in-quarkus-with-mutiny:

> Using `@RequestScope` with [Context Propagation](https://quarkus.io/guides/context-propagation) is the way to go. Dealing with ThreadLocal manually is going to be very error prone.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dC5nI/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/464,https://api.github.com/repos/apache/polaris/issues/464,polaris,2680418061,464,[FEATURE REQUEST] Support refreshing of vended credentials with latest iceberg version(1.7.0),ashish-picha-velotio,95350723,,,OPEN,2024-11-21T18:08:52Z,2025-01-30T21:24:33Z,"### Is your feature request related to a problem? Please describe.

Currently, whenever we use Iceberg with Polaris(hosted in snowflake) in Spark for S3/GCS/Azure catalogs,
we are facing a token expiry issue after approximately 1 hour of job run time - `software.amazon.awssdk.services.s3.model.S3Exception: The provided token has expired`, and for the jobs that take less time are successful.

Stacktrace:
```
Lost task 28.1 in stage 156.0 (TID 20576) (10.51.25.90 executor 14): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 14 in stage 155.0 failed 4 times, most recent failure: Lost task 14.3 in stage 155.0 (TID 20488) (10.51.23.53 executor 7): software.amazon.awssdk.services.s3.model.S3Exception: The provided token has expired. (Service: S3, Status Code: 400, Request ID: C7VGJA131SXAAXK1, Extended Request ID: V3Uk6ufpsyWLFJxPofR4Atiue7K+UlHjEvRCbEDZCdNmN7U/nv/cp+d3l93eWW/AoTW3mFIs2SY=)
    at software.amazon.awssdk.core.internal.http.CombinedResponseHandler.handleErrorResponse(CombinedResponseHandler.java:125)
    at software.amazon.awssdk.core.internal.http.CombinedResponseHandler.handleResponse(CombinedResponseHandler.java:82)
    at software.amazon.awssdk.core.internal.http.CombinedResponseHandler.handle(CombinedResponseHandler.java:60)
    at software.amazon.awssdk.core.internal.http.CombinedResponseHandler.handle(CombinedResponseHandler.java:41)
    at software.amazon.awssdk.core.internal.http.pipeline.stages.HandleResponseStage.execute(HandleResponseStage.java:50)
    at software.amazon.awssdk.core.internal.http.pipeline.stages.HandleResponseStage.execute(HandleResponseStage.java:38)
    at software.amazon.awssdk.core.internal.http.pipeline.RequestPipelineBuilder$ComposingRequestPipelineStage.execute(RequestPipelineBuilder.java:206)
    at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallAttemptTimeoutTrackingStage.execute(ApiCallAttemptTimeoutTrackingStage.java:72)
    at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallAttemptTimeoutTrackingStage.execute(ApiCallAttemptTimeoutTrackingStage.java:42)
    at software.amazon.awssdk.core.internal.http.pipeline.stages.TimeoutExceptionHandlingStage.execute(TimeoutExceptionHandlingStage.java:78)
    at software.amazon.awssdk.core.internal.http.pipeline.stages.TimeoutExceptionHandlingStage.execute(TimeoutExceptionHandlingStage.java:40)
    at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallAttemptMetricCollectionStage.execute(ApiCallAttemptMetricCollectionStage.java:55)
    at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallAttemptMetricCollectionStage.execute(ApiCallAttemptMetricCollectionStage.java:39)
    at software.amazon.awssdk.core.internal.http.pipeline.stages.RetryableStage2.executeRequest(RetryableStage2.java:93)
    at software.amazon.awssdk.core.internal.http.pipeline.stages.RetryableStage2.execute(RetryableStage2.java:56)
    at software.amazon.awssdk.core.internal.http.pipeline.stages.RetryableStage2.execute(RetryableStage2.java:36)
    at software.amazon.awssdk.core.internal.http.pipeline.RequestPipelineBuilder$ComposingRequestPipelineStage.execute(RequestPipelineBuilder.java:206)
    at software.amazon.awssdk.core.internal.http.StreamManagingStage.execute(StreamManagingStage.java:53)
    at software.amazon.awssdk.core.internal.http.StreamManagingStage.execute(StreamManagingStage.java:35)
    at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallTimeoutTrackingStage.executeWithTimer(ApiCallTimeoutTrackingStage.java:80)
    at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallTimeoutTrackingStage.execute(ApiCallTimeoutTrackingStage.java:60)
    at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallTimeoutTrackingStage.execute(ApiCallTimeoutTrackingStage.java:42)
    at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallMetricCollectionStage.execute(ApiCallMetricCollectionStage.java:50)
    at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallMetricCollectionStage.execute(ApiCallMetricCollectionStage.java:32)
    at software.amazon.awssdk.core.internal.http.pipeline.RequestPipelineBuilder$ComposingRequestPipelineStage.execute(RequestPipelineBuilder.java:206)
    at software.amazon.awssdk.core.internal.http.pipeline.stages.ExecutionFailureExceptionReportingStage.execute(ExecutionFailureExceptionReportingStage.java:37)
    at software.amazon.awssdk.core.internal.http.pipeline.stages.ExecutionFailureExceptionReportingStage.execute(ExecutionFailureExceptionReportingStage.java:26)
    at software.amazon.awssdk.core.internal.http.AmazonSyncHttpClient$RequestExecutionBuilderImpl.execute(AmazonSyncHttpClient.java:210)
    at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.invoke(BaseSyncClientHandler.java:103)
    at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.doExecute(BaseSyncClientHandler.java:173)
    at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.lambda$execute$0(BaseSyncClientHandler.java:66)
    at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.measureApiCallSuccess(BaseSyncClientHandler.java:182)
    at software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.execute(BaseSyncClientHandler.java:60)
    at software.amazon.awssdk.core.client.handler.SdkSyncClientHandler.execute(SdkSyncClientHandler.java:52)
    at software.amazon.awssdk.awscore.client.handler.AwsSyncClientHandler.execute(AwsSyncClientHandler.java:60)
    at software.amazon.awssdk.services.s3.DefaultS3Client.getObject(DefaultS3Client.java:5210)
    at org.apache.iceberg.aws.s3.S3InputStream.openStream(S3InputStream.java:192)
    at org.apache.iceberg.aws.s3.S3InputStream.positionStream(S3InputStream.java:177)
    at org.apache.iceberg.aws.s3.S3InputStream.read(S3InputStream.java:94)
    at org.apache.iceberg.shaded.org.apache.parquet.io.DelegatingSeekableInputStream.read(DelegatingSeekableInputStream.java:61)
    at org.apache.iceberg.shaded.org.apache.parquet.bytes.BytesUtils.readIntLittleEndian(BytesUtils.java:83)
    at org.apache.iceberg.shaded.org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:556)
    at org.apache.iceberg.shaded.org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:799)
    at org.apache.iceberg.shaded.org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:666)
    at org.apache.iceberg.parquet.ReadConf.newReader(ReadConf.java:238)
    at org.apache.iceberg.parquet.ReadConf.<init>(ReadConf.java:81)
    at org.apache.iceberg.parquet.VectorizedParquetReader.init(VectorizedParquetReader.java:90)
    at org.apache.iceberg.parquet.VectorizedParquetReader.iterator(VectorizedParquetReader.java:99)
    at org.apache.iceberg.spark.source.BatchDataReader.open(BatchDataReader.java:109)
    at org.apache.iceberg.spark.source.BatchDataReader.open(BatchDataReader.java:41)
    at org.apache.iceberg.spark.source.BaseReader.next(BaseReader.java:143)
    at org.apache.spark.sql.execution.datasources.v2.PartitionIterator.hasNext(DataSourceRDD.scala:120)
    at org.apache.spark.sql.execution.datasources.v2.MetricsIterator.hasNext(DataSourceRDD.scala:158)
    at org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.$anonfun$hasNext$1(DataSourceRDD.scala:63)
    at org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.$anonfun$hasNext$1$adapted(DataSourceRDD.scala:63)
    at scala.Option.exists(Option.scala:376)
    at org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.hasNext(DataSourceRDD.scala:63)
    at org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.advanceToNextIter(DataSourceRDD.scala:97)
    at org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.hasNext(DataSourceRDD.scala:63)
    at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
    at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
    at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage22.columnartorow_nextBatch_0$(Unknown Source)
    at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage22.processNext(Unknown Source)
    at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
    at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
    at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
    at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)
    at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
    at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)
    at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
    at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
    at org.apache.spark.scheduler.Task.run(Task.scala:141)
    at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
    at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
    at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
    at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
    at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
    at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
    at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
    at java.base/java.lang.Thread.run(Thread.java:840)
```

### Describe the solution you'd like

The support for refreshing vended-credentials has been added with the new version of Iceberg, i.e. 1.7.0.
But, this API will need to be implemented in Polaris.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/464/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/464,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6WUW5F,polaris,2521919045,464,NA,chetan-habu,107653462,chetan urkudkar,,NA,2024-12-06T01:57:09Z,2024-12-06T01:57:09Z,Team any updates to share. This is blocking us from enabling long running jobs.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6WUW5F/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/464,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Z6A_M,polaris,2582122444,464,NA,ashish-picha-velotio,95350723,,,NA,2025-01-10T09:08:10Z,2025-01-10T09:08:10Z,"Hi Team,
It would be great if you could share any timeline regarding this feature request.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Z6A_M/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/464,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cf-Jx,polaris,2625626737,464,NA,wolflex888,22242745,Juichang Lu,,NA,2025-01-30T21:24:32Z,2025-01-30T21:24:32Z,"Hi all, I want to start the discussion about the expectations and designs we have on the endpoint. Do we expect the endpoint to return multiple credentials for different tables/catalogs? or we can start with returning credentials on just one table?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cf-Jx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/471,https://api.github.com/repos/apache/polaris/issues/471,polaris,2688114554,471,[BUG] Catalog endpoint for 'check if a table exists' returns <200> but should return <204>,JasperHG90,8079803,Jasper Ginn,,CLOSED,2024-11-24T17:48:01Z,2024-11-27T08:50:11Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

The 'check if table exists' catalog [endpoint](https://polaris.apache.org/in-dev/unreleased/rest-catalog-open-api/#tag/Catalog-API/operation/tableExists) returns status code <200>. The API docs indicate that it should return status code <204>. I initially posted this as a bug in the [PyIceberg repository](https://github.com/apache/iceberg-python/issues/1363#issuecomment-2495556035).

### To Reproduce

Here's the script I posted in the PyIceberg issue

```python
#%%

import httpx
import polars as pl
from pyiceberg.catalog import load_catalog

# Assumes this catalog exists and credentials stored in
#  .pyiceberg.yaml
# Possibly created using https://github.com/JasperHG90/dagster-pyiceberg-example-polaris/blob/main/scripts/set_up_catalog.py
catalog = load_catalog(
    name=""dagster_example_catalog"",
)

# %% Create a namespace

catalog.create_namespace(""example"")

# %% Create data and add to table

df = pl.from_dict({
    ""a"": [1, 2, 3],
    ""b"": [4, 5, 6]
}).to_arrow()

catalog.create_table(
    identifier=""example.table"",
    schema=df.schema
)

# %% This will return 'False'

catalog.table_exists(""example.table"")

# %% But querying the 'table exists' Polaris endpoint  returns 200

catalog_client = httpx.Client(
    base_url=""http://polaris:8181/api/catalog/v1"",
    headers={
        ""Authorization"": ""Bearer principal:root;realm:default-realm"",
        ""Content-Type"": ""application/json"",
    }
)

# See endpoint here: https://polaris.apache.org/in-dev/unreleased/rest-catalog-open-api/#tag/Catalog-API/operation/tableExists
resp = catalog_client.head(
    url=""dagster_example_catalog/namespaces/example/tables/table""
)

resp.status_code # 200
```

This should work with any Polaris instance I suppose. The devcontainer that I use can be found [here](https://github.com/JasperHG90/dagster-pyiceberg-example-polaris/tree/main/.devcontainer).

### Actual Behavior

It returns a <200> status code.

### Expected Behavior

It should return a <204> status code.

### Additional context

N/A

### System information

Ubuntu 22.04 LTS
Polars SHA: [017ebbc](https://github.com/apache/polaris/tree/017ebbc6eeb76239a169079cb6c3d99e725ceb22)","{""url"": ""https://api.github.com/repos/apache/polaris/issues/471/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/471,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6UzsDo,polaris,2496577768,471,NA,MonkeyCanCode,29619290,,,NA,2024-11-25T03:01:29Z,2024-11-25T03:01:29Z,Checking ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6UzsDo/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/471,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6U0uDU,polaris,2496848084,471,NA,MonkeyCanCode,29619290,,,NA,2024-11-25T05:04:19Z,2024-11-25T05:04:19Z,PR for fixing this issue: https://github.com/apache/polaris/pull/472/files,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6U0uDU/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/476,https://api.github.com/repos/apache/polaris/issues/476,polaris,2690472339,476,CI failures / people.json not found,snazy,957468,Robert Stupp,,CLOSED,2024-11-25T11:49:07Z,2024-11-26T13:48:55Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

The `people.json` file is often not available, see https://issues.apache.org/jira/browse/COMDEV-557 for more details.

This issue is just a cross-reference to the Apache JIRA.
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/476/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/480,https://api.github.com/repos/apache/polaris/issues/480,polaris,2691266698,480,[BUG] Polaris can't use S3 when KMS is enabled,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,OPEN,2024-11-25T15:55:20Z,2025-01-27T07:37:24Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

When using Polaris with S3 (without KMS), everything is working fine (I can create Iceberg table from spark-sql on Polaris).

However, when I enable S3 KMS, I get:

```
ServerError: S3Exception: User: arn:aws:sts::601864557682:assumed-role/cep-analytics-platform-role-dev-polaris-catalog/snowflake is not authorized to perform: kms:GenerateDataKey on resource: arn:aws:kms:eu-west-1:601864557682:key/401edca7-d545-4907-9c9f-2695305beb5e because no session policy

allows the kms:GenerateDataKey action (Service: S3, Status Code: 403, Request ID: C0MA61C4VYNS88CP, Extended Request ID: ZboVDdn8eh4YBIjMUbG8X6fDT4oq6OFFqDcq/dKbVsrNDGW3IIhojELznwkyWhMDmSxO376I5o0=)
```

It seems that we have a missing security configuration to use with KMS.

### To Reproduce

Just use S3 KMS with Polaris.

### Actual Behavior

It works fine without KMW, but fails with S3 KMS enabled:

```
ServerError: S3Exception: User: arn:aws:sts::601864557682:assumed-role/cep-analytics-platform-role-dev-polaris-catalog/snowflake is not authorized to perform: kms:GenerateDataKey on resource: arn:aws:kms:eu-west-1:601864557682:key/401edca7-d545-4907-9c9f-2695305beb5e because no session policy

allows the kms:GenerateDataKey action (Service: S3, Status Code: 403, Request ID: C0MA61C4VYNS88CP, Extended Request ID: ZboVDdn8eh4YBIjMUbG8X6fDT4oq6OFFqDcq/dKbVsrNDGW3IIhojELznwkyWhMDmSxO376I5o0=)
```

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/480/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/480,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6VRJ04,polaris,2504301880,480,NA,MonkeyCanCode,29619290,,,NA,2024-11-27T16:27:11Z,2024-11-27T16:27:11Z,"In my setup, I am using S3 with KMS. To get it working, the IAM role needed to include additional IAM policy (for my setup, i have kms:GenerateDataKey, kms:Decrypt, and kms:DescribeKey added to the IAM role used by Polaris).","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6VRJ04/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/480,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6b3UHM,polaris,2614968780,480,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2025-01-27T06:53:50Z,2025-01-27T06:53:50Z,"Hi @jbonofre, did you resolve the issue with the solution provided by @MonkeyCanCode? Appreciate if you can confirm it, and this deserves a doc change.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6b3UHM/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/480,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6b3iam,polaris,2615027366,480,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2025-01-27T07:37:23Z,2025-01-27T07:37:23Z,@flyrain let me try again. ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6b3iam/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/502,https://api.github.com/repos/apache/polaris/issues/502,polaris,2710228642,502,[FEATURE REQUEST] Refactor usage of DropwizardAppExtension in the tests for PolarisApplication to maximize the reuse,gh-yzou,167037035,,,OPEN,2024-12-02T02:17:28Z,2024-12-02T19:29:59Z,"### Is your feature request related to a problem? Please describe.

There are a lot of tests uses DropwizardAppExtension to init a PolarisApplication, for example:
```
private static final DropwizardAppExtension<PolarisApplicationConfig> EXT =
      new DropwizardAppExtension<>(
          PolarisApplication.class,
          ResourceHelpers.resourceFilePath(""polaris-server-integrationtest.yml""),
          // Bind to random port to support parallelism
          ConfigOverride.config(""server.applicationConnectors[0].port"", ""0""),
          ConfigOverride.config(""server.adminConnectors[0].port"", ""0""),
          // Block overlapping catalog paths:
          ConfigOverride.config(""featureConfiguration.ALLOW_OVERLAPPING_CATALOG_URLS"", ""false""));
```
in PolarisOverlappingCatalogTest.java.


### Describe the solution you'd like

We can refactor the usaage as a util function or base class for maximize reuse.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/502/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/502,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6VwsE1,polaris,2512568629,502,NA,gh-yzou,167037035,,,NA,2024-12-02T19:29:58Z,2024-12-02T19:29:58Z,i am working on this,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6VwsE1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/503,https://api.github.com/repos/apache/polaris/issues/503,polaris,2713378030,503,[BUG] Polaris Service return wrong status when there's a location overlaps with existing catalog,wolflex888,22242745,Juichang Lu,,CLOSED,2024-12-02T21:01:22Z,2025-01-04T00:03:17Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

When creating a catalog that has an overlapping location with existing catalog, the service will return 400 ( BAD_REQUEST ), but it should be 409 ( CONFLICT )

### To Reproduce

Create a catalog with the same storage info location. the service will return 400 instead of 409.

### Actual Behavior

The Service returns 400 ( BAD_REQUEST ) when the new catalog has a overlapping location with existing catalog.

### Expected Behavior

I'm expecting the service to return 409 ( CONFLICT ) similar to catalogName conflict when creating a catalog.

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/503/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/503,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Vz8Jr,polaris,2513420907,503,NA,MonkeyCanCode,29619290,,,NA,2024-12-03T02:39:13Z,2024-12-03T02:39:13Z,"Hello @wolflex888,

Thanks for reporting this issue. Upon checking the published API doc, 409 is when the catalog name already existed instead of conflicted path: https://polaris.apache.org/in-dev/unreleased/polaris-management-service/#operation/listCatalogs.

In fact, it is possible to use overlapped path for catalogs (not by default, but with featureConfiguration.ALLOW_OVERLAPPING_CATALOG_URLS set to true...default is false). 

@eric-maynard do you think we should change the status code for this one or update the code to include this as expected?

Thanks,
Yong Zheng
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Vz8Jr/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/503,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6WRhug,polaris,2521176992,503,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-12-05T18:57:24Z,2024-12-05T18:57:24Z,"The intent behind a 400 was to indicate that:
1. The request is invalid, but we won't tell you exactly why (e.g. which existing entity you're in conflict with)
2. You can fix this by changing the request (or via the config to allow overlap which @MonkeyCanCode mentioned)

I don't have a strong opinion on changing this to a 409, though I would note that changing a return code is a breaking change that should normally only happen across API versions","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6WRhug/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/503,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XMIrn,polaris,2536540903,503,NA,mrcnc,547446,Marc Cenac,,NA,2024-12-11T16:52:38Z,2024-12-11T16:52:38Z,What is the use case for setting ALLOW_OVERLAPPING_CATALOG_URLS to true?  It seems like a dangerous thing to enable b/c it could lead to data loss from the delete orphan files procedure on an overlapping table.  Also if you use credentials vending it could allow access to files that aren't part of a table. ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XMIrn/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/503,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XTDA3,polaris,2538352695,503,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2024-12-12T09:30:42Z,2024-12-12T09:30:42Z,"Agreed @mrcnc. The chief concern was that someone could have existing catalogs that overlap. Besides that, they may just have some business justification for overlapping catalogs.

It's also important to point out that the restrictions against overlap do not provide ironclad guarantees as they stand. Even when catalogs are restricted s.t. they can't overlap, things you mentioned are already possible. Vended credentials can potentially read other data that is under a table's prefix. Two (EXTERNAL, by default IIRC) table locations can already overlap within a catalog.

Given this, and given the fact that some early users told us they wanted the option to have overlapping catalog locations, we added that flag.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XTDA3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/503,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZHTV3,polaris,2568828279,503,NA,MonkeyCanCode,29619290,,,NA,2025-01-03T08:09:21Z,2025-01-03T08:09:21Z,@flyrain Same for this one. Kindly check if this one should be close as well. ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZHTV3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/503,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZLk2K,polaris,2569948554,503,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2025-01-04T00:03:16Z,2025-01-04T00:03:16Z,"I'm OK with the return status 400. Also echo @eric-maynard 's point that changing a return status is a breaking change. We shouldn't make such change unless something is really wrong. With that, I think we can close this one. 

BTW, enabling ALLOW_OVERLAPPING_CATALOG_URLS is a potentially risky behavior. I believe we should avoid it whenever possible. Since I'm not aware of any specific use cases that require this feature, I canâ€™t provide further comments, but itâ€™s worth carefully evaluating its necessity before proceeding.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZLk2K/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/507,https://api.github.com/repos/apache/polaris/issues/507,polaris,2718365750,507,[FEATURE REQUEST] Does the polaris CLI support the create table command?,horizonzy,22524871,Yan Zhao,horizonzy@apache.org,CLOSED,2024-12-04T17:20:17Z,2024-12-13T03:48:39Z,"Looks like the Polaris CLI only supports create namespaces command, if I want to register a table in a catalog, how do I do?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/507/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/507,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XQ8I8,polaris,2537800252,507,NA,MonkeyCanCode,29619290,,,NA,2024-12-12T04:40:36Z,2024-12-12T04:40:36Z,"@horizonzy currently the CLI mainly supported catalogs, namespaces, principals, principal-roles, catalog-roles and  privileges management. You can't register a table in a catalog with it as of now. I usually do this via spark/trino/pyiceberg.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XQ8I8/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/507,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XbLAy,polaris,2540482610,507,NA,horizonzy,22524871,Yan Zhao,horizonzy@apache.org,NA,2024-12-13T03:48:38Z,2024-12-13T03:48:38Z,"> @horizonzy currently the CLI mainly supported catalogs, namespaces, principals, principal-roles, catalog-roles and privileges management. You can't register a table in a catalog with it as of now. I usually do this via spark/trino/pyiceberg.

OK, make sense","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XbLAy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/508,https://api.github.com/repos/apache/polaris/issues/508,polaris,2718858081,508,[FEATURE REQUEST] Add support for refresh credentials endpoint,johnnysohn,55504589,,,CLOSED,2024-12-04T21:50:23Z,2024-12-11T19:01:00Z,"### Is your feature request related to a problem? Please describe.

With the release of Iceberg [1.7.0](https://github.com/apache/iceberg/releases/tag/apache-iceberg-1.7.0), we now have a way (new API) to refresh vended credentials. 

Specifically [LoadCredentialsResponse](https://github.com/apache/iceberg/blob/main/open-api/rest-catalog-open-api.yaml#L3165) and an API endpoint has been added to support refreshing vended credentials.

### Describe the solution you'd like

Please implement these new REST spec on Polaris to support refreshing vended credentials. If the Polaris team is resource constrained on providing this in a timely manner, we can help out with the dev effort on this.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/508/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/508,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6WM1lN,polaris,2519947597,508,NA,adutra,463876,Alexandre Dutra,,NA,2024-12-05T10:45:26Z,2024-12-05T10:45:26Z,This is a duplicate of #464.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6WM1lN/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/508,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XNa6Q,polaris,2536877712,508,NA,collado-mike,40346148,Michael Collado,,NA,2024-12-11T19:01:00Z,2024-12-11T19:01:00Z,Closing as dupe. Work can continue on the linked issue,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XNa6Q/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/509,https://api.github.com/repos/apache/polaris/issues/509,polaris,2719431803,509,[BUG] Create namespace failed due to `not authorized for op CREATE_NAMESPACE`,horizonzy,22524871,Yan Zhao,horizonzy@apache.org,CLOSED,2024-12-05T06:08:35Z,2024-12-05T06:52:58Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

I have granted the catalog role with `NAMESPACE_CREATE` privilege, but the log shows the user didn't have the privilege.

```
DEBUG [2024-12-05 14:33:15,035 - 2455845] [pool-3-thread-8] [] o.a.p.s.c.DefaultContextResolver: Resolving RealmContext for method: POST, path: api/catalog/v1/quickstart_catalog/namespaces, queryParams: {}, headers: {Authorization=Bearer principal:quickstart_user;password:13303f19331e1fc386d4173e92882499;realm:default-realm;role:catalog, X-Client-Git-Commit-Short=cbb8530, Accept=application/json, X-Client-Version=Apache Iceberg 1.5.2 (commit cbb853073e681b4075d7c8707610dceecbee3a82), Connection=keep-alive, User-Agent=Apache-HttpClient/5.3.1 (Java/17.0.3.1), Host=localhost:8181, Accept-Encoding=gzip, x-gzip, deflate, Content-Length=40, Content-Type=application/json} 
DEBUG [2024-12-05 14:33:15,035 - 2455845] [pool-3-thread-8] [] o.a.p.s.c.DefaultContextResolver: Resolving CallContext realmContext=""default-realm"" method=""POST"" path=""api/catalog/v1/quickstart_catalog/namespaces"" queryParams=""{}"" headers=""{Authorization=Bearer principal:quickstart_user;password:13303f19331e1fc386d4173e92882499;realm:default-realm;role:catalog, X-Client-Git-Commit-Short=cbb8530, Accept=application/json, X-Client-Version=Apache Iceberg 1.5.2 (commit cbb853073e681b4075d7c8707610dceecbee3a82), Connection=keep-alive, User-Agent=Apache-HttpClient/5.3.1 (Java/17.0.3.1), Host=localhost:8181, Accept-Encoding=gzip, x-gzip, deflate, Content-Length=40, Content-Type=application/json}""
INFO  [2024-12-05 14:33:15,035 - 2455845] [pool-3-thread-8] [] o.a.p.s.tracing.TracingFilter: Started span with parent spanId=""878314b6f8a8d255"" traceId=""05ba37b294ea2b072a278ebe8d452893"" parentContext=""{}""
INFO  [2024-12-05 14:33:15,035 - 2455845] [pool-3-thread-8 - POST /api/catalog/v1/quickstart_catalog/namespaces] [] o.a.p.s.a.TestInlineBearerTokenPolarisAuthenticator: Checking for existence of principal quickstart_user in map {principal=quickstart_user, password=13303f19331e1fc386d4173e92882499, realm=default-realm, role=catalog} 
WARN  [2024-12-05 14:33:15,035 - 2455845] [pool-3-thread-8 - POST /api/catalog/v1/quickstart_catalog/namespaces] [] o.a.p.s.a.TestInlineBearerTokenPolarisAuthenticator: Failed to load secrets for principal quickstart_user 
DEBUG [2024-12-05 14:33:15,035 - 2455845] [pool-3-thread-8 - POST /api/catalog/v1/quickstart_catalog/namespaces] [] o.a.p.s.a.BasePolarisAuthenticator: Resolving principal for tokenInfo client_id=null 
DEBUG [2024-12-05 14:33:15,035 - 2455845] [pool-3-thread-8 - POST /api/catalog/v1/quickstart_catalog/namespaces] [] o.a.p.s.a.BasePolarisAuthenticator: Resolved principal: name=quickstart_user;id=5;parentId=0;entityVersion=1;type=PRINCIPAL;subType=NULL_SUBTYPE;internalProperties={client_id=2a28f9b50ad38147} 
DEBUG [2024-12-05 14:33:15,035 - 2455845] [pool-3-thread-8 - POST /api/catalog/v1/quickstart_catalog/namespaces] [] o.a.p.s.a.BasePolarisAuthenticator: Populating authenticatedPrincipal into CallContext: principalEntity=name=quickstart_user;id=5;parentId=0;entityVersion=1;type=PRINCIPAL;subType=NULL_SUBTYPE;internalProperties={client_id=2a28f9b50ad38147};activatedPrincipalRoleNames=[catalog];activatedPrincipalRoles=null 
DEBUG [2024-12-05 14:33:15,036 - 2455846] [pool-3-thread-8 - POST /api/catalog/v1/quickstart_catalog/namespaces] [] o.a.p.s.c.a.IcebergRestCatalogApi: Invoking CatalogApi with params operation=""createNamespace"" prefix=""quickstart_catalog"" createNamespaceRequest=""CreateNamespaceRequest{namespace=public, properties={}}""
DEBUG [2024-12-05 14:33:15,036 - 2455846] [pool-3-thread-8 - POST /api/catalog/v1/quickstart_catalog/namespaces] [] o.a.p.s.c.RealmEntityManagerFactory: Looking up PolarisEntityManager for realm default-realm 
DEBUG [2024-12-05 14:33:15,036 - 2455846] [pool-3-thread-8 - POST /api/catalog/v1/quickstart_catalog/namespaces] [] o.a.p.c.a.PolarisAuthorizerImpl: Failed to satisfy privilege NAMESPACE_CREATE for principalName quickstart_user on resolvedPath resolvedPath:[entity:name=root_container;id=0;parentId=0;entityVersion=1;type=ROOT;subType=NULL_SUBTYPE;internalProperties={};grantRecordsAsGrantee:[];grantRecordsAsSecurable:[PolarisGrantRec{securableCatalogId=0, securableId=0, granteeCatalogId=0, granteeId=2, privilegeCode=1}], entity:name=quickstart_catalog;id=3;parentId=0;entityVersion=1;type=CATALOG;subType=NULL_SUBTYPE;internalProperties={catalogType=EXTERNAL, storage_configuration_info={""@type"":""AwsStorageConfigurationInfo"",""storageType"":""S3"",""allowedLocations"":[""s3://***************""],""roleARN"":""**************"",""fileIoImplClassName"":""org.apache.iceberg.aws.s3.S3FileIO""}, remoteUrl=null};grantRecordsAsGrantee:[];grantRecordsAsSecurable:[PolarisGrantRec{securableCatalogId=0, securableId=3, granteeCatalogId=3, granteeId=4, privilegeCode=2}, PolarisGrantRec{securableCatalogId=0, securableId=3, granteeCatalogId=3, granteeId=4, privilegeCode=31}, PolarisGrantRec{securableCatalogId=0, securableId=3, granteeCatalogId=3, granteeId=7, privilegeCode=32}, PolarisGrantRec{securableCatalogId=0, securableId=3, granteeCatalogId=3, granteeId=7, privilegeCode=5}]] 
INFO  [2024-12-05 14:33:15,037 - 2455847] [pool-3-thread-8 - POST /api/catalog/v1/quickstart_catalog/namespaces] [] o.a.p.s.e.IcebergExceptionMapper: Handling runtimeException Principal 'quickstart_user' with activated PrincipalRoles '[catalog]' and activated grants via '[]' is not authorized for op CREATE_NAMESPACE 
DEBUG [2024-12-05 14:33:15,037 - 2455847] [pool-3-thread-8 - POST /api/catalog/v1/quickstart_catalog/namespaces] [] o.a.p.s.e.IcebergExceptionMapper: Mapped exception to errorResp: OutboundJaxrsResponse{status=403, reason=Forbidden, hasEntity=true, closed=false, buffered=false} 
INFO  [2024-12-05 14:33:15,037 - 2455847] [pool-3-thread-8] [] i.o.e.l.LoggingSpanExporter: 'POST /api/catalog/v1/quickstart_catalog/namespaces' : 05ba37b294ea2b072a278ebe8d452893 878314b6f8a8d255 SERVER [tracer: /api/catalog/v1/quickstart_catalog/namespaces:] AttributesMap{data={http.request.method=POST, server.address=localhost, url.path=/api/catalog/v1/quickstart_catalog/namespaces, url.scheme=http, realm=default-realm}, capacity=128, totalAddedValues=5} 
127.0.0.1 - quickstart_user [05/12æœˆ/2024:06:33:15 +0000] ""POST /api/catalog/v1/quickstart_catalog/namespaces HTTP/1.1"" 403 204 ""-"" ""Apache-HttpClient/5.3.1 (Java/17.0.3.1)"" 3

```

```
 ./polaris principal-roles list --principal quickstart_user
{""name"": ""quickstart_user_role"", ""properties"": {}, ""createTimestamp"": 1733378020190, ""lastUpdateTimestamp"": 1733378020190, ""entityVersion"": 1}

./polaris catalog-roles list --principal-role quickstart_user_role  quickstart_catalog
{""name"": ""quickstart_catalog_role"", ""properties"": {}, ""createTimestamp"": 1733378024926, ""lastUpdateTimestamp"": 1733378024926, ""entityVersion"": 1}


 ./polaris privileges  list --catalog quickstart_catalog --catalog-role quickstart_catalog_role
{""type"": ""catalog"", ""privilege"": ""CATALOG_MANAGE_CONTENT""}
{""type"": ""catalog"", ""privilege"": ""NAMESPACE_CREATE""}

```

I notice the log 
```
DEBUG [2024-12-05 14:33:15,035 - 2455845] [pool-3-thread-8 - POST /api/catalog/v1/quickstart_catalog/namespaces] [] o.a.p.s.a.BasePolarisAuthenticator: Populating authenticatedPrincipal into CallContext: principalEntity=name=quickstart_user;id=5;parentId=0;entityVersion=1;type=PRINCIPAL;subType=NULL_SUBTYPE;internalProperties={client_id=2a28f9b50ad38147};activatedPrincipalRoleNames=[catalog];activatedPrincipalRoles=null 

```
I already connect the principal `quickstart_user` with catalog role `quickstart_user_role`, but it shows that the `quickstart_user` ""activatedPrincipalRoleNames=[catalog];activatedPrincipalRoles=null""


### To Reproduce
Followed the https://polaris.apache.org/in-dev/unreleased/quickstart/ guidance, and grant the `NAMESPACE_CREATE` privilege to catalog role `quickstart_catalog_role`.

Then start the program,  the program uses the rest catalog to access the Polaris, when creating the namespace, the Polaris server throw the exception.

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

the branch: master ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/509/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/515,https://api.github.com/repos/apache/polaris/issues/515,polaris,2728938918,515,[FEATURE REQUEST] Refactor Cleanup Task Handler,danielhumanmod,135958699,Daniel Tu,,OPEN,2024-12-10T04:01:53Z,2024-12-10T04:01:53Z,"### Is your feature request related to a problem? Please describe.

In #312, we introduced metadata file cleanup logic into the `ManifestFileCleanupTaskHandler`, resulting in this handler being coupled with the cleanup logic for various file types. To improve maintainability and scalability in the future, it may be beneficial to create a base class for cleanup tasks and extract a dedicated batch file cleanup task handler from it.

### Describe the solution you'd like

_No response_

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/515/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/520,https://api.github.com/repos/apache/polaris/issues/520,polaris,2729436970,520,Replace `PolarisDiagnostics` with Guava `Preconditions`,snazy,957468,Robert Stupp,,CLOSED,2024-12-10T08:51:58Z,2025-01-15T09:01:15Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

The only implementation of `PolarisDiagnostics` is a rather wrapper around Guava's `Preconditions`. Instance(s) of `PolarisDiagnostics` are carried around in a bunch of places. Just carrying around this instance to wrap the common `Preconditions` is unnecessary and leads to a lot of rather unnecessary code.

Replacing `PolarisDiagnostics(Impl)` with plain calls to `Preconditions` simplifies the code base in a lot of places.

`RuntimeException`s can always be caught properly at the service level or even below and handled accordingly. If finer grained handling is necessary, it's better to have implicit/injected tracing mechanisms in place, which is more robust and clearer than manual implementations.

The change should also use the opportunity and replace the rather cryptic messages with messages that provide meaningful information to users and ideally also actionable information.

NB: This change would also remove the last usage of the Jetbrains-annotations dependency.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/520/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/520,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6aftfc,polaris,2592004060,520,NA,snazy,957468,Robert Stupp,,NA,2025-01-15T09:01:13Z,2025-01-15T09:01:13Z,Superseded by #759,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6aftfc/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/521,https://api.github.com/repos/apache/polaris/issues/521,polaris,2729458128,521,Isolate dependencies on Dropwizard + hk2,snazy,957468,Robert Stupp,,CLOSED,2024-12-10T09:00:59Z,2024-12-10T20:58:06Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

Dropwizard + hk2 dependencies are currently used in `:polaris-service`, but `:polaris-service` also contains code needed for Quarkus, which causes conflicts.

Specific implementations, DW + Quarkus, should live in separate modules, ideally underneath separate folders in the code base, for example `quarkus/polaris-quarkus-service` or `dropwizard/polaris-dropwizard-service`, to group additional  framework specific modules together.
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/521/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/524,https://api.github.com/repos/apache/polaris/issues/524,polaris,2731031844,524,[FEATURE REQUEST] Reusable integration tests,dimas-b,40603221,Dmitri Bourlatchkov,,CLOSED,2024-12-10T19:41:35Z,2025-01-31T22:11:23Z,"### Is your feature request related to a problem? Please describe.

Currently integration tests use `TestEnvironmentExtension` that is intended to provide multiple execution environments, but at the same time depend on `DropwizardExtensionsSupport` that automatically starts a local DW server.

### Describe the solution you'd like

* Sharable suite of tests that can be executed against different Polaris servers.
* Polaris Server lifecycle delegated to the test environment.
* CI continues to use Dropwizard for integration tests, but in a ""backbox"" manner (tweaking only via standard config options).

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/524/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/524,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6W9h3z,polaris,2532711923,524,NA,dimas-b,40603221,Dmitri Bourlatchkov,,NA,2024-12-10T19:43:59Z,2024-12-10T19:43:59Z,I'm working on PR for this issue :hourglass: ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6W9h3z/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/524,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6W-nTA,polaris,2532996288,524,NA,collado-mike,40346148,Michael Collado,,NA,2024-12-10T21:58:20Z,2024-12-10T21:58:20Z,@andrew4699 has done some work here - it would be good if he can also help define requirements,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6W-nTA/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/524,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6W-5QH,polaris,2533069831,524,NA,dimas-b,40603221,Dmitri Bourlatchkov,,NA,2024-12-10T22:24:56Z,2024-12-10T22:24:56Z,I put my notes above. We also have a Zulip thread on this.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6W-5QH/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/524,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XMRiy,polaris,2536577202,524,NA,andrew4699,7133966,Andrew Guterman,andrew.guterman1@gmail.com,NA,2024-12-11T17:06:46Z,2024-12-11T17:06:46Z,"This sounds great. Today you can jump through a series of hoops and run tests against any Polaris server but it's wasteful (due to always spinning up a DW instance) and not intuitive (only 1 test class supported/distinction between local DW and remote is unclear).

I'm happy to help with implementation once things are less busy. The implementation may also look a bit different in Quarkus vs DW.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XMRiy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/524,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YtkuE,polaris,2562083716,524,NA,dimas-b,40603221,Dmitri Bourlatchkov,,NA,2024-12-26T02:21:19Z,2024-12-26T02:21:19Z,@andrew4699 : Please review #590,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YtkuE/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/524,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YxiNB,polaris,2563121985,524,NA,andrew4699,7133966,Andrew Guterman,andrew.guterman1@gmail.com,NA,2024-12-26T21:52:23Z,2024-12-26T21:52:23Z,Typing from my phoneâ€¦ Iâ€™m out through the 6th but will look when I get a chance.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YxiNB/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/524,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cq4H-,polaris,2628485630,524,NA,dimas-b,40603221,Dmitri Bourlatchkov,,NA,2025-01-31T22:11:21Z,2025-01-31T22:11:21Z,#590 looks sufficient for now from my POV. Closing this issue.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cq4H-/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/526,https://api.github.com/repos/apache/polaris/issues/526,polaris,2731313510,526,Decompose PolarisMetaStoreManager into distinct implementations and divide responsibilities,collado-mike,40346148,Michael Collado,,OPEN,2024-12-10T22:12:57Z,2024-12-12T13:35:49Z,"### Is your feature request related to a problem? Please describe.

Currently, the `PolarisMetaStoreManager` is the central interface to:

* Persistence and retrieval of persisted entities
* Storage and validation of secrets
* Privilege/grant management
* Entity cache validation/eviction/refresh
* Credential vending

#417 did some initial work to break up the interface into multiple interfaces so that components can depend on the specific functionality they require (i.e., persistence only or credential vending only), but the core interface itself still extends all of these interfaces and any metastore implementation must implement all of the methods in every interface. This makes it very difficult to swap out components for specialized tools, such as Vault for secrets management or redis for distributed caches or some policy-based grant manager.

### Describe the solution you'd like

The `PolarisMetaStoreManager` interface should no longer depend on any of the other interfaces and should contain persistence-only method definitions. This allows for persistence implementations to focus only on entity storage and retrieval, while other components can be responsible for implementing secrets management or credential vending. Furthermore, the cache logic should be refactored so that business components, such as the `PolarisServiceImpl` don't need to know anything about the entity cache, but can deal with the persistence interface directly. Caching may be implemented under the hood, but that should be transparent to the business components.

### Describe alternatives you've considered

_No response_

### Additional context

I've started a doc at https://docs.google.com/document/d/1MNCdW-uKVZaR5Ua91FDwxhreBeGjPOoV-CyF0WOWwIg/edit?tab=t.0 that can be used to iterate on a class design so that it's clear how responsibilities are divided. This should prevent multiple people from making conflicting changes while the core components are being refactored.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/526/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/528,https://api.github.com/repos/apache/polaris/issues/528,polaris,2732523491,528,[BUG] Misuse of technical IDs when creating entities,snazy,957468,Robert Stupp,,CLOSED,2024-12-11T10:34:25Z,2024-12-11T12:48:52Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

Implementations of operations that _create new_ entities, for example in `PolarisAdminService`, must always generate a _new_ technical ID and not use an _externally_ provided one.

Many places in the code base so something like this:
```java
  public PolarisEntity createCatalog(PolarisEntity entity) {
---
    long id =
        entity.getId() <= 0
            ? metaStoreManager.generateNewEntityId(getCurrentPolarisContext()).getId()
            : entity.getId();
...
    PolarisEntity polarisEntity =
        new PolarisEntity.Builder(entity)
            .setId(id)
            .setCreateTimestamp(System.currentTimeMillis())
            .build();
...
```

The above pattern is error prone and can easily lead to issues like ID collisions later on.

Such implementation must really ensure that
1. the passed in ID is either not present or a not-present value (0)
2. the ID of the new entity must always be generated
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/528/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/528,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XJq2h,polaris,2535894433,528,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2024-12-11T12:45:26Z,2024-12-11T12:45:26Z,"@snazy to be honest, I don't see the use case to use an external ID. I agree that the ID should be always generated:

```
.setId(metaStoreManager.generateNewEntityId(getCurrentPolarisContext()).getId())
```

and ignore the ID coming from the ""new"" entitiy.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XJq2h/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/537,https://api.github.com/repos/apache/polaris/issues/537,polaris,2733453795,537,Rework main Dockerfile,adutra,463876,Alexandre Dutra,,OPEN,2024-12-11T16:37:41Z,2024-12-19T23:42:15Z,"### Is your feature request related to a problem? Please describe.

The Dockerfile that sits at the repository root is rather insecure, especially this directive:

```dockerfile
COPY --chown=default:root . /app
```

With this directive it's a piece of cake to introduce a backdoor, build a hacked Polaris image, and distribute it.

Moreover, I'm concerned that people would think that this is the ""official"" Dockerfile for Polaris and would use it to push Polaris into production â€“ since it sits at the repository root. This Dockerfile is also referenced in the main `README.md`, which contributes a bit more to branding it as the ""official"" thing.

### Describe the solution you'd like

I would like to suggest at least one of the following mitigation actions:

1. Clearly flag this Dockerfile for evaluation and/or testing purposes, e.g. by renaming it to `Dockerfile-dev`;
2. Better yet, move it to `dropwizard/service` to reduce its build context to just that module and also to reduce the risk of people using it in production.

Moving that Dockerfile would require changing the build steps though, since it won't be possible to build the entire code base anymore inside the docker build. An alternative was suggested a while ago in https://github.com/apache/polaris/pull/268 â€“ _I think we need to revive that PR_. In particular, I don't see a sensible difference between building the code in the docker build vs copying pre-built artifacts, neither in terms of build reproducibility nor in terms of security (both are equally insecure, in fact).

### Describe alternatives you've considered

_No response_

### Additional context

Side note on the ""official"" Dockerfile: we don't have one yet, but ideally, that Dockerfile would check out a released tag and build it. Alternatively, it could download the released Maven artifacts from Maven Central. As a third option, it could copy the final artifacts from the local build directory â€“ but that would only be safe if done in CI and triggered by a trusted user. 

In any case, I wouldn't recommend using the current strategy of building the local codebase inside the docker build as the strategy to use for future official Docker images.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/537/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/537,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XRDHr,polaris,2537828843,537,NA,MonkeyCanCode,29619290,,,NA,2024-12-12T05:10:25Z,2024-12-12T05:10:25Z,"In my opinion, Option 1 will make the Docker image less useful. People will only be able to follow along with the documentation using H2, and advanced users will likely end up creating their own fork to implement something similar, or they might go with Option 2 in their own fork. As for Option 2, the only concern is the build environment, as some people might have trouble setting it up (if that's acceptable?).
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XRDHr/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/537,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XUNab,polaris,2538657435,537,NA,adutra,463876,Alexandre Dutra,,NA,2024-12-12T11:43:27Z,2024-12-12T11:43:27Z,"Hi @MonkeyCanCode why do you say that with Option 1 ""People will only be able to follow along with the documentation using H2, and advanced users will likely end up creating their own fork to implement something similar""? Imho you can keep building images as before, only you would need to pass the flag `-f Dockerfile-dev`.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XUNab/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/537,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XUN95,polaris,2538659705,537,NA,adutra,463876,Alexandre Dutra,,NA,2024-12-12T11:44:39Z,2024-12-12T11:44:39Z,"Also, we should keep in mind that users shouldn't be building Polaris images, they should pull official images from our future official repository. The situation today is because we don't have any released official Polaris image yet.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XUN95/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/537,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XamYu,polaris,2540332590,537,NA,MonkeyCanCode,29619290,,,NA,2024-12-13T01:23:40Z,2024-12-13T01:23:40Z,"@adutra I see what you are saying. Yeah, I was referring to ""build the entire code base anymore inside the docker build"" as I am assuming some components people won't be able to build then ended up moving things around to get a working docker image.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XamYu/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/538,https://api.github.com/repos/apache/polaris/issues/538,polaris,2733660108,538,Table maintenance Support in Polaris,flyrain,1322359,Yufei Gu,yufei@apache.org,OPEN,2024-12-11T18:14:08Z,2024-12-19T23:45:19Z,"### Describe the solution you'd like

Iceberg table maintenance allows users to focus on their business needs without worrying about table management. It ensures tables stay optimized, perform efficiently, and comply with governance policies like data retention. Common maintenance tasks include data compaction, metadata compaction, snapshot expiration, partition stats collection, and orphan file removal.
The Table Maintenance System (TMS) can operate independently from a catalog like Polaris, providing maintenance services even without direct integration. However, it functions more effectively when paired with a catalog. Meanwhile, Polaris should allow pluggable TMS options so users can choose the one that fits their needs. This document outlines how Polaris supports Iceberg table maintenanceâ€”defining its role and clarifying what it should handle and what it should leave to TMS.

Here is the proposal, https://docs.google.com/document/d/1Pd_mzZcfvnUvcH98IbwsIYf4eryet1lQDfclKYx-t-M/edit?usp=sharing.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/538/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/540,https://api.github.com/repos/apache/polaris/issues/540,polaris,2734899865,540,Federation of Catalog-level entities to remote catalogs,dennishuo,7410123,Dennis Huo,,OPEN,2024-12-12T05:42:42Z,2024-12-12T13:35:26Z,"### Is your feature request related to a problem? Please describe.

As Iceberg users sometimes find different Iceberg-catalog sources of truth being created organically over time, it can be difficult to consolidate or centralize workloads onto a new target architecture or onboard new catalog implementations like Polaris to unlock its RBAC features without disrupting ongoing workloads.

Being able to have one Catalog instance serve as a combined ""pane of glass"" serving the contents of a legacy Catalog alongside new datasets enables an incremental migration or even simply enabling different workloads to leverage different catalog features without a stop-the-world migration.

### Describe the solution you'd like

Read-through federation of Catalog entities (e.g. Namespaces, Tables, Views) would allow a Polaris instance to link in an existing remote Catalog as a source-of-truth while exposing a Polaris entry-point along with Polaris RBAC features without performing a disruptive migration of Catalog contents.

Ideally, this federation would require minimal setup of the initial catalog connection while still benefiting from all the fine-grained access control features expected from normal Polaris catalogs; it should intelligently pass through API operations but also allow defining privilege grants on entities without requiring prior setup/syncing of those entities into the Polaris federation layer.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/540/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/540,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XRMFa,polaris,2537865562,540,NA,dennishuo,7410123,Dennis Huo,,NA,2024-12-12T05:43:26Z,2024-12-12T05:43:26Z,Proposal with MVP scope and some tentative design elements in this document: https://docs.google.com/document/d/1Q6eEytxb0btpOPcL8RtkULskOlYUCo_3FLvFRnHkzBY/edit?tab=t.0,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XRMFa/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/541,https://api.github.com/repos/apache/polaris/issues/541,polaris,2735813019,541,[BUG] Possible DoS attack vector with forged realm IDs,adutra,463876,Alexandre Dutra,,CLOSED,2024-12-12T12:49:41Z,2025-01-14T11:29:36Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

So this _is_ a bit of a security vulnerability, but it's already public, and we don't have any official release yet, so ðŸ¤·â€â™‚ï¸ 

It is possible for a malicious actor to cause Polaris to OOM by flooding the server with requests having random realm IDs.

This is possible because a) the default `RealmContextResolver` does not validate that the realm exists and b) many components maintain an unbounded cache of objects keyed by realm ID, e.g.:

* `RealmScopeContext`
* `RealmEntityManagerFactory`
* `RealmTokenBucketRateLimiter`
* `LocalPolarisMetaStoreManagerFactory`

I suggest the following mitigation measures:

* The default `RealmContextResolver` MUST validate the realm IDs â€“ which means that we need to persist realms in the database or somewhere else (maybe in configuration?)
* Any components caching by realm ID should use a bounded cache with proper eviction policies.


### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/541/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/541,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XlgU5,polaris,2543191353,541,NA,adutra,463876,Alexandre Dutra,,NA,2024-12-14T17:19:35Z,2024-12-14T17:19:35Z,"Neither the default realm context resolver nor the default call context resolver seems suitable for production usage:

https://github.com/apache/polaris/blob/85f0beb06144f171c49047f431105e20c5eb270b/service/common/src/main/java/org/apache/polaris/service/context/DefaultRealmContextResolver.java#L50

https://github.com/apache/polaris/blob/85f0beb06144f171c49047f431105e20c5eb270b/service/common/src/main/java/org/apache/polaris/service/context/DefaultCallContextResolver.java#L40","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XlgU5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/541,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Yw4kw,polaris,2562951472,541,NA,adutra,463876,Alexandre Dutra,,NA,2024-12-26T16:57:29Z,2024-12-26T16:57:29Z,"Investigating this a bit more, I think the most problematic aspects are:

1 `RealmTokenBucketRateLimiter`, because this filter kicks in _before_ the authenticating filter, thus executing itself for any request, even unauthenticated. Since it holds a map of token buckets per realm, this map can grow uncontrollably.
2. The tokens endpoint, because this resource is not protected by the authenticating filter and is invoked for every request, even unauthenticated, thus potentially growing the internal maps in `LocalPolarisMetaStoreManagerFactory`.

On the bright side, I _think_ that the internal maps would not grow uncontrollably in a ""real-life"" scenario with EclipseLink and a real database, because the realm initialization would fail on an unknown realm:

https://github.com/apache/polaris/blob/aee3a027b3e3d4e1f4365faea3e9bcff9df849df/extension/persistence/eclipselink/src/main/java/org/apache/polaris/extension/persistence/impl/eclipselink/PolarisEclipseLinkMetaStoreSessionImpl.java#L181

And that initialization would be triggered by the `DefaultCallContextResolver` that is invoked in the `PolarisApplication.ContextResolverFilter`, which is the very first filter to execute. So I believe that un unknown realm would throw an exception here:

https://github.com/apache/polaris/blob/b8446866b55e79c35c6505681c871e22f8a86634/dropwizard/service/src/main/java/org/apache/polaris/service/dropwizard/PolarisApplication.java#L510

That said, it still feels a bit fragile to attempt to create a meta store session for any realm, even unknown, even if from an unauthenticated request, only to see the attempt fail.

(Also, EclipseLink with the default `jdbc:h2:file` datasource is likely to create meta store sessions for any realm without any form of verification.)","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Yw4kw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/541,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Y0V8t,polaris,2563858221,541,NA,adutra,463876,Alexandre Dutra,,NA,2024-12-27T16:36:59Z,2024-12-27T16:36:59Z,"With #594 we have a first step into properly mitigating this issue. It makes it impossible, using the default realm resolver, to inject unknown realms into the application.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Y0V8t/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/542,https://api.github.com/repos/apache/polaris/issues/542,polaris,2736153730,542,polaris-service binary distribution doesn't start,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,CLOSED,2024-12-12T14:59:28Z,2024-12-27T16:50:00Z,"### Is this a possible security vulnerability?

- [X] This is NOT a possible security vulnerability

### Describe the bug

We have binary distributions available in `polaris-service/build/distributions` (both shadow jar or all dependencies).

Extracting a binary distribution from there (for instance using `tar zxvf polaris-service-x.x.x.tar`), we have `bin` and `lib` folders.

Trying to start Polaris there using `bin/polaris-service` fails with:

```
java.lang.ClassNotFoundException: org.apache.polaris.service.PolarisApplication
```

The `bin/polaris-service` script is not fully correct here.
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/542/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/542,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XbQ06,polaris,2540506426,542,NA,MonkeyCanCode,29619290,,,NA,2024-12-13T04:05:32Z,2024-12-13T04:05:32Z,"I am not very familiar with gradle but here is the finding:

With the script (auto generated by gradle I think), it will try to run following command:
```
java -classpath /xxx/lib/polaris-dropwizard-service-1.0.0-incubating-SNAPSHOT.jar org.apache.polaris.service.dropwizard.PolarisApplication
```

However, we don't have `lib/polaris-dropwizard-service-1.0.0-incubating-SNAPSHOT.jar`, Instead, we have `lib/polaris-dropwizard-service-1.0.0-incubating-SNAPSHOT-raw.jar`. The `raw` seems to be from `polaris-shadow-jar.gradle.kts`.

Another thing is, even if I fixed the file name above, that is still not the right command to use. Instead, here should be the right command:
```
java -classpath /xxx/lib/polaris-dropwizard-service-1.0.0-incubating-SNAPSHOT-raw.jar:/xxx/lib/* org.apache.polaris.service.dropwizard.PolarisApplication
```

Then you will see following:
```
usage: java -jar polaris-dropwizard-service-1.0.0-incubating-SNAPSHOT-raw.jar
       [-h] [-v] {server,check,bootstrap,purge} ...

positional arguments:
  {server,check,bootstrap,purge}
                         available commands

named arguments:
  -h, --help             show this help message and exit
  -v, --version          show the application version and exit

 @@@@   @@@  @       @    @@@@   @  @@@@    @@@@    @  @@@@@  @    @     @@@   @@@@
 @   @ @   @ @      @ @   @   @  @  @@     @       @ @   @   @ @   @    @   @ @
 @@@@  @   @ @     @@@@@  @@@@   @    @@   @      @@@@@  @  @@@@@  @    @   @ @  @@@
 @      @@@  @@@@ @     @ @  @@  @  @@@@    @@@@ @     @ @ @@   @@ @@@@  @@@   @@@@

                     *


                                      /////\
                                   //\\///T\\\
                                ///\\\////\\\\\\
                               //\\\\T////\\\\\\\\\
                          /T\ //\\\\\T///T\\//T\\\\\\
                        //\\\/////T\\////\\/////\\\\\\\  //\\
                     //\\\\\\T///////////////////T\\\\\\\T\\\\\
                  //\\\\/////T\//////////\///////T\\\\\T\\\\\\\\
                 //\\\\\/////\\\T////////////////\\\\\\/\\\\\\\\\
,,..,,,..,,,..,//\\\\////////\\\\\\\\\\/////////\\\\\///\\\\\\\\\\,,,..,,..,,,..,,,.
,,..,,,..,,,..,,,..,,,..,,,..,,,..,,,..,,,..,,,..,,,..,,,..,,,..,,,..,,,.,,,..,,,..,
```

Hope this can help someone who is more familiar with gradle to fix this issue.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XbQ06/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/542,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XdK-O,polaris,2541006734,542,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2024-12-13T09:43:07Z,2024-12-13T09:43:07Z,"This works, my point is that our distribution distributions (polaris-service tar or zip) don't work out of the box.

I'm fixing that.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XdK-O/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/542,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Xwc7k,polaris,2546061028,542,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2024-12-16T16:18:26Z,2024-12-16T16:18:26Z,"So, the current situation is:
* shadowJar based binary distribution works
* the ""non Uber jar"" binary distribution doesn't work because the classpath is not correct in `bin/polaris-service`: the `CLASSPATH` should contain `$APP/lib/*` (not the single Polaris service jar which is only valid for shadow jar).

Generally speaking, I don't see the reason about having two binary distributions (the shadowJar one and the ""regular"" one).

I think we should have only one binary distribution (for our end users). Maybe the non shadowJar one makes more sense because users can update some dependency in the distribution is needed (easier than exploding the shadowJar).","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Xwc7k/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/542,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Xwqtw,polaris,2546117488,542,NA,snazy,957468,Robert Stupp,,NA,2024-12-16T16:40:54Z,2024-12-16T16:40:54Z,"> Generally speaking, I don't see the reason about having two binary distributions (the shadowJar one and the ""regular"" one).

Noting: the ""shadow"" one is probably ""provided"" by the shadow plugin.

> I think we should have only one binary distribution (for our end users). Maybe the non shadowJar one makes more sense because users can update some dependency in the distribution is needed (easier than exploding the shadowJar).

I think, the issue rather goes away once we have #469 replacing dropwizard - and/or do not rely on Gradle's ""distribution"" functionality but just package our own zip/tgz with a start-script (it's really not rocket science - likely easier than ""messing"" with the specifics of `distribution`/shadow-plugin).","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Xwqtw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/542,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XxCEU,polaris,2546213140,542,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2024-12-16T17:23:28Z,2024-12-16T17:23:28Z,"@snazy I agree. Let me push a short fix with custom binary distribution. And yeah, #469 will simplify/fix all this ðŸ˜„ ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XxCEU/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/543,https://api.github.com/repos/apache/polaris/issues/543,polaris,2736244548,543,[FEATURE REQUEST] Support for creating nested namespaces recursively,Karthilearns,89193420,Karthikeyan G,,OPEN,2024-12-12T15:35:49Z,2024-12-13T22:38:13Z,"### Is your feature request related to a problem? Please describe.

Currently , Polaris doesn't support creating namespaces which do not exists recursively . for  spark.sql('create namespace n1.n2.n3') to work , n1 and n2 should already be there in place , or else the SQL would fail. 

To bring in compatibility with other catalog's SQL, would it make sense to support creating nested namespaces recursively? Or is there any reason behind not doing this?

### Describe the solution you'd like

allow users to create nested namespaces with a single SQL command,

### Describe alternatives you've considered

The only alternative we have is constructing multiple SQL queries which is difficult compared to what other catalog offers.

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/543/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/543,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XWuv2,polaris,2539318262,543,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2024-12-12T15:41:08Z,2024-12-12T15:41:08Z,"You are using Spark with the Iceberg REST client I guess right ?

So, I guess you are referencing using `foo/bar/john` namespace name, we should create the namespaces `foo`, `bar`, `john` recursively (one call), right ?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XWuv2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/543,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XWzg4,polaris,2539337784,543,NA,Karthilearns,89193420,Karthikeyan G,,NA,2024-12-12T15:49:22Z,2024-12-12T15:49:22Z,"@jbonofre yes , I'm using Spark with Polaris REST catalog. 

Yes , this should happen in one call.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XWzg4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/543,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XW4DX,polaris,2539356375,543,NA,Karthilearns,89193420,Karthikeyan G,,NA,2024-12-12T15:55:54Z,2024-12-12T15:55:54Z,"If this cannot be done or not in Polaris's scope of nested catalogs , I would like to know the reason behind. The one of reason I'm concerned about is,

Say i have my application writing iceberg tables to a REST based catalog. here with Polaris's way of handling nested namespaces , I cannot migrate my application code to an another rest catalog implementation.  The migration use case of iceberg catalogs actually fails here.

","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XW4DX/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/543,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Xa9BC,polaris,2540425282,543,NA,Karthilearns,89193420,Karthikeyan G,,NA,2024-12-13T02:54:57Z,2024-12-13T02:54:57Z,@jbonofre - im happy to contribute a PR incase of feature approval.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Xa9BC/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/543,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XbUxT,polaris,2540522579,543,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-12-13T04:23:36Z,2024-12-13T04:23:36Z,"Hi @Karthilearns, would you mind sharing the error message?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XbUxT/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/543,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XbeFh,polaris,2540560737,543,NA,Karthilearns,89193420,Karthikeyan G,,NA,2024-12-13T05:07:03Z,2024-12-13T05:07:03Z,"Hi @flyrain , 

` session.sql(""use quickstart_catalog"");
   session.sql(""show namespaces"").show();
   session.sql(""create namespace toplevel.second"");`
        
 
Error : 

` Exception in thread ""main"" org.apache.iceberg.exceptions.NoSuchNamespaceException: Namespace does not exist: toplevel
	at org.apache.iceberg.rest.ErrorHandlers$NamespaceErrorHandler.accept(ErrorHandlers.java:173)
	at org.apache.iceberg.rest.ErrorHandlers$NamespaceErrorHandler.accept(ErrorHandlers.java:166)
	at org.apache.iceberg.rest.HTTPClient.throwFailure(HTTPClient.java:211)
	at org.apache.iceberg.rest.HTTPClient.execute(HTTPClient.java:323)
	at org.apache.iceberg.rest.HTTPClient.execute(HTTPClient.java:262)
	at org.apache.iceberg.rest.HTTPClient.post(HTTPClient.java:368)
	at org.apache.iceberg.rest.RESTClient.post(RESTClient.java:112)
	at org.apache.iceberg.rest.RESTSessionCatalog.createNamespace(RESTSessionCatalog.java:538)
	at org.apache.iceberg.catalog.BaseSessionCatalog$AsCatalog.createNamespace(BaseSessionCatalog.java:128)
	at org.apache.iceberg.rest.RESTCatalog.createNamespace(RESTCatalog.java:223)
	at org.apache.iceberg.spark.SparkCatalog.createNamespace(SparkCatalog.java:482)
	at org.apache.spark.sql.execution.datasources.v2.CreateNamespaceExec.run(CreateNamespaceExec.scala:47)
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)
	at org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)
	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
	at org.apache.spark.sql.SparkSession.$anonfun$sql$4(SparkSession.scala:691)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:682)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:713)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:744)
	at com.striim.PolarisCatalog.main(PolarisCatalog.java:17) `       
        ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XbeFh/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/543,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Xi3cT,polaris,2542499603,543,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-12-13T22:38:12Z,2024-12-13T22:38:12Z,"It failed at when Polaris is trying to check the parent namespace's privilege, https://github.com/polaris-catalog/polaris/blob/main/service/common/src/main/java/org/apache/polaris/service/catalog/PolarisCatalogHandlerWrapper.java#L248-L248. 

Basically, the behavior you want here is to create the parent namespace if it doesn't exist, then create the sub namespace. If Polaris allows this behavior, it actually breaks the assumption that one REST API call only creates one namespace. Checking this spec for details, https://github.com/polaris-catalog/polaris/blob/main/spec/rest-catalog-open-api.yaml#L4080-L4080. I think it's more suitable as a client side change, like this pseudo code shows:
```
# create namespace n1.n2
if( n1 not exists) {
   create n1
   create n2
} else {
   create n2
}
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Xi3cT/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/544,https://api.github.com/repos/apache/polaris/issues/544,polaris,2736571753,544,[BUG] Assumption that cache eviction does not happen,snazy,957468,Robert Stupp,,OPEN,2024-12-12T18:04:07Z,2024-12-12T18:07:43Z,"From #465: ""The existing code assumes that all of the entities are in the cache once the Resolver runs. That process puts all of the entities and their grants into the cache so that by the time the Authorizer retrieves the grants, it fetches them from the cache.""

It sounds like that the code really relies on the entities being available from the cache, which means that no eviction must happen. If eviction happens (which must be assumed to happen at any point in time to any cache entry) requests can fail at any time w/ misleading errors and/or wrong information.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/544/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/544,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XYJyq,polaris,2539691178,544,NA,collado-mike,40346148,Michael Collado,,NA,2024-12-12T18:07:41Z,2024-12-12T18:07:41Z,"At least in the linked PR, all cache lookups invoke `entityCache.getOrLoadEntityById` - this will validate that the cache entry is present and do the lookup if it is not. The ""assumption"" mentioned is on the performance characteristics, not the correctness of the code.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XYJyq/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/550,https://api.github.com/repos/apache/polaris/issues/550,polaris,2739287438,550,Support for GCP service account impersonation,collado-mike,40346148,Michael Collado,,OPEN,2024-12-13T22:13:21Z,2024-12-19T23:48:08Z,"### Is your feature request related to a problem? Please describe.

GCP supports [service account impersonation](https://cloud.google.com/iam/docs/service-account-impersonation), so that given credentials for a service account, it's possible to impersonate a different service account, given that the first is granted privileges to do so. The `GcpStorageConfigurationInfo` catalog configuration [here](https://github.com/apache/polaris/blob/main/polaris-core/src/main/java/org/apache/polaris/core/storage/gcp/GcpStorageConfigurationInfo.java#L39-L40) actually has a `gcpServiceAccount` field that we never use when vending GCS storage credentials. We can use the code in https://cloud.google.com/iam/docs/create-short-lived-credentials-direct#create-access to assume the target service account, then generate a short-lived token that has the target service account's privileges subscoped to the table location during the credential vending process.

### Describe the solution you'd like

_No response_

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/550/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/552,https://api.github.com/repos/apache/polaris/issues/552,polaris,2739799183,552,Make Polaris safe against certain unparseable locations,snazy,957468,Robert Stupp,,OPEN,2024-12-14T11:48:36Z,2024-12-14T11:48:48Z,"Using `java.net.URI` for paths/locations generated/used by Apache Iceberg is particularly unsafe.

Characters that are illegal in URI string representations are not escaped by Iceberg and lead to runtime exceptions when parsed for example by `java.net.URI.create(String)`.

Example: A legit column/partition-field name `""_foo_bar_""` will end ""as is"" in any path generated by Iceberg, leading to ` Caused by: java.lang.IllegalArgumentException: Illegal character in path at index ...`.

The safest approach to prevent this issue entirely is to have a dedicated class that deals with ""unsafe encodings"", maybe call it ""StorageUri"".

Mixing ""unsafe"" and ""safe"" encodings will cause errors.
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/552/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/553,https://api.github.com/repos/apache/polaris/issues/553,polaris,2739814399,553,"Use ""genuine"" Iceberg REST spec",snazy,957468,Robert Stupp,,CLOSED,2024-12-14T12:18:01Z,2025-02-04T00:06:40Z,"### Describe the bug

`spec/rest-catalog-open-api.yaml` is a modified/customized version of the ""genuine"" Iceberg REST spec. It can cause issues when the Iceberg REST spec introduces incompatible component names, endpoint paths, etc.

It would be cleaner to move Polaris specific changes elsewhere and leave the ""genuine"" Iceberg REST spec untouched.

It would also be cleaner to _reference_ a specific & well-known version of the Iceberg REST spec instead of copying it.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/553/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/554,https://api.github.com/repos/apache/polaris/issues/554,polaris,2739817005,554,Back/forwards compatible privileges,snazy,957468,Robert Stupp,,OPEN,2024-12-14T12:23:47Z,2024-12-14T12:23:54Z,"### Describe the bug

`polaris-management-service.yml` defines all privileges as enum (values). This approach gets in the way when new privileges are added (client & server are built from different versions of `polaris-management-service.yml`).

The enum-approach is also not going to work with the short/mid-term goal to have ""pluggable authZ"" in Polaris, where authZ implementations can define their own privileges.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/554/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/555,https://api.github.com/repos/apache/polaris/issues/555,polaris,2739823082,555,"Replace ""property bags"" in `polaris-management-service.yml` with specific attributes",snazy,957468,Robert Stupp,,OPEN,2024-12-14T12:31:39Z,2025-01-22T22:43:39Z,"### Describe the bug

Most components in `polaris-management-service.yml` only have a generic property bag, but the valid keys/values are neither defined nor described anywhere.

Property bags are rather error-prone and can be accidentally/intentionally misused in many ways. A public facing API should define all attributes as specific properties with the correct types, including validation rules, descriptions and examples.
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/555/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/555,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ayjYY,polaris,2596943384,555,NA,collado-mike,40346148,Michael Collado,,NA,2025-01-16T21:38:32Z,2025-01-16T21:38:32Z,"There's a liberal use of the ""bug"" label for things that are personal preferences or, at best, generally good guidelines. We should stop using ""bug"" for things that aren't actually broken.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ayjYY/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/555,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a08Af,polaris,2597568543,555,NA,snazy,957468,Robert Stupp,,NA,2025-01-17T07:03:44Z,2025-01-17T07:03:44Z,"We can argue here whether it's an improvement or a bug. However, I definitely tend towards this being a bug, because the use of these property bags makes it extremely hard to distinguish which properties can be updated, whether changes are valid/authorized - a proper type model makes the meaning of the attributes clear for users and implementations.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a08Af/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/555,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a1Jjx,polaris,2597624049,555,NA,collado-mike,40346148,Michael Collado,,NA,2025-01-17T07:46:27Z,2025-01-17T07:46:27Z,"By that logic, any software written in an untyped language would be considered a bug. 
I like types. I think more specific types are good. 

I also think extension points are necessary and it's hard to account for all possible property types. An explicit choice about where to add extension points isn't a bug. It's certainly open for debate. I'm happy to collaborate on improvement proposals. But it's not a bug","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a1Jjx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/555,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a1KqW,polaris,2597628566,555,NA,snazy,957468,Robert Stupp,,NA,2025-01-17T07:49:46Z,2025-01-17T07:49:46Z,"That's good to hear. I'm not opposed of having extension points. But the fundamental and well defined things should really be typed components.

(Unrelated PS: I'm definitely not a fan of untyped languages - type related hidden and hard to detect bugs are a natural consequence of these langauges)","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a1KqW/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/555,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a5lOT,polaris,2598785939,555,NA,collado-mike,40346148,Michael Collado,,NA,2025-01-17T16:55:49Z,2025-01-17T16:55:49Z,"> (Unrelated PS: I'm definitely not a fan of untyped languages - type related hidden and hard to detect bugs are a natural consequence of these langauges)

I'm generally in agreement, but it's what I consider a ""religious"" discussion. I don't try to convert Baptists into Methodists and I generally stay away from ""typed vs untyped"" discussions. I care more about software quality and delivering value to users than I do about whether bugs are caught by the compiler or the tests.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a5lOT/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/555,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a5oNP,polaris,2598798159,555,NA,snazy,957468,Robert Stupp,,NA,2025-01-17T17:02:39Z,2025-01-17T17:02:39Z,"> I care more about software quality and delivering value

That's exactly the point of this issue. I think we're in agreement that proper typing is a big step towards better software quality.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a5oNP/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/555,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a6zyN,polaris,2599107725,555,NA,dimas-b,40603221,Dmitri Bourlatchkov,,NA,2025-01-17T20:05:39Z,2025-01-17T20:05:39Z,"From my POV this is not about java classes as types per se, but about using well-defined forms of configuration. Untyped languages can support that too (also, one can write object-oriented code in C ;) )

This is the point I also brought in https://github.com/apache/polaris/pull/724#discussion_r1920668019","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a6zyN/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/555,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bNKxu,polaris,2603920494,555,NA,dennishuo,7410123,Dennis Huo,,NA,2025-01-21T08:11:22Z,2025-01-21T08:11:22Z,"Yeah I hate untyped languages as well. My understanding is that generally the `properties` fields are all defined in Polaris entities simply for consistency to mirror the Iceberg REST entities defined in the core Iceberg REST spec. So the question would be whether we want the entity model to diverge from Iceberg.

All the `internalProperties` contained within the Polaris persistence layer are precisely funneled through Java wrappers like `CatalogEntity`, `PrincipalEntity`, etc., precisely to enforce typed attributes.

Is this suggestion in this issue to simply get rid of `properties`? As far as I recall there's only one case where there's a member of `properties` that is partially implicit, which I agree leads to some confusing parsing logic -- the `default-base-location` in `Catalog` is portrayed as a required string key in `properties`, whereas the look-and-feel of all other attributes would've made it fit better alongside e.g. `type` and `storageConfigInfo` as top-level attributes in the REST API model (and as a consequence, reside in `internalProperties` and be unpacked through `CatalogEntity` instead of residing in the public `properties` map).","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bNKxu/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/555,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6beVHD,polaris,2608419267,555,NA,collado-mike,40346148,Michael Collado,,NA,2025-01-22T22:43:38Z,2025-01-22T22:43:38Z,"I don't think we can get rid of the `properties` field, given that Iceberg uses it liberally. `internalProperties` is up for debate, though it needs to continue to be extensible - e.g., federated authn may need to set key/value pairs on the `PrincipalEntity` where neither the keys nor values are known by the Polaris project.

I removed the `bug` label, as while the goal is to ""improve software quality"", there is no active bug reported in this issue.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6beVHD/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/556,https://api.github.com/repos/apache/polaris/issues/556,polaris,2739831829,556,Remove `entityVersion` from public APIs,snazy,957468,Robert Stupp,,OPEN,2024-12-14T12:38:53Z,2024-12-14T12:39:00Z,"### Describe the bug

`polaris-management-service.yml` uses a simple `entityVersion` approach to validate whether some update request, which includes the _full_ representation of the entity to be updated, can be performed or not.

The approach to be able to update a whole entity should be replaced with specific update operations per entity type. This is much easier to validate in service implementations and easier to understand from a client's point of view.
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/556/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/557,https://api.github.com/repos/apache/polaris/issues/557,polaris,2739900810,557,Add NOTICE + LICENSE* as static resources to distributables,snazy,957468,Robert Stupp,,CLOSED,2024-12-14T14:10:09Z,2024-12-19T20:25:57Z,"### Describe the bug

The `NOTICE` + `LICENSE*` files should be included in executable artifacts of distributions, so the contents of these files can be
* printed to the console in CLI applications
* returned as static web resources

I.e. those resources need to be _programmatically accessible_.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/557/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/557,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XlQh4,polaris,2543126648,557,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2024-12-14T14:15:37Z,2024-12-14T14:15:37Z,Not the LICENSE from source distribution. It's already done in my PR,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XlQh4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/557,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XtzW1,polaris,2545366453,557,NA,snazy,957468,Robert Stupp,,NA,2024-12-16T11:28:57Z,2024-12-16T11:28:57Z,"Maybe I wasn't clear in the description, but this issue is about having those resources available _programmatically_ and as static web resources, while #495 just adds these files to the zip/tar/etc","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XtzW1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/557,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XulA-,polaris,2545569854,557,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2024-12-16T12:58:49Z,2024-12-16T12:58:49Z,Ahh git it. I thought you mean adding the files in the archive. It makes sense. ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XulA-/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/560,https://api.github.com/repos/apache/polaris/issues/560,polaris,2740639523,560,Bootstrapped status not properly handled,snazy,957468,Robert Stupp,,CLOSED,2024-12-15T13:20:47Z,2024-12-19T13:06:02Z,"### Describe the bug

The ""bootstrapped"" status is incorrectly assumed to be true after a single request, despite asking to run `bootstrap`.

Repro:
1. Add necessary dependencies to `polaris-dropwizard-service`
  ```
  runtimeOnly(project("":polaris-eclipselink""))
  runtimeOnly(libs.h2)
  runtimeOnly(libs.postgresql)
  ```
2. Starting Polaris w/ eclipselink... using `./gradlew :polaris-dropwizard-service:runApp`
3. `curl http://127.0.0.1:8181/api/catalog/v1/config` --> HTTP/500 / ""Error 500 java.lang.IllegalStateException: Realm is not bootstrapped, please run server in bootstrap mode."" --> OK
4. Another `curl http://127.0.0.1:8181/api/catalog/v1/config` --> HTTP/401 Unauthorized


### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/560/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/560,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YAL5y,polaris,2550185586,560,NA,MonkeyCanCode,29619290,,,NA,2024-12-18T02:40:55Z,2024-12-18T02:40:55Z,@snazy here is the fix for this one as well as root cause analysis: https://github.com/apache/polaris/pull/579,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YAL5y/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/560,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YI6h0,polaris,2552473716,560,NA,dimas-b,40603221,Dmitri Bourlatchkov,,NA,2024-12-18T23:44:00Z,2024-12-18T23:44:00Z,"I was not able to reproduce it with current master (5761b53423a5e9f23b10c3d3d2bd03602e07890e) when running from the jar.

```
java -jar dropwizard/service/build/libs/polaris-dropwizard-service-1.0.0-incubating-SNAPSHOT.jar server ./polaris-server.yml
```

I get 500 all the time... Caused by: `jakarta.persistence.PersistenceException: java.util.ServiceConfigurationError: java.net.spi.InetAddressResolverProvider: Provider org.xbill.DNS.spi.DnsjavaInetAddressResolverProvider not found`","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YI6h0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/560,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YJFZ8,polaris,2552518268,560,NA,dimas-b,40603221,Dmitri Bourlatchkov,,NA,2024-12-19T00:22:05Z,2024-12-19T00:22:05Z,I was able to reproduce with #581,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YJFZ8/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/560,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YOMjC,polaris,2553858242,560,NA,adutra,463876,Alexandre Dutra,,NA,2024-12-19T13:06:02Z,2024-12-19T13:06:02Z,Fixed by #579.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YOMjC/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/561,https://api.github.com/repos/apache/polaris/issues/561,polaris,2740642199,561,Polaris not starting up / `TaskHandlerConfiguration` not JSON-serializable,snazy,957468,Robert Stupp,,CLOSED,2024-12-15T13:26:51Z,2025-01-15T09:00:23Z,"### Describe the bug

Polaris startup fails with

```
java.lang.IllegalArgumentException: Unable to create an instance of the configuration class: 'org.apache.polaris.service.dropwizard.config.PolarisApplicationConfig'
        at io.dropwizard.configuration.BaseConfigurationFactory.build(BaseConfigurationFactory.java:125)
        at io.dropwizard.core.cli.ConfiguredCommand.parseConfiguration(ConfiguredCommand.java:141)
        at io.dropwizard.core.cli.ConfiguredCommand.run(ConfiguredCommand.java:85)
        at io.dropwizard.core.cli.Cli.run(Cli.java:78)
        at io.dropwizard.core.Application.run(Application.java:94)
        at org.apache.polaris.service.dropwizard.PolarisApplication.main(PolarisApplication.java:153)
Caused by: java.lang.IllegalArgumentException: No serializer found for class org.apache.polaris.service.config.TaskHandlerConfiguration and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationFeature.FAIL_ON_EMPTY_BEANS) (through reference chain: org.apache.polaris.service.dropwizard.config.PolarisApplicationConfig[""taskHandler""])
        at com.fasterxml.jackson.databind.ObjectMapper.valueToTree(ObjectMapper.java:3614)
        at io.dropwizard.configuration.BaseConfigurationFactory.build(BaseConfigurationFactory.java:120)
        ... 5 more
Caused by: com.fasterxml.jackson.databind.exc.InvalidDefinitionException: No serializer found for class org.apache.polaris.service.config.TaskHandlerConfiguration and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationFeature.FAIL_ON_EMPTY_BEANS) (through reference chain: org.apache.polaris.service.dropwizard.config.PolarisApplicationConfig[""taskHandler""])
        at com.fasterxml.jackson.databind.exc.InvalidDefinitionException.from(InvalidDefinitionException.java:77)
        at com.fasterxml.jackson.databind.SerializerProvider.reportBadDefinition(SerializerProvider.java:1328)
        at com.fasterxml.jackson.databind.DatabindContext.reportBadDefinition(DatabindContext.java:414)
        at com.fasterxml.jackson.databind.ser.impl.UnknownSerializer.failForEmpty(UnknownSerializer.java:53)
        at com.fasterxml.jackson.databind.ser.impl.UnknownSerializer.serialize(UnknownSerializer.java:30)
        at com.fasterxml.jackson.module.blackbird.ser.ObjectPropertyWriter.serializeAsField(ObjectPropertyWriter.java:97)
        at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:770)
        at com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:184)
        at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider._serialize(DefaultSerializerProvider.java:502)
        at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:341)
        at com.fasterxml.jackson.databind.ObjectMapper.valueToTree(ObjectMapper.java:3609)
        ... 6 more
```


### To Reproduce

`./gradlew :polaris-dropwizard-service:runApp --args bootstrap`
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/561/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/561,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XobCx,polaris,2543956145,561,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2024-12-15T17:22:09Z,2024-12-15T17:22:09Z,It's a duplicated from #542 that gathers binary distribution startup issues.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XobCx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/561,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XsMA4,polaris,2544943160,561,NA,snazy,957468,Robert Stupp,,NA,2024-12-16T08:42:44Z,2024-12-16T08:42:44Z,"This is different from #542, right?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XsMA4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/561,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XsNRv,polaris,2544948335,561,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2024-12-16T08:44:38Z,2024-12-16T08:44:38Z,"Yes and no: #542 is about to gather all related startup issues, including this one.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XsNRv/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/561,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XsTRB,polaris,2544972865,561,NA,snazy,957468,Robert Stupp,,NA,2024-12-16T08:54:40Z,2024-12-16T08:54:40Z,"Still, different technical issues","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XsTRB/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/561,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XsZC1,polaris,2544996533,561,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2024-12-16T09:05:14Z,2024-12-16T09:05:14Z,"No problem if you want to reopen, but I kindly ask to update the title to describe the actual issue.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XsZC1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/561,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YSdl4,polaris,2554976632,561,NA,dimas-b,40603221,Dmitri Bourlatchkov,,NA,2024-12-19T16:35:15Z,2024-12-19T16:35:15Z,"This is a peculiarity of YAML config parsing in DW. It works fine if the config file is specified.

```
./gradlew :polaris-dropwizard-service:runApp --args ""bootstrap ../../polaris-server.yml""
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YSdl4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/561,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Yz6Nc,polaris,2563744604,561,NA,adutra,463876,Alexandre Dutra,,NA,2024-12-27T14:17:19Z,2024-12-27T14:17:19Z,"@dimas-b is right: this issue but also #580, #560, #561, #562, only happen when no config file is specified. I think it's mandatory to provide one, only the scripts do not print a clear message saying that the config file wasn't specified.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Yz6Nc/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/561,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Y0NgP,polaris,2563823631,561,NA,adutra,463876,Alexandre Dutra,,NA,2024-12-27T15:53:36Z,2024-12-27T15:53:36Z,I think we should not consider the above mentioned issues as release blockers.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Y0NgP/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/561,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6afs_k,polaris,2592002020,561,NA,snazy,957468,Robert Stupp,,NA,2025-01-15T09:00:22Z,2025-01-15T09:00:22Z,Fixed via #469 ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6afs_k/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/562,https://api.github.com/repos/apache/polaris/issues/562,polaris,2742173152,562,Configuration handling & implementation is racy,snazy,957468,Robert Stupp,,CLOSED,2024-12-16T11:53:15Z,2025-01-07T10:24:13Z,"### Describe the bug

Polaris currently uses Dropwizard and relies on Jackson for configuration, but also ties initialization/setup/business logic into configuration objects.

For example in `PolarisApplicationConfig` there are:
```java
  @JsonProperty(""realmContextResolver"")
  @JsonTypeInfo(use = JsonTypeInfo.Id.NAME, include = JsonTypeInfo.As.PROPERTY, property = ""type"")
  public void setRealmContextResolver(RealmContextResolver realmContextResolver) {
    this.realmContextResolver = realmContextResolver;
  }

  @JsonProperty(""defaultRealm"")
  public void setDefaultRealm(String defaultRealm) {
    this.defaultRealm = defaultRealm;
    realmContextResolver.setDefaultRealm(defaultRealm);
  }
```

These code constructs are racy/error-prone, because literally nothing guarantees that `realmContextResolver` is set to `!= null` when `setDefaultRealm()` is invoked.
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/562/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/562,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XuAtQ,polaris,2545421136,562,NA,snazy,957468,Robert Stupp,,NA,2024-12-16T11:53:59Z,2024-12-16T11:53:59Z,"Example stack trace:
```
io.dropwizard.configuration.ConfigurationParsingException: default configuration has an error:
  * Failed to parse configuration at: defaultRealm; Cannot invoke ""org.apache.polaris.service.context.RealmContextResolver.setDefaultRealm(String)"" because ""this.realmContextResolver"" is null (through reference chain: org.apache.polaris.service.dropwizard.config.PolarisApplicationConfig[""defaultRealm""])

	at io.dropwizard.configuration.ConfigurationParsingException$Builder.build(ConfigurationParsingException.java:277)
	at io.dropwizard.configuration.BaseConfigurationFactory.build(BaseConfigurationFactory.java:177)
	at io.dropwizard.configuration.BaseConfigurationFactory.build(BaseConfigurationFactory.java:121)
	at io.dropwizard.core.cli.ConfiguredCommand.parseConfiguration(ConfiguredCommand.java:141)
	at io.dropwizard.core.cli.ConfiguredCommand.run(ConfiguredCommand.java:85)
	at io.dropwizard.core.cli.Cli.run(Cli.java:78)
	at io.dropwizard.core.Application.run(Application.java:94)
	at org.apache.polaris.service.dropwizard.PolarisApplication.main(PolarisApplication.java:153)
Caused by: com.fasterxml.jackson.databind.JsonMappingException: Cannot invoke ""org.apache.polaris.service.context.RealmContextResolver.setDefaultRealm(String)"" because ""this.realmContextResolver"" is null (through reference chain: org.apache.polaris.service.dropwizard.config.PolarisApplicationConfig[""defaultRealm""])
	at com.fasterxml.jackson.databind.JsonMappingException.wrapWithPath(JsonMappingException.java:402)
	at com.fasterxml.jackson.databind.JsonMappingException.wrapWithPath(JsonMappingException.java:361)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.wrapAndThrow(BeanDeserializerBase.java:1964)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:275)
	at com.fasterxml.jackson.module.blackbird.deser.SuperSonicBeanDeserializer.deserialize(SuperSonicBeanDeserializer.java:155)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:342)
	at com.fasterxml.jackson.databind.ObjectMapper._readValue(ObjectMapper.java:4893)
	at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3036)
	at io.dropwizard.configuration.BaseConfigurationFactory.build(BaseConfigurationFactory.java:148)
	... 6 more
Caused by: java.lang.NullPointerException: Cannot invoke ""org.apache.polaris.service.context.RealmContextResolver.setDefaultRealm(String)"" because ""this.realmContextResolver"" is null
	at org.apache.polaris.service.dropwizard.config.PolarisApplicationConfig.setDefaultRealm(PolarisApplicationConfig.java:307)
	at com.fasterxml.jackson.module.blackbird.deser.SettableStringProperty.set(SettableStringProperty.java:56)
	at com.fasterxml.jackson.module.blackbird.deser.SettableStringProperty.deserializeAndSet(SettableStringProperty.java:41)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:273)
	... 11 more
```
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6XuAtQ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/563,https://api.github.com/repos/apache/polaris/issues/563,polaris,2742205706,563,"Resources not properly closed, resource & memory leaks",snazy,957468,Robert Stupp,,OPEN,2024-12-16T12:06:09Z,2024-12-16T12:06:18Z,"### Describe the bug

Handling of closeable resources is not implemented in a couple of places in the Polaris code base. This leads to thread leaks and potentially other system resource leaks.

None of the resources held by ""storage integrations"" are ever closed.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/563/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/564,https://api.github.com/repos/apache/polaris/issues/564,polaris,2742225084,564,Overly expensive resource utilization via object-storage (and related) clients,snazy,957468,Robert Stupp,,OPEN,2024-12-16T12:14:44Z,2024-12-16T12:14:52Z,"### Describe the bug

Instances of object-storage (e.g. `S3Client`) and credential-vending clients (e.g. `StsClient`) are ""fully"" created for every client request. This means, that also implicit resources like HTTP connection pools and thread pools are created for every client request. This is too expensive.

Related to #563 
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/564/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/565,https://api.github.com/repos/apache/polaris/issues/565,polaris,2742245584,565,Dropwizard/HK2 service implementation doesn't bootstrap,snazy,957468,Robert Stupp,,CLOSED,2024-12-16T12:22:31Z,2025-01-15T08:59:03Z,"### Describe the bug

After tentatively fixing #561 + the mentioned example in #562, another startup/bootstrap blocker occurs running `bootstrap`:
```
java.lang.NullPointerException: Cannot invoke ""org.glassfish.hk2.api.ServiceLocator.getService(java.lang.Class, java.lang.annotation.Annotation[])"" because ""this.serviceLocator"" is null
        at org.apache.polaris.service.dropwizard.config.PolarisApplicationConfig.findService(PolarisApplicationConfig.java:184)
	at org.apache.polaris.service.dropwizard.BootstrapRealmsCommand.run(BootstrapRealmsCommand.java:50)
	at org.apache.polaris.service.dropwizard.BootstrapRealmsCommand.run(BootstrapRealmsCommand.java:37)
	at io.dropwizard.core.cli.ConfiguredCommand.run(ConfiguredCommand.java:98)
	at io.dropwizard.core.cli.Cli.run(Cli.java:78)
	at io.dropwizard.core.Application.run(Application.java:94)
	at org.apache.polaris.service.dropwizard.PolarisApplication.main(PolarisApplication.java:153)
```


### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/565/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/565,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6afsGf,polaris,2591998367,565,NA,snazy,957468,Robert Stupp,,NA,2025-01-15T08:59:02Z,2025-01-15T08:59:02Z,Superseded by #469 ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6afsGf/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/568,https://api.github.com/repos/apache/polaris/issues/568,polaris,2742921195,568,Immutable value objects,snazy,957468,Robert Stupp,,CLOSED,2024-12-16T17:00:32Z,2025-01-15T08:58:41Z,"### Describe the bug

Basically all object types in Polaris have mutable attributes, either directly (via setters) or indirectly (via collections). This is known to be prone to programming issues. All value types should really be immutable types - none of the elements of a value type should be mutable. Libraries like [immutable](https://immutables.github.io/) are built to support this.

[immutable](https://immutables.github.io/) is superior to both Java records and Lombok. While the direct attributes of Java records are not changeable, the objects (collections!) referenced from Java records are not enforced to be immutable. Lombok provides similar functionality than immutables, but adds bytecode (and functions/methods) that is not present in the source code, which makes for example debugging harder.
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/568/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/568,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6afr7c,polaris,2591997660,568,NA,snazy,957468,Robert Stupp,,NA,2025-01-15T08:58:40Z,2025-01-15T08:58:40Z,Fixed via #740 ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6afr7c/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/569,https://api.github.com/repos/apache/polaris/issues/569,polaris,2743738430,569,Add Support for Proxy Settings to Connect to Snowflake Open Catalog Using Spark Connector in Java,sfc-gh-hdogra,118246622,Himanshu Dogra,,CLOSED,2024-12-17T01:39:04Z,2024-12-17T12:18:18Z,"### Is your feature request related to a problem? Please describe.

The customer requested it for the following use case-

**Description:**

> Customers need the ability to configure proxy settings when connecting to Snowflake Open Catalog via the Spark Connector in Java. This is especially critical for organizations where network access to SaaS services (like Snowflake Open Catalog) is restricted and must go through a corporate proxy.
> 
> Currently, proxy configuration is supported for connecting to Snowflake accounts via the Snowflake Spark Connector, as documented here:
> [Proxy Options for Snowflake Spark Connector](https://docs.snowflake.com/en/user-guide/spark-connector-use#proxy-options).
> 
> However, similar proxy configuration options are not available when connecting to Snowflake Open Catalog. Attempts to use standard Spark configurations like spark.driver.extraJavaOptions to set proxy details have not been successful.

**Requested Enhancement:**

> Provide a way to configure proxy details when connecting to Snowflake Open Catalog using Spark in Java, similar to how proxy settings are specified for the Snowflake Spark Connector.

### Describe the solution you'd like

_No response_

### Describe alternatives you've considered

_No response_

### Additional context

As requested by the engineering team, raising this FR for the issue.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/569/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/569,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6X5Bgd,polaris,2548307997,569,NA,snazy,957468,Robert Stupp,,NA,2024-12-17T12:18:17Z,2024-12-17T12:18:17Z,"@sfc-gh-hdogra This is the issue tracker for Apache Polaris, not for Snowflake's service offering, so closing this issue. This is not the right place for requests targeting closed source commercial offerings.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6X5Bgd/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/572,https://api.github.com/repos/apache/polaris/issues/572,polaris,2744067846,572,Add UI in Polaris,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,OPEN,2024-12-17T06:43:01Z,2024-12-18T09:32:17Z,"Apache Polaris can provide a UI (in addition of the swagger one) providing:
- swagger/REST API documentation
- browse namespaces/tables/views (entities), with option to manage entities (create, remove, ...)
- display TMS policies
- display external catalogs (federation)
- browse internal catalogs (with bridge between internal catalogs)
- later, we can imagine to add new views in the UI (like OpenLineage, RBAC management, ...)","{""url"": ""https://api.github.com/repos/apache/polaris/issues/572/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/572,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6X2amW,polaris,2547624342,572,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2024-12-17T06:44:04Z,2024-12-17T06:44:04Z,I will provide a quick mockup and proposal document to illustrate this.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6X2amW/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/572,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YB4Pd,polaris,2550629341,572,NA,snazy,957468,Robert Stupp,,NA,2024-12-18T08:10:30Z,2024-12-18T08:10:30Z,We need a UI/JS guru :),"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YB4Pd/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/572,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YCoWl,polaris,2550826405,572,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2024-12-18T09:32:15Z,2024-12-18T09:32:15Z,Hopefully we can have contributions here ðŸ˜„ ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YCoWl/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/577,https://api.github.com/repos/apache/polaris/issues/577,polaris,2746372593,577,Amazon S3 Tables Integration,flyrain,1322359,Yufei Gu,yufei@apache.org,OPEN,2024-12-17T23:58:15Z,2025-01-22T17:55:06Z,"Polaris is designed to act as a **REST facade for S3 tables**, enabling both **read** and **write** operations by interacting with the S3 table API. Polaris registers an S3 table using its **metadata location**. A flag will be needed to label the new Iceberg table is a s3 table. Below is a summary of the proposed approach:
### **Read Path**  
- The **LoadTable** endpoint in Polaris will call the S3 table API [`get_table_metadata_location`](https://docs.aws.amazon.com/AmazonS3/latest/API/API_s3TableBuckets_GetTableMetadataLocation.html) to fetch the `metadata.json` file.  
- Polaris will then **serialize** the content of the `metadata.json` into a **LoadTableResponse** to return to the client.

### **Write Path**  
When the table is updated, Polaris will:  
1. Gather the changes and generate a new `metadata.json`.  
2. Use the S3 table API [`update-table-metadata-location`](https://docs.aws.amazon.com/cli/latest/reference/s3tables/update-table-metadata-location.html) to commit the new metadata.  

### **AuthZ/AuthN**
We need to ensure that the AWS role used for creating the Polaris catalog has the read and write privileges of the s3 table.


### Describe alternatives you've considered

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/577/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/577,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YFdIM,polaris,2551566860,577,NA,puchengy,8072956,Pucheng Yang,,NA,2024-12-18T15:07:01Z,2024-12-18T15:07:01Z,"@flyrain Thank you for starting the issue, I have two questions:
1. is it right that with this integration, users will continue to have the option to own the metastore service (that holds source of the truth data)?
2. should it be a concern if ""update-table-metadata-location"" fail and cause table metadata out of the sync, which could mislead S3 Tables to clean up missing metadata data (and its data files) as orphan files?

BTW, the link of [get_table_metadata_location](https://docs.aws.amazon.com/cli/latest/reference/athena/get-table-metadata.html) seems wrong? and it should be from S3 Tables API doc.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YFdIM/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/577,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YGqgG,polaris,2551883782,577,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-12-18T17:21:48Z,2024-12-18T17:21:48Z,"> is it right that with this integration, users will continue to have the option to own the metastore service (that holds source of the truth data)?

That's right. This integration won't change the source of truth(s3 table in this case), and other tools or pipelines against the source catalog should still work as is.

> should it be a concern if ""update-table-metadata-location"" fail and cause table metadata out of the sync, which could mislead S3 Tables to clean up missing metadata data (and its data files) as orphan files?

Polaris client will get the failure message in that case, then it can retry or just fail itself. The table is still consistent. But the failure may leave orphan files, which is fine as the other clients also leave orphan files in case of failure. 

Thanks for pointing out the wrong link. Updated.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YGqgG/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/577,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YGuz0,polaris,2551901428,577,NA,puchengy,8072956,Pucheng Yang,,NA,2024-12-18T17:31:07Z,2024-12-18T17:31:07Z,"@flyrain 

> Polaris client will get the failure message in that case, then it can retry or just fail itself. The table is still consistent.

Do you mean that ""update-table-metadata-location"" will be part of the commit to the source catalog (e.g. HMS)?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YGuz0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/577,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YG1px,polaris,2551929457,577,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-12-18T17:46:34Z,2024-12-18T17:46:34Z,"Yes, you could consider Polaris as a proxy when the source of truth is a remote catalog.  Here are two different commit paths depends on different client types:
```
# REST clients commit path
REST client ->  Polaris -> Remote catalog(e.g. HMS, S3 table)

# Other clients commit path
Non-REST clients ->  Remote catalog(e.g. HMS, S3 table)
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YG1px/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/577,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YG3oP,polaris,2551937551,577,NA,puchengy,8072956,Pucheng Yang,,NA,2024-12-18T17:51:02Z,2024-12-18T17:51:02Z,"@flyrain Got it, so in this proposal, HMS and S3 Tables are mutually exclusive? 

Sorry for being unclear, the reason I asked the original question is to see if it is possible to operate HMS and S3 Tables at the same time, and use HMS as the source of the truth (because we want to keep our source of the truth data in HMS) but leverage some of S3 Tables additional features.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YG3oP/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/577,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YG_Ba,polaris,2551967834,577,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-12-18T18:07:58Z,2024-12-18T18:07:58Z,"Yes. They are mutually exclusive. I think it's better to only have one source of truth. In case of s3 tables, s3 service is the source of the truth for sure. An integration of HMS would be like:
```
HMS clients ->  HMS -> S3 table
```
HMS will have to invoke the s3 api `update-table-metadata-location` to commit, otherwise there would be consistent issue.

It's another topic anyway. We may discuss it elsewhere.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YG_Ba/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/577,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZKmYD,polaris,2569692675,577,NA,soumilshah1995,39345855,Soumil Nitin Shah,,NA,2025-01-03T19:09:30Z,2025-01-03T19:09:30Z,I wanted to kindly check if there are any updates on when these items are expected to be released ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZKmYD/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/577,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bcWcx,polaris,2607900465,577,NA,jackye1995,29823233,Jack Ye,jackye@dataolympia.com,NA,2025-01-22T17:55:05Z,2025-01-22T17:55:05Z,"Thank you for bringing this up @flyrain ! In general, I agree with your implementation details described about the read and write paths.

I think the challenge here is less about implementation, but more about how federation looks like for Polaris. We probably want to get consensus around the federation proposal first, before proceeding further:

https://docs.google.com/document/d/1Q6eEytxb0btpOPcL8RtkULskOlYUCo_3FLvFRnHkzBY/edit?pli=1&tab=t.0#heading=h.dr4s0lqru4mo

Because there could be the option to directly mount an entire table bucket, or mount individual S3 tables.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bcWcx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/580,https://api.github.com/repos/apache/polaris/issues/580,polaris,2748433195,580,Bootstrap fails w/ NPE - `PolarisApplicationConfig.serviceLocator` is `null`,snazy,957468,Robert Stupp,,CLOSED,2024-12-18T17:59:49Z,2025-01-15T12:52:16Z,"### Describe the bug

After adding fixes for #560, #561, #562, there's another new NPE that prevents `bootstrap` w/ eclipselink:

```
java.lang.NullPointerException: Cannot invoke ""org.glassfish.hk2.api.ServiceLocator.getService(java.lang.Class, java.lang.annotation.Annotation[])"" because ""this.serviceLocator"" is null
        at org.apache.polaris.service.dropwizard.config.PolarisApplicationConfig.findService(PolarisApplicationConfig.java:189)
	at org.apache.polaris.service.dropwizard.BootstrapRealmsCommand.run(BootstrapRealmsCommand.java:50)
	at org.apache.polaris.service.dropwizard.BootstrapRealmsCommand.run(BootstrapRealmsCommand.java:37)
	at io.dropwizard.core.cli.ConfiguredCommand.run(ConfiguredCommand.java:98)
	at io.dropwizard.core.cli.Cli.run(Cli.java:78)
	at io.dropwizard.core.Application.run(Application.java:94)
	at org.apache.polaris.service.dropwizard.PolarisApplication.main(PolarisApplication.java:154)
```

I'm not sure whether it's worth to fix all these issues but instead wait for #469.

### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/580/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/580,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6airMz,polaris,2592781107,580,NA,snazy,957468,Robert Stupp,,NA,2025-01-15T12:52:15Z,2025-01-15T12:52:15Z,Likely superseded by #469 ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6airMz/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/582,https://api.github.com/repos/apache/polaris/issues/582,polaris,2749062427,582,Unable to update AWS roleArn associated with catalog,MonkeyCanCode,29619290,,,CLOSED,2024-12-19T01:41:44Z,2025-01-07T00:06:53Z,"### Describe the bug

When trying to update the AWS roleArn for an existed catalog, it will throw 400 error.

### To Reproduce

Create a new dummy catalog:
```
curl -X POST -H ""Authorization: Bearer principal:root;realm:default-realm"" ""http://localhost:8181/api/management/v1/catalogs"" -H ""Content-Type: application/json"" -d '{
         ""catalog"": {
           ""name"": ""polaris"",
           ""type"": ""INTERNAL"",
           ""readOnly"": false,
           ""properties"": {
             ""default-base-location"": ""s3://tmp/polaris/""
           },
           ""storageConfigInfo"": {
             ""roleArn"": ""arn:aws:iam::123456789012:role/role-name-with-path"",
             ""storageType"": ""S3"",
             ""allowedLocations"": [
               ""s3://tmp/polaris/""
             ]
           }
         }
       }'
```

Ensure catalog is created:
```
curl -X GET -H ""Authorization: Bearer principal:root;realm:default-realm"" ""http://localhost:8181/api/management/v1/catalogs""
```

Here is the sample output:
```
{
  ""catalogs"": [
    {
      ""type"": ""INTERNAL"",
      ""name"": ""polaris"",
      ""properties"": {
        ""default-base-location"": ""s3://tmp/polaris/""
      },
      ""createTimestamp"": 1734571966158,
      ""lastUpdateTimestamp"": 1734571966158,
      ""entityVersion"": 1,
      ""storageConfigInfo"": {
        ""storageType"": ""S3"",
        ""roleArn"": ""arn:aws:iam::123456789012:role/role-name-with-path"",
        ""externalId"": null,
        ""userArn"": null,
        ""region"": null,
        ""allowedLocations"": [
          ""s3://tmp/polaris/""
        ]
      }
    }
  ]
}
```

Then tried to update `roleArn` for this catalog:
```
curl -X PUT -H ""Authorization: Bearer principal:root;realm:default-realm"" ""http://localhost:8181/api/management/v1/catalogs/polaris"" -H ""Content-Type: application/json"" -d '{
           ""currentEntityVersion"": 1,
           ""properties"": {
             ""default-base-location"": ""s3://tmp/polaris/""
           },
           ""storageConfigInfo"": {
             ""roleArn"": ""arn:aws:iam::123456789013:role/role-name-with-path"",
             ""storageType"": ""S3"",
             ""allowedLocations"": [
               ""s3://tmp/polaris/""
             ]
           }
       }'
```


### Actual Behavior

Getting following error message with status code 400:
```
{
  ""error"": {
    ""message"": ""Cannot modify Role ARN in storage config from AwsStorageConfigurationInfo{storageType=S3, storageType=S3, roleARN=arn:aws:iam::123456789012:role/role-name-with-path, userARN=null, externalId=null, allowedLocation=[s3://tmp/polaris/], region=null} to AwsStorageConfigurationInfo{storageType=S3, storageType=S3, roleARN=arn:aws:iam::123456789013:role/role-name-with-path, userARN=null, externalId=null, allowedLocation=[s3://tmp/polaris/], region=null}"",
    ""type"": ""BadRequestException"",
    ""code"": 400
  }
}
```

### Expected Behavior

Getting 200 instead. 

### Additional context

Here is the code for this (https://github.com/apache/polaris/blob/main/service/common/src/main/java/org/apache/polaris/service/admin/PolarisAdminService.java):
```
      if (!currentAwsConfig.getRoleARN().equals(newAwsConfig.getRoleARN())
          || !newAwsConfig.getRoleARN().equals(currentAwsConfig.getRoleARN())) {
        throw new BadRequestException(
            ""Cannot modify Role ARN in storage config from %s to %s"",
            currentStorageConfig, newStorageConfig);
      }
```

I am not sure why this is not allowed as change of roleARN seems to be common (e.g. renamed of existed AWS role name)

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/582/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/582,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YcLBC,polaris,2557521986,582,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2024-12-20T18:31:44Z,2024-12-20T18:31:44Z,It should be possible as long as Polaris can validate the new role works with existing paths. ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YcLBC/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/582,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YdskC,polaris,2557921538,582,NA,MonkeyCanCode,29619290,,,NA,2024-12-21T00:45:19Z,2024-12-21T00:45:19Z,"> It should be possible as long as Polaris can validate the new role works with existing paths. 

Thanks for the input, will raise a sample PR for this. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YdskC/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/582,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Yd-Jl,polaris,2557993573,582,NA,MonkeyCanCode,29619290,,,NA,2024-12-21T04:38:25Z,2024-12-21T04:38:25Z,Here is the purposed PR for this change: https://github.com/apache/polaris/pull/587,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Yd-Jl/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/582,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZblWx,polaris,2574144945,582,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2025-01-07T00:06:53Z,2025-01-07T00:06:53Z,Close this one as the PR is merged.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZblWx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/583,https://api.github.com/repos/apache/polaris/issues/583,polaris,2750034562,583,Docker build fails with postgres persistence: dnsjava error: Provider org.xbill.DNS.spi.DnsjavaInetAddressResolverProvider not found,offbeatport,186800377,Offbeat Port,,CLOSED,2024-12-19T11:36:59Z,2024-12-19T12:07:10Z,"### Describe the bug

Dockerfile build fails with dnsjava error

### To Reproduce

1. Create a new ""persistence.xml"" file with configuration form here: https://polaris.apache.org/in-dev/unreleased/metastores/#postgres

3. Inside the Dockerfile use this: 
```
ARG ECLIPSELINK=""true""
ARG ECLIPSELINK_DEPS=""org.postgresql:postgresql:42.7.4""

WORKDIR /app

RUN rm -rf build
RUN ./gradlew --no-daemon --info ${ECLIPSELINK_DEPS+""-PeclipseLinkDeps=$ECLIPSELINK_DEPS""} -PeclipseLink=$ECLIPSELINK clean prepareDockerDist

COPY ./persistence.xml /app
RUN jar cvf /app/persistence-conf.jar persistence.xml

```
4. Inside polaris-server.yml use this:
```
metaStoreManager:
  type: eclipse-link
  conf-file: /app/persistence-conf.jar!/persistence.xml
  persistence-unit: polaris
```

6. Build the image: 
```
$ docker build .
```


### Actual Behavior

This is the error I'm getting: 
```bash
Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them
[EL Warning]: metadata: 2024-12-19 11:06:08.715--ServerSession(995911260)--You have specified multiple ids for the entity class [org.apache.polaris.jpa.models.ModelEntityChangeTracking] without specifying an @IdClass. By doing this you may lose the ability to find by identity, distributed cache support etc. Note: You may however use EntityManager find operations by passing a list of primary key fields. Else, you will have to use JPQL queries to read your entities. For other id options see @PrimaryKey.
[EL Warning]: metadata: 2024-12-19 11:06:08.725--ServerSession(995911260)--You have specified multiple ids for the entity class [org.apache.polaris.jpa.models.ModelGrantRecord] without specifying an @IdClass. By doing this you may lose the ability to find by identity, distributed cache support etc. Note: You may however use EntityManager find operations by passing a list of primary key fields. Else, you will have to use JPQL queries to read your entities. For other id options see @PrimaryKey.
[EL Warning]: metadata: 2024-12-19 11:06:08.726--ServerSession(995911260)--You have specified multiple ids for the entity class [org.apache.polaris.jpa.models.ModelEntity] without specifying an @IdClass. By doing this you may lose the ability to find by identity, distributed cache support etc. Note: You may however use EntityManager find operations by passing a list of primary key fields. Else, you will have to use JPQL queries to read your entities. For other id options see @PrimaryKey.
[EL Warning]: metadata: 2024-12-19 11:06:08.727--ServerSession(995911260)--You have specified multiple ids for the entity class [org.apache.polaris.jpa.models.ModelEntityActive] without specifying an @IdClass. By doing this you may lose the ability to find by identity, distributed cache support etc. Note: You may however use EntityManager find operations by passing a list of primary key fields. Else, you will have to use JPQL queries to read your entities. For other id options see @PrimaryKey.
[EL Warning]: metadata: 2024-12-19 11:06:08.728--ServerSession(995911260)--You have specified multiple ids for the entity class [org.apache.polaris.jpa.models.ModelEntityDropped] without specifying an @IdClass. By doing this you may lose the ability to find by identity, distributed cache support etc. Note: You may however use EntityManager find operations by passing a list of primary key fields. Else, you will have to use JPQL queries to read your entities. For other id options see @PrimaryKey.
[EL Info]: 2024-12-19 11:06:08.783--ServerSession(995911260)--EclipseLink, version: Eclipse Persistence Services - 4.0.4.v202407190748-059428cdd2583c46f1f3e50d235854840a6fa9a7
[EL Severe]: ejb: 2024-12-19 11:06:08.804--ServerSession(995911260)--java.util.ServiceConfigurationError: java.net.spi.InetAddressResolverProvider: Provider org.xbill.DNS.spi.DnsjavaInetAddressResolverProvider not found
jakarta.persistence.PersistenceException: java.util.ServiceConfigurationError: java.net.spi.InetAddressResolverProvider: Provider org.xbill.DNS.spi.DnsjavaInetAddressResolverProvider not found
	at org.eclipse.persistence.internal.jpa.EntityManagerSetupImpl.deploy(EntityManagerSetupImpl.java:855)
	at org.eclipse.persistence.internal.jpa.EntityManagerFactoryDelegate.getAbstractSession(EntityManagerFactoryDelegate.java:226)
	at org.eclipse.persistence.internal.jpa.EntityManagerFactoryDelegate.getDatabaseSession(EntityManagerFactoryDelegate.java:203)
	at org.eclipse.persistence.internal.jpa.EntityManagerFactoryImpl.getDatabaseSession(EntityManagerFactoryImpl.java:534)
	at org.eclipse.persistence.jpa.PersistenceProvider.createEntityManagerFactoryImpl(PersistenceProvider.java:153)
	at org.eclipse.persistence.jpa.PersistenceProvider.createEntityManagerFactory(PersistenceProvider.java:191)
	at jakarta.persistence.Persistence.createEntityManagerFactory(Persistence.java:80)
	at org.apache.polaris.extension.persistence.impl.eclipselink.PolarisEclipseLinkMetaStoreSessionImpl.createEntityManagerFactory(PolarisEclipseLinkMetaStoreSessionImpl.java:185)
	at org.apache.polaris.extension.persistence.impl.eclipselink.PolarisEclipseLinkMetaStoreSessionImpl.<init>(PolarisEclipseLinkMetaStoreSessionImpl.java:122)
	at org.apache.polaris.extension.persistence.impl.eclipselink.EclipseLinkPolarisMetaStoreManagerFactory.createMetaStoreSession(EclipseLinkPolarisMetaStoreManagerFactory.java:62)
	at org.apache.polaris.extension.persistence.impl.eclipselink.EclipseLinkPolarisMetaStoreManagerFactory.createMetaStoreSession(EclipseLinkPolarisMetaStoreManagerFactory.java:37)
	at org.apache.polaris.core.persistence.LocalPolarisMetaStoreManagerFactory.lambda$initializeForRealm$0(LocalPolarisMetaStoreManagerFactory.java:78)
	at org.apache.polaris.core.persistence.LocalPolarisMetaStoreManagerFactory.checkPolarisServiceBootstrappedForRealm(LocalPolarisMetaStoreManagerFactory.java:223)
	at org.apache.polaris.core.persistence.LocalPolarisMetaStoreManagerFactory.getOrCreateMetaStoreManager(LocalPolarisMetaStoreManagerFactory.java:128)
	at org.apache.polaris.core.persistence.LocalPolarisMetaStoreManagerFactory.purgeRealms(LocalPolarisMetaStoreManagerFactory.java:110)
	at org.apache.polaris.service.dropwizard.PurgeRealmsCommand.run(PurgeRealmsCommand.java:46)
	at org.apache.polaris.service.dropwizard.PurgeRealmsCommand.run(PurgeRealmsCommand.java:30)
	at io.dropwizard.core.cli.ConfiguredCommand.run(ConfiguredCommand.java:98)
	at io.dropwizard.core.cli.Cli.run(Cli.java:78)
	at io.dropwizard.core.Application.run(Application.java:94)
	at org.apache.polaris.service.dropwizard.PolarisApplication.main(PolarisApplication.java:153)
Caused by: java.util.ServiceConfigurationError: java.net.spi.InetAddressResolverProvider: Provider org.xbill.DNS.spi.DnsjavaInetAddressResolverProvider not found
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:593)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.nextProviderClass(ServiceLoader.java:1219)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1228)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1273)
	at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1309)
	at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1393)
	at java.base/java.util.ServiceLoader.findFirst(ServiceLoader.java:1812)
	at java.base/java.net.InetAddress.loadResolver(InetAddress.java:508)
	at java.base/java.net.InetAddress.resolver(InetAddress.java:488)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1826)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:1139)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1818)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1688)
	at java.base/java.net.InetAddress.getByName(InetAddress.java:1568)
	at java.base/java.net.InetSocketAddress.<init>(InetSocketAddress.java:230)
	at org.postgresql.core.PGStream.createSocket(PGStream.java:258)
	at org.postgresql.core.PGStream.<init>(PGStream.java:121)
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:140)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:268)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:273)
	at org.postgresql.Driver.makeConnection(Driver.java:446)
	at org.postgresql.Driver.connect(Driver.java:298)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
	at org.eclipse.persistence.sessions.DefaultConnector.connect(DefaultConnector.java:102)
	at org.eclipse.persistence.sessions.DatasourceLogin.connectToDatasource(DatasourceLogin.java:174)
	at org.eclipse.persistence.internal.sessions.DatabaseSessionImpl.setOrDetectDatasource(DatabaseSessionImpl.java:226)
	at org.eclipse.persistence.internal.sessions.DatabaseSessionImpl.loginAndDetectDatasource(DatabaseSessionImpl.java:809)
	at org.eclipse.persistence.internal.jpa.EntityManagerFactoryProvider.login(EntityManagerFactoryProvider.java:259)
	at org.eclipse.persistence.internal.jpa.EntityManagerSetupImpl.deploy(EntityManagerSetupImpl.java:770)
	... 20 more
npm ERR! Lifecycle script `purge` failed with error:
npm ERR! Error: command failed
npm ERR!   in workspace: polaris@0.0.1
npm ERR!   at location: /Users/vladpalos/Development/PolarBase/apps/polaris
```

### Expected Behavior

_No response_

### Additional context

It works fine with the h2 persistence configuration.




### System information

macos / openjdk-21 (redhat)
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/583/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/583,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YNNXf,polaris,2553599455,583,NA,offbeatport,186800377,Offbeat Port,,NA,2024-12-19T12:07:10Z,2024-12-19T12:07:10Z,It looks like it's fixed by: https://github.com/apache/polaris/pull/581. Thank you!,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YNNXf/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/584,https://api.github.com/repos/apache/polaris/issues/584,polaris,2751400903,584,Polaris Release Cadence and Roadmap Alignment,flyrain,1322359,Yufei Gu,yufei@apache.org,OPEN,2024-12-19T20:54:03Z,2024-12-20T04:56:14Z,"## Importance of a Defined Release Cadence
Establishing a predictable release cadence will help us:
- Deliver key roadmap features in a timely and structured manner.
- Provide clarity and transparency for contributors and users about what to expect in upcoming versions.
- Align with related projects, such as Apache Iceberg, to ensure compatibility and ease of integration.

## Current Status and Proposal
We are currently preparing for the **0.9.0** release, which is scheduled to ship by **January 2025**. To maintain momentum and adapt to the fast-paced development in the REST catalog space, I propose that we adopt a **three-month release cycle**. This cadence will allow us to stay agile while ensuring regular updates.

Additionally, this schedule aligns with Icebergâ€™s release cycle, which could be beneficial if any Iceberg Spec changes require updates or synchronization with Polaris. While syncing releases with Iceberg isnâ€™t mandatory, aligning them could help streamline cross-project compatibility.

## Suggested Release Plan
Using this cadence as a baseline:
- 0.9.0: January 2025
- 1.0.0: April 2025
- 1.1.0: July 2025
- 1.2.0: October 2025 ...and so on.

Itâ€™s worth noting that actual **release dates may shift by about one month**, depending on development progress or unforeseen circumstances. We could adjust timelines as needed.

Iâ€™ve created related **milestones**(https://github.com/apache/polaris/milestones) in the project to reflect these timelines. I encourage everyone to review them and tag any relevant issues or pull requests with the appropriate versions.

## Roadmap Integration
With these milestones in place, the roadmap will naturally take shape, driven by the features and fixes tagged in each release. Moving forward, we can:
- File new feature requests or bug fixes with milestone tags.
- Use these milestones as a guiding framework for project planning and prioritization.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/584/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/584,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YXdg8,polaris,2556287036,584,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2024-12-20T04:56:13Z,2024-12-20T04:56:13Z,"I'm working on this one (it has been discussed with some community members).
For now, we have to fix blocker issue for rc2 and merge the enhanced runtime framework (which has an impact on release process).
I will define the roadmap and release pace for beginning of Jan.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6YXdg8/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/586,https://api.github.com/repos/apache/polaris/issues/586,polaris,2751672327,586,Unstructured data support in Apache Polaris,flyrain,1322359,Yufei Gu,yufei@apache.org,OPEN,2024-12-20T00:40:00Z,2024-12-20T00:40:27Z,"### Describe the solution you'd like

Polaris has become a cornerstone for managing structured data across diverse processing engines, ensuring high performance and reliability. To further enhance its capabilities, we propose extending Polaris to support unstructured data. This will enable it to handle a broader range of data types efficiently, meeting the growing demands of AI/ML and other data-intensive applications.

You can find the proposal here: [Proposal: Unstructured Data Support in Polaris](https://docs.google.com/document/d/1ofljkrtiXRWc-v6hfkg_laKlYltepTPX7zsg44Tb-BY/edit?usp=sharing)","{""url"": ""https://api.github.com/repos/apache/polaris/issues/586/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/608,https://api.github.com/repos/apache/polaris/issues/608,polaris,2767654293,608,Polaris Server exposes backend meta in error response body,george-zubrienko,14901777,George Zubrienko,,OPEN,2025-01-03T14:21:29Z,2025-01-09T17:43:37Z,"### Describe the bug

Spin up Polaris server using helm chart with Eclipse Link (Postgres), but do not create a Postgres database (do not bootstrap). Run this from inside a pod (or via exposed address if you have ingress):
```
PRINCIPAL_TOKEN=""principal:root;realm:default-realm""
curl -i -X POST -H ""Authorization: Bearer $PRINCIPAL_TOKEN"" -H 'Accept: application/json' -H 'Content-Type: application/json'   http://localhost:8181/api/management/v1/catalogs   -d '{
        ""catalog"": {
          ""name"": ""polaris"",
          ""type"": ""INTERNAL"",
          ""readOnly"": false,
          ""properties"": {
            ""default-base-location"": ""s3://tmp/development/polaris/""
          },
          ""storageConfigInfo"": {
            ""storageType"": ""S3"",
            ""allowedLocations"": [
              ""s3://tmp/development/polaris/""
            ],
            ""roleArn"": ""arn:aws:iam::000000000000:role/polaris-access-role""
          }
        }
      }'
```
Receive this:
```
HTTP/1.1 500 Server Error
Date: Fri, 03 Jan 2025 14:08:25 GMT
Cache-Control: must-revalidate,no-cache,no-store
Content-Type: application/json
Content-Length: 1215
Connection: close

{
""cause2"":""org.postgresql.util.PSQLException: FATAL: database &quot;default-realm&quot; does not exist"",
""cause1"":""Exception [EclipseLink-4002] (Eclipse Persistence Services - 4.0.4.v202407190748-059428cdd2583c46f1f3e50d235854840a6fa9a7): org.eclipse.persistence.exceptions.DatabaseException\nInternal Exception: org.postgresql.util.PSQLException: FATAL: database &quot;default-realm&quot; does not exist\nError Code: 0"",
""servlet"":""jersey"",
""cause0"":""jakarta.persistence.PersistenceException: Exception [EclipseLink-4002] (Eclipse Persistence Services - 4.0.4.v202407190748-059428cdd2583c46f1f3e50d235854840a6fa9a7): org.eclipse.persistence.exceptions.DatabaseException\nInternal Exception: org.postgresql.util.PSQLException: FATAL: database &quot;default-realm&quot; does not exist\nError Code: 0"",
""message"":""jakarta.persistence.PersistenceException: Exception [EclipseLink-4002] (Eclipse Persistence Services - 4.0.4.v202407190748-059428cdd2583c46f1f3e50d235854840a6fa9a7): org.eclipse.persistence.exceptions.DatabaseException\nInternal Exception: org.postgresql.util.PSQLException: FATAL: database &quot;default-realm&quot; does not exist\nError Code: 0"",
""url"":""/api/management/v1/catalogs"",
""status"":""500""
```
In this case, two things happened:
- I was allowed unauthenticated call (check polaris-server below) w/o getting 401 right away
- I am able to see what backend type is configured and I can check what databases are deployed there

### To Reproduce

(in describe section)

### Actual Behavior

HTTP call is allowed and stack trace information reveals certain details about metastore backend

### Expected Behavior

HTTP 401 - w/o any details, details logged on DEBUG level if configured for the server via values.yaml

### Additional context

Polairs build commit: https://github.com/apache/polaris/commit/0f5850c8f6dd01932f758d331dce13d2bc5d0a1c
EclipseLink with PSQL

If database is **bootstrapped**, 401 is returned correctly

### System information

Polaris container sourced from repo's Dockerfile - k8s 1.29 target cluster (EKS)
PSQL (Aurora)
`polaris-server.yml`:
```
authenticator:
  class: org.apache.polaris.service.auth.DefaultPolarisAuthenticator
callContextResolver:
  type: default
cors:
  allowed-credentials: true
  allowed-headers:
  - '*'
  allowed-methods:
  - PATCH
  - POST
  - DELETE
  - GET
  - PUT
  allowed-origins:
  - http://localhost:8080
  allowed-timing-origins:
  - http://localhost:8080
  exposed-headers:
  - '*'
  preflight-max-age: 600
defaultRealms:
- lakehouse
featureConfiguration:
  ENFORCE_PRINCIPAL_CREDENTIAL_ROTATION_REQUIRED_CHECKING: false
  SUPPORTED_CATALOG_STORAGE_TYPES:
  - S3
io:
  factoryType: default
logging:
  appenders:
  - logFormat: '%-5p [%d{ISO8601} - %-6r] [%t] [%X{aid}%X{sid}%X{tid}%X{wid}%X{oid}%X{srv}%X{job}%X{rid}]
      %c{30}: %m %kvp%n%ex'
    threshold: ALL
    type: console
  level: INFO
  loggers:
    org.apache.iceberg.rest: DEBUG
    org.apache.polaris: DEBUG
maxRequestBodyBytes: -1
metaStoreManager:
  conf-file: /eclipselink-config/conf.jar!/persistence.xml
  persistence-unit: polaris
  type: eclipse-link
oauth2:
  type: default
rateLimiter:
  type: no-op
realmContextResolver:
  type: default
server:
  adminConnectors:
  - port: 8182
    type: http
  applicationConnectors:
  - port: 8181
    type: http
  maxThreads: 200
  minThreads: 10
  requestLog:
    appenders:
    - type: console
tokenBroker:
  secret: ...
  type: symmetric-key
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/608/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/616,https://api.github.com/repos/apache/polaris/issues/616,polaris,2772203329,616,"`PolarisApplication.ContextResolverFilter` consumes form-data, breaking endpoints",snazy,957468,Robert Stupp,,CLOSED,2025-01-07T08:29:28Z,2025-01-07T09:22:42Z,"`org.apache.polaris.service.dropwizard.PolarisApplication.ContextResolverFilter#doFilter` calls `jakarta.servlet.ServletRequest#getParameterMap`, which is documented to _trigger the parsing of the query string, POSTed form data where the request body has content type is `application/ x-www-form-urlencoded` ..._ , which means to consume the HTTP request body. Consuming the request body that early in a `Filter` can break other endpoints/servlets that parse the body on their own.

Using `jakarta.servlet.ServletRequest#getParameterMap` in `ContextResolverFilter` is also wrong, because the expected parameters are supposed to be **only** present as URI **query** parameters.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/616/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/616,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZdwIf,polaris,2574713375,616,NA,snazy,957468,Robert Stupp,,NA,2025-01-07T08:48:36Z,2025-01-07T08:48:36Z,"Annoying, the parameter `queryParams` is used neither in `RealmContextResolver` nor in `CallContextResolver` implementations.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZdwIf/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/618,https://api.github.com/repos/apache/polaris/issues/618,polaris,2772270449,618,`TestOAuth2ApiService` selected in _production_ build,snazy,957468,Robert Stupp,,OPEN,2025-01-07T09:00:01Z,2025-01-07T09:36:34Z,"### Describe the bug

Scenarion:
* Polaris with Eclipselink
* Bootstrapped Polaris
* Starting Polaris
* Running `./polaris principals list`

Yields a runtime exception, HTTP/401 hides the actual cause:

```
INFO  [2025-01-07 09:57:15,226 - 3457  ] [dw-93] [] o.a.p.s.d.t.TracingFilter: Started span with parent spanId=""ee5c1a62cd73d22d"" traceId=""13a21ffd612cf2718943bb9bb5492daa"" parentContext=""{}""
INFO  [2025-01-07 09:57:15,249 - 3480  ] [dw-93 - POST /api/catalog/v1/oauth/tokens] [] o.a.p.s.e.IcebergExceptionMapper: Handling runtimeException Failed to read principal entity 
INFO  [2025-01-07 09:57:15,249 - 3480  ] [dw-93 - POST /api/catalog/v1/oauth/tokens] [] o.a.p.s.e.IcebergExceptionMapper: Handling runtimeException 
org.apache.iceberg.exceptions.NotAuthorizedException: Failed to read principal entity
	at org.apache.polaris.service.auth.TestOAuth2ApiService.getPrincipalName(TestOAuth2ApiService.java:107)
	at org.apache.polaris.service.auth.TestOAuth2ApiService.getToken(TestOAuth2ApiService.java:63)
	at org.apache.polaris.service.catalog.api.IcebergRestOAuth2Api.getToken(IcebergRestOAuth2Api.java:113)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:146)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:189)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
...
```


### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/618/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/618,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZeANR,polaris,2574779217,618,NA,adutra,463876,Alexandre Dutra,,NA,2025-01-07T09:20:12Z,2025-01-07T09:20:12Z,"I was thinking that wee could maybe isolate the ""test"" services in a separate module.

For tests that need those, it's only a matter of importing the module.

For users wishing to prototype Polaris with a non-production setup, we could e.g. publish Docker images containing those test services, but clearly labeled as non-production images, e.g. `apache/polaris-eval` or `apache/polaris-test`.

Alternatively, we can also introduce something Ã  la Keycloak and define a ""dev"" mode that must be explicitly enabled if the user wants to use test-grade features.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZeANR/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/618,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZeDRH,polaris,2574791751,618,NA,snazy,957468,Robert Stupp,,NA,2025-01-07T09:26:22Z,2025-01-07T09:26:22Z,I guess that most of these annoying issues just disappear w/ Quarkus ;),"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZeDRH/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/618,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZeHQo,polaris,2574808104,618,NA,adutra,463876,Alexandre Dutra,,NA,2025-01-07T09:34:05Z,2025-01-07T09:34:05Z,"> I guess that most of these annoying issues just disappear w/ Quarkus ;)

Well, the test services are still there, so there is a chance someone could put Polaris into production with test-grade authentication.  But contrary to Dropwizard, the test services are not the default ones, so the user must enable them explicitly.

We should also take UX into account: if someone runs `docker run apache/polaris` and the container fails to start because there is no private key configured or whatever, that's a bad UX. But that's what happens now with Quarkus.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZeHQo/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/618,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZeI15,polaris,2574814585,618,NA,snazy,957468,Robert Stupp,,NA,2025-01-07T09:36:32Z,2025-01-07T09:36:32Z,"Right. I opened #620 as well to highlight the configuration file issues.

The default configuration should at least work - and the file should at least point users to where they find information to make things for example more secure.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZeI15/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/620,https://api.github.com/repos/apache/polaris/issues/620,polaris,2772352277,620,Root `polaris-server.yml` not usable,snazy,957468,Robert Stupp,,CLOSED,2025-01-07T09:34:13Z,2025-01-15T09:22:52Z,"### Describe the bug

The `polaris-server.yml` in the root folder is made for testing purposes, and is by far not usable in production-ish setups. This is not nice and causes a lot of confusion and try-and-error round-trips - most of those errors aren't immediately visible to end users and only discoverable using an attached debugger.

Summary of the issues:
* The `default-realm` cannot be bootstrapped - something like `export POLARIS_BOOTSTRAP_DEFAULT-REALM_ROOT_CLIENT_ID=default_root_client`, as documented, does not work in e.g. `bash` - also: nothing says that the realm and principal name must be upper case in the env var names.
* `oauth2` is configured to `test` - that doesn't make sense for prod use cases
* `authenticator` same as for `oauth2`
* `tokenBroker` is not configured and not mentioned at all in the config file
* `defaultRealm` and `defaultRealms` options are at least confusing

The code design makes it extremely hard for users, even engineers, to figure out that and even harder why things do not work.

I propose to use this issue to come up with a better config mechanism via #469 and follow-ups.

The default configuration should at least work.
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/620/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/620,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6agEE0,polaris,2592096564,620,NA,snazy,957468,Robert Stupp,,NA,2025-01-15T09:22:51Z,2025-01-15T09:22:51Z,Closing after #469 ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6agEE0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/621,https://api.github.com/repos/apache/polaris/issues/621,polaris,2772369996,621,Confusing log messages about `POLARIS_SEQ`,snazy,957468,Robert Stupp,,OPEN,2025-01-07T09:42:15Z,2025-01-17T08:12:13Z,"### Describe the bug

The log messages
```
INFO  [2025-01-07 10:14:25,982 - 1046  ] [main] [] o.a.p.e.p.i.e.PolarisSequenceUtil: Checking if the sequence POLARIS_SEQ exists 
INFO  [2025-01-07 10:14:25,990 - 1054  ] [main] [] o.a.p.e.p.i.e.PolarisSequenceUtil: POLARIS_SEQ does not exist, skipping NEXTVAL 
```
are just confusing - the code mentions ""legacy"", but there is no ""legacy"" in Polaris.

### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/621/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/621,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Z1W61,polaris,2580901557,621,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2025-01-09T17:39:43Z,2025-01-09T17:39:43Z,"Sorry, what are you confused by?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Z1W61/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/621,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6aFd2c,polaris,2585124252,621,NA,snazy,957468,Robert Stupp,,NA,2025-01-11T06:56:31Z,2025-01-11T06:56:31Z,"Because there is no ""legacy"" in Polaris - and that message implies that there's something missing. TL;DR the message is not useful for users, right?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6aFd2c/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/621,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6aFeNr,polaris,2585125739,621,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2025-01-11T07:02:34Z,2025-01-11T07:02:34Z,"What do you mean by â€œthere is no legacyâ€?

On Fri, Jan 10, 2025 at 10:56â€¯PM Robert Stupp ***@***.***>
wrote:

> Because there is no ""legacy"" in Polaris - and that message implies that
> there's something missing. TL;DR the message is not useful for users, right?
>
> â€”
> Reply to this email directly, view it on GitHub
> <https://github.com/apache/polaris/issues/621#issuecomment-2585124252>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AFRE3SHLL4YI5LERB7RBGUT2KC6DJAVCNFSM6AAAAABUXKPDX2VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDKOBVGEZDIMRVGI>
> .
> You are receiving this because you commented.Message ID:
> ***@***.***>
>
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6aFeNr/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/621,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6aWL19,polaris,2589506941,621,NA,snazy,957468,Robert Stupp,,NA,2025-01-14T10:09:18Z,2025-01-14T10:09:18Z,"> What do you mean by â€œthere is no legacyâ€?

There's no Polaris release yet, no?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6aWL19/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/621,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6aWMK9,polaris,2589508285,621,NA,snazy,957468,Robert Stupp,,NA,2025-01-14T10:09:59Z,2025-01-14T10:09:59Z,"Also, what can or should a _user_ do when he sees those messages?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6aWMK9/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/621,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6axT2C,polaris,2596617602,621,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2025-01-16T19:18:56Z,2025-01-16T19:18:56Z,"> Also, what can or should a user do when he sees those messages?

Be aware of what entity in the backend is being used.

> There's no Polaris release yet, no?

I'm not sure I follow you here. The message doesn't refer to any version.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6axT2C/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/621,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a087Q,polaris,2597572304,621,NA,snazy,957468,Robert Stupp,,NA,2025-01-17T07:06:42Z,2025-01-17T07:06:42Z,"> Be aware of what entity in the backend is being used.

@eric-maynard the term ""legacy"" is used in the Javadoc: ""If the legacy `POLARIS_SEQ` generator is available it will be used then cleaned up. In all other cases the `POLARIS_SEQUENCE` table is used directly."". No previous version (there is none released, right?) of the Apache Polaris code base used that identifier.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a087Q/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/621,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a0-MN,polaris,2597577485,621,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2025-01-17T07:10:44Z,2025-01-17T07:10:44Z,"I can see the Javadoc, but I don't see what you're confused by.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a0-MN/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/621,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a0-Wx,polaris,2597578161,621,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2025-01-17T07:11:15Z,2025-01-17T07:11:15Z,"Are you saying that you think ""legacy"" usually is an identifier used to refer to a particular version of software? It is not.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a0-Wx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/621,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a1GNV,polaris,2597610325,621,NA,snazy,957468,Robert Stupp,,NA,2025-01-17T07:36:08Z,2025-01-17T07:36:08Z,"In this case it does. Again, there is no ""POLARIS_SEQ legacy"" in this code base, so the whole thing can and should go away. It is confusing.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a1GNV/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/621,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a1MDk,polaris,2597634276,621,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2025-01-17T07:53:41Z,2025-01-17T07:53:41Z,"No, in this case it actually doesn't. Maybe that's the source of confusion here?

Older ""versions"" of Polaris used this entity POLARIS_SEQ, but it isn't used by newer ""versions"". It is a sort of vestigial entity that may be used one-time to continue the sequence, and [legacy](https://en.wikipedia.org/wiki/Legacy_system) is used in that sense.

Is there another term that you think we should use which would be more clear?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a1MDk/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/621,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a1NBD,polaris,2597638211,621,NA,snazy,957468,Robert Stupp,,NA,2025-01-17T07:56:27Z,2025-01-17T07:56:27Z,"The whole point is that a) the _logging_ is confusing and the ""legacy"" is not properly defined. But still, I cannot find any usage of `POLARIS_SEQ` even in the initial commit.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a1NBD/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/621,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a1Pvg,polaris,2597649376,621,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2025-01-17T08:04:01Z,2025-01-17T08:04:01Z,"Yes -- if POLARIS_SEQ (removed [here](https://github.com/apache/polaris/commit/537eee6578afbea8dede47958edf0b6168326252#diff-86c8895dd16cf603f1de2aa49931368a075f7aafbe2bc4fca0bc7b8c2aa9be76L68)) was used in a release then I would prefer this comment to say something like:
```
If the generator `POLARIS_SEQ` used prior to Polaris X.Y is...
```

But since there isn't a version, ""legacy"" was the most descriptive term I could think of. The generator is legacy in that it may still be around in the metastore but should only be used in a one-off operation and otherwise is disused now.

Eventually I think we can even clean a lot of this up. That is, remove the logging and a lot of the code. We just needed this to make sure we didn't break any existing deployments using the old (legacy) metastore implementation. 

The idea was to wait to ensure nobody was still relying on POLARIS_SEQ before ripping this code out. That may be the case by now.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a1Pvg/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/621,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a1S_l,polaris,2597662693,621,NA,snazy,957468,Robert Stupp,,NA,2025-01-17T08:12:11Z,2025-01-17T08:12:11Z,"TBH: since there is no Polaris release yet, there is nothing to care about. I'll start a dev-ML discussion about this.
TL;DR the whole POLARIS_SEQ stuff can and should go away, especially the user-nag","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a1S_l/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/624,https://api.github.com/repos/apache/polaris/issues/624,polaris,2775196539,624,Root user cannot rotate principal credentials,Gerrit-K,8766565,Gerrit Kieffer,,OPEN,2025-01-08T11:50:40Z,2025-01-11T00:10:31Z,"### Describe the bug

When trying to rotate a principal's credentials via the root user, an HTTP error with code 403 is returned:
```
{""error"":{""message"":""Principal 'root' with activated PrincipalRoles '[]' and activated grants via '[service_admin]' is not authorized for op ROTATE_CREDENTIALS"",""type"":""ForbiddenException"",""code"":403}}
```

### To Reproduce

1. Deploy locally via `docker compose up --build`
2. Note down the root principal credentials and store them in a shell variable, e.g.
    ```shell
    CLIENT_ID=f69f1990657205d9
    CLIENT_SECRET=e89026b4e87d60b7bd6ea75adb16e6f8
    ```
3. Get an access token for the root principal
    ```shell
    TOKEN=""$(curl --request POST ""http://localhost:8181/api/catalog/v1/oauth/tokens?grant_type=client_credentials&scope=PRINCIPAL_ROLE%3AALL&client_id=${CLIENT_ID}&client_secret=${CLIENT_SECRET}"" \
    --header 'content-type: application/x-www-form-urlencoded' \
    | jq -r .access_token)""
    ```
4. Create a new principal
    ```shell
    curl --request POST http://localhost:8181/api/management/v1/principals \
    --header ""Authorization: Bearer $TOKEN"" \
    --header ""Content-Type: application/json"" \
    -d '{""name"": ""test""}')""
    ```
5. Try to rotate the credentials of the new principal using the same token as it was created with
    ```shell
    curl --request POST http://localhost:8181/api/management/v1/principals/test/rotate \
    --header ""Authorization: Bearer $TOKEN""
    ```


### Actual Behavior

The service returns a 403 response
```
{""error"":{""message"":""Principal 'root' with activated PrincipalRoles '[]' and activated grants via '[service_admin]' is not authorized for op ROTATE_CREDENTIALS"",""type"":""ForbiddenException"",""code"":403}}
```

### Expected Behavior

The principal credentials should successfully be rotated

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/624/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/624,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Z1WuZ,polaris,2580900761,624,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2025-01-09T17:39:16Z,2025-01-09T17:39:16Z,"IIRC this is by design, users can rotate their own credentials but root cannot change them.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Z1WuZ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/624,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Z6AO4,polaris,2582119352,624,NA,Gerrit-K,8766565,Gerrit Kieffer,,NA,2025-01-10T09:06:42Z,2025-01-10T09:06:42Z,"Hm, that seems a bit strange to me, to be honest ðŸ¤” A not-so-rare use case for secret rotation is to restore access after credentials have been lost (by whatever means). If the root principal cannot do this, then there is literally no way to recover credentials, so the principal needs to be deleted and a new one set up, including setting up all the roles and permissions. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Z6AO4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/624,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6aEw3H,polaris,2584939975,624,NA,dimas-b,40603221,Dmitri Bourlatchkov,,NA,2025-01-11T00:09:06Z,2025-01-11T00:09:06Z,"I agree with @Gerrit-K .  Having ""root"" capable of resetting any principal's passwords is a valuable feature (whether it falls under the ""rotate credentials"" API or gets a new API endpoint).","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6aEw3H/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/625,https://api.github.com/repos/apache/polaris/issues/625,polaris,2775327461,625,Quick start guide missing configuration,dicarcab,110469300,Diego Cardenas,,CLOSED,2025-01-08T12:54:09Z,2025-01-14T12:00:46Z,"### Describe the bug

Hello, I've trying to test Polaris locally using the official Docker Image and a local gradle build, but have and issue while writing data to a catalog using S3. 

I followed the Quick start guide and everything works fine until I tried to insert data to the table but I kept getting this answer 
`Server error: S3Exception: The bucket you are attempting to access must be addressed using the specified endpoint. Please send all future requests to this endpoint. (Service: S3, Status Code: 301,)` is there any configuration that must be specified to the docker image to be able to write data to the desired location ? 

I set up the aws access and secret key and my bucket is in the same region that is used in the docker compose image. Is there missing steps in the official documentation ?

### To Reproduce
1. set aws AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEYas env variables, AWS_REGION is set as us-west-2 inside docker file as the S3 bucket to be used.
2. Follow the quick start guide create roles and catalog using the docker compose file inside polaris repo
3. start local spark 3.5
4. use catalog and create namespaces and table using spark sql
5. using spark sql spark.sql(""INSERT INTO quickstart_table VALUES (1, 'some data')"") command

### Actual Behavior

error returned by the rest api `Server error: S3Exception: The bucket you are attempting to access must be addressed using the specified endpoint. Please send all future requests to this endpoint. (Service: S3, Status Code: 301,)` is there any configuration that must be specified to the docker image to be able to write data to the desired location ? 

### Expected Behavior

Data should be written in the table

### Additional context

_No response_

### System information

WSL ubuntu, S3 as backend ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/625/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/625,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Zusul,polaris,2579155877,625,NA,MonkeyCanCode,29619290,,,NA,2025-01-09T04:25:27Z,2025-01-09T04:25:27Z,@dicarcab I think you will need to set AWS region as well depends on your setup. Maybe provide a bit more info on how to reproduce this?,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Zusul/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/625,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZzJiu,polaris,2580322478,625,NA,dicarcab,110469300,Diego Cardenas,,NA,2025-01-09T14:14:47Z,2025-01-09T14:14:47Z,@MonkeyCanCode I updated the steps to reproduce the issue. The bucket is located in us-west-2 region as the default value inside the docker compose file. ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ZzJiu/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/625,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Z4C7w,polaris,2581606128,625,NA,MonkeyCanCode,29619290,,,NA,2025-01-10T02:15:16Z,2025-01-10T02:15:16Z,"> @MonkeyCanCode I updated the steps to reproduce the issue. The bucket is located in us-west-2 region as the default value inside the docker compose file.

K. I will take a look later this weekend then update. I recalled this part used to work.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Z4C7w/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/625,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6aINdR,polaris,2585843537,625,NA,MonkeyCanCode,29619290,,,NA,2025-01-12T17:31:08Z,2025-01-12T17:31:08Z,"So this is actually due to missing region set on spark side instead of polaris side. Here is how to reproduce this:

Having the same issue:
```
scala> spark.sql(""INSERT INTO quickstart_table VALUES (1, 'some data')"")
...
software.amazon.awssdk.core.exception.SdkClientException: Unable to load region from any of the providers in the chain software.amazon.awssdk.regions.providers.DefaultAwsRegionProviderChain@1315b5e8: [software.amazon.awssdk.regions.providers.SystemSettingsRegionProvider@350a6bf2: Unable to load region from system settings. Region must be specified either via environment variable (AWS_REGION) or  system property (aws.region)., software.amazon.awssdk.regions.providers.AwsProfileRegionProvider@54b391ae: No region provided in profile: default, software.amazon.awssdk.regions.providers.InstanceProfileRegionProvider@2be11aa0: Unable to contact EC2 metadata service.]
```

One way to fix this is set region on the client side (spark) via global variable but this can be problematic when distributed compute kicked in as worker nodes won't have this set:
```
âžœ  spark-3.5.4-bin-hadoop3 export AWS_REGION=us-west-2
...
scala> spark.sql(""INSERT INTO quickstart_table VALUES (1, 'some data')"")
SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
res7: org.apache.spark.sql.DataFrame = []

scala> spark.sql(""select * from quickstart_table limit 10"").show()
+---+---------+
| id|     data|
+---+---------+
|  1|some data|
+---+---------+
```

Thus, it is better to set via catalog property such as following:
```
--conf spark.sql.catalog.quickstart_catalog.client.region=us-west-2
```

Here is the PR for the above change: https://github.com/apache/polaris/pull/712

Also, this can be avoid is region is set on the catalog level (via storageConfigInfo.region...more details in https://polaris.apache.org/in-dev/unreleased/polaris-management-service/#operation/listCatalogs)
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6aINdR/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/625,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6aTnYM,polaris,2588833292,625,NA,hangc0276,5436568,Hang Chen,chenhang@apache.org,NA,2025-01-14T03:22:05Z,2025-01-14T03:22:05Z,"I encountered the same issue. 
- My iceberg client runs in the us-west-1, 
- The target bucket is located on the us-west-1
- The Snowflake open catalog is located on us-west-2

When I use the Iceberg client to create an Iceberg table, it throws the following exception
```
org.apache.iceberg.exceptions.ServiceFailureException: Server error: S3Exception: The bucket you are attempting to access must be addressed using the specified endpoint. Please send all future requests to this endpoint. (Service: S3, Status Code: 301,
```

Do I need to deploy the Snowflake open catalog in the same region as the target bucket?
@adutra ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6aTnYM/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/625,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6aXCkD,polaris,2589731075,625,NA,snazy,957468,Robert Stupp,,NA,2025-01-14T12:00:45Z,2025-01-14T12:00:45Z,@hangc0276 this is the issue tracker for Apache Polaris. Support for any commercial product has to go to the respective vendor.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6aXCkD/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/634,https://api.github.com/repos/apache/polaris/issues/634,polaris,2779216758,634,Action Required: Fix Renovate Configuration,forking-renovate,,,,CLOSED,2025-01-10T03:51:07Z,2025-01-10T08:52:24Z,"There is an error with this repository's Renovate configuration that needs to be fixed. As a precaution, Renovate will stop PRs until it is resolved.

Location: `renovate.json`
Error type: Invalid JSON (parsing failed)
Message: Syntax error near /*
 * Lice
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/634/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/634,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Z4v58,polaris,2581790332,634,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2025-01-10T05:11:59Z,2025-01-10T05:11:59Z,I'm fixing the renovate.json. ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6Z4v58/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/642,https://api.github.com/repos/apache/polaris/issues/642,polaris,2779625070,642,Dependency Dashboard,forking-renovate,,,,OPEN,2025-01-10T08:53:33Z,2025-02-09T00:34:28Z,"This issue lists Renovate updates and detected dependencies. Read the [Dependency Dashboard](https://docs.renovatebot.com/key-concepts/dashboard/) docs to learn more.

## Config Migration Needed

 - [ ] <!-- create-config-migration-pr --> Select this checkbox to let Renovate create an automated Config Migration PR.

## Awaiting Schedule

These updates are awaiting their schedule. Click on a checkbox to get an update now.

 - [ ] <!-- unschedule-branch=renovate/main/aws-java-sdk-v2-monorepo -->main: Update dependency software.amazon.awssdk:bom to v2.30.16

## Open

These updates have all been created already. Click a checkbox below to force a retry/rebase of any.

 - [ ] <!-- rebase-branch=renovate/main/pin-dependencies -->[main: Pin dependencies](../pull/637) (`actions/checkout`, `actions/setup-java`, `actions/upload-artifact`, `azure/setup-helm`, `gaurav-nelson/github-action-markdown-link-check`, `helm/chart-testing-action`, `medyagh/setup-minikube`)
 - [ ] <!-- rebase-branch=renovate/main/boto3-1.x -->[main: Update dependency boto3 to v1.36.16](../pull/926)
 - [ ] <!-- rebase-branch=renovate/main/com.github.spotbugs-spotbugs-annotations-4.x -->[main: Update dependency com.github.spotbugs:spotbugs-annotations to v4.9.1](../pull/973)
 - [ ] <!-- rebase-branch=renovate/main/medyagh-setup-minikube-0.x -->[main: Update medyagh/setup-minikube action to v0.0.19](../pull/855)
 - [ ] <!-- rebase-branch=renovate/main/opentelemetry-java-monorepo -->[main: Update dependency io.opentelemetry:opentelemetry-bom to v1.47.0](../pull/965)
 - [ ] <!-- rebase-branch=renovate/main/mypy-1.x -->[main: Update dependency mypy to v1.15.0](../pull/946)
 - [ ] <!-- rebase-branch=renovate/main/helm-chart-testing-action-2.x -->[main: Update helm/chart-testing-action action to v2.7.0](../pull/826)
 - [ ] <!-- rebase-branch=renovate/main/urllib3-2.x -->[main: Update dependency urllib3 to v2.3.0](../pull/696)
 - [ ] <!-- rebase-all-open-prs -->**Click on this checkbox to rebase all open PRs at once**

## Ignored or Blocked

These are blocked by an existing closed PR and will not be recreated unless you click a checkbox below.

 - [ ] <!-- recreate-branch=renovate/main/org.antlr-antlr4-runtime-4.x -->[main: Update dependency org.antlr:antlr4-runtime to v4.13.2](../pull/730)
 - [ ] <!-- recreate-branch=renovate/main/scala212 -->[main: Update scala212 to v2.13.16](../pull/746) (`org.scala-lang:scala-reflect`, `org.scala-lang:scala-library`)
 - [ ] <!-- recreate-branch=renovate/main/poetry-2.x -->[main: Update dependency poetry to v2](../pull/873)

## Detected dependencies

<details><summary>docker-compose</summary>
<blockquote>

<details><summary>getting-started/eclipselink/docker-compose.yml</summary>

 - `postgres 17.2`
 - `apache/spark 3.5.4-java17-python3`

</details>

<details><summary>getting-started/spark/docker-compose.yml</summary>


</details>

<details><summary>getting-started/telemetry/docker-compose.yml</summary>

 - `docker.io/prom/prometheus v3.1.0`
 - `docker.io/jaegertracing/all-in-one 1.66.0`

</details>

<details><summary>getting-started/trino/docker-compose.yml</summary>


</details>

<details><summary>regtests/docker-compose.yml</summary>


</details>

<details><summary>site/docker/docker-compose-hugo.yml</summary>


</details>

<details><summary>site/docker/docker-compose-publish.yml</summary>


</details>

</blockquote>
</details>

<details><summary>dockerfile</summary>
<blockquote>

<details><summary>getting-started/spark/notebooks/Dockerfile</summary>


</details>

<details><summary>quarkus/admin/src/main/docker/Dockerfile.jvm</summary>

 - `registry.access.redhat.com/ubi9/openjdk-21 1.21-3.1738663154`

</details>

<details><summary>quarkus/server/src/main/docker/Dockerfile.jvm</summary>

 - `registry.access.redhat.com/ubi9/openjdk-21 1.21-3.1738663154`

</details>

<details><summary>regtests/Dockerfile</summary>

 - `docker.io/apache/spark 3.5.4-java17-python3`

</details>

<details><summary>site/docker/Dockerfile</summary>

 - `ubuntu 24.04`

</details>

</blockquote>
</details>

<details><summary>github-actions</summary>
<blockquote>

<details><summary>.github/workflows/check-md-link.yml</summary>

 - `actions/checkout master`
 - `gaurav-nelson/github-action-markdown-link-check v1`

</details>

<details><summary>.github/workflows/gradle.yml</summary>

 - `actions/checkout v4`
 - `actions/setup-java v4`
 - `gradle/actions v4@94baf225fe0a508e581a564467443d0e2379123b`
 - `actions/upload-artifact v4`
 - `actions/setup-java v4`
 - `actions/upload-artifact v4`

</details>

<details><summary>.github/workflows/helm.yml</summary>

 - `actions/checkout v4`
 - `actions/setup-java v4`
 - `azure/setup-helm v4.2.0`
 - `helm/chart-testing-action v2.6.1`
 - `medyagh/setup-minikube v0.0.18`

</details>

<details><summary>.github/workflows/regtest.yml</summary>

 - `actions/checkout v4`
 - `actions/setup-java v4`

</details>

<details><summary>.github/workflows/site.yml</summary>

 - `actions/checkout v4`
 - `actions/checkout v4`
 - `peaceiris/actions-gh-pages v4@4f9cc6602d3f66b9c108549d475ec49e8ef4d45e`

</details>

<details><summary>.github/workflows/stale.yml</summary>

 - `actions/stale ee7ef89499a3de6e4fe1fc1acb994e67c64e0a2a`
 - `ubuntu 24.04`

</details>

<details><summary>regtests/client/python/.github/workflows/python.yml</summary>

 - `actions/checkout v4@11bd71901bbe5b1630ceea73d27597364c9af683`
 - `actions/setup-python v5@42375524e23c412d93fb67b49958b491fce71c38`

</details>

</blockquote>
</details>

<details><summary>gitlabci</summary>
<blockquote>

<details><summary>regtests/client/python/.gitlab-ci.yml</summary>

 - `python 3.13-alpine`
 - `python 3.13-alpine`
 - `python 3.13-alpine`
 - `python 3.13-alpine`
 - `python 3.13-alpine`

</details>

</blockquote>
</details>

<details><summary>gomod</summary>
<blockquote>

<details><summary>site/go.mod</summary>

 - `go 1.22.2`

</details>

</blockquote>
</details>

<details><summary>gradle</summary>
<blockquote>

<details><summary>gradle.properties</summary>


</details>

<details><summary>settings.gradle.kts</summary>


</details>

<details><summary>build.gradle.kts</summary>


</details>

<details><summary>aggregated-license-report/build.gradle.kts</summary>


</details>

<details><summary>api/iceberg-service/build.gradle.kts</summary>


</details>

<details><summary>api/management-model/build.gradle.kts</summary>


</details>

<details><summary>api/management-service/build.gradle.kts</summary>


</details>

<details><summary>build-logic/settings.gradle.kts</summary>


</details>

<details><summary>build-logic/build.gradle.kts</summary>


</details>

<details><summary>build-logic/src/main/kotlin/polaris-client.gradle.kts</summary>


</details>

<details><summary>build-logic/src/main/kotlin/polaris-java.gradle.kts</summary>


</details>

<details><summary>build-logic/src/main/kotlin/polaris-license-report.gradle.kts</summary>


</details>

<details><summary>build-logic/src/main/kotlin/polaris-quarkus.gradle.kts</summary>


</details>

<details><summary>build-logic/src/main/kotlin/polaris-root.gradle.kts</summary>


</details>

<details><summary>build-logic/src/main/kotlin/polaris-server.gradle.kts</summary>


</details>

<details><summary>build-logic/src/main/kotlin/polaris-shadow-jar.gradle.kts</summary>


</details>

<details><summary>extension/persistence/eclipselink/build.gradle.kts</summary>


</details>

<details><summary>extension/persistence/jpa-model/build.gradle.kts</summary>


</details>

<details><summary>gradle/baselibs.versions.toml</summary>

 - `net.ltgt.gradle:gradle-errorprone-plugin 4.1.0`
 - `gradle.plugin.org.jetbrains.gradle.plugin.idea-ext:gradle-idea-ext 1.1.10`
 - `com.github.jk1:gradle-license-report 2.9`
 - `io.github.gradle-nexus:publish-plugin 2.0.0`
 - `com.gradleup.shadow:shadow-gradle-plugin 8.3.6`
 - `com.diffplug.spotless:spotless-plugin-gradle 7.0.2`

</details>

<details><summary>gradle/libs.versions.toml</summary>

 - `org.antlr:antlr4-runtime 4.9.3`
 - `org.assertj:assertj-core 3.27.3`
 - `com.auth0:java-jwt 4.5.0`
 - `software.amazon.awssdk:bom 2.30.14`
 - `com.azure:azure-sdk-bom 1.2.31`
 - `org.bouncycastle:bcprov-jdk18on 1.80`
 - `com.github.ben-manes.caffeine:caffeine 3.2.0`
 - `commons-codec:commons-codec 1.18.0`
 - `org.apache.commons:commons-lang3 3.17.0`
 - `org.apache.commons:commons-text 1.13.0`
 - `org.eclipse.persistence:eclipselink 4.0.5`
 - `com.google.errorprone:error_prone_core 2.36.0`
 - `com.google.cloud:google-cloud-storage-bom 2.48.1`
 - `com.google.guava:guava 33.4.0-jre`
 - `com.h2database:h2 2.3.232`
 - `dnsjava:dnsjava 3.6.3`
 - `org.apache.hadoop:hadoop-client-api 3.4.1`
 - `org.apache.hadoop:hadoop-client-runtime 3.4.1`
 - `org.apache.hadoop:hadoop-common 3.4.1`
 - `org.apache.hadoop:hadoop-hdfs-client 3.4.1`
 - `org.hawkular.agent:prometheus-scraper 0.23.0.Final`
 - `org.immutables:builder 2.10.1`
 - `org.immutables:value-annotations 2.10.1`
 - `org.immutables:value-processor 2.10.1`
 - `org.apache.iceberg:iceberg-bom 1.7.1`
 - `com.fasterxml.jackson:jackson-bom 2.18.2`
 - `jakarta.annotation:jakarta.annotation-api 3.0.0`
 - `jakarta.enterprise:jakarta.enterprise.cdi-api 4.1.0`
 - `jakarta.inject:jakarta.inject-api 2.0.1`
 - `jakarta.persistence:jakarta.persistence-api 3.2.0`
 - `jakarta.servlet:jakarta.servlet-api 6.1.0`
 - `jakarta.validation:jakarta.validation-api 3.1.1`
 - `jakarta.ws.rs:jakarta.ws.rs-api 4.0.0`
 - `javax.servlet:javax.servlet-api 4.0.1`
 - `org.jetbrains:annotations 26.0.2`
 - `org.junit:junit-bom 5.11.4`
 - `ch.qos.logback:logback-classic 1.5.16`
 - `io.micrometer:micrometer-bom 1.14.3`
 - `org.mockito:mockito-core 5.15.2`
 - `org.mockito:mockito-junit-jupiter 5.15.2`
 - `io.opentelemetry:opentelemetry-bom 1.46.0`
 - `io.opentelemetry.semconv:opentelemetry-semconv 1.25.0-alpha`
 - `info.picocli:picocli-codegen 4.7.6`
 - `org.postgresql:postgresql 42.7.5`
 - `io.prometheus:prometheus-metrics-exporter-servlet-jakarta 1.3.5`
 - `io.quarkus.platform:quarkus-bom 3.18.2`
 - `org.scala-lang:scala-library 2.12.19`
 - `org.scala-lang:scala-reflect 2.12.19`
 - `com.adobe.testing:s3mock-testcontainers 3.12.0`
 - `org.slf4j:slf4j-api 2.0.16`
 - `io.smallrye.common:smallrye-common-annotation 2.9.0`
 - `io.smallrye.config:smallrye-config-core 3.11.2`
 - `org.apache.spark:spark-sql_2.12 3.5.4`
 - `com.github.spotbugs:spotbugs-annotations 4.9.0`
 - `io.swagger:swagger-annotations 1.6.15`
 - `io.swagger:swagger-jaxrs 1.6.15`
 - `org.testcontainers:testcontainers-bom 1.20.4`
 - `org.threeten:threeten-extra 1.8.0`
 - `org.kordamp.gradle.jandex 2.1.0`
 - `org.openapi.generator 7.11.0`
 - `io.quarkus 3.18.2`
 - `org.nosphere.apache.rat 0.8.1`

</details>

<details><summary>integration-tests/build.gradle.kts</summary>

 - `org.apache.spark:spark-sql_2.12 3.5.4`

</details>

<details><summary>polaris-core/build.gradle.kts</summary>

 - `io.airlift:aircompressor 2.0.2`
 - `org.xerial.snappy:snappy-java 1.1.10.7`
 - `org.codehaus.jettison:jettison 1.5.4`
 - `org.apache.commons:commons-configuration2 2.11.0`
 - `org.apache.commons:commons-compress 1.27.1`
 - `com.nimbusds:nimbus-jose-jwt 10.0.1`
 - `io.netty:netty-codec-http2 4.1.117.Final`
 - `io.projectreactor.netty:reactor-netty-http 1.2.2`

</details>

<details><summary>quarkus/admin/build.gradle.kts</summary>


</details>

<details><summary>quarkus/defaults/build.gradle.kts</summary>


</details>

<details><summary>quarkus/server/build.gradle.kts</summary>


</details>

<details><summary>quarkus/service/build.gradle.kts</summary>


</details>

<details><summary>service/common/build.gradle.kts</summary>


</details>

<details><summary>tools/config-docs/annotations/build.gradle.kts</summary>


</details>

<details><summary>tools/config-docs/generator/build.gradle.kts</summary>


</details>

<details><summary>tools/config-docs/site/build.gradle.kts</summary>


</details>

<details><summary>tools/container-spec-helper/build.gradle.kts</summary>


</details>

<details><summary>tools/immutables/build.gradle.kts</summary>


</details>

<details><summary>tools/version/build.gradle.kts</summary>


</details>

</blockquote>
</details>

<details><summary>gradle-wrapper</summary>
<blockquote>

<details><summary>gradle/wrapper/gradle-wrapper.properties</summary>

 - `gradle 8.12.1`

</details>

</blockquote>
</details>

<details><summary>helm-values</summary>
<blockquote>

<details><summary>helm/polaris/values.yaml</summary>


</details>

</blockquote>
</details>

<details><summary>pep621</summary>
<blockquote>

<details><summary>regtests/client/python/pyproject.toml</summary>


</details>

</blockquote>
</details>

<details><summary>pip_requirements</summary>
<blockquote>

<details><summary>regtests/requirements.txt</summary>

 - `poetry ==1.8.5`

</details>

</blockquote>
</details>

<details><summary>pip_setup</summary>
<blockquote>

<details><summary>regtests/client/python/setup.py</summary>

 - `urllib3 >= 1.25.3, < 2.1.0`
 - `pydantic >= 2`
 - `typing-extensions >= 4.7.1`

</details>

</blockquote>
</details>

<details><summary>poetry</summary>
<blockquote>

<details><summary>regtests/client/python/pyproject.toml</summary>

 - `python ^3.8`
 - `urllib3 ^1.25.3`
 - `python-dateutil >=2.8.2`
 - `pydantic >=2`
 - `typing-extensions >=4.7.1`
 - `boto3 ==1.36.10`
 - `pytest >=7.2.1`
 - `flake8 >=4.0.0`
 - `types-python-dateutil >=2.8.19.14`
 - `mypy 1.14.1`

</details>

</blockquote>
</details>

---

- [ ] <!-- manual job -->Check this box to trigger a request for Renovate to run again on this repository

","{""url"": ""https://api.github.com/repos/apache/polaris/issues/642/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/648,https://api.github.com/repos/apache/polaris/issues/648,polaris,2779684553,648,Document release process and how to verify a release,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,OPEN,2025-01-10T09:21:46Z,2025-01-11T05:50:38Z,"As discussed during the community meeting, I will add (on the website):
1. How to do a release (adding a script as well) and what's the process (between PPMC and IPMC)
2. How to verify a release (adding a script as well)","{""url"": ""https://api.github.com/repos/apache/polaris/issues/648/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/649,https://api.github.com/repos/apache/polaris/issues/649,polaris,2779689169,649,Add JDBC persistence backend,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,OPEN,2025-01-10T09:23:41Z,2025-01-27T13:37:19Z,"As discussed during the Polaris Community Meeting, I will add a new plugin implementing JDBC storage backend, without Eclipselink and focusing on PostgreSQL.
It will use ""purely"" JDBC DataSources with DBCP2 connection pooling.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/649/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/649,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bbXNd,polaris,2607641437,649,NA,jackye1995,29823233,Jack Ye,jackye@dataolympia.com,NA,2025-01-22T16:02:55Z,2025-01-22T16:02:55Z,"Based on #766 , the JDBC connection needs to support SERIALIZABLE isolation. This would allow a few scalable distributed backend options like CockroachDB and Google Spanner beyond single node SQL engines that could become a bottleneck.  

Unfortunately the equivalent product in AWS - Amazon Aurora DSQL, only supports REPEATABLE READ as of today... ðŸ˜¢ ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bbXNd/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/649,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bbf59,polaris,2607677053,649,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2025-01-22T16:16:50Z,2025-01-22T16:16:50Z,"That's a good point.

If it should work fine for JDBC, I don't think we should limit/focus only on JDBC in Polaris. We have to support also NoSQL.
If we have to change the Polaris data model to support NoSQL, we should discuss about it now, because, it means that we will have to refactore JDBC plugin to support a new data model.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bbf59/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/649,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bbkAx,polaris,2607693873,649,NA,jackye1995,29823233,Jack Ye,jackye@dataolympia.com,NA,2025-01-22T16:23:32Z,2025-01-22T16:23:32Z,"> We have to support also NoSQL.

Can you explain more about the background on this?

If we want to support both SQL and noSQL, we probably need to create a broad interface that can be implemented by both SQL and noSQL in drastically different ways. I was a bit out of date with where the community is right now, are we acceptable to such change?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bbkAx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/649,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6b6bdL,polaris,2615785291,649,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2025-01-27T13:37:18Z,2025-01-27T13:37:18Z,"@jackye1995 I mean that the Polaris data model should allow us to support both SQL and NoSQL backend. The purpose of this issue, the #650 and #844 is to identify the changes needed on the current data model.
So, I propose to work on a doc with:
* problem statement (what are the blockers/issues with the current Polaris data model to support both SQL and NoSQL backends)
* proposals (what the minimal changes needed on the model to support both SQL and NoSQL)

The reason why I think it's important to discuss this today is because it's central to Polaris and any change later will mean to ""refactore"" the backend plugins.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6b6bdL/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/650,https://api.github.com/repos/apache/polaris/issues/650,polaris,2779692152,650,Add MongoDB persistence backend,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,OPEN,2025-01-10T09:25:14Z,2025-01-15T12:01:00Z,"As discussed during the last Polaris Community Meeting, we will add a persistence backend plugin using MongoDB.
The purpose is to identify the updates that should be done on the persistence model to work with NoSQL backend.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/650/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/650,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ah2yt,polaris,2592566445,650,NA,snazy,957468,Robert Stupp,,NA,2025-01-15T12:00:59Z,2025-01-15T12:00:59Z,"I've been looking through the Polaris code base on how this effort is achievable and the result is not satisfying.
There are a bunch of issues, for example #775, #766, #763, that currently prevent this effort. I suspect there is a lot of work to be done before this effort can actually be started.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ah2yt/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/727,https://api.github.com/repos/apache/polaris/issues/727,polaris,2786639369,727,"Make and keep production and test code working with ""up to date"" Java versions",snazy,957468,Robert Stupp,,OPEN,2025-01-14T09:19:39Z,2025-01-14T09:19:52Z,"### Describe the bug

Polaris, as a server, should be able run run recent Java versions for various reasons (GC improvements, heap usage improvements, OS integration improvements, etc etc etc).

""Client"" libraries (think: Iceberg, Spark, Hadoop) however are known to cause problems with ""newest"" Java versions and/or recent library versions for various reasons.

Polaris relies on Hadoop and Spark for its tests and we are therefore limited to only run on Java versions that those libraries support / work with. It usually takes a lot of time until all these libraries are all compatible with ""newer"" Java versions - often lagging behind a few Java versions.

## Goals

1. Tests should not rely on Hadoop or Spark, at best not even Iceberg, but only on Polaris code
2. If tests (think: integration tests) really need Hadoop and/or Spark, those should run separately using a ""compatible"" Java version to allow Polaris to leverage modern Java versions.

## Polaris tests using Hadoop fail with Java 23

Background: The whole Java `SecurityManager` stuff was deprecated in Java 17 via [JEP 411](https://openjdk.org/jeps/411) (April 2021). Alternatives (`Subject.getSubject()` --> `Subject.current()`) have been [introduced with Java 18](https://bugs.openjdk.org/browse/JDK-8267108).

[JEP 486](https://openjdk.org/jeps/486) is about to _permanently_ disable the security manager, even the workaround to set `java.security.manager=allow` will not work beginning with Java 24 (the JVM won't start).

There's [HADOOP-19212](https://issues.apache.org/jira/browse/HADOOP-19212) (opened June 2024) with sadly rather [stale PR](https://github.com/apache/hadoop/pull/7081).

Workaround for Java 23: #723
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/727/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/729,https://api.github.com/repos/apache/polaris/issues/729,polaris,2786777410,729,Let Polaris use UTC as the only time source on the server side,snazy,957468,Robert Stupp,,CLOSED,2025-01-14T10:26:41Z,2025-01-14T11:17:23Z,"### Describe the bug

Time zone can be confusing and influence date/time based calculations.
Polaris uses [`Clock.system(ZoneId.systemDefault())`](https://github.com/apache/polaris/blob/1868bbd7fac369bea9cd47cd85e478841e29c8c3/polaris-core/src/main/java/org/apache/polaris/core/PolarisCallContext.java#L58), which can cause all kinds of time/date/zone related issues.

### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/729/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/749,https://api.github.com/repos/apache/polaris/issues/749,polaris,2788067012,749,Isolate PolarisSparkIntegrationTest,adutra,463876,Alexandre Dutra,,OPEN,2025-01-14T18:58:17Z,2025-01-15T16:38:29Z,"### Is your feature request related to a problem? Please describe.

This test imports a bunch of `org.apache.spark.*` classes and because of that, causes trouble with dependencies:

```kotlin
  // required for PolarisSparkIntegrationTest
  testImplementation(enforcedPlatform(libs.scala212.lang.library))
  testImplementation(enforcedPlatform(libs.scala212.lang.reflect))
  testImplementation(libs.javax.servlet.api)
  testImplementation(libs.antlr4.runtime)
```

The above dependences, and in particular Antlr, prevents us from using `enforcedPlatform` on Quarkus BOM.

### Describe the solution you'd like

We need to isolate this test in its own configuration and/or module.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/749/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/749,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6acm7h,polaris,2591190753,749,NA,dimas-b,40603221,Dmitri Bourlatchkov,,NA,2025-01-14T22:00:07Z,2025-01-14T22:00:07Z,"`PolarisSparkIntegrationTest` is already in a dedicated module (`integration-tests`). Perhaps if we converted its execution to use `@QuarkusIntegrationTest`, the class path issues would be resolved (no ClassLoader sharing between tests and servers)? ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6acm7h/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/749,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ag-_y,polaris,2592337906,749,NA,adutra,463876,Alexandre Dutra,,NA,2025-01-15T10:59:36Z,2025-01-15T10:59:36Z,"> `PolarisSparkIntegrationTest` is already in a dedicated module (`integration-tests`). Perhaps if we converted its execution to use `@QuarkusIntegrationTest`, the class path issues would be resolved (no ClassLoader sharing between tests and servers)?

I _think_ we would still have the dependency version mismatch issue, and Antlr would have to stay pinned to 4.9.3, which isn't great.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ag-_y/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/749,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6alErM,polaris,2593409740,749,NA,snazy,957468,Robert Stupp,,NA,2025-01-15T16:38:02Z,2025-01-15T16:38:02Z,"Could also use #785 to start a ""real"" Polaris server and run the tests against that one.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6alErM/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/750,https://api.github.com/repos/apache/polaris/issues/750,polaris,2788071079,750,Import Quarkus BOM with enforcedPlatform everywhere,adutra,463876,Alexandre Dutra,,OPEN,2025-01-14T19:00:43Z,2025-01-14T19:00:43Z,"### Describe the bug

Similar to #739, we should use `enforcedPlatform` consistently in all modules. But that is currently blocked by #749 and we can't do it for `polaris-quarkus-service`.

### To Reproduce

_No response_

### Actual Behavior

When attempting to run `quarkusRun` from `polaris-quarkus-service` without `enforcedPlatform`, we get mixed versions of some artifacts like the OpenTelemetry ones.

The typical error message is:

```
2025-01-14 09:28:33,370 ERROR [io.qua.run.Application] [,] [,,,] (main) Failed to start application: java.lang.RuntimeException: Failed to start quarkus
	at io.quarkus.runner.ApplicationImpl.doStart(Unknown Source)
	at io.quarkus.runtime.Application.start(Application.java:101)
	at io.quarkus.runtime.ApplicationLifecycleManager.run(ApplicationLifecycleManager.java:121)
	at io.quarkus.runtime.Quarkus.run(Quarkus.java:71)
	at io.quarkus.runtime.Quarkus.run(Quarkus.java:44)
	at io.quarkus.runtime.Quarkus.run(Quarkus.java:124)
	at io.quarkus.runner.GeneratedMain.main(Unknown Source)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at io.quarkus.bootstrap.runner.QuarkusEntryPoint.doRun(QuarkusEntryPoint.java:62)
	at io.quarkus.bootstrap.runner.QuarkusEntryPoint.main(QuarkusEntryPoint.java:33)
Caused by: java.lang.NoClassDefFoundError: io/opentelemetry/sdk/metrics/internal/export/CardinalityLimitSelector
	at io.opentelemetry.sdk.autoconfigure.MeterProviderConfiguration.lambda$configureMeterProvider$1(MeterProviderConfiguration.java:65)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at io.opentelemetry.sdk.autoconfigure.MeterProviderConfiguration.configureMeterProvider(MeterProviderConfiguration.java:63)
	at io.opentelemetry.sdk.autoconfigure.AutoConfiguredOpenTelemetrySdkBuilder.build(AutoConfiguredOpenTelemetrySdkBuilder.java:452)
	at io.quarkus.opentelemetry.runtime.OpenTelemetryRecorder$1.apply(OpenTelemetryRecorder.java:81)
	at io.quarkus.opentelemetry.runtime.OpenTelemetryRecorder$1.apply(OpenTelemetryRecorder.java:54)
	at io.opentelemetry.api.OpenTelemetry_Le6zQbzkojAYO_OiKIQWJf4lGa4_Synthetic_Bean.createSynthetic(Unknown Source)
	at io.opentelemetry.api.OpenTelemetry_Le6zQbzkojAYO_OiKIQWJf4lGa4_Synthetic_Bean.doCreate(Unknown Source)
	at io.opentelemetry.api.OpenTelemetry_Le6zQbzkojAYO_OiKIQWJf4lGa4_Synthetic_Bean.create(Unknown Source)
	at io.opentelemetry.api.OpenTelemetry_Le6zQbzkojAYO_OiKIQWJf4lGa4_Synthetic_Bean.create(Unknown Source)
	at io.quarkus.arc.impl.AbstractSharedContext.createInstanceHandle(AbstractSharedContext.java:119)
	at io.quarkus.arc.impl.AbstractSharedContext$1.get(AbstractSharedContext.java:38)
	at io.quarkus.arc.impl.AbstractSharedContext$1.get(AbstractSharedContext.java:35)
	at io.quarkus.arc.impl.LazyValue.get(LazyValue.java:32)
	at io.quarkus.arc.impl.ComputingCache.computeIfAbsent(ComputingCache.java:69)
	at io.quarkus.arc.impl.ComputingCacheContextInstances.computeIfAbsent(ComputingCacheContextInstances.java:19)
	at io.quarkus.arc.impl.AbstractSharedContext.get(AbstractSharedContext.java:35)
	at io.opentelemetry.api.OpenTelemetry_Le6zQbzkojAYO_OiKIQWJf4lGa4_Synthetic_Bean.get(Unknown Source)
	at io.opentelemetry.api.OpenTelemetry_Le6zQbzkojAYO_OiKIQWJf4lGa4_Synthetic_Bean.get(Unknown Source)
	at io.quarkus.arc.impl.InstanceImpl.getBeanInstance(InstanceImpl.java:325)
	at io.quarkus.arc.impl.InstanceImpl.getInternal(InstanceImpl.java:309)
	at io.quarkus.arc.impl.InstanceImpl.get(InstanceImpl.java:190)
	at io.quarkus.arc.runtime.BeanContainerImpl.beanInstance(BeanContainerImpl.java:26)
	at io.quarkus.opentelemetry.runtime.tracing.intrumentation.InstrumentationRecorder.setupVertxTracer(InstrumentationRecorder.java:59)
	at io.quarkus.deployment.steps.OpenTelemetryProcessor$setupVertx1012958309.deploy_0(Unknown Source)
	at io.quarkus.deployment.steps.OpenTelemetryProcessor$setupVertx1012958309.deploy(Unknown Source)
	... 11 more
Caused by: java.lang.ClassNotFoundException: io.opentelemetry.sdk.metrics.internal.export.CardinalityLimitSelector
	at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)
	at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:526)
	at io.quarkus.bootstrap.runner.RunnerClassLoader.loadClass(RunnerClassLoader.java:114)
	at io.quarkus.bootstrap.runner.RunnerClassLoader.loadClass(RunnerClassLoader.java:72)
	... 37 more
```

### Expected Behavior

We should be able to run `quarkusRun` from `polaris-quarkus-service` without errors.

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/750/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/755,https://api.github.com/repos/apache/polaris/issues/755,polaris,2789084938,755,Generated files in `regtests/client/python/polaris`,snazy,957468,Robert Stupp,,OPEN,2025-01-15T07:57:26Z,2025-01-15T07:57:34Z,"### Describe the bug

The Python client sources in `regtests/client/python/polaris/` contain generated files, which do not seem to be in sync with the definitions in `spec/`.

Generated files _can_ be in that source tree, but should
a) be `.gitignore`d and
b) be (automatically) generated
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/755/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/756,https://api.github.com/repos/apache/polaris/issues/756,polaris,2789087913,756,"""Polaris client"" should be moved",snazy,957468,Robert Stupp,,OPEN,2025-01-15T07:59:10Z,2025-02-03T02:35:18Z,"### Describe the bug

The Python client is currently located in `regtests/client/`, which implies that it is only used for regression tests, which is not the case.

I propose to move it to another location, for example `client/python/`.
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/756/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/756,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bD7fP,polaris,2601498575,756,NA,PURVANGIKA,178074689,Purvangika kanwar,,NA,2025-01-20T06:49:30Z,2025-01-20T06:49:30Z,"Steps to Relocate the Python Client
Create New Directory:
Create client/python/ to house the Python client.

Move Files:
Move all files from regtests/client/ to client/python/.

bash
Copy
Edit
mv regtests/client/* client/python/
Update References:
Update imports (regtests.client â†’ client.python) across the codebase and documentation.

Verify Tests:
Update test configurations if necessary and run all tests to confirm functionality.

Check Build Scripts:
Update paths in build scripts, CI/CD workflows, or Dockerfiles.

Optional Symlink:
Add a symlink (ln -s client/python regtests/client) for backward compatibility, if required.

Communicate Change:
Update team, release notes, and documentation about the new directory structure.

Code Review:
Submit a pull request for review, merge, and deploy after approval.

This ensures the Python client is better organized without breaking functionality.














","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bD7fP/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/756,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cq5j1,polaris,2628491509,756,NA,MonkeyCanCode,29619290,,,NA,2025-01-31T22:16:18Z,2025-01-31T22:16:18Z,"@snazy are we good to take this one? If no one is working on this yet, I can take this up. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cq5j1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/756,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6csqMe,polaris,2628952862,756,NA,vedansh-5,77830698,Vedansh Saini,,NA,2025-02-01T13:25:07Z,2025-02-01T13:25:07Z,"@snazy  Iâ€™m fairly new to the open-source community and noticed that this issue doesnâ€™t have an assignee yet. If no one else is working on it, could you please assign it to me?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6csqMe/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/756,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cvwgJ,polaris,2629765129,756,NA,MonkeyCanCode,29619290,,,NA,2025-02-03T02:35:17Z,2025-02-03T02:35:17Z,"> [@snazy](https://github.com/snazy) Iâ€™m fairly new to the open-source community and noticed that this issue doesnâ€™t have an assignee yet. If no one else is working on it, could you please assign it to me?

Assigned. Thanks for helping on this.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cvwgJ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/757,https://api.github.com/repos/apache/polaris/issues/757,polaris,2789097775,757,Wrong project and license in `pyproject.toml`,snazy,957468,Robert Stupp,,CLOSED,2025-01-15T08:04:11Z,2025-01-20T10:25:15Z,"### Describe the bug

The contents of `regtests/client/python/pyproject.toml` contains

```toml
[tool.poetry]
name = ""polaris""
version = ""1.0.0""
description = ""Polaris Management Service""
authors = [""OpenAPI Generator Community <team@openapitools.org>""]
license = ""NoLicense""
readme = ""README.md""
repository = ""https://github.com/GIT_USER_ID/GIT_REPO_ID""
keywords = [""OpenAPI"", ""OpenAPI-Generator"", ""Polaris Management Service""]
include = [""polaris.management/py.typed""]
```

which has wrong values for authors, license, repository, keywords.
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/757/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/757,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a0ZVv,polaris,2597426543,757,NA,MonkeyCanCode,29619290,,,NA,2025-01-17T04:46:20Z,2025-01-17T04:46:20Z,Sample PR: https://github.com/apache/polaris/pull/812,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a0ZVv/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/758,https://api.github.com/repos/apache/polaris/issues/758,polaris,2789107319,758,"Tests should not ""spam"" system directories",snazy,957468,Robert Stupp,,OPEN,2025-01-15T08:09:24Z,2025-01-16T14:43:07Z,"### Describe the bug

Some tests write test data to the system global `/tmp`:
```
/tmp/buckets
/tmp/ns
/tmp/ns1
/tmp/PolarisOverlappingTableTest
/tmp/test-private*.pem
/tmp/test-public*.pem
```

This is bad practice and should be replaced with JUnit's `@TempDir`. It can also easily cause issues when tests are run repeatedly.
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/758/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/758,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6auoOb,polaris,2595914651,758,NA,snazy,957468,Robert Stupp,,NA,2025-01-16T14:43:06Z,2025-01-16T14:43:06Z,"This is a real issue causing false-positive test failures:
```
Caused by: org.apache.hadoop.fs.FileAlreadyExistsException: File already exists: file:/tmp/ns1/my_table/metadata/v1.metadata.json
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:559)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:597)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:633)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:721)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:700)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1233)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1210)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1091)
```
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6auoOb/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/759,https://api.github.com/repos/apache/polaris/issues/759,polaris,2789156572,759,`PolarisDiagnostics` issues,snazy,957468,Robert Stupp,,OPEN,2025-01-15T08:36:19Z,2025-01-17T06:57:56Z,"### Describe the bug

The only implementation of `PolarisDiagnostics` (`PolarisDefaultDiagServiceImpl`) has various issues:

* All functions that take `extraInfoFormat` and `extraInfoArgs` seem to accept a SLF4J-style formatting using `{}`, but the actual formatting relies on Guava's `Preconditions`, which only accepts `%s`. The formatted messages then read awkward: `something_went_wrong: id={} fileName={} [""a"", java.lang.Object@deadbeef]` due to the implementation
* The generated exception messages contain rather cryptic information (e.g. `unexpected_not_found_entity`) instead of a description that users can act on.
* Some functions say: ""Create a fatal incident if expression is false"" - but all the implementation does is calling `Preconditions.checkState()`
* Nit-ish maybe: some functions unnecessarily have a `throw new RuntimeException` after a `Preconditions.checkState(false, ...`

The current implementation is not really useful and emits no information/instructions that a user could act on (other than raising questions on a chat or open a GH issue).

These are some options:
1. replace all usages of `PolarisDiagnostics` with direct use of `Preconditions` / `Objects.requireNonNull` and eventually remove `PolarisDiagnostics` and its implementation
2. refactor `PolarisDiagnostics` and implement a proper mapping of error-codes to user consumable and act-able messages

Generally speaking (IMHO), the use of `PolarisDiagnostics` adds a lot of boilerplate code that makes it harder than necessary to read the code.
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/759/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/759,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ayoqA,polaris,2596964992,759,NA,collado-mike,40346148,Michael Collado,,NA,2025-01-16T21:47:48Z,2025-01-16T21:47:48Z,`PolarisDiagnostics` is an intentional extension point for tracking and reporting issues. Moving everything to Guava doesn't allow for collecting and reporting on those issues.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ayoqA/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/759,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ayo77,polaris,2596966139,759,NA,collado-mike,40346148,Michael Collado,,NA,2025-01-16T21:48:13Z,2025-01-16T21:48:13Z,Also not a bug. ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6ayo77/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/759,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a06M2,polaris,2597561142,759,NA,snazy,957468,Robert Stupp,,NA,2025-01-17T06:57:55Z,2025-01-17T06:57:55Z,"This ticket describes a UX issue, because the messages that users see are just cryptic, and therefore IMHO a bug and not an ""enhancement"" or ""improvement"". I'm definitely open for suggestions to remove the boilerplate code and expose user-actionable messages.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a06M2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/760,https://api.github.com/repos/apache/polaris/issues/760,polaris,2789186064,760,Eclipselink module not prepared for multiple realms,snazy,957468,Robert Stupp,,OPEN,2025-01-15T08:49:12Z,2025-01-15T08:49:12Z,"### Describe the bug

The current way of how Polaris uses databases for persistence is to encode the realm-ID in the JDBC connection URL - aka: one isolated database per realm.

On the other side, `org.apache.polaris.extension.persistence.impl.eclipselink.PolarisSequenceUtil` is global and static and it's `initialize()` function does not account the fact that there can be multiple realms.

### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/760/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/761,https://api.github.com/repos/apache/polaris/issues/761,polaris,2789240960,761,`EntityCache` leaks memory & prone to inconsistencies & race conditions,snazy,957468,Robert Stupp,,OPEN,2025-01-15T09:10:54Z,2025-01-16T07:57:56Z,"### Describe the bug

`org.apache.polaris.core.persistence.cache.EntityCache` uses two containers:

```java
  private final Cache<Long, EntityCacheEntry> byId;
  private final AbstractMap<EntityCacheByNameKey, EntityCacheEntry> byName;
```

The first one is a Caffeine cache, the second one is a Java Map.

`byName` can become inconsistent due to race conditions, multiple threads acting on the same entity IDs and/or entity names.
The implementation assumes, that there are no multi-threaded accesses against the same entity IDs and/or entity names, which is not guaranteed.

### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/761/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/761,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6aqOkV,polaris,2594760981,761,NA,ben-manes,378614,Ben Manes,ben.manes@gmail.com,NA,2025-01-16T07:57:54Z,2025-01-16T07:57:54Z,It looks like EntityCache uses a secondary lookup key. You might find the [IndexedCache](https://github.com/ben-manes/caffeine/tree/master/examples/indexable) example useful an alternative implementation of that approach.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6aqOkV/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/763,https://api.github.com/repos/apache/polaris/issues/763,polaris,2789352750,763,`PolarisEclipseLinkMetaStoreSessionImpl` violates `PolarisMetaStoreSession` contract,snazy,957468,Robert Stupp,,OPEN,2025-01-15T10:02:00Z,2025-01-15T10:02:00Z,"### Describe the bug

`PolarisEclipseLinkMetaStoreSessionImpl` uses a `ThreadLocal` containing a `EntityManager`. It is set and removed in all these `runInTransaction` functions.

Calling functions like `lookupEntity` directly on `PolarisMetaStoreSession` will result in a `NullPointerException`.
`PolarisMetaStoreSession` does not require calling `lookupEntity` via a `runInTransaction`, but instead [defines here](https://github.com/apache/polaris/blob/88994f495a844f420187b9404511504601081a1a/polaris-core/src/main/java/org/apache/polaris/core/persistence/PolarisMetaStoreSession.java#L45-L46): `The goal is to make it really easy to back this using databases like Postgres or simpler KV store.` - this is not the case, because it is implicitly required to use `runInTransaction` - but ""simpler"" KV stores do _*not*_ have transactions as in relational databases.

### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/763/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/766,https://api.github.com/repos/apache/polaris/issues/766,polaris,2789394341,766,Polaris persistence mandates the use of transactions & serializable isolation,snazy,957468,Robert Stupp,,OPEN,2025-01-15T10:19:29Z,2025-02-04T18:19:21Z,"### Describe the bug

Despite that `PolarisMetaStoreSession` [clearly says](https://github.com/apache/polaris/blob/88994f495a844f420187b9404511504601081a1a/polaris-core/src/main/java/org/apache/polaris/core/persistence/PolarisMetaStoreSession.java#L45-L46) that `it [is] really easy to back this using [...] simpler KV store.` the whole code architecture of everything around persistence in Polaris requires nothing less than (relational) transactions and strong consistency across multiple rows in multiple tables.

For example `org.apache.polaris.core.persistence.PolarisMetaStoreManagerImpl#writeEntity`:
```java
  private void writeEntity(
      @Nonnull PolarisMetaStoreSession ms,
      @Nonnull PolarisBaseEntity entity,
      boolean writeToActive) {
    ms.writeToEntities(entity);
    ms.writeToEntitiesChangeTracking(entity);

    if (writeToActive) {
      ms.writeToEntitiesActive(entity);
    }
  }
```
works against 2-3 different _rows_ in 2-3 different _tables_, requiring that all or none of the changes succeed - this is multiplied by the number of entities being written. On top it requires that entities being read before (existing and non-existing) did not change when the tx gets committed.

The ""pattern"" of having these different tables leaks into a lot of places. It effectively makes it rather impossible to use anything else than a relational database w/ isolation level `SERIALIZABLE`.

### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/766/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/766,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bm2Tl,polaris,2610652389,766,NA,dennishuo,7410123,Dennis Huo,,NA,2025-01-23T18:30:45Z,2025-01-23T18:30:45Z,"The current code structure probably exaggerates the expected transaction semantics needlessly, and a few minor adjustments should be able to significantly lighten the requirements. In particular:

1. Most of the independent one-shot reads happen to be structured as `runInReadTransaction` but aren't actually depending on transaction semantics
2. The `writeToEntities`, `writeToEntitiesChangeTracking`, `writeToEntitiesActive` triplet is actually more for serving the role of secondary indexes than truly being separate tables. There are caveats depending on how we approach vestigial plans for UNDROP functionality, but it's worth discussing whether these make sense to push down to the `MetaStoreSession` layer and even refactoring the EclipseLink one to better portray these as serving efficient queries on a single table
3. A few operations actually do uniquely require various flavors of transactions across multiple rows or tables; we should enumerate these separately from the majority of ""core"" actions. Of particular interest off the top of my head:
    a. CreateCatalog relationship to a ""storage integration"" object and bootstrapped CatalogRoles
    b. CreatePrincipal with ""principal secrets""
    c. Iceberg-level multi-table commit that uses updateEntitiesPropertiesIfNotChanged
    d. DropTable atomically adding a TaskEntity for cleanup (other DropEntity types as well technically, but the main non-trivial case is for file cleanup when PURGE=true)","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bm2Tl/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/766,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dCtls,polaris,2634733932,766,NA,dennishuo,7410123,Dennis Huo,,NA,2025-02-04T18:19:19Z,2025-02-04T18:19:19Z,"Wrote up some analysis and tentative proposal for the way forward that should get us pretty far with fairly minimal changes:

https://docs.google.com/document/d/1U9rprj8w8-Q0SnQvRMvoVlbX996z-89eOkVwWTQaZG0/edit?tab=t.0","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dCtls/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/767,https://api.github.com/repos/apache/polaris/issues/767,polaris,2789403565,767,Polaris persistence / unclear behavior when creating entites with the same name,snazy,957468,Robert Stupp,,OPEN,2025-01-15T10:23:46Z,2025-01-15T10:23:46Z,"### Describe the bug

I'm not sure whether Polaris persistence can ensure that no two entities (think: Iceberg tables & views) with the same name can ever exist.

The reason I'm bringing this up is the disconnect of the name resolution vs technical ID resolution.

It feels possible that two concurrent requests to e.g. create a new table pass the ""that name does not yet exist"" check and then both write new entities with the same name.

The name checks are only _programmatic_ checks against previous read operations - but there is nothing that technically prevents having duplicate names.

### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/767/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/770,https://api.github.com/repos/apache/polaris/issues/770,polaris,2789479685,770,`PolarisDiagnostics` leaks internal information,snazy,957468,Robert Stupp,,OPEN,2025-01-15T10:56:31Z,2025-01-15T10:56:31Z,"### Describe the bug

(Related to #759) `PolarisDiagnostics` can expose raw contents of an entity, including internal information.
The contents of those entities then ends in exception messages, which leak all the way down to users via HTTP responses and gets exposed to potentially external systems (logging / tracing).

### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/770/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/771,https://api.github.com/repos/apache/polaris/issues/771,polaris,2789487074,771,`CatalogEntity` includes storage specific logic,snazy,957468,Robert Stupp,,OPEN,2025-01-15T10:59:52Z,2025-01-15T10:59:52Z,"### Describe the bug

`CatalogEntity` should be a ""pure"" representation of a catalog, but includes storage specific logic. The same might be true for other entity types.

### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/771/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/772,https://api.github.com/repos/apache/polaris/issues/772,polaris,2789487550,772,Mutable objects used for immutable values,snazy,957468,Robert Stupp,,OPEN,2025-01-15T11:00:05Z,2025-01-15T11:00:05Z,"### Describe the bug

`PolarisEntityCore` type hierarchy is used to represent the persisted (or about to be persisted) state. Especially the already persisted state should be considered immutable. Instances of `PolarisEntityCore` are also cached via `org.apache.polaris.core.persistence.cache.EntityCacheEntry#entity`.

`PolarisEntityCore` + `PolarisBaseEntity` type hierarchy exposes _public_ setters for effectively all properties. This makes it very easy to (accidentally?) _modify_ entity instances that are cached or in any other way shared. Although the types have some ""copy constructors"", the risk of modifying attributes is still there. Even if a legit change to a property of a shared object would not be correct, given the Java memory model guarantees.

### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/772/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/773,https://api.github.com/repos/apache/polaris/issues/773,polaris,2789496047,773,Unnecessary overhead due to Jackson serialization in all entities,snazy,957468,Robert Stupp,,OPEN,2025-01-15T11:03:43Z,2025-01-15T11:03:43Z,"### Describe the bug

The generic property bags `properties` and `internalProperties` are persisted as strings, which contain the JSON serialized representation of both property bags.

Each time a call site requests any of these property bags, the JSON representation is being parsed.

This behavior is quite expensive.

_How_ entities and their attributes are persisted should really be up to the actual persistence implementation.

### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/773/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/774,https://api.github.com/repos/apache/polaris/issues/774,polaris,2789529152,774,Task handling is incomplete,snazy,957468,Robert Stupp,,OPEN,2025-01-15T11:19:26Z,2025-01-17T07:24:00Z,"### Describe the bug

Polaris uses some asynchronously executed tasks to run operations for table and manifest file cleanup. Those tasks are potentially executed in a separate thread in the same JVM. There is however no guarantee that those tasks will eventually run for multiple reasons:

* Tasks (e.g. via `org.apache.polaris.service.catalog.BasePolarisCatalog#dropTable`) are triggered _after_ the fact.
* Although tasks are persisted, there is no mechanism to pick up tasks that did not start or did not finish (""long lasting"" failures, JVM terminates).

Overall this means that for example a ""drop table with purge"" returns a successful result to the user, the actual purge may never ever happen.

### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/774/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/774,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a1CY8,polaris,2597594684,774,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2025-01-17T07:23:59Z,2025-01-17T07:23:59Z,This is true; it's the reason for #270 but ideally we should make the operation reliable.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a1CY8/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/775,https://api.github.com/repos/apache/polaris/issues/775,polaris,2789551417,775,Persistence model built around implementation details,snazy,957468,Robert Stupp,,OPEN,2025-01-15T11:30:25Z,2025-01-17T06:59:23Z,"### Describe the bug

The persistence model (as in `org.apache.polaris.core.entity`) is built around assumptions for a particular implementation. It does not just define different entity types (think: catalog, namespace, table, etc) but also implementation details about cache and data consistency details. These details leak though the whole code base that has to deal with any kind of entity. This makes it extremely difficult to use another persistence backend than the one this persistence model was built for, like the ""simpler KV store"" mentioned in `PolarisMetaStoreSession`.

### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/775/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/775,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6aykPb,polaris,2596946907,775,NA,collado-mike,40346148,Michael Collado,,NA,2025-01-16T21:40:00Z,2025-01-16T21:40:00Z,"This is potentially an improvement, not a bug","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6aykPb/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/775,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a06mb,polaris,2597562779,775,NA,snazy,957468,Robert Stupp,,NA,2025-01-17T06:59:22Z,2025-01-17T06:59:22Z,"> This is potentially an improvement, not a bug

I disagree, because this effectively prevents the intention of the abstraction to have _pluggable_ storage even for ""simpler KV stores"", as defined in the Polaris-internal API.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a06mb/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/776,https://api.github.com/repos/apache/polaris/issues/776,polaris,2789610297,776,"Story, design and implementation for secrets management",snazy,957468,Robert Stupp,,OPEN,2025-01-15T11:55:09Z,2025-01-16T17:59:26Z,"### Is your feature request related to a problem? Please describe.

Polaris does requires secrets like storage credentials and access credentials for remote systems.

Those secrets can currently only be configured statically via the configuration or persisted, latter is rather static as well. Also, secrets are currently persisted in various very different ways / property keys.

It would be much better to have a consistent way to access secrets and (let them) manage those in a secure way. At best, secrets would not even be stored in Polaris, but managed by trusted secrets managers.

All secrets should be considered ""ephemeral"" - meaning: secrets can be rotated at any time without even noticing Polaris. Already assuming in the design that secrets can be rotated at any without being noticed makes it easier for users and system integrators.

### Describe the solution you'd like

_No response_

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/776/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/776,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6awW_U,polaris,2596368340,776,NA,snazy,957468,Robert Stupp,,NA,2025-01-16T17:59:25Z,2025-01-16T17:59:25Z,There some prior art that could serve as a source for thoughts: https://projectnessie.org/nessie-latest/configuration/#secrets-manager-settings,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6awW_U/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/777,https://api.github.com/repos/apache/polaris/issues/777,polaris,2789654502,777,Polaris persistence concurrency issues,snazy,957468,Robert Stupp,,OPEN,2025-01-15T12:11:20Z,2025-01-15T12:11:20Z,"### Describe the bug

As pointed out on the [mailing list](https://lists.apache.org/thread/obvrrh0w36f87rwljptzwonpt89qkcm1), the current persistence implementation in Polaris, even if run with the required isolation level, yields errors like `ERROR: could not
serialize access due to read/write dependencies among transactions`. The underlying test case, which runs concurrent modifications to _different_ Iceberg tables (non-conflicting changes) and did not ""overload"" Polaris, should really _never_ yield such errors to users.

This issue _could_ be a consequence of #775, assuming that the behavior of one persistence backend can be ported 1:1 to another one.

### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/777/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/779,https://api.github.com/repos/apache/polaris/issues/779,polaris,2789798702,779,Polaris management API spec improvements,snazy,957468,Robert Stupp,,OPEN,2025-01-15T13:03:47Z,2025-01-15T13:03:47Z,"### Describe the bug

The current Polaris management spec has a few shortcomings:

* It exposes and requires persistence internals (#556) like entityVersion, created/modified timestamps
* It exposes the rather internal persistence model via a public API
* None of the list requests/responses are use paging
* It uses the generic property bags, which requires detailed knowledge of the properties on each client (#555)
* Create/update/delete requests rely on persistence internals and changes are improperly validated on the server side

I propose a complete overhaul of that API, as a v2 and eventually remove v1 before 1.0:

* Enable pagination of list requests using opaque paging-tokens
* Have a data model built on actual, distinct properties instead of generic property bags. This helps users to reason about individual properties and also helps to not accidentally exposing sensitive information.
* Have specific update requests (or update request payloads) for each kind of change instead of sending the whole entity and update everything. This is much easier to reason about from the client side and also much easier to verify & validate on the server side.


### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/779/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/780,https://api.github.com/repos/apache/polaris/issues/780,polaris,2789878384,780,Persistence model depends on public management API,snazy,957468,Robert Stupp,,OPEN,2025-01-15T13:38:58Z,2025-01-15T13:38:58Z,"### Describe the bug

All entities of the persistence model have `asXyz()` functions to return a type from the management OpenAPI spec. While this is currently convenient, it introduces a cyclic dependency, which should generally be avoided:
* management-API depends on REST endpoints
* REST endpoint implementations depend on entities
* entities depend on management-API

The management API and its implementation should not leak into the persistence model.

### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/780/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/788,https://api.github.com/repos/apache/polaris/issues/788,polaris,2790522616,788,Publish Polaris BillOfMaterials (BOM),adutra,463876,Alexandre Dutra,,OPEN,2025-01-15T18:12:14Z,2025-01-15T18:12:14Z,"### Is your feature request related to a problem? Please describe.

It would help users to have a BOM for Polaris.

### Describe the solution you'd like

_No response_

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/788/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/791,https://api.github.com/repos/apache/polaris/issues/791,polaris,2791559154,791,Introduce 419 AuthenticationTimeoutResponse instead of using 401 UnauthorizedResponse on token expiration,sungwy,107272191,Sung Yun,,OPEN,2025-01-16T02:41:42Z,2025-02-07T08:36:23Z,"### Describe the bug

Iceberg clients rely on the distinction between status code values to refresh the token when AuthenticationTimeoutResponse is issued for expired tokens.

Currently, polaris returns a 401 UnauthorizedResponse which isn't conformant to the REST Catalog Spec.

https://github.com/apache/polaris/blob/49a93f8054284091194a51fa685e9fa802d9b988/integration-tests/src/main/java/org/apache/polaris/service/it/test/PolarisManagementServiceIntegrationTest.java#L1993-L2011

### To Reproduce

Use an expired token to make a request against polaris catalog

### Actual Behavior

Currently, polaris returns a 401 UnauthorizedResponse which isn't conformant to the REST Catalog Spec.


### Expected Behavior

419 AuthenticationTimeoutResponse should be returned

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/791/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/791,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dfaPj,polaris,2642256867,791,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2025-02-07T08:36:18Z,2025-02-07T08:36:18Z,Thanks @sungwy for reporting this. +1 on fixing it. ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dfaPj/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/801,https://api.github.com/repos/apache/polaris/issues/801,polaris,2792823713,801,Credentials provided or generated when bootstrapping should not be rotated,adutra,463876,Alexandre Dutra,,OPEN,2025-01-16T13:44:39Z,2025-02-08T00:14:06Z,"### Describe the bug

When bootstrapping a realm, either with the env var `POLARIS_BOOTSTRAP_CREDENTIALS` or using the admin tool, the provided secrets get rotated. 

Because previous secrets are still valid, this works, but I would argue that that's a bad user experience: the user said they want secret A, and they get secret B, and it's B that gets printed to stdout (for in-memory metastores).

What is the reason for doing this rotation?

* If the secrets were randomly generated, rotating is meaningless
* If the secrets were provided by the user, rotating effectively overrides their instructions.

### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/801/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/801,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6awZ4o,polaris,2596380200,801,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2025-01-16T18:06:01Z,2025-01-16T18:06:01Z,"@collado-mike, I recall we discussed this in my PR to use credential hashes","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6awZ4o/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/801,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a7yVu,polaris,2599363950,801,NA,collado-mike,40346148,Michael Collado,,NA,2025-01-17T23:21:59Z,2025-01-17T23:21:59Z,"I don't recall the discussion, but I think that if the secrets are provided via env variables, they should _not_ be rotated except by the user.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a7yVu/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/801,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6diuA2,polaris,2643124278,801,NA,adutra,463876,Alexandre Dutra,,NA,2025-02-07T14:39:53Z,2025-02-07T14:39:53Z,Is it OK to go ahead and fix this?,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6diuA2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/801,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dnbj4,polaris,2644359416,801,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2025-02-08T00:14:05Z,2025-02-08T00:14:05Z,I think so; if the rotation isn't intentional then we should try to get rid of it,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dnbj4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/813,https://api.github.com/repos/apache/polaris/issues/813,polaris,2794742135,813,Task 'runApp' not found in root project 'polaris' and its subprojects.,LeoLong0325,97018470,,,CLOSED,2025-01-17T07:08:45Z,2025-01-17T08:00:53Z,"### Describe the bug

I encountered the following problem when I followed the build instructions in https://polaris.apache.org/in-dev/unreleased/quickstart/ï¼š
![Image](https://github.com/user-attachments/assets/ffbf2834-5396-4f1d-92b7-4a9a607fa8cc)

My execution order wasï¼š
1. ./gradlew build
2. ./gradlew runApp

I don't know if I missed any steps.

Looking forward to your reply.

### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/813/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/813,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a0_CL,polaris,2597580939,813,NA,eric-maynard,23219656,Eric Maynard,eric.maynard+oss@snowflake.com,NA,2025-01-17T07:13:30Z,2025-01-17T07:13:30Z,"Hi @LeoLong0325, please see #700. Some things are still catching up to after some large refactors that happened recently.

For now, you may find it convenient to use [the 0.9.x branch](https://github.com/apache/polaris/tree/0.9.x).","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a0_CL/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/813,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a1OlT,polaris,2597644627,813,NA,LeoLong0325,97018470,,,NA,2025-01-17T08:00:52Z,2025-01-17T08:00:52Z,"OK, I got it, thanks for your reply!","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a1OlT/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/814,https://api.github.com/repos/apache/polaris/issues/814,polaris,2795329175,814,Add an Environment variable to expose pass extra classpath,kameshsampath,947745,Kamesh Sampath,,CLOSED,2025-01-17T12:07:16Z,2025-01-17T13:16:20Z,"### Is your feature request related to a problem? Please describe.

Currently the `polaris-service` script sets the `CLASSPATH` inside it. As a developer I would like to add some extra paths to Classpath via an external variable like `POLARIS_CLASSPATH` which can then be appened to `CLASSPATH` like CLASSPATH=""$CLASSPATH:$POLARIS_CLASSPATH""

### Describe the solution you'd like

Expose a variable named `POLARIS_CLASSPATH` and update the `polaris-service` to append it to the `CLASSPATH` like CLASSPATH=""$CLASSPATH:$POLARIS_CLASSPATH""

### Describe alternatives you've considered

Currently when running via the container I used to do the sed hack like the following to append to the classpath

```
sed -i '/CLASSPATH=.*/{p;s/.*/CLASSPATH=""$CLASSPATH:\/conf""/}' /app/bin/polaris-service
```

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/814/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/814,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a3eiE,polaris,2598234244,814,NA,snazy,957468,Robert Stupp,,NA,2025-01-17T12:12:58Z,2025-01-17T12:12:58Z,"We do have the ability to add extensions/plugins on our road map.

_Currently_, as with the current code base, this not achievable with Polaris built by `polaris-quarkus-server` as all dependencies have to be present at _build time_.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a3eiE/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/814,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a3e7O,polaris,2598235854,814,NA,kameshsampath,947745,Kamesh Sampath,,NA,2025-01-17T12:13:52Z,2025-01-17T12:13:52Z,I see this no longer needed with new Quarkus based build,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a3e7O/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/814,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a36U_,polaris,2598348095,814,NA,kameshsampath,947745,Kamesh Sampath,,NA,2025-01-17T13:16:19Z,2025-01-17T13:16:19Z,"Thanks, I just noticed the move to Quarkus.

On Fri, 17 Jan 2025 at 5:43â€¯PM, Robert Stupp ***@***.***>
wrote:

> We do have the ability to add extensions/plugins on our road map.
>
> *Currently*, as with the current code base, this not achievable with
> Polaris built by polaris-quarkus-server as all dependencies have to be
> present at *build time*.
>
> â€”
> Reply to this email directly, view it on GitHub
> <https://github.com/apache/polaris/issues/814#issuecomment-2598234244>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAHHMINLB22BN5P4ZRO2JV32LDXWBAVCNFSM6AAAAABVLYZNNWVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDKOJYGIZTIMRUGQ>
> .
> You are receiving this because you authored the thread.Message ID:
> ***@***.***>
>
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a36U_/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/815,https://api.github.com/repos/apache/polaris/issues/815,polaris,2795635970,815,Support Bearer auth tokens in polaris CLI,dimas-b,40603221,Dmitri Bourlatchkov,,CLOSED,2025-01-17T14:39:48Z,2025-01-18T05:42:03Z,"### Is your feature request related to a problem? Please describe.

Currently the `./polaris` CLI tool requires the user to provide a client ID/secret pair.

However, most of Polaris APIs actually require a Bearer token.

With on-going discussions about supporting external IdP, supporting bearer tokens become more appropriate in CLI too.

### Describe the solution you'd like

Add `--token` option as an alternative to `--client-secret`

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/815/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/815,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a717N,polaris,2599378637,815,NA,dennishuo,7410123,Dennis Huo,,NA,2025-01-17T23:42:00Z,2025-01-17T23:42:00Z,I've successfully scripted some cases around directly using the `--access-token` flag without client-id/client-secret; is this proposing to change/extend the behavior of `--access-token` or do we just need to surface better documentation about already being able to use `--access-token` without seting `--client-id` or `--client-secret`?,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a717N/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/815,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a8dRy,polaris,2599539826,815,NA,dimas-b,40603221,Dmitri Bourlatchkov,,NA,2025-01-18T05:23:51Z,2025-01-18T05:23:51Z,I clearly missed the existing `--access-token` option. Sorry about the noise. I'll play with it next week.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a8dRy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/815,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a8jV2,polaris,2599564662,815,NA,dimas-b,40603221,Dmitri Bourlatchkov,,NA,2025-01-18T05:42:02Z,2025-01-18T05:42:02Z,`--access-token` works well. Thanks for the tip @dennishuo !,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a8jV2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/819,https://api.github.com/repos/apache/polaris/issues/819,polaris,2796455386,819,Rethink order of JAX-RS filters in Polaris,adutra,463876,Alexandre Dutra,,CLOSED,2025-01-17T23:13:11Z,2025-02-06T03:08:42Z,"### Is your feature request related to a problem? Please describe.

Currently Polaris has a number of filters, some of them being ""regular"" JAX-RS filters, some others being Vert.x route filters:

| Filter | Type | Priority |
| ------|-----| --------|
| `QuarkusLoggingMDCFilter` | Vert.x | `RouteFilter.DEFAULT_PRIORITY + 100` (110) |
| `QuarkusTracingFilter` | Vert.x | `QuarkusLoggingMDCFilter.PRIORITY - 1` (109) |
| `PolarisPrincipalAuthenticatorFilter` | JAX-RS | `Piorities.AUTHENTICATION ` (1000) |
| `PolarisPrincipalRolesProviderFilter`  | JAX-RS | `Piorities.AUTHENTICATION  + 1` (1001) |
| `RateLimiterFilter` | JAX-RS | `Piorities.USER ` (5000) |

The above has a number of issues:

First off, from my experience, Vert.x filters always execute first, regardless of priorities (also, Vert.x priorities are inverted compared to JAX-RS ones). This induces a wrong order of execution:

1. `QuarkusLoggingMDCFilter`
2. `QuarkusTracingFilter`
3. `PolarisPrincipalAuthenticatorFilter`
4. `PolarisPrincipalRolesProviderFilter`
5. `RateLimiterFilter`

Secondly, we ideally need a filter to verify realm IDs. For two reasons:

1. The default realm ID resolver throws an exception if the realm is unknown. That's fine, but the error at that stage, since the resolver is a CDI bean, is translated into HTTP 500. If we want to return something more meaningful, like HTTP 403, we'd need to do that in a filter.  Related to this: #805.
2. Also, `QuarkusLoggingMDCFilter` and `QuarkusTracingFilter` both need the realm ID. So they should execute after the realm ID filter.

### Describe the solution you'd like

I think we need to reorder the filters as below:

1. `RealmIdFilter`(to be created)
2. `QuarkusLoggingMDCFilter`
3. `QuarkusTracingFilter`
4. `PolarisPrincipalAuthenticatorFilter`
5. `PolarisPrincipalRolesProviderFilter`
6. `RateLimiterFilter`

Or maybe as below if we want the authenticator to kick in first:

1. `PolarisPrincipalAuthenticatorFilter`
2. `RealmIdFilter`(to be created)
3. `PolarisPrincipalRolesProviderFilter`
4. `QuarkusLoggingMDCFilter`
5. `QuarkusTracingFilter`
6. `RateLimiterFilter`

We may need to convert the Vert.x filters into JAX-RS ones, or the other way around.

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/819/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/819,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6beXBv,polaris,2608427119,819,NA,collado-mike,40346148,Michael Collado,,NA,2025-01-22T22:49:46Z,2025-01-22T22:49:46Z,"I guess I have missed the commit where `RealmContextResolver` has been deleted? That was the intention of that filter in the original code base.

The `RealmIdFilter` or `RealmContextResolver` must be executed prior to authentication - a caller can only be authenticated within a realm. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6beXBv/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/819,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bit8a,polaris,2609569562,819,NA,adutra,463876,Alexandre Dutra,,NA,2025-01-23T11:29:55Z,2025-01-23T11:29:55Z,"@collado-mike `RealmContextResolver` wasn't deleted, but renamed. Its default implementation is here now:

https://github.com/apache/polaris/blob/390f1fa57bb1af24a21aa95fdbff49a46e31add7/service/common/src/main/java/org/apache/polaris/service/context/DefaultRealmIdResolver.java#L29

> The RealmIdFilter or RealmContextResolver must be executed prior to authentication - a caller can only be authenticated within a realm.

Thanks for confirming, that was my conclusion as well.

For the record, it was already being resolved prior to authentication, but with one annoying difference: the realm was being resolved as part of CDI resolution, see here:

https://github.com/apache/polaris/blob/df538b3928d259e9ec0339d05b12ef6c73b55a15/quarkus/service/src/main/java/org/apache/polaris/service/quarkus/config/QuarkusProducers.java#L101-L110

While this works well in the happy case (the realm can be resolved), it throws HTTP 500 in the unhappy case of wrong realm.

Hence the changes in #848 : realm resolution is moved to a pre-auth filter:

https://github.com/apache/polaris/blob/9c454942cc12de03ed820dc324c90b7ff4e38341/service/common/src/main/java/org/apache/polaris/service/context/RealmIdFilter.java#L48-L56

The filter resolves the realm, then sets it as a request property. Then CDI now simply reads the realm ID from the request property and produces the request-scoped bean that will be injected everywhere:

https://github.com/apache/polaris/blob/9c454942cc12de03ed820dc324c90b7ff4e38341/quarkus/service/src/main/java/org/apache/polaris/service/quarkus/config/QuarkusProducers.java#L101-L105

Does that make sense?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bit8a/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/821,https://api.github.com/repos/apache/polaris/issues/821,polaris,2796755577,821,License Issue - Polaris has dependency on chardet which is LGPL which makes it difficult to use inside enterprise.,chandransuraj,1064819,Suraj,,OPEN,2025-01-18T05:24:13Z,2025-01-31T22:22:42Z,"### Describe the bug

Getting Polaris inside regulated enterprise is difficult as Polaris has dependency on chardet (encoding detector for Python). Chardet is released under LGPLv2.1 (https://github.com/chardet/chardet/blob/main/LICENSE)
The CLM and other scans inside enterprise block this.


### To Reproduce

_No response_

### Actual Behavior

Sub dependencies should not be more restrictive that the main license (which APL2 in this case)

### Expected Behavior

All underlying dependencies should also be compliant with Apache License

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/821/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/821,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a8mS9,polaris,2599576765,821,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2025-01-18T06:27:41Z,2025-01-18T06:27:41Z,Thanks for pointing this. I already know the issue. It's not a blocker for source distribution but problematic for binary distribution (meaning the way it's shipped). I will check to remove this. ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a8mS9/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/821,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bfdNX,polaris,2608714583,821,NA,MonkeyCanCode,29619290,,,NA,2025-01-23T02:27:26Z,2025-01-23T02:27:26Z,"So `chardet` is from `tox`:
```
tox 4.23.2 tox is a generic virtualenv management and test command line tool
â”œâ”€â”€ cachetools >=5.5
â”œâ”€â”€ chardet >=5.2
â”œâ”€â”€ colorama >=0.4.6
â”œâ”€â”€ filelock >=3.16.1
â”œâ”€â”€ packaging >=24.1
â”œâ”€â”€ platformdirs >=4.3.6
â”œâ”€â”€ pluggy >=1.5
â”œâ”€â”€ pyproject-api >=1.8
â”‚   â”œâ”€â”€ packaging >=24.1
â”‚   â””â”€â”€ tomli >=2.0.1
â”œâ”€â”€ tomli >=2.0.1
â”œâ”€â”€ typing-extensions >=4.12.2
â””â”€â”€ virtualenv >=20.26.6
    â”œâ”€â”€ distlib >=0.3.7,<1
    â”œâ”€â”€ filelock >=3.12.2,<4
    â””â”€â”€ platformdirs >=3.9.1,<5
```

Even the latest version still uses it...assuming we can't get `tox` to use alternative lib such as `charset-normalizer`, we will need to move away from `tox`. What do you think @jbonofre 

Also, I am not sure if we really used `tox` to begin with. Maybe I am missing something here? From our github action, we are only using docker to do the test and I don't see we use `tox` for multi envs testing etc.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bfdNX/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/821,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bqIF2,polaris,2611511670,821,NA,MonkeyCanCode,29619290,,,NA,2025-01-24T04:00:10Z,2025-01-24T04:00:10Z,Here is a sample PR for this: https://github.com/apache/polaris/pull/867,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bqIF2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/821,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bro9n,polaris,2611908455,821,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2025-01-24T08:09:39Z,2025-01-24T08:09:39Z,"@MonkeyCanCode that's a good proposal. I think we can't remove `tox` and use alternatives. Let's start by removing `tox`, I think it's there for ""historical"" reason (I don't think it's still used).","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bro9n/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/821,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bsJzb,polaris,2612042971,821,NA,snazy,957468,Robert Stupp,,NA,2025-01-24T09:20:07Z,2025-01-24T09:20:07Z,"I'm not sure whether chardet in particular is really a problem. Sure, it's LGPL, but tox is used for tests - it wouldn't be distributed. If I understand the [Category X here](https://www.apache.org/legal/resolved.html#prohibited) correctly, the use even of GPL licensed components is okay, as long as it is not distributed in source or binary form.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bsJzb/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/821,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bswK3,polaris,2612200119,821,NA,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,NA,2025-01-24T10:34:32Z,2025-01-24T10:34:32Z,"To give more details:
* generally speaking Cat X dependency should be avoided in ASF projects
* however, it's acceptable if the dependency is optional and not distributed
* in these case, it's not distributed and it's a test dependency, it's not a blocker. If possible, it would be better to remove it but not a blocker/issue.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bswK3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/821,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cq7ZS,polaris,2628499026,821,NA,MonkeyCanCode,29619290,,,NA,2025-01-31T22:22:40Z,2025-01-31T22:22:40Z,"BTW, tox had being removed as part of https://github.com/apache/polaris/pull/867 (we are not currently using it...there are alternative we can do without tox as well for testing different version of python as we are getting close to release CLI module). As https://github.com/apache/polaris/pull/804 is also merged, we are ready to revisit those test cases and how we want to prep CLI for the upcoming release. And yes @jbonofre, as long as we are not distribute it, it will be fine through a test depdency. 

As this is removed at the moment, @chandransuraj should we close this issue?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cq7ZS/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/822,https://api.github.com/repos/apache/polaris/issues/822,polaris,2796964017,822,Automatic license checks for Python,snazy,957468,Robert Stupp,,OPEN,2025-01-18T12:52:11Z,2025-01-18T21:37:47Z,"### Describe the bug

We already have ways to collect and verify licenses for the Java ecosystem.

It would help a lot to also have license verification for the Python ecosystem, to ensure that dependencies are used in an ASF-compliant way.

This is rather not just an ""enhancement"" or ""improvement"" but a necessity, because I suspect that not many people will manually inspect all Python direct and indirect dependencies after every dependency change or at least before every release.

License violations cause serious trouble.

Related: #821

### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/822/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/822,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a-jTh,polaris,2600088801,822,NA,MonkeyCanCode,29619290,,,NA,2025-01-18T21:37:46Z,2025-01-18T21:37:46Z,Maybe consider https://github.com/raimon49/pip-licenses for this?,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6a-jTh/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/827,https://api.github.com/repos/apache/polaris/issues/827,polaris,2799763396,827,Catalog's allowed-location not being respected,lrichards-etsy,81712933,,,CLOSED,2025-01-20T16:19:46Z,2025-01-22T14:50:16Z,"### Describe the bug

I'm trying to register a table from an old catalog into Polaris, but when I set up the Polaris catalog with the needed allowed-locations I get permission errors saying can't access the pathway of the old catalog.



### To Reproduce

I created a new Polaris Catalog (polaris_catalog) and set its default location to be `gs://newCatalog` and also set allowed-locations to be `gs://oldCatalog`. When I go to get the info for this catalog I can see both of those pathways showing up in allowedLocations section.

I then try and run
```
CALL polaris_catalog.system.register_table(
          table => 'new_namespace.migrated_table',
          metadata_file => 'gs://oldCatalog/old_namespace/table/metadata/00001-763bca99-363b-4d94-a6c7-221c8c691a8a.metadata.json'
        )
```



### Actual Behavior

It throws an error saying `org.apache.iceberg.exceptions.ForbiddenException: Forbidden: Invalid locations '[gs://oldCatalog/old_namespace/table]' for identifier 'new_namespace.migrated_table': gs://oldCatalog/old_namespace/table is not in the list of allowed locations: [gs://newCatalog/new_namespace]`

### Expected Behavior

A successful register_table run

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/827/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/827,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bLUu8,polaris,2603436988,827,NA,MonkeyCanCode,29619290,,,NA,2025-01-21T01:14:05Z,2025-01-21T01:14:05Z,"This is reproduce-able on my local as well when using backend with FILE. I recalled this was working before (but I don't recalled if I did this one on SaaS one or OSS one). Then to get the local OSS one working, you will need to make the changes to the following config:
```
featureConfiguration:
...
  ALLOW_UNSTRUCTURED_TABLE_LOCATION: true
...
```

This is because the following code (`PolarisStorageConfigurationInfo.java`):
```
              boolean allowEscape =
                  CallContext.getCurrentContext()
                      .getPolarisCallContext()
                      .getConfigurationStore()
                      .getConfiguration(
                          CallContext.getCurrentContext().getPolarisCallContext(),
                          catalog,
                          PolarisConfiguration.ALLOW_UNSTRUCTURED_TABLE_LOCATION);
              if (!allowEscape
                  && catalog.getCatalogType() != Catalog.TypeEnum.EXTERNAL
                  && baseLocation != null) {
                LOGGER.debug(
                    ""Not allowing unstructured table location for entity: {}"",
                    entityPathReversed.get(0).getName());
                return new StorageConfigurationOverride(configInfo, List.of(baseLocation));
              } else {
                LOGGER.debug(
                    ""Allowing unstructured table location for entity: {}"",
                    entityPathReversed.get(0).getName());

                List<String> locs =
                    userSpecifiedWriteLocations(entityPathReversed.get(0).getPropertiesAsMap());
                return new StorageConfigurationOverride(
                    configInfo,
                    ImmutableList.<String>builder()
                        .addAll(configInfo.getAllowedLocations())
                        .addAll(locs)
                        .build());
```

When `ALLOW_UNSTRUCTURED_TABLE_LOCATION` is not set, it won't read additional allowed locations to begin with via this abstraction. Thus the following will keep failing (`BasePolarisCatalog.java`):
```
  private void validateLocationsForTableLike(
      TableIdentifier identifier,
      Set<String> locations,
      PolarisResolvedPathWrapper resolvedStorageEntity) {
    Optional<PolarisStorageConfigurationInfo> optStorageConfiguration =
        PolarisStorageConfigurationInfo.forEntityPath(
            callContext.getPolarisCallContext().getDiagServices(),
            resolvedStorageEntity.getRawFullPath());

    optStorageConfiguration.ifPresentOrElse(
        storageConfigInfo -> {
          Map<String, Map<PolarisStorageActions, PolarisStorageIntegration.ValidationResult>>
              validationResults =
                  InMemoryStorageIntegration.validateSubpathsOfAllowedLocations(
                      storageConfigInfo, Set.of(PolarisStorageActions.ALL), locations);
          validationResults
              .values()
              .forEach(
                  actionResult ->
                      actionResult
                          .values()
                          .forEach(
                              result -> {
                                if (!result.isSuccess()) {
                                  throw new ForbiddenException(
                                      ""Invalid locations '%s' for identifier '%s': %s"",
                                      locations, identifier, result.getMessage());
                                } else {
                                  LOGGER.debug(
                                      ""Validated locations '{}' for identifier '{}'"",
                                      locations,
                                      identifier);
                                }
                              }));
...
```

When the setting is not set, the `PolarisResolvedPathWrapper` will have the right settings but the abstraction `optStorageConfiguration` that is building on top won't have the right setting for allowed location. Thus failing the check later on.

From the code, it is not storage specific (as there is nothing forcing GCS to fail....from the above, it is tested with FILE only and I recalled I got it working with AWS S3 long time back).

Please give this a try and let me know how it goes. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bLUu8/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/827,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bapPD,polaris,2607453123,827,NA,lrichards-etsy,81712933,,,NA,2025-01-22T14:50:14Z,2025-01-22T14:50:14Z,"Confirmed that with an updated `ALLOW_UNSTRUCTURED_TABLE_LOCATION: true` that the error I was seeing on `register_table` goes away and the table can be seen & queried from Polaris without issue. 

Thanks for looking into this for me! I'll be closing out the issue :) ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bapPD/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/844,https://api.github.com/repos/apache/polaris/issues/844,polaris,2804550149,844,Add Amazon DynamoDB as persistence backend,jackye1995,29823233,Jack Ye,jackye@dataolympia.com,OPEN,2025-01-22T14:31:45Z,2025-01-22T17:38:21Z,"Similar to #650, try using Amazon DynamoDB as a NoSQL persistence backend to see if there is anything that needs to be changed to make Polaris work with it.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/844/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/844,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bbTA2,polaris,2607624246,844,NA,jackye1995,29823233,Jack Ye,jackye@dataolympia.com,NA,2025-01-22T15:56:19Z,2025-01-22T15:56:19Z,"Read through https://github.com/apache/polaris/issues/775, https://github.com/apache/polaris/issues/766, https://github.com/apache/polaris/issues/763, looks like it is a major blocker and won't be solved without big refactoring.

I think it is probably better to pursue a JDBC + serializable isolation approach that #649 is doing for now.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bbTA2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/844,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bcOBy,polaris,2607865970,844,NA,dimas-b,40603221,Dmitri Bourlatchkov,,NA,2025-01-22T17:38:21Z,2025-01-22T17:38:21Z,Related `dev` discussion: https://lists.apache.org/thread/obvrrh0w36f87rwljptzwonpt89qkcm1,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bcOBy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/849,https://api.github.com/repos/apache/polaris/issues/849,polaris,2805010625,849,"Fix annoying ""split package"" build warnings",adutra,463876,Alexandre Dutra,,OPEN,2025-01-22T17:54:55Z,2025-01-22T17:54:55Z,"### Is your feature request related to a problem? Please describe.

When building Polaris, we often see an annoying message printed many times to the console, e.g.:

```
Detected a split package usage which is considered a bad practice and should be avoided. Following packages were detected in multiple archives: 
- ""org.apache.polaris.service.quarkus.catalog.io"" found in [org.apache.polaris:polaris-quarkus-service:1.0.0-incubating-SNAPSHOT]
- ""org.apache.polaris.service.quarkus.metrics"" found in [org.apache.polaris:polaris-quarkus-service:1.0.0-incubating-SNAPSHOT]
- ""org.apache.polaris.service.quarkus.legacy"" found in [org.apache.polaris:polaris-quarkus-service:1.0.0-incubating-SNAPSHOT]
- ""org.apache.polaris.service.quarkus.persistence"" found in [org.apache.polaris:polaris-quarkus-service:1.0.0-incubating-SNAPSHOT]
- ""org.apache.polaris.service.quarkus.storage"" found in [org.apache.polaris:polaris-quarkus-service:1.0.0-incubating-SNAPSHOT]
- ""org.apache.polaris.service.quarkus.config"" found in [org.apache.polaris:polaris-quarkus-service:1.0.0-incubating-SNAPSHOT]
- ""org.apache.polaris.service.quarkus.tracing"" found in [org.apache.polaris:polaris-quarkus-service:1.0.0-incubating-SNAPSHOT]
- ""org.apache.polaris.service.quarkus.logging"" found in [org.apache.polaris:polaris-quarkus-service:1.0.0-incubating-SNAPSHOT]
- ""org.apache.polaris.service.quarkus.context"" found in [org.apache.polaris:polaris-quarkus-service:1.0.0-incubating-SNAPSHOT]
- ""org.apache.polaris.service.quarkus.ratelimiter"" found in [org.apache.polaris:polaris-quarkus-service:1.0.0-incubating-SNAPSHOT]
- ""org.apache.polaris.service.quarkus.auth"" found in [org.apache.polaris:polaris-quarkus-service:1.0.0-incubating-SNAPSHOT]
- ""org.apache.polaris.service.quarkus.task"" found in [org.apache.polaris:polaris-quarkus-service:1.0.0-incubating-SNAPSHOT]
```

I don't think we have truly split packages in Polaris. The above is likely a false positive. This can be seen by the number of conflicting artifacts: there is always only one artifact. This probably hints at 2 or more artifacts produced by the same module, having the same name. One possible culprit would be the artifacts created by the `distribution` plugin.

Related discussion: https://github.com/quarkusio/quarkus/issues/19030#issuecomment-888184047

### Describe the solution you'd like

No more annoying messages.


### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/849/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/865,https://api.github.com/repos/apache/polaris/issues/865,polaris,2808163919,865,Failed to run run_spark_sql.sh,flyrain,1322359,Yufei Gu,yufei@apache.org,CLOSED,2025-01-23T23:41:19Z,2025-01-31T22:23:17Z,"### Describe the bug

The fixed token(`principal:root;realm:default-realm`) for regression test doesn't work any more. It worked before the Quarkus migration. cc @jbonofre @adutra @dimas-b  @eric-maynard

There are a bunch of places relies on this credential:
1. https://github.com/apache/polaris/blob/ee26660f08041b5d2ef08c6a490d88f2a846e4ba/regtests/run_spark_sql.sh#L58
2. https://github.com/polaris-catalog/polaris/blob/ee26660f08041b5d2ef08c6a490d88f2a846e4ba/regtests/t_spark_sql/src/spark_sql_views.sh#L22-L22
3. https://github.com/polaris-catalog/polaris/blob/ee26660f08041b5d2ef08c6a490d88f2a846e4ba/getting-started/trino/create-polaris-catalog.sh#L20-L20
4. https://github.com/polaris-catalog/polaris/blob/ee26660f08041b5d2ef08c6a490d88f2a846e4ba/getting-started/trino/trino-config/catalog/iceberg.properties#L24-L24

All these places relies on this credential will fail. 

I'd suggest to restore this.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/865/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/865,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bpi9O,polaris,2611359566,865,NA,HonahX,140284484,Honah (Jonas) J.,honahx@apache.org,NA,2025-01-24T01:36:31Z,2025-01-24T01:36:31Z,"Seems we need to add some additional env to make the fixed token work
I followed the docker compose yaml and adding the following env to getting-started trino example
https://github.com/apache/polaris/blob/ee26660f08041b5d2ef08c6a490d88f2a846e4ba/regtests/docker-compose.yml#L34-L42
and I am able to create the catalog via token `principal:root;realm:default-realm`

","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bpi9O/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/865,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bpwtY,polaris,2611415896,865,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2025-01-24T02:32:39Z,2025-01-24T02:32:39Z,"Thanks for the finding, @HonahX! It works without changing the credential as well, see #866. I think the class `TestInlineBearerTokenPolarisAuthenticator` is the one not checking the token, which is set by `polaris.authentication.authenticator.type: test`. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bpwtY/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/865,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bqJcg,polaris,2611517216,865,NA,MonkeyCanCode,29619290,,,NA,2025-01-24T04:04:20Z,2025-01-24T04:04:20Z,"So here is this one which @adutra created (not yet ready for review): https://github.com/apache/polaris/pull/804/files

It used the following snippet to pass around token for the test:
```
if ! output=$(curl -X POST -H ""Polaris-Realm: POLARIS"" ""http://${POLARIS_HOST:-localhost}:8181/api/catalog/v1/oauth/tokens"" \
  -d ""grant_type=client_credentials"" \
  -d ""client_id=root"" \
  -d ""client_secret=secret"" \
  -d ""scope=PRINCIPAL_ROLE:ALL""); then
  logred ""Error: Failed to retrieve bearer token""
  exit 1
fi

token=$(echo ""$output"" | awk -F\"" '{print $4}')

export REGTEST_ROOT_BEARER_TOKEN=$token
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bqJcg/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/865,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bqLlc,polaris,2611525980,865,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2025-01-24T04:11:01Z,2025-01-24T04:11:01Z,"I'm OK if we decided to go that direction, that means all places with the token `principal:root;realm:default-realm` needed to be replaced with the token generation script, and we probably don't need the class `TestInlineBearerTokenPolarisAuthenticator` any more.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bqLlc/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/865,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bqMSp,polaris,2611528873,865,NA,MonkeyCanCode,29619290,,,NA,2025-01-24T04:13:30Z,2025-01-24T04:13:30Z,"Yes, I am still reading through recent changes. @adutra what do u think? Should we proceed with #804 as docker change is merged. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bqMSp/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/865,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bsN3q,polaris,2612059626,865,NA,adutra,463876,Alexandre Dutra,,NA,2025-01-24T09:28:52Z,2025-01-24T09:28:52Z,"Hi @MonkeyCanCode @flyrain @HonahX sorry for creating so much confusion here.

Here is my long term vision:

- I think the test profile (used in automated tests) is too different from the prod profile. It is always good to make those converge as much as possible. That's why I opened #786. I think it would be good to merge that one quickly, I will do it today.
- I also think that the regression tests should strive to use the same config as in production. This is not the case today, as you noticed, which is why I think you opened this issue. I started a PR (in draft) here: #804 where the authenticator for regression tests is changed to use the production one. 
- As much as possible, I think that the `test` authenticator + token broker should only be used for prototyping, quickstart guides and demos, but not for tests.

Does that make sense?

If that's OK with you, let's proceed as follows:

- Get #786 merged
- Get #804 reviewed and merged
- Revisit the docs and fix all the places where the regression tests are not launched with the appropriate parameters.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bsN3q/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/865,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bw1hv,polaris,2613270639,865,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2025-01-24T19:50:36Z,2025-01-24T19:50:36Z,"+1 on consolidating to default authenticator. 

With a setting like this, there seems no need to keep the test authenticator around. PoC, demos and quickstart can also use the default authenticator. Let me know If I missed something.
```
  jvmArgs = listOf(""-Dpolaris.bootstrap.credentials=POLARIS,root,secret"")
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bw1hv/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/865,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6b0YLO,polaris,2614198990,865,NA,MonkeyCanCode,29619290,,,NA,2025-01-26T03:54:21Z,2025-01-26T03:54:21Z,This is verified with the current main branch. ,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6b0YLO/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/878,https://api.github.com/repos/apache/polaris/issues/878,polaris,2810314407,878,Admin tool: add support for reading directory of credential files,adutra,463876,Alexandre Dutra,,CLOSED,2025-01-24T20:21:37Z,2025-02-04T12:33:48Z,"### Is your feature request related to a problem? Please describe.

The bootstrap command currently takes its input from command line arguments.

But the best for Kubernetes would be to store the bootstrap credentials in a secret, that could look like this:

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: polaris-bootstrap-creds
data:
  realm1: ""client1:secret1""
  realm2: ""client2:secret2""
```

Then the secret could be mounted and each entry would become a file named `realm1`, `realm2` etc. with contents `client1:secret1`, `client2:secret2` etc.

It would be awesome if the bootstrap command could parse the directory and create the credentials from the files.

### Describe the solution you'd like

No more annoying messages.


### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/878/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/878,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bxB48,polaris,2613321276,878,NA,adutra,463876,Alexandre Dutra,,NA,2025-01-24T20:24:53Z,2025-01-24T20:24:53Z,"This will be useful only if we keep the `bootstrap` job in the Helm chart. If we decide to get rid of it, this enhancement may not be useful.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6bxB48/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/878,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6b9ZO9,polaris,2616562621,878,NA,adutra,463876,Alexandre Dutra,,NA,2025-01-27T18:17:40Z,2025-01-27T18:17:40Z,"After working on this a bit, I think mounting each secret entry as a separate file will be more complex than mounting all the credentials in a single file.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6b9ZO9/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/878,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6c_EHy,polaris,2633777650,878,NA,adutra,463876,Alexandre Dutra,,NA,2025-02-04T12:33:48Z,2025-02-04T12:33:48Z,Closing as we decided to get rid of the `bootstrap` job.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6c_EHy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/885,https://api.github.com/repos/apache/polaris/issues/885,polaris,2813178101,885,Integration tests are failing if the user doesn't have `en_US` default locale,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,OPEN,2025-01-27T14:27:34Z,2025-01-27T14:28:19Z,`:polaris-quarkus-service:intTest` are failing if the default locale is not `en_US`.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/885/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/887,https://api.github.com/repos/apache/polaris/issues/887,polaris,2813411398,887,Better handling of bootstrap and purge errors,adutra,463876,Alexandre Dutra,,OPEN,2025-01-27T16:01:24Z,2025-01-27T16:01:24Z,"### Is your feature request related to a problem? Please describe.

The bootstrap and purge commands currently fail hard on common errors such as: 

- realm is already bootstrapped
- realm does not exist or is not bootstrapped

It would be a better UX if we could ignore these errors via a command line option.

Also, the logged messages do not clearly specify which realm failed. In case many realms were provided to the command, that's confusing.

### Describe the solution you'd like

No more annoying messages.


### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/887/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/891,https://api.github.com/repos/apache/polaris/issues/891,polaris,2813759728,891,Improve the Quick Start page,flyrain,1322359,Yufei Gu,yufei@apache.org,OPEN,2025-01-27T18:28:44Z,2025-01-31T22:41:41Z,"### Describe the solution you'd like

After #859, It makes more sense to deprecate the existing Quick Start page, by replacing it with the docs in directory `./getting-started`. 

cc @adutra @HonahX ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/891/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/891,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cFsf3,polaris,2618738679,891,NA,adutra,463876,Alexandre Dutra,,NA,2025-01-28T11:31:32Z,2025-01-28T11:31:32Z,Question: the Quick Start page is published under https://polaris.apache.org/in-dev/unreleased/quickstart/ â€“ but the docs in directory `getting-started` aren't. How are users browsing https://polaris.apache.org going to find the getting-started examples if we delete the Quick Start page?,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cFsf3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/891,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cJI5U,polaris,2619641428,891,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2025-01-28T17:29:50Z,2025-01-28T17:29:50Z,I think we could use symlink like what we did for `chat-bylaws.md` under the directory `content`.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cJI5U/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/891,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cYwae,polaris,2623735454,891,NA,frHimanshu,104910249,Himanshu A Garode,workspaceofhimanshu@gmail.com,NA,2025-01-30T07:26:36Z,2025-01-30T07:26:36Z,"Hello, I'm new to open source community, can I take this issue? ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cYwae/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/891,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6crAX5,polaris,2628519417,891,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2025-01-31T22:41:35Z,2025-01-31T22:41:35Z,Sure. Thanks @frHimanshu !,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6crAX5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/892,https://api.github.com/repos/apache/polaris/issues/892,polaris,2813914212,892,Community meeting Google Calendar link not working,jackye1995,29823233,Jack Ye,jackye@dataolympia.com,CLOSED,2025-01-27T19:47:49Z,2025-02-03T19:48:09Z,"### Describe the bug

https://github.com/apache/polaris/blob/main/site/content/community/meetings/_index.adoc?plain=1#L32C6-L32C51

### To Reproduce

Go to https://calendar.app.google/pUm1MH1gWiMYzXzD8, it says ""Your link didn't work""

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/892/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/892,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6csDIW,polaris,2628792854,892,NA,MonkeyCanCode,29619290,,,NA,2025-02-01T05:49:10Z,2025-02-01T05:49:10Z,Not sure this google group link is the right thing to use as a replacement for this one. But here is a sample PR for this change and fixed this broken link: https://github.com/apache/polaris/pull/925,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6csDIW/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/892,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cxOe7,polaris,2630150075,892,NA,MonkeyCanCode,29619290,,,NA,2025-02-03T07:17:40Z,2025-02-03T07:17:40Z,"> Not sure this google group link is the right thing to use as a replacement for this one. But here is a sample PR for this change and fixed this broken link: https://github.com/apache/polaris/pull/925

PR is merged, good to close this one. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cxOe7/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/894,https://api.github.com/repos/apache/polaris/issues/894,polaris,2814281006,894,Support customizable Authentication schemes,dimas-b,40603221,Dmitri Bourlatchkov,,OPEN,2025-01-27T23:28:19Z,2025-02-07T08:29:30Z,"### Is your feature request related to a problem? Please describe.

`PolarisPrincipalAuthenticatorFilter` requires all auth tokens to be `Bearer`.


### Describe the solution you'd like

It would be nice to allow other (possibly pluggable) Authentication schemes.

Also, it would be nice to allow running without the `Authorization` header (e.g. for testing purposes).

### Describe alternatives you've considered

_No response_

### Additional context

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/894/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/894,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cFNr3,polaris,2618612471,894,NA,adutra,463876,Alexandre Dutra,,NA,2025-01-28T10:35:31Z,2025-01-28T10:35:31Z,"Should we modify the `Authenticator.authenticate()` method and pass the entire request to the authenticator, so that it can take any action it needs to take? (Similar to what we do to resolve the realm)","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cFNr3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/894,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cJDNW,polaris,2619618134,894,NA,dimas-b,40603221,Dmitri Bourlatchkov,,NA,2025-01-28T17:19:34Z,2025-01-28T17:19:34Z,"That was my immediate thought and I almost opened a simple PR for that, but then I realized that in principle one can leverage the Quarkus Authentication Mechanism framework, in which case application-level filters are not necessary as all... so I filed this issue for discussion / collaboration.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cJDNW/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/894,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dfXGa,polaris,2642243994,894,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2025-02-07T08:29:29Z,2025-02-07T08:29:29Z,"Thanks for filing this! I think this could be useful, but letâ€™s take a step back and look at the use cases first. What other authentication schemes do users and developers care about? Any challenges we might face? cc @dennishuo @collado-mike @eric-maynard 
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dfXGa/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/910,https://api.github.com/repos/apache/polaris/issues/910,polaris,2818902857,910,Proposal: Use of Realm Instead of RealmId,flyrain,1322359,Yufei Gu,yufei@apache.org,OPEN,2025-01-29T18:10:53Z,2025-02-07T08:15:30Z,"### Describe the solution you'd like

I wanted to share my thoughts on the ongoing discussion in[ PR #741](https://github.com/apache/polaris/pull/741). about whether to use `Realm` or `RealmId`. 

The more I consider it, the more it seems that the name Realm is the natural choice. It is more an atomic concept, much like the concept of a `region` in AWS.

If we take a closer look at the current usage across Polarisâ€”in documentation, error messages, and configurationsâ€”`realm` and `realmId` are already used interchangeably. In fact, in most cases, we simply use `realm` rather than `realmId`.

Here are a few examples in the Polaris repo:

Error Messages:
1. `realm: <realm> root principal credentials: <client-id>:<client-secret>`

Configurations:

1. `Polaris.realm-context.realms`
2. `jdbc:h2:file:./build/test_data/polaris/{realm}/db`

Documentation:

1. [Metastores](https://polaris.apache.org/in-dev/unreleased/metastores/)
2. [Configuring Polaris for Production](https://polaris.apache.org/in-dev/unreleased/configuring-polaris-for-production/)
3. [Admin Tool](https://polaris.apache.org/in-dev/unreleased/admin-tool/)

#### Proposal
Based on this consistency and the conceptual clarity it brings, I proposed two options:

- Option 1, using the name `realm` instead of `realmId` throughout Polaris and still keeping the interface (`public interface Realm`) for dependency injection purposes. The interface can be extensible in case we want to add any subconcept to the realm, which may never happen to be honest.
- Option 2, purely using a string for `realm` instead of an interface, this is simpler ultimately, but not extensible and needs more effort to refactor the current code. ","{""url"": ""https://api.github.com/repos/apache/polaris/issues/910/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/910,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cUBLx,polaris,2622493425,910,NA,snazy,957468,Robert Stupp,,NA,2025-01-29T18:16:55Z,2025-01-29T18:16:55Z,We already have an ongoing discussion on the dev-mailing list - I'd really prefer to keep it in one place to not lose any history.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cUBLx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/915,https://api.github.com/repos/apache/polaris/issues/915,polaris,2821536844,915,Duplicate keys in JSON produced for Catalog objects,dimas-b,40603221,Dmitri Bourlatchkov,,OPEN,2025-01-30T18:29:07Z,2025-02-07T08:14:51Z,"### Describe the bug

Serializing `Catalog` objects to JSON appears to produce duplicate `type` entries.

### To Reproduce

1. Start TCP capture
2. Run `QuarkusManagementServiceIT`
3. Find an HTTP POST request for `/api/management/v1/catalogs`
4. Observe duplicate `type` keys in the payload

The same behaviour can be observed in java code by (manually) serializing a `Catalog` object to `String`.

### Actual Behavior

Example HTTP request from integration tests:

```
POST /api/management/v1/catalogs HTTP/1.1
Accept: application/json
Authorization: Bearer ***
Content-Type: application/json
realm: POLARIS
User-Agent: Quarkus REST Client
content-length: 373
host: localhost:41133

{""type"":""INTERNAL"",""type"":""INTERNAL"",""name"":""mycatalog_1iwijzxj1hhj8"",""properties"":{""default-base-location"":""s3://bucket1/""},""createTimestamp"":null,""lastUpdateTimestamp"":null,""entityVersion"":null,""storageConfigInfo"":{""storageType"":""S3"",""roleArn"":""arn:aws:iam::012345678901:role/jdoe"",""externalId"":null,""userArn"":null,""region"":null,""storageType"":""S3"",""allowedLocations"":[]}}
```

### Expected Behavior

Each JSON attribute should appear only once.

Note: while it does not cause errors now, some tools may treat duplicate JSON attributes as errors.

### Additional context

commit f3a5ef0b4262ca03c99b9837517d7d03b88af241

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/915/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/915,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cspZH,polaris,2628949575,915,NA,vedansh-5,77830698,Vedansh Saini,,NA,2025-02-01T13:15:06Z,2025-02-01T13:15:06Z,"Hi @dimas-b 
I came across this issue regarding duplicate type entries when serializing Catalog objects to JSON. I'd like to investigate and work on a fix for it. Could you please assign this issue to me?","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cspZH/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/915,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cvwTZ,polaris,2629764313,915,NA,MonkeyCanCode,29619290,,,NA,2025-02-03T02:34:23Z,2025-02-03T02:34:23Z,"> Hi [@dimas-b](https://github.com/dimas-b) I came across this issue regarding duplicate type entries when serializing Catalog objects to JSON. I'd like to investigate and work on a fix for it. Could you please assign this issue to me?

Assigned. Thanks for the help.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cvwTZ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/927,https://api.github.com/repos/apache/polaris/issues/927,polaris,2825167820,927,regtests failing,snazy,957468,Robert Stupp,,CLOSED,2025-02-01T11:53:49Z,2025-02-03T09:41:51Z,"### Describe the bug

```
Execution failed for task ':polaris-quarkus-server:quarkusAppPartsBuild'.
> There was a failure while executing work items
   > A failure occurred while executing io.quarkus.gradle.tasks.worker.BuildWorker

      > io.quarkus.builder.BuildException: Build failure: Build failed due to errors
Error:         	[error]: Build step io.quarkus.container.image.docker.deployment.DockerProcessor#dockerBuildFromJar threw an exception: java.lang.RuntimeException: Execution of 'docker build -f /home/runner/work/polaris/polaris/quarkus/server/src/main/docker/Dockerfile.jvm -t docker.io/apache/polaris:1.0.0-incubating-SNAPSHOT /home/runner/work/polaris/polaris/quarkus/server' failed. See docker output for more details
        	at io.quarkus.container.image.docker.common.deployment.CommonProcessor.containerRuntimeException(CommonProcessor.java:261)
        	at io.quarkus.container.image.docker.common.deployment.CommonProcessor.buildImage(CommonProcessor.java:249)
        	at io.quarkus.container.image.docker.deployment.DockerProcessor.createContainerImage(DockerProcessor.java:125)
        	at io.quarkus.container.image.docker.deployment.DockerProcessor.createContainerImage(DockerProcessor.java:31)
        	at io.quarkus.container.image.docker.common.deployment.CommonProcessor.buildFromJar(CommonProcessor.java:87)
        	at io.quarkus.container.image.docker.deployment.DockerProcessor.dockerBuildFromJar(DockerProcessor.java:62)
        	at java.base/java.lang.invoke.MethodHandle.invokeWithArguments(MethodHandle.java:733)
        	at io.quarkus.deployment.ExtensionLoader$3.execute(ExtensionLoader.java:856)
        	at io.quarkus.builder.BuildContext.run(BuildContext.java:256)
        	at org.jboss.threads.ContextHandler$1.runWith(ContextHandler.java:18)
        	at org.jboss.threads.EnhancedQueueExecutor$Task.doRunWith(EnhancedQueueExecutor.java:2675)
        	at org.jboss.threads.EnhancedQueueExecutor$Task.run(EnhancedQueueExecutor.java:2654)
        	at org.jboss.threads.EnhancedQueueExecutor.runThreadBody(EnhancedQueueExecutor.java:1627)
        	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1594)
        	at java.base/java.lang.Thread.run(Thread.java:1583)
        	at org.jboss.threads.JBossThread.run(JBossThread.java:499)
```

Example failed runs:
* https://github.com/apache/polaris/actions/runs/13088270149/job/36521991861
* https://github.com/apache/polaris/actions/runs/13086227077/job/36517684332

The failure is unrelated to actual the commits/PRs.


### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/927/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/927,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6csjyh,polaris,2628926625,927,NA,adutra,463876,Alexandre Dutra,,NA,2025-02-01T12:07:17Z,2025-02-01T12:07:17Z,"Seems like a docker pull issue:

```
docker build -f quarkus/server/src/main/docker/Dockerfile.jvm -t docker.io/apache/polaris:1.0.0-incubating-SNAPSHOT  quarkus/server
...
ERROR: failed to solve: registry.access.redhat.com/ubi9/openjdk-21:1.21-3.1737580424: failed to resolve source metadata for registry.access.redhat.com/ubi9/openjdk-21:1.21-3.1737580424: unexpected status from HEAD request to https://registry.access.redhat.com/v2/ubi9/openjdk-21/manifests/1.21-3.1737580424: 503 Service Unavailable
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6csjyh/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/927,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cvs0T,polaris,2629750035,927,NA,MonkeyCanCode,29619290,,,NA,2025-02-03T02:23:03Z,2025-02-03T02:23:03Z,"When I tried to build this locally, it works (same as if I kicked off the build from my own fork). I kicked off a rerun and it completed as well: https://github.com/apache/polaris/actions/runs/13088270149","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cvs0T/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/927,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cyUBn,polaris,2630434919,927,NA,snazy,957468,Robert Stupp,,NA,2025-02-03T09:41:50Z,2025-02-03T09:41:50Z,"Looks like it works now, closing","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6cyUBn/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/939,https://api.github.com/repos/apache/polaris/issues/939,polaris,2829349892,939,Properties polaris.persistence.eclipselink.configuration-file and polaris.persistence.eclipselink.persistence-unit not recognized,ks-frederic-marchand,195518340,,,CLOSED,2025-02-04T07:27:47Z,2025-02-05T08:05:18Z,"### Describe the bug

I'm having the following properties file:
```
polaris.persistence.type=eclipse-link
polaris.persistence.eclipselink.configuration-file=/app/config/persistence.xml
polaris.persistence.eclipselink.persistence-unit=polaris
```

It seems that `polaris.persistence.eclipselink.configuration-file` and `polaris.persistence.eclipselink.persistence-unit` are not recognized by the admin tool.

```
Exception in thread ""main"" java.lang.ExceptionInInitializerError                                                                                                                                                                                               
    at io.quarkus.runner.ApplicationImpl.<clinit>(Unknown Source)                                                                                                                                                                                              
    at java.base/jdk.internal.misc.Unsafe.ensureClassInitialized0(Native Method)                                                                                                                                                                               
    at java.base/jdk.internal.misc.Unsafe.ensureClassInitialized(Unsafe.java:1160)                                                                                                                                                                             
    at java.base/jdk.internal.reflect.MethodHandleAccessorFactory.ensureClassInitialized(MethodHandleAccessorFactory.java:300)                                                                                                                                 
    at java.base/jdk.internal.reflect.MethodHandleAccessorFactory.newConstructorAccessor(MethodHandleAccessorFactory.java:103)                                                                                                                                 
    at java.base/jdk.internal.reflect.ReflectionFactory.newConstructorAccessor(ReflectionFactory.java:200)                                                                                                                                                     
    at java.base/java.lang.reflect.Constructor.acquireConstructorAccessor(Constructor.java:549)                                                                                                                                                                
    at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)                                                                                                                                                                     
    at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)                                                                                                                                                                               
    at io.quarkus.runtime.Quarkus.run(Quarkus.java:70)                                                                                                                                                                                                         
    at io.quarkus.runtime.Quarkus.run(Quarkus.java:44)                                                                                                                                                                                                         
    at io.quarkus.runner.GeneratedMain.main(Unknown Source)                                                                                                                                                                                                    
Caused by: io.smallrye.config.ConfigValidationException: Configuration validation failed:                                                                                                                                                                      
    SRCFG00050: polaris.persistence.eclipselink.configuration-file in PropertiesConfigSource[source=file:/app/config/application.properties]:10 does not map to any root                                                                                       
    SRCFG00050: polaris.persistence.eclipselink.persistence-unit in PropertiesConfigSource[source=file:/app/config/application.properties]:11 does not map to any root                                                                                         
    at io.smallrye.config.SmallRyeConfig.buildMappings(SmallRyeConfig.java:139)                                                                                                                                                                                
    at io.smallrye.config.SmallRyeConfig.<init>(SmallRyeConfig.java:93)                                                                                                                                                                                        
    at io.smallrye.config.SmallRyeConfigBuilder.build(SmallRyeConfigBuilder.java:767)                                                                                                                                                                          
    at io.quarkus.runtime.generated.Config.<clinit>(Unknown Source) 
```

### To Reproduce

_No response_

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

OS: Alpine, Docker
Polaris: latest","{""url"": ""https://api.github.com/repos/apache/polaris/issues/939/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/939,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6c9H5Y,polaris,2633268824,939,NA,adutra,463876,Alexandre Dutra,,NA,2025-02-04T08:58:59Z,2025-02-04T08:58:59Z,Hi thanks for reporting this! Did you build Polaris with support for EclipseLink? it's explained here: https://polaris.apache.org/in-dev/unreleased/metastores/,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6c9H5Y/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/939,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6c9Opy,polaris,2633296498,939,NA,ks-frederic-marchand,195518340,,,NA,2025-02-04T09:10:59Z,2025-02-04T09:10:59Z,"Yes, here is the command I used for the build:

```
gradle clean :polaris-quarkus-server:assemble -PeclipseLinkDeps=org.postgresql:postgresql:42.7.4
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6c9Opy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/939,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6c9b-p,polaris,2633351081,939,NA,adutra,463876,Alexandre Dutra,,NA,2025-02-04T09:34:16Z,2025-02-04T09:34:16Z,"Is this the admin tool or the server? I just tried both and both can start normally.

```shell
# Start Postgres
docker run -e POSTGRES_USER=postgres -e POSTGRES_PASSWORD=postgres -e POSTGRES_DB=POLARIS -p 5432:5432 postgres:17.2

# Build Polaris
./gradlew clean :polaris-quarkus-admin:assemble :polaris-quarkus-server:assemble -PeclipseLinkDeps=org.postgresql:postgresql:42.7.4

# Run the admin tool
java -Dpolaris.persistence.eclipselink.configuration-file=""/path/to/persistence.xmll"" -Dpolaris.persistence.type=eclipse-link -jar quarkus/admin/build/polaris-quarkus-admin-1.0.0-incubating-SNAPSHOT-runner.jar bootstrap -r POLARIS -c POLARIS,root,s3cr3t

# Run the server
java -Dpolaris.persistence.eclipselink.configuration-file=""/path/to/persistence.xml"" -Dpolaris.persistence.type=eclipse-link -jar quarkus/server/build/quarkus-app/quarkus-run.jar

# Grab a token
curl -s http://localhost:8181/api/catalog/v1/oauth/tokens --user root:s3cr3t -d 'grant_type=client_credentials' -d 'scope=PRINCIPAL_ROLE:ALL' -H 'Polaris-Realm: POLARIS'
```

My persistence file:

```xml
<persistence version=""2.0"" xmlns=""http://java.sun.com/xml/ns/persistence""
  xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
  xsi:schemaLocation=""http://java.sun.com/xml/ns/persistence http://java.sun.com/xml/ns/persistence/persistence_2_0.xsd"">
  <persistence-unit name=""polaris"" transaction-type=""RESOURCE_LOCAL"">
    <provider>org.eclipse.persistence.jpa.PersistenceProvider</provider>
    <class>org.apache.polaris.jpa.models.ModelEntity</class>
    <class>org.apache.polaris.jpa.models.ModelEntityActive</class>
    <class>org.apache.polaris.jpa.models.ModelEntityChangeTracking</class>
    <class>org.apache.polaris.jpa.models.ModelEntityDropped</class>
    <class>org.apache.polaris.jpa.models.ModelGrantRecord</class>
    <class>org.apache.polaris.jpa.models.ModelPrincipalSecrets</class>
    <class>org.apache.polaris.jpa.models.ModelSequenceId</class>
    <shared-cache-mode>NONE</shared-cache-mode>
    <properties>
      <property name=""jakarta.persistence.jdbc.url"" value=""jdbc:postgresql://localhost:5432/POLARIS""/>
      <property name=""jakarta.persistence.jdbc.user"" value=""postgres""/>
      <property name=""jakarta.persistence.jdbc.password"" value=""postgres""/>
      <property name=""jakarta.persistence.schema-generation.database.action"" value=""create""/>
      <property name=""eclipselink.logging.level.sql"" value=""FINE""/>
      <property name=""eclipselink.logging.parameters"" value=""true""/>
      <property name=""eclipselink.persistence-context.flush-mode"" value=""auto""/>
    </properties>
  </persistence-unit>
</persistence>
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6c9b-p/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/939,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dF2dv,polaris,2635556719,939,NA,ks-frederic-marchand,195518340,,,NA,2025-02-05T02:22:50Z,2025-02-05T02:22:50Z,"You're right! I was building the admin cli as a separated line without the eclipselink flag. It's all good now, thanks","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dF2dv/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/939,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dHltD,polaris,2636012355,939,NA,adutra,463876,Alexandre Dutra,,NA,2025-02-05T08:05:17Z,2025-02-05T08:05:17Z,Glad to hear that! Closing this issue then.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dHltD/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/941,https://api.github.com/repos/apache/polaris/issues/941,polaris,2831067795,941,API docs on polaris.apache.org are broken,collado-mike,40346148,Michael Collado,,CLOSED,2025-02-04T19:04:36Z,2025-02-07T08:14:11Z,"### Describe the bug

API docs generated from the specs are broken on the apache site: https://polaris.apache.org/in-dev/unreleased/rest-catalog-open-api/ . Currently, they don't load at all, but previously when they did load, the links to various APIs didn't work at all.

### To Reproduce

Go to https://polaris.apache.org/in-dev/unreleased/rest-catalog-open-api/

### Actual Behavior

_No response_

### Expected Behavior

_No response_

### Additional context

_No response_

### System information

_No response_","{""url"": ""https://api.github.com/repos/apache/polaris/issues/941/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/941,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dDSjF,polaris,2634885317,941,NA,HonahX,140284484,Honah (Jonas) J.,honahx@apache.org,NA,2025-02-04T19:31:17Z,2025-02-04T19:31:17Z,"Thanks @collado-mike ! I also discovered the same. Initially I thought it was due to my recent change: https://github.com/apache/polaris/pull/935, but the site sill breaks even after it is reverted: #942 

The current error is:

```
Refused to load the script 'https://cdn.jsdelivr.net/npm/redoc@latest/bundles/redoc.standalone.js' because it violates the following Content Security Policy directive: ""script-src 'self' 'unsafe-inline' 'unsafe-eval' https://analytics.apache.org/"". Note that 'script-src-elem' was not explicitly set, so 'script-src' is used as a fallback.
```","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dDSjF/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/941,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dDjIN,polaris,2634953229,941,NA,singhpk234,35593236,Prashant Singh,,NA,2025-02-04T20:07:32Z,2025-02-04T20:07:32Z,"Adding 

```
<meta http-equiv=""Content-Security-Policy"" content=""default-src *; style-src 'self' 'unsafe-inline'; script-src 'self' 'unsafe-inline' 'unsafe-eval' https://cdn.jsdelivr.net/npm/redoc@latest/bundles/redoc.standalone.js"">
```

fixes this, tested locally, got this from the following SO thread, 
https://stackoverflow.com/a/37308542

Happy to create a PR if no one else is working on it ! 

Side note : Not sure how it worked before 
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dDjIN/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/941,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dDk88,polaris,2634960700,941,NA,HonahX,140284484,Honah (Jonas) J.,honahx@apache.org,NA,2025-02-04T20:11:23Z,2025-02-04T20:11:23Z,"@singhpk234 Thanks for the solution! Just curious, how do you reproduce the issue locally. My local build works fine even without the added meta","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dDk88/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/941,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dERSs,polaris,2635142316,941,NA,singhpk234,35593236,Prashant Singh,,NA,2025-02-04T21:43:59Z,2025-02-04T21:43:59Z,"@HonahX  thank you for your question ! 

as you will see the default CSP policy which is getting applied when rendering https://polaris.apache.org/in-dev/unreleased/rest-catalog-open-api/

is 

```
""script-src 'self' 'unsafe-inline' 'unsafe-eval' https://analytics.apache.org/""
```

which our current script violate (Note this doesn't get applied to developement env), to replicate this 
please go to hugo.yaml and add this to the end before rendering your websire  

```
server:
  headers:
    for: /**
    values:
      Content-Security-Policy: ""script-src 'self' 'unsafe-inline' 'unsafe-eval' https://analytics.apache.org/""
```

To mitigate this add this policy 

```
server:
  headers:
    for: /**
    values:
      Content-Security-Policy: >2
            script-src 'self' https://cdn.jsdelivr.net 'unsafe-inline' 'unsafe-eval' https://analytics.apache.org/ https://cdn.jsdelivr.net
```

P.S Not an expert in this area :P, please take this with a grain of salt !","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dERSs/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/941,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dEXaB,polaris,2635167361,941,NA,collado-mike,40346148,Michael Collado,,NA,2025-02-04T21:59:16Z,2025-02-04T21:59:16Z,"@singhpk234 awesome, thanks for finding the solution. If you haven't already, please open a PR ðŸ™ðŸ½","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dEXaB/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/941,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dPZlU,polaris,2638059860,941,NA,sfc-gh-ygu,175990617,Yufei Gu,,NA,2025-02-05T21:26:03Z,2025-02-05T21:26:03Z,It is still broken for me after #944. Can you confirm from your side?,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dPZlU/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/941,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dQE1T,polaris,2638237011,941,NA,HonahX,140284484,Honah (Jonas) J.,honahx@apache.org,NA,2025-02-05T23:09:31Z,2025-02-05T23:09:31Z,"It is also broken for me. I did some search in ASF infra and found that there is a recent update ([INFRA ticket ](https://issues.apache.org/jira/browse/INFRA-26115) on the Content Security Policy.) Specifically, the change enforcing the following rule
```
4) Using Assets from other Domains
Assets (JavaScript files or snippets, images, fonts, CSS, etc.) from other domains cannot be loaded. All assets need to be hosted on ASF servers.

```
as documented at https://privacy.apache.org/policies/website-policy.html

It seems the shortcode we are using for rendering API docs, 
https://github.com/apache/polaris/blob/20817e14e8448114226e76ab8163de35ba0fd6d2/site/layouts/shortcodes/redoc-polaris.html#L118
falls into the above category and therefore gets banned.

I think a quick solution will be to redirect API docs to a swagger editor like what Iceberg site does for IRC spec:
https://github.com/apache/iceberg/blob/585a338c1e9d287476462e3a6abab40b8803fc2c/site/nav.yml#L45

Please correct me if I misunderstand anything :)


","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dQE1T/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/941,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dQJ-O,polaris,2638258062,941,NA,singhpk234,35593236,Prashant Singh,,NA,2025-02-05T23:22:39Z,2025-02-05T23:22:39Z,"Yes that understanding is correct! I was able to come at the same conclusion as the give HUGO changes for serving the static contents we create is not coming into effect. It works in local as we i,e local server is serving those static contents. 
Seems like ASF had same static serving infra which doesn't allows these cross domain serving 

Though this part is tricky as they do say `.htaccess` can be overriden if we can do that we can override the headers ? If thats true may be then we can modify CSP policy 
https://infra.apache.org/project-site.html

>I think a quick solution will be to redirect API docs to a swagger editor like what Iceberg site does for IRC spec:

Agree with you, here is the pr for the fix https://github.com/apache/polaris/pull/950 it redirects to yaml 
handled it in a way that solves both the yaml rendering

Thank you for digging this up @HonahX definitely learned something today about ASF hosting !","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dQJ-O/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/polaris/issues/941,https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dZEB-,polaris,2640593022,941,NA,flyrain,1322359,Yufei Gu,yufei@apache.org,NA,2025-02-06T17:54:15Z,2025-02-06T17:54:15Z,"It works now. Thanks @collado-mike,  @singhpk234 and @HonahX for the investigation and fix!","{""url"": ""https://api.github.com/repos/apache/polaris/issues/comments/IC_kwDOMCWwoM6dZEB-/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/960,https://api.github.com/repos/apache/polaris/issues/960,polaris,2837396183,960,Rat should scan md files,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,OPEN,2025-02-07T07:01:37Z,2025-02-07T08:16:38Z,Rat currently excludes md files. It should scan md files.,"{""url"": ""https://api.github.com/repos/apache/polaris/issues/960/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/961,https://api.github.com/repos/apache/polaris/issues/961,polaris,2837400087,961,Cleanup NOTICE file,jbonofre,158903,JB OnofrÃ©,jbonofre@apache.org,OPEN,2025-02-07T07:04:03Z,2025-02-07T08:16:25Z,"The NOTICE file can be cleanup: the Nessie code has been copied for build resources, so no need to mention Netty for instance.","{""url"": ""https://api.github.com/repos/apache/polaris/issues/961/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/966,https://api.github.com/repos/apache/polaris/issues/966,polaris,2839154828,966,Support Iceberg Rest Catalog Scan Planning Endpoints,HonahX,140284484,Honah (Jonas) J.,honahx@apache.org,OPEN,2025-02-07T21:49:33Z,2025-02-07T21:50:00Z,"The scan planning endpoints were added to Iceberg spec: https://github.com/apache/iceberg/pull/9695

The issue is opened to track our plan/discussion to support these new endpoints (https://github.com/apache/polaris/pull/936#discussion_r1940359162)
","{""url"": ""https://api.github.com/repos/apache/polaris/issues/966/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/polaris/issues/967,https://api.github.com/repos/apache/polaris/issues/967,polaris,2839360332,967,[BUG] Manifest list files are not deleted,sfc-gh-rxing,142847328,Rulin Xing,,OPEN,2025-02-08T00:47:44Z,2025-02-09T02:05:19Z,"### Describe the bug

I noticed that the current implementation of `dropTableWithPurge` doesnâ€™t delete snapshots. I took a look into the `TaskExecution`,  `TableCleanupTaskHandler`, `ManifestFileCleanupTaskHandler`, and it appears that only the metadata JSON files, manifest files, and data files are removed.

### To Reproduce

1. Launch Polaris locally
2. Create a Polaris catalog: polaris_catalog
3. Configure Spark to connect to the local Polaris instance
4. Create a namespace: `create namespace ns;`
5. Create an Iceberg table: `create table ns.t1 (id INT, name STRING);`
6. Insert some data into it: `insert into ns.t1 values(1, 'XJKDC')`
7. Do drop table with purge: `drop table ns.t1 purge;`
8. Check the s3 bucket to see if there are some manifest lists file remaining.

### Actual Behavior

The snapshots files (manifest list files) are not deleted.

### Expected Behavior

The table location should not have any files in it after we drop the table with purge.

### Additional context

Introduced in this PR: https://github.com/apache/polaris/pull/312

### System information

MacOS
Lastest Polaris","{""url"": ""https://api.github.com/repos/apache/polaris/issues/967/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
