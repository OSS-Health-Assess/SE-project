type,issue_url,comment_url,repo_name,id,issue_num,title,user_login,user_id,user_name,user_email,issue_state,created_at,updated_at,body,reactions
issue,https://api.github.com/repos/apache/incubator-wayang/issues/63,https://api.github.com/repos/apache/incubator-wayang/issues/63,incubator-wayang,1113063148,63,ExecutionPlan.toJsonList add documentation,github-actions,,,,OPEN,2022-01-24T19:39:59Z,2023-07-20T15:07:50Z,"ExecutionPlan.toJsonList add documentation

labels:documentation,todo

@return

https://github.com/apache/incubator-wayang/blob/fe066b31d72e8789886aa1217f2516c576195a32/wayang-commons/wayang-core/src/main/java/org/apache/wayang/core/plan/executionplan/ExecutionPlan.java#L99

```java

        return sb.toString();
    }

    /**
     * TODO: ExecutionPlan.toJsonList add documentation
     * labels:documentation,todo
     *
     * @return
     */
    public List<Map> toJsonList() {
        Counter<ExecutionStage> stageActivationCounter = new Counter<>();
        Queue<ExecutionStage> activatedStages = new LinkedList<>(this.startingStages);

```

eb7c56cfe3a29a574d5f0fac8781f9389527d5ea","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/63/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/64,https://api.github.com/repos/apache/incubator-wayang/issues/64,incubator-wayang,1129134771,64,add unitary test to the elements in the file org.apache.wayang.api.DataQuanta.sc...,github-actions,,,,OPEN,2022-02-09T22:51:01Z,2022-02-09T22:51:02Z,"add unitary test to the elements in the file org.apache.wayang.api.DataQuanta.scala

https://github.com/apache/incubator-wayang/blob/278cbdc4bd8e87863a7cb43bc68c52ca783039c0/wayang-api/wayang-api-scala-java/code/main/scala/org/apache/wayang/api/DataQuanta.scala#L22

```scala


package org.apache.wayang.api

/**
 * TODO: add unitary test to the elements in the file org.apache.wayang.api.DataQuanta.scala
 * labels: unitary-test,todo
 */
import _root_.java.lang.{Iterable => JavaIterable}
import _root_.java.util.function.{Consumer, IntUnaryOperator, BiFunction => JavaBiFunction, Function => JavaFunction}
import _root_.java.util.{Collection => JavaCollection}

```

802365979c9912b9cbb1eedd524c7da7390e8c94","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/64/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/65,https://api.github.com/repos/apache/incubator-wayang/issues/65,incubator-wayang,1129134819,65,add the documentation to the object org.apache.wayang.api.DataQuanta,github-actions,,,,OPEN,2022-02-09T22:51:03Z,2022-02-09T22:51:04Z,"add the documentation to the object org.apache.wayang.api.DataQuanta

https://github.com/apache/incubator-wayang/blob/278cbdc4bd8e87863a7cb43bc68c52ca783039c0/wayang-api/wayang-api-scala-java/code/main/scala/org/apache/wayang/api/DataQuanta.scala#L932

```scala


}

/**
 * TODO: add the documentation to the object org.apache.wayang.api.DataQuanta
 * labels: documentation,todo
 */
object DataQuanta {

  def create[T](output: OutputSlot[T])(implicit planBuilder: PlanBuilder): DataQuanta[_] =

```

6bcf18f428fa2a8cc8989894ff0101b956e79a61","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/65/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/66,https://api.github.com/repos/apache/incubator-wayang/issues/66,incubator-wayang,1129134865,66,add unitary test to the elements in the file org.apache.wayang.api.DataQuantaBui...,github-actions,,,,OPEN,2022-02-09T22:51:06Z,2022-02-09T22:51:07Z,"add unitary test to the elements in the file org.apache.wayang.api.DataQuantaBuilder.scala

https://github.com/apache/incubator-wayang/blob/278cbdc4bd8e87863a7cb43bc68c52ca783039c0/wayang-api/wayang-api-scala-java/code/main/scala/org/apache/wayang/api/DataQuantaBuilder.scala#L22

```scala


package org.apache.wayang.api

/**
 * TODO: add unitary test to the elements in the file org.apache.wayang.api.DataQuantaBuilder.scala
 * labels: unitary-test,todo
 */
import java.util.function.{Consumer, IntUnaryOperator, Function => JavaFunction}
import java.util.{Collection => JavaCollection}
import org.apache.wayang.api.graph.{Edge, EdgeDataQuantaBuilder, EdgeDataQuantaBuilderDecorator}

```

c8c9df7f45ddaf1e16155a5a0e17c4deb7eb30a0","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/66/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/67,https://api.github.com/repos/apache/incubator-wayang/issues/67,incubator-wayang,1129134920,67,add unitary test to the elements in the file org.apache.wayang.api.JavaPlanBuild...,github-actions,,,,OPEN,2022-02-09T22:51:08Z,2022-02-09T22:51:09Z,"add unitary test to the elements in the file org.apache.wayang.api.JavaPlanBuilder.scala

https://github.com/apache/incubator-wayang/blob/278cbdc4bd8e87863a7cb43bc68c52ca783039c0/wayang-api/wayang-api-scala-java/code/main/scala/org/apache/wayang/api/JavaPlanBuilder.scala#L21

```scala

 */

package org.apache.wayang.api
/**
 * TODO: add unitary test to the elements in the file org.apache.wayang.api.JavaPlanBuilder.scala
 * labels: unitary-test,todo
 */
import java.util.{Collection => JavaCollection}
import org.apache.commons.lang3.Validate
import org.apache.wayang.api.util.DataQuantaBuilderCache

```

f749b48e33189a4fec6508a1af48e238265907df","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/67/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/68,https://api.github.com/repos/apache/incubator-wayang/issues/68,incubator-wayang,1129134984,68,add unitary test to the elements in the file org.apache.wayang.api.PlanBuilder.s...,github-actions,,,,OPEN,2022-02-09T22:51:10Z,2022-02-09T22:51:12Z,"add unitary test to the elements in the file org.apache.wayang.api.PlanBuilder.scala

https://github.com/apache/incubator-wayang/blob/278cbdc4bd8e87863a7cb43bc68c52ca783039c0/wayang-api/wayang-api-scala-java/code/main/scala/org/apache/wayang/api/PlanBuilder.scala#L21

```scala

 */

package org.apache.wayang.api
/**
 * TODO: add unitary test to the elements in the file org.apache.wayang.api.PlanBuilder.scala
 * labels: unitary-test,todo
 */
import org.apache.commons.lang3.Validate
import org.apache.wayang.api
import org.apache.wayang.basic.data.Record

```

16a4914ccf4698994676780dfe1ffcde45ca495e","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/68/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/69,https://api.github.com/repos/apache/incubator-wayang/issues/69,incubator-wayang,1129135044,69,add unitary test to the elements in the file org.apache.wayang.api.RecordDataQua...,github-actions,,,,OPEN,2022-02-09T22:51:13Z,2022-02-09T22:51:14Z,"add unitary test to the elements in the file org.apache.wayang.api.RecordDataQuantaBuilder.scala

https://github.com/apache/incubator-wayang/blob/278cbdc4bd8e87863a7cb43bc68c52ca783039c0/wayang-api/wayang-api-scala-java/code/main/scala/org/apache/wayang/api/RecordDataQuantaBuilder.scala#L21

```scala

 */

package org.apache.wayang.api
/**
 * TODO: add unitary test to the elements in the file org.apache.wayang.api.RecordDataQuantaBuilder.scala
 * labels: unitary-test,todo
 */
import org.apache.wayang.api.util.DataQuantaBuilderDecorator
import org.apache.wayang.basic.data.Record
import org.apache.wayang.basic.function.ProjectionDescriptor

```

8d9c1b73814e5cb75c62e20fe537b2ca7652677b","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/69/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/70,https://api.github.com/repos/apache/incubator-wayang/issues/70,incubator-wayang,1129135099,70,add the description for the implicitis in org.apache.wayang.api.graph,github-actions,,,,OPEN,2022-02-09T22:51:15Z,2022-02-09T22:51:16Z,"add the description for the implicitis in org.apache.wayang.api.graph

https://github.com/apache/incubator-wayang/blob/278cbdc4bd8e87863a7cb43bc68c52ca783039c0/wayang-api/wayang-api-scala-java/code/main/scala/org/apache/wayang/api/graph/package.scala#L29

```scala

  */
package object graph {

  /**
   * TODO: add the description for the implicitis in org.apache.wayang.api.graph
   * labels: documentation,todo
   */

  type Vertex = java.lang.Long

  type Edge = T2[Vertex, Vertex]

```

b1e0e4b397bbbbba3042a694a04106bbeddc22db","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/70/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/71,https://api.github.com/repos/apache/incubator-wayang/issues/71,incubator-wayang,1129135152,71,add the documentation in the implicit of org.apache.wayang.api,github-actions,,,,OPEN,2022-02-09T22:51:18Z,2022-02-09T22:51:19Z,"add the documentation in the implicit of org.apache.wayang.api

https://github.com/apache/incubator-wayang/blob/278cbdc4bd8e87863a7cb43bc68c52ca783039c0/wayang-api/wayang-api-scala-java/code/main/scala/org/apache/wayang/api/package.scala#L41

```scala

/**
  * Provides implicits for the basic Wayang API.
  */
/**
 * TODO: add the documentation in the implicit of org.apache.wayang.api
 * labels: documentation,todo
 */
package object api {

  implicit def basicDataUnitType[T](implicit classTag: ClassTag[T]): BasicDataUnitType[T] = {

```

afd91b27aa8122e38852815a840fd64dd31ecd63","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/71/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/72,https://api.github.com/repos/apache/incubator-wayang/issues/72,incubator-wayang,1129135209,72,add the documentation in the methods of org.apache.wayang.api.util.DataQuantaBui...,github-actions,,,,OPEN,2022-02-09T22:51:20Z,2022-02-09T22:51:21Z,"add the documentation in the methods of org.apache.wayang.api.util.DataQuantaBuilderDecorator

https://github.com/apache/incubator-wayang/blob/278cbdc4bd8e87863a7cb43bc68c52ca783039c0/wayang-api/wayang-api-scala-java/code/main/scala/org/apache/wayang/api/util/DataQuantaBuilderDecorator.scala#L31

```scala

/**
  * Utility to extend a [[DataQuantaBuilder]]'s functionality by decoration.
  */
/**
 * TODO: add the documentation in the methods of org.apache.wayang.api.util.DataQuantaBuilderDecorator
 * labels: documentation,todo
 */
abstract class DataQuantaBuilderDecorator[This <: DataQuantaBuilder[This, Out], Out]
(baseBuilder: DataQuantaBuilder[_, Out])
  extends DataQuantaBuilder[This, Out] {

```

5e1d9e1f024145b62c1c86bef26e3deddf5f2340","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/72/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/80,https://api.github.com/repos/apache/incubator-wayang/issues/80,incubator-wayang,1167539574,80,Fix code scanning alert - Failure to use HTTPS or SFTP URL in Maven artifact upload/download,2pk03,1323575,Alexander Alten-Lorenz,,CLOSED,2022-03-13T10:22:01Z,2022-03-13T20:00:35Z,"<!-- Warning: The suggested title contains the alert rule name. This can expose security information. -->

Tracking issue for:
- [ ] https://github.com/apache/incubator-wayang/security/code-scanning/1
","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/80/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/83,https://api.github.com/repos/apache/incubator-wayang/issues/83,incubator-wayang,1173334295,83,validate if the implementation apply for the case,github-actions,,,,OPEN,2022-03-18T08:36:53Z,2022-03-18T08:36:54Z,"validate if the implementation apply for the case

First, inspect the size of the file and its line sizes.

https://github.com/apache/incubator-wayang/blob/f8692b292d6e988f479699e6c5144fa5d4ba9bf2/wayang-commons/wayang-basic/src/main/java/org/apache/wayang/basic/operators/ObjectFileSource.java#L102

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.basic.operators;

import java.util.Optional;
import java.util.OptionalDouble;
import java.util.OptionalLong;
import org.apache.commons.lang3.Validate;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.apache.wayang.commons.util.profiledb.model.measurement.TimeMeasurement;
import org.apache.wayang.core.api.Configuration;
import org.apache.wayang.core.optimizer.OptimizationContext;
import org.apache.wayang.core.optimizer.cardinality.CardinalityEstimate;
import org.apache.wayang.core.plan.wayangplan.UnarySource;
import org.apache.wayang.core.types.DataSetType;
import org.apache.wayang.core.util.fs.FileSystems;

/**
 * This source reads a text file and outputs the lines as data units.
 */
public class ObjectFileSource<T> extends UnarySource<T> {

    private final Logger logger = LogManager.getLogger(this.getClass());

    private final String inputUrl;

    private final Class<T> tClass;

    public ObjectFileSource(String inputUrl, DataSetType<T> type) {
        super(type);
        this.inputUrl = inputUrl;
        this.tClass = type.getDataUnitType().getTypeClass();
    }

    public ObjectFileSource(String inputUrl, Class<T> tClass) {
        super(DataSetType.createDefault(tClass));
        this.inputUrl = inputUrl;
        this.tClass = tClass;
    }

    /**
     * Copies an instance (exclusive of broadcasts).
     *
     * @param that that should be copied
     */
    public ObjectFileSource(ObjectFileSource that) {
        super(that);
        this.inputUrl = that.getInputUrl();
        this.tClass = that.getTypeClass();
    }

    public String getInputUrl() {
        return this.inputUrl;
    }

    public Class<T> getTypeClass(){
        return this.tClass;
    }

    @Override
    public Optional<org.apache.wayang.core.optimizer.cardinality.CardinalityEstimator> createCardinalityEstimator(
            final int outputIndex,
            final Configuration configuration) {
        Validate.inclusiveBetween(0, this.getNumOutputs() - 1, outputIndex);
        return Optional.of(new ObjectFileSource.CardinalityEstimator());
    }


    /**
     * Custom {@link org.apache.wayang.core.optimizer.cardinality.CardinalityEstimator} for {@link FlatMapOperator}s.
     */
    protected class CardinalityEstimator implements org.apache.wayang.core.optimizer.cardinality.CardinalityEstimator {

        public final CardinalityEstimate FALLBACK_ESTIMATE = new CardinalityEstimate(1000L, 100000000L, 0.7);

        public static final double CORRECTNESS_PROBABILITY = 0.95d;

        /**
         * We expect selectivities to be correct within a factor of {@value #EXPECTED_ESTIMATE_DEVIATION}.
         */
        public static final double EXPECTED_ESTIMATE_DEVIATION = 0.05;

        @Override
        public CardinalityEstimate estimate(OptimizationContext optimizationContext, CardinalityEstimate... inputEstimates) {
            //TODO validate if the implementation apply for the case
            Validate.isTrue(ObjectFileSource.this.getNumInputs() == inputEstimates.length);

            // see Job for StopWatch measurements
            final TimeMeasurement timeMeasurement = optimizationContext.getJob().getStopWatch().start(
                    ""Optimization"", ""Cardinality&Load Estimation"", ""Push Estimation"", ""Estimate source cardinalities""
            );

            // Query the job cache first to see if there is already an estimate.
            String jobCacheKey = String.format(""%s.estimate(%s)"", this.getClass().getCanonicalName(), ObjectFileSource.this.inputUrl);
            CardinalityEstimate cardinalityEstimate = optimizationContext.queryJobCache(jobCacheKey, CardinalityEstimate.class);
            if (cardinalityEstimate != null) return  cardinalityEstimate;

            // Otherwise calculate the cardinality.
            // First, inspect the size of the file and its line sizes.
            OptionalLong fileSize = FileSystems.getFileSize(ObjectFileSource.this.inputUrl);
            if (!fileSize.isPresent()) {
                ObjectFileSource.this.logger.warn(""Could not determine size of {}... deliver fallback estimate."",
                        ObjectFileSource.this.inputUrl);
                timeMeasurement.stop();
                return this.FALLBACK_ESTIMATE;

            } else if (fileSize.getAsLong() == 0L) {
                timeMeasurement.stop();
                return new CardinalityEstimate(0L, 0L, 1d);
            }

            OptionalDouble bytesPerLine = this.estimateBytesPerLine();
            if (!bytesPerLine.isPresent()) {
                ObjectFileSource.this.logger.warn(""Could not determine average line size of {}... deliver fallback estimate."",
                        ObjectFileSource.this.inputUrl);
                timeMeasurement.stop();
                return this.FALLBACK_ESTIMATE;
            }

            // Extrapolate a cardinality estimate for the complete file.
            double numEstimatedLines = fileSize.getAsLong() / bytesPerLine.getAsDouble();
            double expectedDeviation = numEstimatedLines * EXPECTED_ESTIMATE_DEVIATION;
            cardinalityEstimate = new CardinalityEstimate(
                    (long) (numEstimatedLines - expectedDeviation),
                    (long) (numEstimatedLines + expectedDeviation),
                    CORRECTNESS_PROBABILITY
            );

            // Cache the result, so that it will not be recalculated again.
            optimizationContext.putIntoJobCache(jobCacheKey, cardinalityEstimate);

            timeMeasurement.stop();
            return cardinalityEstimate;
        }

        /**
         * Estimate the number of bytes that are in each line of a given file.
         *
         * @return the average number of bytes per line if it could be determined
         */
        private OptionalDouble estimateBytesPerLine() {
            //TODO validate if the implementation apply for the case
//            final Optional<FileSystem> fileSystem = FileSystems.getFileSystem(ObjectFileSource.this.inputUrl);
//            if (fileSystem.isPresent()) {
//
//                // Construct a limited reader for the first x KiB of the file.
//                final int KiB = 1024;
//                final int MiB = 1024 * KiB;
//                try (LimitedInputStream lis = new LimitedInputStream(fileSystem.get().open(
//                    ObjectFileSource.this.inputUrl), 1 * MiB)) {
//                    final BufferedReader bufferedReader = new BufferedReader(
//                            new InputStreamReader(lis, ObjectFileSource.this.encoding)
//                    );
//
//                    // Read as much as possible.
//                    char[] cbuf = new char[1024];
//                    int numReadChars, numLineFeeds = 0;
//                    while ((numReadChars = bufferedReader.read(cbuf)) != -1) {
//                        for (int i = 0; i < numReadChars; i++) {
//                            if (cbuf[i] == '\n') {
//                                numLineFeeds++;
//                            }
//                        }
//                    }
//
//                    if (numLineFeeds == 0) {
//                        ObjectFileSource.this.logger.warn(""Could not find any newline character in {}."", ObjectFileSource.this.inputUrl);
//                        return OptionalDouble.empty();
//                    }
//                    return OptionalDouble.of((double) lis.getNumReadBytes() / numLineFeeds);
//                } catch (IOException e) {
//                    ObjectFileSource.this.logger.error(""Could not estimate bytes per line of an input file."", e);
//                }
//            }

            return OptionalDouble.empty();
        }
    }

}

```

7731165e0c2dfeb54dd56b576a364f28aa4f9d1f","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/83/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/84,https://api.github.com/repos/apache/incubator-wayang/issues/84,incubator-wayang,1173334328,84,validate if the implementation apply for the case,github-actions,,,,CLOSED,2022-03-18T08:36:55Z,2023-07-20T15:07:37Z,"validate if the implementation apply for the case

final Optional<FileSystem> fileSystem = FileSystems.getFileSystem(ObjectFileSource.this.inputUrl);

if (fileSystem.isPresent()) {

final int KiB = 1024;

final int MiB = 1024 * KiB;

try (LimitedInputStream lis = new LimitedInputStream(fileSystem.get().open(

ObjectFileSource.this.inputUrl), 1 * MiB)) {

final BufferedReader bufferedReader = new BufferedReader(

new InputStreamReader(lis, ObjectFileSource.this.encoding)

);

char[] cbuf = new char[1024];

int numReadChars, numLineFeeds = 0;

while ((numReadChars = bufferedReader.read(cbuf)) != -1) {

for (int i = 0; i < numReadChars; i++) {

if (cbuf[i] == '\n') {

numLineFeeds++;

}

}

}

ObjectFileSource.this.logger.warn(""Could not find any newline character in {}."", ObjectFileSource.this.inputUrl);

return OptionalDouble.empty();

}

return OptionalDouble.of((double) lis.getNumReadBytes() / numLineFeeds);

} catch (IOException e) {

ObjectFileSource.this.logger.error(""Could not estimate bytes per line of an input file."", e);

}

}

https://github.com/apache/incubator-wayang/blob/f8692b292d6e988f479699e6c5144fa5d4ba9bf2/wayang-commons/wayang-basic/src/main/java/org/apache/wayang/basic/operators/ObjectFileSource.java#L102

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.basic.operators;

import java.util.Optional;
import java.util.OptionalDouble;
import java.util.OptionalLong;
import org.apache.commons.lang3.Validate;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.apache.wayang.commons.util.profiledb.model.measurement.TimeMeasurement;
import org.apache.wayang.core.api.Configuration;
import org.apache.wayang.core.optimizer.OptimizationContext;
import org.apache.wayang.core.optimizer.cardinality.CardinalityEstimate;
import org.apache.wayang.core.plan.wayangplan.UnarySource;
import org.apache.wayang.core.types.DataSetType;
import org.apache.wayang.core.util.fs.FileSystems;

/**
 * This source reads a text file and outputs the lines as data units.
 */
public class ObjectFileSource<T> extends UnarySource<T> {

    private final Logger logger = LogManager.getLogger(this.getClass());

    private final String inputUrl;

    private final Class<T> tClass;

    public ObjectFileSource(String inputUrl, DataSetType<T> type) {
        super(type);
        this.inputUrl = inputUrl;
        this.tClass = type.getDataUnitType().getTypeClass();
    }

    public ObjectFileSource(String inputUrl, Class<T> tClass) {
        super(DataSetType.createDefault(tClass));
        this.inputUrl = inputUrl;
        this.tClass = tClass;
    }

    /**
     * Copies an instance (exclusive of broadcasts).
     *
     * @param that that should be copied
     */
    public ObjectFileSource(ObjectFileSource that) {
        super(that);
        this.inputUrl = that.getInputUrl();
        this.tClass = that.getTypeClass();
    }

    public String getInputUrl() {
        return this.inputUrl;
    }

    public Class<T> getTypeClass(){
        return this.tClass;
    }

    @Override
    public Optional<org.apache.wayang.core.optimizer.cardinality.CardinalityEstimator> createCardinalityEstimator(
            final int outputIndex,
            final Configuration configuration) {
        Validate.inclusiveBetween(0, this.getNumOutputs() - 1, outputIndex);
        return Optional.of(new ObjectFileSource.CardinalityEstimator());
    }


    /**
     * Custom {@link org.apache.wayang.core.optimizer.cardinality.CardinalityEstimator} for {@link FlatMapOperator}s.
     */
    protected class CardinalityEstimator implements org.apache.wayang.core.optimizer.cardinality.CardinalityEstimator {

        public final CardinalityEstimate FALLBACK_ESTIMATE = new CardinalityEstimate(1000L, 100000000L, 0.7);

        public static final double CORRECTNESS_PROBABILITY = 0.95d;

        /**
         * We expect selectivities to be correct within a factor of {@value #EXPECTED_ESTIMATE_DEVIATION}.
         */
        public static final double EXPECTED_ESTIMATE_DEVIATION = 0.05;

        @Override
        public CardinalityEstimate estimate(OptimizationContext optimizationContext, CardinalityEstimate... inputEstimates) {
            //TODO validate if the implementation apply for the case
            Validate.isTrue(ObjectFileSource.this.getNumInputs() == inputEstimates.length);

            // see Job for StopWatch measurements
            final TimeMeasurement timeMeasurement = optimizationContext.getJob().getStopWatch().start(
                    ""Optimization"", ""Cardinality&Load Estimation"", ""Push Estimation"", ""Estimate source cardinalities""
            );

            // Query the job cache first to see if there is already an estimate.
            String jobCacheKey = String.format(""%s.estimate(%s)"", this.getClass().getCanonicalName(), ObjectFileSource.this.inputUrl);
            CardinalityEstimate cardinalityEstimate = optimizationContext.queryJobCache(jobCacheKey, CardinalityEstimate.class);
            if (cardinalityEstimate != null) return  cardinalityEstimate;

            // Otherwise calculate the cardinality.
            // First, inspect the size of the file and its line sizes.
            OptionalLong fileSize = FileSystems.getFileSize(ObjectFileSource.this.inputUrl);
            if (!fileSize.isPresent()) {
                ObjectFileSource.this.logger.warn(""Could not determine size of {}... deliver fallback estimate."",
                        ObjectFileSource.this.inputUrl);
                timeMeasurement.stop();
                return this.FALLBACK_ESTIMATE;

            } else if (fileSize.getAsLong() == 0L) {
                timeMeasurement.stop();
                return new CardinalityEstimate(0L, 0L, 1d);
            }

            OptionalDouble bytesPerLine = this.estimateBytesPerLine();
            if (!bytesPerLine.isPresent()) {
                ObjectFileSource.this.logger.warn(""Could not determine average line size of {}... deliver fallback estimate."",
                        ObjectFileSource.this.inputUrl);
                timeMeasurement.stop();
                return this.FALLBACK_ESTIMATE;
            }

            // Extrapolate a cardinality estimate for the complete file.
            double numEstimatedLines = fileSize.getAsLong() / bytesPerLine.getAsDouble();
            double expectedDeviation = numEstimatedLines * EXPECTED_ESTIMATE_DEVIATION;
            cardinalityEstimate = new CardinalityEstimate(
                    (long) (numEstimatedLines - expectedDeviation),
                    (long) (numEstimatedLines + expectedDeviation),
                    CORRECTNESS_PROBABILITY
            );

            // Cache the result, so that it will not be recalculated again.
            optimizationContext.putIntoJobCache(jobCacheKey, cardinalityEstimate);

            timeMeasurement.stop();
            return cardinalityEstimate;
        }

        /**
         * Estimate the number of bytes that are in each line of a given file.
         *
         * @return the average number of bytes per line if it could be determined
         */
        private OptionalDouble estimateBytesPerLine() {
            //TODO validate if the implementation apply for the case
//            final Optional<FileSystem> fileSystem = FileSystems.getFileSystem(ObjectFileSource.this.inputUrl);
//            if (fileSystem.isPresent()) {
//
//                // Construct a limited reader for the first x KiB of the file.
//                final int KiB = 1024;
//                final int MiB = 1024 * KiB;
//                try (LimitedInputStream lis = new LimitedInputStream(fileSystem.get().open(
//                    ObjectFileSource.this.inputUrl), 1 * MiB)) {
//                    final BufferedReader bufferedReader = new BufferedReader(
//                            new InputStreamReader(lis, ObjectFileSource.this.encoding)
//                    );
//
//                    // Read as much as possible.
//                    char[] cbuf = new char[1024];
//                    int numReadChars, numLineFeeds = 0;
//                    while ((numReadChars = bufferedReader.read(cbuf)) != -1) {
//                        for (int i = 0; i < numReadChars; i++) {
//                            if (cbuf[i] == '\n') {
//                                numLineFeeds++;
//                            }
//                        }
//                    }
//
//                    if (numLineFeeds == 0) {
//                        ObjectFileSource.this.logger.warn(""Could not find any newline character in {}."", ObjectFileSource.this.inputUrl);
//                        return OptionalDouble.empty();
//                    }
//                    return OptionalDouble.of((double) lis.getNumReadBytes() / numLineFeeds);
//                } catch (IOException e) {
//                    ObjectFileSource.this.logger.error(""Could not estimate bytes per line of an input file."", e);
//                }
//            }

            return OptionalDouble.empty();
        }
    }

}

```

b203e321870282a9e7eb01c6d42418d849753199","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/84/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/85,https://api.github.com/repos/apache/incubator-wayang/issues/85,incubator-wayang,1173334373,85,remove the set parallelism 1,github-actions,,,,OPEN,2022-03-18T08:36:59Z,2022-03-18T08:36:59Z,"remove the set parallelism 1

https://github.com/apache/incubator-wayang/blob/f8692b292d6e988f479699e6c5144fa5d4ba9bf2/wayang-platforms/wayang-flink/code/main/java/org/apache/wayang/flink/operators/FlinkObjectFileSink.java#L79

```java


        assert inputs.length == this.getNumInputs();
        assert outputs.length <= 1;
        final FileChannel.Instance output;
        final String targetPath;
        if(outputs.length == 1) {
            output = (FileChannel.Instance) outputs[0];
            targetPath = output.addGivenOrTempPath(this.textFileUrl, flinkExecutor.getConfiguration());
        }else{
            targetPath = this.textFileUrl;
        }

        //TODO: remove the set parallelism 1
        DataSetChannel.Instance input = (DataSetChannel.Instance) inputs[0];
        final DataSink<Type> tDataSink = input.<Type>provideDataSet()
                .write(new WayangFileOutputFormat<Type>(targetPath), targetPath, FileSystem.WriteMode.OVERWRITE)

```

034c188dd90f952249452462d3ed4c3af6231d37","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/85/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/90,https://api.github.com/repos/apache/incubator-wayang/issues/90,incubator-wayang,1173803631,90,Protoc at Github Action,berttty,24259784,Bertty Contreras-Rojas,,CLOSED,2022-03-18T16:51:28Z,2022-03-21T11:55:08Z,It required to install the package 'protobuf-compiler' in the Github action before to compile the code,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/90/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/94,https://api.github.com/repos/apache/incubator-wayang/issues/94,incubator-wayang,1175346078,94,Remove Logs during test mode,ro-pardo,6936238,Rodrigo Pardo Meza,ro.pardo.meza@gmail.com,OPEN,2022-03-21T12:55:54Z,2022-03-21T12:56:20Z,"It is unnecessary that by default in TEST Mode, there are displayed as a result all the Logs from Flink, Spark, etc.

This should be first configured by the developer.","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/94/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/95,https://api.github.com/repos/apache/incubator-wayang/issues/95,incubator-wayang,1175355590,95,"key should be given by ""udf""",github-actions,,,,CLOSED,2022-03-21T13:03:28Z,2022-03-21T18:45:50Z,"key should be given by ""udf""

UDF specifies reducer function

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/pywayang/orchestrator/dataquanta.py#L104

```python

#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the ""License""); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

from orchestrator.operator import Operator
from graph.graph import Graph
from graph.traversal import Traversal
from protobuf.planwriter import MessageWriter
import itertools
import collections
import logging
from functools import reduce
import operator


# Wraps a Source operation to create an iterable
class DataQuantaBuilder:
    def __init__(self, descriptor):
        self.descriptor = descriptor

    def source(self, source):

        if type(source) is str:
            source_ori = open(source, ""r"")
        else:
            source_ori = source
        return DataQuanta(
            Operator(
                operator_type=""source"",
                udf=source,
                iterator=iter(source_ori),
                previous=[],
                python_exec=False
            ),
            descriptor=self.descriptor
        )


# Wraps an operation over an iterable
class DataQuanta:
    def __init__(self, operator=None, descriptor=None):
        self.operator = operator
        self.descriptor = descriptor
        if self.operator.is_source():
            self.descriptor.add_source(self.operator)
        if self.operator.is_sink():
            self.descriptor.add_sink(self.operator)

    # Operational Functions
    def filter(self, udf):
        def func(iterator):
            return filter(udf, iterator)

        return DataQuanta(
            Operator(
                operator_type=""filter"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def flatmap(self, udf):

        def auxfunc(iterator):
            return itertools.chain.from_iterable(map(udf, iterator))

        def func(iterator):
            mapped = map(udf, iterator)
            flattened = flatten_single_dim(mapped)
            yield from flattened

        def flatten_single_dim(mapped):
            for item in mapped:
                for subitem in item:
                    yield subitem

        return DataQuanta(
            Operator(
                operator_type=""flatmap"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def group_by(self, udf):
        def func(iterator):
            # TODO key should be given by ""udf""
            return itertools.groupby(iterator, key=operator.itemgetter(0))
            #return itertools.groupby(sorted(iterator), key=itertools.itemgetter(0))

        return DataQuanta(
            Operator(
                operator_type=""group_by"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def map(self, udf):
        def func(iterator):
            return map(udf, iterator)

        return DataQuanta(
            Operator(
                operator_type=""map"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    # Key specifies pivot dimensions
    # UDF specifies reducer function
    def reduce_by_key(self, keys, udf):

        op = Operator(
            operator_type=""reduce_by_key"",
            udf=udf,
            previous=[self.operator],
            python_exec=False
        )

        print(len(keys), keys)
        for i in range(0, len(keys)):
            """"""if keys[i] is int:
                op.set_parameter(""vector_position|""+str(i), keys[i])
            else:
                op.set_parameter(""dimension_key|""+str(i), keys[i])""""""

            # TODO maybe would be better just leave the number as key
            op.set_parameter(""dimension|""+str(i+1), keys[i])

        return DataQuanta(
            op,
            descriptor=self.descriptor
        )

    def reduce(self, udf):
        def func(iterator):
            return reduce(udf, iterator)

        return DataQuanta(
            Operator(
                operator_type=""reduce"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def sink(self, path, end=""\n""):
        def consume(iterator):
            with open(path, 'w') as f:
                for x in iterator:
                    f.write(str(x) + end)

        def func(iterator):
            consume(iterator)
            # return self.__run(consume)

        return DataQuanta(
            Operator(
                operator_type=""sink"",

                udf=path,
                # To execute directly uncomment
                # udf=func,

                previous=[self.operator],
                python_exec=False
            ),
            descriptor=self.descriptor
        )

    def sort(self, udf):

        def func(iterator):
            return sorted(iterator, key=udf)

        return DataQuanta(
            Operator(
                operator_type=""sort"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    # This function allow the union to be performed by Python
    # Nevertheless, current configuration runs it over Java
    def union(self, other):

        def func(iterator):
            return itertools.chain(iterator, other.operator.getIterator())

        return DataQuanta(
            Operator(
                operator_type=""union"",
                udf=func,
                previous=[self.operator, other.operator],
                python_exec=False
            ),
            descriptor=self.descriptor
        )

    def __run(self, consumer):
        consumer(self.operator.getIterator())

    # Execution Functions
    def console(self, end=""\n""):
        def consume(iterator):
            for x in iterator:
                print(x, end=end)

        self.__run(consume)

    # Only for debugging purposes!
    # To execute the plan directly in the program driver
    def execute(self):
        logging.warn(""DEBUG Execution"")
        logging.info(""Reminder to swap SINK UDF value from path to func"")
        logging.debug(self.operator.previous[0].operator_type)
        if self.operator.is_sink():
            logging.debug(self.operator.operator_type)
            logging.debug(self.operator.udf)
            logging.debug(len(self.operator.previous))
            self.operator.udf(self.operator.previous[0].getIterator())
        else:
            logging.error(""Plan must call execute from SINK type of operator"")
            raise RuntimeError

    # Converts Python Functional Plan to valid Wayang Plan
    def to_wayang_plan(self):

        sinks = self.descriptor.get_sinks()
        if len(sinks) == 0:
            return

        graph = Graph()
        graph.populate(self.descriptor.get_sinks())

        # Uncomment to check the Graph built
        # graph.print_adjlist()

        # Function to be consumed by Traverse
        # Separates Python Plan into a List of Pipelines
        def define_pipelines(node1, current_pipeline, collection):
            def store_unique(pipe_to_insert):
                for pipe in collection:
                    if equivalent_lists(pipe, pipe_to_insert):
                        return
                collection.append(pipe_to_insert)

            def equivalent_lists(l1, l2):
                if collections.Counter(l1) == collections.Counter(l2):
                    return True
                else:
                    return False

            if not current_pipeline:
                current_pipeline = [node1]

            elif node1.operator.is_boundary():
                store_unique(current_pipeline.copy())
                current_pipeline.clear()
                current_pipeline.append(node1)

            else:
                current_pipeline.append(node1)

            if node1.operator.sink:
                store_unique(current_pipeline.copy())
                current_pipeline.clear()

            return current_pipeline

        # Works over the graph
        trans = Traversal(
            graph=graph,
            origin=self.descriptor.get_sources(),
            # udf=lambda x, y, z: d(x, y, z)
            # UDF always will receive:
            # x: a Node object,
            # y: an object representing the result of the last iteration,
            # z: a collection to store final results inside your UDF
            udf=lambda x, y, z: define_pipelines(x, y, z)
        )

        # Gets the results of the traverse process
        collected_stages = trans.get_collected_data()

        # Passing the Stages to a Wayang message writer
        writer = MessageWriter()
        a = 0
        # Stage is composed of class Node objects
        for stage in collected_stages:
            a += 1
            logging.info(""///"")
            logging.info(""stage"" + str(a))
            writer.process_pipeline(stage)

        writer.set_dependencies()

        # Uses a file to provide the plan
        # writer.write_message(self.descriptor)

        # Send the plan to Wayang REST api directly
        writer.send_message(self.descriptor)

```

071d79ff81738e15f7e5cbbf8c883d315e8e1d61","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/95/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/96,https://api.github.com/repos/apache/incubator-wayang/issues/96,incubator-wayang,1175355650,96,maybe would be better just leave the number as key,github-actions,,,,CLOSED,2022-03-21T13:03:30Z,2022-03-21T18:45:50Z,"maybe would be better just leave the number as key

udf=func,

Nevertheless, current configuration runs it over Java

To execute the plan directly in the program driver

graph.print_adjlist()

Separates Python Plan into a List of Pipelines

UDF always will receive:

x: a Node object,

y: an object representing the result of the last iteration,

z: a collection to store final results inside your UDF

writer.write_message(self.descriptor)

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/pywayang/orchestrator/dataquanta.py#L150

```python

#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the ""License""); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

from orchestrator.operator import Operator
from graph.graph import Graph
from graph.traversal import Traversal
from protobuf.planwriter import MessageWriter
import itertools
import collections
import logging
from functools import reduce
import operator


# Wraps a Source operation to create an iterable
class DataQuantaBuilder:
    def __init__(self, descriptor):
        self.descriptor = descriptor

    def source(self, source):

        if type(source) is str:
            source_ori = open(source, ""r"")
        else:
            source_ori = source
        return DataQuanta(
            Operator(
                operator_type=""source"",
                udf=source,
                iterator=iter(source_ori),
                previous=[],
                python_exec=False
            ),
            descriptor=self.descriptor
        )


# Wraps an operation over an iterable
class DataQuanta:
    def __init__(self, operator=None, descriptor=None):
        self.operator = operator
        self.descriptor = descriptor
        if self.operator.is_source():
            self.descriptor.add_source(self.operator)
        if self.operator.is_sink():
            self.descriptor.add_sink(self.operator)

    # Operational Functions
    def filter(self, udf):
        def func(iterator):
            return filter(udf, iterator)

        return DataQuanta(
            Operator(
                operator_type=""filter"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def flatmap(self, udf):

        def auxfunc(iterator):
            return itertools.chain.from_iterable(map(udf, iterator))

        def func(iterator):
            mapped = map(udf, iterator)
            flattened = flatten_single_dim(mapped)
            yield from flattened

        def flatten_single_dim(mapped):
            for item in mapped:
                for subitem in item:
                    yield subitem

        return DataQuanta(
            Operator(
                operator_type=""flatmap"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def group_by(self, udf):
        def func(iterator):
            # TODO key should be given by ""udf""
            return itertools.groupby(iterator, key=operator.itemgetter(0))
            #return itertools.groupby(sorted(iterator), key=itertools.itemgetter(0))

        return DataQuanta(
            Operator(
                operator_type=""group_by"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def map(self, udf):
        def func(iterator):
            return map(udf, iterator)

        return DataQuanta(
            Operator(
                operator_type=""map"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    # Key specifies pivot dimensions
    # UDF specifies reducer function
    def reduce_by_key(self, keys, udf):

        op = Operator(
            operator_type=""reduce_by_key"",
            udf=udf,
            previous=[self.operator],
            python_exec=False
        )

        print(len(keys), keys)
        for i in range(0, len(keys)):
            """"""if keys[i] is int:
                op.set_parameter(""vector_position|""+str(i), keys[i])
            else:
                op.set_parameter(""dimension_key|""+str(i), keys[i])""""""

            # TODO maybe would be better just leave the number as key
            op.set_parameter(""dimension|""+str(i+1), keys[i])

        return DataQuanta(
            op,
            descriptor=self.descriptor
        )

    def reduce(self, udf):
        def func(iterator):
            return reduce(udf, iterator)

        return DataQuanta(
            Operator(
                operator_type=""reduce"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def sink(self, path, end=""\n""):
        def consume(iterator):
            with open(path, 'w') as f:
                for x in iterator:
                    f.write(str(x) + end)

        def func(iterator):
            consume(iterator)
            # return self.__run(consume)

        return DataQuanta(
            Operator(
                operator_type=""sink"",

                udf=path,
                # To execute directly uncomment
                # udf=func,

                previous=[self.operator],
                python_exec=False
            ),
            descriptor=self.descriptor
        )

    def sort(self, udf):

        def func(iterator):
            return sorted(iterator, key=udf)

        return DataQuanta(
            Operator(
                operator_type=""sort"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    # This function allow the union to be performed by Python
    # Nevertheless, current configuration runs it over Java
    def union(self, other):

        def func(iterator):
            return itertools.chain(iterator, other.operator.getIterator())

        return DataQuanta(
            Operator(
                operator_type=""union"",
                udf=func,
                previous=[self.operator, other.operator],
                python_exec=False
            ),
            descriptor=self.descriptor
        )

    def __run(self, consumer):
        consumer(self.operator.getIterator())

    # Execution Functions
    def console(self, end=""\n""):
        def consume(iterator):
            for x in iterator:
                print(x, end=end)

        self.__run(consume)

    # Only for debugging purposes!
    # To execute the plan directly in the program driver
    def execute(self):
        logging.warn(""DEBUG Execution"")
        logging.info(""Reminder to swap SINK UDF value from path to func"")
        logging.debug(self.operator.previous[0].operator_type)
        if self.operator.is_sink():
            logging.debug(self.operator.operator_type)
            logging.debug(self.operator.udf)
            logging.debug(len(self.operator.previous))
            self.operator.udf(self.operator.previous[0].getIterator())
        else:
            logging.error(""Plan must call execute from SINK type of operator"")
            raise RuntimeError

    # Converts Python Functional Plan to valid Wayang Plan
    def to_wayang_plan(self):

        sinks = self.descriptor.get_sinks()
        if len(sinks) == 0:
            return

        graph = Graph()
        graph.populate(self.descriptor.get_sinks())

        # Uncomment to check the Graph built
        # graph.print_adjlist()

        # Function to be consumed by Traverse
        # Separates Python Plan into a List of Pipelines
        def define_pipelines(node1, current_pipeline, collection):
            def store_unique(pipe_to_insert):
                for pipe in collection:
                    if equivalent_lists(pipe, pipe_to_insert):
                        return
                collection.append(pipe_to_insert)

            def equivalent_lists(l1, l2):
                if collections.Counter(l1) == collections.Counter(l2):
                    return True
                else:
                    return False

            if not current_pipeline:
                current_pipeline = [node1]

            elif node1.operator.is_boundary():
                store_unique(current_pipeline.copy())
                current_pipeline.clear()
                current_pipeline.append(node1)

            else:
                current_pipeline.append(node1)

            if node1.operator.sink:
                store_unique(current_pipeline.copy())
                current_pipeline.clear()

            return current_pipeline

        # Works over the graph
        trans = Traversal(
            graph=graph,
            origin=self.descriptor.get_sources(),
            # udf=lambda x, y, z: d(x, y, z)
            # UDF always will receive:
            # x: a Node object,
            # y: an object representing the result of the last iteration,
            # z: a collection to store final results inside your UDF
            udf=lambda x, y, z: define_pipelines(x, y, z)
        )

        # Gets the results of the traverse process
        collected_stages = trans.get_collected_data()

        # Passing the Stages to a Wayang message writer
        writer = MessageWriter()
        a = 0
        # Stage is composed of class Node objects
        for stage in collected_stages:
            a += 1
            logging.info(""///"")
            logging.info(""stage"" + str(a))
            writer.process_pipeline(stage)

        writer.set_dependencies()

        # Uses a file to provide the plan
        # writer.write_message(self.descriptor)

        # Send the plan to Wayang REST api directly
        writer.send_message(self.descriptor)

```

668a0429fb75425f983112ec63959c33341a58f7","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/96/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/97,https://api.github.com/repos/apache/incubator-wayang/issues/97,incubator-wayang,1175355704,97,create reduce by,github-actions,,,,CLOSED,2022-03-21T13:03:33Z,2022-03-21T18:45:51Z,"create reduce by

.reduce_by(reducer) \

.flatmap(lambda elem: elem.split(""|""))

.map(lambda elem: (elem, elem.split(""|""))) \

L_RETURNFLAG 8

L_LINESTATUS 9

L_QUANTITY 4

L_EXTENDEDPRICE 5

discount 6

tax 7

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/pywayang/orchestrator/execdirectly.py#L114

```python

#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the ""License""); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

from orchestrator.plan import Descriptor
from orchestrator.dataquanta import DataQuantaBuilder
import datetime


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_sort(descriptor):
    plan = DataQuantaBuilder(descriptor)
    sink_dataquanta = \
        plan.source(""../test/words.txt"") \
            .sort(lambda elem: elem.lower()) \
            .sink(""../test/output.txt"", end="""")
    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_sort_filter(descriptor):
    plan = DataQuantaBuilder(descriptor)
    sink_dataquanta = \
        plan.source(""../test/words.txt"") \
            .sort(lambda elem: elem.lower()) \
            .filter(lambda elem: str(elem).startswith(""f"")) \
            .sink(""../test/output.txt"", end="""")
    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_filter_text(descriptor):
    plan = DataQuantaBuilder(descriptor)

    sink_dataquanta = \
        plan.source(""../test/words.txt"") \
            .filter(lambda elem: str(elem).startswith(""f"")) \
            .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_filter(descriptor):
    plan = DataQuantaBuilder(descriptor)

    sink_dataquanta = \
        plan.source(""../test/numbers.txt"") \
            .filter(lambda elem: int(elem) % 2 != 0) \
            .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_basic(descriptor):
    plan = DataQuantaBuilder(descriptor)

    sink_dataquanta = \
        plan.source(""../test/lines.txt"") \
            .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_junction(descriptor):

    plan = DataQuantaBuilder(descriptor)

    dq_source_a = plan.source(""../test/lines.txt"")
    dq_source_b = plan.source(""../test/morelines.txt"") \
        .filter(lambda elem: str(elem).startswith(""I""))
    dq_source_c = plan.source(""../test/lastlines.txt"") \
        .filter(lambda elem: str(elem).startswith(""W""))

    sink_dataquanta = dq_source_a.union(dq_source_b) \
        .union(dq_source_c) \
        .sort(lambda elem: elem.lower()) \
        .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


def plan_java_junction(descriptor):

    plan = DataQuantaBuilder(descriptor)

    dq_source_a = plan.source(""../test/lines.txt"")
    dq_source_b = plan.source(""../test/morelines.txt"")
    sink_dataquanta = dq_source_a.union(dq_source_b) \
        .filter(lambda elem: str(elem).startswith(""I"")) \
        .sort(lambda elem: elem.lower()) \
        .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


def plan_tpch_q1(descriptor):

    #TODO create reduce by
    plan = DataQuantaBuilder(descriptor)

    def reducer(obj1, obj2):
        return obj1[0]

    sink = plan.source(""../test/lineitem.txt"") \
        .map(lambda elem: elem.split(""|"")) \
        .filter(lambda elem: datetime.datetime.strptime(elem[10], '%Y-%m-%d') <= datetime.datetime.strptime(""1998-09-02"", '%Y-%m-%d')) \
        .map(lambda elem:
           [elem[8], elem[9], elem[4], elem[5],
            float(elem[5]) * (1 - float(elem[6])),
            float(elem[5]) * (1 - float(elem[6])) * (1 + float(elem[7])),
            elem[4], elem[5],
            elem[6], 1]) \
        .sink(""../test/output.txt"", end="""")
        # .group_by(lambda elem: elem) \
        # .reduce_by(reducer) \
        # .flatmap(lambda elem: elem.split(""|""))
        # .map(lambda elem: (elem, elem.split(""|""))) \
        # L_RETURNFLAG 8
        # L_LINESTATUS 9
        # L_QUANTITY 4
        # L_EXTENDEDPRICE 5
        # discount 6
        # tax 7

    return dq_source_b


def plan_full_java(descriptor):

    plan = DataQuantaBuilder(descriptor)

    dq_source_a = plan.source(""../test/lines.txt"")
    dq_source_b = plan.source(""../test/morelines.txt"")
    sink_dataquanta = dq_source_a.union(dq_source_b) \
        .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


if __name__ == '__main__':

    # Plan will contain general info about the Wayang Plan created here
    descriptor = Descriptor()

    plan_dataquanta_sink = plan_tpch_q1(descriptor)
    plan_dataquanta_sink.execute()

```

aff53164d9e4797b22e4d4a00753ad8b2676ba93","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/97/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/98,https://api.github.com/repos/apache/incubator-wayang/issues/98,incubator-wayang,1175355744,98,create reduce by,github-actions,,,,CLOSED,2022-03-21T13:03:36Z,2022-03-21T18:45:51Z,"create reduce by

plan_dataquanta_sink.console()

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/pywayang/orchestrator/main.py#L114

```python

#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the ""License""); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

from orchestrator.plan import Descriptor
from orchestrator.dataquanta import DataQuantaBuilder
import datetime


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_sort(descriptor):
    plan = DataQuantaBuilder(descriptor)
    sink_dataquanta = \
        plan.source(""../test/words.txt"") \
            .sort(lambda elem: elem.lower()) \
            .sink(""../test/output.txt"", end="""")
    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_sort_filter(descriptor):
    plan = DataQuantaBuilder(descriptor)
    sink_dataquanta = \
        plan.source(""../test/words.txt"") \
            .sort(lambda elem: elem.lower()) \
            .filter(lambda elem: str(elem).startswith(""f"")) \
            .sink(""../test/output.txt"", end="""")
    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_filter_text(descriptor):
    plan = DataQuantaBuilder(descriptor)

    sink_dataquanta = \
        plan.source(""../test/words.txt"") \
            .filter(lambda elem: str(elem).startswith(""f"")) \
            .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_filter(descriptor):
    plan = DataQuantaBuilder(descriptor)

    sink_dataquanta = \
        plan.source(""../test/numbers.txt"") \
            .filter(lambda elem: int(elem) % 2 != 0) \
            .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_basic(descriptor):
    plan = DataQuantaBuilder(descriptor)

    sink_dataquanta = \
        plan.source(""../test/lines.txt"") \
            .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_junction(descriptor):

    plan = DataQuantaBuilder(descriptor)

    dq_source_a = plan.source(""../test/lines.txt"")
    dq_source_b = plan.source(""../test/morelines.txt"") \
        .filter(lambda elem: str(elem).startswith(""I""))
    dq_source_c = plan.source(""../test/lastlines.txt"") \
        .filter(lambda elem: str(elem).startswith(""W""))

    sink_dataquanta = dq_source_a.union(dq_source_b) \
        .union(dq_source_c) \
        .sort(lambda elem: elem.lower()) \
        .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


def plan_java_junction(descriptor):

    plan = DataQuantaBuilder(descriptor)

    dq_source_a = plan.source(""../test/lines.txt"")
    dq_source_b = plan.source(""../test/morelines.txt"")
    sink_dataquanta = dq_source_a.union(dq_source_b) \
        .filter(lambda elem: str(elem).startswith(""I"")) \
        .sort(lambda elem: elem.lower()) \
        .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


def plan_tpch_q1(descriptor):

    # TODO create reduce by
    plan = DataQuantaBuilder(descriptor)

    def reducer(obj1, obj2):
        return obj1[0], obj1[1], obj1[2] + obj2[2], obj1[3] + obj2[3], obj1[4] + obj2[4], obj1[5] + obj2[5], \
               obj1[6] + obj2[6], obj1[7] + obj2[7], obj1[8] + obj2[8], obj1[9] + obj2[9]

    sink = plan.source(""../test/lineitem.txt"") \
        .map(lambda elem: elem.split(""|"")) \
        .sink(""../test/output.txt"", end="""")
    """"""
        .filter(lambda elem: datetime.datetime.strptime(elem[10], '%Y-%m-%d') <= datetime.datetime.strptime('1998-09-02', '%Y-%m-%d')) \
        .map(lambda elem:
             [elem[8], elem[9], elem[4], elem[5],
              float(elem[5]) * (1 - float(elem[6])),
              float(elem[5]) * (1 - float(elem[6])) * (1 + float(elem[7])),
              elem[4], elem[5],
              elem[6], 1]) \
        .sink(""../test/output.txt"", end="""")""""""
        # .reduce_by_key([0, 1], reducer) \


    return sink


def plan_full_java(descriptor):

    plan = DataQuantaBuilder(descriptor)

    dq_source_a = plan.source(""../test/lines.txt"")
    dq_source_b = plan.source(""../test/morelines.txt"")
    sink_dataquanta = dq_source_a.union(dq_source_b) \
        .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


def plan_wordcount(descriptor):

    plan = DataQuantaBuilder(descriptor)
    sink_wordcount = plan.source(""../test/lineitem.txt"") \
        .filter(lambda elem: len(str(elem).split(""|"")[0]) < 4) \
        .flatmap(lambda elem: str(elem).split(""|"")) \
        .sink(""../test/output.txt"", end="""")

    return sink_wordcount


if __name__ == '__main__':

    # Plan will contain general info about the Wayang Plan created here
    descriptor = Descriptor()
    descriptor.add_plugin(Descriptor.Plugin.spark)
    descriptor.add_plugin(Descriptor.Plugin.java)

    plan_dataquanta_sink = plan_wordcount(descriptor)
    # plan_dataquanta_sink.execute()
    # plan_dataquanta_sink.console()

    plan_dataquanta_sink.to_wayang_plan()

```

7d744e87f3c7a2f596ae70bd906f86980648240c","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/98/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/99,https://api.github.com/repos/apache/incubator-wayang/issues/99,incubator-wayang,1175355795,99,Why managing previous and predecessors per separate?,github-actions,,,,CLOSED,2022-03-21T13:03:38Z,2022-03-21T18:45:52Z,"Why managing previous and predecessors per separate?

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/pywayang/orchestrator/operator.py#L69

```python

#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the ""License""); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

import pickle
import cloudpickle
from config.config_reader import get_source_types
from config.config_reader import get_sink_types
from config.config_reader import get_boundary_types
import logging

pickle_protocol = pickle.HIGHEST_PROTOCOL


# Describes an Operation over an intermediate result
# Each operation could be processed by Python or Java platforms
class Operator:

    def __init__(
            self, operator_type=None, udf=None, previous=None,
            iterator=None, python_exec=False
    ):

        # Operator ID
        self.id = id(self)

        # Operator Type
        self.operator_type = operator_type

        # Set Boundaries
        if self.operator_type in get_boundary_types():
            self.boundary = True
        else:
            self.boundary = False

        # UDF Function
        self.udf = udf

        # Source types must come with an Iterator
        self.iterator = iterator
        if operator_type in get_source_types():
            if iterator is None:
                print(""Source Operator Type without an Iterator"")
                raise
            else:
                self.source = True
        else:
            self.source = False

        # Sink Operators
        if operator_type in get_sink_types():
            self.sink = True
        else:
            self.sink = False

        # TODO Why managing previous and predecessors per separate?
        self.previous = previous

        self.successor = []
        self.predecessor = []

        self.parameters = {}

        # Set predecessors and successors from previous
        if self.previous:
            for prev in self.previous:
                if prev is not None:
                    prev.set_successor(self)
                    self.set_predecessor(prev)

        self.python_exec = python_exec

        logging.info(""Operator:"" + str(self.getID()) + "", type:"" + self.operator_type + "", PythonExecutable: "" +
                     str(self.python_exec) +
                     "", is boundary: "" + str(self.is_boundary()) + "", is source: "" +
                     str(self.source) + "", is sink: "" + str(self.sink))

    def getID(self):
        return self.id

    def is_source(self):
        return self.source

    def is_sink(self):
        return self.sink

    def is_boundary(self):
        return self.boundary

    def serialize_udf(self):
        self.udf = cloudpickle.dumps(self.udf)

    def getIterator(self):
        if self.is_source():
            return self.iterator
        # TODO this should iterate through previous REDESIGN
        return self.udf(self.previous[0].getIterator())

    def set_parameter(self, key, value):
        self.parameters[key] = value

    def set_successor(self, suc):
        if (not self.is_sink()) and self.successor.count(suc) == 0:
            self.successor.append(suc)

    def set_predecessor(self, suc):
        if self.predecessor.count(suc) == 0:
            self.predecessor.append(suc)

```

33b13ed166582bb29212019ff9be3dc264b98994","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/99/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/100,https://api.github.com/repos/apache/incubator-wayang/issues/100,incubator-wayang,1175355848,100,this should iterate through previous REDESIGN,github-actions,,,,CLOSED,2022-03-21T13:03:41Z,2022-03-21T18:45:53Z,"this should iterate through previous REDESIGN

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/pywayang/orchestrator/operator.py#L109

```python

#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the ""License""); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

import pickle
import cloudpickle
from config.config_reader import get_source_types
from config.config_reader import get_sink_types
from config.config_reader import get_boundary_types
import logging

pickle_protocol = pickle.HIGHEST_PROTOCOL


# Describes an Operation over an intermediate result
# Each operation could be processed by Python or Java platforms
class Operator:

    def __init__(
            self, operator_type=None, udf=None, previous=None,
            iterator=None, python_exec=False
    ):

        # Operator ID
        self.id = id(self)

        # Operator Type
        self.operator_type = operator_type

        # Set Boundaries
        if self.operator_type in get_boundary_types():
            self.boundary = True
        else:
            self.boundary = False

        # UDF Function
        self.udf = udf

        # Source types must come with an Iterator
        self.iterator = iterator
        if operator_type in get_source_types():
            if iterator is None:
                print(""Source Operator Type without an Iterator"")
                raise
            else:
                self.source = True
        else:
            self.source = False

        # Sink Operators
        if operator_type in get_sink_types():
            self.sink = True
        else:
            self.sink = False

        # TODO Why managing previous and predecessors per separate?
        self.previous = previous

        self.successor = []
        self.predecessor = []

        self.parameters = {}

        # Set predecessors and successors from previous
        if self.previous:
            for prev in self.previous:
                if prev is not None:
                    prev.set_successor(self)
                    self.set_predecessor(prev)

        self.python_exec = python_exec

        logging.info(""Operator:"" + str(self.getID()) + "", type:"" + self.operator_type + "", PythonExecutable: "" +
                     str(self.python_exec) +
                     "", is boundary: "" + str(self.is_boundary()) + "", is source: "" +
                     str(self.source) + "", is sink: "" + str(self.sink))

    def getID(self):
        return self.id

    def is_source(self):
        return self.source

    def is_sink(self):
        return self.sink

    def is_boundary(self):
        return self.boundary

    def serialize_udf(self):
        self.udf = cloudpickle.dumps(self.udf)

    def getIterator(self):
        if self.is_source():
            return self.iterator
        # TODO this should iterate through previous REDESIGN
        return self.udf(self.previous[0].getIterator())

    def set_parameter(self, key, value):
        self.parameters[key] = value

    def set_successor(self, suc):
        if (not self.is_sink()) and self.successor.count(suc) == 0:
            self.successor.append(suc)

    def set_predecessor(self, suc):
        if self.predecessor.count(suc) == 0:
            self.predecessor.append(suc)

```

552a18ba849015c40334bc9e43f351b2794a005a","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/100/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/101,https://api.github.com/repos/apache/incubator-wayang/issues/101,incubator-wayang,1175355903,101,add to a config file,github-actions,,,,CLOSED,2022-03-21T13:03:43Z,2022-03-21T18:45:53Z,"add to a config file

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/wayang-api/wayang-api-python/src/main/java/org/apache/wayang/api/python/executor/ProcessFeeder.java#L41

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.python.executor;

import com.google.protobuf.ByteString;
import org.apache.wayang.api.python.function.PythonUdf;
import org.apache.wayang.core.api.exception.WayangException;

import java.io.BufferedOutputStream;
import java.io.DataOutputStream;
import java.io.IOException;
import java.net.Socket;
import java.net.SocketException;
import java.nio.charset.StandardCharsets;
import java.util.Iterator;
import java.util.Map;

public class ProcessFeeder<Input, Output> {

    private Socket socket;
    private PythonUdf<Input, Output> udf;
    private ByteString serializedUDF;
    private Iterable<Input> input;

    //TODO add to a config file
    int END_OF_DATA_SECTION = -1;
    int NULL = -5;

    public ProcessFeeder(
            Socket socket,
            PythonUdf<Input, Output> udf,
            ByteString serializedUDF,
            Iterable<Input> input){

        if(input == null) throw new WayangException(""Nothing to process with Python API"");

        this.socket = socket;
        this.udf = udf;
        this.serializedUDF = serializedUDF;
        this.input = input;

    }

    public void send(){

        try{
            //TODO use config buffer size
            int BUFFER_SIZE = 8192;

            BufferedOutputStream stream = new BufferedOutputStream(socket.getOutputStream(), BUFFER_SIZE);
            DataOutputStream dataOut = new DataOutputStream(stream);

            writeUDF(serializedUDF, dataOut);
            this.writeIteratorToStream(input.iterator(), dataOut);
            dataOut.writeInt(END_OF_DATA_SECTION);
            dataOut.flush();

        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public void writeUDF(ByteString serializedUDF, DataOutputStream dataOut){

        //write(serializedUDF.toByteArray(), dataOut);
        writeBytes(serializedUDF.toByteArray(), dataOut);
        System.out.println(""UDF written"");

    }

    public void writeIteratorToStream(Iterator<Input> iter, DataOutputStream dataOut){

        System.out.println(""iterator being send"");
        for (Iterator<Input> it = iter; it.hasNext(); ) {
            Input elem = it.next();
            //System.out.println(elem.toString());
            write(elem, dataOut);
        }
    }

    /*TODO Missing case PortableDataStream */
    public void write(Object obj, DataOutputStream dataOut){
        try {

            if(obj == null)
                dataOut.writeInt(this.NULL);

            /**
             * Byte Array cases
             */
            else if (obj instanceof Byte[] || obj instanceof byte[]) {
                System.out.println(""Writing Bytes"");
                writeBytes(obj, dataOut);
            }
            /**
             * String case
             * */
            else if (obj instanceof String)
                writeUTF((String) obj, dataOut);

            /**
             * Key, Value case
             * */
            else if (obj instanceof Map.Entry)
                writeKeyValue((Map.Entry) obj, dataOut);

            else{
                throw new WayangException(""Unexpected element type "" + obj.getClass());
            }


        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public void writeBytes(Object obj, DataOutputStream dataOut){

        try{

            if (obj instanceof Byte[]) {

                int length = ((Byte[]) obj).length;

                byte[] bytes = new byte[length];
                int j=0;

                // Unboxing Byte values. (Byte[] to byte[])
                for(Byte b: ((Byte[]) obj))
                    bytes[j++] = b.byteValue();

                dataOut.writeInt(length);
                dataOut.write(bytes);

            } else if (obj instanceof byte[]) {

                dataOut.writeInt(((byte[]) obj).length);
                dataOut.write(((byte[]) obj));
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public void writeUTF(String str, DataOutputStream dataOut){

        byte[] bytes = str.getBytes(StandardCharsets.UTF_8);

        try {

            dataOut.writeInt(bytes.length);
            dataOut.write(bytes);
        } catch (SocketException e){

        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public void writeKeyValue(Map.Entry obj, DataOutputStream dataOut){

        write(obj.getKey(), dataOut);
        write(obj.getValue(), dataOut);
    }

}

```

10c00fe30db45034ba821b8fb31d86cc1dd94b3b","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/101/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/102,https://api.github.com/repos/apache/incubator-wayang/issues/102,incubator-wayang,1175355950,102,use config buffer size,github-actions,,,,CLOSED,2022-03-21T13:03:46Z,2022-03-21T18:45:54Z,"use config buffer size

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/wayang-api/wayang-api-python/src/main/java/org/apache/wayang/api/python/executor/ProcessFeeder.java#L63

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.python.executor;

import com.google.protobuf.ByteString;
import org.apache.wayang.api.python.function.PythonUdf;
import org.apache.wayang.core.api.exception.WayangException;

import java.io.BufferedOutputStream;
import java.io.DataOutputStream;
import java.io.IOException;
import java.net.Socket;
import java.net.SocketException;
import java.nio.charset.StandardCharsets;
import java.util.Iterator;
import java.util.Map;

public class ProcessFeeder<Input, Output> {

    private Socket socket;
    private PythonUdf<Input, Output> udf;
    private ByteString serializedUDF;
    private Iterable<Input> input;

    //TODO add to a config file
    int END_OF_DATA_SECTION = -1;
    int NULL = -5;

    public ProcessFeeder(
            Socket socket,
            PythonUdf<Input, Output> udf,
            ByteString serializedUDF,
            Iterable<Input> input){

        if(input == null) throw new WayangException(""Nothing to process with Python API"");

        this.socket = socket;
        this.udf = udf;
        this.serializedUDF = serializedUDF;
        this.input = input;

    }

    public void send(){

        try{
            //TODO use config buffer size
            int BUFFER_SIZE = 8192;

            BufferedOutputStream stream = new BufferedOutputStream(socket.getOutputStream(), BUFFER_SIZE);
            DataOutputStream dataOut = new DataOutputStream(stream);

            writeUDF(serializedUDF, dataOut);
            this.writeIteratorToStream(input.iterator(), dataOut);
            dataOut.writeInt(END_OF_DATA_SECTION);
            dataOut.flush();

        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public void writeUDF(ByteString serializedUDF, DataOutputStream dataOut){

        //write(serializedUDF.toByteArray(), dataOut);
        writeBytes(serializedUDF.toByteArray(), dataOut);
        System.out.println(""UDF written"");

    }

    public void writeIteratorToStream(Iterator<Input> iter, DataOutputStream dataOut){

        System.out.println(""iterator being send"");
        for (Iterator<Input> it = iter; it.hasNext(); ) {
            Input elem = it.next();
            //System.out.println(elem.toString());
            write(elem, dataOut);
        }
    }

    /*TODO Missing case PortableDataStream */
    public void write(Object obj, DataOutputStream dataOut){
        try {

            if(obj == null)
                dataOut.writeInt(this.NULL);

            /**
             * Byte Array cases
             */
            else if (obj instanceof Byte[] || obj instanceof byte[]) {
                System.out.println(""Writing Bytes"");
                writeBytes(obj, dataOut);
            }
            /**
             * String case
             * */
            else if (obj instanceof String)
                writeUTF((String) obj, dataOut);

            /**
             * Key, Value case
             * */
            else if (obj instanceof Map.Entry)
                writeKeyValue((Map.Entry) obj, dataOut);

            else{
                throw new WayangException(""Unexpected element type "" + obj.getClass());
            }


        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public void writeBytes(Object obj, DataOutputStream dataOut){

        try{

            if (obj instanceof Byte[]) {

                int length = ((Byte[]) obj).length;

                byte[] bytes = new byte[length];
                int j=0;

                // Unboxing Byte values. (Byte[] to byte[])
                for(Byte b: ((Byte[]) obj))
                    bytes[j++] = b.byteValue();

                dataOut.writeInt(length);
                dataOut.write(bytes);

            } else if (obj instanceof byte[]) {

                dataOut.writeInt(((byte[]) obj).length);
                dataOut.write(((byte[]) obj));
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public void writeUTF(String str, DataOutputStream dataOut){

        byte[] bytes = str.getBytes(StandardCharsets.UTF_8);

        try {

            dataOut.writeInt(bytes.length);
            dataOut.write(bytes);
        } catch (SocketException e){

        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public void writeKeyValue(Map.Entry obj, DataOutputStream dataOut){

        write(obj.getKey(), dataOut);
        write(obj.getValue(), dataOut);
    }

}

```

1123270d0111584d60c442992a6fb02cee29f9b6","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/102/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/103,https://api.github.com/repos/apache/incubator-wayang/issues/103,incubator-wayang,1175355997,103,Missing case PortableDataStream,github-actions,,,,CLOSED,2022-03-21T13:03:48Z,2022-03-21T18:45:54Z,"Missing case PortableDataStream

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/wayang-api/wayang-api-python/src/main/java/org/apache/wayang/api/python/executor/ProcessFeeder.java#L97

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.python.executor;

import com.google.protobuf.ByteString;
import org.apache.wayang.api.python.function.PythonUdf;
import org.apache.wayang.core.api.exception.WayangException;

import java.io.BufferedOutputStream;
import java.io.DataOutputStream;
import java.io.IOException;
import java.net.Socket;
import java.net.SocketException;
import java.nio.charset.StandardCharsets;
import java.util.Iterator;
import java.util.Map;

public class ProcessFeeder<Input, Output> {

    private Socket socket;
    private PythonUdf<Input, Output> udf;
    private ByteString serializedUDF;
    private Iterable<Input> input;

    //TODO add to a config file
    int END_OF_DATA_SECTION = -1;
    int NULL = -5;

    public ProcessFeeder(
            Socket socket,
            PythonUdf<Input, Output> udf,
            ByteString serializedUDF,
            Iterable<Input> input){

        if(input == null) throw new WayangException(""Nothing to process with Python API"");

        this.socket = socket;
        this.udf = udf;
        this.serializedUDF = serializedUDF;
        this.input = input;

    }

    public void send(){

        try{
            //TODO use config buffer size
            int BUFFER_SIZE = 8192;

            BufferedOutputStream stream = new BufferedOutputStream(socket.getOutputStream(), BUFFER_SIZE);
            DataOutputStream dataOut = new DataOutputStream(stream);

            writeUDF(serializedUDF, dataOut);
            this.writeIteratorToStream(input.iterator(), dataOut);
            dataOut.writeInt(END_OF_DATA_SECTION);
            dataOut.flush();

        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public void writeUDF(ByteString serializedUDF, DataOutputStream dataOut){

        //write(serializedUDF.toByteArray(), dataOut);
        writeBytes(serializedUDF.toByteArray(), dataOut);
        System.out.println(""UDF written"");

    }

    public void writeIteratorToStream(Iterator<Input> iter, DataOutputStream dataOut){

        System.out.println(""iterator being send"");
        for (Iterator<Input> it = iter; it.hasNext(); ) {
            Input elem = it.next();
            //System.out.println(elem.toString());
            write(elem, dataOut);
        }
    }

    /*TODO Missing case PortableDataStream */
    public void write(Object obj, DataOutputStream dataOut){
        try {

            if(obj == null)
                dataOut.writeInt(this.NULL);

            /**
             * Byte Array cases
             */
            else if (obj instanceof Byte[] || obj instanceof byte[]) {
                System.out.println(""Writing Bytes"");
                writeBytes(obj, dataOut);
            }
            /**
             * String case
             * */
            else if (obj instanceof String)
                writeUTF((String) obj, dataOut);

            /**
             * Key, Value case
             * */
            else if (obj instanceof Map.Entry)
                writeKeyValue((Map.Entry) obj, dataOut);

            else{
                throw new WayangException(""Unexpected element type "" + obj.getClass());
            }


        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public void writeBytes(Object obj, DataOutputStream dataOut){

        try{

            if (obj instanceof Byte[]) {

                int length = ((Byte[]) obj).length;

                byte[] bytes = new byte[length];
                int j=0;

                // Unboxing Byte values. (Byte[] to byte[])
                for(Byte b: ((Byte[]) obj))
                    bytes[j++] = b.byteValue();

                dataOut.writeInt(length);
                dataOut.write(bytes);

            } else if (obj instanceof byte[]) {

                dataOut.writeInt(((byte[]) obj).length);
                dataOut.write(((byte[]) obj));
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public void writeUTF(String str, DataOutputStream dataOut){

        byte[] bytes = str.getBytes(StandardCharsets.UTF_8);

        try {

            dataOut.writeInt(bytes.length);
            dataOut.write(bytes);
        } catch (SocketException e){

        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public void writeKeyValue(Map.Entry obj, DataOutputStream dataOut){

        write(obj.getKey(), dataOut);
        write(obj.getValue(), dataOut);
    }

}

```

a39f09115503fc5acbf1b5f8db4e52ba6d47567d","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/103/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/104,https://api.github.com/repos/apache/incubator-wayang/issues/104,incubator-wayang,1175356069,104,use config buffer size,github-actions,,,,CLOSED,2022-03-21T13:03:51Z,2022-03-21T18:47:03Z,"use config buffer size

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/wayang-api/wayang-api-python/src/main/java/org/apache/wayang/api/python/executor/ProcessReceiver.java#L34

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.python.executor;

import java.io.BufferedInputStream;
import java.io.DataInputStream;
import java.io.IOException;
import java.net.Socket;
import java.util.Iterator;
/*TODO cannot be always string, include definition for every operator
*  like: map(udf, inputtype, outputtype)*/
public class ProcessReceiver<Output> {

    private ReaderIterator<Output> iterator;

    public ProcessReceiver(Socket socket){
        try{
            //TODO use config buffer size
            int BUFFER_SIZE = 8192;

            DataInputStream stream = new DataInputStream(new BufferedInputStream(socket.getInputStream(), BUFFER_SIZE));
            this.iterator = new ReaderIterator<>(stream);

        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public Iterable<Output> getIterable(){
        return () -> iterator;
    }

    public void print(){
        iterator.forEachRemaining(x -> System.out.println(x.toString()));

    }
}

```

00041f78a7f7fe83b09721ebb1d71cd4c2f14bae","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/104/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/105,https://api.github.com/repos/apache/incubator-wayang/issues/105,incubator-wayang,1175356114,105,"cannot be always string, include definition for every operator",github-actions,,,,CLOSED,2022-03-21T13:03:53Z,2022-03-21T18:47:03Z,"cannot be always string, include definition for every operator

like: map(udf, inputtype, outputtype)

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/wayang-api/wayang-api-python/src/main/java/org/apache/wayang/api/python/executor/ProcessReceiver.java#L26

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.python.executor;

import java.io.BufferedInputStream;
import java.io.DataInputStream;
import java.io.IOException;
import java.net.Socket;
import java.util.Iterator;
/*TODO cannot be always string, include definition for every operator
*  like: map(udf, inputtype, outputtype)*/
public class ProcessReceiver<Output> {

    private ReaderIterator<Output> iterator;

    public ProcessReceiver(Socket socket){
        try{
            //TODO use config buffer size
            int BUFFER_SIZE = 8192;

            DataInputStream stream = new DataInputStream(new BufferedInputStream(socket.getInputStream(), BUFFER_SIZE));
            this.iterator = new ReaderIterator<>(stream);

        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public Iterable<Output> getIterable(){
        return () -> iterator;
    }

    public void print(){
        iterator.forEachRemaining(x -> System.out.println(x.toString()));

    }
}

```

8abd710475aacb398e08336b85000219e3f1432e","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/105/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/106,https://api.github.com/repos/apache/incubator-wayang/issues/106,incubator-wayang,1175356178,106,How to get the config,github-actions,,,,CLOSED,2022-03-21T13:03:56Z,2022-03-21T18:47:04Z,"How to get the config

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/wayang-api/wayang-api-python/src/main/java/org/apache/wayang/api/python/executor/PythonProcessCaller.java#L42

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.python.executor;

import com.google.protobuf.ByteString;
import org.apache.wayang.core.api.Configuration;
import org.apache.wayang.core.api.exception.WayangException;

import java.io.IOException;
import java.net.InetAddress;
import java.net.ServerSocket;
import java.net.Socket;
import java.nio.charset.StandardCharsets;
import java.util.Arrays;
import java.util.Base64;
import java.util.HashMap;
import java.util.Map;

public class PythonProcessCaller {

    private Process process;
    private Socket socket;
    private ServerSocket serverSocket;
    private boolean ready;

    //TODO How to get the config
    private Configuration configuration;

    public PythonProcessCaller(ByteString serializedUDF){

        //TODO create documentation to how to the configuration in the code
        this.configuration = new Configuration(""file:///Users/rodrigopardomeza/wayang/incubator-wayang/wayang-api/wayang-api-python/src/main/resources/wayang-api-python-defaults.properties"");
        this.ready = false;
        byte[] addr = new byte[4];
        addr[0] = 127; addr[1] = 0; addr[2] = 0; addr[3] = 1;

        try {
            /*TODO should NOT be assigned an specific port, set port as 0 (zero)*/
            this.serverSocket = new ServerSocket(0, 1, InetAddress.getByAddress(addr));
            ProcessBuilder pb = new ProcessBuilder(
                    Arrays.asList(
                            ""python3"",
                            this.configuration.getStringProperty(""wayang.api.python.worker"")
                    )
            );
            Map<String, String> workerEnv = pb.environment();
            workerEnv.put(""PYTHON_WORKER_FACTORY_PORT"", String.valueOf(this.serverSocket.getLocalPort()));

            // TODO See what is happening with ENV Python version
            workerEnv.put(""PYTHONPATH"", ""/Users/rodrigopardomeza/wayang/incubator-wayang/pywayang/:/Users/rodrigopardomeza/opt/anaconda3/"");

            pb.redirectOutput(ProcessBuilder.Redirect.INHERIT);
            pb.redirectError(ProcessBuilder.Redirect.INHERIT);
            this.process = pb.start();


            // Redirect worker stdout and stderr
            //IDK redirectStreamsToStderr(worker.getInputStream, worker.getErrorStream)

            // Wait for it to connect to our socket
            this.serverSocket.setSoTimeout(10000);

            try {
                this.socket = this.serverSocket.accept();
                this.serverSocket.setSoTimeout(0);

                if(socket.isConnected())
                    this.ready = true;

            } catch (Exception e) {
                System.out.println(e);
                throw new WayangException(""Python worker failed to connect back."", e);
            }
        } catch (Exception e){
            System.out.println(e);
            throw new WayangException(""Python worker failed"");
        }
    }

    public Process getProcess() {
        return process;
    }

    public Socket getSocket() {
        return socket;
    }

    public boolean isReady(){
        return ready;
    }

    public void close(){
        try {
            this.process.destroy();
            this.socket.close();
            this.serverSocket.close();
            System.out.println(""Everything closed"");
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}

```

45abbc7fea306b9325653d54f42c157c5caffcd7","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/106/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/107,https://api.github.com/repos/apache/incubator-wayang/issues/107,incubator-wayang,1175356212,107,use config buffer size,github-actions,,,,CLOSED,2022-03-21T13:03:58Z,2022-03-21T18:47:04Z,"use config buffer size

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/wayang-api/wayang-api-python/src/main/java/org/apache/wayang/api/python/executor/ProcessReceiver.java#L34

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.python.executor;

import java.io.BufferedInputStream;
import java.io.DataInputStream;
import java.io.IOException;
import java.net.Socket;
import java.util.Iterator;
/*TODO cannot be always string, include definition for every operator
*  like: map(udf, inputtype, outputtype)*/
public class ProcessReceiver<Output> {

    private ReaderIterator<Output> iterator;

    public ProcessReceiver(Socket socket){
        try{
            //TODO use config buffer size
            int BUFFER_SIZE = 8192;

            DataInputStream stream = new DataInputStream(new BufferedInputStream(socket.getInputStream(), BUFFER_SIZE));
            this.iterator = new ReaderIterator<>(stream);

        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public Iterable<Output> getIterable(){
        return () -> iterator;
    }

    public void print(){
        iterator.forEachRemaining(x -> System.out.println(x.toString()));

    }
}

```

00041f78a7f7fe83b09721ebb1d71cd4c2f14bae","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/107/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/108,https://api.github.com/repos/apache/incubator-wayang/issues/108,incubator-wayang,1175356244,108,create documentation to how to the configuration in the code,github-actions,,,,CLOSED,2022-03-21T13:03:59Z,2022-03-21T18:47:05Z,"create documentation to how to the configuration in the code

this.configuration = new Configuration(""file:///Users/rodrigopardomeza/wayang/incubator-wayang/wayang-api/wayang-api-python/src/main/resources/wayang-api-python-defaults.properties"");

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/wayang-api/wayang-api-python/src/main/java/org/apache/wayang/api/python/executor/PythonProcessCaller.java#L47

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.python.executor;

import com.google.protobuf.ByteString;
import org.apache.wayang.core.api.Configuration;
import org.apache.wayang.core.api.exception.WayangException;

import java.io.IOException;
import java.net.InetAddress;
import java.net.ServerSocket;
import java.net.Socket;
import java.nio.charset.StandardCharsets;
import java.util.Arrays;
import java.util.Base64;
import java.util.HashMap;
import java.util.Map;

public class PythonProcessCaller {

    private Process process;
    private Socket socket;
    private ServerSocket serverSocket;
    private boolean ready;

    //TODO How to get the config
    private Configuration configuration;

    public PythonProcessCaller(ByteString serializedUDF){

        //TODO create documentation to how to the configuration in the code
        this.configuration = new Configuration(""file:///Users/rodrigopardomeza/wayang/incubator-wayang/wayang-api/wayang-api-python/src/main/resources/wayang-api-python-defaults.properties"");
        this.ready = false;
        byte[] addr = new byte[4];
        addr[0] = 127; addr[1] = 0; addr[2] = 0; addr[3] = 1;

        try {
            /*TODO should NOT be assigned an specific port, set port as 0 (zero)*/
            this.serverSocket = new ServerSocket(0, 1, InetAddress.getByAddress(addr));
            ProcessBuilder pb = new ProcessBuilder(
                    Arrays.asList(
                            ""python3"",
                            this.configuration.getStringProperty(""wayang.api.python.worker"")
                    )
            );
            Map<String, String> workerEnv = pb.environment();
            workerEnv.put(""PYTHON_WORKER_FACTORY_PORT"", String.valueOf(this.serverSocket.getLocalPort()));

            // TODO See what is happening with ENV Python version
            workerEnv.put(""PYTHONPATH"", ""/Users/rodrigopardomeza/wayang/incubator-wayang/pywayang/:/Users/rodrigopardomeza/opt/anaconda3/"");

            pb.redirectOutput(ProcessBuilder.Redirect.INHERIT);
            pb.redirectError(ProcessBuilder.Redirect.INHERIT);
            this.process = pb.start();


            // Redirect worker stdout and stderr
            //IDK redirectStreamsToStderr(worker.getInputStream, worker.getErrorStream)

            // Wait for it to connect to our socket
            this.serverSocket.setSoTimeout(10000);

            try {
                this.socket = this.serverSocket.accept();
                this.serverSocket.setSoTimeout(0);

                if(socket.isConnected())
                    this.ready = true;

            } catch (Exception e) {
                System.out.println(e);
                throw new WayangException(""Python worker failed to connect back."", e);
            }
        } catch (Exception e){
            System.out.println(e);
            throw new WayangException(""Python worker failed"");
        }
    }

    public Process getProcess() {
        return process;
    }

    public Socket getSocket() {
        return socket;
    }

    public boolean isReady(){
        return ready;
    }

    public void close(){
        try {
            this.process.destroy();
            this.socket.close();
            this.serverSocket.close();
            System.out.println(""Everything closed"");
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}

```

4a0fbc9208e2cedccea3043c1a899cafbe73e522","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/108/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/109,https://api.github.com/repos/apache/incubator-wayang/issues/109,incubator-wayang,1175356269,109,"cannot be always string, include definition for every operator",github-actions,,,,CLOSED,2022-03-21T13:04:00Z,2022-03-21T18:47:05Z,"cannot be always string, include definition for every operator

like: map(udf, inputtype, outputtype)

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/wayang-api/wayang-api-python/src/main/java/org/apache/wayang/api/python/executor/ProcessReceiver.java#L26

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.python.executor;

import java.io.BufferedInputStream;
import java.io.DataInputStream;
import java.io.IOException;
import java.net.Socket;
import java.util.Iterator;
/*TODO cannot be always string, include definition for every operator
*  like: map(udf, inputtype, outputtype)*/
public class ProcessReceiver<Output> {

    private ReaderIterator<Output> iterator;

    public ProcessReceiver(Socket socket){
        try{
            //TODO use config buffer size
            int BUFFER_SIZE = 8192;

            DataInputStream stream = new DataInputStream(new BufferedInputStream(socket.getInputStream(), BUFFER_SIZE));
            this.iterator = new ReaderIterator<>(stream);

        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public Iterable<Output> getIterable(){
        return () -> iterator;
    }

    public void print(){
        iterator.forEachRemaining(x -> System.out.println(x.toString()));

    }
}

```

8abd710475aacb398e08336b85000219e3f1432e","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/109/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/110,https://api.github.com/repos/apache/incubator-wayang/issues/110,incubator-wayang,1175356311,110,See what is happening with ENV Python version,github-actions,,,,CLOSED,2022-03-21T13:04:02Z,2022-03-21T18:47:06Z,"See what is happening with ENV Python version

IDK redirectStreamsToStderr(worker.getInputStream, worker.getErrorStream)

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/wayang-api/wayang-api-python/src/main/java/org/apache/wayang/api/python/executor/PythonProcessCaller.java#L65

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.python.executor;

import com.google.protobuf.ByteString;
import org.apache.wayang.core.api.Configuration;
import org.apache.wayang.core.api.exception.WayangException;

import java.io.IOException;
import java.net.InetAddress;
import java.net.ServerSocket;
import java.net.Socket;
import java.nio.charset.StandardCharsets;
import java.util.Arrays;
import java.util.Base64;
import java.util.HashMap;
import java.util.Map;

public class PythonProcessCaller {

    private Process process;
    private Socket socket;
    private ServerSocket serverSocket;
    private boolean ready;

    //TODO How to get the config
    private Configuration configuration;

    public PythonProcessCaller(ByteString serializedUDF){

        //TODO create documentation to how to the configuration in the code
        this.configuration = new Configuration(""file:///Users/rodrigopardomeza/wayang/incubator-wayang/wayang-api/wayang-api-python/src/main/resources/wayang-api-python-defaults.properties"");
        this.ready = false;
        byte[] addr = new byte[4];
        addr[0] = 127; addr[1] = 0; addr[2] = 0; addr[3] = 1;

        try {
            /*TODO should NOT be assigned an specific port, set port as 0 (zero)*/
            this.serverSocket = new ServerSocket(0, 1, InetAddress.getByAddress(addr));
            ProcessBuilder pb = new ProcessBuilder(
                    Arrays.asList(
                            ""python3"",
                            this.configuration.getStringProperty(""wayang.api.python.worker"")
                    )
            );
            Map<String, String> workerEnv = pb.environment();
            workerEnv.put(""PYTHON_WORKER_FACTORY_PORT"", String.valueOf(this.serverSocket.getLocalPort()));

            // TODO See what is happening with ENV Python version
            workerEnv.put(""PYTHONPATH"", ""/Users/rodrigopardomeza/wayang/incubator-wayang/pywayang/:/Users/rodrigopardomeza/opt/anaconda3/"");

            pb.redirectOutput(ProcessBuilder.Redirect.INHERIT);
            pb.redirectError(ProcessBuilder.Redirect.INHERIT);
            this.process = pb.start();


            // Redirect worker stdout and stderr
            //IDK redirectStreamsToStderr(worker.getInputStream, worker.getErrorStream)

            // Wait for it to connect to our socket
            this.serverSocket.setSoTimeout(10000);

            try {
                this.socket = this.serverSocket.accept();
                this.serverSocket.setSoTimeout(0);

                if(socket.isConnected())
                    this.ready = true;

            } catch (Exception e) {
                System.out.println(e);
                throw new WayangException(""Python worker failed to connect back."", e);
            }
        } catch (Exception e){
            System.out.println(e);
            throw new WayangException(""Python worker failed"");
        }
    }

    public Process getProcess() {
        return process;
    }

    public Socket getSocket() {
        return socket;
    }

    public boolean isReady(){
        return ready;
    }

    public void close(){
        try {
            this.process.destroy();
            this.socket.close();
            this.serverSocket.close();
            System.out.println(""Everything closed"");
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}

```

ff647ebc44c8a28c02079340b5b775e2a5564fbd","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/110/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/111,https://api.github.com/repos/apache/incubator-wayang/issues/111,incubator-wayang,1175356325,111,How to get the config,github-actions,,,,CLOSED,2022-03-21T13:04:03Z,2022-03-21T18:47:07Z,"How to get the config

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/wayang-api/wayang-api-python/src/main/java/org/apache/wayang/api/python/executor/PythonProcessCaller.java#L42

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.python.executor;

import com.google.protobuf.ByteString;
import org.apache.wayang.core.api.Configuration;
import org.apache.wayang.core.api.exception.WayangException;

import java.io.IOException;
import java.net.InetAddress;
import java.net.ServerSocket;
import java.net.Socket;
import java.nio.charset.StandardCharsets;
import java.util.Arrays;
import java.util.Base64;
import java.util.HashMap;
import java.util.Map;

public class PythonProcessCaller {

    private Process process;
    private Socket socket;
    private ServerSocket serverSocket;
    private boolean ready;

    //TODO How to get the config
    private Configuration configuration;

    public PythonProcessCaller(ByteString serializedUDF){

        //TODO create documentation to how to the configuration in the code
        this.configuration = new Configuration(""file:///Users/rodrigopardomeza/wayang/incubator-wayang/wayang-api/wayang-api-python/src/main/resources/wayang-api-python-defaults.properties"");
        this.ready = false;
        byte[] addr = new byte[4];
        addr[0] = 127; addr[1] = 0; addr[2] = 0; addr[3] = 1;

        try {
            /*TODO should NOT be assigned an specific port, set port as 0 (zero)*/
            this.serverSocket = new ServerSocket(0, 1, InetAddress.getByAddress(addr));
            ProcessBuilder pb = new ProcessBuilder(
                    Arrays.asList(
                            ""python3"",
                            this.configuration.getStringProperty(""wayang.api.python.worker"")
                    )
            );
            Map<String, String> workerEnv = pb.environment();
            workerEnv.put(""PYTHON_WORKER_FACTORY_PORT"", String.valueOf(this.serverSocket.getLocalPort()));

            // TODO See what is happening with ENV Python version
            workerEnv.put(""PYTHONPATH"", ""/Users/rodrigopardomeza/wayang/incubator-wayang/pywayang/:/Users/rodrigopardomeza/opt/anaconda3/"");

            pb.redirectOutput(ProcessBuilder.Redirect.INHERIT);
            pb.redirectError(ProcessBuilder.Redirect.INHERIT);
            this.process = pb.start();


            // Redirect worker stdout and stderr
            //IDK redirectStreamsToStderr(worker.getInputStream, worker.getErrorStream)

            // Wait for it to connect to our socket
            this.serverSocket.setSoTimeout(10000);

            try {
                this.socket = this.serverSocket.accept();
                this.serverSocket.setSoTimeout(0);

                if(socket.isConnected())
                    this.ready = true;

            } catch (Exception e) {
                System.out.println(e);
                throw new WayangException(""Python worker failed to connect back."", e);
            }
        } catch (Exception e){
            System.out.println(e);
            throw new WayangException(""Python worker failed"");
        }
    }

    public Process getProcess() {
        return process;
    }

    public Socket getSocket() {
        return socket;
    }

    public boolean isReady(){
        return ready;
    }

    public void close(){
        try {
            this.process.destroy();
            this.socket.close();
            this.serverSocket.close();
            System.out.println(""Everything closed"");
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}

```

45abbc7fea306b9325653d54f42c157c5caffcd7","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/111/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/112,https://api.github.com/repos/apache/incubator-wayang/issues/112,incubator-wayang,1175356375,112,"should NOT be assigned an specific port, set port as 0 (zero)",github-actions,,,,CLOSED,2022-03-21T13:04:04Z,2022-03-21T18:47:07Z,"should NOT be assigned an specific port, set port as 0 (zero)

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/wayang-api/wayang-api-python/src/main/java/org/apache/wayang/api/python/executor/PythonProcessCaller.java#L54

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.python.executor;

import com.google.protobuf.ByteString;
import org.apache.wayang.core.api.Configuration;
import org.apache.wayang.core.api.exception.WayangException;

import java.io.IOException;
import java.net.InetAddress;
import java.net.ServerSocket;
import java.net.Socket;
import java.nio.charset.StandardCharsets;
import java.util.Arrays;
import java.util.Base64;
import java.util.HashMap;
import java.util.Map;

public class PythonProcessCaller {

    private Process process;
    private Socket socket;
    private ServerSocket serverSocket;
    private boolean ready;

    //TODO How to get the config
    private Configuration configuration;

    public PythonProcessCaller(ByteString serializedUDF){

        //TODO create documentation to how to the configuration in the code
        this.configuration = new Configuration(""file:///Users/rodrigopardomeza/wayang/incubator-wayang/wayang-api/wayang-api-python/src/main/resources/wayang-api-python-defaults.properties"");
        this.ready = false;
        byte[] addr = new byte[4];
        addr[0] = 127; addr[1] = 0; addr[2] = 0; addr[3] = 1;

        try {
            /*TODO should NOT be assigned an specific port, set port as 0 (zero)*/
            this.serverSocket = new ServerSocket(0, 1, InetAddress.getByAddress(addr));
            ProcessBuilder pb = new ProcessBuilder(
                    Arrays.asList(
                            ""python3"",
                            this.configuration.getStringProperty(""wayang.api.python.worker"")
                    )
            );
            Map<String, String> workerEnv = pb.environment();
            workerEnv.put(""PYTHON_WORKER_FACTORY_PORT"", String.valueOf(this.serverSocket.getLocalPort()));

            // TODO See what is happening with ENV Python version
            workerEnv.put(""PYTHONPATH"", ""/Users/rodrigopardomeza/wayang/incubator-wayang/pywayang/:/Users/rodrigopardomeza/opt/anaconda3/"");

            pb.redirectOutput(ProcessBuilder.Redirect.INHERIT);
            pb.redirectError(ProcessBuilder.Redirect.INHERIT);
            this.process = pb.start();


            // Redirect worker stdout and stderr
            //IDK redirectStreamsToStderr(worker.getInputStream, worker.getErrorStream)

            // Wait for it to connect to our socket
            this.serverSocket.setSoTimeout(10000);

            try {
                this.socket = this.serverSocket.accept();
                this.serverSocket.setSoTimeout(0);

                if(socket.isConnected())
                    this.ready = true;

            } catch (Exception e) {
                System.out.println(e);
                throw new WayangException(""Python worker failed to connect back."", e);
            }
        } catch (Exception e){
            System.out.println(e);
            throw new WayangException(""Python worker failed"");
        }
    }

    public Process getProcess() {
        return process;
    }

    public Socket getSocket() {
        return socket;
    }

    public boolean isReady(){
        return ready;
    }

    public void close(){
        try {
            this.process.destroy();
            this.socket.close();
            this.serverSocket.close();
            System.out.println(""Everything closed"");
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}

```

e53ef66982b0ddda9c06e9e07b72b10c30fe48b0","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/112/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/113,https://api.github.com/repos/apache/incubator-wayang/issues/113,incubator-wayang,1175356388,113,create documentation to how to the configuration in the code,github-actions,,,,CLOSED,2022-03-21T13:04:05Z,2022-03-21T18:47:08Z,"create documentation to how to the configuration in the code

this.configuration = new Configuration(""file:///Users/rodrigopardomeza/wayang/incubator-wayang/wayang-api/wayang-api-python/src/main/resources/wayang-api-python-defaults.properties"");

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/wayang-api/wayang-api-python/src/main/java/org/apache/wayang/api/python/executor/PythonProcessCaller.java#L47

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.python.executor;

import com.google.protobuf.ByteString;
import org.apache.wayang.core.api.Configuration;
import org.apache.wayang.core.api.exception.WayangException;

import java.io.IOException;
import java.net.InetAddress;
import java.net.ServerSocket;
import java.net.Socket;
import java.nio.charset.StandardCharsets;
import java.util.Arrays;
import java.util.Base64;
import java.util.HashMap;
import java.util.Map;

public class PythonProcessCaller {

    private Process process;
    private Socket socket;
    private ServerSocket serverSocket;
    private boolean ready;

    //TODO How to get the config
    private Configuration configuration;

    public PythonProcessCaller(ByteString serializedUDF){

        //TODO create documentation to how to the configuration in the code
        this.configuration = new Configuration(""file:///Users/rodrigopardomeza/wayang/incubator-wayang/wayang-api/wayang-api-python/src/main/resources/wayang-api-python-defaults.properties"");
        this.ready = false;
        byte[] addr = new byte[4];
        addr[0] = 127; addr[1] = 0; addr[2] = 0; addr[3] = 1;

        try {
            /*TODO should NOT be assigned an specific port, set port as 0 (zero)*/
            this.serverSocket = new ServerSocket(0, 1, InetAddress.getByAddress(addr));
            ProcessBuilder pb = new ProcessBuilder(
                    Arrays.asList(
                            ""python3"",
                            this.configuration.getStringProperty(""wayang.api.python.worker"")
                    )
            );
            Map<String, String> workerEnv = pb.environment();
            workerEnv.put(""PYTHON_WORKER_FACTORY_PORT"", String.valueOf(this.serverSocket.getLocalPort()));

            // TODO See what is happening with ENV Python version
            workerEnv.put(""PYTHONPATH"", ""/Users/rodrigopardomeza/wayang/incubator-wayang/pywayang/:/Users/rodrigopardomeza/opt/anaconda3/"");

            pb.redirectOutput(ProcessBuilder.Redirect.INHERIT);
            pb.redirectError(ProcessBuilder.Redirect.INHERIT);
            this.process = pb.start();


            // Redirect worker stdout and stderr
            //IDK redirectStreamsToStderr(worker.getInputStream, worker.getErrorStream)

            // Wait for it to connect to our socket
            this.serverSocket.setSoTimeout(10000);

            try {
                this.socket = this.serverSocket.accept();
                this.serverSocket.setSoTimeout(0);

                if(socket.isConnected())
                    this.ready = true;

            } catch (Exception e) {
                System.out.println(e);
                throw new WayangException(""Python worker failed to connect back."", e);
            }
        } catch (Exception e){
            System.out.println(e);
            throw new WayangException(""Python worker failed"");
        }
    }

    public Process getProcess() {
        return process;
    }

    public Socket getSocket() {
        return socket;
    }

    public boolean isReady(){
        return ready;
    }

    public void close(){
        try {
            this.process.destroy();
            this.socket.close();
            this.serverSocket.close();
            System.out.println(""Everything closed"");
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}

```

4a0fbc9208e2cedccea3043c1a899cafbe73e522","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/113/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/114,https://api.github.com/repos/apache/incubator-wayang/issues/114,incubator-wayang,1175356432,114,First we must receive the operator + UDF,github-actions,,,,CLOSED,2022-03-21T13:04:07Z,2022-03-21T18:47:09Z,"First we must receive the operator + UDF

print(""base64_message"")

print(base64_message)

print (func)

for x in func([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]): print(x)

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/wayang-api/wayang-api-python/src/main/python/worker.py#L119

```python

#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the ""License""); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

import os
import socket
import struct
import pickle
import base64
import re
import sys


class SpecialLengths(object):
    END_OF_DATA_SECTION = -1
    PYTHON_EXCEPTION_THROWN = -2
    TIMING_DATA = -3
    END_OF_STREAM = -4
    NULL = -5
    START_ARROW_STREAM = -6


def read_int(stream):
    length = stream.read(4)
    if not length:
        raise EOFError
    res = struct.unpack(""!i"", length)[0]
    return res


class UTF8Deserializer:
    """"""
    Deserializes streams written by String.getBytes.
    """"""

    def __init__(self, use_unicode=True):
        self.use_unicode = use_unicode

    def loads(self, stream):
        length = read_int(stream)
        if length == SpecialLengths.END_OF_DATA_SECTION:
            raise EOFError
        elif length == SpecialLengths.NULL:
            return None
        s = stream.read(length)
        return s.decode(""utf-8"") if self.use_unicode else s

    def load_stream(self, stream):
        try:
            while True:
                yield self.loads(stream)
        except struct.error:
            return
        except EOFError:
            return

    def __repr__(self):
        return ""UTF8Deserializer(%s)"" % self.use_unicode


def write_int(p, outfile):
    outfile.write(struct.pack(""!i"", p))


def write_with_length(obj, stream):
    serialized = obj.encode('utf-8')
    if serialized is None:
        raise ValueError(""serialized value should not be None"")
    if len(serialized) > (1 << 31):
        raise ValueError(""can not serialize object larger than 2G"")
    write_int(len(serialized), stream)
    stream.write(serialized)


def dump_stream(iterator, stream):

    for obj in iterator:
        if type(obj) is str:
            write_with_length(obj, stream)
        ## elif type(obj) is list:
        ##    write_with_length(obj, stream)
    print(""Termine"")
    write_int(SpecialLengths.END_OF_DATA_SECTION, stream)
    print(""Escribi Fin"")


def process(infile, outfile):
    """"""udf64 = os.environ[""UDF""]
    print(""udf64"")
    print(udf64)
    #serialized_udf = binascii.a2b_base64(udf64)
    #serialized_udf = base64.b64decode(udf64)
    serialized_udf = bytearray(udf64, encoding='utf-16')
    # NOT VALID TO BE UTF8  serialized_udf = bytes(udf64, 'UTF-8')
    print(""serialized_udf"")
    print(serialized_udf)
    # input to be ast.literal_eval(serialized_udf)
    func = pickle.loads(serialized_udf, encoding=""bytes"")
    print (""func"")
    print (func)
    print(func([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]))
    # func([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])""""""



    # TODO First we must receive the operator + UDF
    """"""udf = lambda elem: elem.lower()

    def func(it):
        return sorted(it, key=udf)""""""
    udf_length = read_int(infile)
    print(""udf_length"")
    print(udf_length)
    serialized_udf = infile.read(udf_length)
    print(""serialized_udf"")
    print(serialized_udf)
    #base64_message = base64.b64decode(serialized_udf + ""==="")
    #print(""base64_message"")
    #print(base64_message)
    func = pickle.loads(serialized_udf)
    #func = ori.lala(serialized_udf)
    #print (func)
    #for x in func([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]): print(x)

    """"""print(""example"")
    for x in func(""2344|234|efrf|$#|ffrf""): print(x)""""""
    # TODO Here we are temporarily assuming that the user is exclusively sending UTF8. User has several types
    iterator = UTF8Deserializer().load_stream(infile)
    # out_iter = sorted(iterator, key=lambda elem: elem.lower())
    out_iter = func(iterator)
    dump_stream(iterator=out_iter, stream=outfile)


def local_connect(port):
    sock = None
    errors = []
    # Support for both IPv4 and IPv6.
    # On most of IPv6-ready systems, IPv6 will take precedence.
    for res in socket.getaddrinfo(""127.0.0.1"", port, socket.AF_UNSPEC, socket.SOCK_STREAM):
        af, socktype, proto, _, sa = res
        try:
            sock = socket.socket(af, socktype, proto)
            # sock.settimeout(int(os.environ.get(""SPARK_AUTH_SOCKET_TIMEOUT"", 15)))
            sock.settimeout(30)
            sock.connect(sa)
            # sockfile = sock.makefile(""rwb"", int(os.environ.get(""SPARK_BUFFER_SIZE"", 65536)))
            sockfile = sock.makefile(""rwb"", 65536)
            # _do_server_auth(sockfile, auth_secret)
            return (sockfile, sock)
        except socket.error as e:
            emsg = str(e)
            errors.append(""tried to connect to %s, but an error occurred: %s"" % (sa, emsg))
            sock.close()
            sock = None
    raise Exception(""could not open socket: %s"" % errors)


if __name__ == '__main__':
    print(""Python version"")
    print (sys.version)
    java_port = int(os.environ[""PYTHON_WORKER_FACTORY_PORT""])
    sock_file, sock = local_connect(java_port)
    process(sock_file, sock_file)
    sock_file.flush()
    exit()

```

af039622f101f845343bfb05bdcec8c3ef432251","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/114/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/115,https://api.github.com/repos/apache/incubator-wayang/issues/115,incubator-wayang,1175356441,115,See what is happening with ENV Python version,github-actions,,,,CLOSED,2022-03-21T13:04:07Z,2022-03-21T18:47:09Z,"See what is happening with ENV Python version

IDK redirectStreamsToStderr(worker.getInputStream, worker.getErrorStream)

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/wayang-api/wayang-api-python/src/main/java/org/apache/wayang/api/python/executor/PythonProcessCaller.java#L65

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.python.executor;

import com.google.protobuf.ByteString;
import org.apache.wayang.core.api.Configuration;
import org.apache.wayang.core.api.exception.WayangException;

import java.io.IOException;
import java.net.InetAddress;
import java.net.ServerSocket;
import java.net.Socket;
import java.nio.charset.StandardCharsets;
import java.util.Arrays;
import java.util.Base64;
import java.util.HashMap;
import java.util.Map;

public class PythonProcessCaller {

    private Process process;
    private Socket socket;
    private ServerSocket serverSocket;
    private boolean ready;

    //TODO How to get the config
    private Configuration configuration;

    public PythonProcessCaller(ByteString serializedUDF){

        //TODO create documentation to how to the configuration in the code
        this.configuration = new Configuration(""file:///Users/rodrigopardomeza/wayang/incubator-wayang/wayang-api/wayang-api-python/src/main/resources/wayang-api-python-defaults.properties"");
        this.ready = false;
        byte[] addr = new byte[4];
        addr[0] = 127; addr[1] = 0; addr[2] = 0; addr[3] = 1;

        try {
            /*TODO should NOT be assigned an specific port, set port as 0 (zero)*/
            this.serverSocket = new ServerSocket(0, 1, InetAddress.getByAddress(addr));
            ProcessBuilder pb = new ProcessBuilder(
                    Arrays.asList(
                            ""python3"",
                            this.configuration.getStringProperty(""wayang.api.python.worker"")
                    )
            );
            Map<String, String> workerEnv = pb.environment();
            workerEnv.put(""PYTHON_WORKER_FACTORY_PORT"", String.valueOf(this.serverSocket.getLocalPort()));

            // TODO See what is happening with ENV Python version
            workerEnv.put(""PYTHONPATH"", ""/Users/rodrigopardomeza/wayang/incubator-wayang/pywayang/:/Users/rodrigopardomeza/opt/anaconda3/"");

            pb.redirectOutput(ProcessBuilder.Redirect.INHERIT);
            pb.redirectError(ProcessBuilder.Redirect.INHERIT);
            this.process = pb.start();


            // Redirect worker stdout and stderr
            //IDK redirectStreamsToStderr(worker.getInputStream, worker.getErrorStream)

            // Wait for it to connect to our socket
            this.serverSocket.setSoTimeout(10000);

            try {
                this.socket = this.serverSocket.accept();
                this.serverSocket.setSoTimeout(0);

                if(socket.isConnected())
                    this.ready = true;

            } catch (Exception e) {
                System.out.println(e);
                throw new WayangException(""Python worker failed to connect back."", e);
            }
        } catch (Exception e){
            System.out.println(e);
            throw new WayangException(""Python worker failed"");
        }
    }

    public Process getProcess() {
        return process;
    }

    public Socket getSocket() {
        return socket;
    }

    public boolean isReady(){
        return ready;
    }

    public void close(){
        try {
            this.process.destroy();
            this.socket.close();
            this.serverSocket.close();
            System.out.println(""Everything closed"");
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}

```

ff647ebc44c8a28c02079340b5b775e2a5564fbd","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/115/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/116,https://api.github.com/repos/apache/incubator-wayang/issues/116,incubator-wayang,1175356488,116,Here we are temporarily assuming that the user is exclusively sending UTF8. User...,github-actions,,,,CLOSED,2022-03-21T13:04:09Z,2022-03-21T18:47:10Z,"Here we are temporarily assuming that the user is exclusively sending UTF8. User has several types

On most of IPv6-ready systems, IPv6 will take precedence.

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/wayang-api/wayang-api-python/src/main/python/worker.py#L140

```python

#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the ""License""); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

import os
import socket
import struct
import pickle
import base64
import re
import sys


class SpecialLengths(object):
    END_OF_DATA_SECTION = -1
    PYTHON_EXCEPTION_THROWN = -2
    TIMING_DATA = -3
    END_OF_STREAM = -4
    NULL = -5
    START_ARROW_STREAM = -6


def read_int(stream):
    length = stream.read(4)
    if not length:
        raise EOFError
    res = struct.unpack(""!i"", length)[0]
    return res


class UTF8Deserializer:
    """"""
    Deserializes streams written by String.getBytes.
    """"""

    def __init__(self, use_unicode=True):
        self.use_unicode = use_unicode

    def loads(self, stream):
        length = read_int(stream)
        if length == SpecialLengths.END_OF_DATA_SECTION:
            raise EOFError
        elif length == SpecialLengths.NULL:
            return None
        s = stream.read(length)
        return s.decode(""utf-8"") if self.use_unicode else s

    def load_stream(self, stream):
        try:
            while True:
                yield self.loads(stream)
        except struct.error:
            return
        except EOFError:
            return

    def __repr__(self):
        return ""UTF8Deserializer(%s)"" % self.use_unicode


def write_int(p, outfile):
    outfile.write(struct.pack(""!i"", p))


def write_with_length(obj, stream):
    serialized = obj.encode('utf-8')
    if serialized is None:
        raise ValueError(""serialized value should not be None"")
    if len(serialized) > (1 << 31):
        raise ValueError(""can not serialize object larger than 2G"")
    write_int(len(serialized), stream)
    stream.write(serialized)


def dump_stream(iterator, stream):

    for obj in iterator:
        if type(obj) is str:
            write_with_length(obj, stream)
        ## elif type(obj) is list:
        ##    write_with_length(obj, stream)
    print(""Termine"")
    write_int(SpecialLengths.END_OF_DATA_SECTION, stream)
    print(""Escribi Fin"")


def process(infile, outfile):
    """"""udf64 = os.environ[""UDF""]
    print(""udf64"")
    print(udf64)
    #serialized_udf = binascii.a2b_base64(udf64)
    #serialized_udf = base64.b64decode(udf64)
    serialized_udf = bytearray(udf64, encoding='utf-16')
    # NOT VALID TO BE UTF8  serialized_udf = bytes(udf64, 'UTF-8')
    print(""serialized_udf"")
    print(serialized_udf)
    # input to be ast.literal_eval(serialized_udf)
    func = pickle.loads(serialized_udf, encoding=""bytes"")
    print (""func"")
    print (func)
    print(func([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]))
    # func([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])""""""



    # TODO First we must receive the operator + UDF
    """"""udf = lambda elem: elem.lower()

    def func(it):
        return sorted(it, key=udf)""""""
    udf_length = read_int(infile)
    print(""udf_length"")
    print(udf_length)
    serialized_udf = infile.read(udf_length)
    print(""serialized_udf"")
    print(serialized_udf)
    #base64_message = base64.b64decode(serialized_udf + ""==="")
    #print(""base64_message"")
    #print(base64_message)
    func = pickle.loads(serialized_udf)
    #func = ori.lala(serialized_udf)
    #print (func)
    #for x in func([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]): print(x)

    """"""print(""example"")
    for x in func(""2344|234|efrf|$#|ffrf""): print(x)""""""
    # TODO Here we are temporarily assuming that the user is exclusively sending UTF8. User has several types
    iterator = UTF8Deserializer().load_stream(infile)
    # out_iter = sorted(iterator, key=lambda elem: elem.lower())
    out_iter = func(iterator)
    dump_stream(iterator=out_iter, stream=outfile)


def local_connect(port):
    sock = None
    errors = []
    # Support for both IPv4 and IPv6.
    # On most of IPv6-ready systems, IPv6 will take precedence.
    for res in socket.getaddrinfo(""127.0.0.1"", port, socket.AF_UNSPEC, socket.SOCK_STREAM):
        af, socktype, proto, _, sa = res
        try:
            sock = socket.socket(af, socktype, proto)
            # sock.settimeout(int(os.environ.get(""SPARK_AUTH_SOCKET_TIMEOUT"", 15)))
            sock.settimeout(30)
            sock.connect(sa)
            # sockfile = sock.makefile(""rwb"", int(os.environ.get(""SPARK_BUFFER_SIZE"", 65536)))
            sockfile = sock.makefile(""rwb"", 65536)
            # _do_server_auth(sockfile, auth_secret)
            return (sockfile, sock)
        except socket.error as e:
            emsg = str(e)
            errors.append(""tried to connect to %s, but an error occurred: %s"" % (sa, emsg))
            sock.close()
            sock = None
    raise Exception(""could not open socket: %s"" % errors)


if __name__ == '__main__':
    print(""Python version"")
    print (sys.version)
    java_port = int(os.environ[""PYTHON_WORKER_FACTORY_PORT""])
    sock_file, sock = local_connect(java_port)
    process(sock_file, sock_file)
    sock_file.flush()
    exit()

```

f57e9e4e72ff5497ee6a645385c8fc0b3a44d5ba","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/116/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/117,https://api.github.com/repos/apache/incubator-wayang/issues/117,incubator-wayang,1175356498,117,"should NOT be assigned an specific port, set port as 0 (zero)",github-actions,,,,CLOSED,2022-03-21T13:04:10Z,2022-03-21T18:47:10Z,"should NOT be assigned an specific port, set port as 0 (zero)

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/wayang-api/wayang-api-python/src/main/java/org/apache/wayang/api/python/executor/PythonProcessCaller.java#L54

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.python.executor;

import com.google.protobuf.ByteString;
import org.apache.wayang.core.api.Configuration;
import org.apache.wayang.core.api.exception.WayangException;

import java.io.IOException;
import java.net.InetAddress;
import java.net.ServerSocket;
import java.net.Socket;
import java.nio.charset.StandardCharsets;
import java.util.Arrays;
import java.util.Base64;
import java.util.HashMap;
import java.util.Map;

public class PythonProcessCaller {

    private Process process;
    private Socket socket;
    private ServerSocket serverSocket;
    private boolean ready;

    //TODO How to get the config
    private Configuration configuration;

    public PythonProcessCaller(ByteString serializedUDF){

        //TODO create documentation to how to the configuration in the code
        this.configuration = new Configuration(""file:///Users/rodrigopardomeza/wayang/incubator-wayang/wayang-api/wayang-api-python/src/main/resources/wayang-api-python-defaults.properties"");
        this.ready = false;
        byte[] addr = new byte[4];
        addr[0] = 127; addr[1] = 0; addr[2] = 0; addr[3] = 1;

        try {
            /*TODO should NOT be assigned an specific port, set port as 0 (zero)*/
            this.serverSocket = new ServerSocket(0, 1, InetAddress.getByAddress(addr));
            ProcessBuilder pb = new ProcessBuilder(
                    Arrays.asList(
                            ""python3"",
                            this.configuration.getStringProperty(""wayang.api.python.worker"")
                    )
            );
            Map<String, String> workerEnv = pb.environment();
            workerEnv.put(""PYTHON_WORKER_FACTORY_PORT"", String.valueOf(this.serverSocket.getLocalPort()));

            // TODO See what is happening with ENV Python version
            workerEnv.put(""PYTHONPATH"", ""/Users/rodrigopardomeza/wayang/incubator-wayang/pywayang/:/Users/rodrigopardomeza/opt/anaconda3/"");

            pb.redirectOutput(ProcessBuilder.Redirect.INHERIT);
            pb.redirectError(ProcessBuilder.Redirect.INHERIT);
            this.process = pb.start();


            // Redirect worker stdout and stderr
            //IDK redirectStreamsToStderr(worker.getInputStream, worker.getErrorStream)

            // Wait for it to connect to our socket
            this.serverSocket.setSoTimeout(10000);

            try {
                this.socket = this.serverSocket.accept();
                this.serverSocket.setSoTimeout(0);

                if(socket.isConnected())
                    this.ready = true;

            } catch (Exception e) {
                System.out.println(e);
                throw new WayangException(""Python worker failed to connect back."", e);
            }
        } catch (Exception e){
            System.out.println(e);
            throw new WayangException(""Python worker failed"");
        }
    }

    public Process getProcess() {
        return process;
    }

    public Socket getSocket() {
        return socket;
    }

    public boolean isReady(){
        return ready;
    }

    public void close(){
        try {
            this.process.destroy();
            this.socket.close();
            this.serverSocket.close();
            System.out.println(""Everything closed"");
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}

```

e53ef66982b0ddda9c06e9e07b72b10c30fe48b0","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/117/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/118,https://api.github.com/repos/apache/incubator-wayang/issues/118,incubator-wayang,1175356533,118,Connect with predecessors requires more details in connection slot,github-actions,,,,CLOSED,2022-03-21T13:04:12Z,2022-03-21T18:47:11Z,"Connect with predecessors requires more details in connection slot

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/wayang-api/wayang-api-rest/src/main/java/org/apache/wayang/api/rest/server/spring/decoder/WayangPlanBuilder.java#L134

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.rest.server.spring.decoder;

import com.google.protobuf.InvalidProtocolBufferException;
import org.apache.wayang.api.python.function.WrappedPythonFunction;
import org.apache.wayang.basic.operators.MapPartitionsOperator;
import org.apache.wayang.basic.operators.TextFileSink;
import org.apache.wayang.basic.operators.TextFileSource;
import org.apache.wayang.basic.operators.UnionAllOperator;
import org.apache.wayang.commons.serializable.OperatorProto;
import org.apache.wayang.commons.serializable.PlanProto;
import org.apache.wayang.commons.serializable.WayangPlanProto;
import org.apache.wayang.core.api.WayangContext;
import org.apache.wayang.core.api.exception.WayangException;
import org.apache.wayang.core.function.MapPartitionsDescriptor;
import org.apache.wayang.core.plan.wayangplan.OperatorBase;
import org.apache.wayang.core.plan.wayangplan.WayangPlan;
import org.apache.wayang.java.Java;
import org.apache.wayang.spark.Spark;

import java.io.File;
import java.io.FileInputStream;
import java.io.IOException;
import java.net.MalformedURLException;
import java.net.URL;
import java.util.*;
import java.util.stream.Collectors;
import java.util.Base64;

public class WayangPlanBuilder {

    private WayangPlan wayangPlan;
    private WayangContext wayangContext;

    public WayangPlanBuilder(FileInputStream planFile){
        try {

            WayangPlanProto plan = WayangPlanProto.parseFrom(planFile);

            this.wayangContext = buildContext(plan);
            this.wayangPlan = buildPlan(plan);

        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public WayangPlanBuilder(String writtenPlan){

        System.out.println(writtenPlan);
        byte[] message = Base64.getDecoder().decode(writtenPlan);
        System.out.println(message);

        try {
            WayangPlanProto plan = WayangPlanProto.parseFrom(message);

            this.wayangContext = buildContext(plan);
            this.wayangPlan = buildPlan(plan);
        } catch (InvalidProtocolBufferException e) {
            e.printStackTrace();
        }

    }

    private WayangContext buildContext(WayangPlanProto plan){

        WayangContext ctx = new WayangContext();
        plan.getContext().getPlatformsList().forEach(platform -> {
            if (platform.getNumber() == 0)
                ctx.with(Java.basicPlugin());
            else if (platform.getNumber() == 1)
                ctx.with(Spark.basicPlugin());
        });
        //ctx.with(Spark.basicPlugin());

        return ctx;
    }

    private WayangPlan buildPlan(WayangPlanProto plan){

        System.out.println(plan);

        PlanProto planProto = plan.getPlan();
        LinkedList<OperatorProto> protoList = new LinkedList<>();
        planProto.getSourcesList().forEach(protoList::addLast);

        Map<String, OperatorBase> operators = new HashMap<>();
        List<OperatorBase> sinks = new ArrayList<>();
        while(! protoList.isEmpty()) {

            OperatorProto proto = protoList.pollFirst();

            /* Checking if protoOperator can be connected to the current WayangPlan*/
            boolean processIt;
            if(proto.getType().equals(""source"")) processIt = true;

            else {
                /* Checking if ALL predecessors were already processed */
                processIt = true;
                for(String predecessor : proto.getPredecessorsList()){
                    if (!operators.containsKey(predecessor)) {
                        processIt = false;
                        break;
                    }
                }
            }

            /* Operators should not be processed twice*/
            if(operators.containsKey(proto.getId())) processIt = false;

            if(processIt) {

                /* Create and store Wayang operator */
                OperatorBase operator = createOperatorByType(proto);
                operators.put(proto.getId(), operator);

                /*TODO Connect with predecessors requires more details in connection slot*/
                int order = 0;
                for (String pre_id : proto.getPredecessorsList()) {

                    OperatorBase predecessor = operators.get(pre_id);
                    /* Only works without replicate topology */
                    predecessor.connectTo(0, operator, order);
                    order++;

                    if(proto.getType().equals(""sink"")){
                        sinks.add(operator);
                        //if(!sinks.contains(operator)) {
                        //    sinks.add(operator);
                        //}
                    }
                }

                /*List of OperatorProto successors
                 * They will be added to the protoList
                 * nevertheless they must be processed only if the parents are in operators list */
                List<OperatorProto> listSuccessors = planProto.getOperatorsList()
                        .stream()
                        .filter(t -> proto.getSuccessorsList().contains(t.getId()))
                        .collect(Collectors.toList());
                for (OperatorProto successor : listSuccessors){
                    if(!protoList.contains(successor)){
                        protoList.addLast(successor);
                    }
                }

                List<OperatorProto> sinkSuccessors = planProto.getSinksList()
                        .stream()
                        .filter(t -> proto.getSuccessorsList().contains(t.getId()))
                        .collect(Collectors.toList());
                for (OperatorProto successor : sinkSuccessors){
                    if(!protoList.contains(successor)){
                        protoList.addLast(successor);
                    }
                }

            } else {

                /* In case we cannot process it yet, It must be added again at the end*/
                protoList.addLast(proto);
            }
        }

        WayangPlan wayangPlan = new WayangPlan(sinks.get(0));
        return wayangPlan;
    }

    public OperatorBase createOperatorByType(OperatorProto operator){

        System.out.println(""Typo: "" + operator.getType());
        switch(operator.getType()){
            case ""source"":
                try {
                    String source_path = operator.getPath();
                    URL url = new File(source_path).toURI().toURL();
                    return new TextFileSource(url.toString());
                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""sink"":
                try {
                    String sink_path = operator.getPath();
                    URL url = new File(sink_path).toURI().toURL();
                    return new TextFileSink<String>(
                            url.toString(),
                            String.class
                    );

                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""map_partition"":
                return new MapPartitionsOperator<>(
                        new MapPartitionsDescriptor<String, String>(
                                new WrappedPythonFunction<String, String>(
                                        l -> l,
                                        operator.getUdf()
                                ),
                                String.class,
                                String.class
                        )
                );

            case ""union"":
                return new UnionAllOperator<String>(
                        String.class
                );

        }

        throw new WayangException(""Operator Type not supported"");
    }

    public WayangContext getWayangContext() {
        return wayangContext;
    }

    public WayangPlan getWayangPlan() {
        return wayangPlan;
    }
}

```

74c68f9b6dfefde05989465bbcac62fa6ebc504d","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/118/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/119,https://api.github.com/repos/apache/incubator-wayang/issues/119,incubator-wayang,1175356548,119,First we must receive the operator + UDF,github-actions,,,,CLOSED,2022-03-21T13:04:12Z,2022-03-21T18:47:12Z,"First we must receive the operator + UDF

print(""base64_message"")

print(base64_message)

print (func)

for x in func([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]): print(x)

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/wayang-api/wayang-api-python/src/main/python/worker.py#L119

```python

#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the ""License""); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

import os
import socket
import struct
import pickle
import base64
import re
import sys


class SpecialLengths(object):
    END_OF_DATA_SECTION = -1
    PYTHON_EXCEPTION_THROWN = -2
    TIMING_DATA = -3
    END_OF_STREAM = -4
    NULL = -5
    START_ARROW_STREAM = -6


def read_int(stream):
    length = stream.read(4)
    if not length:
        raise EOFError
    res = struct.unpack(""!i"", length)[0]
    return res


class UTF8Deserializer:
    """"""
    Deserializes streams written by String.getBytes.
    """"""

    def __init__(self, use_unicode=True):
        self.use_unicode = use_unicode

    def loads(self, stream):
        length = read_int(stream)
        if length == SpecialLengths.END_OF_DATA_SECTION:
            raise EOFError
        elif length == SpecialLengths.NULL:
            return None
        s = stream.read(length)
        return s.decode(""utf-8"") if self.use_unicode else s

    def load_stream(self, stream):
        try:
            while True:
                yield self.loads(stream)
        except struct.error:
            return
        except EOFError:
            return

    def __repr__(self):
        return ""UTF8Deserializer(%s)"" % self.use_unicode


def write_int(p, outfile):
    outfile.write(struct.pack(""!i"", p))


def write_with_length(obj, stream):
    serialized = obj.encode('utf-8')
    if serialized is None:
        raise ValueError(""serialized value should not be None"")
    if len(serialized) > (1 << 31):
        raise ValueError(""can not serialize object larger than 2G"")
    write_int(len(serialized), stream)
    stream.write(serialized)


def dump_stream(iterator, stream):

    for obj in iterator:
        if type(obj) is str:
            write_with_length(obj, stream)
        ## elif type(obj) is list:
        ##    write_with_length(obj, stream)
    print(""Termine"")
    write_int(SpecialLengths.END_OF_DATA_SECTION, stream)
    print(""Escribi Fin"")


def process(infile, outfile):
    """"""udf64 = os.environ[""UDF""]
    print(""udf64"")
    print(udf64)
    #serialized_udf = binascii.a2b_base64(udf64)
    #serialized_udf = base64.b64decode(udf64)
    serialized_udf = bytearray(udf64, encoding='utf-16')
    # NOT VALID TO BE UTF8  serialized_udf = bytes(udf64, 'UTF-8')
    print(""serialized_udf"")
    print(serialized_udf)
    # input to be ast.literal_eval(serialized_udf)
    func = pickle.loads(serialized_udf, encoding=""bytes"")
    print (""func"")
    print (func)
    print(func([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]))
    # func([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])""""""



    # TODO First we must receive the operator + UDF
    """"""udf = lambda elem: elem.lower()

    def func(it):
        return sorted(it, key=udf)""""""
    udf_length = read_int(infile)
    print(""udf_length"")
    print(udf_length)
    serialized_udf = infile.read(udf_length)
    print(""serialized_udf"")
    print(serialized_udf)
    #base64_message = base64.b64decode(serialized_udf + ""==="")
    #print(""base64_message"")
    #print(base64_message)
    func = pickle.loads(serialized_udf)
    #func = ori.lala(serialized_udf)
    #print (func)
    #for x in func([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]): print(x)

    """"""print(""example"")
    for x in func(""2344|234|efrf|$#|ffrf""): print(x)""""""
    # TODO Here we are temporarily assuming that the user is exclusively sending UTF8. User has several types
    iterator = UTF8Deserializer().load_stream(infile)
    # out_iter = sorted(iterator, key=lambda elem: elem.lower())
    out_iter = func(iterator)
    dump_stream(iterator=out_iter, stream=outfile)


def local_connect(port):
    sock = None
    errors = []
    # Support for both IPv4 and IPv6.
    # On most of IPv6-ready systems, IPv6 will take precedence.
    for res in socket.getaddrinfo(""127.0.0.1"", port, socket.AF_UNSPEC, socket.SOCK_STREAM):
        af, socktype, proto, _, sa = res
        try:
            sock = socket.socket(af, socktype, proto)
            # sock.settimeout(int(os.environ.get(""SPARK_AUTH_SOCKET_TIMEOUT"", 15)))
            sock.settimeout(30)
            sock.connect(sa)
            # sockfile = sock.makefile(""rwb"", int(os.environ.get(""SPARK_BUFFER_SIZE"", 65536)))
            sockfile = sock.makefile(""rwb"", 65536)
            # _do_server_auth(sockfile, auth_secret)
            return (sockfile, sock)
        except socket.error as e:
            emsg = str(e)
            errors.append(""tried to connect to %s, but an error occurred: %s"" % (sa, emsg))
            sock.close()
            sock = None
    raise Exception(""could not open socket: %s"" % errors)


if __name__ == '__main__':
    print(""Python version"")
    print (sys.version)
    java_port = int(os.environ[""PYTHON_WORKER_FACTORY_PORT""])
    sock_file, sock = local_connect(java_port)
    process(sock_file, sock_file)
    sock_file.flush()
    exit()

```

af039622f101f845343bfb05bdcec8c3ef432251","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/119/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/120,https://api.github.com/repos/apache/incubator-wayang/issues/120,incubator-wayang,1175356598,120,ADD id to executions,github-actions,,,,CLOSED,2022-03-21T13:04:14Z,2022-03-21T18:47:12Z,"ADD id to executions

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/wayang-api/wayang-api-rest/src/main/java/org/apache/wayang/api/rest/server/spring/general/WayangController.java#L68

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.rest.server.spring.general;

import com.google.protobuf.ByteString;
import org.apache.wayang.api.python.function.WrappedPythonFunction;
import org.apache.wayang.api.rest.server.spring.decoder.WayangPlanBuilder;
import org.apache.wayang.basic.operators.*;
import org.apache.wayang.commons.serializable.OperatorProto;
import org.apache.wayang.commons.serializable.PlanProto;
import org.apache.wayang.core.api.WayangContext;
import org.apache.wayang.core.api.exception.WayangException;
import org.apache.wayang.core.function.MapPartitionsDescriptor;
import org.apache.wayang.core.plan.wayangplan.OperatorBase;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.RestController;

import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.IOException;
import java.net.MalformedURLException;
import java.net.URI;
import java.net.URISyntaxException;
import java.net.URL;
import java.nio.file.Paths;
import java.util.*;
import java.util.stream.Collectors;

import org.apache.wayang.core.plan.wayangplan.WayangPlan;
import org.apache.wayang.java.Java;
import org.apache.wayang.spark.Spark;

import org.apache.wayang.commons.serializable.WayangPlanProto;
import org.springframework.web.multipart.MultipartFile;


@RestController
public class WayangController {

    @GetMapping(""/plan/create/fromfile"")
    public String planFromFile(
            //@RequestParam(""file"") MultipartFile file
    ){

        try {
            FileInputStream inputStream = new FileInputStream(Paths.get(""."").toRealPath() + ""/protobuf/wayang_message"");
            WayangPlanBuilder wpb = new WayangPlanBuilder(inputStream);

            /*TODO ADD id to executions*/
            wpb.getWayangContext().execute(wpb.getWayangPlan());

        } catch (IOException e) {
            e.printStackTrace();
        }

        return ""Builder works"";
    }

    @PostMapping(""/plan/create"")
    public String planFromMessage(
            @RequestParam(""message"") String message
    ){

        WayangPlanBuilder wpb = new WayangPlanBuilder(message);

        /*TODO ADD id to executions*/
        wpb.getWayangContext().execute(wpb.getWayangPlan());

        return """";
    }

    @GetMapping(""/"")
    public String all(){
        System.out.println(""detected!"");

        try {
            FileInputStream inputStream = new FileInputStream(Paths.get(""."").toRealPath() + ""/protobuf/wayang_message"");
            WayangPlanProto plan = WayangPlanProto.parseFrom(inputStream);

            WayangContext wc = buildContext(plan);
            WayangPlan wp = buildPlan(plan);

            System.out.println(""Plan!"");
            System.out.println(wp.toString());

            wc.execute(wp);
            return(""Works!"");

        } catch (FileNotFoundException e) {
            e.printStackTrace();
        } catch (IOException e) {
            e.printStackTrace();
        }

        return ""Not working"";
    }

    private WayangContext buildContext(WayangPlanProto plan){

        WayangContext ctx = new WayangContext();
        plan.getContext().getPlatformsList().forEach(platform -> {
            if (platform.getNumber() == 0)
                ctx.with(Java.basicPlugin());
            else if (platform.getNumber() == 1)
                ctx.with(Spark.basicPlugin());
        });
        //ctx.with(Spark.basicPlugin());

        return ctx;
    }

    private WayangPlan buildPlan(WayangPlanProto plan){

        System.out.println(plan);

        PlanProto planProto = plan.getPlan();
        LinkedList<OperatorProto> protoList = new LinkedList<>();
        planProto.getSourcesList().forEach(protoList::addLast);

        Map<String, OperatorBase> operators = new HashMap<>();
        List<OperatorBase> sinks = new ArrayList<>();
        while(! protoList.isEmpty()) {

            OperatorProto proto = protoList.pollFirst();

            /* Checking if protoOperator can be connected to the current WayangPlan*/
            boolean processIt;
            if(proto.getType().equals(""source"")) processIt = true;

            else {
                /* Checking if ALL predecessors were already processed */
                processIt = true;
                for(String predecessor : proto.getPredecessorsList()){
                    if (!operators.containsKey(predecessor)) {
                        processIt = false;
                        break;
                    }
                }
            }

            /* Operators should not be processed twice*/
            if(operators.containsKey(proto.getId())) processIt = false;

            if(processIt) {

                /* Create and store Wayang operator */
                OperatorBase operator = createOperatorByType(proto);
                operators.put(proto.getId(), operator);

                /*TODO Connect with predecessors requires more details in connection slot*/
                int order = 0;
                for (String pre_id : proto.getPredecessorsList()) {

                    OperatorBase predecessor = operators.get(pre_id);
                    /* Only works without replicate topology */
                    predecessor.connectTo(0, operator, order);
                    order++;

                    if(proto.getType().equals(""sink"")){
                        sinks.add(operator);
                        //if(!sinks.contains(operator)) {
                        //    sinks.add(operator);
                        //}
                    }
                }

                /*List of OperatorProto successors
                 * They will be added to the protoList
                 * nevertheless they must be processed only if the parents are in operators list */
                List<OperatorProto> listSuccessors = planProto.getOperatorsList()
                        .stream()
                        .filter(t -> proto.getSuccessorsList().contains(t.getId()))
                        .collect(Collectors.toList());
                for (OperatorProto successor : listSuccessors){
                    if(!protoList.contains(successor)){
                        protoList.addLast(successor);
                    }
                }

                List<OperatorProto> sinkSuccessors = planProto.getSinksList()
                        .stream()
                        .filter(t -> proto.getSuccessorsList().contains(t.getId()))
                        .collect(Collectors.toList());
                for (OperatorProto successor : sinkSuccessors){
                    if(!protoList.contains(successor)){
                        protoList.addLast(successor);
                    }
                }

            } else {

                /* In case we cannot process it yet, It must be added again at the end*/
                protoList.addLast(proto);
            }
        }

        WayangPlan wayangPlan = new WayangPlan(sinks.get(0));
        return wayangPlan;
    }

    public OperatorBase createOperatorByType(OperatorProto operator){

        System.out.println(""Typo: "" + operator.getType());
        switch(operator.getType()){
            case ""source"":
                try {
                    String source_path = operator.getPath();
                    URL url = new File(source_path).toURI().toURL();
                    return new TextFileSource(url.toString());
                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""sink"":
                try {
                    String sink_path = operator.getPath();
                    URL url = new File(sink_path).toURI().toURL();
                    return new TextFileSink<String>(
                            url.toString(),
                            String.class
                    );

                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""reduce_by_key"":
                try {
                    /* Function to be applied in Python workers */
                    ByteString function = operator.getUdf();

                    /* Has dimension or positions that compose GroupKey */
                    Map<String, String> parameters = operator.getParametersMap();

                    PyWayangReduceByOperator<String, String> op = new PyWayangReduceByOperator(
                        operator.getParametersMap(),
                        operator.getUdf() ,
                        String.class,
                        String.class,
                            false
                    );

                    String sink_path = operator.getPath();
                    URL url = new File(sink_path).toURI().toURL();
                    return new TextFileSink<String>(
                            url.toString(),
                            String.class
                    );

                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""map_partition"":
                return new MapPartitionsOperator<>(
                    new MapPartitionsDescriptor<String, String>(
                        new WrappedPythonFunction<String, String>(
                            l -> l,
                            operator.getUdf()
                        ),
                        String.class,
                        String.class
                    )
                );

            case ""union"":
                return new UnionAllOperator<String>(
                        String.class
                );

        }

        throw new WayangException(""Operator Type not supported"");
    }

    public static URI createUri(String resourcePath) {
        try {
            return Thread.currentThread().getClass().getResource(resourcePath).toURI();
        } catch (URISyntaxException e) {
            throw new IllegalArgumentException(""Illegal URI."", e);
        }

    }

}

```

b85732398b37855b6b38d657127ec8b731d0cb6c","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/120/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/121,https://api.github.com/repos/apache/incubator-wayang/issues/121,incubator-wayang,1175356604,121,Here we are temporarily assuming that the user is exclusively sending UTF8. User...,github-actions,,,,CLOSED,2022-03-21T13:04:15Z,2022-03-21T18:47:13Z,"Here we are temporarily assuming that the user is exclusively sending UTF8. User has several types

On most of IPv6-ready systems, IPv6 will take precedence.

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/wayang-api/wayang-api-python/src/main/python/worker.py#L140

```python

#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the ""License""); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

import os
import socket
import struct
import pickle
import base64
import re
import sys


class SpecialLengths(object):
    END_OF_DATA_SECTION = -1
    PYTHON_EXCEPTION_THROWN = -2
    TIMING_DATA = -3
    END_OF_STREAM = -4
    NULL = -5
    START_ARROW_STREAM = -6


def read_int(stream):
    length = stream.read(4)
    if not length:
        raise EOFError
    res = struct.unpack(""!i"", length)[0]
    return res


class UTF8Deserializer:
    """"""
    Deserializes streams written by String.getBytes.
    """"""

    def __init__(self, use_unicode=True):
        self.use_unicode = use_unicode

    def loads(self, stream):
        length = read_int(stream)
        if length == SpecialLengths.END_OF_DATA_SECTION:
            raise EOFError
        elif length == SpecialLengths.NULL:
            return None
        s = stream.read(length)
        return s.decode(""utf-8"") if self.use_unicode else s

    def load_stream(self, stream):
        try:
            while True:
                yield self.loads(stream)
        except struct.error:
            return
        except EOFError:
            return

    def __repr__(self):
        return ""UTF8Deserializer(%s)"" % self.use_unicode


def write_int(p, outfile):
    outfile.write(struct.pack(""!i"", p))


def write_with_length(obj, stream):
    serialized = obj.encode('utf-8')
    if serialized is None:
        raise ValueError(""serialized value should not be None"")
    if len(serialized) > (1 << 31):
        raise ValueError(""can not serialize object larger than 2G"")
    write_int(len(serialized), stream)
    stream.write(serialized)


def dump_stream(iterator, stream):

    for obj in iterator:
        if type(obj) is str:
            write_with_length(obj, stream)
        ## elif type(obj) is list:
        ##    write_with_length(obj, stream)
    print(""Termine"")
    write_int(SpecialLengths.END_OF_DATA_SECTION, stream)
    print(""Escribi Fin"")


def process(infile, outfile):
    """"""udf64 = os.environ[""UDF""]
    print(""udf64"")
    print(udf64)
    #serialized_udf = binascii.a2b_base64(udf64)
    #serialized_udf = base64.b64decode(udf64)
    serialized_udf = bytearray(udf64, encoding='utf-16')
    # NOT VALID TO BE UTF8  serialized_udf = bytes(udf64, 'UTF-8')
    print(""serialized_udf"")
    print(serialized_udf)
    # input to be ast.literal_eval(serialized_udf)
    func = pickle.loads(serialized_udf, encoding=""bytes"")
    print (""func"")
    print (func)
    print(func([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]))
    # func([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])""""""



    # TODO First we must receive the operator + UDF
    """"""udf = lambda elem: elem.lower()

    def func(it):
        return sorted(it, key=udf)""""""
    udf_length = read_int(infile)
    print(""udf_length"")
    print(udf_length)
    serialized_udf = infile.read(udf_length)
    print(""serialized_udf"")
    print(serialized_udf)
    #base64_message = base64.b64decode(serialized_udf + ""==="")
    #print(""base64_message"")
    #print(base64_message)
    func = pickle.loads(serialized_udf)
    #func = ori.lala(serialized_udf)
    #print (func)
    #for x in func([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]): print(x)

    """"""print(""example"")
    for x in func(""2344|234|efrf|$#|ffrf""): print(x)""""""
    # TODO Here we are temporarily assuming that the user is exclusively sending UTF8. User has several types
    iterator = UTF8Deserializer().load_stream(infile)
    # out_iter = sorted(iterator, key=lambda elem: elem.lower())
    out_iter = func(iterator)
    dump_stream(iterator=out_iter, stream=outfile)


def local_connect(port):
    sock = None
    errors = []
    # Support for both IPv4 and IPv6.
    # On most of IPv6-ready systems, IPv6 will take precedence.
    for res in socket.getaddrinfo(""127.0.0.1"", port, socket.AF_UNSPEC, socket.SOCK_STREAM):
        af, socktype, proto, _, sa = res
        try:
            sock = socket.socket(af, socktype, proto)
            # sock.settimeout(int(os.environ.get(""SPARK_AUTH_SOCKET_TIMEOUT"", 15)))
            sock.settimeout(30)
            sock.connect(sa)
            # sockfile = sock.makefile(""rwb"", int(os.environ.get(""SPARK_BUFFER_SIZE"", 65536)))
            sockfile = sock.makefile(""rwb"", 65536)
            # _do_server_auth(sockfile, auth_secret)
            return (sockfile, sock)
        except socket.error as e:
            emsg = str(e)
            errors.append(""tried to connect to %s, but an error occurred: %s"" % (sa, emsg))
            sock.close()
            sock = None
    raise Exception(""could not open socket: %s"" % errors)


if __name__ == '__main__':
    print(""Python version"")
    print (sys.version)
    java_port = int(os.environ[""PYTHON_WORKER_FACTORY_PORT""])
    sock_file, sock = local_connect(java_port)
    process(sock_file, sock_file)
    sock_file.flush()
    exit()

```

f57e9e4e72ff5497ee6a645385c8fc0b3a44d5ba","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/121/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/122,https://api.github.com/repos/apache/incubator-wayang/issues/122,incubator-wayang,1175356654,122,ADD id to executions,github-actions,,,,CLOSED,2022-03-21T13:04:17Z,2022-03-21T18:47:14Z,"ADD id to executions

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/wayang-api/wayang-api-rest/src/main/java/org/apache/wayang/api/rest/server/spring/general/WayangController.java#L85

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.rest.server.spring.general;

import com.google.protobuf.ByteString;
import org.apache.wayang.api.python.function.WrappedPythonFunction;
import org.apache.wayang.api.rest.server.spring.decoder.WayangPlanBuilder;
import org.apache.wayang.basic.operators.*;
import org.apache.wayang.commons.serializable.OperatorProto;
import org.apache.wayang.commons.serializable.PlanProto;
import org.apache.wayang.core.api.WayangContext;
import org.apache.wayang.core.api.exception.WayangException;
import org.apache.wayang.core.function.MapPartitionsDescriptor;
import org.apache.wayang.core.plan.wayangplan.OperatorBase;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.RestController;

import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.IOException;
import java.net.MalformedURLException;
import java.net.URI;
import java.net.URISyntaxException;
import java.net.URL;
import java.nio.file.Paths;
import java.util.*;
import java.util.stream.Collectors;

import org.apache.wayang.core.plan.wayangplan.WayangPlan;
import org.apache.wayang.java.Java;
import org.apache.wayang.spark.Spark;

import org.apache.wayang.commons.serializable.WayangPlanProto;
import org.springframework.web.multipart.MultipartFile;


@RestController
public class WayangController {

    @GetMapping(""/plan/create/fromfile"")
    public String planFromFile(
            //@RequestParam(""file"") MultipartFile file
    ){

        try {
            FileInputStream inputStream = new FileInputStream(Paths.get(""."").toRealPath() + ""/protobuf/wayang_message"");
            WayangPlanBuilder wpb = new WayangPlanBuilder(inputStream);

            /*TODO ADD id to executions*/
            wpb.getWayangContext().execute(wpb.getWayangPlan());

        } catch (IOException e) {
            e.printStackTrace();
        }

        return ""Builder works"";
    }

    @PostMapping(""/plan/create"")
    public String planFromMessage(
            @RequestParam(""message"") String message
    ){

        WayangPlanBuilder wpb = new WayangPlanBuilder(message);

        /*TODO ADD id to executions*/
        wpb.getWayangContext().execute(wpb.getWayangPlan());

        return """";
    }

    @GetMapping(""/"")
    public String all(){
        System.out.println(""detected!"");

        try {
            FileInputStream inputStream = new FileInputStream(Paths.get(""."").toRealPath() + ""/protobuf/wayang_message"");
            WayangPlanProto plan = WayangPlanProto.parseFrom(inputStream);

            WayangContext wc = buildContext(plan);
            WayangPlan wp = buildPlan(plan);

            System.out.println(""Plan!"");
            System.out.println(wp.toString());

            wc.execute(wp);
            return(""Works!"");

        } catch (FileNotFoundException e) {
            e.printStackTrace();
        } catch (IOException e) {
            e.printStackTrace();
        }

        return ""Not working"";
    }

    private WayangContext buildContext(WayangPlanProto plan){

        WayangContext ctx = new WayangContext();
        plan.getContext().getPlatformsList().forEach(platform -> {
            if (platform.getNumber() == 0)
                ctx.with(Java.basicPlugin());
            else if (platform.getNumber() == 1)
                ctx.with(Spark.basicPlugin());
        });
        //ctx.with(Spark.basicPlugin());

        return ctx;
    }

    private WayangPlan buildPlan(WayangPlanProto plan){

        System.out.println(plan);

        PlanProto planProto = plan.getPlan();
        LinkedList<OperatorProto> protoList = new LinkedList<>();
        planProto.getSourcesList().forEach(protoList::addLast);

        Map<String, OperatorBase> operators = new HashMap<>();
        List<OperatorBase> sinks = new ArrayList<>();
        while(! protoList.isEmpty()) {

            OperatorProto proto = protoList.pollFirst();

            /* Checking if protoOperator can be connected to the current WayangPlan*/
            boolean processIt;
            if(proto.getType().equals(""source"")) processIt = true;

            else {
                /* Checking if ALL predecessors were already processed */
                processIt = true;
                for(String predecessor : proto.getPredecessorsList()){
                    if (!operators.containsKey(predecessor)) {
                        processIt = false;
                        break;
                    }
                }
            }

            /* Operators should not be processed twice*/
            if(operators.containsKey(proto.getId())) processIt = false;

            if(processIt) {

                /* Create and store Wayang operator */
                OperatorBase operator = createOperatorByType(proto);
                operators.put(proto.getId(), operator);

                /*TODO Connect with predecessors requires more details in connection slot*/
                int order = 0;
                for (String pre_id : proto.getPredecessorsList()) {

                    OperatorBase predecessor = operators.get(pre_id);
                    /* Only works without replicate topology */
                    predecessor.connectTo(0, operator, order);
                    order++;

                    if(proto.getType().equals(""sink"")){
                        sinks.add(operator);
                        //if(!sinks.contains(operator)) {
                        //    sinks.add(operator);
                        //}
                    }
                }

                /*List of OperatorProto successors
                 * They will be added to the protoList
                 * nevertheless they must be processed only if the parents are in operators list */
                List<OperatorProto> listSuccessors = planProto.getOperatorsList()
                        .stream()
                        .filter(t -> proto.getSuccessorsList().contains(t.getId()))
                        .collect(Collectors.toList());
                for (OperatorProto successor : listSuccessors){
                    if(!protoList.contains(successor)){
                        protoList.addLast(successor);
                    }
                }

                List<OperatorProto> sinkSuccessors = planProto.getSinksList()
                        .stream()
                        .filter(t -> proto.getSuccessorsList().contains(t.getId()))
                        .collect(Collectors.toList());
                for (OperatorProto successor : sinkSuccessors){
                    if(!protoList.contains(successor)){
                        protoList.addLast(successor);
                    }
                }

            } else {

                /* In case we cannot process it yet, It must be added again at the end*/
                protoList.addLast(proto);
            }
        }

        WayangPlan wayangPlan = new WayangPlan(sinks.get(0));
        return wayangPlan;
    }

    public OperatorBase createOperatorByType(OperatorProto operator){

        System.out.println(""Typo: "" + operator.getType());
        switch(operator.getType()){
            case ""source"":
                try {
                    String source_path = operator.getPath();
                    URL url = new File(source_path).toURI().toURL();
                    return new TextFileSource(url.toString());
                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""sink"":
                try {
                    String sink_path = operator.getPath();
                    URL url = new File(sink_path).toURI().toURL();
                    return new TextFileSink<String>(
                            url.toString(),
                            String.class
                    );

                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""reduce_by_key"":
                try {
                    /* Function to be applied in Python workers */
                    ByteString function = operator.getUdf();

                    /* Has dimension or positions that compose GroupKey */
                    Map<String, String> parameters = operator.getParametersMap();

                    PyWayangReduceByOperator<String, String> op = new PyWayangReduceByOperator(
                        operator.getParametersMap(),
                        operator.getUdf() ,
                        String.class,
                        String.class,
                            false
                    );

                    String sink_path = operator.getPath();
                    URL url = new File(sink_path).toURI().toURL();
                    return new TextFileSink<String>(
                            url.toString(),
                            String.class
                    );

                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""map_partition"":
                return new MapPartitionsOperator<>(
                    new MapPartitionsDescriptor<String, String>(
                        new WrappedPythonFunction<String, String>(
                            l -> l,
                            operator.getUdf()
                        ),
                        String.class,
                        String.class
                    )
                );

            case ""union"":
                return new UnionAllOperator<String>(
                        String.class
                );

        }

        throw new WayangException(""Operator Type not supported"");
    }

    public static URI createUri(String resourcePath) {
        try {
            return Thread.currentThread().getClass().getResource(resourcePath).toURI();
        } catch (URISyntaxException e) {
            throw new IllegalArgumentException(""Illegal URI."", e);
        }

    }

}

```

87ee4971b5736963ad1dcede16329f8f8f3163c9","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/122/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/123,https://api.github.com/repos/apache/incubator-wayang/issues/123,incubator-wayang,1175356658,123,Connect with predecessors requires more details in connection slot,github-actions,,,,CLOSED,2022-03-21T13:04:17Z,2022-03-21T18:47:14Z,"Connect with predecessors requires more details in connection slot

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/wayang-api/wayang-api-rest/src/main/java/org/apache/wayang/api/rest/server/spring/decoder/WayangPlanBuilder.java#L134

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.rest.server.spring.decoder;

import com.google.protobuf.InvalidProtocolBufferException;
import org.apache.wayang.api.python.function.WrappedPythonFunction;
import org.apache.wayang.basic.operators.MapPartitionsOperator;
import org.apache.wayang.basic.operators.TextFileSink;
import org.apache.wayang.basic.operators.TextFileSource;
import org.apache.wayang.basic.operators.UnionAllOperator;
import org.apache.wayang.commons.serializable.OperatorProto;
import org.apache.wayang.commons.serializable.PlanProto;
import org.apache.wayang.commons.serializable.WayangPlanProto;
import org.apache.wayang.core.api.WayangContext;
import org.apache.wayang.core.api.exception.WayangException;
import org.apache.wayang.core.function.MapPartitionsDescriptor;
import org.apache.wayang.core.plan.wayangplan.OperatorBase;
import org.apache.wayang.core.plan.wayangplan.WayangPlan;
import org.apache.wayang.java.Java;
import org.apache.wayang.spark.Spark;

import java.io.File;
import java.io.FileInputStream;
import java.io.IOException;
import java.net.MalformedURLException;
import java.net.URL;
import java.util.*;
import java.util.stream.Collectors;
import java.util.Base64;

public class WayangPlanBuilder {

    private WayangPlan wayangPlan;
    private WayangContext wayangContext;

    public WayangPlanBuilder(FileInputStream planFile){
        try {

            WayangPlanProto plan = WayangPlanProto.parseFrom(planFile);

            this.wayangContext = buildContext(plan);
            this.wayangPlan = buildPlan(plan);

        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public WayangPlanBuilder(String writtenPlan){

        System.out.println(writtenPlan);
        byte[] message = Base64.getDecoder().decode(writtenPlan);
        System.out.println(message);

        try {
            WayangPlanProto plan = WayangPlanProto.parseFrom(message);

            this.wayangContext = buildContext(plan);
            this.wayangPlan = buildPlan(plan);
        } catch (InvalidProtocolBufferException e) {
            e.printStackTrace();
        }

    }

    private WayangContext buildContext(WayangPlanProto plan){

        WayangContext ctx = new WayangContext();
        plan.getContext().getPlatformsList().forEach(platform -> {
            if (platform.getNumber() == 0)
                ctx.with(Java.basicPlugin());
            else if (platform.getNumber() == 1)
                ctx.with(Spark.basicPlugin());
        });
        //ctx.with(Spark.basicPlugin());

        return ctx;
    }

    private WayangPlan buildPlan(WayangPlanProto plan){

        System.out.println(plan);

        PlanProto planProto = plan.getPlan();
        LinkedList<OperatorProto> protoList = new LinkedList<>();
        planProto.getSourcesList().forEach(protoList::addLast);

        Map<String, OperatorBase> operators = new HashMap<>();
        List<OperatorBase> sinks = new ArrayList<>();
        while(! protoList.isEmpty()) {

            OperatorProto proto = protoList.pollFirst();

            /* Checking if protoOperator can be connected to the current WayangPlan*/
            boolean processIt;
            if(proto.getType().equals(""source"")) processIt = true;

            else {
                /* Checking if ALL predecessors were already processed */
                processIt = true;
                for(String predecessor : proto.getPredecessorsList()){
                    if (!operators.containsKey(predecessor)) {
                        processIt = false;
                        break;
                    }
                }
            }

            /* Operators should not be processed twice*/
            if(operators.containsKey(proto.getId())) processIt = false;

            if(processIt) {

                /* Create and store Wayang operator */
                OperatorBase operator = createOperatorByType(proto);
                operators.put(proto.getId(), operator);

                /*TODO Connect with predecessors requires more details in connection slot*/
                int order = 0;
                for (String pre_id : proto.getPredecessorsList()) {

                    OperatorBase predecessor = operators.get(pre_id);
                    /* Only works without replicate topology */
                    predecessor.connectTo(0, operator, order);
                    order++;

                    if(proto.getType().equals(""sink"")){
                        sinks.add(operator);
                        //if(!sinks.contains(operator)) {
                        //    sinks.add(operator);
                        //}
                    }
                }

                /*List of OperatorProto successors
                 * They will be added to the protoList
                 * nevertheless they must be processed only if the parents are in operators list */
                List<OperatorProto> listSuccessors = planProto.getOperatorsList()
                        .stream()
                        .filter(t -> proto.getSuccessorsList().contains(t.getId()))
                        .collect(Collectors.toList());
                for (OperatorProto successor : listSuccessors){
                    if(!protoList.contains(successor)){
                        protoList.addLast(successor);
                    }
                }

                List<OperatorProto> sinkSuccessors = planProto.getSinksList()
                        .stream()
                        .filter(t -> proto.getSuccessorsList().contains(t.getId()))
                        .collect(Collectors.toList());
                for (OperatorProto successor : sinkSuccessors){
                    if(!protoList.contains(successor)){
                        protoList.addLast(successor);
                    }
                }

            } else {

                /* In case we cannot process it yet, It must be added again at the end*/
                protoList.addLast(proto);
            }
        }

        WayangPlan wayangPlan = new WayangPlan(sinks.get(0));
        return wayangPlan;
    }

    public OperatorBase createOperatorByType(OperatorProto operator){

        System.out.println(""Typo: "" + operator.getType());
        switch(operator.getType()){
            case ""source"":
                try {
                    String source_path = operator.getPath();
                    URL url = new File(source_path).toURI().toURL();
                    return new TextFileSource(url.toString());
                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""sink"":
                try {
                    String sink_path = operator.getPath();
                    URL url = new File(sink_path).toURI().toURL();
                    return new TextFileSink<String>(
                            url.toString(),
                            String.class
                    );

                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""map_partition"":
                return new MapPartitionsOperator<>(
                        new MapPartitionsDescriptor<String, String>(
                                new WrappedPythonFunction<String, String>(
                                        l -> l,
                                        operator.getUdf()
                                ),
                                String.class,
                                String.class
                        )
                );

            case ""union"":
                return new UnionAllOperator<String>(
                        String.class
                );

        }

        throw new WayangException(""Operator Type not supported"");
    }

    public WayangContext getWayangContext() {
        return wayangContext;
    }

    public WayangPlan getWayangPlan() {
        return wayangPlan;
    }
}

```

74c68f9b6dfefde05989465bbcac62fa6ebc504d","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/123/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/124,https://api.github.com/repos/apache/incubator-wayang/issues/124,incubator-wayang,1175356713,124,Connect with predecessors requires more details in connection slot,github-actions,,,,CLOSED,2022-03-21T13:04:20Z,2022-03-21T18:47:15Z,"Connect with predecessors requires more details in connection slot

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/wayang-api/wayang-api-rest/src/main/java/org/apache/wayang/api/rest/server/spring/general/WayangController.java#L169

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.rest.server.spring.general;

import com.google.protobuf.ByteString;
import org.apache.wayang.api.python.function.WrappedPythonFunction;
import org.apache.wayang.api.rest.server.spring.decoder.WayangPlanBuilder;
import org.apache.wayang.basic.operators.*;
import org.apache.wayang.commons.serializable.OperatorProto;
import org.apache.wayang.commons.serializable.PlanProto;
import org.apache.wayang.core.api.WayangContext;
import org.apache.wayang.core.api.exception.WayangException;
import org.apache.wayang.core.function.MapPartitionsDescriptor;
import org.apache.wayang.core.plan.wayangplan.OperatorBase;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.RestController;

import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.IOException;
import java.net.MalformedURLException;
import java.net.URI;
import java.net.URISyntaxException;
import java.net.URL;
import java.nio.file.Paths;
import java.util.*;
import java.util.stream.Collectors;

import org.apache.wayang.core.plan.wayangplan.WayangPlan;
import org.apache.wayang.java.Java;
import org.apache.wayang.spark.Spark;

import org.apache.wayang.commons.serializable.WayangPlanProto;
import org.springframework.web.multipart.MultipartFile;


@RestController
public class WayangController {

    @GetMapping(""/plan/create/fromfile"")
    public String planFromFile(
            //@RequestParam(""file"") MultipartFile file
    ){

        try {
            FileInputStream inputStream = new FileInputStream(Paths.get(""."").toRealPath() + ""/protobuf/wayang_message"");
            WayangPlanBuilder wpb = new WayangPlanBuilder(inputStream);

            /*TODO ADD id to executions*/
            wpb.getWayangContext().execute(wpb.getWayangPlan());

        } catch (IOException e) {
            e.printStackTrace();
        }

        return ""Builder works"";
    }

    @PostMapping(""/plan/create"")
    public String planFromMessage(
            @RequestParam(""message"") String message
    ){

        WayangPlanBuilder wpb = new WayangPlanBuilder(message);

        /*TODO ADD id to executions*/
        wpb.getWayangContext().execute(wpb.getWayangPlan());

        return """";
    }

    @GetMapping(""/"")
    public String all(){
        System.out.println(""detected!"");

        try {
            FileInputStream inputStream = new FileInputStream(Paths.get(""."").toRealPath() + ""/protobuf/wayang_message"");
            WayangPlanProto plan = WayangPlanProto.parseFrom(inputStream);

            WayangContext wc = buildContext(plan);
            WayangPlan wp = buildPlan(plan);

            System.out.println(""Plan!"");
            System.out.println(wp.toString());

            wc.execute(wp);
            return(""Works!"");

        } catch (FileNotFoundException e) {
            e.printStackTrace();
        } catch (IOException e) {
            e.printStackTrace();
        }

        return ""Not working"";
    }

    private WayangContext buildContext(WayangPlanProto plan){

        WayangContext ctx = new WayangContext();
        plan.getContext().getPlatformsList().forEach(platform -> {
            if (platform.getNumber() == 0)
                ctx.with(Java.basicPlugin());
            else if (platform.getNumber() == 1)
                ctx.with(Spark.basicPlugin());
        });
        //ctx.with(Spark.basicPlugin());

        return ctx;
    }

    private WayangPlan buildPlan(WayangPlanProto plan){

        System.out.println(plan);

        PlanProto planProto = plan.getPlan();
        LinkedList<OperatorProto> protoList = new LinkedList<>();
        planProto.getSourcesList().forEach(protoList::addLast);

        Map<String, OperatorBase> operators = new HashMap<>();
        List<OperatorBase> sinks = new ArrayList<>();
        while(! protoList.isEmpty()) {

            OperatorProto proto = protoList.pollFirst();

            /* Checking if protoOperator can be connected to the current WayangPlan*/
            boolean processIt;
            if(proto.getType().equals(""source"")) processIt = true;

            else {
                /* Checking if ALL predecessors were already processed */
                processIt = true;
                for(String predecessor : proto.getPredecessorsList()){
                    if (!operators.containsKey(predecessor)) {
                        processIt = false;
                        break;
                    }
                }
            }

            /* Operators should not be processed twice*/
            if(operators.containsKey(proto.getId())) processIt = false;

            if(processIt) {

                /* Create and store Wayang operator */
                OperatorBase operator = createOperatorByType(proto);
                operators.put(proto.getId(), operator);

                /*TODO Connect with predecessors requires more details in connection slot*/
                int order = 0;
                for (String pre_id : proto.getPredecessorsList()) {

                    OperatorBase predecessor = operators.get(pre_id);
                    /* Only works without replicate topology */
                    predecessor.connectTo(0, operator, order);
                    order++;

                    if(proto.getType().equals(""sink"")){
                        sinks.add(operator);
                        //if(!sinks.contains(operator)) {
                        //    sinks.add(operator);
                        //}
                    }
                }

                /*List of OperatorProto successors
                 * They will be added to the protoList
                 * nevertheless they must be processed only if the parents are in operators list */
                List<OperatorProto> listSuccessors = planProto.getOperatorsList()
                        .stream()
                        .filter(t -> proto.getSuccessorsList().contains(t.getId()))
                        .collect(Collectors.toList());
                for (OperatorProto successor : listSuccessors){
                    if(!protoList.contains(successor)){
                        protoList.addLast(successor);
                    }
                }

                List<OperatorProto> sinkSuccessors = planProto.getSinksList()
                        .stream()
                        .filter(t -> proto.getSuccessorsList().contains(t.getId()))
                        .collect(Collectors.toList());
                for (OperatorProto successor : sinkSuccessors){
                    if(!protoList.contains(successor)){
                        protoList.addLast(successor);
                    }
                }

            } else {

                /* In case we cannot process it yet, It must be added again at the end*/
                protoList.addLast(proto);
            }
        }

        WayangPlan wayangPlan = new WayangPlan(sinks.get(0));
        return wayangPlan;
    }

    public OperatorBase createOperatorByType(OperatorProto operator){

        System.out.println(""Typo: "" + operator.getType());
        switch(operator.getType()){
            case ""source"":
                try {
                    String source_path = operator.getPath();
                    URL url = new File(source_path).toURI().toURL();
                    return new TextFileSource(url.toString());
                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""sink"":
                try {
                    String sink_path = operator.getPath();
                    URL url = new File(sink_path).toURI().toURL();
                    return new TextFileSink<String>(
                            url.toString(),
                            String.class
                    );

                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""reduce_by_key"":
                try {
                    /* Function to be applied in Python workers */
                    ByteString function = operator.getUdf();

                    /* Has dimension or positions that compose GroupKey */
                    Map<String, String> parameters = operator.getParametersMap();

                    PyWayangReduceByOperator<String, String> op = new PyWayangReduceByOperator(
                        operator.getParametersMap(),
                        operator.getUdf() ,
                        String.class,
                        String.class,
                            false
                    );

                    String sink_path = operator.getPath();
                    URL url = new File(sink_path).toURI().toURL();
                    return new TextFileSink<String>(
                            url.toString(),
                            String.class
                    );

                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""map_partition"":
                return new MapPartitionsOperator<>(
                    new MapPartitionsDescriptor<String, String>(
                        new WrappedPythonFunction<String, String>(
                            l -> l,
                            operator.getUdf()
                        ),
                        String.class,
                        String.class
                    )
                );

            case ""union"":
                return new UnionAllOperator<String>(
                        String.class
                );

        }

        throw new WayangException(""Operator Type not supported"");
    }

    public static URI createUri(String resourcePath) {
        try {
            return Thread.currentThread().getClass().getResource(resourcePath).toURI();
        } catch (URISyntaxException e) {
            throw new IllegalArgumentException(""Illegal URI."", e);
        }

    }

}

```

46f8cdedd25da6c3205060ebd781dafe78222516","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/124/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/125,https://api.github.com/repos/apache/incubator-wayang/issues/125,incubator-wayang,1175356719,125,ADD id to executions,github-actions,,,,CLOSED,2022-03-21T13:04:20Z,2022-03-21T18:47:16Z,"ADD id to executions

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/wayang-api/wayang-api-rest/src/main/java/org/apache/wayang/api/rest/server/spring/general/WayangController.java#L68

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.rest.server.spring.general;

import com.google.protobuf.ByteString;
import org.apache.wayang.api.python.function.WrappedPythonFunction;
import org.apache.wayang.api.rest.server.spring.decoder.WayangPlanBuilder;
import org.apache.wayang.basic.operators.*;
import org.apache.wayang.commons.serializable.OperatorProto;
import org.apache.wayang.commons.serializable.PlanProto;
import org.apache.wayang.core.api.WayangContext;
import org.apache.wayang.core.api.exception.WayangException;
import org.apache.wayang.core.function.MapPartitionsDescriptor;
import org.apache.wayang.core.plan.wayangplan.OperatorBase;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.RestController;

import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.IOException;
import java.net.MalformedURLException;
import java.net.URI;
import java.net.URISyntaxException;
import java.net.URL;
import java.nio.file.Paths;
import java.util.*;
import java.util.stream.Collectors;

import org.apache.wayang.core.plan.wayangplan.WayangPlan;
import org.apache.wayang.java.Java;
import org.apache.wayang.spark.Spark;

import org.apache.wayang.commons.serializable.WayangPlanProto;
import org.springframework.web.multipart.MultipartFile;


@RestController
public class WayangController {

    @GetMapping(""/plan/create/fromfile"")
    public String planFromFile(
            //@RequestParam(""file"") MultipartFile file
    ){

        try {
            FileInputStream inputStream = new FileInputStream(Paths.get(""."").toRealPath() + ""/protobuf/wayang_message"");
            WayangPlanBuilder wpb = new WayangPlanBuilder(inputStream);

            /*TODO ADD id to executions*/
            wpb.getWayangContext().execute(wpb.getWayangPlan());

        } catch (IOException e) {
            e.printStackTrace();
        }

        return ""Builder works"";
    }

    @PostMapping(""/plan/create"")
    public String planFromMessage(
            @RequestParam(""message"") String message
    ){

        WayangPlanBuilder wpb = new WayangPlanBuilder(message);

        /*TODO ADD id to executions*/
        wpb.getWayangContext().execute(wpb.getWayangPlan());

        return """";
    }

    @GetMapping(""/"")
    public String all(){
        System.out.println(""detected!"");

        try {
            FileInputStream inputStream = new FileInputStream(Paths.get(""."").toRealPath() + ""/protobuf/wayang_message"");
            WayangPlanProto plan = WayangPlanProto.parseFrom(inputStream);

            WayangContext wc = buildContext(plan);
            WayangPlan wp = buildPlan(plan);

            System.out.println(""Plan!"");
            System.out.println(wp.toString());

            wc.execute(wp);
            return(""Works!"");

        } catch (FileNotFoundException e) {
            e.printStackTrace();
        } catch (IOException e) {
            e.printStackTrace();
        }

        return ""Not working"";
    }

    private WayangContext buildContext(WayangPlanProto plan){

        WayangContext ctx = new WayangContext();
        plan.getContext().getPlatformsList().forEach(platform -> {
            if (platform.getNumber() == 0)
                ctx.with(Java.basicPlugin());
            else if (platform.getNumber() == 1)
                ctx.with(Spark.basicPlugin());
        });
        //ctx.with(Spark.basicPlugin());

        return ctx;
    }

    private WayangPlan buildPlan(WayangPlanProto plan){

        System.out.println(plan);

        PlanProto planProto = plan.getPlan();
        LinkedList<OperatorProto> protoList = new LinkedList<>();
        planProto.getSourcesList().forEach(protoList::addLast);

        Map<String, OperatorBase> operators = new HashMap<>();
        List<OperatorBase> sinks = new ArrayList<>();
        while(! protoList.isEmpty()) {

            OperatorProto proto = protoList.pollFirst();

            /* Checking if protoOperator can be connected to the current WayangPlan*/
            boolean processIt;
            if(proto.getType().equals(""source"")) processIt = true;

            else {
                /* Checking if ALL predecessors were already processed */
                processIt = true;
                for(String predecessor : proto.getPredecessorsList()){
                    if (!operators.containsKey(predecessor)) {
                        processIt = false;
                        break;
                    }
                }
            }

            /* Operators should not be processed twice*/
            if(operators.containsKey(proto.getId())) processIt = false;

            if(processIt) {

                /* Create and store Wayang operator */
                OperatorBase operator = createOperatorByType(proto);
                operators.put(proto.getId(), operator);

                /*TODO Connect with predecessors requires more details in connection slot*/
                int order = 0;
                for (String pre_id : proto.getPredecessorsList()) {

                    OperatorBase predecessor = operators.get(pre_id);
                    /* Only works without replicate topology */
                    predecessor.connectTo(0, operator, order);
                    order++;

                    if(proto.getType().equals(""sink"")){
                        sinks.add(operator);
                        //if(!sinks.contains(operator)) {
                        //    sinks.add(operator);
                        //}
                    }
                }

                /*List of OperatorProto successors
                 * They will be added to the protoList
                 * nevertheless they must be processed only if the parents are in operators list */
                List<OperatorProto> listSuccessors = planProto.getOperatorsList()
                        .stream()
                        .filter(t -> proto.getSuccessorsList().contains(t.getId()))
                        .collect(Collectors.toList());
                for (OperatorProto successor : listSuccessors){
                    if(!protoList.contains(successor)){
                        protoList.addLast(successor);
                    }
                }

                List<OperatorProto> sinkSuccessors = planProto.getSinksList()
                        .stream()
                        .filter(t -> proto.getSuccessorsList().contains(t.getId()))
                        .collect(Collectors.toList());
                for (OperatorProto successor : sinkSuccessors){
                    if(!protoList.contains(successor)){
                        protoList.addLast(successor);
                    }
                }

            } else {

                /* In case we cannot process it yet, It must be added again at the end*/
                protoList.addLast(proto);
            }
        }

        WayangPlan wayangPlan = new WayangPlan(sinks.get(0));
        return wayangPlan;
    }

    public OperatorBase createOperatorByType(OperatorProto operator){

        System.out.println(""Typo: "" + operator.getType());
        switch(operator.getType()){
            case ""source"":
                try {
                    String source_path = operator.getPath();
                    URL url = new File(source_path).toURI().toURL();
                    return new TextFileSource(url.toString());
                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""sink"":
                try {
                    String sink_path = operator.getPath();
                    URL url = new File(sink_path).toURI().toURL();
                    return new TextFileSink<String>(
                            url.toString(),
                            String.class
                    );

                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""reduce_by_key"":
                try {
                    /* Function to be applied in Python workers */
                    ByteString function = operator.getUdf();

                    /* Has dimension or positions that compose GroupKey */
                    Map<String, String> parameters = operator.getParametersMap();

                    PyWayangReduceByOperator<String, String> op = new PyWayangReduceByOperator(
                        operator.getParametersMap(),
                        operator.getUdf() ,
                        String.class,
                        String.class,
                            false
                    );

                    String sink_path = operator.getPath();
                    URL url = new File(sink_path).toURI().toURL();
                    return new TextFileSink<String>(
                            url.toString(),
                            String.class
                    );

                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""map_partition"":
                return new MapPartitionsOperator<>(
                    new MapPartitionsDescriptor<String, String>(
                        new WrappedPythonFunction<String, String>(
                            l -> l,
                            operator.getUdf()
                        ),
                        String.class,
                        String.class
                    )
                );

            case ""union"":
                return new UnionAllOperator<String>(
                        String.class
                );

        }

        throw new WayangException(""Operator Type not supported"");
    }

    public static URI createUri(String resourcePath) {
        try {
            return Thread.currentThread().getClass().getResource(resourcePath).toURI();
        } catch (URISyntaxException e) {
            throw new IllegalArgumentException(""Illegal URI."", e);
        }

    }

}

```

b85732398b37855b6b38d657127ec8b731d0cb6c","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/125/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/126,https://api.github.com/repos/apache/incubator-wayang/issues/126,incubator-wayang,1175356782,126,ADD id to executions,github-actions,,,,CLOSED,2022-03-21T13:04:23Z,2022-03-21T18:47:17Z,"ADD id to executions

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/wayang-api/wayang-api-rest/src/main/java/org/apache/wayang/api/rest/server/spring/general/WayangController.java#L85

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.rest.server.spring.general;

import com.google.protobuf.ByteString;
import org.apache.wayang.api.python.function.WrappedPythonFunction;
import org.apache.wayang.api.rest.server.spring.decoder.WayangPlanBuilder;
import org.apache.wayang.basic.operators.*;
import org.apache.wayang.commons.serializable.OperatorProto;
import org.apache.wayang.commons.serializable.PlanProto;
import org.apache.wayang.core.api.WayangContext;
import org.apache.wayang.core.api.exception.WayangException;
import org.apache.wayang.core.function.MapPartitionsDescriptor;
import org.apache.wayang.core.plan.wayangplan.OperatorBase;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.RestController;

import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.IOException;
import java.net.MalformedURLException;
import java.net.URI;
import java.net.URISyntaxException;
import java.net.URL;
import java.nio.file.Paths;
import java.util.*;
import java.util.stream.Collectors;

import org.apache.wayang.core.plan.wayangplan.WayangPlan;
import org.apache.wayang.java.Java;
import org.apache.wayang.spark.Spark;

import org.apache.wayang.commons.serializable.WayangPlanProto;
import org.springframework.web.multipart.MultipartFile;


@RestController
public class WayangController {

    @GetMapping(""/plan/create/fromfile"")
    public String planFromFile(
            //@RequestParam(""file"") MultipartFile file
    ){

        try {
            FileInputStream inputStream = new FileInputStream(Paths.get(""."").toRealPath() + ""/protobuf/wayang_message"");
            WayangPlanBuilder wpb = new WayangPlanBuilder(inputStream);

            /*TODO ADD id to executions*/
            wpb.getWayangContext().execute(wpb.getWayangPlan());

        } catch (IOException e) {
            e.printStackTrace();
        }

        return ""Builder works"";
    }

    @PostMapping(""/plan/create"")
    public String planFromMessage(
            @RequestParam(""message"") String message
    ){

        WayangPlanBuilder wpb = new WayangPlanBuilder(message);

        /*TODO ADD id to executions*/
        wpb.getWayangContext().execute(wpb.getWayangPlan());

        return """";
    }

    @GetMapping(""/"")
    public String all(){
        System.out.println(""detected!"");

        try {
            FileInputStream inputStream = new FileInputStream(Paths.get(""."").toRealPath() + ""/protobuf/wayang_message"");
            WayangPlanProto plan = WayangPlanProto.parseFrom(inputStream);

            WayangContext wc = buildContext(plan);
            WayangPlan wp = buildPlan(plan);

            System.out.println(""Plan!"");
            System.out.println(wp.toString());

            wc.execute(wp);
            return(""Works!"");

        } catch (FileNotFoundException e) {
            e.printStackTrace();
        } catch (IOException e) {
            e.printStackTrace();
        }

        return ""Not working"";
    }

    private WayangContext buildContext(WayangPlanProto plan){

        WayangContext ctx = new WayangContext();
        plan.getContext().getPlatformsList().forEach(platform -> {
            if (platform.getNumber() == 0)
                ctx.with(Java.basicPlugin());
            else if (platform.getNumber() == 1)
                ctx.with(Spark.basicPlugin());
        });
        //ctx.with(Spark.basicPlugin());

        return ctx;
    }

    private WayangPlan buildPlan(WayangPlanProto plan){

        System.out.println(plan);

        PlanProto planProto = plan.getPlan();
        LinkedList<OperatorProto> protoList = new LinkedList<>();
        planProto.getSourcesList().forEach(protoList::addLast);

        Map<String, OperatorBase> operators = new HashMap<>();
        List<OperatorBase> sinks = new ArrayList<>();
        while(! protoList.isEmpty()) {

            OperatorProto proto = protoList.pollFirst();

            /* Checking if protoOperator can be connected to the current WayangPlan*/
            boolean processIt;
            if(proto.getType().equals(""source"")) processIt = true;

            else {
                /* Checking if ALL predecessors were already processed */
                processIt = true;
                for(String predecessor : proto.getPredecessorsList()){
                    if (!operators.containsKey(predecessor)) {
                        processIt = false;
                        break;
                    }
                }
            }

            /* Operators should not be processed twice*/
            if(operators.containsKey(proto.getId())) processIt = false;

            if(processIt) {

                /* Create and store Wayang operator */
                OperatorBase operator = createOperatorByType(proto);
                operators.put(proto.getId(), operator);

                /*TODO Connect with predecessors requires more details in connection slot*/
                int order = 0;
                for (String pre_id : proto.getPredecessorsList()) {

                    OperatorBase predecessor = operators.get(pre_id);
                    /* Only works without replicate topology */
                    predecessor.connectTo(0, operator, order);
                    order++;

                    if(proto.getType().equals(""sink"")){
                        sinks.add(operator);
                        //if(!sinks.contains(operator)) {
                        //    sinks.add(operator);
                        //}
                    }
                }

                /*List of OperatorProto successors
                 * They will be added to the protoList
                 * nevertheless they must be processed only if the parents are in operators list */
                List<OperatorProto> listSuccessors = planProto.getOperatorsList()
                        .stream()
                        .filter(t -> proto.getSuccessorsList().contains(t.getId()))
                        .collect(Collectors.toList());
                for (OperatorProto successor : listSuccessors){
                    if(!protoList.contains(successor)){
                        protoList.addLast(successor);
                    }
                }

                List<OperatorProto> sinkSuccessors = planProto.getSinksList()
                        .stream()
                        .filter(t -> proto.getSuccessorsList().contains(t.getId()))
                        .collect(Collectors.toList());
                for (OperatorProto successor : sinkSuccessors){
                    if(!protoList.contains(successor)){
                        protoList.addLast(successor);
                    }
                }

            } else {

                /* In case we cannot process it yet, It must be added again at the end*/
                protoList.addLast(proto);
            }
        }

        WayangPlan wayangPlan = new WayangPlan(sinks.get(0));
        return wayangPlan;
    }

    public OperatorBase createOperatorByType(OperatorProto operator){

        System.out.println(""Typo: "" + operator.getType());
        switch(operator.getType()){
            case ""source"":
                try {
                    String source_path = operator.getPath();
                    URL url = new File(source_path).toURI().toURL();
                    return new TextFileSource(url.toString());
                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""sink"":
                try {
                    String sink_path = operator.getPath();
                    URL url = new File(sink_path).toURI().toURL();
                    return new TextFileSink<String>(
                            url.toString(),
                            String.class
                    );

                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""reduce_by_key"":
                try {
                    /* Function to be applied in Python workers */
                    ByteString function = operator.getUdf();

                    /* Has dimension or positions that compose GroupKey */
                    Map<String, String> parameters = operator.getParametersMap();

                    PyWayangReduceByOperator<String, String> op = new PyWayangReduceByOperator(
                        operator.getParametersMap(),
                        operator.getUdf() ,
                        String.class,
                        String.class,
                            false
                    );

                    String sink_path = operator.getPath();
                    URL url = new File(sink_path).toURI().toURL();
                    return new TextFileSink<String>(
                            url.toString(),
                            String.class
                    );

                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""map_partition"":
                return new MapPartitionsOperator<>(
                    new MapPartitionsDescriptor<String, String>(
                        new WrappedPythonFunction<String, String>(
                            l -> l,
                            operator.getUdf()
                        ),
                        String.class,
                        String.class
                    )
                );

            case ""union"":
                return new UnionAllOperator<String>(
                        String.class
                );

        }

        throw new WayangException(""Operator Type not supported"");
    }

    public static URI createUri(String resourcePath) {
        try {
            return Thread.currentThread().getClass().getResource(resourcePath).toURI();
        } catch (URISyntaxException e) {
            throw new IllegalArgumentException(""Illegal URI."", e);
        }

    }

}

```

87ee4971b5736963ad1dcede16329f8f8f3163c9","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/126/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/127,https://api.github.com/repos/apache/incubator-wayang/issues/127,incubator-wayang,1175356861,127,Connect with predecessors requires more details in connection slot,github-actions,,,,CLOSED,2022-03-21T13:04:26Z,2022-03-21T18:47:17Z,"Connect with predecessors requires more details in connection slot

https://github.com/apache/incubator-wayang/blob/7fc5b5489baa4cf78fa96c8d9f1f7b3b141ceb98/wayang-api/wayang-api-rest/src/main/java/org/apache/wayang/api/rest/server/spring/general/WayangController.java#L169

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.rest.server.spring.general;

import com.google.protobuf.ByteString;
import org.apache.wayang.api.python.function.WrappedPythonFunction;
import org.apache.wayang.api.rest.server.spring.decoder.WayangPlanBuilder;
import org.apache.wayang.basic.operators.*;
import org.apache.wayang.commons.serializable.OperatorProto;
import org.apache.wayang.commons.serializable.PlanProto;
import org.apache.wayang.core.api.WayangContext;
import org.apache.wayang.core.api.exception.WayangException;
import org.apache.wayang.core.function.MapPartitionsDescriptor;
import org.apache.wayang.core.plan.wayangplan.OperatorBase;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.RestController;

import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.IOException;
import java.net.MalformedURLException;
import java.net.URI;
import java.net.URISyntaxException;
import java.net.URL;
import java.nio.file.Paths;
import java.util.*;
import java.util.stream.Collectors;

import org.apache.wayang.core.plan.wayangplan.WayangPlan;
import org.apache.wayang.java.Java;
import org.apache.wayang.spark.Spark;

import org.apache.wayang.commons.serializable.WayangPlanProto;
import org.springframework.web.multipart.MultipartFile;


@RestController
public class WayangController {

    @GetMapping(""/plan/create/fromfile"")
    public String planFromFile(
            //@RequestParam(""file"") MultipartFile file
    ){

        try {
            FileInputStream inputStream = new FileInputStream(Paths.get(""."").toRealPath() + ""/protobuf/wayang_message"");
            WayangPlanBuilder wpb = new WayangPlanBuilder(inputStream);

            /*TODO ADD id to executions*/
            wpb.getWayangContext().execute(wpb.getWayangPlan());

        } catch (IOException e) {
            e.printStackTrace();
        }

        return ""Builder works"";
    }

    @PostMapping(""/plan/create"")
    public String planFromMessage(
            @RequestParam(""message"") String message
    ){

        WayangPlanBuilder wpb = new WayangPlanBuilder(message);

        /*TODO ADD id to executions*/
        wpb.getWayangContext().execute(wpb.getWayangPlan());

        return """";
    }

    @GetMapping(""/"")
    public String all(){
        System.out.println(""detected!"");

        try {
            FileInputStream inputStream = new FileInputStream(Paths.get(""."").toRealPath() + ""/protobuf/wayang_message"");
            WayangPlanProto plan = WayangPlanProto.parseFrom(inputStream);

            WayangContext wc = buildContext(plan);
            WayangPlan wp = buildPlan(plan);

            System.out.println(""Plan!"");
            System.out.println(wp.toString());

            wc.execute(wp);
            return(""Works!"");

        } catch (FileNotFoundException e) {
            e.printStackTrace();
        } catch (IOException e) {
            e.printStackTrace();
        }

        return ""Not working"";
    }

    private WayangContext buildContext(WayangPlanProto plan){

        WayangContext ctx = new WayangContext();
        plan.getContext().getPlatformsList().forEach(platform -> {
            if (platform.getNumber() == 0)
                ctx.with(Java.basicPlugin());
            else if (platform.getNumber() == 1)
                ctx.with(Spark.basicPlugin());
        });
        //ctx.with(Spark.basicPlugin());

        return ctx;
    }

    private WayangPlan buildPlan(WayangPlanProto plan){

        System.out.println(plan);

        PlanProto planProto = plan.getPlan();
        LinkedList<OperatorProto> protoList = new LinkedList<>();
        planProto.getSourcesList().forEach(protoList::addLast);

        Map<String, OperatorBase> operators = new HashMap<>();
        List<OperatorBase> sinks = new ArrayList<>();
        while(! protoList.isEmpty()) {

            OperatorProto proto = protoList.pollFirst();

            /* Checking if protoOperator can be connected to the current WayangPlan*/
            boolean processIt;
            if(proto.getType().equals(""source"")) processIt = true;

            else {
                /* Checking if ALL predecessors were already processed */
                processIt = true;
                for(String predecessor : proto.getPredecessorsList()){
                    if (!operators.containsKey(predecessor)) {
                        processIt = false;
                        break;
                    }
                }
            }

            /* Operators should not be processed twice*/
            if(operators.containsKey(proto.getId())) processIt = false;

            if(processIt) {

                /* Create and store Wayang operator */
                OperatorBase operator = createOperatorByType(proto);
                operators.put(proto.getId(), operator);

                /*TODO Connect with predecessors requires more details in connection slot*/
                int order = 0;
                for (String pre_id : proto.getPredecessorsList()) {

                    OperatorBase predecessor = operators.get(pre_id);
                    /* Only works without replicate topology */
                    predecessor.connectTo(0, operator, order);
                    order++;

                    if(proto.getType().equals(""sink"")){
                        sinks.add(operator);
                        //if(!sinks.contains(operator)) {
                        //    sinks.add(operator);
                        //}
                    }
                }

                /*List of OperatorProto successors
                 * They will be added to the protoList
                 * nevertheless they must be processed only if the parents are in operators list */
                List<OperatorProto> listSuccessors = planProto.getOperatorsList()
                        .stream()
                        .filter(t -> proto.getSuccessorsList().contains(t.getId()))
                        .collect(Collectors.toList());
                for (OperatorProto successor : listSuccessors){
                    if(!protoList.contains(successor)){
                        protoList.addLast(successor);
                    }
                }

                List<OperatorProto> sinkSuccessors = planProto.getSinksList()
                        .stream()
                        .filter(t -> proto.getSuccessorsList().contains(t.getId()))
                        .collect(Collectors.toList());
                for (OperatorProto successor : sinkSuccessors){
                    if(!protoList.contains(successor)){
                        protoList.addLast(successor);
                    }
                }

            } else {

                /* In case we cannot process it yet, It must be added again at the end*/
                protoList.addLast(proto);
            }
        }

        WayangPlan wayangPlan = new WayangPlan(sinks.get(0));
        return wayangPlan;
    }

    public OperatorBase createOperatorByType(OperatorProto operator){

        System.out.println(""Typo: "" + operator.getType());
        switch(operator.getType()){
            case ""source"":
                try {
                    String source_path = operator.getPath();
                    URL url = new File(source_path).toURI().toURL();
                    return new TextFileSource(url.toString());
                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""sink"":
                try {
                    String sink_path = operator.getPath();
                    URL url = new File(sink_path).toURI().toURL();
                    return new TextFileSink<String>(
                            url.toString(),
                            String.class
                    );

                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""reduce_by_key"":
                try {
                    /* Function to be applied in Python workers */
                    ByteString function = operator.getUdf();

                    /* Has dimension or positions that compose GroupKey */
                    Map<String, String> parameters = operator.getParametersMap();

                    PyWayangReduceByOperator<String, String> op = new PyWayangReduceByOperator(
                        operator.getParametersMap(),
                        operator.getUdf() ,
                        String.class,
                        String.class,
                            false
                    );

                    String sink_path = operator.getPath();
                    URL url = new File(sink_path).toURI().toURL();
                    return new TextFileSink<String>(
                            url.toString(),
                            String.class
                    );

                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""map_partition"":
                return new MapPartitionsOperator<>(
                    new MapPartitionsDescriptor<String, String>(
                        new WrappedPythonFunction<String, String>(
                            l -> l,
                            operator.getUdf()
                        ),
                        String.class,
                        String.class
                    )
                );

            case ""union"":
                return new UnionAllOperator<String>(
                        String.class
                );

        }

        throw new WayangException(""Operator Type not supported"");
    }

    public static URI createUri(String resourcePath) {
        try {
            return Thread.currentThread().getClass().getResource(resourcePath).toURI();
        } catch (URISyntaxException e) {
            throw new IllegalArgumentException(""Illegal URI."", e);
        }

    }

}

```

46f8cdedd25da6c3205060ebd781dafe78222516","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/127/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/128,https://api.github.com/repos/apache/incubator-wayang/issues/128,incubator-wayang,1175368671,128,Stop testing with Travis CI,ro-pardo,6936238,Rodrigo Pardo Meza,ro.pardo.meza@gmail.com,CLOSED,2022-03-21T13:12:56Z,2022-04-04T08:47:16Z,"Last month was decided to start using Github actions for our DevOps pipelines.
Nevertheless Travis is still being executed in addition to Github Actions.

We should delete Travis CI pipelines from the project","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/128/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/128,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5AAiBN,incubator-wayang,1073881165,128,NA,CalvinKirs,16631152,Calvin Kirs,kirs@apache.org,NA,2022-03-21T13:14:38Z,2022-03-21T13:14:38Z,+1. We should create a related Issue for document automation,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5AAiBN/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/134,https://api.github.com/repos/apache/incubator-wayang/issues/134,incubator-wayang,1187097233,134,Add Testing Operator - Apache Flink,berttty,24259784,Bertty Contreras-Rojas,,OPEN,2022-03-30T22:48:49Z,2022-03-30T22:51:44Z,"The [platform-flink](https://github.com/apache/incubator-wayang/tree/main/wayang-platforms/wayang-flink/code) was added and had just the integrations test, but it does not have the operator test like in [platform-spark](https://github.com/apache/incubator-wayang/tree/main/wayang-platforms/wayang-spark/code/test/java/org/apache/wayang/spark)

The idea is to create a similar operators test of platform-spark but in platform-flink ","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/134/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/138,https://api.github.com/repos/apache/incubator-wayang/issues/138,incubator-wayang,1195784457,138,Error in Spark Operator Test,msanyoto,57170771,Matthew JS,,CLOSED,2022-04-07T09:37:37Z,2022-04-11T08:29:08Z,"I tried running this [class](https://github.com/apache/incubator-wayang/blob/main/wayang-platforms/wayang-spark/code/test/java/org/apache/wayang/spark/operators/SparkCartesianOperatorTest.java) in my Intellij. However I got the following error;

Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
22/04/07 11:31:38 WARN Utils: Your hostname, xxx resolves to a loopback address: 127.0.1.1; using 10.x.x.1 instead (on interface wlo1)
22/04/07 11:31:38 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address

java.lang.ExceptionInInitializerError

I think it is a local machine problem in my side. If so, do we need to also add documentation for people trying to use Spark?","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/138/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/138,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5BDf76,incubator-wayang,1091436282,138,NA,2pk03,1323575,Alexander Alten-Lorenz,,NA,2022-04-07T09:41:03Z,2022-04-07T09:41:03Z,"Yeah, that comes with 127.0.0.1 machine name resolver (normally localhost resolves to 127.0.0.1). Please set the local IP of your spark instance with:

EXPORT SPARK_LOCAL_IP=YOUR_IP

Yes, would be great to add this into our FAQ :) ","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5BDf76/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/138,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5BDg7s,incubator-wayang,1091440364,138,NA,msanyoto,57170771,Matthew JS,,NA,2022-04-07T09:45:00Z,2022-04-07T09:45:00Z,"Sorry,

So I just need to open the terminal of the project and just type EXPORT SPARK_LOCAL_IP=MY_IP in the command line?","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5BDg7s/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/138,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5BDhQS,incubator-wayang,1091441682,138,NA,2pk03,1323575,Alexander Alten-Lorenz,,NA,2022-04-07T09:46:03Z,2022-04-07T09:46:03Z,"Yes, in a terminal or via export variables in your IDE. That should to the trick :) ","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5BDhQS/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/138,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5BDnDx,incubator-wayang,1091465457,138,NA,msanyoto,57170771,Matthew JS,,NA,2022-04-07T10:00:21Z,2022-04-07T10:00:21Z,"Lastly, do you need to install Apache Spark to be able to access SPARK_HOME and  have the Spark.env configuration? because I think I need to add it manually to the spark.env and SPARK_LOCAL_IP= localhost. I tried using export SPARK_LOCAL_IP=10.x.x.1 and it didn't work","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5BDnDx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/138,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5BI7Eo,incubator-wayang,1092858152,138,NA,2pk03,1323575,Alexander Alten-Lorenz,,NA,2022-04-08T13:25:45Z,2022-04-08T13:25:45Z,"Yes, I wrote a small blog post about:
https://mapredit.blogspot.com/2021/09/compile-apache-wayang-on-mac-m1.html

For OSX it's easy with brew ","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5BI7Eo/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/138,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5BPxJB,incubator-wayang,1094652481,138,NA,berttty,24259784,Bertty Contreras-Rojas,,NA,2022-04-11T07:33:15Z,2022-04-11T07:33:15Z,"@regaleo605 
Did you solve it?","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5BPxJB/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/138,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5BP8R_,incubator-wayang,1094698111,138,NA,msanyoto,57170771,Matthew JS,,NA,2022-04-11T08:22:56Z,2022-04-11T08:22:56Z,"More or less, so if you don't install Spark then you can't use the command export SPARK_LOCAL_IP in the terminal.

I assume that is also the case with sqlite and maybe other wayang platform?

Thank you in advance","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5BP8R_/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/138,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5BP9AG,incubator-wayang,1094701062,138,NA,2pk03,1323575,Alexander Alten-Lorenz,,NA,2022-04-11T08:25:50Z,2022-04-11T08:25:50Z,"Yes, you need to have access to the platforms to use Wayang. Wayang is a sublayer above the processing frameworks you want to use: wayang.apache.org/documentation 
https://github.com/databloom-ai/BDE is a full prebuilt dev environment, comes also as docker container.","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5BP9AG/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/138,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5BP9yg,incubator-wayang,1094704288,138,NA,msanyoto,57170771,Matthew JS,,NA,2022-04-11T08:29:08Z,2022-04-11T08:29:08Z,"No wonder, then issues solved. Thank you for the clarification. It was helpful","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5BP9yg/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/140,https://api.github.com/repos/apache/incubator-wayang/issues/140,incubator-wayang,1197689601,140,download Apache rat if is needed,github-actions,,,,CLOSED,2022-04-08T18:58:49Z,2023-07-20T15:07:38Z,"download Apache rat if is needed

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/bin/check-license.sh#L22

```sh

#!/bin/bash

################################################################################
##
##  Licensed to the Apache Software Foundation (ASF) under one or more
##  contributor license agreements.  See the NOTICE file distributed with
##  this work for additional information regarding copyright ownership.
##  The ASF licenses this file to You under the Apache License, Version 2.0
##  (the ""License""); you may not use this file except in compliance with
##  the License.  You may obtain a copy of the License at
##
##      http://www.apache.org/licenses/LICENSE-2.0
##
##  Unless required by applicable law or agreed to in writing, software
##  distributed under the License is distributed on an ""AS IS"" BASIS,
##  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
##  See the License for the specific language governing permissions and
##  limitations under the License.
##
################################################################################

# TODO download Apache rat if is needed

BASE=$(cd ""$(dirname ""$0"")/.."" | pwd)
cd ${BASE}
RAT_HOME=/opt/apache-rat-0.13

java -jar ${RAT_HOME}/apache-rat-0.13.jar -E .rat-excludes -d . | grep ""== File:""

```

41da0f5549bd49c7d9717a87eff29f7243e514b5","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/140/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/141,https://api.github.com/repos/apache/incubator-wayang/issues/141,incubator-wayang,1197689626,141,download Apache rat if is needed,github-actions,,,,OPEN,2022-04-08T18:58:51Z,2022-04-08T18:58:52Z,"download Apache rat if is needed

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/bin/check-license.sh#L22

```sh

#!/bin/bash

################################################################################
##
##  Licensed to the Apache Software Foundation (ASF) under one or more
##  contributor license agreements.  See the NOTICE file distributed with
##  this work for additional information regarding copyright ownership.
##  The ASF licenses this file to You under the Apache License, Version 2.0
##  (the ""License""); you may not use this file except in compliance with
##  the License.  You may obtain a copy of the License at
##
##      http://www.apache.org/licenses/LICENSE-2.0
##
##  Unless required by applicable law or agreed to in writing, software
##  distributed under the License is distributed on an ""AS IS"" BASIS,
##  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
##  See the License for the specific language governing permissions and
##  limitations under the License.
##
################################################################################

# TODO download Apache rat if is needed

BASE=$(cd ""$(dirname ""$0"")/.."" | pwd)
cd ${BASE}
RAT_HOME=/opt/apache-rat-0.13

java -jar ${RAT_HOME}/apache-rat-0.13.jar -E .rat-excludes -d . | grep ""== File:""

```

41da0f5549bd49c7d9717a87eff29f7243e514b5","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/141/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/142,https://api.github.com/repos/apache/incubator-wayang/issues/142,incubator-wayang,1197689627,142,"key should be given by ""udf""",github-actions,,,,CLOSED,2022-04-08T18:58:51Z,2023-07-20T15:07:38Z,"key should be given by ""udf""

UDF specifies reducer function

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/old_code/orchestrator/dataquanta.py#L104

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

from old_code.orchestrator.operator import Operator
from old_code.old_graph.graph import Graph
from old_code.old_graph.traversal import Traversal
from old_code.protobuf.planwriter import MessageWriter
import itertools
import collections
import logging
from functools import reduce
import operator


# Wraps a Source operation to create an iterable
class DataQuantaBuilder:
    def __init__(self, descriptor):
        self.descriptor = descriptor

    def source(self, source):

        if type(source) is str:
            source_ori = open(source, ""r"")
        else:
            source_ori = source
        return DataQuanta(
            Operator(
                operator_type=""source"",
                udf=source,
                iterator=iter(source_ori),
                previous=[],
                python_exec=False
            ),
            descriptor=self.descriptor
        )


# Wraps an operation over an iterable
class DataQuanta:
    def __init__(self, operator=None, descriptor=None):
        self.operator = operator
        self.descriptor = descriptor
        if self.operator.is_source():
            self.descriptor.add_source(self.operator)
        if self.operator.is_sink():
            self.descriptor.add_sink(self.operator)

    # Operational Functions
    def filter(self, udf):
        def func(iterator):
            return filter(udf, iterator)

        return DataQuanta(
            Operator(
                operator_type=""filter"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def flatmap(self, udf):

        def auxfunc(iterator):
            return itertools.chain.from_iterable(map(udf, iterator))

        def func(iterator):
            mapped = map(udf, iterator)
            flattened = flatten_single_dim(mapped)
            yield from flattened

        def flatten_single_dim(mapped):
            for item in mapped:
                for subitem in item:
                    yield subitem

        return DataQuanta(
            Operator(
                operator_type=""flatmap"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def group_by(self, udf):
        def func(iterator):
            # TODO key should be given by ""udf""
            return itertools.groupby(iterator, key=operator.itemgetter(0))
            #return itertools.groupby(sorted(iterator), key=itertools.itemgetter(0))

        return DataQuanta(
            Operator(
                operator_type=""group_by"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def map(self, udf):
        def func(iterator):
            return map(udf, iterator)

        return DataQuanta(
            Operator(
                operator_type=""map"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    # Key specifies pivot dimensions
    # UDF specifies reducer function
    def reduce_by_key(self, keys, udf):

        op = Operator(
            operator_type=""reduce_by_key"",
            udf=udf,
            previous=[self.operator],
            python_exec=False
        )

        #print(len(keys), keys)
        for i in range(0, len(keys)):
            """"""if keys[i] is int:
                op.set_parameter(""vector_position|""+str(i), keys[i])
            else:
                op.set_parameter(""dimension_key|""+str(i), keys[i])""""""

            # TODO maybe would be better just leave the number as key
            op.set_parameter(""dimension|""+str(i+1), keys[i])

        return DataQuanta(
            op,
            descriptor=self.descriptor
        )

    def reduce(self, udf):
        def func(iterator):
            return reduce(udf, iterator)

        return DataQuanta(
            Operator(
                operator_type=""reduce"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def sink(self, path, end=""\n""):
        def consume(iterator):
            with open(path, 'w') as f:
                for x in iterator:
                    f.write(str(x) + end)

        def func(iterator):
            consume(iterator)
            # return self.__run(consume)

        return DataQuanta(
            Operator(
                operator_type=""sink"",

                udf=path,
                # To execute directly uncomment
                # udf=func,

                previous=[self.operator],
                python_exec=False
            ),
            descriptor=self.descriptor
        )

    def sort(self, udf):

        def func(iterator):
            return sorted(iterator, key=udf)

        return DataQuanta(
            Operator(
                operator_type=""sort"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    # This function allow the union to be performed by Python
    # Nevertheless, current configuration runs it over Java
    def union(self, other):

        def func(iterator):
            return itertools.chain(iterator, other.operator.getIterator())

        return DataQuanta(
            Operator(
                operator_type=""union"",
                udf=func,
                previous=[self.operator, other.operator],
                python_exec=False
            ),
            descriptor=self.descriptor
        )

    def __run(self, consumer):
        consumer(self.operator.getIterator())

    # Execution Functions
    def console(self, end=""\n""):
        def consume(iterator):
            for x in iterator:
                print(x, end=end)

        self.__run(consume)

    # Only for debugging purposes!
    # To execute the plan directly in the program driver
    def execute(self):
        logging.warn(""DEBUG Execution"")
        logging.info(""Reminder to swap SINK UDF value from path to func"")
        logging.debug(self.operator.previous[0].operator_type)
        if self.operator.is_sink():
            logging.debug(self.operator.operator_type)
            logging.debug(self.operator.udf)
            logging.debug(len(self.operator.previous))
            self.operator.udf(self.operator.previous[0].getIterator())
        else:
            logging.error(""Plan must call execute from SINK type of operator"")
            raise RuntimeError

    # Converts Python Functional Plan to valid Wayang Plan
    def to_wayang_plan(self):

        sinks = self.descriptor.get_sinks()
        if len(sinks) == 0:
            return

        graph = Graph()
        graph.populate(self.descriptor.get_sinks())

        # Uncomment to check the Graph built
        # graph.print_adjlist()

        # Function to be consumed by Traverse
        # Separates Python Plan into a List of Pipelines
        def define_pipelines(node1, current_pipeline, collection):
            def store_unique(pipe_to_insert):
                for pipe in collection:
                    if equivalent_lists(pipe, pipe_to_insert):
                        return
                collection.append(pipe_to_insert)

            def equivalent_lists(l1, l2):
                if collections.Counter(l1) == collections.Counter(l2):
                    return True
                else:
                    return False

            if not current_pipeline:
                current_pipeline = [node1]

            elif node1.operator.is_boundary():
                store_unique(current_pipeline.copy())
                current_pipeline.clear()
                current_pipeline.append(node1)

            else:
                current_pipeline.append(node1)

            if node1.operator.sink:
                store_unique(current_pipeline.copy())
                current_pipeline.clear()

            return current_pipeline

        # Works over the graph
        trans = Traversal(
            graph=graph,
            origin=self.descriptor.get_sources(),
            # udf=lambda x, y, z: d(x, y, z)
            # UDF always will receive:
            # x: a Node object,
            # y: an object representing the result of the last iteration,
            # z: a collection to store final results inside your UDF
            udf=lambda x, y, z: define_pipelines(x, y, z)
        )

        # Gets the results of the traverse process
        collected_stages = trans.get_collected_data()

        # Passing the Stages to a Wayang message writer
        writer = MessageWriter()
        a = 0
        # Stage is composed of class Node objects
        for stage in collected_stages:
            a += 1
            logging.info(""///"")
            logging.info(""stage"" + str(a))
            writer.process_pipeline(stage)

        writer.set_dependencies()

        # Uses a file to provide the plan
        # writer.write_message(self.descriptor)

        # Send the plan to Wayang REST api directly
        writer.send_message(self.descriptor)

```

a6624919e50a9242a0f67e19e436fa077b474a10","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/142/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/143,https://api.github.com/repos/apache/incubator-wayang/issues/143,incubator-wayang,1197689653,143,"key should be given by ""udf""",github-actions,,,,OPEN,2022-04-08T18:58:53Z,2022-04-08T18:58:54Z,"key should be given by ""udf""

UDF specifies reducer function

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/old_code/orchestrator/dataquanta.py#L104

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

from old_code.orchestrator.operator import Operator
from old_code.old_graph.graph import Graph
from old_code.old_graph.traversal import Traversal
from old_code.protobuf.planwriter import MessageWriter
import itertools
import collections
import logging
from functools import reduce
import operator


# Wraps a Source operation to create an iterable
class DataQuantaBuilder:
    def __init__(self, descriptor):
        self.descriptor = descriptor

    def source(self, source):

        if type(source) is str:
            source_ori = open(source, ""r"")
        else:
            source_ori = source
        return DataQuanta(
            Operator(
                operator_type=""source"",
                udf=source,
                iterator=iter(source_ori),
                previous=[],
                python_exec=False
            ),
            descriptor=self.descriptor
        )


# Wraps an operation over an iterable
class DataQuanta:
    def __init__(self, operator=None, descriptor=None):
        self.operator = operator
        self.descriptor = descriptor
        if self.operator.is_source():
            self.descriptor.add_source(self.operator)
        if self.operator.is_sink():
            self.descriptor.add_sink(self.operator)

    # Operational Functions
    def filter(self, udf):
        def func(iterator):
            return filter(udf, iterator)

        return DataQuanta(
            Operator(
                operator_type=""filter"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def flatmap(self, udf):

        def auxfunc(iterator):
            return itertools.chain.from_iterable(map(udf, iterator))

        def func(iterator):
            mapped = map(udf, iterator)
            flattened = flatten_single_dim(mapped)
            yield from flattened

        def flatten_single_dim(mapped):
            for item in mapped:
                for subitem in item:
                    yield subitem

        return DataQuanta(
            Operator(
                operator_type=""flatmap"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def group_by(self, udf):
        def func(iterator):
            # TODO key should be given by ""udf""
            return itertools.groupby(iterator, key=operator.itemgetter(0))
            #return itertools.groupby(sorted(iterator), key=itertools.itemgetter(0))

        return DataQuanta(
            Operator(
                operator_type=""group_by"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def map(self, udf):
        def func(iterator):
            return map(udf, iterator)

        return DataQuanta(
            Operator(
                operator_type=""map"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    # Key specifies pivot dimensions
    # UDF specifies reducer function
    def reduce_by_key(self, keys, udf):

        op = Operator(
            operator_type=""reduce_by_key"",
            udf=udf,
            previous=[self.operator],
            python_exec=False
        )

        #print(len(keys), keys)
        for i in range(0, len(keys)):
            """"""if keys[i] is int:
                op.set_parameter(""vector_position|""+str(i), keys[i])
            else:
                op.set_parameter(""dimension_key|""+str(i), keys[i])""""""

            # TODO maybe would be better just leave the number as key
            op.set_parameter(""dimension|""+str(i+1), keys[i])

        return DataQuanta(
            op,
            descriptor=self.descriptor
        )

    def reduce(self, udf):
        def func(iterator):
            return reduce(udf, iterator)

        return DataQuanta(
            Operator(
                operator_type=""reduce"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def sink(self, path, end=""\n""):
        def consume(iterator):
            with open(path, 'w') as f:
                for x in iterator:
                    f.write(str(x) + end)

        def func(iterator):
            consume(iterator)
            # return self.__run(consume)

        return DataQuanta(
            Operator(
                operator_type=""sink"",

                udf=path,
                # To execute directly uncomment
                # udf=func,

                previous=[self.operator],
                python_exec=False
            ),
            descriptor=self.descriptor
        )

    def sort(self, udf):

        def func(iterator):
            return sorted(iterator, key=udf)

        return DataQuanta(
            Operator(
                operator_type=""sort"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    # This function allow the union to be performed by Python
    # Nevertheless, current configuration runs it over Java
    def union(self, other):

        def func(iterator):
            return itertools.chain(iterator, other.operator.getIterator())

        return DataQuanta(
            Operator(
                operator_type=""union"",
                udf=func,
                previous=[self.operator, other.operator],
                python_exec=False
            ),
            descriptor=self.descriptor
        )

    def __run(self, consumer):
        consumer(self.operator.getIterator())

    # Execution Functions
    def console(self, end=""\n""):
        def consume(iterator):
            for x in iterator:
                print(x, end=end)

        self.__run(consume)

    # Only for debugging purposes!
    # To execute the plan directly in the program driver
    def execute(self):
        logging.warn(""DEBUG Execution"")
        logging.info(""Reminder to swap SINK UDF value from path to func"")
        logging.debug(self.operator.previous[0].operator_type)
        if self.operator.is_sink():
            logging.debug(self.operator.operator_type)
            logging.debug(self.operator.udf)
            logging.debug(len(self.operator.previous))
            self.operator.udf(self.operator.previous[0].getIterator())
        else:
            logging.error(""Plan must call execute from SINK type of operator"")
            raise RuntimeError

    # Converts Python Functional Plan to valid Wayang Plan
    def to_wayang_plan(self):

        sinks = self.descriptor.get_sinks()
        if len(sinks) == 0:
            return

        graph = Graph()
        graph.populate(self.descriptor.get_sinks())

        # Uncomment to check the Graph built
        # graph.print_adjlist()

        # Function to be consumed by Traverse
        # Separates Python Plan into a List of Pipelines
        def define_pipelines(node1, current_pipeline, collection):
            def store_unique(pipe_to_insert):
                for pipe in collection:
                    if equivalent_lists(pipe, pipe_to_insert):
                        return
                collection.append(pipe_to_insert)

            def equivalent_lists(l1, l2):
                if collections.Counter(l1) == collections.Counter(l2):
                    return True
                else:
                    return False

            if not current_pipeline:
                current_pipeline = [node1]

            elif node1.operator.is_boundary():
                store_unique(current_pipeline.copy())
                current_pipeline.clear()
                current_pipeline.append(node1)

            else:
                current_pipeline.append(node1)

            if node1.operator.sink:
                store_unique(current_pipeline.copy())
                current_pipeline.clear()

            return current_pipeline

        # Works over the graph
        trans = Traversal(
            graph=graph,
            origin=self.descriptor.get_sources(),
            # udf=lambda x, y, z: d(x, y, z)
            # UDF always will receive:
            # x: a Node object,
            # y: an object representing the result of the last iteration,
            # z: a collection to store final results inside your UDF
            udf=lambda x, y, z: define_pipelines(x, y, z)
        )

        # Gets the results of the traverse process
        collected_stages = trans.get_collected_data()

        # Passing the Stages to a Wayang message writer
        writer = MessageWriter()
        a = 0
        # Stage is composed of class Node objects
        for stage in collected_stages:
            a += 1
            logging.info(""///"")
            logging.info(""stage"" + str(a))
            writer.process_pipeline(stage)

        writer.set_dependencies()

        # Uses a file to provide the plan
        # writer.write_message(self.descriptor)

        # Send the plan to Wayang REST api directly
        writer.send_message(self.descriptor)

```

a6624919e50a9242a0f67e19e436fa077b474a10","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/143/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/144,https://api.github.com/repos/apache/incubator-wayang/issues/144,incubator-wayang,1197689658,144,maybe would be better just leave the number as key,github-actions,,,,OPEN,2022-04-08T18:58:53Z,2022-04-08T18:58:54Z,"maybe would be better just leave the number as key

udf=func,

Nevertheless, current configuration runs it over Java

To execute the plan directly in the program driver

graph.print_adjlist()

Separates Python Plan into a List of Pipelines

UDF always will receive:

x: a Node object,

y: an object representing the result of the last iteration,

z: a collection to store final results inside your UDF

writer.write_message(self.descriptor)

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/old_code/orchestrator/dataquanta.py#L150

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

from old_code.orchestrator.operator import Operator
from old_code.old_graph.graph import Graph
from old_code.old_graph.traversal import Traversal
from old_code.protobuf.planwriter import MessageWriter
import itertools
import collections
import logging
from functools import reduce
import operator


# Wraps a Source operation to create an iterable
class DataQuantaBuilder:
    def __init__(self, descriptor):
        self.descriptor = descriptor

    def source(self, source):

        if type(source) is str:
            source_ori = open(source, ""r"")
        else:
            source_ori = source
        return DataQuanta(
            Operator(
                operator_type=""source"",
                udf=source,
                iterator=iter(source_ori),
                previous=[],
                python_exec=False
            ),
            descriptor=self.descriptor
        )


# Wraps an operation over an iterable
class DataQuanta:
    def __init__(self, operator=None, descriptor=None):
        self.operator = operator
        self.descriptor = descriptor
        if self.operator.is_source():
            self.descriptor.add_source(self.operator)
        if self.operator.is_sink():
            self.descriptor.add_sink(self.operator)

    # Operational Functions
    def filter(self, udf):
        def func(iterator):
            return filter(udf, iterator)

        return DataQuanta(
            Operator(
                operator_type=""filter"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def flatmap(self, udf):

        def auxfunc(iterator):
            return itertools.chain.from_iterable(map(udf, iterator))

        def func(iterator):
            mapped = map(udf, iterator)
            flattened = flatten_single_dim(mapped)
            yield from flattened

        def flatten_single_dim(mapped):
            for item in mapped:
                for subitem in item:
                    yield subitem

        return DataQuanta(
            Operator(
                operator_type=""flatmap"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def group_by(self, udf):
        def func(iterator):
            # TODO key should be given by ""udf""
            return itertools.groupby(iterator, key=operator.itemgetter(0))
            #return itertools.groupby(sorted(iterator), key=itertools.itemgetter(0))

        return DataQuanta(
            Operator(
                operator_type=""group_by"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def map(self, udf):
        def func(iterator):
            return map(udf, iterator)

        return DataQuanta(
            Operator(
                operator_type=""map"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    # Key specifies pivot dimensions
    # UDF specifies reducer function
    def reduce_by_key(self, keys, udf):

        op = Operator(
            operator_type=""reduce_by_key"",
            udf=udf,
            previous=[self.operator],
            python_exec=False
        )

        #print(len(keys), keys)
        for i in range(0, len(keys)):
            """"""if keys[i] is int:
                op.set_parameter(""vector_position|""+str(i), keys[i])
            else:
                op.set_parameter(""dimension_key|""+str(i), keys[i])""""""

            # TODO maybe would be better just leave the number as key
            op.set_parameter(""dimension|""+str(i+1), keys[i])

        return DataQuanta(
            op,
            descriptor=self.descriptor
        )

    def reduce(self, udf):
        def func(iterator):
            return reduce(udf, iterator)

        return DataQuanta(
            Operator(
                operator_type=""reduce"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def sink(self, path, end=""\n""):
        def consume(iterator):
            with open(path, 'w') as f:
                for x in iterator:
                    f.write(str(x) + end)

        def func(iterator):
            consume(iterator)
            # return self.__run(consume)

        return DataQuanta(
            Operator(
                operator_type=""sink"",

                udf=path,
                # To execute directly uncomment
                # udf=func,

                previous=[self.operator],
                python_exec=False
            ),
            descriptor=self.descriptor
        )

    def sort(self, udf):

        def func(iterator):
            return sorted(iterator, key=udf)

        return DataQuanta(
            Operator(
                operator_type=""sort"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    # This function allow the union to be performed by Python
    # Nevertheless, current configuration runs it over Java
    def union(self, other):

        def func(iterator):
            return itertools.chain(iterator, other.operator.getIterator())

        return DataQuanta(
            Operator(
                operator_type=""union"",
                udf=func,
                previous=[self.operator, other.operator],
                python_exec=False
            ),
            descriptor=self.descriptor
        )

    def __run(self, consumer):
        consumer(self.operator.getIterator())

    # Execution Functions
    def console(self, end=""\n""):
        def consume(iterator):
            for x in iterator:
                print(x, end=end)

        self.__run(consume)

    # Only for debugging purposes!
    # To execute the plan directly in the program driver
    def execute(self):
        logging.warn(""DEBUG Execution"")
        logging.info(""Reminder to swap SINK UDF value from path to func"")
        logging.debug(self.operator.previous[0].operator_type)
        if self.operator.is_sink():
            logging.debug(self.operator.operator_type)
            logging.debug(self.operator.udf)
            logging.debug(len(self.operator.previous))
            self.operator.udf(self.operator.previous[0].getIterator())
        else:
            logging.error(""Plan must call execute from SINK type of operator"")
            raise RuntimeError

    # Converts Python Functional Plan to valid Wayang Plan
    def to_wayang_plan(self):

        sinks = self.descriptor.get_sinks()
        if len(sinks) == 0:
            return

        graph = Graph()
        graph.populate(self.descriptor.get_sinks())

        # Uncomment to check the Graph built
        # graph.print_adjlist()

        # Function to be consumed by Traverse
        # Separates Python Plan into a List of Pipelines
        def define_pipelines(node1, current_pipeline, collection):
            def store_unique(pipe_to_insert):
                for pipe in collection:
                    if equivalent_lists(pipe, pipe_to_insert):
                        return
                collection.append(pipe_to_insert)

            def equivalent_lists(l1, l2):
                if collections.Counter(l1) == collections.Counter(l2):
                    return True
                else:
                    return False

            if not current_pipeline:
                current_pipeline = [node1]

            elif node1.operator.is_boundary():
                store_unique(current_pipeline.copy())
                current_pipeline.clear()
                current_pipeline.append(node1)

            else:
                current_pipeline.append(node1)

            if node1.operator.sink:
                store_unique(current_pipeline.copy())
                current_pipeline.clear()

            return current_pipeline

        # Works over the graph
        trans = Traversal(
            graph=graph,
            origin=self.descriptor.get_sources(),
            # udf=lambda x, y, z: d(x, y, z)
            # UDF always will receive:
            # x: a Node object,
            # y: an object representing the result of the last iteration,
            # z: a collection to store final results inside your UDF
            udf=lambda x, y, z: define_pipelines(x, y, z)
        )

        # Gets the results of the traverse process
        collected_stages = trans.get_collected_data()

        # Passing the Stages to a Wayang message writer
        writer = MessageWriter()
        a = 0
        # Stage is composed of class Node objects
        for stage in collected_stages:
            a += 1
            logging.info(""///"")
            logging.info(""stage"" + str(a))
            writer.process_pipeline(stage)

        writer.set_dependencies()

        # Uses a file to provide the plan
        # writer.write_message(self.descriptor)

        # Send the plan to Wayang REST api directly
        writer.send_message(self.descriptor)

```

29b7cf7a2a05abd6b06329f92725e3722568951a","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/144/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/145,https://api.github.com/repos/apache/incubator-wayang/issues/145,incubator-wayang,1197689679,145,maybe would be better just leave the number as key,github-actions,,,,CLOSED,2022-04-08T18:58:56Z,2023-07-20T15:07:17Z,"maybe would be better just leave the number as key

udf=func,

Nevertheless, current configuration runs it over Java

To execute the plan directly in the program driver

graph.print_adjlist()

Separates Python Plan into a List of Pipelines

UDF always will receive:

x: a Node object,

y: an object representing the result of the last iteration,

z: a collection to store final results inside your UDF

writer.write_message(self.descriptor)

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/old_code/orchestrator/dataquanta.py#L150

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

from old_code.orchestrator.operator import Operator
from old_code.old_graph.graph import Graph
from old_code.old_graph.traversal import Traversal
from old_code.protobuf.planwriter import MessageWriter
import itertools
import collections
import logging
from functools import reduce
import operator


# Wraps a Source operation to create an iterable
class DataQuantaBuilder:
    def __init__(self, descriptor):
        self.descriptor = descriptor

    def source(self, source):

        if type(source) is str:
            source_ori = open(source, ""r"")
        else:
            source_ori = source
        return DataQuanta(
            Operator(
                operator_type=""source"",
                udf=source,
                iterator=iter(source_ori),
                previous=[],
                python_exec=False
            ),
            descriptor=self.descriptor
        )


# Wraps an operation over an iterable
class DataQuanta:
    def __init__(self, operator=None, descriptor=None):
        self.operator = operator
        self.descriptor = descriptor
        if self.operator.is_source():
            self.descriptor.add_source(self.operator)
        if self.operator.is_sink():
            self.descriptor.add_sink(self.operator)

    # Operational Functions
    def filter(self, udf):
        def func(iterator):
            return filter(udf, iterator)

        return DataQuanta(
            Operator(
                operator_type=""filter"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def flatmap(self, udf):

        def auxfunc(iterator):
            return itertools.chain.from_iterable(map(udf, iterator))

        def func(iterator):
            mapped = map(udf, iterator)
            flattened = flatten_single_dim(mapped)
            yield from flattened

        def flatten_single_dim(mapped):
            for item in mapped:
                for subitem in item:
                    yield subitem

        return DataQuanta(
            Operator(
                operator_type=""flatmap"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def group_by(self, udf):
        def func(iterator):
            # TODO key should be given by ""udf""
            return itertools.groupby(iterator, key=operator.itemgetter(0))
            #return itertools.groupby(sorted(iterator), key=itertools.itemgetter(0))

        return DataQuanta(
            Operator(
                operator_type=""group_by"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def map(self, udf):
        def func(iterator):
            return map(udf, iterator)

        return DataQuanta(
            Operator(
                operator_type=""map"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    # Key specifies pivot dimensions
    # UDF specifies reducer function
    def reduce_by_key(self, keys, udf):

        op = Operator(
            operator_type=""reduce_by_key"",
            udf=udf,
            previous=[self.operator],
            python_exec=False
        )

        #print(len(keys), keys)
        for i in range(0, len(keys)):
            """"""if keys[i] is int:
                op.set_parameter(""vector_position|""+str(i), keys[i])
            else:
                op.set_parameter(""dimension_key|""+str(i), keys[i])""""""

            # TODO maybe would be better just leave the number as key
            op.set_parameter(""dimension|""+str(i+1), keys[i])

        return DataQuanta(
            op,
            descriptor=self.descriptor
        )

    def reduce(self, udf):
        def func(iterator):
            return reduce(udf, iterator)

        return DataQuanta(
            Operator(
                operator_type=""reduce"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def sink(self, path, end=""\n""):
        def consume(iterator):
            with open(path, 'w') as f:
                for x in iterator:
                    f.write(str(x) + end)

        def func(iterator):
            consume(iterator)
            # return self.__run(consume)

        return DataQuanta(
            Operator(
                operator_type=""sink"",

                udf=path,
                # To execute directly uncomment
                # udf=func,

                previous=[self.operator],
                python_exec=False
            ),
            descriptor=self.descriptor
        )

    def sort(self, udf):

        def func(iterator):
            return sorted(iterator, key=udf)

        return DataQuanta(
            Operator(
                operator_type=""sort"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    # This function allow the union to be performed by Python
    # Nevertheless, current configuration runs it over Java
    def union(self, other):

        def func(iterator):
            return itertools.chain(iterator, other.operator.getIterator())

        return DataQuanta(
            Operator(
                operator_type=""union"",
                udf=func,
                previous=[self.operator, other.operator],
                python_exec=False
            ),
            descriptor=self.descriptor
        )

    def __run(self, consumer):
        consumer(self.operator.getIterator())

    # Execution Functions
    def console(self, end=""\n""):
        def consume(iterator):
            for x in iterator:
                print(x, end=end)

        self.__run(consume)

    # Only for debugging purposes!
    # To execute the plan directly in the program driver
    def execute(self):
        logging.warn(""DEBUG Execution"")
        logging.info(""Reminder to swap SINK UDF value from path to func"")
        logging.debug(self.operator.previous[0].operator_type)
        if self.operator.is_sink():
            logging.debug(self.operator.operator_type)
            logging.debug(self.operator.udf)
            logging.debug(len(self.operator.previous))
            self.operator.udf(self.operator.previous[0].getIterator())
        else:
            logging.error(""Plan must call execute from SINK type of operator"")
            raise RuntimeError

    # Converts Python Functional Plan to valid Wayang Plan
    def to_wayang_plan(self):

        sinks = self.descriptor.get_sinks()
        if len(sinks) == 0:
            return

        graph = Graph()
        graph.populate(self.descriptor.get_sinks())

        # Uncomment to check the Graph built
        # graph.print_adjlist()

        # Function to be consumed by Traverse
        # Separates Python Plan into a List of Pipelines
        def define_pipelines(node1, current_pipeline, collection):
            def store_unique(pipe_to_insert):
                for pipe in collection:
                    if equivalent_lists(pipe, pipe_to_insert):
                        return
                collection.append(pipe_to_insert)

            def equivalent_lists(l1, l2):
                if collections.Counter(l1) == collections.Counter(l2):
                    return True
                else:
                    return False

            if not current_pipeline:
                current_pipeline = [node1]

            elif node1.operator.is_boundary():
                store_unique(current_pipeline.copy())
                current_pipeline.clear()
                current_pipeline.append(node1)

            else:
                current_pipeline.append(node1)

            if node1.operator.sink:
                store_unique(current_pipeline.copy())
                current_pipeline.clear()

            return current_pipeline

        # Works over the graph
        trans = Traversal(
            graph=graph,
            origin=self.descriptor.get_sources(),
            # udf=lambda x, y, z: d(x, y, z)
            # UDF always will receive:
            # x: a Node object,
            # y: an object representing the result of the last iteration,
            # z: a collection to store final results inside your UDF
            udf=lambda x, y, z: define_pipelines(x, y, z)
        )

        # Gets the results of the traverse process
        collected_stages = trans.get_collected_data()

        # Passing the Stages to a Wayang message writer
        writer = MessageWriter()
        a = 0
        # Stage is composed of class Node objects
        for stage in collected_stages:
            a += 1
            logging.info(""///"")
            logging.info(""stage"" + str(a))
            writer.process_pipeline(stage)

        writer.set_dependencies()

        # Uses a file to provide the plan
        # writer.write_message(self.descriptor)

        # Send the plan to Wayang REST api directly
        writer.send_message(self.descriptor)

```

29b7cf7a2a05abd6b06329f92725e3722568951a","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/145/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/146,https://api.github.com/repos/apache/incubator-wayang/issues/146,incubator-wayang,1197689680,146,create reduce by,github-actions,,,,OPEN,2022-04-08T18:58:56Z,2022-04-08T18:58:58Z,"create reduce by

.reduce_by(reducer) \

.flatmap(lambda elem: elem.split(""|""))

.map(lambda elem: (elem, elem.split(""|""))) \

L_RETURNFLAG 8

L_LINESTATUS 9

L_QUANTITY 4

L_EXTENDEDPRICE 5

discount 6

tax 7

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/old_code/orchestrator/execdirectly.py#L114

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

from old_code.orchestrator.plan import Descriptor
from old_code.orchestrator.dataquanta import DataQuantaBuilder
import datetime


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_sort(descriptor):
    plan = DataQuantaBuilder(descriptor)
    sink_dataquanta = \
        plan.source(""../test/words.txt"") \
            .sort(lambda elem: elem.lower()) \
            .sink(""../test/output.txt"", end="""")
    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_sort_filter(descriptor):
    plan = DataQuantaBuilder(descriptor)
    sink_dataquanta = \
        plan.source(""../test/words.txt"") \
            .sort(lambda elem: elem.lower()) \
            .filter(lambda elem: str(elem).startswith(""f"")) \
            .sink(""../test/output.txt"", end="""")
    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_filter_text(descriptor):
    plan = DataQuantaBuilder(descriptor)

    sink_dataquanta = \
        plan.source(""../test/words.txt"") \
            .filter(lambda elem: str(elem).startswith(""f"")) \
            .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_filter(descriptor):
    plan = DataQuantaBuilder(descriptor)

    sink_dataquanta = \
        plan.source(""../test/numbers.txt"") \
            .filter(lambda elem: int(elem) % 2 != 0) \
            .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_basic(descriptor):
    plan = DataQuantaBuilder(descriptor)

    sink_dataquanta = \
        plan.source(""../test/lines.txt"") \
            .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_junction(descriptor):

    plan = DataQuantaBuilder(descriptor)

    dq_source_a = plan.source(""../test/lines.txt"")
    dq_source_b = plan.source(""../test/morelines.txt"") \
        .filter(lambda elem: str(elem).startswith(""I""))
    dq_source_c = plan.source(""../test/lastlines.txt"") \
        .filter(lambda elem: str(elem).startswith(""W""))

    sink_dataquanta = dq_source_a.union(dq_source_b) \
        .union(dq_source_c) \
        .sort(lambda elem: elem.lower()) \
        .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


def plan_java_junction(descriptor):

    plan = DataQuantaBuilder(descriptor)

    dq_source_a = plan.source(""../test/lines.txt"")
    dq_source_b = plan.source(""../test/morelines.txt"")
    sink_dataquanta = dq_source_a.union(dq_source_b) \
        .filter(lambda elem: str(elem).startswith(""I"")) \
        .sort(lambda elem: elem.lower()) \
        .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


def plan_tpch_q1(descriptor):

    #TODO create reduce by
    plan = DataQuantaBuilder(descriptor)

    def reducer(obj1, obj2):
        return obj1[0]

    sink = plan.source(""../test/lineitem.txt"") \
        .map(lambda elem: elem.split(""|"")) \
        .filter(lambda elem: datetime.datetime.strptime(elem[10], '%Y-%m-%d') <= datetime.datetime.strptime(""1998-09-02"", '%Y-%m-%d')) \
        .map(lambda elem:
           [elem[8], elem[9], elem[4], elem[5],
            float(elem[5]) * (1 - float(elem[6])),
            float(elem[5]) * (1 - float(elem[6])) * (1 + float(elem[7])),
            elem[4], elem[5],
            elem[6], 1]) \
        .sink(""../test/output.txt"", end="""")
        # .group_by(lambda elem: elem) \
        # .reduce_by(reducer) \
        # .flatmap(lambda elem: elem.split(""|""))
        # .map(lambda elem: (elem, elem.split(""|""))) \
        # L_RETURNFLAG 8
        # L_LINESTATUS 9
        # L_QUANTITY 4
        # L_EXTENDEDPRICE 5
        # discount 6
        # tax 7

    return dq_source_b


def plan_full_java(descriptor):

    plan = DataQuantaBuilder(descriptor)

    dq_source_a = plan.source(""../test/lines.txt"")
    dq_source_b = plan.source(""../test/morelines.txt"")
    sink_dataquanta = dq_source_a.union(dq_source_b) \
        .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


if __name__ == '__main__':

    # Plan will contain general info about the Wayang Plan created here
    descriptor = Descriptor()

    plan_dataquanta_sink = plan_tpch_q1(descriptor)
    plan_dataquanta_sink.execute()

```

51e742eca9956aa600b395df0227706080e263d7","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/146/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/147,https://api.github.com/repos/apache/incubator-wayang/issues/147,incubator-wayang,1197689730,147,create reduce by,github-actions,,,,CLOSED,2022-04-08T18:58:59Z,2023-07-20T15:07:07Z,"create reduce by

.reduce_by(reducer) \

.flatmap(lambda elem: elem.split(""|""))

.map(lambda elem: (elem, elem.split(""|""))) \

L_RETURNFLAG 8

L_LINESTATUS 9

L_QUANTITY 4

L_EXTENDEDPRICE 5

discount 6

tax 7

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/old_code/orchestrator/execdirectly.py#L114

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

from old_code.orchestrator.plan import Descriptor
from old_code.orchestrator.dataquanta import DataQuantaBuilder
import datetime


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_sort(descriptor):
    plan = DataQuantaBuilder(descriptor)
    sink_dataquanta = \
        plan.source(""../test/words.txt"") \
            .sort(lambda elem: elem.lower()) \
            .sink(""../test/output.txt"", end="""")
    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_sort_filter(descriptor):
    plan = DataQuantaBuilder(descriptor)
    sink_dataquanta = \
        plan.source(""../test/words.txt"") \
            .sort(lambda elem: elem.lower()) \
            .filter(lambda elem: str(elem).startswith(""f"")) \
            .sink(""../test/output.txt"", end="""")
    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_filter_text(descriptor):
    plan = DataQuantaBuilder(descriptor)

    sink_dataquanta = \
        plan.source(""../test/words.txt"") \
            .filter(lambda elem: str(elem).startswith(""f"")) \
            .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_filter(descriptor):
    plan = DataQuantaBuilder(descriptor)

    sink_dataquanta = \
        plan.source(""../test/numbers.txt"") \
            .filter(lambda elem: int(elem) % 2 != 0) \
            .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_basic(descriptor):
    plan = DataQuantaBuilder(descriptor)

    sink_dataquanta = \
        plan.source(""../test/lines.txt"") \
            .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_junction(descriptor):

    plan = DataQuantaBuilder(descriptor)

    dq_source_a = plan.source(""../test/lines.txt"")
    dq_source_b = plan.source(""../test/morelines.txt"") \
        .filter(lambda elem: str(elem).startswith(""I""))
    dq_source_c = plan.source(""../test/lastlines.txt"") \
        .filter(lambda elem: str(elem).startswith(""W""))

    sink_dataquanta = dq_source_a.union(dq_source_b) \
        .union(dq_source_c) \
        .sort(lambda elem: elem.lower()) \
        .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


def plan_java_junction(descriptor):

    plan = DataQuantaBuilder(descriptor)

    dq_source_a = plan.source(""../test/lines.txt"")
    dq_source_b = plan.source(""../test/morelines.txt"")
    sink_dataquanta = dq_source_a.union(dq_source_b) \
        .filter(lambda elem: str(elem).startswith(""I"")) \
        .sort(lambda elem: elem.lower()) \
        .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


def plan_tpch_q1(descriptor):

    #TODO create reduce by
    plan = DataQuantaBuilder(descriptor)

    def reducer(obj1, obj2):
        return obj1[0]

    sink = plan.source(""../test/lineitem.txt"") \
        .map(lambda elem: elem.split(""|"")) \
        .filter(lambda elem: datetime.datetime.strptime(elem[10], '%Y-%m-%d') <= datetime.datetime.strptime(""1998-09-02"", '%Y-%m-%d')) \
        .map(lambda elem:
           [elem[8], elem[9], elem[4], elem[5],
            float(elem[5]) * (1 - float(elem[6])),
            float(elem[5]) * (1 - float(elem[6])) * (1 + float(elem[7])),
            elem[4], elem[5],
            elem[6], 1]) \
        .sink(""../test/output.txt"", end="""")
        # .group_by(lambda elem: elem) \
        # .reduce_by(reducer) \
        # .flatmap(lambda elem: elem.split(""|""))
        # .map(lambda elem: (elem, elem.split(""|""))) \
        # L_RETURNFLAG 8
        # L_LINESTATUS 9
        # L_QUANTITY 4
        # L_EXTENDEDPRICE 5
        # discount 6
        # tax 7

    return dq_source_b


def plan_full_java(descriptor):

    plan = DataQuantaBuilder(descriptor)

    dq_source_a = plan.source(""../test/lines.txt"")
    dq_source_b = plan.source(""../test/morelines.txt"")
    sink_dataquanta = dq_source_a.union(dq_source_b) \
        .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


if __name__ == '__main__':

    # Plan will contain general info about the Wayang Plan created here
    descriptor = Descriptor()

    plan_dataquanta_sink = plan_tpch_q1(descriptor)
    plan_dataquanta_sink.execute()

```

51e742eca9956aa600b395df0227706080e263d7","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/147/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/148,https://api.github.com/repos/apache/incubator-wayang/issues/148,incubator-wayang,1197689732,148,create reduce by,github-actions,,,,CLOSED,2022-04-08T18:58:59Z,2023-07-20T15:07:07Z,"create reduce by

plan_dataquanta_sink.console()

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/old_code/orchestrator/main.py#L113

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

from old_code.orchestrator.plan import Descriptor
from old_code.orchestrator.dataquanta import DataQuantaBuilder


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_sort(descriptor):
    plan = DataQuantaBuilder(descriptor)
    sink_dataquanta = \
        plan.source(""../test/words.txt"") \
            .sort(lambda elem: elem.lower()) \
            .sink(""../test/output.txt"", end="""")
    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_sort_filter(descriptor):
    plan = DataQuantaBuilder(descriptor)
    sink_dataquanta = \
        plan.source(""../test/words.txt"") \
            .sort(lambda elem: elem.lower()) \
            .filter(lambda elem: str(elem).startswith(""f"")) \
            .sink(""../test/output.txt"", end="""")
    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_filter_text(descriptor):
    plan = DataQuantaBuilder(descriptor)

    sink_dataquanta = \
        plan.source(""../test/words.txt"") \
            .filter(lambda elem: str(elem).startswith(""f"")) \
            .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_filter(descriptor):
    plan = DataQuantaBuilder(descriptor)

    sink_dataquanta = \
        plan.source(""../test/numbers.txt"") \
            .filter(lambda elem: int(elem) % 2 != 0) \
            .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_basic(descriptor):
    plan = DataQuantaBuilder(descriptor)

    sink_dataquanta = \
        plan.source(""../test/lines.txt"") \
            .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_junction(descriptor):

    plan = DataQuantaBuilder(descriptor)

    dq_source_a = plan.source(""../test/lines.txt"")
    dq_source_b = plan.source(""../test/morelines.txt"") \
        .filter(lambda elem: str(elem).startswith(""I""))
    dq_source_c = plan.source(""../test/lastlines.txt"") \
        .filter(lambda elem: str(elem).startswith(""W""))

    sink_dataquanta = dq_source_a.union(dq_source_b) \
        .union(dq_source_c) \
        .sort(lambda elem: elem.lower()) \
        .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


def plan_java_junction(descriptor):

    plan = DataQuantaBuilder(descriptor)

    dq_source_a = plan.source(""../test/lines.txt"")
    dq_source_b = plan.source(""../test/morelines.txt"")
    sink_dataquanta = dq_source_a.union(dq_source_b) \
        .filter(lambda elem: str(elem).startswith(""I"")) \
        .sort(lambda elem: elem.lower()) \
        .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


def plan_tpch_q1(descriptor):

    # TODO create reduce by
    plan = DataQuantaBuilder(descriptor)

    def reducer(obj1, obj2):
        return obj1[0], obj1[1], obj1[2] + obj2[2], obj1[3] + obj2[3], obj1[4] + obj2[4], obj1[5] + obj2[5], \
               obj1[6] + obj2[6], obj1[7] + obj2[7], obj1[8] + obj2[8], obj1[9] + obj2[9]

    sink = plan.source(""../test/lineitem.txt"") \
        .map(lambda elem: elem.split(""|"")) \
        .sink(""../test/output.txt"", end="""")
    """"""
        .filter(lambda elem: datetime.datetime.strptime(elem[10], '%Y-%m-%d') <= datetime.datetime.strptime('1998-09-02', '%Y-%m-%d')) \
        .map(lambda elem:
             [elem[8], elem[9], elem[4], elem[5],
              float(elem[5]) * (1 - float(elem[6])),
              float(elem[5]) * (1 - float(elem[6])) * (1 + float(elem[7])),
              elem[4], elem[5],
              elem[6], 1]) \
        .sink(""../test/output.txt"", end="""")""""""
        # .reduce_by_key([0, 1], reducer) \


    return sink


def plan_full_java(descriptor):

    plan = DataQuantaBuilder(descriptor)

    dq_source_a = plan.source(""../test/lines.txt"")
    dq_source_b = plan.source(""../test/morelines.txt"")
    sink_dataquanta = dq_source_a.union(dq_source_b) \
        .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


def plan_wordcount(descriptor):

    plan = DataQuantaBuilder(descriptor)
    sink_wordcount = plan.source(""../test/lineitem.txt"") \
        .filter(lambda elem: len(str(elem).split(""|"")[0]) < 4) \
        .flatmap(lambda elem: str(elem).split(""|"")) \
        .sink(""../test/output.txt"", end="""")

    return sink_wordcount


if __name__ == '__main__':

    # Plan will contain general info about the Wayang Plan created here
    descriptor = Descriptor()
    descriptor.add_plugin(Descriptor.Plugin.spark)
    descriptor.add_plugin(Descriptor.Plugin.java)

    plan_dataquanta_sink = plan_wordcount(descriptor)
    # plan_dataquanta_sink.execute()
    # plan_dataquanta_sink.console()

    plan_dataquanta_sink.to_wayang_plan()

```

3dbd8c28b595c8cf36137527d9aa512a5b738c38","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/148/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/149,https://api.github.com/repos/apache/incubator-wayang/issues/149,incubator-wayang,1197689757,149,create reduce by,github-actions,,,,CLOSED,2022-04-08T18:59:01Z,2023-07-20T15:07:08Z,"create reduce by

plan_dataquanta_sink.console()

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/old_code/orchestrator/main.py#L113

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

from old_code.orchestrator.plan import Descriptor
from old_code.orchestrator.dataquanta import DataQuantaBuilder


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_sort(descriptor):
    plan = DataQuantaBuilder(descriptor)
    sink_dataquanta = \
        plan.source(""../test/words.txt"") \
            .sort(lambda elem: elem.lower()) \
            .sink(""../test/output.txt"", end="""")
    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_sort_filter(descriptor):
    plan = DataQuantaBuilder(descriptor)
    sink_dataquanta = \
        plan.source(""../test/words.txt"") \
            .sort(lambda elem: elem.lower()) \
            .filter(lambda elem: str(elem).startswith(""f"")) \
            .sink(""../test/output.txt"", end="""")
    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_filter_text(descriptor):
    plan = DataQuantaBuilder(descriptor)

    sink_dataquanta = \
        plan.source(""../test/words.txt"") \
            .filter(lambda elem: str(elem).startswith(""f"")) \
            .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_filter(descriptor):
    plan = DataQuantaBuilder(descriptor)

    sink_dataquanta = \
        plan.source(""../test/numbers.txt"") \
            .filter(lambda elem: int(elem) % 2 != 0) \
            .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_basic(descriptor):
    plan = DataQuantaBuilder(descriptor)

    sink_dataquanta = \
        plan.source(""../test/lines.txt"") \
            .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_junction(descriptor):

    plan = DataQuantaBuilder(descriptor)

    dq_source_a = plan.source(""../test/lines.txt"")
    dq_source_b = plan.source(""../test/morelines.txt"") \
        .filter(lambda elem: str(elem).startswith(""I""))
    dq_source_c = plan.source(""../test/lastlines.txt"") \
        .filter(lambda elem: str(elem).startswith(""W""))

    sink_dataquanta = dq_source_a.union(dq_source_b) \
        .union(dq_source_c) \
        .sort(lambda elem: elem.lower()) \
        .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


def plan_java_junction(descriptor):

    plan = DataQuantaBuilder(descriptor)

    dq_source_a = plan.source(""../test/lines.txt"")
    dq_source_b = plan.source(""../test/morelines.txt"")
    sink_dataquanta = dq_source_a.union(dq_source_b) \
        .filter(lambda elem: str(elem).startswith(""I"")) \
        .sort(lambda elem: elem.lower()) \
        .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


def plan_tpch_q1(descriptor):

    # TODO create reduce by
    plan = DataQuantaBuilder(descriptor)

    def reducer(obj1, obj2):
        return obj1[0], obj1[1], obj1[2] + obj2[2], obj1[3] + obj2[3], obj1[4] + obj2[4], obj1[5] + obj2[5], \
               obj1[6] + obj2[6], obj1[7] + obj2[7], obj1[8] + obj2[8], obj1[9] + obj2[9]

    sink = plan.source(""../test/lineitem.txt"") \
        .map(lambda elem: elem.split(""|"")) \
        .sink(""../test/output.txt"", end="""")
    """"""
        .filter(lambda elem: datetime.datetime.strptime(elem[10], '%Y-%m-%d') <= datetime.datetime.strptime('1998-09-02', '%Y-%m-%d')) \
        .map(lambda elem:
             [elem[8], elem[9], elem[4], elem[5],
              float(elem[5]) * (1 - float(elem[6])),
              float(elem[5]) * (1 - float(elem[6])) * (1 + float(elem[7])),
              elem[4], elem[5],
              elem[6], 1]) \
        .sink(""../test/output.txt"", end="""")""""""
        # .reduce_by_key([0, 1], reducer) \


    return sink


def plan_full_java(descriptor):

    plan = DataQuantaBuilder(descriptor)

    dq_source_a = plan.source(""../test/lines.txt"")
    dq_source_b = plan.source(""../test/morelines.txt"")
    sink_dataquanta = dq_source_a.union(dq_source_b) \
        .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


def plan_wordcount(descriptor):

    plan = DataQuantaBuilder(descriptor)
    sink_wordcount = plan.source(""../test/lineitem.txt"") \
        .filter(lambda elem: len(str(elem).split(""|"")[0]) < 4) \
        .flatmap(lambda elem: str(elem).split(""|"")) \
        .sink(""../test/output.txt"", end="""")

    return sink_wordcount


if __name__ == '__main__':

    # Plan will contain general info about the Wayang Plan created here
    descriptor = Descriptor()
    descriptor.add_plugin(Descriptor.Plugin.spark)
    descriptor.add_plugin(Descriptor.Plugin.java)

    plan_dataquanta_sink = plan_wordcount(descriptor)
    # plan_dataquanta_sink.execute()
    # plan_dataquanta_sink.console()

    plan_dataquanta_sink.to_wayang_plan()

```

3dbd8c28b595c8cf36137527d9aa512a5b738c38","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/149/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/150,https://api.github.com/repos/apache/incubator-wayang/issues/150,incubator-wayang,1197689758,150,Why managing previous and predecessors per separate?,github-actions,,,,OPEN,2022-04-08T18:59:02Z,2022-04-08T18:59:03Z,"Why managing previous and predecessors per separate?

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/old_code/orchestrator/operator.py#L73

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import pickle
import cloudpickle
from old_code.config.config_reader import get_source_types
from old_code.config.config_reader import get_sink_types
from old_code.config.config_reader import get_boundary_types
import logging

pickle_protocol = pickle.HIGHEST_PROTOCOL


# Describes an Operation over an intermediate result
# Each operation could be processed by Python or Java platforms
class Operator:

    def __init__(
        self,
        operator_type=None,
        udf=None,
        previous=None,
        iterator=None,
        python_exec=False
    ):

        # Operator ID
        self.id = id(self)

        # Operator Type
        self.operator_type = operator_type

        # Set Boundaries
        if self.operator_type in get_boundary_types():
            self.boundary = True
        else:
            self.boundary = False

        # UDF Function
        self.udf = udf

        # Source types must come with an Iterator
        self.iterator = iterator
        if operator_type in get_source_types():
            if iterator is None:
                print(""Source Operator Type without an Iterator"")
                raise
            else:
                self.source = True
        else:
            self.source = False

        # Sink Operators
        if operator_type in get_sink_types():
            self.sink = True
        else:
            self.sink = False

        # TODO Why managing previous and predecessors per separate?
        self.previous = previous

        self.successor = []
        self.predecessor = []

        self.parameters = {}

        # Set predecessors and successors from previous
        if self.previous:
            for prev in self.previous:
                if prev is not None:
                    prev.set_successor(self)
                    self.set_predecessor(prev)

        self.python_exec = python_exec

        logging.info(""Operator:"" + str(self.getID()) + "", type:"" + self.operator_type + "", PythonExecutable: "" +
                     str(self.python_exec) +
                     "", is boundary: "" + str(self.is_boundary()) + "", is source: "" +
                     str(self.source) + "", is sink: "" + str(self.sink))

    def getID(self):
        return self.id

    def is_source(self):
        return self.source

    def is_sink(self):
        return self.sink

    def is_boundary(self):
        return self.boundary

    def serialize_udf(self):
        self.udf = cloudpickle.dumps(self.udf)

    def getIterator(self):
        if self.is_source():
            return self.iterator
        # TODO this should iterate through previous REDESIGN
        return self.udf(self.previous[0].getIterator())

    def set_parameter(self, key, value):
        self.parameters[key] = value

    def set_successor(self, suc):
        if (not self.is_sink()) and self.successor.count(suc) == 0:
            self.successor.append(suc)

    def set_predecessor(self, suc):
        if self.predecessor.count(suc) == 0:
            self.predecessor.append(suc)

```

4db4163cbf8d5dfca00fd2f9658188fb7a61dac2","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/150/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/151,https://api.github.com/repos/apache/incubator-wayang/issues/151,incubator-wayang,1197689793,151,this should iterate through previous REDESIGN,github-actions,,,,CLOSED,2022-04-08T18:59:04Z,2023-07-20T15:10:57Z,"this should iterate through previous REDESIGN

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/old_code/orchestrator/operator.py#L113

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import pickle
import cloudpickle
from old_code.config.config_reader import get_source_types
from old_code.config.config_reader import get_sink_types
from old_code.config.config_reader import get_boundary_types
import logging

pickle_protocol = pickle.HIGHEST_PROTOCOL


# Describes an Operation over an intermediate result
# Each operation could be processed by Python or Java platforms
class Operator:

    def __init__(
        self,
        operator_type=None,
        udf=None,
        previous=None,
        iterator=None,
        python_exec=False
    ):

        # Operator ID
        self.id = id(self)

        # Operator Type
        self.operator_type = operator_type

        # Set Boundaries
        if self.operator_type in get_boundary_types():
            self.boundary = True
        else:
            self.boundary = False

        # UDF Function
        self.udf = udf

        # Source types must come with an Iterator
        self.iterator = iterator
        if operator_type in get_source_types():
            if iterator is None:
                print(""Source Operator Type without an Iterator"")
                raise
            else:
                self.source = True
        else:
            self.source = False

        # Sink Operators
        if operator_type in get_sink_types():
            self.sink = True
        else:
            self.sink = False

        # TODO Why managing previous and predecessors per separate?
        self.previous = previous

        self.successor = []
        self.predecessor = []

        self.parameters = {}

        # Set predecessors and successors from previous
        if self.previous:
            for prev in self.previous:
                if prev is not None:
                    prev.set_successor(self)
                    self.set_predecessor(prev)

        self.python_exec = python_exec

        logging.info(""Operator:"" + str(self.getID()) + "", type:"" + self.operator_type + "", PythonExecutable: "" +
                     str(self.python_exec) +
                     "", is boundary: "" + str(self.is_boundary()) + "", is source: "" +
                     str(self.source) + "", is sink: "" + str(self.sink))

    def getID(self):
        return self.id

    def is_source(self):
        return self.source

    def is_sink(self):
        return self.sink

    def is_boundary(self):
        return self.boundary

    def serialize_udf(self):
        self.udf = cloudpickle.dumps(self.udf)

    def getIterator(self):
        if self.is_source():
            return self.iterator
        # TODO this should iterate through previous REDESIGN
        return self.udf(self.previous[0].getIterator())

    def set_parameter(self, key, value):
        self.parameters[key] = value

    def set_successor(self, suc):
        if (not self.is_sink()) and self.successor.count(suc) == 0:
            self.successor.append(suc)

    def set_predecessor(self, suc):
        if self.predecessor.count(suc) == 0:
            self.predecessor.append(suc)

```

92558c7773af84fb9ff7b8b4a13b4616180443e5","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/151/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/152,https://api.github.com/repos/apache/incubator-wayang/issues/152,incubator-wayang,1197689794,152,Why managing previous and predecessors per separate?,github-actions,,,,OPEN,2022-04-08T18:59:04Z,2022-04-08T18:59:06Z,"Why managing previous and predecessors per separate?

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/old_code/orchestrator/operator.py#L73

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import pickle
import cloudpickle
from old_code.config.config_reader import get_source_types
from old_code.config.config_reader import get_sink_types
from old_code.config.config_reader import get_boundary_types
import logging

pickle_protocol = pickle.HIGHEST_PROTOCOL


# Describes an Operation over an intermediate result
# Each operation could be processed by Python or Java platforms
class Operator:

    def __init__(
        self,
        operator_type=None,
        udf=None,
        previous=None,
        iterator=None,
        python_exec=False
    ):

        # Operator ID
        self.id = id(self)

        # Operator Type
        self.operator_type = operator_type

        # Set Boundaries
        if self.operator_type in get_boundary_types():
            self.boundary = True
        else:
            self.boundary = False

        # UDF Function
        self.udf = udf

        # Source types must come with an Iterator
        self.iterator = iterator
        if operator_type in get_source_types():
            if iterator is None:
                print(""Source Operator Type without an Iterator"")
                raise
            else:
                self.source = True
        else:
            self.source = False

        # Sink Operators
        if operator_type in get_sink_types():
            self.sink = True
        else:
            self.sink = False

        # TODO Why managing previous and predecessors per separate?
        self.previous = previous

        self.successor = []
        self.predecessor = []

        self.parameters = {}

        # Set predecessors and successors from previous
        if self.previous:
            for prev in self.previous:
                if prev is not None:
                    prev.set_successor(self)
                    self.set_predecessor(prev)

        self.python_exec = python_exec

        logging.info(""Operator:"" + str(self.getID()) + "", type:"" + self.operator_type + "", PythonExecutable: "" +
                     str(self.python_exec) +
                     "", is boundary: "" + str(self.is_boundary()) + "", is source: "" +
                     str(self.source) + "", is sink: "" + str(self.sink))

    def getID(self):
        return self.id

    def is_source(self):
        return self.source

    def is_sink(self):
        return self.sink

    def is_boundary(self):
        return self.boundary

    def serialize_udf(self):
        self.udf = cloudpickle.dumps(self.udf)

    def getIterator(self):
        if self.is_source():
            return self.iterator
        # TODO this should iterate through previous REDESIGN
        return self.udf(self.previous[0].getIterator())

    def set_parameter(self, key, value):
        self.parameters[key] = value

    def set_successor(self, suc):
        if (not self.is_sink()) and self.successor.count(suc) == 0:
            self.successor.append(suc)

    def set_predecessor(self, suc):
        if self.predecessor.count(suc) == 0:
            self.predecessor.append(suc)

```

4db4163cbf8d5dfca00fd2f9658188fb7a61dac2","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/152/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/153,https://api.github.com/repos/apache/incubator-wayang/issues/153,incubator-wayang,1197689822,153,not necesary it it 0,github-actions,,,,OPEN,2022-04-08T18:59:06Z,2022-04-08T18:59:07Z,"not necesary it it 0

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/core/translator.py#L49

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

from pywy.graph.types import (WGraphOfVec, NodeVec)
from pywy.core.plugin import Plugin
from pywy.core.plan import PywyPlan
from pywy.core.mapping import Mapping


class Translator:

    plugin: Plugin
    plan: PywyPlan

    def __init__(self, plugin: Plugin, plan: PywyPlan):
        self.plugin = plugin
        self.plan = plan

    def translate(self):
        mappings: Mapping = self.plugin.get_mappings()
        graph = WGraphOfVec(self.plan.sinks)

        def translate2plugin(current_op: NodeVec, next_op: NodeVec):
            if current_op is None:
                return

            if current_op.current[1] is None:
                current_op.current[1] = mappings.get_instanceof(current_op.current[0])

            if next_op is None:
                return
            if next_op.current[1] is None:
                next_op.current[1] = mappings.get_instanceof(next_op.current[0])

            # TODO not necesary it it 0
            current_op.current[1].connect(0, next_op.current[1], 0)

        graph.traversal(graph.starting_nodes, translate2plugin)

        node = []
        for elem in graph.starting_nodes:
            node.append(elem.current[1])

        return PywyPlan({self.plugin}, node)

```

faa6d95fe21aa8beb6316ff96ecbcc5626efb21e","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/153/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/154,https://api.github.com/repos/apache/incubator-wayang/issues/154,incubator-wayang,1197689831,154,this should iterate through previous REDESIGN,github-actions,,,,OPEN,2022-04-08T18:59:07Z,2022-04-08T18:59:08Z,"this should iterate through previous REDESIGN

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/old_code/orchestrator/operator.py#L113

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import pickle
import cloudpickle
from old_code.config.config_reader import get_source_types
from old_code.config.config_reader import get_sink_types
from old_code.config.config_reader import get_boundary_types
import logging

pickle_protocol = pickle.HIGHEST_PROTOCOL


# Describes an Operation over an intermediate result
# Each operation could be processed by Python or Java platforms
class Operator:

    def __init__(
        self,
        operator_type=None,
        udf=None,
        previous=None,
        iterator=None,
        python_exec=False
    ):

        # Operator ID
        self.id = id(self)

        # Operator Type
        self.operator_type = operator_type

        # Set Boundaries
        if self.operator_type in get_boundary_types():
            self.boundary = True
        else:
            self.boundary = False

        # UDF Function
        self.udf = udf

        # Source types must come with an Iterator
        self.iterator = iterator
        if operator_type in get_source_types():
            if iterator is None:
                print(""Source Operator Type without an Iterator"")
                raise
            else:
                self.source = True
        else:
            self.source = False

        # Sink Operators
        if operator_type in get_sink_types():
            self.sink = True
        else:
            self.sink = False

        # TODO Why managing previous and predecessors per separate?
        self.previous = previous

        self.successor = []
        self.predecessor = []

        self.parameters = {}

        # Set predecessors and successors from previous
        if self.previous:
            for prev in self.previous:
                if prev is not None:
                    prev.set_successor(self)
                    self.set_predecessor(prev)

        self.python_exec = python_exec

        logging.info(""Operator:"" + str(self.getID()) + "", type:"" + self.operator_type + "", PythonExecutable: "" +
                     str(self.python_exec) +
                     "", is boundary: "" + str(self.is_boundary()) + "", is source: "" +
                     str(self.source) + "", is sink: "" + str(self.sink))

    def getID(self):
        return self.id

    def is_source(self):
        return self.source

    def is_sink(self):
        return self.sink

    def is_boundary(self):
        return self.boundary

    def serialize_udf(self):
        self.udf = cloudpickle.dumps(self.udf)

    def getIterator(self):
        if self.is_source():
            return self.iterator
        # TODO this should iterate through previous REDESIGN
        return self.udf(self.previous[0].getIterator())

    def set_parameter(self, key, value):
        self.parameters[key] = value

    def set_successor(self, suc):
        if (not self.is_sink()) and self.successor.count(suc) == 0:
            self.successor.append(suc)

    def set_predecessor(self, suc):
        if self.predecessor.count(suc) == 0:
            self.predecessor.append(suc)

```

92558c7773af84fb9ff7b8b4a13b4616180443e5","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/154/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/155,https://api.github.com/repos/apache/incubator-wayang/issues/155,incubator-wayang,1197689842,155,add the logic to execute the plan,github-actions,,,,OPEN,2022-04-08T18:59:08Z,2022-04-08T18:59:11Z,"add the logic to execute the plan

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/dataquanta.py#L103

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

from typing import Set, List, cast

from pywy.core import Translator
from pywy.operators.base import PO_T
from pywy.types import (GenericTco, Predicate, Function, FlatmapFunction, IterableOut, T, In, Out)
from pywy.operators import *
from pywy.core import PywyPlan
from pywy.core import Plugin


class WayangContext:
    """"""
    This is the entry point for users to work with Wayang.
    """"""
    plugins: Set[Plugin]

    def __init__(self):
        self.plugins = set()

    """"""
    add a :class:`Plugin` to the :class:`Context`
    """"""

    def register(self, *plugins: Plugin):
        for p in plugins:
            self.plugins.add(p)
        return self

    """"""
    remove a :class:`Plugin` from the :class:`Context`
    """"""

    def unregister(self, *plugins: Plugin):
        for p in plugins:
            self.plugins.remove(p)
        return self

    def textfile(self, file_path: str) -> 'DataQuanta[str]':
        return DataQuanta(self, TextFileSource(file_path))

    def __str__(self):
        return ""Plugins: {}"".format(str(self.plugins))

    def __repr__(self):
        return self.__str__()


class DataQuanta(GenericTco):
    """"""
    Represents an intermediate result/data flow edge in a [[WayangPlan]].
    """"""
    context: WayangContext

    def __init__(self, context: WayangContext, operator: PywyOperator):
        self.operator = operator
        self.context = context

    def filter(self: ""DataQuanta[T]"", p: Predicate) -> ""DataQuanta[T]"":
        return DataQuanta(self.context, self._connect(FilterOperator(p)))

    def map(self: ""DataQuanta[In]"", f: Function) -> ""DataQuanta[Out]"":
        return DataQuanta(self.context, self._connect(MapOperator(f)))

    def flatmap(self: ""DataQuanta[In]"", f: FlatmapFunction) -> ""DataQuanta[IterableOut]"":
        return DataQuanta(self.context, self._connect(FlatmapOperator(f)))

    def store_textfile(self: ""DataQuanta[In]"", path: str, end_line: str = None):
        last: List[SinkOperator] = [
            cast(
                SinkOperator,
                self._connect(
                    TextFileSink(
                        path,
                        self.operator.outputSlot[0],
                        end_line
                    )
                )
            )
        ]
        plan = PywyPlan(self.context.plugins, last)

        plug = self.context.plugins.pop()
        trs: Translator = Translator(plug, plan)
        new_plan = trs.translate()
        plug.get_executor().execute(new_plan)
        # TODO add the logic to execute the plan

    def _connect(self, op: PO_T, port_op: int = 0) -> PywyOperator:
        self.operator.connect(0, op, port_op)
        return op

    def __str__(self):
        return str(self.operator)

    def __repr__(self):
        return self.__str__()

```

4a29f0081231beb08b25fb64d6ece42227be765c","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/155/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/156,https://api.github.com/repos/apache/incubator-wayang/issues/156,incubator-wayang,1197689857,156,not necesary it it 0,github-actions,,,,OPEN,2022-04-08T18:59:10Z,2022-04-08T18:59:10Z,"not necesary it it 0

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/core/translator.py#L49

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

from pywy.graph.types import (WGraphOfVec, NodeVec)
from pywy.core.plugin import Plugin
from pywy.core.plan import PywyPlan
from pywy.core.mapping import Mapping


class Translator:

    plugin: Plugin
    plan: PywyPlan

    def __init__(self, plugin: Plugin, plan: PywyPlan):
        self.plugin = plugin
        self.plan = plan

    def translate(self):
        mappings: Mapping = self.plugin.get_mappings()
        graph = WGraphOfVec(self.plan.sinks)

        def translate2plugin(current_op: NodeVec, next_op: NodeVec):
            if current_op is None:
                return

            if current_op.current[1] is None:
                current_op.current[1] = mappings.get_instanceof(current_op.current[0])

            if next_op is None:
                return
            if next_op.current[1] is None:
                next_op.current[1] = mappings.get_instanceof(next_op.current[0])

            # TODO not necesary it it 0
            current_op.current[1].connect(0, next_op.current[1], 0)

        graph.traversal(graph.starting_nodes, translate2plugin)

        node = []
        for elem in graph.starting_nodes:
            node.append(elem.current[1])

        return PywyPlan({self.plugin}, node)

```

faa6d95fe21aa8beb6316ff96ecbcc5626efb21e","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/156/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/157,https://api.github.com/repos/apache/incubator-wayang/issues/157,incubator-wayang,1197689892,157,get this information by a configuration and ideally by the context,github-actions,,,,CLOSED,2022-04-08T18:59:12Z,2023-07-20T15:06:54Z,"get this information by a configuration and ideally by the context

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/platforms/python/execution.py#L36

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

from pywy.graph.types import WGraphOfOperator, NodeOperator
from pywy.core import ChannelDescriptor
from pywy.core import Executor
from pywy.core import PywyPlan
from pywy.operators import TextFileSource
from pywy.platforms.python.channels import PY_ITERATOR_CHANNEL_DESCRIPTOR
from pywy.platforms.python.operator.py_execution_operator import PyExecutionOperator


class PyExecutor(Executor):

    def __init__(self):
        super(PyExecutor, self).__init__()

    def execute(self, plan):
        pywyPlan: PywyPlan = plan
        graph = WGraphOfOperator(pywyPlan.sinks)

        # TODO get this information by a configuration and ideally by the context
        descriptor_default: ChannelDescriptor = PY_ITERATOR_CHANNEL_DESCRIPTOR
        files_pool = []

        def execute(op_current: NodeOperator, op_next: NodeOperator):
            if op_current is None:
                return

            py_current: PyExecutionOperator = op_current.current
            if py_current.outputs == 0:
                py_current.execute(py_current.inputChannel, [])
                return

            if op_next is None:
                return
            py_next: PyExecutionOperator = op_next.current
            outputs = py_current.get_output_channeldescriptors()
            inputs = py_next.get_input_channeldescriptors()

            intersect = outputs.intersection(inputs)
            if len(intersect) == 0:
                raise Exception(
                    ""The operator(A) {} can't connect with (B) {}, ""
                    ""because the output of (A) is {} and the input of (B) is {} "".format(
                        py_current,
                        py_next,
                        outputs,
                        inputs
                    )
                )

            if len(intersect) > 1:
                if descriptor_default is None:
                    raise Exception(
                        ""The interaction between the operator (A) {} and (B) {}, ""
                        ""can't be decided because are several channel availables {}"".format(
                            py_current,
                            py_next,
                            intersect
                        )
                    )
                descriptor = descriptor_default
            else:
                descriptor = intersect.pop()

            # TODO validate if is valite for several output
            py_current.outputChannel[0] = descriptor.create_instance()

            py_current.execute(py_current.inputChannel, py_current.outputChannel)

            py_next.inputChannel = py_current.outputChannel

            if isinstance(py_current, TextFileSource):
                files_pool.append(py_current.outputChannel[0].provide_iterable())

        graph.traversal(graph.starting_nodes, execute)
        # close the files used during the execution
        for f in files_pool:
            f.close()

```

0881f71f5e321b6608ba96b264024b9a452c27a2","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/157/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/158,https://api.github.com/repos/apache/incubator-wayang/issues/158,incubator-wayang,1197689896,158,add the logic to execute the plan,github-actions,,,,OPEN,2022-04-08T18:59:12Z,2022-04-08T18:59:14Z,"add the logic to execute the plan

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/dataquanta.py#L103

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

from typing import Set, List, cast

from pywy.core import Translator
from pywy.operators.base import PO_T
from pywy.types import (GenericTco, Predicate, Function, FlatmapFunction, IterableOut, T, In, Out)
from pywy.operators import *
from pywy.core import PywyPlan
from pywy.core import Plugin


class WayangContext:
    """"""
    This is the entry point for users to work with Wayang.
    """"""
    plugins: Set[Plugin]

    def __init__(self):
        self.plugins = set()

    """"""
    add a :class:`Plugin` to the :class:`Context`
    """"""

    def register(self, *plugins: Plugin):
        for p in plugins:
            self.plugins.add(p)
        return self

    """"""
    remove a :class:`Plugin` from the :class:`Context`
    """"""

    def unregister(self, *plugins: Plugin):
        for p in plugins:
            self.plugins.remove(p)
        return self

    def textfile(self, file_path: str) -> 'DataQuanta[str]':
        return DataQuanta(self, TextFileSource(file_path))

    def __str__(self):
        return ""Plugins: {}"".format(str(self.plugins))

    def __repr__(self):
        return self.__str__()


class DataQuanta(GenericTco):
    """"""
    Represents an intermediate result/data flow edge in a [[WayangPlan]].
    """"""
    context: WayangContext

    def __init__(self, context: WayangContext, operator: PywyOperator):
        self.operator = operator
        self.context = context

    def filter(self: ""DataQuanta[T]"", p: Predicate) -> ""DataQuanta[T]"":
        return DataQuanta(self.context, self._connect(FilterOperator(p)))

    def map(self: ""DataQuanta[In]"", f: Function) -> ""DataQuanta[Out]"":
        return DataQuanta(self.context, self._connect(MapOperator(f)))

    def flatmap(self: ""DataQuanta[In]"", f: FlatmapFunction) -> ""DataQuanta[IterableOut]"":
        return DataQuanta(self.context, self._connect(FlatmapOperator(f)))

    def store_textfile(self: ""DataQuanta[In]"", path: str, end_line: str = None):
        last: List[SinkOperator] = [
            cast(
                SinkOperator,
                self._connect(
                    TextFileSink(
                        path,
                        self.operator.outputSlot[0],
                        end_line
                    )
                )
            )
        ]
        plan = PywyPlan(self.context.plugins, last)

        plug = self.context.plugins.pop()
        trs: Translator = Translator(plug, plan)
        new_plan = trs.translate()
        plug.get_executor().execute(new_plan)
        # TODO add the logic to execute the plan

    def _connect(self, op: PO_T, port_op: int = 0) -> PywyOperator:
        self.operator.connect(0, op, port_op)
        return op

    def __str__(self):
        return str(self.operator)

    def __repr__(self):
        return self.__str__()

```

4a29f0081231beb08b25fb64d6ece42227be765c","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/158/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/159,https://api.github.com/repos/apache/incubator-wayang/issues/159,incubator-wayang,1197689920,159,validate if is valite for several output,github-actions,,,,CLOSED,2022-04-08T18:59:14Z,2023-07-20T15:06:41Z,"validate if is valite for several output

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/platforms/python/execution.py#L81

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

from pywy.graph.types import WGraphOfOperator, NodeOperator
from pywy.core import ChannelDescriptor
from pywy.core import Executor
from pywy.core import PywyPlan
from pywy.operators import TextFileSource
from pywy.platforms.python.channels import PY_ITERATOR_CHANNEL_DESCRIPTOR
from pywy.platforms.python.operator.py_execution_operator import PyExecutionOperator


class PyExecutor(Executor):

    def __init__(self):
        super(PyExecutor, self).__init__()

    def execute(self, plan):
        pywyPlan: PywyPlan = plan
        graph = WGraphOfOperator(pywyPlan.sinks)

        # TODO get this information by a configuration and ideally by the context
        descriptor_default: ChannelDescriptor = PY_ITERATOR_CHANNEL_DESCRIPTOR
        files_pool = []

        def execute(op_current: NodeOperator, op_next: NodeOperator):
            if op_current is None:
                return

            py_current: PyExecutionOperator = op_current.current
            if py_current.outputs == 0:
                py_current.execute(py_current.inputChannel, [])
                return

            if op_next is None:
                return
            py_next: PyExecutionOperator = op_next.current
            outputs = py_current.get_output_channeldescriptors()
            inputs = py_next.get_input_channeldescriptors()

            intersect = outputs.intersection(inputs)
            if len(intersect) == 0:
                raise Exception(
                    ""The operator(A) {} can't connect with (B) {}, ""
                    ""because the output of (A) is {} and the input of (B) is {} "".format(
                        py_current,
                        py_next,
                        outputs,
                        inputs
                    )
                )

            if len(intersect) > 1:
                if descriptor_default is None:
                    raise Exception(
                        ""The interaction between the operator (A) {} and (B) {}, ""
                        ""can't be decided because are several channel availables {}"".format(
                            py_current,
                            py_next,
                            intersect
                        )
                    )
                descriptor = descriptor_default
            else:
                descriptor = intersect.pop()

            # TODO validate if is valite for several output
            py_current.outputChannel[0] = descriptor.create_instance()

            py_current.execute(py_current.inputChannel, py_current.outputChannel)

            py_next.inputChannel = py_current.outputChannel

            if isinstance(py_current, TextFileSource):
                files_pool.append(py_current.outputChannel[0].provide_iterable())

        graph.traversal(graph.starting_nodes, execute)
        # close the files used during the execution
        for f in files_pool:
            f.close()

```

1ad962a42f5e49779547a717aa0d44a67ac01d12","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/159/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/160,https://api.github.com/repos/apache/incubator-wayang/issues/160,incubator-wayang,1197689935,160,get this information by a configuration and ideally by the context,github-actions,,,,OPEN,2022-04-08T18:59:16Z,2022-04-08T18:59:17Z,"get this information by a configuration and ideally by the context

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/platforms/python/execution.py#L36

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

from pywy.graph.types import WGraphOfOperator, NodeOperator
from pywy.core import ChannelDescriptor
from pywy.core import Executor
from pywy.core import PywyPlan
from pywy.operators import TextFileSource
from pywy.platforms.python.channels import PY_ITERATOR_CHANNEL_DESCRIPTOR
from pywy.platforms.python.operator.py_execution_operator import PyExecutionOperator


class PyExecutor(Executor):

    def __init__(self):
        super(PyExecutor, self).__init__()

    def execute(self, plan):
        pywyPlan: PywyPlan = plan
        graph = WGraphOfOperator(pywyPlan.sinks)

        # TODO get this information by a configuration and ideally by the context
        descriptor_default: ChannelDescriptor = PY_ITERATOR_CHANNEL_DESCRIPTOR
        files_pool = []

        def execute(op_current: NodeOperator, op_next: NodeOperator):
            if op_current is None:
                return

            py_current: PyExecutionOperator = op_current.current
            if py_current.outputs == 0:
                py_current.execute(py_current.inputChannel, [])
                return

            if op_next is None:
                return
            py_next: PyExecutionOperator = op_next.current
            outputs = py_current.get_output_channeldescriptors()
            inputs = py_next.get_input_channeldescriptors()

            intersect = outputs.intersection(inputs)
            if len(intersect) == 0:
                raise Exception(
                    ""The operator(A) {} can't connect with (B) {}, ""
                    ""because the output of (A) is {} and the input of (B) is {} "".format(
                        py_current,
                        py_next,
                        outputs,
                        inputs
                    )
                )

            if len(intersect) > 1:
                if descriptor_default is None:
                    raise Exception(
                        ""The interaction between the operator (A) {} and (B) {}, ""
                        ""can't be decided because are several channel availables {}"".format(
                            py_current,
                            py_next,
                            intersect
                        )
                    )
                descriptor = descriptor_default
            else:
                descriptor = intersect.pop()

            # TODO validate if is valite for several output
            py_current.outputChannel[0] = descriptor.create_instance()

            py_current.execute(py_current.inputChannel, py_current.outputChannel)

            py_next.inputChannel = py_current.outputChannel

            if isinstance(py_current, TextFileSource):
                files_pool.append(py_current.outputChannel[0].provide_iterable())

        graph.traversal(graph.starting_nodes, execute)
        # close the files used during the execution
        for f in files_pool:
            f.close()

```

0881f71f5e321b6608ba96b264024b9a452c27a2","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/160/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/161,https://api.github.com/repos/apache/incubator-wayang/issues/161,incubator-wayang,1197689941,161,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:16Z,2023-07-20T15:06:41Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/core/channel_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitCoreChannel(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

694746551ae2d53f5b194631dd6beaeb46a74bae","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/161/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/162,https://api.github.com/repos/apache/incubator-wayang/issues/162,incubator-wayang,1197689962,162,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:18Z,2023-07-20T15:06:42Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/core/executor_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitCoreExecutor(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

c34d589874bc5d874a9d1a7f51a159e574ee1e54","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/162/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/163,https://api.github.com/repos/apache/incubator-wayang/issues/163,incubator-wayang,1197689964,163,validate if is valite for several output,github-actions,,,,OPEN,2022-04-08T18:59:18Z,2022-04-08T18:59:19Z,"validate if is valite for several output

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/platforms/python/execution.py#L81

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

from pywy.graph.types import WGraphOfOperator, NodeOperator
from pywy.core import ChannelDescriptor
from pywy.core import Executor
from pywy.core import PywyPlan
from pywy.operators import TextFileSource
from pywy.platforms.python.channels import PY_ITERATOR_CHANNEL_DESCRIPTOR
from pywy.platforms.python.operator.py_execution_operator import PyExecutionOperator


class PyExecutor(Executor):

    def __init__(self):
        super(PyExecutor, self).__init__()

    def execute(self, plan):
        pywyPlan: PywyPlan = plan
        graph = WGraphOfOperator(pywyPlan.sinks)

        # TODO get this information by a configuration and ideally by the context
        descriptor_default: ChannelDescriptor = PY_ITERATOR_CHANNEL_DESCRIPTOR
        files_pool = []

        def execute(op_current: NodeOperator, op_next: NodeOperator):
            if op_current is None:
                return

            py_current: PyExecutionOperator = op_current.current
            if py_current.outputs == 0:
                py_current.execute(py_current.inputChannel, [])
                return

            if op_next is None:
                return
            py_next: PyExecutionOperator = op_next.current
            outputs = py_current.get_output_channeldescriptors()
            inputs = py_next.get_input_channeldescriptors()

            intersect = outputs.intersection(inputs)
            if len(intersect) == 0:
                raise Exception(
                    ""The operator(A) {} can't connect with (B) {}, ""
                    ""because the output of (A) is {} and the input of (B) is {} "".format(
                        py_current,
                        py_next,
                        outputs,
                        inputs
                    )
                )

            if len(intersect) > 1:
                if descriptor_default is None:
                    raise Exception(
                        ""The interaction between the operator (A) {} and (B) {}, ""
                        ""can't be decided because are several channel availables {}"".format(
                            py_current,
                            py_next,
                            intersect
                        )
                    )
                descriptor = descriptor_default
            else:
                descriptor = intersect.pop()

            # TODO validate if is valite for several output
            py_current.outputChannel[0] = descriptor.create_instance()

            py_current.execute(py_current.inputChannel, py_current.outputChannel)

            py_next.inputChannel = py_current.outputChannel

            if isinstance(py_current, TextFileSource):
                files_pool.append(py_current.outputChannel[0].provide_iterable())

        graph.traversal(graph.starting_nodes, execute)
        # close the files used during the execution
        for f in files_pool:
            f.close()

```

1ad962a42f5e49779547a717aa0d44a67ac01d12","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/163/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/164,https://api.github.com/repos/apache/incubator-wayang/issues/164,incubator-wayang,1197689988,164,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:20Z,2023-07-20T15:06:42Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/core/mapping_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitCoreMapping(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

1ec1b3cdc3a3e0dfb570d5e24b44c1385f8a203f","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/164/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/165,https://api.github.com/repos/apache/incubator-wayang/issues/165,incubator-wayang,1197689992,165,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:21Z,2023-07-20T15:06:43Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/core/channel_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitCoreChannel(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

694746551ae2d53f5b194631dd6beaeb46a74bae","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/165/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/166,https://api.github.com/repos/apache/incubator-wayang/issues/166,incubator-wayang,1197690012,166,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:22Z,2023-07-20T15:06:24Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/core/plan_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitCorePlan(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

43356b83edf7ff3ec179abfeb22a87298afde7ac","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/166/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/167,https://api.github.com/repos/apache/incubator-wayang/issues/167,incubator-wayang,1197690014,167,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:23Z,2023-07-20T15:06:24Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/core/executor_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitCoreExecutor(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

c34d589874bc5d874a9d1a7f51a159e574ee1e54","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/167/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/168,https://api.github.com/repos/apache/incubator-wayang/issues/168,incubator-wayang,1197690042,168,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:25Z,2023-07-20T15:06:25Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/core/plugin_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitCorePlugin(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

c613d5a0e653844da11540299ce9550b0b022815","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/168/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/169,https://api.github.com/repos/apache/incubator-wayang/issues/169,incubator-wayang,1197690043,169,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:25Z,2023-07-20T15:06:25Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/core/mapping_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitCoreMapping(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

1ec1b3cdc3a3e0dfb570d5e24b44c1385f8a203f","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/169/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/170,https://api.github.com/repos/apache/incubator-wayang/issues/170,incubator-wayang,1197690065,170,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:27Z,2023-07-20T15:06:26Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/core/translator_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitCoreTranslator(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

a7799b1d6ad674eb798cf1fe9ae4d0ad26ac4981","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/170/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/171,https://api.github.com/repos/apache/incubator-wayang/issues/171,incubator-wayang,1197690072,171,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:27Z,2023-07-20T15:06:27Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/core/plan_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitCorePlan(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

43356b83edf7ff3ec179abfeb22a87298afde7ac","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/171/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/172,https://api.github.com/repos/apache/incubator-wayang/issues/172,incubator-wayang,1197690092,172,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:29Z,2023-07-20T15:06:27Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/graph/graph_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitGraphGraph(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

415c5736cea4794a7c51753a006d723e9e469816","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/172/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/173,https://api.github.com/repos/apache/incubator-wayang/issues/173,incubator-wayang,1197690103,173,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:30Z,2023-07-20T15:06:11Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/core/plugin_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitCorePlugin(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

c613d5a0e653844da11540299ce9550b0b022815","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/173/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/174,https://api.github.com/repos/apache/incubator-wayang/issues/174,incubator-wayang,1197690119,174,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:31Z,2023-07-20T15:06:12Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/graph/types_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitGraphTypes(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

4003b12c2d166b6af60fdd0a765b896e11153ead","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/174/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/175,https://api.github.com/repos/apache/incubator-wayang/issues/175,incubator-wayang,1197690130,175,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:32Z,2023-07-20T15:06:12Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/core/translator_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitCoreTranslator(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

a7799b1d6ad674eb798cf1fe9ae4d0ad26ac4981","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/175/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/176,https://api.github.com/repos/apache/incubator-wayang/issues/176,incubator-wayang,1197690140,176,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:33Z,2023-07-20T15:06:13Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/operators/base_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitOperatorsBase(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

7b172c401cd61516ba126e8289536da77a09fec5","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/176/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/177,https://api.github.com/repos/apache/incubator-wayang/issues/177,incubator-wayang,1197690154,177,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:34Z,2023-07-20T15:06:13Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/graph/graph_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitGraphGraph(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

415c5736cea4794a7c51753a006d723e9e469816","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/177/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/178,https://api.github.com/repos/apache/incubator-wayang/issues/178,incubator-wayang,1197690169,178,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:35Z,2023-07-20T15:06:14Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/operators/sink_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitOperatorsSink(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

a671f0e5c336dfad4e2afd55259866f5c9848a62","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/178/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/179,https://api.github.com/repos/apache/incubator-wayang/issues/179,incubator-wayang,1197690185,179,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:36Z,2023-07-20T15:05:58Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/graph/types_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitGraphTypes(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

4003b12c2d166b6af60fdd0a765b896e11153ead","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/179/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/180,https://api.github.com/repos/apache/incubator-wayang/issues/180,incubator-wayang,1197690197,180,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:38Z,2023-07-20T15:05:59Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/operators/source_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitOperatorsSource(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

a21d25473200ff1bee0c2e8cb9458b103f268cda","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/180/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/181,https://api.github.com/repos/apache/incubator-wayang/issues/181,incubator-wayang,1197690214,181,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:39Z,2023-07-20T15:05:59Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/operators/base_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitOperatorsBase(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

7b172c401cd61516ba126e8289536da77a09fec5","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/181/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/182,https://api.github.com/repos/apache/incubator-wayang/issues/182,incubator-wayang,1197690229,182,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:40Z,2023-07-20T15:06:00Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/operators/unary_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitOperatorsUnary(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

34a79c90fa633093a22c989159d48208e2317aed","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/182/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/183,https://api.github.com/repos/apache/incubator-wayang/issues/183,incubator-wayang,1197690239,183,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:41Z,2023-07-20T15:06:00Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/operators/sink_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitOperatorsSink(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

a671f0e5c336dfad4e2afd55259866f5c9848a62","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/183/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/184,https://api.github.com/repos/apache/incubator-wayang/issues/184,incubator-wayang,1197690249,184,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:42Z,2023-07-20T15:06:01Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/platforms/python/channel_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitPlatformPyChannel(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

57ad21751807fb78e3162ac399de8f99590ac064","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/184/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/185,https://api.github.com/repos/apache/incubator-wayang/issues/185,incubator-wayang,1197690258,185,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:43Z,2023-07-20T15:05:45Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/operators/source_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitOperatorsSource(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

a21d25473200ff1bee0c2e8cb9458b103f268cda","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/185/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/186,https://api.github.com/repos/apache/incubator-wayang/issues/186,incubator-wayang,1197690265,186,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:44Z,2023-07-20T15:05:46Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/platforms/python/execution_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitPlatformPyExecution(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

d5d340f32f42e9e83eaeebf530a09885fff83c81","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/186/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/187,https://api.github.com/repos/apache/incubator-wayang/issues/187,incubator-wayang,1197690287,187,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:46Z,2023-07-20T15:05:46Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/operators/unary_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitOperatorsUnary(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

34a79c90fa633093a22c989159d48208e2317aed","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/187/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/188,https://api.github.com/repos/apache/incubator-wayang/issues/188,incubator-wayang,1197690292,188,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:46Z,2023-07-20T15:05:47Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/platforms/python/mappings_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitPlatformPyMappings(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

58da4adfa2a31024f3755664e02b454a55582bcd","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/188/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/189,https://api.github.com/repos/apache/incubator-wayang/issues/189,incubator-wayang,1197690312,189,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:48Z,2023-07-20T15:05:48Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/platforms/python/channel_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitPlatformPyChannel(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

57ad21751807fb78e3162ac399de8f99590ac064","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/189/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/190,https://api.github.com/repos/apache/incubator-wayang/issues/190,incubator-wayang,1197690314,190,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:48Z,2023-07-20T15:05:49Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/platforms/python/operator/py_execution_operator_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitPlatformPyOperatorExecution(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

e520f26346d270507f81b86e58e8c52e70902cc8","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/190/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/191,https://api.github.com/repos/apache/incubator-wayang/issues/191,incubator-wayang,1197690336,191,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:50Z,2023-07-20T15:05:33Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/platforms/python/execution_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitPlatformPyExecution(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

d5d340f32f42e9e83eaeebf530a09885fff83c81","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/191/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/192,https://api.github.com/repos/apache/incubator-wayang/issues/192,incubator-wayang,1197690341,192,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:50Z,2023-07-20T15:05:34Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/platforms/python/operator/py_sink_textfile_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitPlatformPyOperatorSinkTextfile(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

ac543e18eb27eea0d4915f9312183b527709f304","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/192/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/193,https://api.github.com/repos/apache/incubator-wayang/issues/193,incubator-wayang,1197690372,193,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:53Z,2023-07-20T15:05:34Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/platforms/python/mappings_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitPlatformPyMappings(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

58da4adfa2a31024f3755664e02b454a55582bcd","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/193/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/194,https://api.github.com/repos/apache/incubator-wayang/issues/194,incubator-wayang,1197690400,194,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:55Z,2023-07-20T15:05:35Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/platforms/python/operator/py_execution_operator_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitPlatformPyOperatorExecution(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

e520f26346d270507f81b86e58e8c52e70902cc8","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/194/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/195,https://api.github.com/repos/apache/incubator-wayang/issues/195,incubator-wayang,1197690404,195,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:55Z,2023-07-20T15:05:35Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/platforms/python/operator/py_source_textfile_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitPlatformPyOperatorSourceTextfile(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

f3a8f1d40bd85de266bfc87df31124ed6491ae7f","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/195/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/196,https://api.github.com/repos/apache/incubator-wayang/issues/196,incubator-wayang,1197690439,196,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:57Z,2023-07-20T15:05:36Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/platforms/python/operator/py_sink_textfile_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitPlatformPyOperatorSinkTextfile(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

ac543e18eb27eea0d4915f9312183b527709f304","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/196/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/197,https://api.github.com/repos/apache/incubator-wayang/issues/197,incubator-wayang,1197690440,197,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T18:59:58Z,2023-07-20T15:05:22Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/platforms/python/operator/py_unary_filter_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitPlatformPyOperatorUnaryFilter(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

776c8f02562c17e7c3b72babe1265448fa4d7473","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/197/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/198,https://api.github.com/repos/apache/incubator-wayang/issues/198,incubator-wayang,1197690471,198,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T19:00:00Z,2023-07-20T15:05:22Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/platforms/python/operator/py_source_textfile_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitPlatformPyOperatorSourceTextfile(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

f3a8f1d40bd85de266bfc87df31124ed6491ae7f","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/198/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/199,https://api.github.com/repos/apache/incubator-wayang/issues/199,incubator-wayang,1197690480,199,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T19:00:00Z,2023-07-20T15:05:23Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/platforms/python/platform_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitPlatformPyPlatform(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

be752c07de968dbab6192d47af55fc99cba9107a","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/199/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/200,https://api.github.com/repos/apache/incubator-wayang/issues/200,incubator-wayang,1197690501,200,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T19:00:02Z,2023-07-20T15:05:23Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/platforms/python/operator/py_unary_filter_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitPlatformPyOperatorUnaryFilter(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

776c8f02562c17e7c3b72babe1265448fa4d7473","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/200/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/201,https://api.github.com/repos/apache/incubator-wayang/issues/201,incubator-wayang,1197690506,201,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T19:00:02Z,2023-07-20T15:05:24Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/platforms/python/plugin_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitPlatformPyPlugin(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

2b68bfba565807814230670fcef496b4fb0b9746","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/201/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/202,https://api.github.com/repos/apache/incubator-wayang/issues/202,incubator-wayang,1197690533,202,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T19:00:05Z,2023-07-20T15:05:24Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/platforms/python/platform_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitPlatformPyPlatform(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

be752c07de968dbab6192d47af55fc99cba9107a","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/202/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/203,https://api.github.com/repos/apache/incubator-wayang/issues/203,incubator-wayang,1197690535,203,add the missing test for get_type_bifunction,github-actions,,,,CLOSED,2022-04-08T19:00:05Z,2023-07-20T15:11:09Z,"add the missing test for get_type_bifunction

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/types_test.py#L251

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import inspect
import unittest
from unittest.mock import Mock

from pywy.exception import PywyException
from pywy.types import get_type_function, get_type_bifunction, get_type_flatmap_function, get_type_predicate

empty_type = inspect._empty


class TestUnitTypesPredicate(unittest.TestCase):
    def setUp(self):
        pass

    def test_predicate_without_parameters(self):
        def pred() -> bool:
            return True

        try:
            get_type_predicate(pred)
            self.fail(""The predicates parameters are mandatory"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Predicate are distinct than one,"" in str(ex))

    def test_predicate_with_one_parameter_no_type(self):
        def pred(x) -> bool:
            return True

        try:
            pred_type = get_type_predicate(pred)
            self.assertEqual(pred_type, empty_type)
        except PywyException as ex:
            self.fail(str(ex))

    def test_predicate_with_one_parameter_with_basic_type(self):
        def pred(x: int) -> bool:
            return True

        try:
            pred_type = get_type_predicate(pred)
            self.assertEqual(pred_type, int)
        except PywyException as ex:
            self.fail(str(ex))

    def test_predicate_with_one_parameter_with_obe_type(self):
        def pred(x: Mock) -> bool:
            return True

        try:
            pred_type = get_type_predicate(pred)
            self.assertEqual(pred_type, Mock)
        except PywyException as ex:
            self.fail(str(ex))

    def test_predicate_with_two_parameters(self):
        def pred(x: Mock, y: Mock) -> bool:
            return True

        try:
            get_type_predicate(pred)
            self.fail(""the predicate can have just one input"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Predicate are distinct than one"" in str(ex))


class TestUnitTypesFunction(unittest.TestCase):
    def setUp(self):
        pass

    def test_function_without_parameters_no_return(self):
        def func():
            return

        try:
            get_type_function(func)
            self.fail(""The function parameters are mandatory"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Function are distinct than one,"" in str(ex))

    def test_function_with_one_parameter_no_type_no_return(self):
        def func(x):
            return

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, empty_type)
            self.assertEqual(output_type, empty_type)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_one_parameter_with_basic_type_no_return(self):
        def func(x: int):
            return

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, int)
            self.assertEqual(output_type, empty_type)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_one_parameter_with_obj_type_no_return(self):
        def func(x: Mock):
            return

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, Mock)
            self.assertEqual(output_type, empty_type)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_two_parameters_no_return(self):
        def func(x: Mock, y: Mock):
            return

        try:
            get_type_function(func)
            self.fail(""the function can have just one input"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Function are distinct than one"" in str(ex))

    def test_function_without_parameters_basic_return(self):
        def func() -> int:
            return 0

        try:
            get_type_function(func)
            self.fail(""The function parameters are mandatory"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Function are distinct than one,"" in str(ex))

    def test_function_with_one_parameter_no_type_basic_return(self):
        def func(x) -> int:
            return 0

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, empty_type)
            self.assertEqual(output_type, int)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_one_parameter_with_basic_type_basic_return(self):
        def func(x: int) -> int:
            return 0

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, int)
            self.assertEqual(output_type, int)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_one_parameter_with_obj_type_basic_return(self):
        def func(x: Mock) -> int:
            return 0

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, Mock)
            self.assertEqual(output_type, int)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_two_parameters_basic_return(self):
        def func(x: Mock, y: Mock) -> int:
            return 0

        try:
            get_type_function(func)
            self.fail(""the function can have just one input"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Function are distinct than one"" in str(ex))

    def test_function_without_parameters_obj_return(self):
        def func() -> Mock:
            return Mock()

        try:
            get_type_function(func)
            self.fail(""The function parameters are mandatory"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Function are distinct than one,"" in str(ex))

    def test_function_with_one_parameter_no_type_obj_return(self):
        def func(x) -> Mock:
            return Mock()

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, empty_type)
            self.assertEqual(output_type, Mock)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_one_parameter_with_basic_type_basic_return(self):
        def func(x: int) -> Mock:
            return Mock()

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, int)
            self.assertEqual(output_type, Mock)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_one_parameter_with_obe_type_basic_return(self):
        def func(x: Mock) -> Mock:
            return Mock()

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, Mock)
            self.assertEqual(output_type, Mock)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_two_parameters_basic_return(self):
        def func(x: Mock, y: Mock) -> Mock:
            return Mock()

        try:
            get_type_function(func)
            self.fail(""the function can have just one input"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Function are distinct than one"" in str(ex))


class TestUnitTypesBiFunction(unittest.TestCase):
    def setUp(self):
        pass

    # TODO add the missing test for get_type_bifunction
    def test_bifunction_without_parameters_no_return(self):
        def func():
            return

        try:
            get_type_bifunction(func)
            self.fail(""The bifunction parameters are mandatory"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the BiFunction are distinct than two,"" in str(ex))


class TestUnitTypesFlatmapFunction(unittest.TestCase):
    def setUp(self):
        pass

    # TODO add the missing test for get_type_flatmap_function
    def test_flatmapfunction_without_parameters_no_return(self):
        def func():
            return

        try:
            get_type_flatmap_function(func)
            self.fail(""The bifunction parameters are mandatory"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the FlatmapFunction are distinct than one,"" in str(ex))

```

7dc2f76a86e926a07b18c116b5637f9cfdf8dda6","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/203/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/204,https://api.github.com/repos/apache/incubator-wayang/issues/204,incubator-wayang,1197690562,204,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENV...",github-actions,,,,CLOSED,2022-04-08T19:00:07Z,2023-07-20T15:06:14Z,"REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT

Returns

-------

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/platforms/python/plugin_test.py#L27

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import unittest


class TestUnitPlatformPyPlugin(unittest.TestCase):
    def setUp(self):
        pass

    def test_TO_REMOVE(self):
        """"""
        TODO REMOVE THIS TEST, IT JUST TO VALIDATE THAT EVERYTHING IS CORRECT IN TERMS OF ENVIRONMENT
        Returns
        -------

        """"""
        self.assertEqual(""a"", ""a"")


```

2b68bfba565807814230670fcef496b4fb0b9746","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/204/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/205,https://api.github.com/repos/apache/incubator-wayang/issues/205,incubator-wayang,1197690567,205,add the missing test for get_type_flatmap_function,github-actions,,,,CLOSED,2022-04-08T19:00:07Z,2023-07-20T15:11:09Z,"add the missing test for get_type_flatmap_function

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/types_test.py#L267

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import inspect
import unittest
from unittest.mock import Mock

from pywy.exception import PywyException
from pywy.types import get_type_function, get_type_bifunction, get_type_flatmap_function, get_type_predicate

empty_type = inspect._empty


class TestUnitTypesPredicate(unittest.TestCase):
    def setUp(self):
        pass

    def test_predicate_without_parameters(self):
        def pred() -> bool:
            return True

        try:
            get_type_predicate(pred)
            self.fail(""The predicates parameters are mandatory"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Predicate are distinct than one,"" in str(ex))

    def test_predicate_with_one_parameter_no_type(self):
        def pred(x) -> bool:
            return True

        try:
            pred_type = get_type_predicate(pred)
            self.assertEqual(pred_type, empty_type)
        except PywyException as ex:
            self.fail(str(ex))

    def test_predicate_with_one_parameter_with_basic_type(self):
        def pred(x: int) -> bool:
            return True

        try:
            pred_type = get_type_predicate(pred)
            self.assertEqual(pred_type, int)
        except PywyException as ex:
            self.fail(str(ex))

    def test_predicate_with_one_parameter_with_obe_type(self):
        def pred(x: Mock) -> bool:
            return True

        try:
            pred_type = get_type_predicate(pred)
            self.assertEqual(pred_type, Mock)
        except PywyException as ex:
            self.fail(str(ex))

    def test_predicate_with_two_parameters(self):
        def pred(x: Mock, y: Mock) -> bool:
            return True

        try:
            get_type_predicate(pred)
            self.fail(""the predicate can have just one input"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Predicate are distinct than one"" in str(ex))


class TestUnitTypesFunction(unittest.TestCase):
    def setUp(self):
        pass

    def test_function_without_parameters_no_return(self):
        def func():
            return

        try:
            get_type_function(func)
            self.fail(""The function parameters are mandatory"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Function are distinct than one,"" in str(ex))

    def test_function_with_one_parameter_no_type_no_return(self):
        def func(x):
            return

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, empty_type)
            self.assertEqual(output_type, empty_type)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_one_parameter_with_basic_type_no_return(self):
        def func(x: int):
            return

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, int)
            self.assertEqual(output_type, empty_type)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_one_parameter_with_obj_type_no_return(self):
        def func(x: Mock):
            return

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, Mock)
            self.assertEqual(output_type, empty_type)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_two_parameters_no_return(self):
        def func(x: Mock, y: Mock):
            return

        try:
            get_type_function(func)
            self.fail(""the function can have just one input"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Function are distinct than one"" in str(ex))

    def test_function_without_parameters_basic_return(self):
        def func() -> int:
            return 0

        try:
            get_type_function(func)
            self.fail(""The function parameters are mandatory"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Function are distinct than one,"" in str(ex))

    def test_function_with_one_parameter_no_type_basic_return(self):
        def func(x) -> int:
            return 0

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, empty_type)
            self.assertEqual(output_type, int)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_one_parameter_with_basic_type_basic_return(self):
        def func(x: int) -> int:
            return 0

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, int)
            self.assertEqual(output_type, int)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_one_parameter_with_obj_type_basic_return(self):
        def func(x: Mock) -> int:
            return 0

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, Mock)
            self.assertEqual(output_type, int)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_two_parameters_basic_return(self):
        def func(x: Mock, y: Mock) -> int:
            return 0

        try:
            get_type_function(func)
            self.fail(""the function can have just one input"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Function are distinct than one"" in str(ex))

    def test_function_without_parameters_obj_return(self):
        def func() -> Mock:
            return Mock()

        try:
            get_type_function(func)
            self.fail(""The function parameters are mandatory"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Function are distinct than one,"" in str(ex))

    def test_function_with_one_parameter_no_type_obj_return(self):
        def func(x) -> Mock:
            return Mock()

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, empty_type)
            self.assertEqual(output_type, Mock)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_one_parameter_with_basic_type_basic_return(self):
        def func(x: int) -> Mock:
            return Mock()

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, int)
            self.assertEqual(output_type, Mock)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_one_parameter_with_obe_type_basic_return(self):
        def func(x: Mock) -> Mock:
            return Mock()

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, Mock)
            self.assertEqual(output_type, Mock)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_two_parameters_basic_return(self):
        def func(x: Mock, y: Mock) -> Mock:
            return Mock()

        try:
            get_type_function(func)
            self.fail(""the function can have just one input"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Function are distinct than one"" in str(ex))


class TestUnitTypesBiFunction(unittest.TestCase):
    def setUp(self):
        pass

    # TODO add the missing test for get_type_bifunction
    def test_bifunction_without_parameters_no_return(self):
        def func():
            return

        try:
            get_type_bifunction(func)
            self.fail(""The bifunction parameters are mandatory"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the BiFunction are distinct than two,"" in str(ex))


class TestUnitTypesFlatmapFunction(unittest.TestCase):
    def setUp(self):
        pass

    # TODO add the missing test for get_type_flatmap_function
    def test_flatmapfunction_without_parameters_no_return(self):
        def func():
            return

        try:
            get_type_flatmap_function(func)
            self.fail(""The bifunction parameters are mandatory"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the FlatmapFunction are distinct than one,"" in str(ex))

```

b516891d77b9474c671316ead75f6a9867225c82","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/205/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/206,https://api.github.com/repos/apache/incubator-wayang/issues/206,incubator-wayang,1197690590,206,add the missing test for get_type_bifunction,github-actions,,,,OPEN,2022-04-08T19:00:09Z,2022-04-08T19:00:10Z,"add the missing test for get_type_bifunction

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/types_test.py#L251

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import inspect
import unittest
from unittest.mock import Mock

from pywy.exception import PywyException
from pywy.types import get_type_function, get_type_bifunction, get_type_flatmap_function, get_type_predicate

empty_type = inspect._empty


class TestUnitTypesPredicate(unittest.TestCase):
    def setUp(self):
        pass

    def test_predicate_without_parameters(self):
        def pred() -> bool:
            return True

        try:
            get_type_predicate(pred)
            self.fail(""The predicates parameters are mandatory"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Predicate are distinct than one,"" in str(ex))

    def test_predicate_with_one_parameter_no_type(self):
        def pred(x) -> bool:
            return True

        try:
            pred_type = get_type_predicate(pred)
            self.assertEqual(pred_type, empty_type)
        except PywyException as ex:
            self.fail(str(ex))

    def test_predicate_with_one_parameter_with_basic_type(self):
        def pred(x: int) -> bool:
            return True

        try:
            pred_type = get_type_predicate(pred)
            self.assertEqual(pred_type, int)
        except PywyException as ex:
            self.fail(str(ex))

    def test_predicate_with_one_parameter_with_obe_type(self):
        def pred(x: Mock) -> bool:
            return True

        try:
            pred_type = get_type_predicate(pred)
            self.assertEqual(pred_type, Mock)
        except PywyException as ex:
            self.fail(str(ex))

    def test_predicate_with_two_parameters(self):
        def pred(x: Mock, y: Mock) -> bool:
            return True

        try:
            get_type_predicate(pred)
            self.fail(""the predicate can have just one input"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Predicate are distinct than one"" in str(ex))


class TestUnitTypesFunction(unittest.TestCase):
    def setUp(self):
        pass

    def test_function_without_parameters_no_return(self):
        def func():
            return

        try:
            get_type_function(func)
            self.fail(""The function parameters are mandatory"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Function are distinct than one,"" in str(ex))

    def test_function_with_one_parameter_no_type_no_return(self):
        def func(x):
            return

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, empty_type)
            self.assertEqual(output_type, empty_type)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_one_parameter_with_basic_type_no_return(self):
        def func(x: int):
            return

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, int)
            self.assertEqual(output_type, empty_type)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_one_parameter_with_obj_type_no_return(self):
        def func(x: Mock):
            return

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, Mock)
            self.assertEqual(output_type, empty_type)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_two_parameters_no_return(self):
        def func(x: Mock, y: Mock):
            return

        try:
            get_type_function(func)
            self.fail(""the function can have just one input"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Function are distinct than one"" in str(ex))

    def test_function_without_parameters_basic_return(self):
        def func() -> int:
            return 0

        try:
            get_type_function(func)
            self.fail(""The function parameters are mandatory"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Function are distinct than one,"" in str(ex))

    def test_function_with_one_parameter_no_type_basic_return(self):
        def func(x) -> int:
            return 0

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, empty_type)
            self.assertEqual(output_type, int)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_one_parameter_with_basic_type_basic_return(self):
        def func(x: int) -> int:
            return 0

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, int)
            self.assertEqual(output_type, int)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_one_parameter_with_obj_type_basic_return(self):
        def func(x: Mock) -> int:
            return 0

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, Mock)
            self.assertEqual(output_type, int)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_two_parameters_basic_return(self):
        def func(x: Mock, y: Mock) -> int:
            return 0

        try:
            get_type_function(func)
            self.fail(""the function can have just one input"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Function are distinct than one"" in str(ex))

    def test_function_without_parameters_obj_return(self):
        def func() -> Mock:
            return Mock()

        try:
            get_type_function(func)
            self.fail(""The function parameters are mandatory"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Function are distinct than one,"" in str(ex))

    def test_function_with_one_parameter_no_type_obj_return(self):
        def func(x) -> Mock:
            return Mock()

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, empty_type)
            self.assertEqual(output_type, Mock)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_one_parameter_with_basic_type_basic_return(self):
        def func(x: int) -> Mock:
            return Mock()

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, int)
            self.assertEqual(output_type, Mock)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_one_parameter_with_obe_type_basic_return(self):
        def func(x: Mock) -> Mock:
            return Mock()

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, Mock)
            self.assertEqual(output_type, Mock)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_two_parameters_basic_return(self):
        def func(x: Mock, y: Mock) -> Mock:
            return Mock()

        try:
            get_type_function(func)
            self.fail(""the function can have just one input"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Function are distinct than one"" in str(ex))


class TestUnitTypesBiFunction(unittest.TestCase):
    def setUp(self):
        pass

    # TODO add the missing test for get_type_bifunction
    def test_bifunction_without_parameters_no_return(self):
        def func():
            return

        try:
            get_type_bifunction(func)
            self.fail(""The bifunction parameters are mandatory"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the BiFunction are distinct than two,"" in str(ex))


class TestUnitTypesFlatmapFunction(unittest.TestCase):
    def setUp(self):
        pass

    # TODO add the missing test for get_type_flatmap_function
    def test_flatmapfunction_without_parameters_no_return(self):
        def func():
            return

        try:
            get_type_flatmap_function(func)
            self.fail(""The bifunction parameters are mandatory"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the FlatmapFunction are distinct than one,"" in str(ex))

```

7dc2f76a86e926a07b18c116b5637f9cfdf8dda6","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/206/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/207,https://api.github.com/repos/apache/incubator-wayang/issues/207,incubator-wayang,1197690611,207,add the missing test for get_type_flatmap_function,github-actions,,,,OPEN,2022-04-08T19:00:12Z,2022-04-08T19:00:13Z,"add the missing test for get_type_flatmap_function

https://github.com/apache/incubator-wayang/blob/4cc0bfdca06dda171b661822daae5fa438d9d475/python/src/pywy/tests/unit/types_test.py#L267

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

import inspect
import unittest
from unittest.mock import Mock

from pywy.exception import PywyException
from pywy.types import get_type_function, get_type_bifunction, get_type_flatmap_function, get_type_predicate

empty_type = inspect._empty


class TestUnitTypesPredicate(unittest.TestCase):
    def setUp(self):
        pass

    def test_predicate_without_parameters(self):
        def pred() -> bool:
            return True

        try:
            get_type_predicate(pred)
            self.fail(""The predicates parameters are mandatory"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Predicate are distinct than one,"" in str(ex))

    def test_predicate_with_one_parameter_no_type(self):
        def pred(x) -> bool:
            return True

        try:
            pred_type = get_type_predicate(pred)
            self.assertEqual(pred_type, empty_type)
        except PywyException as ex:
            self.fail(str(ex))

    def test_predicate_with_one_parameter_with_basic_type(self):
        def pred(x: int) -> bool:
            return True

        try:
            pred_type = get_type_predicate(pred)
            self.assertEqual(pred_type, int)
        except PywyException as ex:
            self.fail(str(ex))

    def test_predicate_with_one_parameter_with_obe_type(self):
        def pred(x: Mock) -> bool:
            return True

        try:
            pred_type = get_type_predicate(pred)
            self.assertEqual(pred_type, Mock)
        except PywyException as ex:
            self.fail(str(ex))

    def test_predicate_with_two_parameters(self):
        def pred(x: Mock, y: Mock) -> bool:
            return True

        try:
            get_type_predicate(pred)
            self.fail(""the predicate can have just one input"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Predicate are distinct than one"" in str(ex))


class TestUnitTypesFunction(unittest.TestCase):
    def setUp(self):
        pass

    def test_function_without_parameters_no_return(self):
        def func():
            return

        try:
            get_type_function(func)
            self.fail(""The function parameters are mandatory"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Function are distinct than one,"" in str(ex))

    def test_function_with_one_parameter_no_type_no_return(self):
        def func(x):
            return

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, empty_type)
            self.assertEqual(output_type, empty_type)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_one_parameter_with_basic_type_no_return(self):
        def func(x: int):
            return

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, int)
            self.assertEqual(output_type, empty_type)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_one_parameter_with_obj_type_no_return(self):
        def func(x: Mock):
            return

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, Mock)
            self.assertEqual(output_type, empty_type)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_two_parameters_no_return(self):
        def func(x: Mock, y: Mock):
            return

        try:
            get_type_function(func)
            self.fail(""the function can have just one input"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Function are distinct than one"" in str(ex))

    def test_function_without_parameters_basic_return(self):
        def func() -> int:
            return 0

        try:
            get_type_function(func)
            self.fail(""The function parameters are mandatory"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Function are distinct than one,"" in str(ex))

    def test_function_with_one_parameter_no_type_basic_return(self):
        def func(x) -> int:
            return 0

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, empty_type)
            self.assertEqual(output_type, int)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_one_parameter_with_basic_type_basic_return(self):
        def func(x: int) -> int:
            return 0

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, int)
            self.assertEqual(output_type, int)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_one_parameter_with_obj_type_basic_return(self):
        def func(x: Mock) -> int:
            return 0

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, Mock)
            self.assertEqual(output_type, int)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_two_parameters_basic_return(self):
        def func(x: Mock, y: Mock) -> int:
            return 0

        try:
            get_type_function(func)
            self.fail(""the function can have just one input"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Function are distinct than one"" in str(ex))

    def test_function_without_parameters_obj_return(self):
        def func() -> Mock:
            return Mock()

        try:
            get_type_function(func)
            self.fail(""The function parameters are mandatory"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Function are distinct than one,"" in str(ex))

    def test_function_with_one_parameter_no_type_obj_return(self):
        def func(x) -> Mock:
            return Mock()

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, empty_type)
            self.assertEqual(output_type, Mock)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_one_parameter_with_basic_type_basic_return(self):
        def func(x: int) -> Mock:
            return Mock()

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, int)
            self.assertEqual(output_type, Mock)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_one_parameter_with_obe_type_basic_return(self):
        def func(x: Mock) -> Mock:
            return Mock()

        try:
            input_type, output_type = get_type_function(func)
            self.assertEqual(input_type, Mock)
            self.assertEqual(output_type, Mock)
        except PywyException as ex:
            self.fail(str(ex))

    def test_function_with_two_parameters_basic_return(self):
        def func(x: Mock, y: Mock) -> Mock:
            return Mock()

        try:
            get_type_function(func)
            self.fail(""the function can have just one input"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the Function are distinct than one"" in str(ex))


class TestUnitTypesBiFunction(unittest.TestCase):
    def setUp(self):
        pass

    # TODO add the missing test for get_type_bifunction
    def test_bifunction_without_parameters_no_return(self):
        def func():
            return

        try:
            get_type_bifunction(func)
            self.fail(""The bifunction parameters are mandatory"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the BiFunction are distinct than two,"" in str(ex))


class TestUnitTypesFlatmapFunction(unittest.TestCase):
    def setUp(self):
        pass

    # TODO add the missing test for get_type_flatmap_function
    def test_flatmapfunction_without_parameters_no_return(self):
        def func():
            return

        try:
            get_type_flatmap_function(func)
            self.fail(""The bifunction parameters are mandatory"")
        except PywyException as ex:
            self.assertTrue(""the parameters for the FlatmapFunction are distinct than one,"" in str(ex))

```

b516891d77b9474c671316ead75f6a9867225c82","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/207/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/210,https://api.github.com/repos/apache/incubator-wayang/issues/210,incubator-wayang,1199623024,210,add documentation to Python-API,berttty,24259784,Bertty Contreras-Rojas,,OPEN,2022-04-11T08:42:26Z,2022-04-11T08:42:26Z,add the minimal documentation to the Python-API,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/210/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/211,https://api.github.com/repos/apache/incubator-wayang/issues/211,incubator-wayang,1199640996,211,add JVM-platform inside of Python-API,berttty,24259784,Bertty Contreras-Rojas,,CLOSED,2022-04-11T08:57:05Z,2022-06-19T22:23:00Z,To enable running the code on any platform requires the interaction between Python and JVM platforms,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/211/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/213,https://api.github.com/repos/apache/incubator-wayang/issues/213,incubator-wayang,1202419396,213,not necesary it it 0,github-actions,,,,OPEN,2022-04-12T21:38:03Z,2022-04-12T21:38:05Z,"not necesary it it 0

https://github.com/apache/incubator-wayang/blob/77a5d3b5854f59b9cad1f9e9921b849ccc5cca58/python/src/pywy/core/core.py#L165

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

from typing import Set, Iterable

from pywy.core.executor import Executor
from pywy.core.platform import Platform
from pywy.core.mapping import Mapping
from pywy.graph.graph import WayangGraph
from pywy.graph.types import WGraphOfVec, NodeOperator, NodeVec
from pywy.operators import SinkOperator


class TranslateContext:
    """"""TranslateContext contextual variables a parameters for the translation
    """"""
    pass


class Plugin:
    """""" TODO: enrich this documentation
    A plugin contributes the following components to a :class:`Context`
    - mappings
    - channels
    - configurations
    In turn, it may require several :clas:`Platform`s for its operation.
    """"""

    platforms: Set[Platform]
    mappings: Mapping
    translate_context: TranslateContext

    def __init__(
            self,
            platforms: Set[Platform],
            mappings: Mapping = Mapping(),
            translate_context: TranslateContext = None):
        self.platforms = platforms
        self.mappings = mappings
        self.translate_context = translate_context

    def get_mappings(self) -> Mapping:
        return self.mappings

    def get_executor(self) -> Executor:
        pass

    def __str__(self):
        return ""Platforms: {}, Mappings: {}"".format(str(self.platforms), str(self.mappings))

    def __repr__(self):
        return self.__str__()


class PywyPlan:
    """"""A PywyPlan consists of a set of :py:class:`pywy.operators.base.PywyOperator`

    the operator inside PywyPlan follow a Directed acyclic graph(DAG), and describe
    how the execution needs to be performed

    Attributes
    ----------
    graph : :py:class:`pywy.graph.graph.WayangGraph`
       Graph that describe the DAG, and it provides the iterable properties to
       the PywyPlan
    plugins : :obj:`set` of :py:class:`pywy.core.plugin.Plugin`
        plugins is the set of possible platforms that can be uses to execute
        the PywyPlan
    sinks : :py:class:`typing.Iterable` of :py:class:`pywy.operators.sink.SinkOperator`
        The list of sink operators, this describe the end of the pipeline, and
        they are used to build the `graph`
    """"""
    graph: WayangGraph

    def __init__(self, plugins: Set[Plugin], sinks: Iterable[SinkOperator]):
        """"""basic Constructor of PywyPlan

        this constructor set the plugins and sinks element, and it prepares
        everything for been executed

        Parameters
        ----------
        plugins
            Description of `plugins`.
        sinks
            Description of `sinks`.
        """"""
        self.plugins = plugins
        self.sinks = sinks
        self.set_graph()

    def set_graph(self):
        """""" it builds the :py:class:`pywy.graph.graph.WayangGraph` of the current PywyPlan
        """"""
        self.graph = WGraphOfVec(self.sinks)

    def execute(self):
        """""" Execute the plan with the plugin provided at the moment of creation
        """"""
        plug = next(iter(self.plugins))
        trs: Translator = Translator(plug, self)
        new_plan = trs.translate()
        plug.get_executor().execute(new_plan)


class Translator:
    """"""Translator use the :py:class:`pywy.core.Mapping` to convert the :py:class:`pywy.operators.base.PywyOperator`

    Translator take a plan a produce the executable version of the plan using as tool
    the :py:class:`pywy.core.Mapping` of the :py:class:`pywy.core.core.Plugin` and convert
    the :py:class:`pywy.operators.base.PywyOperator` into an executable version inside
    the :py:class:`pywy.core.Platform`

    Attributes
    ----------
    plugin : :py:class:`pywy.core.core.Plugin`
        plugin use in the translation
    plan : :py:class:`pywy.core.core.PywyPlan`
        Plan to be translated by the translator
    translate_context: :py:class:`pywy.core.core.TranslateContext`
        context used by the translates at runtime in some case is not needed
    """"""

    plugin: Plugin
    plan: PywyPlan
    translate_context: TranslateContext

    def __init__(self, plugin: Plugin, plan: PywyPlan):
        self.plugin = plugin
        self.plan = plan
        self.translate_context = plugin.translate_context

    def translate(self):
        mappings: Mapping = self.plugin.get_mappings()
        graph = WGraphOfVec(self.plan.sinks)

        translate = self.translate_context

        def translate2plugin(current_op: NodeVec, next_op: NodeVec):
            if current_op is None:
                return

            if current_op.current[1] is None:
                current_op.current[1] = mappings.get_instanceof(current_op.current[0], **{'translate_context': translate})

            if next_op is None:
                return
            if next_op.current[1] is None:
                next_op.current[1] = mappings.get_instanceof(next_op.current[0], **{'translate_context': translate})

            # TODO not necesary it it 0
            current_op.current[1].connect(0, next_op.current[1], 0)

        graph.traversal(graph.starting_nodes, translate2plugin)

        node = []
        for elem in graph.starting_nodes:
            node.append(elem.current[1])

        return PywyPlan({self.plugin}, node)

```

2087a1b8832ae32d949dacaa8443436923675cc0","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/213/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/214,https://api.github.com/repos/apache/incubator-wayang/issues/214,incubator-wayang,1202419420,214,not necesary it it 0,github-actions,,,,CLOSED,2022-04-12T21:38:05Z,2023-07-20T15:04:45Z,"not necesary it it 0

https://github.com/apache/incubator-wayang/blob/77a5d3b5854f59b9cad1f9e9921b849ccc5cca58/python/src/pywy/core/core.py#L165

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

from typing import Set, Iterable

from pywy.core.executor import Executor
from pywy.core.platform import Platform
from pywy.core.mapping import Mapping
from pywy.graph.graph import WayangGraph
from pywy.graph.types import WGraphOfVec, NodeOperator, NodeVec
from pywy.operators import SinkOperator


class TranslateContext:
    """"""TranslateContext contextual variables a parameters for the translation
    """"""
    pass


class Plugin:
    """""" TODO: enrich this documentation
    A plugin contributes the following components to a :class:`Context`
    - mappings
    - channels
    - configurations
    In turn, it may require several :clas:`Platform`s for its operation.
    """"""

    platforms: Set[Platform]
    mappings: Mapping
    translate_context: TranslateContext

    def __init__(
            self,
            platforms: Set[Platform],
            mappings: Mapping = Mapping(),
            translate_context: TranslateContext = None):
        self.platforms = platforms
        self.mappings = mappings
        self.translate_context = translate_context

    def get_mappings(self) -> Mapping:
        return self.mappings

    def get_executor(self) -> Executor:
        pass

    def __str__(self):
        return ""Platforms: {}, Mappings: {}"".format(str(self.platforms), str(self.mappings))

    def __repr__(self):
        return self.__str__()


class PywyPlan:
    """"""A PywyPlan consists of a set of :py:class:`pywy.operators.base.PywyOperator`

    the operator inside PywyPlan follow a Directed acyclic graph(DAG), and describe
    how the execution needs to be performed

    Attributes
    ----------
    graph : :py:class:`pywy.graph.graph.WayangGraph`
       Graph that describe the DAG, and it provides the iterable properties to
       the PywyPlan
    plugins : :obj:`set` of :py:class:`pywy.core.plugin.Plugin`
        plugins is the set of possible platforms that can be uses to execute
        the PywyPlan
    sinks : :py:class:`typing.Iterable` of :py:class:`pywy.operators.sink.SinkOperator`
        The list of sink operators, this describe the end of the pipeline, and
        they are used to build the `graph`
    """"""
    graph: WayangGraph

    def __init__(self, plugins: Set[Plugin], sinks: Iterable[SinkOperator]):
        """"""basic Constructor of PywyPlan

        this constructor set the plugins and sinks element, and it prepares
        everything for been executed

        Parameters
        ----------
        plugins
            Description of `plugins`.
        sinks
            Description of `sinks`.
        """"""
        self.plugins = plugins
        self.sinks = sinks
        self.set_graph()

    def set_graph(self):
        """""" it builds the :py:class:`pywy.graph.graph.WayangGraph` of the current PywyPlan
        """"""
        self.graph = WGraphOfVec(self.sinks)

    def execute(self):
        """""" Execute the plan with the plugin provided at the moment of creation
        """"""
        plug = next(iter(self.plugins))
        trs: Translator = Translator(plug, self)
        new_plan = trs.translate()
        plug.get_executor().execute(new_plan)


class Translator:
    """"""Translator use the :py:class:`pywy.core.Mapping` to convert the :py:class:`pywy.operators.base.PywyOperator`

    Translator take a plan a produce the executable version of the plan using as tool
    the :py:class:`pywy.core.Mapping` of the :py:class:`pywy.core.core.Plugin` and convert
    the :py:class:`pywy.operators.base.PywyOperator` into an executable version inside
    the :py:class:`pywy.core.Platform`

    Attributes
    ----------
    plugin : :py:class:`pywy.core.core.Plugin`
        plugin use in the translation
    plan : :py:class:`pywy.core.core.PywyPlan`
        Plan to be translated by the translator
    translate_context: :py:class:`pywy.core.core.TranslateContext`
        context used by the translates at runtime in some case is not needed
    """"""

    plugin: Plugin
    plan: PywyPlan
    translate_context: TranslateContext

    def __init__(self, plugin: Plugin, plan: PywyPlan):
        self.plugin = plugin
        self.plan = plan
        self.translate_context = plugin.translate_context

    def translate(self):
        mappings: Mapping = self.plugin.get_mappings()
        graph = WGraphOfVec(self.plan.sinks)

        translate = self.translate_context

        def translate2plugin(current_op: NodeVec, next_op: NodeVec):
            if current_op is None:
                return

            if current_op.current[1] is None:
                current_op.current[1] = mappings.get_instanceof(current_op.current[0], **{'translate_context': translate})

            if next_op is None:
                return
            if next_op.current[1] is None:
                next_op.current[1] = mappings.get_instanceof(next_op.current[0], **{'translate_context': translate})

            # TODO not necesary it it 0
            current_op.current[1].connect(0, next_op.current[1], 0)

        graph.traversal(graph.starting_nodes, translate2plugin)

        node = []
        for elem in graph.starting_nodes:
            node.append(elem.current[1])

        return PywyPlan({self.plugin}, node)

```

2087a1b8832ae32d949dacaa8443436923675cc0","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/214/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/215,https://api.github.com/repos/apache/incubator-wayang/issues/215,incubator-wayang,1202419453,215,enrich this documentation,github-actions,,,,OPEN,2022-04-12T21:38:07Z,2023-07-20T15:10:45Z,"enrich this documentation

A plugin contributes the following components to a :class:`Context`

- mappings

- channels

- configurations

In turn, it may require several :clas:`Platform`s for its operation.

https://github.com/apache/incubator-wayang/blob/77a5d3b5854f59b9cad1f9e9921b849ccc5cca58/python/src/pywy/core/core.py#L35

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

from typing import Set, Iterable

from pywy.core.executor import Executor
from pywy.core.platform import Platform
from pywy.core.mapping import Mapping
from pywy.graph.graph import WayangGraph
from pywy.graph.types import WGraphOfVec, NodeOperator, NodeVec
from pywy.operators import SinkOperator


class TranslateContext:
    """"""TranslateContext contextual variables a parameters for the translation
    """"""
    pass


class Plugin:
    """""" TODO: enrich this documentation
    A plugin contributes the following components to a :class:`Context`
    - mappings
    - channels
    - configurations
    In turn, it may require several :clas:`Platform`s for its operation.
    """"""

    platforms: Set[Platform]
    mappings: Mapping
    translate_context: TranslateContext

    def __init__(
            self,
            platforms: Set[Platform],
            mappings: Mapping = Mapping(),
            translate_context: TranslateContext = None):
        self.platforms = platforms
        self.mappings = mappings
        self.translate_context = translate_context

    def get_mappings(self) -> Mapping:
        return self.mappings

    def get_executor(self) -> Executor:
        pass

    def __str__(self):
        return ""Platforms: {}, Mappings: {}"".format(str(self.platforms), str(self.mappings))

    def __repr__(self):
        return self.__str__()


class PywyPlan:
    """"""A PywyPlan consists of a set of :py:class:`pywy.operators.base.PywyOperator`

    the operator inside PywyPlan follow a Directed acyclic graph(DAG), and describe
    how the execution needs to be performed

    Attributes
    ----------
    graph : :py:class:`pywy.graph.graph.WayangGraph`
       Graph that describe the DAG, and it provides the iterable properties to
       the PywyPlan
    plugins : :obj:`set` of :py:class:`pywy.core.plugin.Plugin`
        plugins is the set of possible platforms that can be uses to execute
        the PywyPlan
    sinks : :py:class:`typing.Iterable` of :py:class:`pywy.operators.sink.SinkOperator`
        The list of sink operators, this describe the end of the pipeline, and
        they are used to build the `graph`
    """"""
    graph: WayangGraph

    def __init__(self, plugins: Set[Plugin], sinks: Iterable[SinkOperator]):
        """"""basic Constructor of PywyPlan

        this constructor set the plugins and sinks element, and it prepares
        everything for been executed

        Parameters
        ----------
        plugins
            Description of `plugins`.
        sinks
            Description of `sinks`.
        """"""
        self.plugins = plugins
        self.sinks = sinks
        self.set_graph()

    def set_graph(self):
        """""" it builds the :py:class:`pywy.graph.graph.WayangGraph` of the current PywyPlan
        """"""
        self.graph = WGraphOfVec(self.sinks)

    def execute(self):
        """""" Execute the plan with the plugin provided at the moment of creation
        """"""
        plug = next(iter(self.plugins))
        trs: Translator = Translator(plug, self)
        new_plan = trs.translate()
        plug.get_executor().execute(new_plan)


class Translator:
    """"""Translator use the :py:class:`pywy.core.Mapping` to convert the :py:class:`pywy.operators.base.PywyOperator`

    Translator take a plan a produce the executable version of the plan using as tool
    the :py:class:`pywy.core.Mapping` of the :py:class:`pywy.core.core.Plugin` and convert
    the :py:class:`pywy.operators.base.PywyOperator` into an executable version inside
    the :py:class:`pywy.core.Platform`

    Attributes
    ----------
    plugin : :py:class:`pywy.core.core.Plugin`
        plugin use in the translation
    plan : :py:class:`pywy.core.core.PywyPlan`
        Plan to be translated by the translator
    translate_context: :py:class:`pywy.core.core.TranslateContext`
        context used by the translates at runtime in some case is not needed
    """"""

    plugin: Plugin
    plan: PywyPlan
    translate_context: TranslateContext

    def __init__(self, plugin: Plugin, plan: PywyPlan):
        self.plugin = plugin
        self.plan = plan
        self.translate_context = plugin.translate_context

    def translate(self):
        mappings: Mapping = self.plugin.get_mappings()
        graph = WGraphOfVec(self.plan.sinks)

        translate = self.translate_context

        def translate2plugin(current_op: NodeVec, next_op: NodeVec):
            if current_op is None:
                return

            if current_op.current[1] is None:
                current_op.current[1] = mappings.get_instanceof(current_op.current[0], **{'translate_context': translate})

            if next_op is None:
                return
            if next_op.current[1] is None:
                next_op.current[1] = mappings.get_instanceof(next_op.current[0], **{'translate_context': translate})

            # TODO not necesary it it 0
            current_op.current[1].connect(0, next_op.current[1], 0)

        graph.traversal(graph.starting_nodes, translate2plugin)

        node = []
        for elem in graph.starting_nodes:
            node.append(elem.current[1])

        return PywyPlan({self.plugin}, node)

```

0c8da42b1bd9ca098954e746fef503b59fbb2a8c","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/215/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/216,https://api.github.com/repos/apache/incubator-wayang/issues/216,incubator-wayang,1202419454,216,enrich this documentation,github-actions,,,,CLOSED,2022-04-12T21:38:07Z,2023-07-20T15:04:38Z,"enrich this documentation

A plugin contributes the following components to a :class:`Context`

- mappings

- channels

- configurations

In turn, it may require several :clas:`Platform`s for its operation.

https://github.com/apache/incubator-wayang/blob/77a5d3b5854f59b9cad1f9e9921b849ccc5cca58/python/src/pywy/core/core.py#L35

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

from typing import Set, Iterable

from pywy.core.executor import Executor
from pywy.core.platform import Platform
from pywy.core.mapping import Mapping
from pywy.graph.graph import WayangGraph
from pywy.graph.types import WGraphOfVec, NodeOperator, NodeVec
from pywy.operators import SinkOperator


class TranslateContext:
    """"""TranslateContext contextual variables a parameters for the translation
    """"""
    pass


class Plugin:
    """""" TODO: enrich this documentation
    A plugin contributes the following components to a :class:`Context`
    - mappings
    - channels
    - configurations
    In turn, it may require several :clas:`Platform`s for its operation.
    """"""

    platforms: Set[Platform]
    mappings: Mapping
    translate_context: TranslateContext

    def __init__(
            self,
            platforms: Set[Platform],
            mappings: Mapping = Mapping(),
            translate_context: TranslateContext = None):
        self.platforms = platforms
        self.mappings = mappings
        self.translate_context = translate_context

    def get_mappings(self) -> Mapping:
        return self.mappings

    def get_executor(self) -> Executor:
        pass

    def __str__(self):
        return ""Platforms: {}, Mappings: {}"".format(str(self.platforms), str(self.mappings))

    def __repr__(self):
        return self.__str__()


class PywyPlan:
    """"""A PywyPlan consists of a set of :py:class:`pywy.operators.base.PywyOperator`

    the operator inside PywyPlan follow a Directed acyclic graph(DAG), and describe
    how the execution needs to be performed

    Attributes
    ----------
    graph : :py:class:`pywy.graph.graph.WayangGraph`
       Graph that describe the DAG, and it provides the iterable properties to
       the PywyPlan
    plugins : :obj:`set` of :py:class:`pywy.core.plugin.Plugin`
        plugins is the set of possible platforms that can be uses to execute
        the PywyPlan
    sinks : :py:class:`typing.Iterable` of :py:class:`pywy.operators.sink.SinkOperator`
        The list of sink operators, this describe the end of the pipeline, and
        they are used to build the `graph`
    """"""
    graph: WayangGraph

    def __init__(self, plugins: Set[Plugin], sinks: Iterable[SinkOperator]):
        """"""basic Constructor of PywyPlan

        this constructor set the plugins and sinks element, and it prepares
        everything for been executed

        Parameters
        ----------
        plugins
            Description of `plugins`.
        sinks
            Description of `sinks`.
        """"""
        self.plugins = plugins
        self.sinks = sinks
        self.set_graph()

    def set_graph(self):
        """""" it builds the :py:class:`pywy.graph.graph.WayangGraph` of the current PywyPlan
        """"""
        self.graph = WGraphOfVec(self.sinks)

    def execute(self):
        """""" Execute the plan with the plugin provided at the moment of creation
        """"""
        plug = next(iter(self.plugins))
        trs: Translator = Translator(plug, self)
        new_plan = trs.translate()
        plug.get_executor().execute(new_plan)


class Translator:
    """"""Translator use the :py:class:`pywy.core.Mapping` to convert the :py:class:`pywy.operators.base.PywyOperator`

    Translator take a plan a produce the executable version of the plan using as tool
    the :py:class:`pywy.core.Mapping` of the :py:class:`pywy.core.core.Plugin` and convert
    the :py:class:`pywy.operators.base.PywyOperator` into an executable version inside
    the :py:class:`pywy.core.Platform`

    Attributes
    ----------
    plugin : :py:class:`pywy.core.core.Plugin`
        plugin use in the translation
    plan : :py:class:`pywy.core.core.PywyPlan`
        Plan to be translated by the translator
    translate_context: :py:class:`pywy.core.core.TranslateContext`
        context used by the translates at runtime in some case is not needed
    """"""

    plugin: Plugin
    plan: PywyPlan
    translate_context: TranslateContext

    def __init__(self, plugin: Plugin, plan: PywyPlan):
        self.plugin = plugin
        self.plan = plan
        self.translate_context = plugin.translate_context

    def translate(self):
        mappings: Mapping = self.plugin.get_mappings()
        graph = WGraphOfVec(self.plan.sinks)

        translate = self.translate_context

        def translate2plugin(current_op: NodeVec, next_op: NodeVec):
            if current_op is None:
                return

            if current_op.current[1] is None:
                current_op.current[1] = mappings.get_instanceof(current_op.current[0], **{'translate_context': translate})

            if next_op is None:
                return
            if next_op.current[1] is None:
                next_op.current[1] = mappings.get_instanceof(next_op.current[0], **{'translate_context': translate})

            # TODO not necesary it it 0
            current_op.current[1].connect(0, next_op.current[1], 0)

        graph.traversal(graph.starting_nodes, translate2plugin)

        node = []
        for elem in graph.starting_nodes:
            node.append(elem.current[1])

        return PywyPlan({self.plugin}, node)

```

0c8da42b1bd9ca098954e746fef503b59fbb2a8c","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/216/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/217,https://api.github.com/repos/apache/incubator-wayang/issues/217,incubator-wayang,1202419513,217,get this information by a configuration and ideally by the context,github-actions,,,,OPEN,2022-04-12T21:38:11Z,2022-04-12T21:38:12Z,"get this information by a configuration and ideally by the context

https://github.com/apache/incubator-wayang/blob/77a5d3b5854f59b9cad1f9e9921b849ccc5cca58/python/src/pywy/platforms/jvm/execution.py#L35

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

from pywy.core import Executor, ChannelDescriptor
from pywy.core import PywyPlan
from pywy.platforms.jvm.channels import DISPATCHABLE_CHANNEL_DESCRIPTOR
from pywy.platforms.jvm.graph import NodeDispatch, WGraphDispatch
from pywy.platforms.jvm.operator import JVMExecutionOperator
from pywy.platforms.jvm.serializable.wayang_jvm_operator import WayangJVMOperator


class JVMExecutor(Executor):

    def __init__(self):
        super(JVMExecutor, self).__init__()

    def execute(self, plan):
        pywyPlan: PywyPlan = plan
        graph = WGraphDispatch(pywyPlan.sinks)

        # TODO get this information by a configuration and ideally by the context
        descriptor_default: ChannelDescriptor = DISPATCHABLE_CHANNEL_DESCRIPTOR

        def execute(op_current: NodeDispatch, op_next: NodeDispatch):
            if op_current is None:
                return

            jvm_current: JVMExecutionOperator = op_current.current
            if jvm_current.outputs == 0:
                jvm_current.execute(jvm_current.inputChannel, [])
                return

            if op_next is None:
                return

            jvm_next: JVMExecutionOperator = op_next.current
            outputs = jvm_current.get_output_channeldescriptors()
            inputs = jvm_next.get_input_channeldescriptors()

            intersect = outputs.intersection(inputs)
            if len(intersect) == 0:
                raise Exception(
                    ""The operator(A) {} can't connect with (B) {}, ""
                    ""because the output of (A) is {} and the input of (B) is {} "".format(
                        jvm_current,
                        jvm_next,
                        outputs,
                        inputs
                    )
                )

            if len(intersect) > 1:
                if descriptor_default is None:
                    raise Exception(
                        ""The interaction between the operator (A) {} and (B) {}, ""
                        ""can't be decided because are several channel availables {}"".format(
                            jvm_current,
                            jvm_next,
                            intersect
                        )
                    )
                descriptor = descriptor_default
            else:
                descriptor = intersect.pop()

            # TODO validate if is valite for several output
            jvm_current.outputChannel[0] = descriptor.create_instance()

            jvm_current.execute(jvm_current.inputChannel, jvm_current.outputChannel)

            jvm_next.inputChannel = jvm_current.outputChannel

        graph.traversal(graph.starting_nodes, execute)

        magic: JVMExecutionOperator = graph.starting_nodes[0].current

        magic.translate_context.generate_request()



```

8f8ae12d9fabc2f3033024dd4c6de257600be75f","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/217/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/218,https://api.github.com/repos/apache/incubator-wayang/issues/218,incubator-wayang,1202419519,218,get this information by a configuration and ideally by the context,github-actions,,,,CLOSED,2022-04-12T21:38:11Z,2023-07-20T15:04:32Z,"get this information by a configuration and ideally by the context

https://github.com/apache/incubator-wayang/blob/77a5d3b5854f59b9cad1f9e9921b849ccc5cca58/python/src/pywy/platforms/jvm/execution.py#L35

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

from pywy.core import Executor, ChannelDescriptor
from pywy.core import PywyPlan
from pywy.platforms.jvm.channels import DISPATCHABLE_CHANNEL_DESCRIPTOR
from pywy.platforms.jvm.graph import NodeDispatch, WGraphDispatch
from pywy.platforms.jvm.operator import JVMExecutionOperator
from pywy.platforms.jvm.serializable.wayang_jvm_operator import WayangJVMOperator


class JVMExecutor(Executor):

    def __init__(self):
        super(JVMExecutor, self).__init__()

    def execute(self, plan):
        pywyPlan: PywyPlan = plan
        graph = WGraphDispatch(pywyPlan.sinks)

        # TODO get this information by a configuration and ideally by the context
        descriptor_default: ChannelDescriptor = DISPATCHABLE_CHANNEL_DESCRIPTOR

        def execute(op_current: NodeDispatch, op_next: NodeDispatch):
            if op_current is None:
                return

            jvm_current: JVMExecutionOperator = op_current.current
            if jvm_current.outputs == 0:
                jvm_current.execute(jvm_current.inputChannel, [])
                return

            if op_next is None:
                return

            jvm_next: JVMExecutionOperator = op_next.current
            outputs = jvm_current.get_output_channeldescriptors()
            inputs = jvm_next.get_input_channeldescriptors()

            intersect = outputs.intersection(inputs)
            if len(intersect) == 0:
                raise Exception(
                    ""The operator(A) {} can't connect with (B) {}, ""
                    ""because the output of (A) is {} and the input of (B) is {} "".format(
                        jvm_current,
                        jvm_next,
                        outputs,
                        inputs
                    )
                )

            if len(intersect) > 1:
                if descriptor_default is None:
                    raise Exception(
                        ""The interaction between the operator (A) {} and (B) {}, ""
                        ""can't be decided because are several channel availables {}"".format(
                            jvm_current,
                            jvm_next,
                            intersect
                        )
                    )
                descriptor = descriptor_default
            else:
                descriptor = intersect.pop()

            # TODO validate if is valite for several output
            jvm_current.outputChannel[0] = descriptor.create_instance()

            jvm_current.execute(jvm_current.inputChannel, jvm_current.outputChannel)

            jvm_next.inputChannel = jvm_current.outputChannel

        graph.traversal(graph.starting_nodes, execute)

        magic: JVMExecutionOperator = graph.starting_nodes[0].current

        magic.translate_context.generate_request()



```

8f8ae12d9fabc2f3033024dd4c6de257600be75f","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/218/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/219,https://api.github.com/repos/apache/incubator-wayang/issues/219,incubator-wayang,1202419538,219,validate if is valite for several output,github-actions,,,,OPEN,2022-04-12T21:38:13Z,2022-04-12T21:38:14Z,"validate if is valite for several output

https://github.com/apache/incubator-wayang/blob/77a5d3b5854f59b9cad1f9e9921b849ccc5cca58/python/src/pywy/platforms/jvm/execution.py#L80

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

from pywy.core import Executor, ChannelDescriptor
from pywy.core import PywyPlan
from pywy.platforms.jvm.channels import DISPATCHABLE_CHANNEL_DESCRIPTOR
from pywy.platforms.jvm.graph import NodeDispatch, WGraphDispatch
from pywy.platforms.jvm.operator import JVMExecutionOperator
from pywy.platforms.jvm.serializable.wayang_jvm_operator import WayangJVMOperator


class JVMExecutor(Executor):

    def __init__(self):
        super(JVMExecutor, self).__init__()

    def execute(self, plan):
        pywyPlan: PywyPlan = plan
        graph = WGraphDispatch(pywyPlan.sinks)

        # TODO get this information by a configuration and ideally by the context
        descriptor_default: ChannelDescriptor = DISPATCHABLE_CHANNEL_DESCRIPTOR

        def execute(op_current: NodeDispatch, op_next: NodeDispatch):
            if op_current is None:
                return

            jvm_current: JVMExecutionOperator = op_current.current
            if jvm_current.outputs == 0:
                jvm_current.execute(jvm_current.inputChannel, [])
                return

            if op_next is None:
                return

            jvm_next: JVMExecutionOperator = op_next.current
            outputs = jvm_current.get_output_channeldescriptors()
            inputs = jvm_next.get_input_channeldescriptors()

            intersect = outputs.intersection(inputs)
            if len(intersect) == 0:
                raise Exception(
                    ""The operator(A) {} can't connect with (B) {}, ""
                    ""because the output of (A) is {} and the input of (B) is {} "".format(
                        jvm_current,
                        jvm_next,
                        outputs,
                        inputs
                    )
                )

            if len(intersect) > 1:
                if descriptor_default is None:
                    raise Exception(
                        ""The interaction between the operator (A) {} and (B) {}, ""
                        ""can't be decided because are several channel availables {}"".format(
                            jvm_current,
                            jvm_next,
                            intersect
                        )
                    )
                descriptor = descriptor_default
            else:
                descriptor = intersect.pop()

            # TODO validate if is valite for several output
            jvm_current.outputChannel[0] = descriptor.create_instance()

            jvm_current.execute(jvm_current.inputChannel, jvm_current.outputChannel)

            jvm_next.inputChannel = jvm_current.outputChannel

        graph.traversal(graph.starting_nodes, execute)

        magic: JVMExecutionOperator = graph.starting_nodes[0].current

        magic.translate_context.generate_request()



```

a881b024a8724f7b7a1f77afa7a269acaf1fa2a1","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/219/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/220,https://api.github.com/repos/apache/incubator-wayang/issues/220,incubator-wayang,1202419542,220,validate if is valite for several output,github-actions,,,,CLOSED,2022-04-12T21:38:14Z,2023-07-20T15:04:17Z,"validate if is valite for several output

https://github.com/apache/incubator-wayang/blob/77a5d3b5854f59b9cad1f9e9921b849ccc5cca58/python/src/pywy/platforms/jvm/execution.py#L80

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

from pywy.core import Executor, ChannelDescriptor
from pywy.core import PywyPlan
from pywy.platforms.jvm.channels import DISPATCHABLE_CHANNEL_DESCRIPTOR
from pywy.platforms.jvm.graph import NodeDispatch, WGraphDispatch
from pywy.platforms.jvm.operator import JVMExecutionOperator
from pywy.platforms.jvm.serializable.wayang_jvm_operator import WayangJVMOperator


class JVMExecutor(Executor):

    def __init__(self):
        super(JVMExecutor, self).__init__()

    def execute(self, plan):
        pywyPlan: PywyPlan = plan
        graph = WGraphDispatch(pywyPlan.sinks)

        # TODO get this information by a configuration and ideally by the context
        descriptor_default: ChannelDescriptor = DISPATCHABLE_CHANNEL_DESCRIPTOR

        def execute(op_current: NodeDispatch, op_next: NodeDispatch):
            if op_current is None:
                return

            jvm_current: JVMExecutionOperator = op_current.current
            if jvm_current.outputs == 0:
                jvm_current.execute(jvm_current.inputChannel, [])
                return

            if op_next is None:
                return

            jvm_next: JVMExecutionOperator = op_next.current
            outputs = jvm_current.get_output_channeldescriptors()
            inputs = jvm_next.get_input_channeldescriptors()

            intersect = outputs.intersection(inputs)
            if len(intersect) == 0:
                raise Exception(
                    ""The operator(A) {} can't connect with (B) {}, ""
                    ""because the output of (A) is {} and the input of (B) is {} "".format(
                        jvm_current,
                        jvm_next,
                        outputs,
                        inputs
                    )
                )

            if len(intersect) > 1:
                if descriptor_default is None:
                    raise Exception(
                        ""The interaction between the operator (A) {} and (B) {}, ""
                        ""can't be decided because are several channel availables {}"".format(
                            jvm_current,
                            jvm_next,
                            intersect
                        )
                    )
                descriptor = descriptor_default
            else:
                descriptor = intersect.pop()

            # TODO validate if is valite for several output
            jvm_current.outputChannel[0] = descriptor.create_instance()

            jvm_current.execute(jvm_current.inputChannel, jvm_current.outputChannel)

            jvm_next.inputChannel = jvm_current.outputChannel

        graph.traversal(graph.starting_nodes, execute)

        magic: JVMExecutionOperator = graph.starting_nodes[0].current

        magic.translate_context.generate_request()



```

a881b024a8724f7b7a1f77afa7a269acaf1fa2a1","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/220/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/221,https://api.github.com/repos/apache/incubator-wayang/issues/221,incubator-wayang,1202419569,221,check for the case where the index matter,github-actions,,,,OPEN,2022-04-12T21:38:15Z,2022-04-12T21:38:16Z,"check for the case where the index matter

https://github.com/apache/incubator-wayang/blob/77a5d3b5854f59b9cad1f9e9921b849ccc5cca58/python/src/pywy/platforms/jvm/operator/jvm_unary_filter.py#L61

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

from typing import Set, List, Type

from pywy.core.channel import CH_T, ChannelDescriptor
from pywy.operators.unary import FilterOperator
from pywy.platforms.jvm.channels import DISPATCHABLE_CHANNEL_DESCRIPTOR, DispatchableChannel
from pywy.platforms.jvm.operator.jvm_execution_operator import JVMExecutionOperator
from pywy.platforms.commons.channels import (
    CommonsCallableChannel
)
from pywy.platforms.jvm.serializable.wayang_jvm_operator import WayangJVMMappartitionOperator, WayangJVMOperator


class JVMFilterOperator(FilterOperator, JVMExecutionOperator):

    def __init__(self, origin: FilterOperator = None, **kwargs):
        predicate = None if origin is None else origin.predicate
        super().__init__(predicate)
        self.set_context(**kwargs)

    def execute(self, inputs: List[Type[CH_T]], outputs: List[Type[CH_T]]):
        self.validate_channels(inputs, outputs)
        udf = self.predicate
        if isinstance(inputs[0], DispatchableChannel):
            py_in_dispatch_channel: DispatchableChannel = inputs[0]
            py_out_dispatch_channel: DispatchableChannel = outputs[0]

            def func(iterator):
                return filter(udf, iterator)

            py_out_dispatch_channel.accept_callable(
                CommonsCallableChannel.concatenate(
                    func,
                    py_in_dispatch_channel.provide_callable()
                )
            )

            op: WayangJVMOperator = py_in_dispatch_channel.provide_dispatchable()

            if isinstance(op, WayangJVMMappartitionOperator):
                py_out_dispatch_channel.accept_dispatchable(op)
                return

            current: WayangJVMMappartitionOperator = WayangJVMMappartitionOperator(self.name)
            # TODO check for the case where the index matter
            op.connect_to(0, current, 0)
            self.close_operator(op)
            py_out_dispatch_channel.accept_dispatchable(current)

        else:
            raise Exception(""Channel Type does not supported"")

    def get_input_channeldescriptors(self) -> Set[ChannelDescriptor]:
        return {DISPATCHABLE_CHANNEL_DESCRIPTOR}

    def get_output_channeldescriptors(self) -> Set[ChannelDescriptor]:
        return {DISPATCHABLE_CHANNEL_DESCRIPTOR}

```

456c3f1256e226291d2b657267900dc092281993","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/221/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/222,https://api.github.com/repos/apache/incubator-wayang/issues/222,incubator-wayang,1202419573,222,check for the case where the index matter,github-actions,,,,OPEN,2022-04-12T21:38:16Z,2022-04-12T21:38:17Z,"check for the case where the index matter

https://github.com/apache/incubator-wayang/blob/77a5d3b5854f59b9cad1f9e9921b849ccc5cca58/python/src/pywy/platforms/jvm/operator/jvm_unary_filter.py#L61

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

from typing import Set, List, Type

from pywy.core.channel import CH_T, ChannelDescriptor
from pywy.operators.unary import FilterOperator
from pywy.platforms.jvm.channels import DISPATCHABLE_CHANNEL_DESCRIPTOR, DispatchableChannel
from pywy.platforms.jvm.operator.jvm_execution_operator import JVMExecutionOperator
from pywy.platforms.commons.channels import (
    CommonsCallableChannel
)
from pywy.platforms.jvm.serializable.wayang_jvm_operator import WayangJVMMappartitionOperator, WayangJVMOperator


class JVMFilterOperator(FilterOperator, JVMExecutionOperator):

    def __init__(self, origin: FilterOperator = None, **kwargs):
        predicate = None if origin is None else origin.predicate
        super().__init__(predicate)
        self.set_context(**kwargs)

    def execute(self, inputs: List[Type[CH_T]], outputs: List[Type[CH_T]]):
        self.validate_channels(inputs, outputs)
        udf = self.predicate
        if isinstance(inputs[0], DispatchableChannel):
            py_in_dispatch_channel: DispatchableChannel = inputs[0]
            py_out_dispatch_channel: DispatchableChannel = outputs[0]

            def func(iterator):
                return filter(udf, iterator)

            py_out_dispatch_channel.accept_callable(
                CommonsCallableChannel.concatenate(
                    func,
                    py_in_dispatch_channel.provide_callable()
                )
            )

            op: WayangJVMOperator = py_in_dispatch_channel.provide_dispatchable()

            if isinstance(op, WayangJVMMappartitionOperator):
                py_out_dispatch_channel.accept_dispatchable(op)
                return

            current: WayangJVMMappartitionOperator = WayangJVMMappartitionOperator(self.name)
            # TODO check for the case where the index matter
            op.connect_to(0, current, 0)
            self.close_operator(op)
            py_out_dispatch_channel.accept_dispatchable(current)

        else:
            raise Exception(""Channel Type does not supported"")

    def get_input_channeldescriptors(self) -> Set[ChannelDescriptor]:
        return {DISPATCHABLE_CHANNEL_DESCRIPTOR}

    def get_output_channeldescriptors(self) -> Set[ChannelDescriptor]:
        return {DISPATCHABLE_CHANNEL_DESCRIPTOR}

```

456c3f1256e226291d2b657267900dc092281993","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/222/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/225,https://api.github.com/repos/apache/incubator-wayang/issues/225,incubator-wayang,1222760110,225,Operator Distinct One value,berttty,24259784,Bertty Contreras-Rojas,,CLOSED,2022-05-02T11:13:19Z,2022-05-02T13:21:07Z,The distinct operator just shows one value independent of the value that could have,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/225/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/227,https://api.github.com/repos/apache/incubator-wayang/issues/227,incubator-wayang,1222882778,227,Validate FlinkJoinOperator implementation,github-actions,,,,OPEN,2022-05-02T13:21:38Z,2022-05-02T13:21:39Z,"Validate FlinkJoinOperator implementation

it is required to validate the implementation of FlinkJoinOperator

because trigger an exception in the test and looks like is a problem in the

implementation of the implementation in the operator

labels:flink,bug

https://github.com/apache/incubator-wayang/blob/be9c4138fc6971401ce98d83125a753098134766/wayang-platforms/wayang-flink/code/test/java/org/apache/wayang/flink/operators/FlinkJoinOperatorTest.java#L41

```java

import org.apache.wayang.core.types.DataUnitType;
import org.apache.wayang.flink.channels.DataSetChannel;
import org.junit.Assert;
import org.junit.jupiter.api.Test;
import org.junit.jupiter.api.Disabled;

import java.util.Arrays;
import java.util.List;


//problematic
/**
 * Test suite for {@link FlinkJoinOperator}.
 */
public class FlinkJoinOperatorTest extends FlinkOperatorTestBase{

    //TODO: Validate FlinkJoinOperator implementation
    // it is required to validate the implementation of FlinkJoinOperator
    // because trigger an exception in the test and looks like is a problem in the
    // implementation of the implementation in the operator
    // labels:flink,bug
    @Test
    @Disabled(""until validation of implementation of the FlinkJoinOperator"")
    public void testExecution() throws Exception {
        // Prepare test data.
        DataSetChannel.Instance input0 = this.createDataSetChannelInstance(Arrays.asList(

```

596268dc3046c6b005a62d8a5beb8fb91d767535","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/227/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/228,https://api.github.com/repos/apache/incubator-wayang/issues/228,incubator-wayang,1222882823,228,Validate FlinkReduceByOperator implementation,github-actions,,,,OPEN,2022-05-02T13:21:40Z,2022-05-02T13:21:41Z,"Validate FlinkReduceByOperator implementation

it is required to validate the implementation of FlinkReduceByOperator

because trigger an exception in the test and looks like is a problem in the

implementation of the implementation in the operator

labels:flink,bug

https://github.com/apache/incubator-wayang/blob/be9c4138fc6971401ce98d83125a753098134766/wayang-platforms/wayang-flink/code/test/java/org/apache/wayang/flink/operators/FlinkReduceByOperatorTest.java#L43

```java

 * Test suite for {@link FlinkReduceByOperator}.
 */
public class FlinkReduceByOperatorTest extends FlinkOperatorTestBase{

    //TODO: Validate FlinkReduceByOperator implementation
    // it is required to validate the implementation of FlinkReduceByOperator
    // because trigger an exception in the test and looks like is a problem in the
    // implementation of the implementation in the operator
    // labels:flink,bug
    @Test
    @Disabled(""until validation of implementation of the FlinkReduceByOperator"")
    public void testExecution() throws Exception {
        // Prepare test data.
        List<Tuple2<String, Integer>> inputList = Arrays.stream(""aaabbccccdeefff"".split(""""))

```

1741ca057151dc57ac86e764f975145c80f4c56b","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/228/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/229,https://api.github.com/repos/apache/incubator-wayang/issues/229,incubator-wayang,1236963978,229,Wayang JOIN operator can't be placed in Postgres,gstamatakis,13163237,Giorgos Stamatakis,giorgoshstam@gmail.com,CLOSED,2022-05-16T10:44:22Z,2022-05-23T18:28:29Z,"Greetings,

I'm facing the following error when attempting to execute a single JOIN operation in Postgres.
First and foremost I'm assuming that a JOIN operator can be placed in Postgres, if not please feel free to close this issue as off-topic.
More specifically, I'm attempting to load 2 Postgres tables and join on their primary key.
I'm manually restricting the JOIN Operator to run on a `Postgres.platform()` and both Postgres.readTable operations also placed in Postgres. The result is a WayangException that informed me that no plans could be produced (see attached logs). 
The following code chunk is the Wayang code I'm trying to execute.
```
    /* Builder to prepare and execute the plan */
    val planBuilder = new PlanBuilder(wayangContext, jobName = ""ExampleJob"")

    /* Tables/Tuples fetching functions */
    val createTableSourceKeyword = new PostgresTableSource(""keyword"", ""id"", ""keyword"", ""phonetic_code"")
    val createTableSourceMovieKeyword = new PostgresTableSource(""movie_keyword"", ""id"", ""movie_id"", ""keyword_id"")

    // Left relation
    val left = planBuilder.readTable(createTableSourceKeyword).withName(""load_left"").withTargetPlatforms(Postgres.platform())
      .filter(_.getString(1) == ""character-name-in-title"", sqlUdf = ""keyword = 'character-name-in-title'"", selectivity = 1.0).withName(""filter1"").withTargetPlatforms(Postgres.platform())

    // Right relation
    val right = planBuilder.readTable(createTableSourceMovieKeyword).withName(""load_right"").withTargetPlatforms(Postgres.platform())

    // Execute the JOIN and return the results
    left
      
      .join[Record, Int](thisKeyUdf = _.getInt(0), that = right, thatKeyUdf = row => row.getInt(0)).withName(""join1"").withTargetPlatforms(Postgres.platform())

      //Fetch all items but only keep a few to avoid memory issues
      .collect()
```

Logs
[wayang_logs.txt](https://github.com/apache/incubator-wayang/files/8699336/wayang_logs.txt)","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/229/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/229,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5DQ4iK,incubator-wayang,1128499338,229,NA,berttty,24259784,Bertty Contreras-Rojas,,NA,2022-05-17T07:13:08Z,2022-05-17T07:13:08Z,"Hi @gstamatakis, currently Postgres platform does not have the join operator, because Wayang does not have an sql generator to bring UDF to SQL code to send to Postgres. 
","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5DQ4iK/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/229,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5DQ6OE,incubator-wayang,1128506244,229,NA,gstamatakis,13163237,Giorgos Stamatakis,giorgoshstam@gmail.com,NA,2022-05-17T07:20:50Z,2022-05-17T07:20:50Z,"Hello @berttty, thanks for the quick response.
Although unfortunate, it's understandable. Are there any plans in your roadmap for adding JOINs in Postgres? 
Regardless, you can consider this issue closed ","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5DQ6OE/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/239,https://api.github.com/repos/apache/incubator-wayang/issues/239,incubator-wayang,1276181738,239,First we must receive the operator + UDF,github-actions,,,,OPEN,2022-06-19T22:23:22Z,2022-06-19T22:23:23Z,"First we must receive the operator + UDF

print(""base64_message"")

print(base64_message)

print (func)

for x in func([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]): print(x)

https://github.com/apache/incubator-wayang/blob/d859a97d43a8c3c3c964150eaff8f3833e41ea75/python/src/pywy/platforms/jvm/worker.py#L312

```python

#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the ""License""); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

import os
import socket
import struct
import pickle
from itertools import chain

import cloudpickle
import base64
import re
import sys
import time

class SpecialLengths(object):
    END_OF_DATA_SECTION = -1
    PYTHON_EXCEPTION_THROWN = -2
    TIMING_DATA = -3
    END_OF_STREAM = -4
    NULL = -5
    START_ARROW_STREAM = -6


def read_int(stream):
    length = stream.read(4)
    if not length:
        raise EOFError
    res = struct.unpack(""!i"", length)[0]
    return res


class UTF8Deserializer:
    """"""
    Deserializes streams written by String.getBytes.
    """"""

    def __init__(self, use_unicode=True):
        self.use_unicode = use_unicode

    def loads(self, stream):
        length = read_int(stream)
        if length == SpecialLengths.END_OF_DATA_SECTION:
            raise EOFError
        elif length == SpecialLengths.NULL:
            return None
        s = stream.read(length)
        return s.decode(""utf-8"") if self.use_unicode else s

    def load_stream(self, stream):
        try:
            while True:
                yield self.loads(stream)
        except struct.error:
            return
        except EOFError:
            return

    def __repr__(self):
        return ""UTF8Deserializer(%s)"" % self.use_unicode


def write_int(p, outfile):
    outfile.write(struct.pack(""!i"", p))


def write_with_length(obj, stream):
    serialized = obj.encode('utf-8')
    if serialized is None:
        raise ValueError(""serialized value should not be None"")
    if len(serialized) > (1 << 31):
        raise ValueError(""can not serialize object larger than 2G"")
    write_int(len(serialized), stream)
    stream.write(serialized)


class Serializer:
    def dump_stream(self, iterator, stream):
        """"""
        Serialize an iterator of objects to the output stream.
        """"""
        raise NotImplementedError

    def load_stream(self, stream):
        """"""
        Return an iterator of deserialized objects from the input stream.
        """"""
        raise NotImplementedError

    def dumps(self, obj):
        """"""
        Serialize an object into a byte array.
        When batching is used, this will be called with an array of objects.
        """"""
        raise NotImplementedError

    def _load_stream_without_unbatching(self, stream):
        """"""
        Return an iterator of deserialized batches (iterable) of objects from the input stream.
        If the serializer does not operate on batches the default implementation returns an
        iterator of single element lists.
        """"""
        return map(lambda x: [x], self.load_stream(stream))

    # Note: our notion of ""equality"" is that output generated by
    # equal serializers can be deserialized using the same serializer.

    # This default implementation handles the simple cases;
    # subclasses should override __eq__ as appropriate.

    def __eq__(self, other):
        return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

    def __ne__(self, other):
        return not self.__eq__(other)

    def __repr__(self):
        return ""%s()"" % self.__class__.__name__

    def __hash__(self):
        return hash(str(self))

class FramedSerializer(Serializer):

    """"""
    Serializer that writes objects as a stream of (length, data) pairs,
    where `length` is a 32-bit integer and data is `length` bytes.
    """"""

    def dump_stream(self, iterator, stream):
        for obj in iterator:
            self._write_with_length(obj, stream)

    def load_stream(self, stream):
        while True:
            try:
                yield self._read_with_length(stream)
            except EOFError:
                return

    def _write_with_length(self, obj, stream):
        serialized = self.dumps(obj)
        if serialized is None:
            raise ValueError(""serialized value should not be None"")
        if len(serialized) > (1 << 31):
            raise ValueError(""can not serialize object larger than 2G"")
        write_int(len(serialized), stream)
        stream.write(serialized)

    def _read_with_length(self, stream):
        length = read_int(stream)
        if length == SpecialLengths.END_OF_DATA_SECTION:
            raise EOFError
        elif length == SpecialLengths.NULL:
            return None
        obj = stream.read(length)
        if len(obj) < length:
            raise EOFError
        return self.loads(obj)

    def dumps(self, obj):
        """"""
        Serialize an object into a byte array.
        When batching is used, this will be called with an array of objects.
        """"""
        raise NotImplementedError

    def loads(self, obj):
        """"""
        Deserialize an object from a byte array.
        """"""
        raise NotImplementedError


class BatchedSerializer(Serializer):

    """"""
    Serializes a stream of objects in batches by calling its wrapped
    Serializer with streams of objects.
    """"""

    UNLIMITED_BATCH_SIZE = -1
    UNKNOWN_BATCH_SIZE = 0

    def __init__(self, serializer, batchSize=UNLIMITED_BATCH_SIZE):
        self.serializer = serializer
        self.batchSize = batchSize

    def _batched(self, iterator):
        if self.batchSize == self.UNLIMITED_BATCH_SIZE:
            print(""hahahhaha"")
            yield list(iterator)
        elif hasattr(iterator, ""__len__"") and hasattr(iterator, ""__getslice__""):
            n = len(iterator)
            for i in range(0, n, self.batchSize):
                toc = time.perf_counter()
                print(f""batched toc1={toc:0.4f}"")
                yield iterator[i : i + self.batchSize]
        else:
            items = []
            count = 0
            for item in iterator:
                items.append(item)
                count += 1
                if count == self.batchSize:
                    yield items
                    items = []
                    count = 0
            if items:
                yield items

    def dump_stream(self, iterator, stream):
        self.serializer.dump_stream(self._batched(iterator), stream)

    def load_stream(self, stream):
        return chain.from_iterable(self._load_stream_without_unbatching(stream))

    def _load_stream_without_unbatching(self, stream):
        return self.serializer.load_stream(stream)

    def __repr__(self):
        return ""BatchedSerializer(%s, %d)"" % (str(self.serializer), self.batchSize)


class PickleSerializer(FramedSerializer):

    """"""
    Serializes objects using Python's pickle serializer:

        http://docs.python.org/2/library/pickle.html

    This serializer supports nearly any Python object, but may
    not be as fast as more specialized serializers.
    """"""

    def dumps(self, obj):
        return pickle.dumps(obj, pickle_protocol)

    def loads(self, obj, encoding=""bytes""):
        return pickle.loads(obj, encoding=encoding)

pickle_protocol = pickle.HIGHEST_PROTOCOL
class CloudPickleSerializer(FramedSerializer):
    def dumps(self, obj):
        try:
            return cloudpickle.dumps(obj, pickle_protocol)
        except pickle.PickleError:
            raise
        except Exception as e:
            emsg = str(e)
            if ""'i' format requires"" in emsg:
                msg = ""Object too large to serialize: %s"" % emsg
            else:
                msg = ""Could not serialize object: %s: %s"" % (e.__class__.__name__, emsg)
#            print_exec(sys.stderr)
            raise pickle.PicklingError(msg)

    def loads(self, obj, encoding=""bytes""):
        return cloudpickle.loads(obj, encoding=encoding)

#if sys.version_info < (3, 8):
CPickleSerializer = PickleSerializer
#else:
#    CPickleSerializer = CloudPickleSerializer

def dump_stream(iterator, stream):

    for obj in iterator:
        if type(obj) is str:
            print(""here?2"")
            write_with_length(obj, stream)
        ## elif type(obj) is list:
        ##    write_with_length(obj, stream)
    print(""Termine"")
    write_int(SpecialLengths.END_OF_DATA_SECTION, stream)
    print(""Escribi Fin"")


def process(infile, outfile):
    """"""udf64 = os.environ[""UDF""]
    print(""udf64"")
    print(udf64)
    #serialized_udf = binascii.a2b_base64(udf64)
    #serialized_udf = base64.b64decode(udf64)
    serialized_udf = bytearray(udf64, encoding='utf-16')
    # NOT VALID TO BE UTF8  serialized_udf = bytes(udf64, 'UTF-8')
    print(""serialized_udf"")
    print(serialized_udf)
    # input to be ast.literal_eval(serialized_udf)
    func = pickle.loads(serialized_udf, encoding=""bytes"")
    print (""func"")
    print (func)
    print(func([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]))
    # func([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])""""""



    # TODO First we must receive the operator + UDF
    """"""udf = lambda elem: elem.lower()

    def func(it):
        return sorted(it, key=udf)""""""
    udf_length = read_int(infile)
    print(""udf_length"")
    print(udf_length)
    serialized_udf = infile.read(udf_length)
    print(""serialized_udf"")
    print(serialized_udf)
    #base64_message = base64.b64decode(serialized_udf + ""==="")
    #print(""base64_message"")
    #print(base64_message)
    func = pickle.loads(serialized_udf)
    #func = ori.lala(serialized_udf)
    #print (func)
    #for x in func([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]): print(x)


    """"""print(""example"")
    for x in func(""2344|234|efrf|$#|ffrf""): print(x)""""""
    # TODO Here we are temporarily assuming that the user is exclusively sending UTF8. User has several types
    iterator = UTF8Deserializer().load_stream(infile)
    # out_iter = sorted(iterator, key=lambda elem: elem.lower())
    # out_iter = batched(func(iterator))
    ser = BatchedSerializer(CPickleSerializer(), 100)
    ser.dump_stream(func(iterator), outfile)
    #dump_stream(iterator=out_iter, stream=outfile)


def local_connect(port):
    sock = None
    errors = []
    # Support for both IPv4 and IPv6.
    # On most of IPv6-ready systems, IPv6 will take precedence.
    for res in socket.getaddrinfo(""127.0.0.1"", port, socket.AF_UNSPEC, socket.SOCK_STREAM):
        af, socktype, proto, _, sa = res
        try:
            sock = socket.socket(af, socktype, proto)
            # sock.settimeout(int(os.environ.get(""SPARK_AUTH_SOCKET_TIMEOUT"", 15)))
            sock.settimeout(30)
            sock.connect(sa)
            # sockfile = sock.makefile(""rwb"", int(os.environ.get(""SPARK_BUFFER_SIZE"", 65536)))
            sockfile = sock.makefile(""rwb"", 65536)
            # _do_server_auth(sockfile, auth_secret)
            return (sockfile, sock)
        except socket.error as e:
            emsg = str(e)
            errors.append(""tried to connect to %s, but an error occurred: %s"" % (sa, emsg))
            sock.close()
            sock = None
    raise Exception(""could not open socket: %s"" % errors)


if __name__ == '__main__':
    print(""Python version"")
    print (sys.version)
    java_port = int(os.environ[""PYTHON_WORKER_FACTORY_PORT""])
    sock_file, sock = local_connect(java_port)
    process(sock_file, sock_file)
    sock_file.flush()
    exit()

```

0813a0a3b2b354371afdb83209486c15916b7eca","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/239/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/240,https://api.github.com/repos/apache/incubator-wayang/issues/240,incubator-wayang,1276181746,240,Here we are temporarily assuming that the user is exclusively sending UTF8. User...,github-actions,,,,OPEN,2022-06-19T22:23:25Z,2022-06-19T22:23:26Z,"Here we are temporarily assuming that the user is exclusively sending UTF8. User has several types

out_iter = batched(func(iterator))

On most of IPv6-ready systems, IPv6 will take precedence.

https://github.com/apache/incubator-wayang/blob/d859a97d43a8c3c3c964150eaff8f3833e41ea75/python/src/pywy/platforms/jvm/worker.py#L334

```python

#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the ""License""); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

import os
import socket
import struct
import pickle
from itertools import chain

import cloudpickle
import base64
import re
import sys
import time

class SpecialLengths(object):
    END_OF_DATA_SECTION = -1
    PYTHON_EXCEPTION_THROWN = -2
    TIMING_DATA = -3
    END_OF_STREAM = -4
    NULL = -5
    START_ARROW_STREAM = -6


def read_int(stream):
    length = stream.read(4)
    if not length:
        raise EOFError
    res = struct.unpack(""!i"", length)[0]
    return res


class UTF8Deserializer:
    """"""
    Deserializes streams written by String.getBytes.
    """"""

    def __init__(self, use_unicode=True):
        self.use_unicode = use_unicode

    def loads(self, stream):
        length = read_int(stream)
        if length == SpecialLengths.END_OF_DATA_SECTION:
            raise EOFError
        elif length == SpecialLengths.NULL:
            return None
        s = stream.read(length)
        return s.decode(""utf-8"") if self.use_unicode else s

    def load_stream(self, stream):
        try:
            while True:
                yield self.loads(stream)
        except struct.error:
            return
        except EOFError:
            return

    def __repr__(self):
        return ""UTF8Deserializer(%s)"" % self.use_unicode


def write_int(p, outfile):
    outfile.write(struct.pack(""!i"", p))


def write_with_length(obj, stream):
    serialized = obj.encode('utf-8')
    if serialized is None:
        raise ValueError(""serialized value should not be None"")
    if len(serialized) > (1 << 31):
        raise ValueError(""can not serialize object larger than 2G"")
    write_int(len(serialized), stream)
    stream.write(serialized)


class Serializer:
    def dump_stream(self, iterator, stream):
        """"""
        Serialize an iterator of objects to the output stream.
        """"""
        raise NotImplementedError

    def load_stream(self, stream):
        """"""
        Return an iterator of deserialized objects from the input stream.
        """"""
        raise NotImplementedError

    def dumps(self, obj):
        """"""
        Serialize an object into a byte array.
        When batching is used, this will be called with an array of objects.
        """"""
        raise NotImplementedError

    def _load_stream_without_unbatching(self, stream):
        """"""
        Return an iterator of deserialized batches (iterable) of objects from the input stream.
        If the serializer does not operate on batches the default implementation returns an
        iterator of single element lists.
        """"""
        return map(lambda x: [x], self.load_stream(stream))

    # Note: our notion of ""equality"" is that output generated by
    # equal serializers can be deserialized using the same serializer.

    # This default implementation handles the simple cases;
    # subclasses should override __eq__ as appropriate.

    def __eq__(self, other):
        return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

    def __ne__(self, other):
        return not self.__eq__(other)

    def __repr__(self):
        return ""%s()"" % self.__class__.__name__

    def __hash__(self):
        return hash(str(self))

class FramedSerializer(Serializer):

    """"""
    Serializer that writes objects as a stream of (length, data) pairs,
    where `length` is a 32-bit integer and data is `length` bytes.
    """"""

    def dump_stream(self, iterator, stream):
        for obj in iterator:
            self._write_with_length(obj, stream)

    def load_stream(self, stream):
        while True:
            try:
                yield self._read_with_length(stream)
            except EOFError:
                return

    def _write_with_length(self, obj, stream):
        serialized = self.dumps(obj)
        if serialized is None:
            raise ValueError(""serialized value should not be None"")
        if len(serialized) > (1 << 31):
            raise ValueError(""can not serialize object larger than 2G"")
        write_int(len(serialized), stream)
        stream.write(serialized)

    def _read_with_length(self, stream):
        length = read_int(stream)
        if length == SpecialLengths.END_OF_DATA_SECTION:
            raise EOFError
        elif length == SpecialLengths.NULL:
            return None
        obj = stream.read(length)
        if len(obj) < length:
            raise EOFError
        return self.loads(obj)

    def dumps(self, obj):
        """"""
        Serialize an object into a byte array.
        When batching is used, this will be called with an array of objects.
        """"""
        raise NotImplementedError

    def loads(self, obj):
        """"""
        Deserialize an object from a byte array.
        """"""
        raise NotImplementedError


class BatchedSerializer(Serializer):

    """"""
    Serializes a stream of objects in batches by calling its wrapped
    Serializer with streams of objects.
    """"""

    UNLIMITED_BATCH_SIZE = -1
    UNKNOWN_BATCH_SIZE = 0

    def __init__(self, serializer, batchSize=UNLIMITED_BATCH_SIZE):
        self.serializer = serializer
        self.batchSize = batchSize

    def _batched(self, iterator):
        if self.batchSize == self.UNLIMITED_BATCH_SIZE:
            print(""hahahhaha"")
            yield list(iterator)
        elif hasattr(iterator, ""__len__"") and hasattr(iterator, ""__getslice__""):
            n = len(iterator)
            for i in range(0, n, self.batchSize):
                toc = time.perf_counter()
                print(f""batched toc1={toc:0.4f}"")
                yield iterator[i : i + self.batchSize]
        else:
            items = []
            count = 0
            for item in iterator:
                items.append(item)
                count += 1
                if count == self.batchSize:
                    yield items
                    items = []
                    count = 0
            if items:
                yield items

    def dump_stream(self, iterator, stream):
        self.serializer.dump_stream(self._batched(iterator), stream)

    def load_stream(self, stream):
        return chain.from_iterable(self._load_stream_without_unbatching(stream))

    def _load_stream_without_unbatching(self, stream):
        return self.serializer.load_stream(stream)

    def __repr__(self):
        return ""BatchedSerializer(%s, %d)"" % (str(self.serializer), self.batchSize)


class PickleSerializer(FramedSerializer):

    """"""
    Serializes objects using Python's pickle serializer:

        http://docs.python.org/2/library/pickle.html

    This serializer supports nearly any Python object, but may
    not be as fast as more specialized serializers.
    """"""

    def dumps(self, obj):
        return pickle.dumps(obj, pickle_protocol)

    def loads(self, obj, encoding=""bytes""):
        return pickle.loads(obj, encoding=encoding)

pickle_protocol = pickle.HIGHEST_PROTOCOL
class CloudPickleSerializer(FramedSerializer):
    def dumps(self, obj):
        try:
            return cloudpickle.dumps(obj, pickle_protocol)
        except pickle.PickleError:
            raise
        except Exception as e:
            emsg = str(e)
            if ""'i' format requires"" in emsg:
                msg = ""Object too large to serialize: %s"" % emsg
            else:
                msg = ""Could not serialize object: %s: %s"" % (e.__class__.__name__, emsg)
#            print_exec(sys.stderr)
            raise pickle.PicklingError(msg)

    def loads(self, obj, encoding=""bytes""):
        return cloudpickle.loads(obj, encoding=encoding)

#if sys.version_info < (3, 8):
CPickleSerializer = PickleSerializer
#else:
#    CPickleSerializer = CloudPickleSerializer

def dump_stream(iterator, stream):

    for obj in iterator:
        if type(obj) is str:
            print(""here?2"")
            write_with_length(obj, stream)
        ## elif type(obj) is list:
        ##    write_with_length(obj, stream)
    print(""Termine"")
    write_int(SpecialLengths.END_OF_DATA_SECTION, stream)
    print(""Escribi Fin"")


def process(infile, outfile):
    """"""udf64 = os.environ[""UDF""]
    print(""udf64"")
    print(udf64)
    #serialized_udf = binascii.a2b_base64(udf64)
    #serialized_udf = base64.b64decode(udf64)
    serialized_udf = bytearray(udf64, encoding='utf-16')
    # NOT VALID TO BE UTF8  serialized_udf = bytes(udf64, 'UTF-8')
    print(""serialized_udf"")
    print(serialized_udf)
    # input to be ast.literal_eval(serialized_udf)
    func = pickle.loads(serialized_udf, encoding=""bytes"")
    print (""func"")
    print (func)
    print(func([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]))
    # func([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])""""""



    # TODO First we must receive the operator + UDF
    """"""udf = lambda elem: elem.lower()

    def func(it):
        return sorted(it, key=udf)""""""
    udf_length = read_int(infile)
    print(""udf_length"")
    print(udf_length)
    serialized_udf = infile.read(udf_length)
    print(""serialized_udf"")
    print(serialized_udf)
    #base64_message = base64.b64decode(serialized_udf + ""==="")
    #print(""base64_message"")
    #print(base64_message)
    func = pickle.loads(serialized_udf)
    #func = ori.lala(serialized_udf)
    #print (func)
    #for x in func([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]): print(x)


    """"""print(""example"")
    for x in func(""2344|234|efrf|$#|ffrf""): print(x)""""""
    # TODO Here we are temporarily assuming that the user is exclusively sending UTF8. User has several types
    iterator = UTF8Deserializer().load_stream(infile)
    # out_iter = sorted(iterator, key=lambda elem: elem.lower())
    # out_iter = batched(func(iterator))
    ser = BatchedSerializer(CPickleSerializer(), 100)
    ser.dump_stream(func(iterator), outfile)
    #dump_stream(iterator=out_iter, stream=outfile)


def local_connect(port):
    sock = None
    errors = []
    # Support for both IPv4 and IPv6.
    # On most of IPv6-ready systems, IPv6 will take precedence.
    for res in socket.getaddrinfo(""127.0.0.1"", port, socket.AF_UNSPEC, socket.SOCK_STREAM):
        af, socktype, proto, _, sa = res
        try:
            sock = socket.socket(af, socktype, proto)
            # sock.settimeout(int(os.environ.get(""SPARK_AUTH_SOCKET_TIMEOUT"", 15)))
            sock.settimeout(30)
            sock.connect(sa)
            # sockfile = sock.makefile(""rwb"", int(os.environ.get(""SPARK_BUFFER_SIZE"", 65536)))
            sockfile = sock.makefile(""rwb"", 65536)
            # _do_server_auth(sockfile, auth_secret)
            return (sockfile, sock)
        except socket.error as e:
            emsg = str(e)
            errors.append(""tried to connect to %s, but an error occurred: %s"" % (sa, emsg))
            sock.close()
            sock = None
    raise Exception(""could not open socket: %s"" % errors)


if __name__ == '__main__':
    print(""Python version"")
    print (sys.version)
    java_port = int(os.environ[""PYTHON_WORKER_FACTORY_PORT""])
    sock_file, sock = local_connect(java_port)
    process(sock_file, sock_file)
    sock_file.flush()
    exit()

```

a7989c6c2bf9072b3fe883701292f21a021f90c7","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/240/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/241,https://api.github.com/repos/apache/incubator-wayang/issues/241,incubator-wayang,1276181760,241,add to a config file,github-actions,,,,OPEN,2022-06-19T22:23:27Z,2022-06-19T22:23:28Z,"add to a config file

https://github.com/apache/incubator-wayang/blob/d859a97d43a8c3c3c964150eaff8f3833e41ea75/wayang-api/wayang-api-python/src/main/java/org/apache/wayang/api/python/executor/ProcessFeeder.java#L41

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.python.executor;

import org.apache.wayang.api.python.function.PythonCode;
import org.apache.wayang.api.python.function.PythonUDF;
import org.apache.wayang.core.api.exception.WayangException;

import java.io.BufferedOutputStream;
import java.io.DataOutputStream;
import java.io.IOException;
import java.net.Socket;
import java.net.SocketException;
import java.nio.charset.StandardCharsets;
import java.util.Iterator;
import java.util.Map;

public class ProcessFeeder<Input, Output> {

    private Socket socket;
    private PythonUDF<Input, Output> udf;
    private PythonCode serializedUDF;
    private Iterable<Input> input;

    //TODO add to a config file
    int END_OF_DATA_SECTION = -1;
    int NULL = -5;

    public ProcessFeeder(
            Socket socket,
            PythonUDF<Input, Output> udf,
            PythonCode serializedUDF,
            Iterable<Input> input){

        if(input == null) throw new WayangException(""Nothing to process with Python API"");

        this.socket = socket;
        this.udf = udf;
        this.serializedUDF = serializedUDF;
        this.input = input;

    }

    public void send(){

        try{
            //TODO use config buffer size
            int BUFFER_SIZE = 8 * 1024;

            BufferedOutputStream stream = new BufferedOutputStream(socket.getOutputStream(), BUFFER_SIZE);
            DataOutputStream dataOut = new DataOutputStream(stream);

            writeUDF(serializedUDF, dataOut);
            this.writeIteratorToStream(input.iterator(), dataOut);
            dataOut.writeInt(END_OF_DATA_SECTION);
            dataOut.flush();

        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public void writeUDF(PythonCode serializedUDF, DataOutputStream dataOut){

        //write(serializedUDF.toByteArray(), dataOut);
        writeBytes(serializedUDF.toByteArray(), dataOut);
        System.out.println(""UDF written"");

    }

    public void writeIteratorToStream(Iterator<Input> iter, DataOutputStream dataOut)
        throws IOException {

        System.out.println(""iterator being send"");
        int buffer = 0;
        for (Iterator<Input> it = iter; it.hasNext(); ) {
            Input elem = it.next();
            //System.out.println(elem.toString());
            write(elem, dataOut);
        }
    }

    /*TODO Missing case PortableDataStream */
    public void write(Object obj, DataOutputStream dataOut){
        try {

            if(obj == null)
                dataOut.writeInt(this.NULL);

            /**
             * Byte Array cases
             */
            else if (obj instanceof Byte[] || obj instanceof byte[]) {
                System.out.println(""Writing Bytes"");
                writeBytes(obj, dataOut);
            }
            /**
             * String case
             * */
            else if (obj instanceof String)
                writeUTF((String) obj, dataOut);

            /**
             * Key, Value case
             * */
            else if (obj instanceof Map.Entry)
                writeKeyValue((Map.Entry) obj, dataOut);

            else{
                throw new WayangException(""Unexpected element type "" + obj.getClass());
            }


        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public void writeBytes(Object obj, DataOutputStream dataOut){

        try{

            if (obj instanceof Byte[]) {

                int length = ((Byte[]) obj).length;

                byte[] bytes = new byte[length];
                int j=0;

                // Unboxing Byte values. (Byte[] to byte[])
                for(Byte b: ((Byte[]) obj))
                    bytes[j++] = b.byteValue();

                dataOut.writeInt(length);
                dataOut.write(bytes);

            } else if (obj instanceof byte[]) {

                dataOut.writeInt(((byte[]) obj).length);
                dataOut.write(((byte[]) obj));
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public void writeUTF(String str, DataOutputStream dataOut){

        byte[] bytes = str.getBytes(StandardCharsets.UTF_8);

        try {

            dataOut.writeInt(bytes.length);
            dataOut.write(bytes);
        } catch (SocketException e){

        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public void writeKeyValue(Map.Entry obj, DataOutputStream dataOut){

        write(obj.getKey(), dataOut);
        write(obj.getValue(), dataOut);
    }

}

```

cac3777d06d10f33de59ddd1d466c1443654a845","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/241/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/242,https://api.github.com/repos/apache/incubator-wayang/issues/242,incubator-wayang,1276181771,242,use config buffer size,github-actions,,,,OPEN,2022-06-19T22:23:29Z,2022-06-19T22:23:30Z,"use config buffer size

https://github.com/apache/incubator-wayang/blob/d859a97d43a8c3c3c964150eaff8f3833e41ea75/wayang-api/wayang-api-python/src/main/java/org/apache/wayang/api/python/executor/ProcessFeeder.java#L63

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.python.executor;

import org.apache.wayang.api.python.function.PythonCode;
import org.apache.wayang.api.python.function.PythonUDF;
import org.apache.wayang.core.api.exception.WayangException;

import java.io.BufferedOutputStream;
import java.io.DataOutputStream;
import java.io.IOException;
import java.net.Socket;
import java.net.SocketException;
import java.nio.charset.StandardCharsets;
import java.util.Iterator;
import java.util.Map;

public class ProcessFeeder<Input, Output> {

    private Socket socket;
    private PythonUDF<Input, Output> udf;
    private PythonCode serializedUDF;
    private Iterable<Input> input;

    //TODO add to a config file
    int END_OF_DATA_SECTION = -1;
    int NULL = -5;

    public ProcessFeeder(
            Socket socket,
            PythonUDF<Input, Output> udf,
            PythonCode serializedUDF,
            Iterable<Input> input){

        if(input == null) throw new WayangException(""Nothing to process with Python API"");

        this.socket = socket;
        this.udf = udf;
        this.serializedUDF = serializedUDF;
        this.input = input;

    }

    public void send(){

        try{
            //TODO use config buffer size
            int BUFFER_SIZE = 8 * 1024;

            BufferedOutputStream stream = new BufferedOutputStream(socket.getOutputStream(), BUFFER_SIZE);
            DataOutputStream dataOut = new DataOutputStream(stream);

            writeUDF(serializedUDF, dataOut);
            this.writeIteratorToStream(input.iterator(), dataOut);
            dataOut.writeInt(END_OF_DATA_SECTION);
            dataOut.flush();

        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public void writeUDF(PythonCode serializedUDF, DataOutputStream dataOut){

        //write(serializedUDF.toByteArray(), dataOut);
        writeBytes(serializedUDF.toByteArray(), dataOut);
        System.out.println(""UDF written"");

    }

    public void writeIteratorToStream(Iterator<Input> iter, DataOutputStream dataOut)
        throws IOException {

        System.out.println(""iterator being send"");
        int buffer = 0;
        for (Iterator<Input> it = iter; it.hasNext(); ) {
            Input elem = it.next();
            //System.out.println(elem.toString());
            write(elem, dataOut);
        }
    }

    /*TODO Missing case PortableDataStream */
    public void write(Object obj, DataOutputStream dataOut){
        try {

            if(obj == null)
                dataOut.writeInt(this.NULL);

            /**
             * Byte Array cases
             */
            else if (obj instanceof Byte[] || obj instanceof byte[]) {
                System.out.println(""Writing Bytes"");
                writeBytes(obj, dataOut);
            }
            /**
             * String case
             * */
            else if (obj instanceof String)
                writeUTF((String) obj, dataOut);

            /**
             * Key, Value case
             * */
            else if (obj instanceof Map.Entry)
                writeKeyValue((Map.Entry) obj, dataOut);

            else{
                throw new WayangException(""Unexpected element type "" + obj.getClass());
            }


        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public void writeBytes(Object obj, DataOutputStream dataOut){

        try{

            if (obj instanceof Byte[]) {

                int length = ((Byte[]) obj).length;

                byte[] bytes = new byte[length];
                int j=0;

                // Unboxing Byte values. (Byte[] to byte[])
                for(Byte b: ((Byte[]) obj))
                    bytes[j++] = b.byteValue();

                dataOut.writeInt(length);
                dataOut.write(bytes);

            } else if (obj instanceof byte[]) {

                dataOut.writeInt(((byte[]) obj).length);
                dataOut.write(((byte[]) obj));
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public void writeUTF(String str, DataOutputStream dataOut){

        byte[] bytes = str.getBytes(StandardCharsets.UTF_8);

        try {

            dataOut.writeInt(bytes.length);
            dataOut.write(bytes);
        } catch (SocketException e){

        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public void writeKeyValue(Map.Entry obj, DataOutputStream dataOut){

        write(obj.getKey(), dataOut);
        write(obj.getValue(), dataOut);
    }

}

```

84ea6d0fccdb4ad32b164d5ac8df30be52535b1b","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/242/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/243,https://api.github.com/repos/apache/incubator-wayang/issues/243,incubator-wayang,1276181781,243,Missing case PortableDataStream,github-actions,,,,OPEN,2022-06-19T22:23:31Z,2022-06-19T22:23:32Z,"Missing case PortableDataStream

https://github.com/apache/incubator-wayang/blob/d859a97d43a8c3c3c964150eaff8f3833e41ea75/wayang-api/wayang-api-python/src/main/java/org/apache/wayang/api/python/executor/ProcessFeeder.java#L99

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.python.executor;

import org.apache.wayang.api.python.function.PythonCode;
import org.apache.wayang.api.python.function.PythonUDF;
import org.apache.wayang.core.api.exception.WayangException;

import java.io.BufferedOutputStream;
import java.io.DataOutputStream;
import java.io.IOException;
import java.net.Socket;
import java.net.SocketException;
import java.nio.charset.StandardCharsets;
import java.util.Iterator;
import java.util.Map;

public class ProcessFeeder<Input, Output> {

    private Socket socket;
    private PythonUDF<Input, Output> udf;
    private PythonCode serializedUDF;
    private Iterable<Input> input;

    //TODO add to a config file
    int END_OF_DATA_SECTION = -1;
    int NULL = -5;

    public ProcessFeeder(
            Socket socket,
            PythonUDF<Input, Output> udf,
            PythonCode serializedUDF,
            Iterable<Input> input){

        if(input == null) throw new WayangException(""Nothing to process with Python API"");

        this.socket = socket;
        this.udf = udf;
        this.serializedUDF = serializedUDF;
        this.input = input;

    }

    public void send(){

        try{
            //TODO use config buffer size
            int BUFFER_SIZE = 8 * 1024;

            BufferedOutputStream stream = new BufferedOutputStream(socket.getOutputStream(), BUFFER_SIZE);
            DataOutputStream dataOut = new DataOutputStream(stream);

            writeUDF(serializedUDF, dataOut);
            this.writeIteratorToStream(input.iterator(), dataOut);
            dataOut.writeInt(END_OF_DATA_SECTION);
            dataOut.flush();

        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public void writeUDF(PythonCode serializedUDF, DataOutputStream dataOut){

        //write(serializedUDF.toByteArray(), dataOut);
        writeBytes(serializedUDF.toByteArray(), dataOut);
        System.out.println(""UDF written"");

    }

    public void writeIteratorToStream(Iterator<Input> iter, DataOutputStream dataOut)
        throws IOException {

        System.out.println(""iterator being send"");
        int buffer = 0;
        for (Iterator<Input> it = iter; it.hasNext(); ) {
            Input elem = it.next();
            //System.out.println(elem.toString());
            write(elem, dataOut);
        }
    }

    /*TODO Missing case PortableDataStream */
    public void write(Object obj, DataOutputStream dataOut){
        try {

            if(obj == null)
                dataOut.writeInt(this.NULL);

            /**
             * Byte Array cases
             */
            else if (obj instanceof Byte[] || obj instanceof byte[]) {
                System.out.println(""Writing Bytes"");
                writeBytes(obj, dataOut);
            }
            /**
             * String case
             * */
            else if (obj instanceof String)
                writeUTF((String) obj, dataOut);

            /**
             * Key, Value case
             * */
            else if (obj instanceof Map.Entry)
                writeKeyValue((Map.Entry) obj, dataOut);

            else{
                throw new WayangException(""Unexpected element type "" + obj.getClass());
            }


        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public void writeBytes(Object obj, DataOutputStream dataOut){

        try{

            if (obj instanceof Byte[]) {

                int length = ((Byte[]) obj).length;

                byte[] bytes = new byte[length];
                int j=0;

                // Unboxing Byte values. (Byte[] to byte[])
                for(Byte b: ((Byte[]) obj))
                    bytes[j++] = b.byteValue();

                dataOut.writeInt(length);
                dataOut.write(bytes);

            } else if (obj instanceof byte[]) {

                dataOut.writeInt(((byte[]) obj).length);
                dataOut.write(((byte[]) obj));
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public void writeUTF(String str, DataOutputStream dataOut){

        byte[] bytes = str.getBytes(StandardCharsets.UTF_8);

        try {

            dataOut.writeInt(bytes.length);
            dataOut.write(bytes);
        } catch (SocketException e){

        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public void writeKeyValue(Map.Entry obj, DataOutputStream dataOut){

        write(obj.getKey(), dataOut);
        write(obj.getValue(), dataOut);
    }

}

```

f13251a8123b363fcb4482f4482051a23155f93b","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/243/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/244,https://api.github.com/repos/apache/incubator-wayang/issues/244,incubator-wayang,1276181793,244,use config buffer size,github-actions,,,,OPEN,2022-06-19T22:23:33Z,2022-06-19T22:23:34Z,"use config buffer size

https://github.com/apache/incubator-wayang/blob/d859a97d43a8c3c3c964150eaff8f3833e41ea75/wayang-api/wayang-api-python/src/main/java/org/apache/wayang/api/python/executor/ProcessReceiver.java#L34

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.python.executor;

import java.io.BufferedInputStream;
import java.io.DataInputStream;
import java.io.IOException;
import java.net.Socket;
import java.util.Iterator;
/*TODO cannot be always string, include definition for every operator
*  like: map(udf, inputtype, outputtype)*/
public class ProcessReceiver<Output> {

    private ReaderIterator<Output> iterator;

    public ProcessReceiver(Socket socket){
        try{
            //TODO use config buffer size
            int BUFFER_SIZE = 1 * 1024;

            DataInputStream stream = new DataInputStream(new BufferedInputStream(socket.getInputStream(), BUFFER_SIZE));
            this.iterator = new ReaderIterator<>(stream);

        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public Iterable<Output> getIterable(){
        return () -> iterator;
    }

    public void print(){
        iterator.forEachRemaining(x -> System.out.println(x.toString()));

    }
}

```

47a7557f6cfc6a7d14b37414e7dcb97e76724949","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/244/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/245,https://api.github.com/repos/apache/incubator-wayang/issues/245,incubator-wayang,1276181803,245,"cannot be always string, include definition for every operator",github-actions,,,,OPEN,2022-06-19T22:23:35Z,2022-06-19T22:23:36Z,"cannot be always string, include definition for every operator

like: map(udf, inputtype, outputtype)

https://github.com/apache/incubator-wayang/blob/d859a97d43a8c3c3c964150eaff8f3833e41ea75/wayang-api/wayang-api-python/src/main/java/org/apache/wayang/api/python/executor/ProcessReceiver.java#L26

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.python.executor;

import java.io.BufferedInputStream;
import java.io.DataInputStream;
import java.io.IOException;
import java.net.Socket;
import java.util.Iterator;
/*TODO cannot be always string, include definition for every operator
*  like: map(udf, inputtype, outputtype)*/
public class ProcessReceiver<Output> {

    private ReaderIterator<Output> iterator;

    public ProcessReceiver(Socket socket){
        try{
            //TODO use config buffer size
            int BUFFER_SIZE = 1 * 1024;

            DataInputStream stream = new DataInputStream(new BufferedInputStream(socket.getInputStream(), BUFFER_SIZE));
            this.iterator = new ReaderIterator<>(stream);

        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public Iterable<Output> getIterable(){
        return () -> iterator;
    }

    public void print(){
        iterator.forEachRemaining(x -> System.out.println(x.toString()));

    }
}

```

00389544ba283bb371a70c4a4ad058235b6a4288","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/245/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/246,https://api.github.com/repos/apache/incubator-wayang/issues/246,incubator-wayang,1276181819,246,How to get the config,github-actions,,,,OPEN,2022-06-19T22:23:38Z,2022-06-19T22:23:39Z,"How to get the config

https://github.com/apache/incubator-wayang/blob/d859a97d43a8c3c3c964150eaff8f3833e41ea75/wayang-api/wayang-api-python/src/main/java/org/apache/wayang/api/python/executor/PythonProcessCaller.java#L41

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.python.executor;

import java.lang.ProcessBuilder.Redirect;
import org.apache.wayang.api.python.function.PythonCode;
import org.apache.wayang.core.api.Configuration;
import org.apache.wayang.core.api.exception.WayangException;

import java.io.IOException;
import java.net.InetAddress;
import java.net.ServerSocket;
import java.net.Socket;
import java.util.Arrays;
import java.util.Map;
import org.apache.wayang.core.util.ReflectionUtils;

public class PythonProcessCaller {

    private Thread process;
    private Socket socket;
    private ServerSocket serverSocket;
    private boolean ready;

    //TODO How to get the config
    private Configuration configuration;

    public PythonProcessCaller(PythonCode serializedUDF){

        //TODO create documentation to how to the configuration in the code
        this.configuration = new Configuration();
        this.configuration.load(ReflectionUtils.loadResource(""wayang-api-python-defaults.properties""));
        this.ready = false;
        byte[] addr = new byte[4];
        addr[0] = 127; addr[1] = 0; addr[2] = 0; addr[3] = 1;

        try {
            /*TODO should NOT be assigned an specific port, set port as 0 (zero)*/
            this.serverSocket = new ServerSocket(0, 1, InetAddress.getByAddress(addr));

            Runnable run1 = () -> {
                ProcessBuilder pb = new ProcessBuilder(
                    Arrays.asList(
                        ""python3"",
                        this.configuration.getStringProperty(""wayang.api.python.worker"")
                    )
                );
                Map<String, String> workerEnv = pb.environment();
                workerEnv.put(""PYTHON_WORKER_FACTORY_PORT"",
                    String.valueOf(this.serverSocket.getLocalPort()));

                // TODO See what is happening with ENV Python version
                workerEnv.put(
                    ""PYTHONPATH"",
                    this.configuration.getStringProperty(""wayang.api.python.path"")
                );

                pb.redirectOutput(Redirect.INHERIT);
                pb.redirectError(Redirect.INHERIT);
                try {
                    pb.start();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            };
            this.process = new Thread(run1);
            this.process.start();

            // Redirect worker stdout and stderr
            //IDK redirectStreamsToStderr(worker.getInputStream, worker.getErrorStream)

            // Wait for it to connect to our socket
            this.serverSocket.setSoTimeout(100000);

            try {
                this.socket = this.serverSocket.accept();
                this.serverSocket.setSoTimeout(0);

                if(socket.isConnected())
                    this.ready = true;

            } catch (Exception e) {
                System.out.println(e);
                throw new WayangException(""Python worker failed to connect back."", e);
            }
        } catch (Exception e){
            System.out.println(e);
            throw new WayangException(""Python worker failed"");
        }
    }

    public Thread getProcess() {
        return process;
    }

    public Socket getSocket() {
        return socket;
    }

    public boolean isReady(){
        return ready;
    }

    public void close(){
        try {
            this.process.interrupt();
            this.socket.close();
            this.serverSocket.close();
            System.out.println(""Everything closed"");
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}

```

d27c59411e0c1662feed06d4f75ce9331f24bc8e","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/246/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/247,https://api.github.com/repos/apache/incubator-wayang/issues/247,incubator-wayang,1276181830,247,create documentation to how to the configuration in the code,github-actions,,,,OPEN,2022-06-19T22:23:40Z,2023-10-10T12:13:50Z,"create documentation to how to the configuration in the code

https://github.com/apache/incubator-wayang/blob/d859a97d43a8c3c3c964150eaff8f3833e41ea75/wayang-api/wayang-api-python/src/main/java/org/apache/wayang/api/python/executor/PythonProcessCaller.java#L46

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.python.executor;

import java.lang.ProcessBuilder.Redirect;
import org.apache.wayang.api.python.function.PythonCode;
import org.apache.wayang.core.api.Configuration;
import org.apache.wayang.core.api.exception.WayangException;

import java.io.IOException;
import java.net.InetAddress;
import java.net.ServerSocket;
import java.net.Socket;
import java.util.Arrays;
import java.util.Map;
import org.apache.wayang.core.util.ReflectionUtils;

public class PythonProcessCaller {

    private Thread process;
    private Socket socket;
    private ServerSocket serverSocket;
    private boolean ready;

    //TODO How to get the config
    private Configuration configuration;

    public PythonProcessCaller(PythonCode serializedUDF){

        //TODO create documentation to how to the configuration in the code
        this.configuration = new Configuration();
        this.configuration.load(ReflectionUtils.loadResource(""wayang-api-python-defaults.properties""));
        this.ready = false;
        byte[] addr = new byte[4];
        addr[0] = 127; addr[1] = 0; addr[2] = 0; addr[3] = 1;

        try {
            /*TODO should NOT be assigned an specific port, set port as 0 (zero)*/
            this.serverSocket = new ServerSocket(0, 1, InetAddress.getByAddress(addr));

            Runnable run1 = () -> {
                ProcessBuilder pb = new ProcessBuilder(
                    Arrays.asList(
                        ""python3"",
                        this.configuration.getStringProperty(""wayang.api.python.worker"")
                    )
                );
                Map<String, String> workerEnv = pb.environment();
                workerEnv.put(""PYTHON_WORKER_FACTORY_PORT"",
                    String.valueOf(this.serverSocket.getLocalPort()));

                // TODO See what is happening with ENV Python version
                workerEnv.put(
                    ""PYTHONPATH"",
                    this.configuration.getStringProperty(""wayang.api.python.path"")
                );

                pb.redirectOutput(Redirect.INHERIT);
                pb.redirectError(Redirect.INHERIT);
                try {
                    pb.start();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            };
            this.process = new Thread(run1);
            this.process.start();

            // Redirect worker stdout and stderr
            //IDK redirectStreamsToStderr(worker.getInputStream, worker.getErrorStream)

            // Wait for it to connect to our socket
            this.serverSocket.setSoTimeout(100000);

            try {
                this.socket = this.serverSocket.accept();
                this.serverSocket.setSoTimeout(0);

                if(socket.isConnected())
                    this.ready = true;

            } catch (Exception e) {
                System.out.println(e);
                throw new WayangException(""Python worker failed to connect back."", e);
            }
        } catch (Exception e){
            System.out.println(e);
            throw new WayangException(""Python worker failed"");
        }
    }

    public Thread getProcess() {
        return process;
    }

    public Socket getSocket() {
        return socket;
    }

    public boolean isReady(){
        return ready;
    }

    public void close(){
        try {
            this.process.interrupt();
            this.socket.close();
            this.serverSocket.close();
            System.out.println(""Everything closed"");
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}

```

7ba4ec6c88b60b5a7cb861519278a3e9dc99303a","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/247/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/247,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5ontsT,incubator-wayang,1755241235,247,NA,kamir,1241122,Mirko Kämpf,mirko.kaempf@gmail.com,NA,2023-10-10T12:06:19Z,2023-10-10T12:06:19Z,"What is expected in this task? 

Can someone please line out what kind of documentation is expected?
Is it just some inline docu of the code or rather a tutorial page in the docs project?

","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5ontsT/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/247,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5onx_8,incubator-wayang,1755258876,247,NA,2pk03,1323575,Alexander Alten-Lorenz,,NA,2023-10-10T12:13:50Z,2023-10-10T12:13:50Z,"I think that's an automated issue, when test / comments are missing. We plan to restructure the whole code before we release 1.0.","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5onx_8/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/248,https://api.github.com/repos/apache/incubator-wayang/issues/248,incubator-wayang,1276181838,248,See what is happening with ENV Python version,github-actions,,,,CLOSED,2022-06-19T22:23:42Z,2024-05-09T06:27:54Z,"See what is happening with ENV Python version

IDK redirectStreamsToStderr(worker.getInputStream, worker.getErrorStream)

https://github.com/apache/incubator-wayang/blob/d859a97d43a8c3c3c964150eaff8f3833e41ea75/wayang-api/wayang-api-python/src/main/java/org/apache/wayang/api/python/executor/PythonProcessCaller.java#L68

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.python.executor;

import java.lang.ProcessBuilder.Redirect;
import org.apache.wayang.api.python.function.PythonCode;
import org.apache.wayang.core.api.Configuration;
import org.apache.wayang.core.api.exception.WayangException;

import java.io.IOException;
import java.net.InetAddress;
import java.net.ServerSocket;
import java.net.Socket;
import java.util.Arrays;
import java.util.Map;
import org.apache.wayang.core.util.ReflectionUtils;

public class PythonProcessCaller {

    private Thread process;
    private Socket socket;
    private ServerSocket serverSocket;
    private boolean ready;

    //TODO How to get the config
    private Configuration configuration;

    public PythonProcessCaller(PythonCode serializedUDF){

        //TODO create documentation to how to the configuration in the code
        this.configuration = new Configuration();
        this.configuration.load(ReflectionUtils.loadResource(""wayang-api-python-defaults.properties""));
        this.ready = false;
        byte[] addr = new byte[4];
        addr[0] = 127; addr[1] = 0; addr[2] = 0; addr[3] = 1;

        try {
            /*TODO should NOT be assigned an specific port, set port as 0 (zero)*/
            this.serverSocket = new ServerSocket(0, 1, InetAddress.getByAddress(addr));

            Runnable run1 = () -> {
                ProcessBuilder pb = new ProcessBuilder(
                    Arrays.asList(
                        ""python3"",
                        this.configuration.getStringProperty(""wayang.api.python.worker"")
                    )
                );
                Map<String, String> workerEnv = pb.environment();
                workerEnv.put(""PYTHON_WORKER_FACTORY_PORT"",
                    String.valueOf(this.serverSocket.getLocalPort()));

                // TODO See what is happening with ENV Python version
                workerEnv.put(
                    ""PYTHONPATH"",
                    this.configuration.getStringProperty(""wayang.api.python.path"")
                );

                pb.redirectOutput(Redirect.INHERIT);
                pb.redirectError(Redirect.INHERIT);
                try {
                    pb.start();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            };
            this.process = new Thread(run1);
            this.process.start();

            // Redirect worker stdout and stderr
            //IDK redirectStreamsToStderr(worker.getInputStream, worker.getErrorStream)

            // Wait for it to connect to our socket
            this.serverSocket.setSoTimeout(100000);

            try {
                this.socket = this.serverSocket.accept();
                this.serverSocket.setSoTimeout(0);

                if(socket.isConnected())
                    this.ready = true;

            } catch (Exception e) {
                System.out.println(e);
                throw new WayangException(""Python worker failed to connect back."", e);
            }
        } catch (Exception e){
            System.out.println(e);
            throw new WayangException(""Python worker failed"");
        }
    }

    public Thread getProcess() {
        return process;
    }

    public Socket getSocket() {
        return socket;
    }

    public boolean isReady(){
        return ready;
    }

    public void close(){
        try {
            this.process.interrupt();
            this.socket.close();
            this.serverSocket.close();
            System.out.println(""Everything closed"");
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}

```

6aef97fd1a10c19047511ac36e2ad48ecf58e229","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/248/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/248,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M59SniQ,incubator-wayang,2102032528,248,NA,github-actions,,,,NA,2024-05-09T06:27:54Z,2024-05-09T06:27:54Z,Closed in c25c6561bf786d76d0dc717b28cf15885c269232,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M59SniQ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/249,https://api.github.com/repos/apache/incubator-wayang/issues/249,incubator-wayang,1276181848,249,"should NOT be assigned an specific port, set port as 0 (zero)",github-actions,,,,OPEN,2022-06-19T22:23:45Z,2022-06-19T22:23:46Z,"should NOT be assigned an specific port, set port as 0 (zero)

https://github.com/apache/incubator-wayang/blob/d859a97d43a8c3c3c964150eaff8f3833e41ea75/wayang-api/wayang-api-python/src/main/java/org/apache/wayang/api/python/executor/PythonProcessCaller.java#L54

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.python.executor;

import java.lang.ProcessBuilder.Redirect;
import org.apache.wayang.api.python.function.PythonCode;
import org.apache.wayang.core.api.Configuration;
import org.apache.wayang.core.api.exception.WayangException;

import java.io.IOException;
import java.net.InetAddress;
import java.net.ServerSocket;
import java.net.Socket;
import java.util.Arrays;
import java.util.Map;
import org.apache.wayang.core.util.ReflectionUtils;

public class PythonProcessCaller {

    private Thread process;
    private Socket socket;
    private ServerSocket serverSocket;
    private boolean ready;

    //TODO How to get the config
    private Configuration configuration;

    public PythonProcessCaller(PythonCode serializedUDF){

        //TODO create documentation to how to the configuration in the code
        this.configuration = new Configuration();
        this.configuration.load(ReflectionUtils.loadResource(""wayang-api-python-defaults.properties""));
        this.ready = false;
        byte[] addr = new byte[4];
        addr[0] = 127; addr[1] = 0; addr[2] = 0; addr[3] = 1;

        try {
            /*TODO should NOT be assigned an specific port, set port as 0 (zero)*/
            this.serverSocket = new ServerSocket(0, 1, InetAddress.getByAddress(addr));

            Runnable run1 = () -> {
                ProcessBuilder pb = new ProcessBuilder(
                    Arrays.asList(
                        ""python3"",
                        this.configuration.getStringProperty(""wayang.api.python.worker"")
                    )
                );
                Map<String, String> workerEnv = pb.environment();
                workerEnv.put(""PYTHON_WORKER_FACTORY_PORT"",
                    String.valueOf(this.serverSocket.getLocalPort()));

                // TODO See what is happening with ENV Python version
                workerEnv.put(
                    ""PYTHONPATH"",
                    this.configuration.getStringProperty(""wayang.api.python.path"")
                );

                pb.redirectOutput(Redirect.INHERIT);
                pb.redirectError(Redirect.INHERIT);
                try {
                    pb.start();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            };
            this.process = new Thread(run1);
            this.process.start();

            // Redirect worker stdout and stderr
            //IDK redirectStreamsToStderr(worker.getInputStream, worker.getErrorStream)

            // Wait for it to connect to our socket
            this.serverSocket.setSoTimeout(100000);

            try {
                this.socket = this.serverSocket.accept();
                this.serverSocket.setSoTimeout(0);

                if(socket.isConnected())
                    this.ready = true;

            } catch (Exception e) {
                System.out.println(e);
                throw new WayangException(""Python worker failed to connect back."", e);
            }
        } catch (Exception e){
            System.out.println(e);
            throw new WayangException(""Python worker failed"");
        }
    }

    public Thread getProcess() {
        return process;
    }

    public Socket getSocket() {
        return socket;
    }

    public boolean isReady(){
        return ready;
    }

    public void close(){
        try {
            this.process.interrupt();
            this.socket.close();
            this.serverSocket.close();
            System.out.println(""Everything closed"");
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}

```

74da6b059ade7d349ae45590256ae9654459cb20","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/249/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/250,https://api.github.com/repos/apache/incubator-wayang/issues/250,incubator-wayang,1276181858,250,Connect with predecessors requires more details in connection slot,github-actions,,,,OPEN,2022-06-19T22:23:47Z,2022-06-19T22:23:48Z,"Connect with predecessors requires more details in connection slot

https://github.com/apache/incubator-wayang/blob/d859a97d43a8c3c3c964150eaff8f3833e41ea75/wayang-api/wayang-api-rest/src/main/java/org/apache/wayang/api/rest/server/spring/decoder/WayangPlanBuilder.java#L134

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.rest.server.spring.decoder;

import com.google.protobuf.InvalidProtocolBufferException;
import org.apache.wayang.api.python.function.WrappedPythonFunction;
import org.apache.wayang.basic.operators.MapPartitionsOperator;
import org.apache.wayang.basic.operators.TextFileSink;
import org.apache.wayang.basic.operators.TextFileSource;
import org.apache.wayang.basic.operators.UnionAllOperator;
import org.apache.wayang.commons.serializable.OperatorProto;
import org.apache.wayang.commons.serializable.PlanProto;
import org.apache.wayang.commons.serializable.WayangPlanProto;
import org.apache.wayang.core.api.WayangContext;
import org.apache.wayang.core.api.exception.WayangException;
import org.apache.wayang.core.function.MapPartitionsDescriptor;
import org.apache.wayang.core.plan.wayangplan.OperatorBase;
import org.apache.wayang.core.plan.wayangplan.WayangPlan;
import org.apache.wayang.java.Java;
import org.apache.wayang.spark.Spark;

import java.io.File;
import java.io.FileInputStream;
import java.io.IOException;
import java.net.MalformedURLException;
import java.net.URL;
import java.util.*;
import java.util.stream.Collectors;
import java.util.Base64;

public class WayangPlanBuilder {

    private WayangPlan wayangPlan;
    private WayangContext wayangContext;

    public WayangPlanBuilder(FileInputStream planFile){
        try {

            WayangPlanProto plan = WayangPlanProto.parseFrom(planFile);

            this.wayangContext = buildContext(plan);
            this.wayangPlan = buildPlan(plan);

        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public WayangPlanBuilder(String writtenPlan){

        System.out.println(writtenPlan);
        byte[] message = Base64.getDecoder().decode(writtenPlan);
        System.out.println(message);

        try {
            WayangPlanProto plan = WayangPlanProto.parseFrom(message);

            this.wayangContext = buildContext(plan);
            this.wayangPlan = buildPlan(plan);
        } catch (InvalidProtocolBufferException e) {
            e.printStackTrace();
        }

    }

    private WayangContext buildContext(WayangPlanProto plan){

        WayangContext ctx = new WayangContext();
//        plan.getContext().getPlatformsList().forEach(platform -> {
//            if (platform.getNumber() == 0)
//                ctx.with(Java.basicPlugin());
//            else if (platform.getNumber() == 1)
//                ctx.with(Spark.basicPlugin());
//        });
        ctx.with(Spark.basicPlugin());

        return ctx;
    }

    private WayangPlan buildPlan(WayangPlanProto plan){

        System.out.println(plan);

        PlanProto planProto = plan.getPlan();
        LinkedList<OperatorProto> protoList = new LinkedList<>();
        planProto.getSourcesList().forEach(protoList::addLast);

        Map<String, OperatorBase> operators = new HashMap<>();
        List<OperatorBase> sinks = new ArrayList<>();
        while(! protoList.isEmpty()) {

            OperatorProto proto = protoList.pollFirst();

            /* Checking if protoOperator can be connected to the current WayangPlan*/
            boolean processIt;
            if(proto.getType().equals(""source"")) processIt = true;

            else {
                /* Checking if ALL predecessors were already processed */
                processIt = true;
                for(String predecessor : proto.getPredecessorsList()){
                    if (!operators.containsKey(predecessor)) {
                        processIt = false;
                        break;
                    }
                }
            }

            /* Operators should not be processed twice*/
            if(operators.containsKey(proto.getId())) processIt = false;

            if(processIt) {

                /* Create and store Wayang operator */
                OperatorBase operator = createOperatorByType(proto);
                operators.put(proto.getId(), operator);

                /*TODO Connect with predecessors requires more details in connection slot*/
                int order = 0;
                for (String pre_id : proto.getPredecessorsList()) {

                    OperatorBase predecessor = operators.get(pre_id);
                    /* Only works without replicate topology */
                    predecessor.connectTo(0, operator, order);
                    order++;

                    if(proto.getType().toLowerCase().contains(""sink"")){
                        sinks.add(operator);
                        //if(!sinks.contains(operator)) {
                        //    sinks.add(operator);
                        //}
                    }
                }

                /*List of OperatorProto successors
                 * They will be added to the protoList
                 * nevertheless they must be processed only if the parents are in operators list */
                List<OperatorProto> listSuccessors = planProto.getOperatorsList()
                        .stream()
                        .filter(t -> proto.getSuccessorsList().contains(t.getId()))
                        .collect(Collectors.toList());
                for (OperatorProto successor : listSuccessors){
                    if(!protoList.contains(successor)){
                        protoList.addLast(successor);
                    }
                }

                List<OperatorProto> sinkSuccessors = planProto.getSinksList()
                        .stream()
                        .filter(t -> proto.getSuccessorsList().contains(t.getId()))
                        .collect(Collectors.toList());
                for (OperatorProto successor : sinkSuccessors){
                    if(!protoList.contains(successor)){
                        protoList.addLast(successor);
                    }
                }

            } else {

                /* In case we cannot process it yet, It must be added again at the end*/
                protoList.addLast(proto);
            }
        }

        WayangPlan wayangPlan = new WayangPlan(sinks.get(0));
        return wayangPlan;
    }

    public OperatorBase createOperatorByType(OperatorProto operator){

        switch(operator.getType()){
            case ""TextFileSource"":
                try {
                    String source_path = operator.getPath();
                    URL url = new File(source_path).toURI().toURL();
                    return new TextFileSource(url.toString());
                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""TextFileSink"":
                try {
                    String sink_path = operator.getPath();
                    URL url = new File(sink_path).toURI().toURL();
                    return new TextFileSink<String>(
                            url.toString(),
                            String.class
                    );

                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""MapPartitionOperator"":
                return new MapPartitionsOperator<>(
                        new MapPartitionsDescriptor<String, String>(
                                new WrappedPythonFunction<String, String>(
                                        l -> l,
                                        operator.getUdf()
                                ),
                                String.class,
                                String.class
                        )
                );

            case ""union"":
                return new UnionAllOperator<String>(
                        String.class
                );

        }

        throw new WayangException(""Operator Type not supported ""+operator.getType());
    }

    public WayangContext getWayangContext() {
        return wayangContext;
    }

    public WayangPlan getWayangPlan() {
        return wayangPlan;
    }
}

```

968f82f6dab0e9e1d3ede6303836f9e65e3d9304","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/250/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/251,https://api.github.com/repos/apache/incubator-wayang/issues/251,incubator-wayang,1276181869,251,ADD id to executions,github-actions,,,,CLOSED,2022-06-19T22:23:49Z,2023-07-20T15:09:39Z,"ADD id to executions

https://github.com/apache/incubator-wayang/blob/d859a97d43a8c3c3c964150eaff8f3833e41ea75/wayang-api/wayang-api-rest/src/main/java/org/apache/wayang/api/rest/server/spring/general/WayangController.java#L68

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.rest.server.spring.general;

import com.google.protobuf.ByteString;
import org.apache.wayang.api.python.function.WrappedPythonFunction;
import org.apache.wayang.api.rest.server.spring.decoder.WayangPlanBuilder;
import org.apache.wayang.basic.operators.*;
import org.apache.wayang.commons.serializable.OperatorProto;
import org.apache.wayang.commons.serializable.PlanProto;
import org.apache.wayang.core.api.WayangContext;
import org.apache.wayang.core.api.exception.WayangException;
import org.apache.wayang.core.function.MapPartitionsDescriptor;
import org.apache.wayang.core.plan.wayangplan.OperatorBase;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.RestController;

import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.IOException;
import java.net.MalformedURLException;
import java.net.URI;
import java.net.URISyntaxException;
import java.net.URL;
import java.nio.file.Paths;
import java.util.*;
import java.util.stream.Collectors;

import org.apache.wayang.core.plan.wayangplan.WayangPlan;
import org.apache.wayang.java.Java;
import org.apache.wayang.spark.Spark;

import org.apache.wayang.commons.serializable.WayangPlanProto;
import org.springframework.web.multipart.MultipartFile;


@RestController
public class WayangController {

    @GetMapping(""/plan/create/fromfile"")
    public String planFromFile(
            //@RequestParam(""file"") MultipartFile file
    ){

        try {
            FileInputStream inputStream = new FileInputStream(Paths.get(""."").toRealPath() + ""/protobuf/wayang_message"");
            WayangPlanBuilder wpb = new WayangPlanBuilder(inputStream);

            /*TODO ADD id to executions*/
            wpb.getWayangContext().execute(wpb.getWayangPlan());

        } catch (IOException e) {
            e.printStackTrace();
        }

        return ""Builder works"";
    }

    @PostMapping(""/plan/create"")
    public String planFromMessage(
            @RequestParam(""message"") String message
    ){

        WayangPlanBuilder wpb = new WayangPlanBuilder(message);

        /*TODO ADD id to executions*/
        wpb.getWayangContext().execute(wpb.getWayangPlan());

        return """";
    }

    @GetMapping(""/"")
    public String all(){
        System.out.println(""detected!"");

        try {
            FileInputStream inputStream = new FileInputStream(Paths.get(""."").toRealPath() + ""/protobuf/wayang_message"");
            WayangPlanProto plan = WayangPlanProto.parseFrom(inputStream);

            WayangContext wc = buildContext(plan);
            WayangPlan wp = buildPlan(plan);

            System.out.println(""Plan!"");
            System.out.println(wp.toString());

            wc.execute(wp);
            return(""Works!"");

        } catch (FileNotFoundException e) {
            e.printStackTrace();
        } catch (IOException e) {
            e.printStackTrace();
        }

        return ""Not working"";
    }

    private WayangContext buildContext(WayangPlanProto plan){

        WayangContext ctx = new WayangContext();
//        plan.getContext().getPlatformsList().forEach(platform -> {
//            if (platform.getNumber() == 0)
//                ctx.with(Java.basicPlugin());
//            else if (platform.getNumber() == 1)
//                ctx.with(Spark.basicPlugin());
//        });
        ctx.with(Spark.basicPlugin());

        return ctx;
    }

    private WayangPlan buildPlan(WayangPlanProto plan){

        System.out.println(plan);

        PlanProto planProto = plan.getPlan();
        LinkedList<OperatorProto> protoList = new LinkedList<>();
        planProto.getSourcesList().forEach(protoList::addLast);

        Map<String, OperatorBase> operators = new HashMap<>();
        List<OperatorBase> sinks = new ArrayList<>();
        while(! protoList.isEmpty()) {

            OperatorProto proto = protoList.pollFirst();

            /* Checking if protoOperator can be connected to the current WayangPlan*/
            boolean processIt;
            if(proto.getType().equals(""source"")) processIt = true;

            else {
                /* Checking if ALL predecessors were already processed */
                processIt = true;
                for(String predecessor : proto.getPredecessorsList()){
                    if (!operators.containsKey(predecessor)) {
                        processIt = false;
                        break;
                    }
                }
            }

            /* Operators should not be processed twice*/
            if(operators.containsKey(proto.getId())) processIt = false;

            if(processIt) {

                /* Create and store Wayang operator */
                OperatorBase operator = createOperatorByType(proto);
                operators.put(proto.getId(), operator);

                /*TODO Connect with predecessors requires more details in connection slot*/
                int order = 0;
                for (String pre_id : proto.getPredecessorsList()) {

                    OperatorBase predecessor = operators.get(pre_id);
                    /* Only works without replicate topology */
                    predecessor.connectTo(0, operator, order);
                    order++;

                    if(proto.getType().equals(""sink"")){
                        sinks.add(operator);
                        //if(!sinks.contains(operator)) {
                        //    sinks.add(operator);
                        //}
                    }
                }

                /*List of OperatorProto successors
                 * They will be added to the protoList
                 * nevertheless they must be processed only if the parents are in operators list */
                List<OperatorProto> listSuccessors = planProto.getOperatorsList()
                        .stream()
                        .filter(t -> proto.getSuccessorsList().contains(t.getId()))
                        .collect(Collectors.toList());
                for (OperatorProto successor : listSuccessors){
                    if(!protoList.contains(successor)){
                        protoList.addLast(successor);
                    }
                }

                List<OperatorProto> sinkSuccessors = planProto.getSinksList()
                        .stream()
                        .filter(t -> proto.getSuccessorsList().contains(t.getId()))
                        .collect(Collectors.toList());
                for (OperatorProto successor : sinkSuccessors){
                    if(!protoList.contains(successor)){
                        protoList.addLast(successor);
                    }
                }

            } else {

                /* In case we cannot process it yet, It must be added again at the end*/
                protoList.addLast(proto);
            }
        }

        WayangPlan wayangPlan = new WayangPlan(sinks.get(0));
        return wayangPlan;
    }

    public OperatorBase createOperatorByType(OperatorProto operator){

        System.out.println(""Typo: "" + operator.getType());
        switch(operator.getType()){
            case ""source"":
                try {
                    String source_path = operator.getPath();
                    URL url = new File(source_path).toURI().toURL();
                    return new TextFileSource(url.toString());
                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""sink"":
                try {
                    String sink_path = operator.getPath();
                    URL url = new File(sink_path).toURI().toURL();
                    return new TextFileSink<String>(
                            url.toString(),
                            String.class
                    );

                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""reduce_by_key"":
                try {
                    /* Function to be applied in Python workers */
                    ByteString function = operator.getUdf();

                    /* Has dimension or positions that compose GroupKey */
                    Map<String, String> parameters = operator.getParametersMap();

                    PyWayangReduceByOperator<String, String> op = new PyWayangReduceByOperator(
                        operator.getParametersMap(),
                        operator.getUdf() ,
                        String.class,
                        String.class,
                            false
                    );

                    String sink_path = operator.getPath();
                    URL url = new File(sink_path).toURI().toURL();
                    return new TextFileSink<String>(
                            url.toString(),
                            String.class
                    );

                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""map_partition"":
                return new MapPartitionsOperator<>(
                    new MapPartitionsDescriptor<String, String>(
                        new WrappedPythonFunction<String, String>(
                            l -> l,
                            operator.getUdf()
                        ),
                        String.class,
                        String.class
                    )
                );

            case ""union"":
                return new UnionAllOperator<String>(
                        String.class
                );

        }

        throw new WayangException(""Operator Type not supported"");
    }

    public static URI createUri(String resourcePath) {
        try {
            return Thread.currentThread().getClass().getResource(resourcePath).toURI();
        } catch (URISyntaxException e) {
            throw new IllegalArgumentException(""Illegal URI."", e);
        }

    }

}

```

fc40b51c9c64a2be4b9ade89923dcd88f2da6ce4","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/251/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/252,https://api.github.com/repos/apache/incubator-wayang/issues/252,incubator-wayang,1276181874,252,ADD id to executions,github-actions,,,,CLOSED,2022-06-19T22:23:51Z,2024-05-09T06:28:01Z,"ADD id to executions

https://github.com/apache/incubator-wayang/blob/d859a97d43a8c3c3c964150eaff8f3833e41ea75/wayang-api/wayang-api-rest/src/main/java/org/apache/wayang/api/rest/server/spring/general/WayangController.java#L85

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.rest.server.spring.general;

import com.google.protobuf.ByteString;
import org.apache.wayang.api.python.function.WrappedPythonFunction;
import org.apache.wayang.api.rest.server.spring.decoder.WayangPlanBuilder;
import org.apache.wayang.basic.operators.*;
import org.apache.wayang.commons.serializable.OperatorProto;
import org.apache.wayang.commons.serializable.PlanProto;
import org.apache.wayang.core.api.WayangContext;
import org.apache.wayang.core.api.exception.WayangException;
import org.apache.wayang.core.function.MapPartitionsDescriptor;
import org.apache.wayang.core.plan.wayangplan.OperatorBase;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.RestController;

import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.IOException;
import java.net.MalformedURLException;
import java.net.URI;
import java.net.URISyntaxException;
import java.net.URL;
import java.nio.file.Paths;
import java.util.*;
import java.util.stream.Collectors;

import org.apache.wayang.core.plan.wayangplan.WayangPlan;
import org.apache.wayang.java.Java;
import org.apache.wayang.spark.Spark;

import org.apache.wayang.commons.serializable.WayangPlanProto;
import org.springframework.web.multipart.MultipartFile;


@RestController
public class WayangController {

    @GetMapping(""/plan/create/fromfile"")
    public String planFromFile(
            //@RequestParam(""file"") MultipartFile file
    ){

        try {
            FileInputStream inputStream = new FileInputStream(Paths.get(""."").toRealPath() + ""/protobuf/wayang_message"");
            WayangPlanBuilder wpb = new WayangPlanBuilder(inputStream);

            /*TODO ADD id to executions*/
            wpb.getWayangContext().execute(wpb.getWayangPlan());

        } catch (IOException e) {
            e.printStackTrace();
        }

        return ""Builder works"";
    }

    @PostMapping(""/plan/create"")
    public String planFromMessage(
            @RequestParam(""message"") String message
    ){

        WayangPlanBuilder wpb = new WayangPlanBuilder(message);

        /*TODO ADD id to executions*/
        wpb.getWayangContext().execute(wpb.getWayangPlan());

        return """";
    }

    @GetMapping(""/"")
    public String all(){
        System.out.println(""detected!"");

        try {
            FileInputStream inputStream = new FileInputStream(Paths.get(""."").toRealPath() + ""/protobuf/wayang_message"");
            WayangPlanProto plan = WayangPlanProto.parseFrom(inputStream);

            WayangContext wc = buildContext(plan);
            WayangPlan wp = buildPlan(plan);

            System.out.println(""Plan!"");
            System.out.println(wp.toString());

            wc.execute(wp);
            return(""Works!"");

        } catch (FileNotFoundException e) {
            e.printStackTrace();
        } catch (IOException e) {
            e.printStackTrace();
        }

        return ""Not working"";
    }

    private WayangContext buildContext(WayangPlanProto plan){

        WayangContext ctx = new WayangContext();
//        plan.getContext().getPlatformsList().forEach(platform -> {
//            if (platform.getNumber() == 0)
//                ctx.with(Java.basicPlugin());
//            else if (platform.getNumber() == 1)
//                ctx.with(Spark.basicPlugin());
//        });
        ctx.with(Spark.basicPlugin());

        return ctx;
    }

    private WayangPlan buildPlan(WayangPlanProto plan){

        System.out.println(plan);

        PlanProto planProto = plan.getPlan();
        LinkedList<OperatorProto> protoList = new LinkedList<>();
        planProto.getSourcesList().forEach(protoList::addLast);

        Map<String, OperatorBase> operators = new HashMap<>();
        List<OperatorBase> sinks = new ArrayList<>();
        while(! protoList.isEmpty()) {

            OperatorProto proto = protoList.pollFirst();

            /* Checking if protoOperator can be connected to the current WayangPlan*/
            boolean processIt;
            if(proto.getType().equals(""source"")) processIt = true;

            else {
                /* Checking if ALL predecessors were already processed */
                processIt = true;
                for(String predecessor : proto.getPredecessorsList()){
                    if (!operators.containsKey(predecessor)) {
                        processIt = false;
                        break;
                    }
                }
            }

            /* Operators should not be processed twice*/
            if(operators.containsKey(proto.getId())) processIt = false;

            if(processIt) {

                /* Create and store Wayang operator */
                OperatorBase operator = createOperatorByType(proto);
                operators.put(proto.getId(), operator);

                /*TODO Connect with predecessors requires more details in connection slot*/
                int order = 0;
                for (String pre_id : proto.getPredecessorsList()) {

                    OperatorBase predecessor = operators.get(pre_id);
                    /* Only works without replicate topology */
                    predecessor.connectTo(0, operator, order);
                    order++;

                    if(proto.getType().equals(""sink"")){
                        sinks.add(operator);
                        //if(!sinks.contains(operator)) {
                        //    sinks.add(operator);
                        //}
                    }
                }

                /*List of OperatorProto successors
                 * They will be added to the protoList
                 * nevertheless they must be processed only if the parents are in operators list */
                List<OperatorProto> listSuccessors = planProto.getOperatorsList()
                        .stream()
                        .filter(t -> proto.getSuccessorsList().contains(t.getId()))
                        .collect(Collectors.toList());
                for (OperatorProto successor : listSuccessors){
                    if(!protoList.contains(successor)){
                        protoList.addLast(successor);
                    }
                }

                List<OperatorProto> sinkSuccessors = planProto.getSinksList()
                        .stream()
                        .filter(t -> proto.getSuccessorsList().contains(t.getId()))
                        .collect(Collectors.toList());
                for (OperatorProto successor : sinkSuccessors){
                    if(!protoList.contains(successor)){
                        protoList.addLast(successor);
                    }
                }

            } else {

                /* In case we cannot process it yet, It must be added again at the end*/
                protoList.addLast(proto);
            }
        }

        WayangPlan wayangPlan = new WayangPlan(sinks.get(0));
        return wayangPlan;
    }

    public OperatorBase createOperatorByType(OperatorProto operator){

        System.out.println(""Typo: "" + operator.getType());
        switch(operator.getType()){
            case ""source"":
                try {
                    String source_path = operator.getPath();
                    URL url = new File(source_path).toURI().toURL();
                    return new TextFileSource(url.toString());
                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""sink"":
                try {
                    String sink_path = operator.getPath();
                    URL url = new File(sink_path).toURI().toURL();
                    return new TextFileSink<String>(
                            url.toString(),
                            String.class
                    );

                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""reduce_by_key"":
                try {
                    /* Function to be applied in Python workers */
                    ByteString function = operator.getUdf();

                    /* Has dimension or positions that compose GroupKey */
                    Map<String, String> parameters = operator.getParametersMap();

                    PyWayangReduceByOperator<String, String> op = new PyWayangReduceByOperator(
                        operator.getParametersMap(),
                        operator.getUdf() ,
                        String.class,
                        String.class,
                            false
                    );

                    String sink_path = operator.getPath();
                    URL url = new File(sink_path).toURI().toURL();
                    return new TextFileSink<String>(
                            url.toString(),
                            String.class
                    );

                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""map_partition"":
                return new MapPartitionsOperator<>(
                    new MapPartitionsDescriptor<String, String>(
                        new WrappedPythonFunction<String, String>(
                            l -> l,
                            operator.getUdf()
                        ),
                        String.class,
                        String.class
                    )
                );

            case ""union"":
                return new UnionAllOperator<String>(
                        String.class
                );

        }

        throw new WayangException(""Operator Type not supported"");
    }

    public static URI createUri(String resourcePath) {
        try {
            return Thread.currentThread().getClass().getResource(resourcePath).toURI();
        } catch (URISyntaxException e) {
            throw new IllegalArgumentException(""Illegal URI."", e);
        }

    }

}

```

367a529142a08de7c8523472734a47b1d1914866","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/252/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/252,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M59Snjr,incubator-wayang,2102032619,252,NA,github-actions,,,,NA,2024-05-09T06:27:58Z,2024-05-09T06:27:58Z,Closed in c25c6561bf786d76d0dc717b28cf15885c269232,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M59Snjr/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/252,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M59SnkR,incubator-wayang,2102032657,252,NA,github-actions,,,,NA,2024-05-09T06:28:00Z,2024-05-09T06:28:00Z,Closed in c25c6561bf786d76d0dc717b28cf15885c269232,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M59SnkR/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/253,https://api.github.com/repos/apache/incubator-wayang/issues/253,incubator-wayang,1276181884,253,Connect with predecessors requires more details in connection slot,github-actions,,,,OPEN,2022-06-19T22:23:54Z,2022-06-19T22:23:55Z,"Connect with predecessors requires more details in connection slot

https://github.com/apache/incubator-wayang/blob/d859a97d43a8c3c3c964150eaff8f3833e41ea75/wayang-api/wayang-api-rest/src/main/java/org/apache/wayang/api/rest/server/spring/general/WayangController.java#L169

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.rest.server.spring.general;

import com.google.protobuf.ByteString;
import org.apache.wayang.api.python.function.WrappedPythonFunction;
import org.apache.wayang.api.rest.server.spring.decoder.WayangPlanBuilder;
import org.apache.wayang.basic.operators.*;
import org.apache.wayang.commons.serializable.OperatorProto;
import org.apache.wayang.commons.serializable.PlanProto;
import org.apache.wayang.core.api.WayangContext;
import org.apache.wayang.core.api.exception.WayangException;
import org.apache.wayang.core.function.MapPartitionsDescriptor;
import org.apache.wayang.core.plan.wayangplan.OperatorBase;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.RestController;

import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.IOException;
import java.net.MalformedURLException;
import java.net.URI;
import java.net.URISyntaxException;
import java.net.URL;
import java.nio.file.Paths;
import java.util.*;
import java.util.stream.Collectors;

import org.apache.wayang.core.plan.wayangplan.WayangPlan;
import org.apache.wayang.java.Java;
import org.apache.wayang.spark.Spark;

import org.apache.wayang.commons.serializable.WayangPlanProto;
import org.springframework.web.multipart.MultipartFile;


@RestController
public class WayangController {

    @GetMapping(""/plan/create/fromfile"")
    public String planFromFile(
            //@RequestParam(""file"") MultipartFile file
    ){

        try {
            FileInputStream inputStream = new FileInputStream(Paths.get(""."").toRealPath() + ""/protobuf/wayang_message"");
            WayangPlanBuilder wpb = new WayangPlanBuilder(inputStream);

            /*TODO ADD id to executions*/
            wpb.getWayangContext().execute(wpb.getWayangPlan());

        } catch (IOException e) {
            e.printStackTrace();
        }

        return ""Builder works"";
    }

    @PostMapping(""/plan/create"")
    public String planFromMessage(
            @RequestParam(""message"") String message
    ){

        WayangPlanBuilder wpb = new WayangPlanBuilder(message);

        /*TODO ADD id to executions*/
        wpb.getWayangContext().execute(wpb.getWayangPlan());

        return """";
    }

    @GetMapping(""/"")
    public String all(){
        System.out.println(""detected!"");

        try {
            FileInputStream inputStream = new FileInputStream(Paths.get(""."").toRealPath() + ""/protobuf/wayang_message"");
            WayangPlanProto plan = WayangPlanProto.parseFrom(inputStream);

            WayangContext wc = buildContext(plan);
            WayangPlan wp = buildPlan(plan);

            System.out.println(""Plan!"");
            System.out.println(wp.toString());

            wc.execute(wp);
            return(""Works!"");

        } catch (FileNotFoundException e) {
            e.printStackTrace();
        } catch (IOException e) {
            e.printStackTrace();
        }

        return ""Not working"";
    }

    private WayangContext buildContext(WayangPlanProto plan){

        WayangContext ctx = new WayangContext();
//        plan.getContext().getPlatformsList().forEach(platform -> {
//            if (platform.getNumber() == 0)
//                ctx.with(Java.basicPlugin());
//            else if (platform.getNumber() == 1)
//                ctx.with(Spark.basicPlugin());
//        });
        ctx.with(Spark.basicPlugin());

        return ctx;
    }

    private WayangPlan buildPlan(WayangPlanProto plan){

        System.out.println(plan);

        PlanProto planProto = plan.getPlan();
        LinkedList<OperatorProto> protoList = new LinkedList<>();
        planProto.getSourcesList().forEach(protoList::addLast);

        Map<String, OperatorBase> operators = new HashMap<>();
        List<OperatorBase> sinks = new ArrayList<>();
        while(! protoList.isEmpty()) {

            OperatorProto proto = protoList.pollFirst();

            /* Checking if protoOperator can be connected to the current WayangPlan*/
            boolean processIt;
            if(proto.getType().equals(""source"")) processIt = true;

            else {
                /* Checking if ALL predecessors were already processed */
                processIt = true;
                for(String predecessor : proto.getPredecessorsList()){
                    if (!operators.containsKey(predecessor)) {
                        processIt = false;
                        break;
                    }
                }
            }

            /* Operators should not be processed twice*/
            if(operators.containsKey(proto.getId())) processIt = false;

            if(processIt) {

                /* Create and store Wayang operator */
                OperatorBase operator = createOperatorByType(proto);
                operators.put(proto.getId(), operator);

                /*TODO Connect with predecessors requires more details in connection slot*/
                int order = 0;
                for (String pre_id : proto.getPredecessorsList()) {

                    OperatorBase predecessor = operators.get(pre_id);
                    /* Only works without replicate topology */
                    predecessor.connectTo(0, operator, order);
                    order++;

                    if(proto.getType().equals(""sink"")){
                        sinks.add(operator);
                        //if(!sinks.contains(operator)) {
                        //    sinks.add(operator);
                        //}
                    }
                }

                /*List of OperatorProto successors
                 * They will be added to the protoList
                 * nevertheless they must be processed only if the parents are in operators list */
                List<OperatorProto> listSuccessors = planProto.getOperatorsList()
                        .stream()
                        .filter(t -> proto.getSuccessorsList().contains(t.getId()))
                        .collect(Collectors.toList());
                for (OperatorProto successor : listSuccessors){
                    if(!protoList.contains(successor)){
                        protoList.addLast(successor);
                    }
                }

                List<OperatorProto> sinkSuccessors = planProto.getSinksList()
                        .stream()
                        .filter(t -> proto.getSuccessorsList().contains(t.getId()))
                        .collect(Collectors.toList());
                for (OperatorProto successor : sinkSuccessors){
                    if(!protoList.contains(successor)){
                        protoList.addLast(successor);
                    }
                }

            } else {

                /* In case we cannot process it yet, It must be added again at the end*/
                protoList.addLast(proto);
            }
        }

        WayangPlan wayangPlan = new WayangPlan(sinks.get(0));
        return wayangPlan;
    }

    public OperatorBase createOperatorByType(OperatorProto operator){

        System.out.println(""Typo: "" + operator.getType());
        switch(operator.getType()){
            case ""source"":
                try {
                    String source_path = operator.getPath();
                    URL url = new File(source_path).toURI().toURL();
                    return new TextFileSource(url.toString());
                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""sink"":
                try {
                    String sink_path = operator.getPath();
                    URL url = new File(sink_path).toURI().toURL();
                    return new TextFileSink<String>(
                            url.toString(),
                            String.class
                    );

                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""reduce_by_key"":
                try {
                    /* Function to be applied in Python workers */
                    ByteString function = operator.getUdf();

                    /* Has dimension or positions that compose GroupKey */
                    Map<String, String> parameters = operator.getParametersMap();

                    PyWayangReduceByOperator<String, String> op = new PyWayangReduceByOperator(
                        operator.getParametersMap(),
                        operator.getUdf() ,
                        String.class,
                        String.class,
                            false
                    );

                    String sink_path = operator.getPath();
                    URL url = new File(sink_path).toURI().toURL();
                    return new TextFileSink<String>(
                            url.toString(),
                            String.class
                    );

                } catch (MalformedURLException e) {
                    e.printStackTrace();
                }
                break;
            case ""map_partition"":
                return new MapPartitionsOperator<>(
                    new MapPartitionsDescriptor<String, String>(
                        new WrappedPythonFunction<String, String>(
                            l -> l,
                            operator.getUdf()
                        ),
                        String.class,
                        String.class
                    )
                );

            case ""union"":
                return new UnionAllOperator<String>(
                        String.class
                );

        }

        throw new WayangException(""Operator Type not supported"");
    }

    public static URI createUri(String resourcePath) {
        try {
            return Thread.currentThread().getClass().getResource(resourcePath).toURI();
        } catch (URISyntaxException e) {
            throw new IllegalArgumentException(""Illegal URI."", e);
        }

    }

}

```

d441489723f52894d7c7ff7648e5fff599eefa28","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/253/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/272,https://api.github.com/repos/apache/incubator-wayang/issues/272,incubator-wayang,1574285090,272,Feature Request: Wayang Dashboard,ichbinrich,11424621,Ricardo Martinez,msc.ricardomartinez@yahoo.com,OPEN,2023-02-07T12:59:12Z,2023-02-07T12:59:12Z,"Dear all,

having a Dashboard would improve the user experience while using Wayang, therefore my suggestion is to develop a Web User Interface and a Back-end to support the following:

- Overview of the system
- High level per Job statistics view
- Detailed Job view (maybe a graph with the operators)

The system may look like this:

![HackIt-FrontBackEnd drawio](https://user-images.githubusercontent.com/11424621/217248611-7587f6cf-6db9-44f8-aafd-6aa31656bbf9.png)

In subsequent issues the details can be discussed to assure concreteness in each one. Layout, API, Communication Channels, Other concerns.

Comments and suggestions required.","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/272/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/273,https://api.github.com/repos/apache/incubator-wayang/issues/273,incubator-wayang,1574288830,273,New Feature: Dashboard - Layouts,ichbinrich,11424621,Ricardo Martinez,msc.ricardomartinez@yahoo.com,CLOSED,2023-02-07T13:01:32Z,2023-07-20T15:08:53Z,"As a follow up issue from #272, my suggestion for the layout of a basic Dashboard would be as the following Layouts:

![HackIt-Dashboard-DocumentationHome drawio](https://user-images.githubusercontent.com/11424621/217251841-6539dc17-801c-4ffa-a530-a1f261c2f7cd.png)

![HackIt-Dashboard-DocumentationJobs drawio](https://user-images.githubusercontent.com/11424621/217251862-8b1d7308-180e-4b07-941d-54800e25832f.png)

![HackIt-Dashboard-DocumentationJobDetail drawio](https://user-images.githubusercontent.com/11424621/217251879-f21ce8b4-340f-48fa-afa0-9cf628cc6778.png)



","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/273/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/273,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5UrtzS,incubator-wayang,1420745938,273,NA,2pk03,1323575,Alexander Alten-Lorenz,,NA,2023-02-07T13:07:49Z,2023-02-07T13:07:49Z,"That looks pretty good, simple but powerful!","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5UrtzS/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/273,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5bStSE,incubator-wayang,1531630724,273,NA,ichbinrich,11424621,Ricardo Martinez,msc.ricardomartinez@yahoo.com,NA,2023-05-02T14:57:42Z,2023-05-02T14:57:42Z,"After some discussions, the layout changed to a more user-friendly, following some patterns in other dashboards, the current design is as follows: 

![GeneralLayout](https://user-images.githubusercontent.com/11424621/235704431-2d7dc0ea-c818-46dd-b9ea-0a7a1bc33c87.png)

The Dashboard would be separated in different components and sections as follows:

![NewLayout-Sections](https://user-images.githubusercontent.com/11424621/235704695-fe7a9f19-f64c-45d4-baf2-6e6eb4d0355c.png)

","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5bStSE/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/273,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5bSyC4,incubator-wayang,1531650232,273,NA,ichbinrich,11424621,Ricardo Martinez,msc.ricardomartinez@yahoo.com,NA,2023-05-02T15:09:56Z,2023-05-02T15:09:56Z,"An actual screen shot of the running webapp:

![image](https://user-images.githubusercontent.com/11424621/235707960-5b42f47b-f23a-4999-96eb-dd1b3d5e997d.png)
","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5bSyC4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/273,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5bS4TW,incubator-wayang,1531675862,273,NA,2pk03,1323575,Alexander Alten-Lorenz,,NA,2023-05-02T15:26:47Z,2023-05-02T15:26:47Z,+1 awesome!,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5bS4TW/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/274,https://api.github.com/repos/apache/incubator-wayang/issues/274,incubator-wayang,1577625787,274,New Feature: Dashboard Backend,ichbinrich,11424621,Ricardo Martinez,msc.ricardomartinez@yahoo.com,OPEN,2023-02-09T10:27:03Z,2023-02-09T10:27:03Z,"As a follow up issue from #272, there is a requirement to expose an API to be consumed by the UI, that could be achieved by creating a back-end component, e.g. a web server, that communicates with the Wayang core and provides the data collected, such as  summary of the current jobs (Running Jobs), available platforms, just to give a couple of examples. Initially this component could be passive, i.e. only consumes data to show in the UI, potentially it could turn into an active component, allowing interact with Wayang, e.g. Submit a new job or cancel a running job.","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/274/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/282,https://api.github.com/repos/apache/incubator-wayang/issues/282,incubator-wayang,1663256884,282,Smooth-Installation,JorgeQuiane,5936313,Jorge Quiane,,CLOSED,2023-04-11T21:40:54Z,2023-04-21T12:24:38Z,"We need to improve the installation of wayang so that most people (including non-experts) can install and get jobs running on Wayang. For this we need to be able to:
- make sure the readme instructions are correct and correct them if necessary (https://github.com/apache/incubator-wayang)
- give a pointer to these instructions in the Wayang website (https://wayang.apache.org/documentation/)
- improve the installation process so that it gets super simple to do by non-experts
- test all the benchmarks (https://github.com/apache/incubator-wayang/tree/main/wayang-benchmark) and write the instructions to run such benchmarks (this will be like the test of the Wayang installation)","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/282/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/282,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5Zz-on,incubator-wayang,1506798119,282,NA,zkaoudi,10105712,Zoi Kaoudi,,NA,2023-04-13T11:26:19Z,2023-04-13T11:26:19Z,"Just to make things more concrete: We need to separate between two things: 

1. Running Wayang after building it with maven.
- Improve instructions for building, if necessary
- Include scripts or instructions on how to execute an example and the benchmark tasks

2. Running Wayang after downloading the file from the downloads page. Current problems with this are:
- there is no wayang-submit script, in contrast to what is written in the README
- The file from the download page is a zip and the command indicated in the README assumes a .gz file
- The file linked in the download page is a source release. Is there somewhere a file with binaries only? If yes, we should point to that one. If not, we should create one.


","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5Zz-on/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/282,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5Z1itt,incubator-wayang,1507208045,282,NA,bgeng777,80749729,Biao Geng,,NA,2023-04-13T15:53:16Z,2023-04-13T15:53:16Z,"Hi there, thanks for creating this issue. I am new to wayang and when I tried to follow the current README to run the wordcount example, I met the problem that there is no wayang-submit script. 
I finally managed to run the example with wayang-submit and the process is as follows:
#### 1. Get the wayang-submit binary
As @zkaoudi mentioned, there is no wayang-submit binary file in the downloaded zip file. To get the binary, I build the main branch of the repo with `./mvnw clean install -DskipTests  ` and finally get the jar in the repo's `bin` folder:
![image](https://user-images.githubusercontent.com/80749729/231810865-45ab3141-5558-4d8e-8d74-ddea3b1c21a4.png)
#### 2. Copy the binary to extracted apache-wayang-0.6.0-incubating folder and relevant jars for the WordCount example
After copying wayang-submit to extracted apache-wayang-0.6.0-incubating folder, I tried to run command like `wayang-submit org.apache.wayang.apps.wordcount.Main java file://$(pwd)/README.md`, but I met many errors about class missing. 
After some debugging, I make dir named 'jars' under WAYANG_HOME (it looks like Wayang will add jars under WAYANG_HOME/jars into the classpath) and copied following jars from the project repo into it(these jars should be built or downloaded by maven after building the project).
![image](https://user-images.githubusercontent.com/80749729/231811530-0afcb611-ed00-43a1-81a6-89be1a60ed1e.png)
#### 3. Run `wayang-submit` with WordCount example
After step 1 and 2, I can run:
```
wayang-submit org.apache.wayang.apps.wordcount.Main java file://$(pwd)/README.md
```
and get the output:
![image](https://user-images.githubusercontent.com/80749729/231813486-ee7eedf0-6d5e-4c17-bde1-91354c9ee509.png)


So according to my experience, I believe there are at least 3 more things we may need to take care:
1. Add necessary jars into the released package
2. Avoid printing some meaningless info in the terminal like:
![image](https://user-images.githubusercontent.com/80749729/231814329-0c177e54-f896-4539-a46a-3ef93823a714.png)
3. We may need to get rid of `aws-java-sdk-bundle-1.11.271.jar` dependency when running locally.

I hope my experience can help others who just want to give a try on the quickstart and I am willing to help to make this process more smooth and user-friendly.
","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5Z1itt/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/282,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5Z2syA,incubator-wayang,1507511424,282,NA,zkaoudi,10105712,Zoi Kaoudi,,NA,2023-04-13T19:35:03Z,2023-04-13T19:35:03Z,"That is great. Just a question:
At which point you get all this meaningless info in the terminal? When running in the WordCount?","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5Z2syA/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/282,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5Z4A2Q,incubator-wayang,1507855760,282,NA,bgeng777,80749729,Biao Geng,,NA,2023-04-14T02:50:39Z,2023-04-14T02:50:39Z,"@zkaoudi You are right that the ""meaningless"" info(maybe jars under some classpath) is printed after I type command like `wayang-submit org.apache.wayang.apps.wordcount.Main java file://$(pwd)/README.md`. Also, I can see some output that alerts me that there are no jars/lib directories under WAYANG_HOME. I have not gave a deep look at the source code and am not so sure if they are relevant.","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5Z4A2Q/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/282,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5adxmg,incubator-wayang,1517754784,282,NA,zkaoudi,10105712,Zoi Kaoudi,,NA,2023-04-21T12:24:37Z,2023-04-21T12:24:37Z,I believe this issue has now been addressed. Thanks @bgeng777!,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5adxmg/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/283,https://api.github.com/repos/apache/incubator-wayang/issues/283,incubator-wayang,1666249320,283,Code restructure,zkaoudi,10105712,Zoi Kaoudi,,OPEN,2023-04-13T11:38:28Z,2024-01-10T08:43:22Z,"Currently, there are some modules that the source code is not in the usual path of ""[module_name]/src/main/java"" but inside a ""code"" folder. This is not the case for all modules. We should restructure the code to be as it is done usually: ""[module_name]/src/main/java""

NOTE: It seems that this ""code"" folder was created because of some incompatibility with GraphChi and the java/scala versions. So we may have to discard GraphChi","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/283/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/283,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5Z5kmG,incubator-wayang,1508264326,283,NA,2pk03,1323575,Alexander Alten-Lorenz,,NA,2023-04-14T10:01:34Z,2023-04-14T10:01:34Z,+1 to retire GraphChi. We should also consider retiring Java 8 support.,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5Z5kmG/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/283,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5ai3TW,incubator-wayang,1519088854,283,NA,bgeng777,80749729,Biao Geng,,NA,2023-04-23T15:06:42Z,2023-04-23T15:06:42Z,"+1 for the restructure and retire GraphChi. If we want to take a further step after removing GraphChi, it is worthwhile to consider retiring Scala2.11 as well. 
The underlying engines have done such removal:
Spark dropped Scala2.11 since Spark3.0. See [here](https://issues.apache.org/jira/browse/SPARK-26132)
Flink dropped Scala2.11 since Flink1.15. See [here](https://issues.apache.org/jira/browse/FLINK-20845)
It can reduce matainers' bandwidth on different scala version. Feel free to correct me if I miss some potential dependency on Scala2.11 in Wayang. :)","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5ai3TW/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/283,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5ai3Zl,incubator-wayang,1519089253,283,NA,2pk03,1323575,Alexander Alten-Lorenz,,NA,2023-04-23T15:08:23Z,2023-04-23T15:08:23Z,+1 ,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5ai3Zl/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/283,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5dxr2e,incubator-wayang,1573305758,283,NA,,,,,NA,2023-06-02T07:48:34Z,2023-06-02T07:48:34Z,"One reason the ../code/.. directories exist is to avoid multiple Scala versions deps within the same project. So If it is needed to support multiple versions, maybe a strategy like 1 branch/version would be a good idea to avoid code duplication due to deps with different versions.","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5dxr2e/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/283,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5trmHe,incubator-wayang,1840144862,283,NA,2pk03,1323575,Alexander Alten-Lorenz,,NA,2023-12-05T07:24:11Z,2023-12-05T07:24:11Z,bump,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5trmHe/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/283,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5trtFQ,incubator-wayang,1840173392,283,NA,zkaoudi,10105712,Zoi Kaoudi,,NA,2023-12-05T07:44:39Z,2023-12-05T07:44:39Z,What about retiring scala 2.11?,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5trtFQ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/283,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5tryzH,incubator-wayang,1840196807,283,NA,kbeedkar,8502905,Kaustubh Beedkar,,NA,2023-12-05T07:57:48Z,2023-12-05T07:57:48Z,+1,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5tryzH/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/283,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5wUCj1,incubator-wayang,1884301557,283,NA,juripetersen,43411515,Juri Petersen,,NA,2024-01-10T07:09:03Z,2024-01-10T07:09:03Z,I will take care of implementing the restructure of this issue.,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5wUCj1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/283,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5wUdso,incubator-wayang,1884412712,283,NA,zkaoudi,10105712,Zoi Kaoudi,,NA,2024-01-10T08:43:21Z,2024-01-10T08:43:21Z,Great! Thanks Juri! ,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5wUdso/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/285,https://api.github.com/repos/apache/incubator-wayang/issues/285,incubator-wayang,1669789084,285,create a map with specific dataset type,github-actions,,,,OPEN,2023-04-16T08:50:01Z,2023-04-16T08:50:02Z,"create a map with specific dataset type

https://github.com/apache/incubator-wayang/blob/d46f3c3f0fb963c2ee2640f00a106042fba55431/wayang-api/wayang-api-sql/src/main/java/org/apache/wayang/api/sql/calcite/converter/WayangProjectVisitor.java#L54

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package org.apache.wayang.api.sql.calcite.converter;

import org.apache.calcite.rel.core.Project;
import org.apache.calcite.rel.type.RelDataType;
import org.apache.calcite.rel.type.RelDataTypeField;
import org.apache.calcite.rex.RexInputRef;
import org.apache.calcite.rex.RexNode;
import org.apache.wayang.api.sql.calcite.rel.WayangProject;
import org.apache.wayang.basic.data.Record;
import org.apache.wayang.basic.operators.MapOperator;
import org.apache.wayang.core.function.FunctionDescriptor;
import org.apache.wayang.core.plan.wayangplan.Operator;

import java.util.ArrayList;
import java.util.List;

public class WayangProjectVisitor extends WayangRelNodeVisitor<WayangProject> {
    WayangProjectVisitor(WayangRelConverter wayangRelConverter) {
        super(wayangRelConverter);
    }

    @Override
    Operator visit(WayangProject wayangRelNode) {

        Operator childOp = wayangRelConverter.convert(wayangRelNode.getInput(0));

        /* Quick check */
        List<RexNode> projects = ((Project) wayangRelNode).getProjects();
        for(RexNode rexNode : projects) {
            if (!(rexNode instanceof RexInputRef)) {
                throw new IllegalStateException(""Generalized Projections not supported yet"");
            }
        }

        //TODO: create a map with specific dataset type
        MapOperator<Record, Record> projection = new MapOperator(
                new MapFunctionImpl(projects),
                Record.class,
                Record.class);

        childOp.connectTo(0, projection, 0);

        return projection;
    }


    private class MapFunctionImpl implements
            FunctionDescriptor.SerializableFunction<Record, Record> {

        private final int[] fields;

        private MapFunctionImpl(int[] fields) {
            this. fields = fields;
        }

        private MapFunctionImpl(List<RexNode> projects) {
            this(getProjectFields(projects));
        }

        @Override
        public Record apply(Record record) {

            List<Object> projectedRecord = new ArrayList<>();
            for(int field : fields) {
                projectedRecord.add(record.getField(field));
            }

            return new Record(projectedRecord.toArray(new Object[0]));
        }
    }

    private static int[] getProjectFields(List<RexNode> projects) {
        final int[] fields = new int[projects.size()];
        for (int i = 0; i < projects.size(); i++) {
            final RexNode exp = projects.get(i);
            if (exp instanceof RexInputRef) {
                fields[i] = ((RexInputRef) exp).getIndex();
            } else {
                return null; // not a simple projection
            }
        }
        return fields;
    }
}

```

17020a1705b3f23ce8e4515424eb3397d5f2876c","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/285/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/286,https://api.github.com/repos/apache/incubator-wayang/issues/286,incubator-wayang,1669789098,286,resolve table source to platform specific source,github-actions,,,,CLOSED,2023-04-16T08:50:04Z,2023-04-26T15:09:00Z,"resolve table source to platform specific source

https://github.com/apache/incubator-wayang/blob/d46f3c3f0fb963c2ee2640f00a106042fba55431/wayang-api/wayang-api-sql/src/main/java/org/apache/wayang/api/sql/calcite/converter/WayangTableScanVisitor.java#L49

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.sql.calcite.converter;

import org.apache.calcite.rel.type.RelDataType;
import org.apache.calcite.rel.type.RelDataTypeField;
import org.apache.wayang.api.sql.calcite.rel.WayangTableScan;
import org.apache.wayang.api.sql.sources.fs.JavaCSVTableSource;
import org.apache.wayang.basic.data.Record;
import org.apache.wayang.basic.operators.TableSource;
import org.apache.wayang.basic.operators.TextFileSource;
import org.apache.wayang.core.plan.wayangplan.Operator;
import org.apache.wayang.core.types.DataSetType;
import org.apache.wayang.postgres.Postgres;
import org.apache.wayang.postgres.operators.PostgresTableSource;
import org.apache.wayang.postgres.platform.PostgresPlatform;

import java.util.ArrayList;
import java.util.List;

public class WayangTableScanVisitor extends WayangRelNodeVisitor<WayangTableScan> {
    WayangTableScanVisitor(WayangRelConverter wayangRelConverter) {
        super(wayangRelConverter);
    }

    @Override
    Operator visit(WayangTableScan wayangRelNode) {

        String tableName = wayangRelNode.getTableName();
        List<String> columnNames = wayangRelNode.getColumnNames();


        //TODO: resolve table source to platform specific source
        //TODO: create tablesource with column types


        RelDataType rowType = wayangRelNode.getRowType();

        List<RelDataType> fieldTypes = new ArrayList<>();

        for(RelDataTypeField field : rowType.getFieldList()) {
            fieldTypes.add(field.getType());
        }

        return new JavaCSVTableSource(""file:/data/Projects/databloom/test-data/orders.csv"",
                DataSetType.createDefault(Record.class),
                fieldTypes);

//        return new PostgresTableSource(tableName);

    }
}

```

cbceeab4c3c07be49e1a355dfbadef4aaebbcf88","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/286/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/286,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5a0BO4,incubator-wayang,1523585976,286,NA,github-actions,,,,NA,2023-04-26T15:08:59Z,2023-04-26T15:08:59Z,Closed in 388cce9f8955c4c2e8df7b4094e4a7416340754f,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5a0BO4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/287,https://api.github.com/repos/apache/incubator-wayang/issues/287,incubator-wayang,1669789121,287,create tablesource with column types,github-actions,,,,CLOSED,2023-04-16T08:50:06Z,2023-04-26T15:09:03Z,"create tablesource with column types

https://github.com/apache/incubator-wayang/blob/d46f3c3f0fb963c2ee2640f00a106042fba55431/wayang-api/wayang-api-sql/src/main/java/org/apache/wayang/api/sql/calcite/converter/WayangTableScanVisitor.java#L50

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.sql.calcite.converter;

import org.apache.calcite.rel.type.RelDataType;
import org.apache.calcite.rel.type.RelDataTypeField;
import org.apache.wayang.api.sql.calcite.rel.WayangTableScan;
import org.apache.wayang.api.sql.sources.fs.JavaCSVTableSource;
import org.apache.wayang.basic.data.Record;
import org.apache.wayang.basic.operators.TableSource;
import org.apache.wayang.basic.operators.TextFileSource;
import org.apache.wayang.core.plan.wayangplan.Operator;
import org.apache.wayang.core.types.DataSetType;
import org.apache.wayang.postgres.Postgres;
import org.apache.wayang.postgres.operators.PostgresTableSource;
import org.apache.wayang.postgres.platform.PostgresPlatform;

import java.util.ArrayList;
import java.util.List;

public class WayangTableScanVisitor extends WayangRelNodeVisitor<WayangTableScan> {
    WayangTableScanVisitor(WayangRelConverter wayangRelConverter) {
        super(wayangRelConverter);
    }

    @Override
    Operator visit(WayangTableScan wayangRelNode) {

        String tableName = wayangRelNode.getTableName();
        List<String> columnNames = wayangRelNode.getColumnNames();


        //TODO: resolve table source to platform specific source
        //TODO: create tablesource with column types


        RelDataType rowType = wayangRelNode.getRowType();

        List<RelDataType> fieldTypes = new ArrayList<>();

        for(RelDataTypeField field : rowType.getFieldList()) {
            fieldTypes.add(field.getType());
        }

        return new JavaCSVTableSource(""file:/data/Projects/databloom/test-data/orders.csv"",
                DataSetType.createDefault(Record.class),
                fieldTypes);

//        return new PostgresTableSource(tableName);

    }
}

```

fcd09a6e5e95ca23296fa19330ed08042c1f7177","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/287/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/287,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5a0BQq,incubator-wayang,1523586090,287,NA,github-actions,,,,NA,2023-04-26T15:09:02Z,2023-04-26T15:09:02Z,Closed in 388cce9f8955c4c2e8df7b4094e4a7416340754f,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5a0BQq/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/289,https://api.github.com/repos/apache/incubator-wayang/issues/289,incubator-wayang,1669789133,289,populate map from JDBC metadata,github-actions,,,,CLOSED,2023-04-16T08:50:08Z,2023-07-20T15:03:48Z,"populate map from JDBC metadata

returned by Phoenix among others, maps to TableType.SYSTEM_TABLE.

We know enum constants are upper-case without spaces, so we can't

make things worse.

This can happen if you start JdbcSchema off a ""public"" PG schema

The tables are not designed to be queried by users, however we do

not filter them as we keep all the other table types.

object, hence try to get it from there if it was not specified by user

because we're creating a proto-type, not a type; before being used, the

proto-type will be copied into a real type factory.

scale = resultSet.getInt(9); // SCALE

""INTEGER"".

that we need to re-build our own cache.

https://github.com/apache/incubator-wayang/blob/d46f3c3f0fb963c2ee2640f00a106042fba55431/wayang-api/wayang-api-sql/src/main/java/org/apache/wayang/api/sql/calcite/jdbc/JdbcSchema.java#L212

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to you under the Apache License, Version 2.0
 * (the ""License""); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.wayang.api.sql.calcite.jdbc;

import com.google.common.collect.*;
import org.apache.calcite.adapter.jdbc.JdbcConvention;
//import org.apache.calcite.adapter.jdbc.JdbcTable;
//import org.apache.calcite.adapter.jdbc.JdbcUtils;
import org.apache.calcite.avatica.AvaticaUtils;
import org.apache.calcite.avatica.MetaImpl;
import org.apache.calcite.avatica.SqlType;
import org.apache.calcite.linq4j.function.Experimental;
import org.apache.calcite.linq4j.tree.Expression;
import org.apache.calcite.rel.type.*;
import org.apache.calcite.schema.Table;
import org.apache.calcite.schema.*;
import org.apache.calcite.sql.SqlDialect;
import org.apache.calcite.sql.SqlDialectFactory;
import org.apache.calcite.sql.SqlDialectFactoryImpl;
import org.apache.calcite.sql.type.SqlTypeFactoryImpl;
import org.apache.calcite.sql.type.SqlTypeName;
import org.apache.calcite.util.Pair;
import org.apache.calcite.util.Util;
import org.checkerframework.checker.nullness.qual.Nullable;

import javax.sql.DataSource;
import java.sql.*;
import java.util.*;
import java.util.function.BiFunction;

import static java.util.Objects.requireNonNull;

/**
 * Implementation of {@link Schema} that is backed by a JDBC data source.
 *
 * <p>The tables in the JDBC data source appear to be tables in this schema;
 * queries against this schema are executed against those tables, pushing down
 * as much as possible of the query logic to SQL.</p>
 */
public class JdbcSchema implements Schema {
  final DataSource dataSource;
  final @Nullable String catalog;
  final @Nullable String schema;
  public final SqlDialect dialect;
  final JdbcConvention convention;
  private @Nullable ImmutableMap<String, JdbcTable> tableMap;
  private final boolean snapshot;

  @Experimental
  public static final ThreadLocal<@Nullable Foo> THREAD_METADATA = new ThreadLocal<>();

  private static final Ordering<Iterable<Integer>> VERSION_ORDERING =
      Ordering.<Integer>natural().lexicographical();

  /**
   * Creates a JDBC schema.
   *
   * @param dataSource Data source
   * @param dialect SQL dialect
   * @param convention Calling convention
   * @param catalog Catalog name, or null
   * @param schema Schema name pattern
   */
  public JdbcSchema(DataSource dataSource, SqlDialect dialect,
                    JdbcConvention convention, @Nullable String catalog, @Nullable String schema) {
    this(dataSource, dialect, convention, catalog, schema, null);
  }

  private JdbcSchema(DataSource dataSource, SqlDialect dialect,
                     JdbcConvention convention, @Nullable String catalog, @Nullable String schema,
                     @Nullable ImmutableMap<String, JdbcTable> tableMap) {
    this.dataSource = requireNonNull(dataSource, ""dataSource"");
    this.dialect = requireNonNull(dialect, ""dialect"");
    this.convention = convention;
    this.catalog = catalog;
    this.schema = schema;
    this.tableMap = tableMap;
    this.snapshot = tableMap != null;
  }

  public static JdbcSchema create(
      SchemaPlus parentSchema,
      String name,
      DataSource dataSource,
      @Nullable String catalog,
      @Nullable String schema) {
    return create(parentSchema, name, dataSource,
        SqlDialectFactoryImpl.INSTANCE, catalog, schema);
  }

  public static JdbcSchema create(
      SchemaPlus parentSchema,
      String name,
      DataSource dataSource,
      SqlDialectFactory dialectFactory,
      @Nullable String catalog,
      @Nullable String schema) {
    final Expression expression =
        Schemas.subSchemaExpression(parentSchema, name, JdbcSchema.class);
    final SqlDialect dialect = createDialect(dialectFactory, dataSource);
    final JdbcConvention convention =
        JdbcConvention.of(dialect, expression, name);
    return new JdbcSchema(dataSource, dialect, convention, catalog, schema);
  }

  /**
   * Creates a JdbcSchema, taking credentials from a map.
   *
   * @param parentSchema Parent schema
   * @param name Name
   * @param operand Map of property/value pairs
   * @return A JdbcSchema
   */
  public static JdbcSchema create(
      SchemaPlus parentSchema,
      String name,
      Map<String, Object> operand) {
    DataSource dataSource;
    try {
      final String dataSourceName = (String) operand.get(""dataSource"");
      if (dataSourceName != null) {
        dataSource =
            AvaticaUtils.instantiatePlugin(DataSource.class, dataSourceName);
      } else {
        final String jdbcUrl = (String) requireNonNull(operand.get(""jdbcUrl""), ""jdbcUrl"");
        final String jdbcDriver = (String) operand.get(""jdbcDriver"");
        final String jdbcUser = (String) operand.get(""jdbcUser"");
        final String jdbcPassword = (String) operand.get(""jdbcPassword"");
        dataSource = dataSource(jdbcUrl, jdbcDriver, jdbcUser, jdbcPassword);
      }
    } catch (Exception e) {
      throw new RuntimeException(""Error while reading dataSource"", e);
    }
    String jdbcCatalog = (String) operand.get(""jdbcCatalog"");
    String jdbcSchema = (String) operand.get(""jdbcSchema"");
    String sqlDialectFactory = (String) operand.get(""sqlDialectFactory"");

    if (sqlDialectFactory == null || sqlDialectFactory.isEmpty()) {
      return JdbcSchema.create(
          parentSchema, name, dataSource, jdbcCatalog, jdbcSchema);
    } else {
      SqlDialectFactory factory = AvaticaUtils.instantiatePlugin(
          SqlDialectFactory.class, sqlDialectFactory);
      return JdbcSchema.create(
          parentSchema, name, dataSource, factory, jdbcCatalog, jdbcSchema);
    }
  }

  /**
   * Returns a suitable SQL dialect for the given data source.
   *
   * @param dataSource The data source
   *
   * @deprecated Use {@link #createDialect(SqlDialectFactory, DataSource)} instead
   */
  @Deprecated // to be removed before 2.0
  public static SqlDialect createDialect(DataSource dataSource) {
    return createDialect(SqlDialectFactoryImpl.INSTANCE, dataSource);
  }

  /** Returns a suitable SQL dialect for the given data source. */
  public static SqlDialect createDialect(SqlDialectFactory dialectFactory,
                                         DataSource dataSource) {
    return JdbcUtils.DialectPool.INSTANCE.get(dialectFactory, dataSource);
  }

  /** Creates a JDBC data source with the given specification. */
  public static DataSource dataSource(String url, @Nullable String driverClassName,
                                      @Nullable String username, @Nullable String password) {
    if (url.startsWith(""jdbc:hsqldb:"")) {
      // Prevent hsqldb from screwing up java.util.logging.
      System.setProperty(""hsqldb.reconfig_logging"", ""false"");
    }
    return JdbcUtils.DataSourcePool.INSTANCE.get(url, driverClassName, username,
        password);
  }

  @Override public boolean isMutable() {
    return false;
  }

  @Override public Schema snapshot(SchemaVersion version) {
    return new JdbcSchema(dataSource, dialect, convention, catalog, schema,
        tableMap);
  }

  // Used by generated code.
  public DataSource getDataSource() {
    return dataSource;
  }

  @Override public Expression getExpression(@Nullable SchemaPlus parentSchema, String name) {
    requireNonNull(parentSchema, ""parentSchema must not be null for JdbcSchema"");
    return Schemas.subSchemaExpression(parentSchema, name, JdbcSchema.class);
  }

  protected Multimap<String, Function> getFunctions() {
    // TODO: populate map from JDBC metadata
    return ImmutableMultimap.of();
  }

  @Override public final Collection<Function> getFunctions(String name) {
    return getFunctions().get(name); // never null
  }

  @Override public final Set<String> getFunctionNames() {
    return getFunctions().keySet();
  }

  private ImmutableMap<String, JdbcTable> computeTables() {
    Connection connection = null;
    ResultSet resultSet = null;
    try {
      connection = dataSource.getConnection();
      final Pair<@Nullable String, @Nullable String> catalogSchema = getCatalogSchema(connection);
      final String catalog = catalogSchema.left;
      final String schema = catalogSchema.right;
      final Iterable<MetaImpl.MetaTable> tableDefs;
      Foo threadMetadata = THREAD_METADATA.get();
      if (threadMetadata != null) {
        tableDefs = threadMetadata.apply(catalog, schema);
      } else {
        final List<MetaImpl.MetaTable> tableDefList = new ArrayList<>();
        final DatabaseMetaData metaData = connection.getMetaData();
        resultSet = metaData.getTables(catalog, schema, null, null);
        while (resultSet.next()) {
          final String catalogName = resultSet.getString(1);
          final String schemaName = resultSet.getString(2);
          final String tableName = resultSet.getString(3);
          final String tableTypeName = resultSet.getString(4);
          tableDefList.add(
              new MetaImpl.MetaTable(catalogName, schemaName, tableName,
                  tableTypeName));
        }
        tableDefs = tableDefList;
      }

      final ImmutableMap.Builder<String, JdbcTable> builder =
          ImmutableMap.builder();
      for (MetaImpl.MetaTable tableDef : tableDefs) {
        // Clean up table type. In particular, this ensures that 'SYSTEM TABLE',
        // returned by Phoenix among others, maps to TableType.SYSTEM_TABLE.
        // We know enum constants are upper-case without spaces, so we can't
        // make things worse.
        //
        // PostgreSQL returns tableTypeName==null for pg_toast* tables
        // This can happen if you start JdbcSchema off a ""public"" PG schema
        // The tables are not designed to be queried by users, however we do
        // not filter them as we keep all the other table types.
        final String tableTypeName2 =
            tableDef.tableType == null
            ? null
            : tableDef.tableType.toUpperCase(Locale.ROOT).replace(' ', '_');
        final TableType tableType =
            Util.enumVal(TableType.OTHER, tableTypeName2);
        if (tableType == TableType.OTHER  && tableTypeName2 != null) {
          System.out.println(""Unknown table type: "" + tableTypeName2);
        }
        final JdbcTable table =
            new JdbcTable(this, tableDef.tableCat, tableDef.tableSchem,
                tableDef.tableName, tableType);
        builder.put(tableDef.tableName, table);
      }
      return builder.build();
    } catch (SQLException e) {
      throw new RuntimeException(
          ""Exception while reading tables"", e);
    } finally {
      close(connection, null, resultSet);
    }
  }

  /** Returns [major, minor] version from a database metadata. */
  private static List<Integer> version(DatabaseMetaData metaData) throws SQLException {
    return ImmutableList.of(metaData.getJDBCMajorVersion(),
        metaData.getJDBCMinorVersion());
  }

  /** Returns a pair of (catalog, schema) for the current connection. */
  private Pair<@Nullable String, @Nullable String> getCatalogSchema(Connection connection)
      throws SQLException {
    final DatabaseMetaData metaData = connection.getMetaData();
    final List<Integer> version41 = ImmutableList.of(4, 1); // JDBC 4.1
    String catalog = this.catalog;
    String schema = this.schema;
    final boolean jdbc41OrAbove =
        VERSION_ORDERING.compare(version(metaData), version41) >= 0;
    if (catalog == null && jdbc41OrAbove) {
      // From JDBC 4.1, catalog and schema can be retrieved from the connection
      // object, hence try to get it from there if it was not specified by user
      catalog = connection.getCatalog();
    }
    if (schema == null && jdbc41OrAbove) {
      schema = connection.getSchema();
      if ("""".equals(schema)) {
        schema = null; // PostgreSQL returns useless """" sometimes
      }
    }
    if ((catalog == null || schema == null)
        && metaData.getDatabaseProductName().equals(""PostgreSQL"")) {
      final String sql = ""select current_database(), current_schema()"";
      try (Statement statement = connection.createStatement();
           ResultSet resultSet = statement.executeQuery(sql)) {
        if (resultSet.next()) {
          catalog = resultSet.getString(1);
          schema = resultSet.getString(2);
        }
      }
    }
    return Pair.of(catalog, schema);
  }

  @Override public @Nullable Table getTable(String name) {
    return getTableMap(false).get(name);
  }

  private synchronized ImmutableMap<String, JdbcTable> getTableMap(
      boolean force) {
    if (force || tableMap == null) {
      tableMap = computeTables();
    }
    return tableMap;
  }

  RelProtoDataType getRelDataType(String catalogName, String schemaName,
                                  String tableName) throws SQLException {
    Connection connection = null;
    try {
      connection = dataSource.getConnection();
      DatabaseMetaData metaData = connection.getMetaData();
      return getRelDataType(metaData, catalogName, schemaName, tableName);
    } finally {
      close(connection, null, null);
    }
  }

  RelProtoDataType getRelDataType(DatabaseMetaData metaData, String catalogName,
                                  String schemaName, String tableName) throws SQLException {
    final ResultSet resultSet =
        metaData.getColumns(catalogName, schemaName, tableName, null);

    // Temporary type factory, just for the duration of this method. Allowable
    // because we're creating a proto-type, not a type; before being used, the
    // proto-type will be copied into a real type factory.
    final RelDataTypeFactory typeFactory =
        new SqlTypeFactoryImpl(RelDataTypeSystem.DEFAULT);
    final RelDataTypeFactory.Builder fieldInfo = typeFactory.builder();
    while (resultSet.next()) {
      final String columnName = requireNonNull(resultSet.getString(4), ""columnName"");
      final int dataType = resultSet.getInt(5);
      final String typeString = resultSet.getString(6);
      final int precision;
      final int scale;
      switch (SqlType.valueOf(dataType)) {
      case TIMESTAMP:
      case TIME:
        precision = resultSet.getInt(9); // SCALE
        scale = 0;
        break;
      default:
        precision = resultSet.getInt(7); // SIZE
        scale = resultSet.getInt(9); // SCALE
        break;
      }
      RelDataType sqlType =
          sqlType(typeFactory, dataType, precision, scale, typeString);
      boolean nullable = resultSet.getInt(11) != DatabaseMetaData.columnNoNulls;
      fieldInfo.add(columnName, sqlType).nullable(nullable);
    }
    resultSet.close();
    return RelDataTypeImpl.proto(fieldInfo.build());
  }

  private static RelDataType sqlType(RelDataTypeFactory typeFactory, int dataType,
                                     int precision, int scale, @Nullable String typeString) {
    // Fall back to ANY if type is unknown
    final SqlTypeName sqlTypeName =
        Util.first(SqlTypeName.getNameForJdbcType(dataType), SqlTypeName.ANY);
    switch (sqlTypeName) {
    case ARRAY:
      RelDataType component = null;
      if (typeString != null && typeString.endsWith("" ARRAY"")) {
        // E.g. hsqldb gives ""INTEGER ARRAY"", so we deduce the component type
        // ""INTEGER"".
        final String remaining = typeString.substring(0,
            typeString.length() - "" ARRAY"".length());
        component = parseTypeString(typeFactory, remaining);
      }
      if (component == null) {
        component = typeFactory.createTypeWithNullability(
            typeFactory.createSqlType(SqlTypeName.ANY), true);
      }
      return typeFactory.createArrayType(component, -1);
    default:
      break;
    }
    if (precision >= 0
        && scale >= 0
        && sqlTypeName.allowsPrecScale(true, true)) {
      return typeFactory.createSqlType(sqlTypeName, precision, scale);
    } else if (precision >= 0 && sqlTypeName.allowsPrecNoScale()) {
      return typeFactory.createSqlType(sqlTypeName, precision);
    } else {
      assert sqlTypeName.allowsNoPrecNoScale();
      return typeFactory.createSqlType(sqlTypeName);
    }
  }

  /** Given ""INTEGER"", returns BasicSqlType(INTEGER).
   * Given ""VARCHAR(10)"", returns BasicSqlType(VARCHAR, 10).
   * Given ""NUMERIC(10, 2)"", returns BasicSqlType(NUMERIC, 10, 2). */
  private static RelDataType parseTypeString(RelDataTypeFactory typeFactory,
                                             String typeString) {
    int precision = -1;
    int scale = -1;
    int open = typeString.indexOf(""("");
    if (open >= 0) {
      int close = typeString.indexOf("")"", open);
      if (close >= 0) {
        String rest = typeString.substring(open + 1, close);
        typeString = typeString.substring(0, open);
        int comma = rest.indexOf("","");
        if (comma >= 0) {
          precision = Integer.parseInt(rest.substring(0, comma));
          scale = Integer.parseInt(rest.substring(comma));
        } else {
          precision = Integer.parseInt(rest);
        }
      }
    }
    try {
      final SqlTypeName typeName = SqlTypeName.valueOf(typeString);
      return typeName.allowsPrecScale(true, true)
          ? typeFactory.createSqlType(typeName, precision, scale)
          : typeName.allowsPrecScale(true, false)
          ? typeFactory.createSqlType(typeName, precision)
          : typeFactory.createSqlType(typeName);
    } catch (IllegalArgumentException e) {
      return typeFactory.createTypeWithNullability(
          typeFactory.createSqlType(SqlTypeName.ANY), true);
    }
  }

  @Override public Set<String> getTableNames() {
    // This method is called during a cache refresh. We can take it as a signal
    // that we need to re-build our own cache.
    return getTableMap(!snapshot).keySet();
  }

  protected Map<String, RelProtoDataType> getTypes() {
    // TODO: populate map from JDBC metadata
    return ImmutableMap.of();
  }

  @Override public @Nullable RelProtoDataType getType(String name) {
    return getTypes().get(name);
  }

  @Override public Set<String> getTypeNames() {
    //noinspection RedundantCast
    return (Set<String>) getTypes().keySet();
  }

  @Override public @Nullable Schema getSubSchema(String name) {
    // JDBC does not support sub-schemas.
    return null;
  }

  @Override public Set<String> getSubSchemaNames() {
    return ImmutableSet.of();
  }

  private static void close(
      @Nullable Connection connection,
      @Nullable Statement statement,
      @Nullable ResultSet resultSet) {
    if (resultSet != null) {
      try {
        resultSet.close();
      } catch (SQLException e) {
        // ignore
      }
    }
    if (statement != null) {
      try {
        statement.close();
      } catch (SQLException e) {
        // ignore
      }
    }
    if (connection != null) {
      try {
        connection.close();
      } catch (SQLException e) {
        // ignore
      }
    }
  }

  /** Schema factory that creates a
   * {@link org.apache.calcite.adapter.jdbc.JdbcSchema}.
   *
   * <p>This allows you to create a jdbc schema inside a model.json file, like
   * this:
   *
   * <blockquote><pre>
   * {
   *   ""version"": ""1.0"",
   *   ""defaultSchema"": ""FOODMART_CLONE"",
   *   ""schemas"": [
   *     {
   *       ""name"": ""FOODMART_CLONE"",
   *       ""type"": ""custom"",
   *       ""factory"": ""org.apache.calcite.adapter.jdbc.JdbcSchema$Factory"",
   *       ""operand"": {
   *         ""jdbcDriver"": ""com.mysql.jdbc.Driver"",
   *         ""jdbcUrl"": ""jdbc:mysql://localhost/foodmart"",
   *         ""jdbcUser"": ""foodmart"",
   *         ""jdbcPassword"": ""foodmart""
   *       }
   *     }
   *   ]
   * }</pre></blockquote>
   */
  public static class Factory implements SchemaFactory {
    public static final Factory INSTANCE = new Factory();

    private Factory() {}

    @Override public Schema create(
        SchemaPlus parentSchema,
        String name,
        Map<String, Object> operand) {
      return JdbcSchema.create(parentSchema, name, operand);
    }
  }

  /** Do not use. */
  @Experimental
  public interface Foo
      extends BiFunction<@Nullable String, @Nullable String, Iterable<MetaImpl.MetaTable>> {
  }
}

```

2f37169e47fa9738117d3c8fcdc68b5fb2db218e","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/289/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/290,https://api.github.com/repos/apache/incubator-wayang/issues/290,incubator-wayang,1669789142,290,populate map from JDBC metadata,github-actions,,,,OPEN,2023-04-16T08:50:10Z,2023-04-16T08:50:11Z,"populate map from JDBC metadata

https://github.com/apache/incubator-wayang/blob/d46f3c3f0fb963c2ee2640f00a106042fba55431/wayang-api/wayang-api-sql/src/main/java/org/apache/wayang/api/sql/calcite/jdbc/JdbcSchema.java#L212

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to you under the Apache License, Version 2.0
 * (the ""License""); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.wayang.api.sql.calcite.jdbc;

import com.google.common.collect.*;
import org.apache.calcite.adapter.jdbc.JdbcConvention;
//import org.apache.calcite.adapter.jdbc.JdbcTable;
//import org.apache.calcite.adapter.jdbc.JdbcUtils;
import org.apache.calcite.avatica.AvaticaUtils;
import org.apache.calcite.avatica.MetaImpl;
import org.apache.calcite.avatica.SqlType;
import org.apache.calcite.linq4j.function.Experimental;
import org.apache.calcite.linq4j.tree.Expression;
import org.apache.calcite.rel.type.*;
import org.apache.calcite.schema.Table;
import org.apache.calcite.schema.*;
import org.apache.calcite.sql.SqlDialect;
import org.apache.calcite.sql.SqlDialectFactory;
import org.apache.calcite.sql.SqlDialectFactoryImpl;
import org.apache.calcite.sql.type.SqlTypeFactoryImpl;
import org.apache.calcite.sql.type.SqlTypeName;
import org.apache.calcite.util.Pair;
import org.apache.calcite.util.Util;
import org.checkerframework.checker.nullness.qual.Nullable;

import javax.sql.DataSource;
import java.sql.*;
import java.util.*;
import java.util.function.BiFunction;

import static java.util.Objects.requireNonNull;

/**
 * Implementation of {@link Schema} that is backed by a JDBC data source.
 *
 * <p>The tables in the JDBC data source appear to be tables in this schema;
 * queries against this schema are executed against those tables, pushing down
 * as much as possible of the query logic to SQL.</p>
 */
public class JdbcSchema implements Schema {
  final DataSource dataSource;
  final @Nullable String catalog;
  final @Nullable String schema;
  public final SqlDialect dialect;
  final JdbcConvention convention;
  private @Nullable ImmutableMap<String, JdbcTable> tableMap;
  private final boolean snapshot;

  @Experimental
  public static final ThreadLocal<@Nullable Foo> THREAD_METADATA = new ThreadLocal<>();

  private static final Ordering<Iterable<Integer>> VERSION_ORDERING =
      Ordering.<Integer>natural().lexicographical();

  /**
   * Creates a JDBC schema.
   *
   * @param dataSource Data source
   * @param dialect SQL dialect
   * @param convention Calling convention
   * @param catalog Catalog name, or null
   * @param schema Schema name pattern
   */
  public JdbcSchema(DataSource dataSource, SqlDialect dialect,
                    JdbcConvention convention, @Nullable String catalog, @Nullable String schema) {
    this(dataSource, dialect, convention, catalog, schema, null);
  }

  private JdbcSchema(DataSource dataSource, SqlDialect dialect,
                     JdbcConvention convention, @Nullable String catalog, @Nullable String schema,
                     @Nullable ImmutableMap<String, JdbcTable> tableMap) {
    this.dataSource = requireNonNull(dataSource, ""dataSource"");
    this.dialect = requireNonNull(dialect, ""dialect"");
    this.convention = convention;
    this.catalog = catalog;
    this.schema = schema;
    this.tableMap = tableMap;
    this.snapshot = tableMap != null;
  }

  public static JdbcSchema create(
      SchemaPlus parentSchema,
      String name,
      DataSource dataSource,
      @Nullable String catalog,
      @Nullable String schema) {
    return create(parentSchema, name, dataSource,
        SqlDialectFactoryImpl.INSTANCE, catalog, schema);
  }

  public static JdbcSchema create(
      SchemaPlus parentSchema,
      String name,
      DataSource dataSource,
      SqlDialectFactory dialectFactory,
      @Nullable String catalog,
      @Nullable String schema) {
    final Expression expression =
        Schemas.subSchemaExpression(parentSchema, name, JdbcSchema.class);
    final SqlDialect dialect = createDialect(dialectFactory, dataSource);
    final JdbcConvention convention =
        JdbcConvention.of(dialect, expression, name);
    return new JdbcSchema(dataSource, dialect, convention, catalog, schema);
  }

  /**
   * Creates a JdbcSchema, taking credentials from a map.
   *
   * @param parentSchema Parent schema
   * @param name Name
   * @param operand Map of property/value pairs
   * @return A JdbcSchema
   */
  public static JdbcSchema create(
      SchemaPlus parentSchema,
      String name,
      Map<String, Object> operand) {
    DataSource dataSource;
    try {
      final String dataSourceName = (String) operand.get(""dataSource"");
      if (dataSourceName != null) {
        dataSource =
            AvaticaUtils.instantiatePlugin(DataSource.class, dataSourceName);
      } else {
        final String jdbcUrl = (String) requireNonNull(operand.get(""jdbcUrl""), ""jdbcUrl"");
        final String jdbcDriver = (String) operand.get(""jdbcDriver"");
        final String jdbcUser = (String) operand.get(""jdbcUser"");
        final String jdbcPassword = (String) operand.get(""jdbcPassword"");
        dataSource = dataSource(jdbcUrl, jdbcDriver, jdbcUser, jdbcPassword);
      }
    } catch (Exception e) {
      throw new RuntimeException(""Error while reading dataSource"", e);
    }
    String jdbcCatalog = (String) operand.get(""jdbcCatalog"");
    String jdbcSchema = (String) operand.get(""jdbcSchema"");
    String sqlDialectFactory = (String) operand.get(""sqlDialectFactory"");

    if (sqlDialectFactory == null || sqlDialectFactory.isEmpty()) {
      return JdbcSchema.create(
          parentSchema, name, dataSource, jdbcCatalog, jdbcSchema);
    } else {
      SqlDialectFactory factory = AvaticaUtils.instantiatePlugin(
          SqlDialectFactory.class, sqlDialectFactory);
      return JdbcSchema.create(
          parentSchema, name, dataSource, factory, jdbcCatalog, jdbcSchema);
    }
  }

  /**
   * Returns a suitable SQL dialect for the given data source.
   *
   * @param dataSource The data source
   *
   * @deprecated Use {@link #createDialect(SqlDialectFactory, DataSource)} instead
   */
  @Deprecated // to be removed before 2.0
  public static SqlDialect createDialect(DataSource dataSource) {
    return createDialect(SqlDialectFactoryImpl.INSTANCE, dataSource);
  }

  /** Returns a suitable SQL dialect for the given data source. */
  public static SqlDialect createDialect(SqlDialectFactory dialectFactory,
                                         DataSource dataSource) {
    return JdbcUtils.DialectPool.INSTANCE.get(dialectFactory, dataSource);
  }

  /** Creates a JDBC data source with the given specification. */
  public static DataSource dataSource(String url, @Nullable String driverClassName,
                                      @Nullable String username, @Nullable String password) {
    if (url.startsWith(""jdbc:hsqldb:"")) {
      // Prevent hsqldb from screwing up java.util.logging.
      System.setProperty(""hsqldb.reconfig_logging"", ""false"");
    }
    return JdbcUtils.DataSourcePool.INSTANCE.get(url, driverClassName, username,
        password);
  }

  @Override public boolean isMutable() {
    return false;
  }

  @Override public Schema snapshot(SchemaVersion version) {
    return new JdbcSchema(dataSource, dialect, convention, catalog, schema,
        tableMap);
  }

  // Used by generated code.
  public DataSource getDataSource() {
    return dataSource;
  }

  @Override public Expression getExpression(@Nullable SchemaPlus parentSchema, String name) {
    requireNonNull(parentSchema, ""parentSchema must not be null for JdbcSchema"");
    return Schemas.subSchemaExpression(parentSchema, name, JdbcSchema.class);
  }

  protected Multimap<String, Function> getFunctions() {
    // TODO: populate map from JDBC metadata
    return ImmutableMultimap.of();
  }

  @Override public final Collection<Function> getFunctions(String name) {
    return getFunctions().get(name); // never null
  }

  @Override public final Set<String> getFunctionNames() {
    return getFunctions().keySet();
  }

  private ImmutableMap<String, JdbcTable> computeTables() {
    Connection connection = null;
    ResultSet resultSet = null;
    try {
      connection = dataSource.getConnection();
      final Pair<@Nullable String, @Nullable String> catalogSchema = getCatalogSchema(connection);
      final String catalog = catalogSchema.left;
      final String schema = catalogSchema.right;
      final Iterable<MetaImpl.MetaTable> tableDefs;
      Foo threadMetadata = THREAD_METADATA.get();
      if (threadMetadata != null) {
        tableDefs = threadMetadata.apply(catalog, schema);
      } else {
        final List<MetaImpl.MetaTable> tableDefList = new ArrayList<>();
        final DatabaseMetaData metaData = connection.getMetaData();
        resultSet = metaData.getTables(catalog, schema, null, null);
        while (resultSet.next()) {
          final String catalogName = resultSet.getString(1);
          final String schemaName = resultSet.getString(2);
          final String tableName = resultSet.getString(3);
          final String tableTypeName = resultSet.getString(4);
          tableDefList.add(
              new MetaImpl.MetaTable(catalogName, schemaName, tableName,
                  tableTypeName));
        }
        tableDefs = tableDefList;
      }

      final ImmutableMap.Builder<String, JdbcTable> builder =
          ImmutableMap.builder();
      for (MetaImpl.MetaTable tableDef : tableDefs) {
        // Clean up table type. In particular, this ensures that 'SYSTEM TABLE',
        // returned by Phoenix among others, maps to TableType.SYSTEM_TABLE.
        // We know enum constants are upper-case without spaces, so we can't
        // make things worse.
        //
        // PostgreSQL returns tableTypeName==null for pg_toast* tables
        // This can happen if you start JdbcSchema off a ""public"" PG schema
        // The tables are not designed to be queried by users, however we do
        // not filter them as we keep all the other table types.
        final String tableTypeName2 =
            tableDef.tableType == null
            ? null
            : tableDef.tableType.toUpperCase(Locale.ROOT).replace(' ', '_');
        final TableType tableType =
            Util.enumVal(TableType.OTHER, tableTypeName2);
        if (tableType == TableType.OTHER  && tableTypeName2 != null) {
          System.out.println(""Unknown table type: "" + tableTypeName2);
        }
        final JdbcTable table =
            new JdbcTable(this, tableDef.tableCat, tableDef.tableSchem,
                tableDef.tableName, tableType);
        builder.put(tableDef.tableName, table);
      }
      return builder.build();
    } catch (SQLException e) {
      throw new RuntimeException(
          ""Exception while reading tables"", e);
    } finally {
      close(connection, null, resultSet);
    }
  }

  /** Returns [major, minor] version from a database metadata. */
  private static List<Integer> version(DatabaseMetaData metaData) throws SQLException {
    return ImmutableList.of(metaData.getJDBCMajorVersion(),
        metaData.getJDBCMinorVersion());
  }

  /** Returns a pair of (catalog, schema) for the current connection. */
  private Pair<@Nullable String, @Nullable String> getCatalogSchema(Connection connection)
      throws SQLException {
    final DatabaseMetaData metaData = connection.getMetaData();
    final List<Integer> version41 = ImmutableList.of(4, 1); // JDBC 4.1
    String catalog = this.catalog;
    String schema = this.schema;
    final boolean jdbc41OrAbove =
        VERSION_ORDERING.compare(version(metaData), version41) >= 0;
    if (catalog == null && jdbc41OrAbove) {
      // From JDBC 4.1, catalog and schema can be retrieved from the connection
      // object, hence try to get it from there if it was not specified by user
      catalog = connection.getCatalog();
    }
    if (schema == null && jdbc41OrAbove) {
      schema = connection.getSchema();
      if ("""".equals(schema)) {
        schema = null; // PostgreSQL returns useless """" sometimes
      }
    }
    if ((catalog == null || schema == null)
        && metaData.getDatabaseProductName().equals(""PostgreSQL"")) {
      final String sql = ""select current_database(), current_schema()"";
      try (Statement statement = connection.createStatement();
           ResultSet resultSet = statement.executeQuery(sql)) {
        if (resultSet.next()) {
          catalog = resultSet.getString(1);
          schema = resultSet.getString(2);
        }
      }
    }
    return Pair.of(catalog, schema);
  }

  @Override public @Nullable Table getTable(String name) {
    return getTableMap(false).get(name);
  }

  private synchronized ImmutableMap<String, JdbcTable> getTableMap(
      boolean force) {
    if (force || tableMap == null) {
      tableMap = computeTables();
    }
    return tableMap;
  }

  RelProtoDataType getRelDataType(String catalogName, String schemaName,
                                  String tableName) throws SQLException {
    Connection connection = null;
    try {
      connection = dataSource.getConnection();
      DatabaseMetaData metaData = connection.getMetaData();
      return getRelDataType(metaData, catalogName, schemaName, tableName);
    } finally {
      close(connection, null, null);
    }
  }

  RelProtoDataType getRelDataType(DatabaseMetaData metaData, String catalogName,
                                  String schemaName, String tableName) throws SQLException {
    final ResultSet resultSet =
        metaData.getColumns(catalogName, schemaName, tableName, null);

    // Temporary type factory, just for the duration of this method. Allowable
    // because we're creating a proto-type, not a type; before being used, the
    // proto-type will be copied into a real type factory.
    final RelDataTypeFactory typeFactory =
        new SqlTypeFactoryImpl(RelDataTypeSystem.DEFAULT);
    final RelDataTypeFactory.Builder fieldInfo = typeFactory.builder();
    while (resultSet.next()) {
      final String columnName = requireNonNull(resultSet.getString(4), ""columnName"");
      final int dataType = resultSet.getInt(5);
      final String typeString = resultSet.getString(6);
      final int precision;
      final int scale;
      switch (SqlType.valueOf(dataType)) {
      case TIMESTAMP:
      case TIME:
        precision = resultSet.getInt(9); // SCALE
        scale = 0;
        break;
      default:
        precision = resultSet.getInt(7); // SIZE
        scale = resultSet.getInt(9); // SCALE
        break;
      }
      RelDataType sqlType =
          sqlType(typeFactory, dataType, precision, scale, typeString);
      boolean nullable = resultSet.getInt(11) != DatabaseMetaData.columnNoNulls;
      fieldInfo.add(columnName, sqlType).nullable(nullable);
    }
    resultSet.close();
    return RelDataTypeImpl.proto(fieldInfo.build());
  }

  private static RelDataType sqlType(RelDataTypeFactory typeFactory, int dataType,
                                     int precision, int scale, @Nullable String typeString) {
    // Fall back to ANY if type is unknown
    final SqlTypeName sqlTypeName =
        Util.first(SqlTypeName.getNameForJdbcType(dataType), SqlTypeName.ANY);
    switch (sqlTypeName) {
    case ARRAY:
      RelDataType component = null;
      if (typeString != null && typeString.endsWith("" ARRAY"")) {
        // E.g. hsqldb gives ""INTEGER ARRAY"", so we deduce the component type
        // ""INTEGER"".
        final String remaining = typeString.substring(0,
            typeString.length() - "" ARRAY"".length());
        component = parseTypeString(typeFactory, remaining);
      }
      if (component == null) {
        component = typeFactory.createTypeWithNullability(
            typeFactory.createSqlType(SqlTypeName.ANY), true);
      }
      return typeFactory.createArrayType(component, -1);
    default:
      break;
    }
    if (precision >= 0
        && scale >= 0
        && sqlTypeName.allowsPrecScale(true, true)) {
      return typeFactory.createSqlType(sqlTypeName, precision, scale);
    } else if (precision >= 0 && sqlTypeName.allowsPrecNoScale()) {
      return typeFactory.createSqlType(sqlTypeName, precision);
    } else {
      assert sqlTypeName.allowsNoPrecNoScale();
      return typeFactory.createSqlType(sqlTypeName);
    }
  }

  /** Given ""INTEGER"", returns BasicSqlType(INTEGER).
   * Given ""VARCHAR(10)"", returns BasicSqlType(VARCHAR, 10).
   * Given ""NUMERIC(10, 2)"", returns BasicSqlType(NUMERIC, 10, 2). */
  private static RelDataType parseTypeString(RelDataTypeFactory typeFactory,
                                             String typeString) {
    int precision = -1;
    int scale = -1;
    int open = typeString.indexOf(""("");
    if (open >= 0) {
      int close = typeString.indexOf("")"", open);
      if (close >= 0) {
        String rest = typeString.substring(open + 1, close);
        typeString = typeString.substring(0, open);
        int comma = rest.indexOf("","");
        if (comma >= 0) {
          precision = Integer.parseInt(rest.substring(0, comma));
          scale = Integer.parseInt(rest.substring(comma));
        } else {
          precision = Integer.parseInt(rest);
        }
      }
    }
    try {
      final SqlTypeName typeName = SqlTypeName.valueOf(typeString);
      return typeName.allowsPrecScale(true, true)
          ? typeFactory.createSqlType(typeName, precision, scale)
          : typeName.allowsPrecScale(true, false)
          ? typeFactory.createSqlType(typeName, precision)
          : typeFactory.createSqlType(typeName);
    } catch (IllegalArgumentException e) {
      return typeFactory.createTypeWithNullability(
          typeFactory.createSqlType(SqlTypeName.ANY), true);
    }
  }

  @Override public Set<String> getTableNames() {
    // This method is called during a cache refresh. We can take it as a signal
    // that we need to re-build our own cache.
    return getTableMap(!snapshot).keySet();
  }

  protected Map<String, RelProtoDataType> getTypes() {
    // TODO: populate map from JDBC metadata
    return ImmutableMap.of();
  }

  @Override public @Nullable RelProtoDataType getType(String name) {
    return getTypes().get(name);
  }

  @Override public Set<String> getTypeNames() {
    //noinspection RedundantCast
    return (Set<String>) getTypes().keySet();
  }

  @Override public @Nullable Schema getSubSchema(String name) {
    // JDBC does not support sub-schemas.
    return null;
  }

  @Override public Set<String> getSubSchemaNames() {
    return ImmutableSet.of();
  }

  private static void close(
      @Nullable Connection connection,
      @Nullable Statement statement,
      @Nullable ResultSet resultSet) {
    if (resultSet != null) {
      try {
        resultSet.close();
      } catch (SQLException e) {
        // ignore
      }
    }
    if (statement != null) {
      try {
        statement.close();
      } catch (SQLException e) {
        // ignore
      }
    }
    if (connection != null) {
      try {
        connection.close();
      } catch (SQLException e) {
        // ignore
      }
    }
  }

  /** Schema factory that creates a
   * {@link org.apache.calcite.adapter.jdbc.JdbcSchema}.
   *
   * <p>This allows you to create a jdbc schema inside a model.json file, like
   * this:
   *
   * <blockquote><pre>
   * {
   *   ""version"": ""1.0"",
   *   ""defaultSchema"": ""FOODMART_CLONE"",
   *   ""schemas"": [
   *     {
   *       ""name"": ""FOODMART_CLONE"",
   *       ""type"": ""custom"",
   *       ""factory"": ""org.apache.calcite.adapter.jdbc.JdbcSchema$Factory"",
   *       ""operand"": {
   *         ""jdbcDriver"": ""com.mysql.jdbc.Driver"",
   *         ""jdbcUrl"": ""jdbc:mysql://localhost/foodmart"",
   *         ""jdbcUser"": ""foodmart"",
   *         ""jdbcPassword"": ""foodmart""
   *       }
   *     }
   *   ]
   * }</pre></blockquote>
   */
  public static class Factory implements SchemaFactory {
    public static final Factory INSTANCE = new Factory();

    private Factory() {}

    @Override public Schema create(
        SchemaPlus parentSchema,
        String name,
        Map<String, Object> operand) {
      return JdbcSchema.create(parentSchema, name, operand);
    }
  }

  /** Do not use. */
  @Experimental
  public interface Foo
      extends BiFunction<@Nullable String, @Nullable String, Iterable<MetaImpl.MetaTable>> {
  }
}

```

5252d68c2aa25243b0fccde1af5f960246deadc1","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/290/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/291,https://api.github.com/repos/apache/incubator-wayang/issues/291,incubator-wayang,1669789155,291,create a basic ruleset,github-actions,,,,OPEN,2023-04-16T08:50:12Z,2023-04-16T08:50:13Z,"create a basic ruleset

https://github.com/apache/incubator-wayang/blob/d46f3c3f0fb963c2ee2640f00a106042fba55431/wayang-api/wayang-api-sql/src/main/java/org/apache/wayang/api/sql/calcite/optimizer/Optimizer.java#L199

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to you under the Apache License, Version 2.0
 * (the ""License""); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.sql.calcite.optimizer;

import com.google.common.collect.ImmutableList;
import org.apache.calcite.avatica.util.Casing;
import org.apache.calcite.config.CalciteConnectionConfig;
import org.apache.calcite.config.CalciteConnectionConfigImpl;
import org.apache.calcite.config.CalciteConnectionProperty;
import org.apache.calcite.jdbc.CalciteSchema;
import org.apache.calcite.jdbc.JavaTypeFactoryImpl;
import org.apache.calcite.plan.*;
import org.apache.calcite.plan.volcano.VolcanoPlanner;
import org.apache.calcite.prepare.CalciteCatalogReader;
import org.apache.calcite.prepare.Prepare;
import org.apache.calcite.rel.RelNode;
import org.apache.calcite.rel.RelRoot;
import org.apache.calcite.rel.type.RelDataTypeFactory;
import org.apache.calcite.rex.RexBuilder;
import org.apache.calcite.sql.SqlNode;
import org.apache.calcite.sql.SqlOperatorTable;
import org.apache.calcite.sql.fun.SqlStdOperatorTable;
import org.apache.calcite.sql.parser.SqlParser;
import org.apache.calcite.sql.util.ChainedSqlOperatorTable;
import org.apache.calcite.sql.validate.SqlValidator;
import org.apache.calcite.sql.validate.SqlValidatorUtil;
import org.apache.calcite.sql2rel.SqlToRelConverter;
import org.apache.calcite.sql2rel.StandardConvertletTable;
import org.apache.calcite.tools.Program;
import org.apache.calcite.tools.Programs;
import org.apache.calcite.tools.RuleSet;
import org.apache.calcite.tools.RuleSets;
import org.apache.wayang.api.sql.calcite.converter.WayangRelConverter;
import org.apache.wayang.api.sql.calcite.schema.WayangSchema;
import org.apache.wayang.basic.data.Record;
import org.apache.wayang.basic.operators.LocalCallbackSink;
import org.apache.wayang.core.plan.wayangplan.Operator;
import org.apache.wayang.core.plan.wayangplan.WayangPlan;

import java.util.ArrayList;
import java.util.Collection;
import java.util.Collections;
import java.util.Properties;

public class Optimizer {

    private final CalciteConnectionConfig config;
    private final SqlValidator sqlValidator;
    private final SqlToRelConverter sqlToRelConverter;
    private final VolcanoPlanner volcanoPlanner;

    public Optimizer(
            CalciteConnectionConfig config,
            SqlValidator sqlValidator,
            SqlToRelConverter sqlToRelConverter,
            VolcanoPlanner volcanoPlanner) {
        this.config = config;
        this.sqlValidator = sqlValidator;
        this.sqlToRelConverter = sqlToRelConverter;
        this.volcanoPlanner = volcanoPlanner;
    }

    public static Optimizer create(
            CalciteSchema calciteSchema,
            Properties configProperties,
            RelDataTypeFactory typeFactory) {

        CalciteConnectionConfig config = new CalciteConnectionConfigImpl(configProperties);

        CalciteCatalogReader catalogReader = new CalciteCatalogReader(
                calciteSchema.root(),
                ImmutableList.of(calciteSchema.name),
                typeFactory,
                config
        );

        SqlOperatorTable operatorTable = new ChainedSqlOperatorTable(ImmutableList.of(SqlStdOperatorTable.instance()));

        SqlValidator.Config validatorConfig = SqlValidator.Config.DEFAULT
                .withLenientOperatorLookup(config.lenientOperatorLookup())
                .withSqlConformance(config.conformance())
                .withDefaultNullCollation(config.defaultNullCollation())
                .withIdentifierExpansion(true);

        SqlValidator validator = SqlValidatorUtil.newValidator(operatorTable, catalogReader, typeFactory, validatorConfig);

        VolcanoPlanner planner = new VolcanoPlanner(RelOptCostImpl.FACTORY, Contexts.of(config));
        planner.addRelTraitDef(ConventionTraitDef.INSTANCE);

        RelOptCluster cluster = RelOptCluster.create(planner, new RexBuilder(typeFactory));

        SqlToRelConverter.Config converterConfig = SqlToRelConverter.config()
                .withTrimUnusedFields(true)
                .withExpand(false);

        SqlToRelConverter converter = new SqlToRelConverter(
                null,
                validator,
                catalogReader,
                cluster,
                StandardConvertletTable.INSTANCE,
                converterConfig
        );

        return new Optimizer(config, validator, converter, planner);
    }



    //To remove
    public static Optimizer create(WayangSchema wayangSchema) {
        RelDataTypeFactory typeFactory = new JavaTypeFactoryImpl();

        // Configuration
        Properties configProperties = new Properties();
        configProperties.put(CalciteConnectionProperty.CASE_SENSITIVE.camelName(), Boolean.TRUE.toString());
        configProperties.put(CalciteConnectionProperty.UNQUOTED_CASING.camelName(), Casing.UNCHANGED.toString());
        configProperties.put(CalciteConnectionProperty.QUOTED_CASING.camelName(), Casing.UNCHANGED.toString());

        CalciteConnectionConfig config = new CalciteConnectionConfigImpl(configProperties);

        CalciteSchema rootSchema = CalciteSchema.createRootSchema(false, false);
        rootSchema.add(wayangSchema.getSchemaName(), wayangSchema);
        Prepare.CatalogReader catalogReader = new CalciteCatalogReader(
                rootSchema,
                Collections.singletonList(wayangSchema.getSchemaName()),
                typeFactory,
                config
        );

        SqlOperatorTable operatorTable = new ChainedSqlOperatorTable(ImmutableList.of(SqlStdOperatorTable.instance()));

        SqlValidator.Config validatorConfig = SqlValidator.Config.DEFAULT
                .withLenientOperatorLookup(config.lenientOperatorLookup())
                .withSqlConformance(config.conformance())
                .withDefaultNullCollation(config.defaultNullCollation())
                .withIdentifierExpansion(true);

        SqlValidator validator = SqlValidatorUtil.newValidator(operatorTable, catalogReader, typeFactory, validatorConfig);

        VolcanoPlanner planner = new VolcanoPlanner(RelOptCostImpl.FACTORY, Contexts.of(config));
        planner.addRelTraitDef(ConventionTraitDef.INSTANCE);

        RelOptCluster cluster = RelOptCluster.create(planner, new RexBuilder(typeFactory));

        SqlToRelConverter.Config converterConfig = SqlToRelConverter.config()
                .withTrimUnusedFields(true)
                .withExpand(false);

        SqlToRelConverter converter = new SqlToRelConverter(
                null,
                validator,
                catalogReader,
                cluster,
                StandardConvertletTable.INSTANCE,
                converterConfig
        );

        return new Optimizer(config, validator, converter, planner);
    }


    public SqlNode parseSql(String sql) throws Exception {
        SqlParser.Config parserConfig = SqlParser.config()
                .withCaseSensitive(config.caseSensitive())
                .withQuotedCasing(config.quotedCasing())
                .withUnquotedCasing(config.unquotedCasing())
                .withConformance(config.conformance());

        SqlParser parser = SqlParser.create(sql, parserConfig);

        return parser.parseStmt();
    }

    public SqlNode validate(SqlNode sqlNode) {
        return sqlValidator.validate(sqlNode);
    }

    public RelNode convert(SqlNode sqlNode) {
        RelRoot root  = sqlToRelConverter.convertQuery(sqlNode, false, true);
        return root.rel;
    }

    //TODO: create a basic ruleset
    public RelNode optimize(RelNode node, RelTraitSet requiredTraitSet, RuleSet rules) {
        Program program = Programs.of(RuleSets.ofList(rules));

        return program.run(
                volcanoPlanner,
                node,
                requiredTraitSet,
                Collections.emptyList(),
                Collections.emptyList()
        );
    }

    public WayangPlan convert(RelNode relNode) {
        return convert(relNode, new ArrayList<>());
    }

    public WayangPlan convert(RelNode relNode, Collection<Record> collector) {

        LocalCallbackSink<Record> sink = LocalCallbackSink.createCollectingSink(collector, Record.class);

        Operator op = new WayangRelConverter().convert(relNode);

        op.connectTo(0, sink, 0);
        return new WayangPlan(sink);
    }


    public static class ConfigProperties {

        public static Properties getDefaults() {
            Properties configProperties = new Properties();
            configProperties.put(CalciteConnectionProperty.CASE_SENSITIVE.camelName(), Boolean.TRUE.toString());
            configProperties.put(CalciteConnectionProperty.UNQUOTED_CASING.camelName(), Casing.UNCHANGED.toString());
            configProperties.put(CalciteConnectionProperty.QUOTED_CASING.camelName(), Casing.UNCHANGED.toString());
            return configProperties;
        }

    }


}



```

f6f94044461810f9b62858ea2505a5db2b35ef13","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/291/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/292,https://api.github.com/repos/apache/incubator-wayang/issues/292,incubator-wayang,1669789169,292,split into multiple classes,github-actions,,,,OPEN,2023-04-16T08:50:15Z,2023-04-16T08:50:15Z,"split into multiple classes

https://github.com/apache/incubator-wayang/blob/d46f3c3f0fb963c2ee2640f00a106042fba55431/wayang-api/wayang-api-sql/src/main/java/org/apache/wayang/api/sql/calcite/rules/WayangRules.java#L41

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to you under the Apache License, Version 2.0
 * (the ""License""); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.sql.calcite.rules;

import org.apache.calcite.adapter.enumerable.EnumerableConvention;
import org.apache.calcite.plan.Convention;
import org.apache.calcite.plan.RelOptRule;
import org.apache.calcite.plan.RelOptTable;
import org.apache.calcite.rel.RelNode;
import org.apache.calcite.rel.convert.ConverterRule;
import org.apache.calcite.rel.core.TableScan;
import org.apache.calcite.rel.logical.LogicalFilter;
import org.apache.calcite.rel.logical.LogicalJoin;
import org.apache.calcite.rel.logical.LogicalProject;
import org.apache.calcite.rel.logical.LogicalTableScan;
import org.apache.wayang.api.sql.calcite.convention.WayangConvention;
import org.apache.wayang.api.sql.calcite.rel.WayangFilter;
import org.apache.wayang.api.sql.calcite.rel.WayangJoin;
import org.apache.wayang.api.sql.calcite.rel.WayangProject;
import org.apache.wayang.api.sql.calcite.rel.WayangTableScan;
import org.checkerframework.checker.nullness.qual.Nullable;

import java.util.ArrayList;
import java.util.List;

//TODO: split into multiple classes
public class WayangRules {

    private WayangRules(){
    }


    public static final RelOptRule WAYANG_JOIN_RULE = new WayangJoinRule(WayangJoinRule.DEFAULT_CONFIG);
    public static final RelOptRule WAYANG_PROJECT_RULE = new WayangProjectRule(WayangProjectRule.DEFAULT_CONFIG);
    public static final RelOptRule WAYANG_FILTER_RULE =  new WayangFilterRule(WayangFilterRule.DEFAULT_CONFIG);
    public static final RelOptRule WAYANG_TABLESCAN_RULE = new WayangTableScanRule(WayangTableScanRule.DEFAULT_CONFIG);
    public static final RelOptRule WAYANG_TABLESCAN_ENUMERABLE_RULE =
            new WayangTableScanRule(WayangTableScanRule.ENUMERABLE_CONFIG);


    private static class WayangProjectRule extends ConverterRule {

        public static final Config DEFAULT_CONFIG = Config.INSTANCE
                .withConversion(LogicalProject.class,
                        Convention.NONE, WayangConvention.INSTANCE,
                        ""WayangProjectRule"")
                .withRuleFactory(WayangProjectRule::new);


        protected WayangProjectRule(Config config) {
            super(config);
        }

        public RelNode convert(RelNode rel) {
            final LogicalProject project = (LogicalProject) rel;
            return new WayangProject(
                    project.getCluster(),
                    project.getTraitSet().replace(WayangConvention.INSTANCE),
                    convert(project.getInput(), project.getInput().getTraitSet()
                            .replace(WayangConvention.INSTANCE)),
                    project.getProjects(),
                    project.getRowType());
        }
    }


    private static class WayangFilterRule extends ConverterRule {

        public static final Config DEFAULT_CONFIG = Config.INSTANCE
                .withConversion(LogicalFilter.class,
                        Convention.NONE, WayangConvention.INSTANCE,
                        ""WayangFilterRule"")
                .withRuleFactory(WayangFilterRule::new);


        protected WayangFilterRule(Config config) {
            super(config);
        }

        @Override
        public RelNode convert(RelNode rel) {
            final LogicalFilter filter = (LogicalFilter) rel;
            return new WayangFilter(
                    rel.getCluster(),
                    rel.getTraitSet().replace(WayangConvention.INSTANCE),
                    convert(filter.getInput(), filter.getInput().getTraitSet().
                            replace(WayangConvention.INSTANCE)),
                    filter.getCondition());
        }

    }

    private static class WayangTableScanRule extends ConverterRule {

        public static final Config DEFAULT_CONFIG = Config.INSTANCE
                .withConversion(LogicalTableScan.class,
                        Convention.NONE, WayangConvention.INSTANCE,
                        ""WayangTableScanRule"")
                .withRuleFactory(WayangTableScanRule::new);

        public static final Config ENUMERABLE_CONFIG = Config.INSTANCE
                .withConversion(TableScan.class,
                        EnumerableConvention.INSTANCE, WayangConvention.INSTANCE,
                        ""WayangTableScanRule1"")
                .withRuleFactory(WayangTableScanRule::new);

        protected WayangTableScanRule(Config config) {
            super(config);
        }

        @Override
        public @Nullable RelNode convert(RelNode relNode) {

            TableScan scan = (TableScan) relNode;
            final RelOptTable relOptTable = scan.getTable();

            /**
             * This is quick hack to prevent volcano from merging projects on to TableScans
             * TODO: a cleaner way to handle this
             */
            if(relOptTable.getRowType() == scan.getRowType()) {
                return WayangTableScan.create(scan.getCluster(), relOptTable);
            }
            return null;
        }
    }


    private static class WayangJoinRule extends ConverterRule {

        public static final Config DEFAULT_CONFIG = Config.INSTANCE
                .withConversion(LogicalJoin.class, Convention.NONE,
                        WayangConvention.INSTANCE, ""WayangJoinRule"")
                .withRuleFactory(WayangJoinRule::new);

        protected WayangJoinRule(Config config) {
            super(config);
        }

        @Override
        public @Nullable RelNode convert(RelNode relNode) {
            LogicalJoin join = (LogicalJoin) relNode;
            List<RelNode> newInputs = new ArrayList<>();
            for(RelNode input : join.getInputs()) {
                if(!(input.getConvention() instanceof WayangConvention)) {
                    input = convert(input, input.getTraitSet().replace(WayangConvention.INSTANCE));
                }
                newInputs.add(input);
            }

            return new WayangJoin(
                    join.getCluster(),
                    join.getTraitSet().replace(WayangConvention.INSTANCE),
                    newInputs.get(0),
                    newInputs.get(1),
                    join.getCondition(),
                    join.getVariablesSet(),
                    join.getJoinType()
            );
        }
    }


}

```

9f0f09f1adf621756dc435652fc6b278a42b00ec","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/292/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/293,https://api.github.com/repos/apache/incubator-wayang/issues/293,incubator-wayang,1669789180,293,a cleaner way to handle this,github-actions,,,,OPEN,2023-04-16T08:50:17Z,2023-04-16T08:50:17Z,"a cleaner way to handle this

https://github.com/apache/incubator-wayang/blob/d46f3c3f0fb963c2ee2640f00a106042fba55431/wayang-api/wayang-api-sql/src/main/java/org/apache/wayang/api/sql/calcite/rules/WayangRules.java#L134

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to you under the Apache License, Version 2.0
 * (the ""License""); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.sql.calcite.rules;

import org.apache.calcite.adapter.enumerable.EnumerableConvention;
import org.apache.calcite.plan.Convention;
import org.apache.calcite.plan.RelOptRule;
import org.apache.calcite.plan.RelOptTable;
import org.apache.calcite.rel.RelNode;
import org.apache.calcite.rel.convert.ConverterRule;
import org.apache.calcite.rel.core.TableScan;
import org.apache.calcite.rel.logical.LogicalFilter;
import org.apache.calcite.rel.logical.LogicalJoin;
import org.apache.calcite.rel.logical.LogicalProject;
import org.apache.calcite.rel.logical.LogicalTableScan;
import org.apache.wayang.api.sql.calcite.convention.WayangConvention;
import org.apache.wayang.api.sql.calcite.rel.WayangFilter;
import org.apache.wayang.api.sql.calcite.rel.WayangJoin;
import org.apache.wayang.api.sql.calcite.rel.WayangProject;
import org.apache.wayang.api.sql.calcite.rel.WayangTableScan;
import org.checkerframework.checker.nullness.qual.Nullable;

import java.util.ArrayList;
import java.util.List;

//TODO: split into multiple classes
public class WayangRules {

    private WayangRules(){
    }


    public static final RelOptRule WAYANG_JOIN_RULE = new WayangJoinRule(WayangJoinRule.DEFAULT_CONFIG);
    public static final RelOptRule WAYANG_PROJECT_RULE = new WayangProjectRule(WayangProjectRule.DEFAULT_CONFIG);
    public static final RelOptRule WAYANG_FILTER_RULE =  new WayangFilterRule(WayangFilterRule.DEFAULT_CONFIG);
    public static final RelOptRule WAYANG_TABLESCAN_RULE = new WayangTableScanRule(WayangTableScanRule.DEFAULT_CONFIG);
    public static final RelOptRule WAYANG_TABLESCAN_ENUMERABLE_RULE =
            new WayangTableScanRule(WayangTableScanRule.ENUMERABLE_CONFIG);


    private static class WayangProjectRule extends ConverterRule {

        public static final Config DEFAULT_CONFIG = Config.INSTANCE
                .withConversion(LogicalProject.class,
                        Convention.NONE, WayangConvention.INSTANCE,
                        ""WayangProjectRule"")
                .withRuleFactory(WayangProjectRule::new);


        protected WayangProjectRule(Config config) {
            super(config);
        }

        public RelNode convert(RelNode rel) {
            final LogicalProject project = (LogicalProject) rel;
            return new WayangProject(
                    project.getCluster(),
                    project.getTraitSet().replace(WayangConvention.INSTANCE),
                    convert(project.getInput(), project.getInput().getTraitSet()
                            .replace(WayangConvention.INSTANCE)),
                    project.getProjects(),
                    project.getRowType());
        }
    }


    private static class WayangFilterRule extends ConverterRule {

        public static final Config DEFAULT_CONFIG = Config.INSTANCE
                .withConversion(LogicalFilter.class,
                        Convention.NONE, WayangConvention.INSTANCE,
                        ""WayangFilterRule"")
                .withRuleFactory(WayangFilterRule::new);


        protected WayangFilterRule(Config config) {
            super(config);
        }

        @Override
        public RelNode convert(RelNode rel) {
            final LogicalFilter filter = (LogicalFilter) rel;
            return new WayangFilter(
                    rel.getCluster(),
                    rel.getTraitSet().replace(WayangConvention.INSTANCE),
                    convert(filter.getInput(), filter.getInput().getTraitSet().
                            replace(WayangConvention.INSTANCE)),
                    filter.getCondition());
        }

    }

    private static class WayangTableScanRule extends ConverterRule {

        public static final Config DEFAULT_CONFIG = Config.INSTANCE
                .withConversion(LogicalTableScan.class,
                        Convention.NONE, WayangConvention.INSTANCE,
                        ""WayangTableScanRule"")
                .withRuleFactory(WayangTableScanRule::new);

        public static final Config ENUMERABLE_CONFIG = Config.INSTANCE
                .withConversion(TableScan.class,
                        EnumerableConvention.INSTANCE, WayangConvention.INSTANCE,
                        ""WayangTableScanRule1"")
                .withRuleFactory(WayangTableScanRule::new);

        protected WayangTableScanRule(Config config) {
            super(config);
        }

        @Override
        public @Nullable RelNode convert(RelNode relNode) {

            TableScan scan = (TableScan) relNode;
            final RelOptTable relOptTable = scan.getTable();

            /**
             * This is quick hack to prevent volcano from merging projects on to TableScans
             * TODO: a cleaner way to handle this
             */
            if(relOptTable.getRowType() == scan.getRowType()) {
                return WayangTableScan.create(scan.getCluster(), relOptTable);
            }
            return null;
        }
    }


    private static class WayangJoinRule extends ConverterRule {

        public static final Config DEFAULT_CONFIG = Config.INSTANCE
                .withConversion(LogicalJoin.class, Convention.NONE,
                        WayangConvention.INSTANCE, ""WayangJoinRule"")
                .withRuleFactory(WayangJoinRule::new);

        protected WayangJoinRule(Config config) {
            super(config);
        }

        @Override
        public @Nullable RelNode convert(RelNode relNode) {
            LogicalJoin join = (LogicalJoin) relNode;
            List<RelNode> newInputs = new ArrayList<>();
            for(RelNode input : join.getInputs()) {
                if(!(input.getConvention() instanceof WayangConvention)) {
                    input = convert(input, input.getTraitSet().replace(WayangConvention.INSTANCE));
                }
                newInputs.add(input);
            }

            return new WayangJoin(
                    join.getCluster(),
                    join.getTraitSet().replace(WayangConvention.INSTANCE),
                    newInputs.get(0),
                    newInputs.get(1),
                    join.getCondition(),
                    join.getVariablesSet(),
                    join.getJoinType()
            );
        }
    }


}

```

0f23df970ae28b4fb0903f6f11d9ad9196a81871","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/293/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/294,https://api.github.com/repos/apache/incubator-wayang/issues/294,incubator-wayang,1669789199,294,Automatically create calcite schema based on user provided configurations of tab...,github-actions,,,,OPEN,2023-04-16T08:50:19Z,2023-04-16T08:50:20Z,"Automatically create calcite schema based on user provided configurations of table sources

https://github.com/apache/incubator-wayang/blob/d46f3c3f0fb963c2ee2640f00a106042fba55431/wayang-api/wayang-api-sql/src/main/java/org/apache/wayang/api/sql/calcite/schema/SchemaUtils.java#L32

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to you under the Apache License, Version 2.0
 * (the ""License""); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.sql.calcite.schema;

import org.apache.calcite.jdbc.CalciteConnection;
import org.apache.calcite.jdbc.CalciteSchema;
import org.apache.calcite.schema.SchemaPlus;
import org.apache.wayang.core.api.Configuration;

import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.SQLException;
import java.util.Properties;

/**
 * This class contains some hardcoded functions for creating calcite schema.
 * TODO: Automatically create calcite schema based on user provided configurations of table sources
 */
public class SchemaUtils {

    private static Properties getPostgresProperties() {
        /** Hardcoded for testing **/
        Properties info = new Properties();
        info.put(""model"",
                ""inline:""
                        + ""{\n""
                        + ""  version: '1.0',\n""
                        + ""  defaultSchema: 'tpch',\n""
                        + ""  schemas: [\n""
                        + ""     {\n""
                        + ""       name: 'postgres',\n""
                        + ""       type: 'custom',\n""
                        + ""       factory: 'org.apache.wayang.api.sql.calcite.jdbc.JdbcSchema$Factory',\n""
                        + ""       operand: {\n""
                        + ""         jdbcDriver: 'org.postgresql.Driver',\n""
                        + ""         jdbcUrl: 'jdbc:postgresql://localhost:5432/tpch',\n""
                        + ""         jdbcUser: 'user',\n""
                        + ""         jdbcPassword: 'password'\n""
                        + ""       }\n""
                        + ""     }\n""
                        + ""  ]\n""
                        + ""}"");
        return info;
    }

    private static Properties getFileProperties() {
        Properties info = new Properties();
        info.put(""model"",
                ""inline:""
                        + ""{\n""
                        + ""  version: '1.0',\n""
                        + ""  defaultSchema: 'tpch',\n""
                        + ""  schemas: [ {\n""
                        + ""    name: 'fs',\n""
                        + ""    type: 'custom',\n""
                        + ""    factory: 'org.apache.calcite.adapter.file.FileSchemaFactory',\n""
                        + ""    operand: {\n""
                        + ""        directory: '/data/Projects/databloom/test-data'\n""
                        + ""      } \n""
                        + ""    }\n""
                        + ""  ]\n""
                        + ""}""
        );
        return info;
    }


    public static CalciteSchema getPostgresSchema(Configuration configuration) throws SQLException {
        final Connection connection = DriverManager.getConnection(""jdbc:calcite:"", getPostgresProperties());
        return getCalciteSchema(connection);
    }

    public static CalciteSchema getFileSchema(Configuration configuration) throws SQLException {
        final Connection connection = DriverManager.getConnection(""jdbc:calcite:"", getFileProperties());
        return getCalciteSchema(connection);
    }

    public static CalciteSchema getCalciteSchema(Connection connection) throws SQLException {
            CalciteConnection calciteConnection = connection.unwrap(CalciteConnection.class);
            final SchemaPlus schemaPlus = calciteConnection.getRootSchema();
            CalciteSchema calciteSchema = CalciteSchema.from(schemaPlus);
            return calciteSchema;
    }
}

```

0fdef9320b429e35c9ea27527ce773624c5b88da","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/294/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/295,https://api.github.com/repos/apache/incubator-wayang/issues/295,incubator-wayang,1669789205,295,enable logging,github-actions,,,,OPEN,2023-04-16T08:50:21Z,2023-10-13T05:01:13Z,"enable logging

than the specified value.

https://github.com/apache/incubator-wayang/blob/d46f3c3f0fb963c2ee2640f00a106042fba55431/wayang-api/wayang-api-sql/src/main/java/org/apache/wayang/api/sql/sources/fs/CsvRowConverter.java#L146

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to you under the Apache License, Version 2.0
 * (the ""License""); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.sql.sources.fs;

import au.com.bytecode.opencsv.CSVParser;
import org.apache.calcite.avatica.util.DateTimeUtils;
import org.apache.calcite.rel.type.RelDataType;
import org.apache.commons.lang3.time.FastDateFormat;

import java.io.IOException;
import java.math.BigDecimal;
import java.math.RoundingMode;
import java.text.ParseException;
import java.util.Date;
import java.util.Locale;
import java.util.TimeZone;

/**
 * Based on Calcite's CSV enumerator.
 * TODO: handle different variants
 *
 */
public class CsvRowConverter {


    private static final CSVParser parser;

    private static final FastDateFormat TIME_FORMAT_DATE;
    private static final FastDateFormat TIME_FORMAT_TIME;
    private static final FastDateFormat TIME_FORMAT_TIMESTAMP;

    static {
        final TimeZone gmt = TimeZone.getTimeZone(""GMT"");
        TIME_FORMAT_DATE = FastDateFormat.getInstance(""yyyy-MM-dd"", gmt);
        TIME_FORMAT_TIME = FastDateFormat.getInstance(""HH:mm:ss"", gmt);
        TIME_FORMAT_TIMESTAMP = FastDateFormat.getInstance(""yyyy-MM-dd HH:mm:ss"", gmt);

        parser = new CSVParser();
    }





    public static Object convert(RelDataType fieldType, String string) {
        if (fieldType == null || string == null) {
            return string;
        }
        switch (fieldType.getSqlTypeName()) {
            case BOOLEAN:
                if (string.length() == 0) {
                    return null;
                }
                return Boolean.parseBoolean(string);
            case TINYINT:
                if (string.length() == 0) {
                    return null;
                }
                return Byte.parseByte(string);
            case SMALLINT:
                if (string.length() == 0) {
                    return null;
                }
                return Short.parseShort(string);
            case INTEGER:
                if (string.length() == 0) {
                    return null;
                }
                return Integer.parseInt(string);
            case BIGINT:
                if (string.length() == 0) {
                    return null;
                }
                return Long.parseLong(string);
            case FLOAT:
                if (string.length() == 0) {
                    return null;
                }
                return Float.parseFloat(string);
            case DOUBLE:
                if (string.length() == 0) {
                    return null;
                }
                return Double.parseDouble(string);
            case DECIMAL:
                if (string.length() == 0) {
                    return null;
                }
                return parseDecimal(fieldType.getPrecision(), fieldType.getScale(), string);
            case DATE:
                if (string.length() == 0) {
                    return null;
                }
                try {
                    Date date = TIME_FORMAT_DATE.parse(string);
                    return (int) (date.getTime() / DateTimeUtils.MILLIS_PER_DAY);
                } catch (ParseException e) {
                    return null;
                }
            case TIME:
                if (string.length() == 0) {
                    return null;
                }
                try {
                    Date date = TIME_FORMAT_TIME.parse(string);
                    return (int) date.getTime();
                } catch (ParseException e) {
                    return null;
                }
            case TIMESTAMP:
                if (string.length() == 0) {
                    return null;
                }
                try {
                    Date date = TIME_FORMAT_TIMESTAMP.parse(string);
                    return date.getTime();
                } catch (ParseException e) {
                    return null;
                }
            case VARCHAR:
            default:
                return string;
        }
    }

    private static BigDecimal parseDecimal(int precision, int scale, String string) {
        BigDecimal result = new BigDecimal(string);
        // If the parsed value has more fractional digits than the specified scale, round ties away
        // from 0.
        if (result.scale() > scale) {
            //TODO: enable logging
            /*LOGGER.warn(
                    ""Decimal value {} exceeds declared scale ({}). Performing rounding to keep the ""
                            + ""first {} fractional digits."",
                    result, scale, scale);*/
            result = result.setScale(scale, RoundingMode.HALF_UP);
        }
        // Throws an exception if the parsed value has more digits to the left of the decimal point
        // than the specified value.
        if (result.precision() - result.scale() > precision - scale) {
            throw new IllegalArgumentException(String
                    .format(Locale.ROOT, ""Decimal value %s exceeds declared precision (%d) and scale (%d)."",
                            result, precision, scale));
        }
        return result;
    }


    public static String[] parseLine(String s) throws IOException {
        return parser.parseLine(s);
    }
}

```

d2860c46967a7ef4c79ca64f47103c7265136dac","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/295/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/295,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5ony4V,incubator-wayang,1755262485,295,NA,kamir,1241122,Mirko Kämpf,mirko.kaempf@gmail.com,NA,2023-10-10T12:16:11Z,2023-10-10T12:16:11Z,"What is meant by ""Handle different variants?""

","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5ony4V/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/295,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5ooMkE,incubator-wayang,1755367684,295,NA,kbeedkar,8502905,Kaustubh Beedkar,,NA,2023-10-10T12:53:13Z,2023-10-10T12:53:13Z,"It meant dealing with different separators in the CSV file.  A later PR fixed that, but did not cleanup the TODO. ","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5ooMkE/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/295,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5o9AQf,incubator-wayang,1760822303,295,NA,kamir,1241122,Mirko Kämpf,mirko.kaempf@gmail.com,NA,2023-10-13T05:01:12Z,2023-10-13T05:01:12Z,"Ok. I see. 
I will work on that next.
As of now, I just have added the logging capability.
But this was a good warm up exercise.","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5o9AQf/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/296,https://api.github.com/repos/apache/incubator-wayang/issues/296,incubator-wayang,1669789214,296,handle different variants,github-actions,,,,OPEN,2023-04-16T08:50:23Z,2023-04-16T08:50:24Z,"handle different variants

https://github.com/apache/incubator-wayang/blob/d46f3c3f0fb963c2ee2640f00a106042fba55431/wayang-api/wayang-api-sql/src/main/java/org/apache/wayang/api/sql/sources/fs/CsvRowConverter.java#L35

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to you under the Apache License, Version 2.0
 * (the ""License""); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.sql.sources.fs;

import au.com.bytecode.opencsv.CSVParser;
import org.apache.calcite.avatica.util.DateTimeUtils;
import org.apache.calcite.rel.type.RelDataType;
import org.apache.commons.lang3.time.FastDateFormat;

import java.io.IOException;
import java.math.BigDecimal;
import java.math.RoundingMode;
import java.text.ParseException;
import java.util.Date;
import java.util.Locale;
import java.util.TimeZone;

/**
 * Based on Calcite's CSV enumerator.
 * TODO: handle different variants
 *
 */
public class CsvRowConverter {


    private static final CSVParser parser;

    private static final FastDateFormat TIME_FORMAT_DATE;
    private static final FastDateFormat TIME_FORMAT_TIME;
    private static final FastDateFormat TIME_FORMAT_TIMESTAMP;

    static {
        final TimeZone gmt = TimeZone.getTimeZone(""GMT"");
        TIME_FORMAT_DATE = FastDateFormat.getInstance(""yyyy-MM-dd"", gmt);
        TIME_FORMAT_TIME = FastDateFormat.getInstance(""HH:mm:ss"", gmt);
        TIME_FORMAT_TIMESTAMP = FastDateFormat.getInstance(""yyyy-MM-dd HH:mm:ss"", gmt);

        parser = new CSVParser();
    }





    public static Object convert(RelDataType fieldType, String string) {
        if (fieldType == null || string == null) {
            return string;
        }
        switch (fieldType.getSqlTypeName()) {
            case BOOLEAN:
                if (string.length() == 0) {
                    return null;
                }
                return Boolean.parseBoolean(string);
            case TINYINT:
                if (string.length() == 0) {
                    return null;
                }
                return Byte.parseByte(string);
            case SMALLINT:
                if (string.length() == 0) {
                    return null;
                }
                return Short.parseShort(string);
            case INTEGER:
                if (string.length() == 0) {
                    return null;
                }
                return Integer.parseInt(string);
            case BIGINT:
                if (string.length() == 0) {
                    return null;
                }
                return Long.parseLong(string);
            case FLOAT:
                if (string.length() == 0) {
                    return null;
                }
                return Float.parseFloat(string);
            case DOUBLE:
                if (string.length() == 0) {
                    return null;
                }
                return Double.parseDouble(string);
            case DECIMAL:
                if (string.length() == 0) {
                    return null;
                }
                return parseDecimal(fieldType.getPrecision(), fieldType.getScale(), string);
            case DATE:
                if (string.length() == 0) {
                    return null;
                }
                try {
                    Date date = TIME_FORMAT_DATE.parse(string);
                    return (int) (date.getTime() / DateTimeUtils.MILLIS_PER_DAY);
                } catch (ParseException e) {
                    return null;
                }
            case TIME:
                if (string.length() == 0) {
                    return null;
                }
                try {
                    Date date = TIME_FORMAT_TIME.parse(string);
                    return (int) date.getTime();
                } catch (ParseException e) {
                    return null;
                }
            case TIMESTAMP:
                if (string.length() == 0) {
                    return null;
                }
                try {
                    Date date = TIME_FORMAT_TIMESTAMP.parse(string);
                    return date.getTime();
                } catch (ParseException e) {
                    return null;
                }
            case VARCHAR:
            default:
                return string;
        }
    }

    private static BigDecimal parseDecimal(int precision, int scale, String string) {
        BigDecimal result = new BigDecimal(string);
        // If the parsed value has more fractional digits than the specified scale, round ties away
        // from 0.
        if (result.scale() > scale) {
            //TODO: enable logging
            /*LOGGER.warn(
                    ""Decimal value {} exceeds declared scale ({}). Performing rounding to keep the ""
                            + ""first {} fractional digits."",
                    result, scale, scale);*/
            result = result.setScale(scale, RoundingMode.HALF_UP);
        }
        // Throws an exception if the parsed value has more digits to the left of the decimal point
        // than the specified value.
        if (result.precision() - result.scale() > precision - scale) {
            throw new IllegalArgumentException(String
                    .format(Locale.ROOT, ""Decimal value %s exceeds declared precision (%d) and scale (%d)."",
                            result, precision, scale));
        }
        return result;
    }


    public static String[] parseLine(String s) throws IOException {
        return parser.parseLine(s);
    }
}

```

3e399fbf5b5d18c34dd6946262c37b561bb6a66c","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/296/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/297,https://api.github.com/repos/apache/incubator-wayang/issues/297,incubator-wayang,1669789222,297,incorporate fields later for projectable table scans,github-actions,,,,OPEN,2023-04-16T08:50:25Z,2023-04-16T08:50:26Z,"incorporate fields later for projectable table scans

private final ImmutableIntList fields;

https://github.com/apache/incubator-wayang/blob/d46f3c3f0fb963c2ee2640f00a106042fba55431/wayang-api/wayang-api-sql/src/main/java/org/apache/wayang/api/sql/sources/fs/JavaCSVTableSource.java#L56

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to you under the Apache License, Version 2.0
 * (the ""License""); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.sql.sources.fs;

import org.apache.calcite.rel.type.RelDataType;
import org.apache.commons.io.IOUtils;
import org.apache.wayang.basic.channels.FileChannel;
import org.apache.wayang.basic.data.Record;
import org.apache.wayang.core.api.exception.WayangException;
import org.apache.wayang.core.optimizer.OptimizationContext;
import org.apache.wayang.core.plan.wayangplan.ExecutionOperator;
import org.apache.wayang.core.plan.wayangplan.UnarySource;
import org.apache.wayang.core.platform.ChannelDescriptor;
import org.apache.wayang.core.platform.ChannelInstance;
import org.apache.wayang.core.platform.lineage.ExecutionLineageNode;
import org.apache.wayang.core.types.DataSetType;
import org.apache.wayang.core.util.Tuple;
import org.apache.wayang.core.util.fs.FileSystem;
import org.apache.wayang.core.util.fs.FileSystems;
import org.apache.wayang.core.util.fs.FileUtils;
import org.apache.wayang.java.channels.StreamChannel;
import org.apache.wayang.java.execution.JavaExecutor;
import org.apache.wayang.java.operators.JavaExecutionOperator;

import java.io.BufferedReader;
import java.io.IOException;
import java.io.InputStreamReader;
import java.io.UncheckedIOException;
import java.util.*;
import java.util.function.Function;
import java.util.stream.Stream;
import java.util.stream.StreamSupport;

public class JavaCSVTableSource<T> extends UnarySource<T> implements JavaExecutionOperator {


    private final String sourcePath;

    private final List<RelDataType> fieldTypes;

    // TODO: incorporate fields later for projectable table scans
    // private final ImmutableIntList fields;

    public JavaCSVTableSource(String sourcePath, DataSetType type, List<RelDataType> fieldTypes) {
        super(type);
        this.sourcePath = sourcePath;
        this.fieldTypes = fieldTypes;
    }

    /*public JavaCSVTableSource(DataSetType<T> type) {
        this(null, type);
    }*/

    @Override
    public Tuple<Collection<ExecutionLineageNode>, Collection<ChannelInstance>> evaluate(
            ChannelInstance[] inputs,
            ChannelInstance[] outputs,
            JavaExecutor javaExecutor,
            OptimizationContext.OperatorContext operatorContext) {
        assert outputs.length == this.getNumOutputs();

        final String path;
        if (this.sourcePath == null) {
            final FileChannel.Instance input = (FileChannel.Instance) inputs[0];
            path = input.getSinglePath();
        } else {
            assert inputs.length == 0;
            path = this.sourcePath;
        }
        final String actualInputPath = FileSystems.findActualSingleInputPath(path);
        Stream<T> stream = this.createStream(actualInputPath);
        ((StreamChannel.Instance) outputs[0]).accept(stream);

        return ExecutionOperator.modelLazyExecution(inputs, outputs, operatorContext);
    }

    private Stream<T> createStream(String actualInputPath) {
        Function<String, T> parser = this::parseLine;
        return streamLines(actualInputPath).map(parser);
    }

    private T parseLine(String s) {
        Class typeClass = this.getType().getDataUnitType().getTypeClass();
        assert typeClass == Record.class;
        try {
            String[] tokens = CsvRowConverter.parseLine(s);

            if (tokens.length != fieldTypes.size()) {
                throw new IllegalStateException(String.format(""Error while parsing CSV file %s at line %s"", sourcePath, s));
            }
            final Object[] objects = new Object[tokens.length];
            for (int i = 0; i < tokens.length; i++) {
                objects[i] = CsvRowConverter.convert(fieldTypes.get(i), tokens[i]);
            }
            return (T) new Record(objects);
        } catch (IOException e) {
            System.out.println(e.getMessage());
        }
        throw new IllegalStateException(String.format(""Error while parsing CSV file %s at line %s"", sourcePath, s));
    }





    @Override
    public List<ChannelDescriptor> getSupportedInputChannels(int index) {
        return Collections.singletonList(FileChannel.HDFS_TSV_DESCRIPTOR);
    }

    @Override
    public List<ChannelDescriptor> getSupportedOutputChannels(int index) {
        assert index <= this.getNumOutputs() || (index == 0 && this.getNumOutputs() == 0);
        return Collections.singletonList(StreamChannel.DESCRIPTOR);
    }

    /**
     * Copied from {@link FileUtils} as a quick work around to read CSV file after skipping
     * header row.
     *
     * Creates a {@link Stream} of a lines of the file.
     *
     * @param path of the file
     * @return the {@link Stream}
     */
    private static Stream<String> streamLines(String path) {
        final FileSystem fileSystem = FileSystems.getFileSystem(path).orElseThrow(
                () -> new IllegalStateException(String.format(""No file system found for %s"", path))
        );
        try {
            Iterator<String> lineIterator = createLineIterator(fileSystem, path);
            lineIterator.next(); // skip header row
            return StreamSupport.stream(Spliterators.spliteratorUnknownSize(lineIterator, 0), false);
        } catch (IOException e) {
            throw new WayangException(String.format(""%s failed to read %s."", FileUtils.class, path), e);
        }

    }

    /**
     * Creates an {@link Iterator} over the lines of a given {@code path} (that resides in the given {@code fileSystem}).
     */
    private static Iterator<String> createLineIterator(FileSystem fileSystem, String path) throws IOException {
        final BufferedReader reader = new BufferedReader(new InputStreamReader(fileSystem.open(path), ""UTF-8""));
        return new Iterator<String>() {

            String next;

            {
                this.advance();
            }

            private void advance() {
                try {
                    this.next = reader.readLine();
                } catch (IOException e) {
                    this.next = null;
                    throw new UncheckedIOException(e);
                } finally {
                    if (this.next == null) {
                        IOUtils.closeQuietly(reader);
                    }
                }
            }

            @Override
            public boolean hasNext() {
                return this.next != null;
            }

            @Override
            public String next() {
                assert this.hasNext();
                final String returnValue = this.next;
                this.advance();
                return returnValue;
            }
        };

    }





}

```

2b1aef4e9a7503c7e7f9987af1737a27fe565f78","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/297/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/305,https://api.github.com/repos/apache/incubator-wayang/issues/305,incubator-wayang,1682982095,305,hard-coded path,zkaoudi,10105712,Zoi Kaoudi,,CLOSED,2023-04-25T11:29:19Z,2023-04-26T15:18:59Z,"The WayangTableScanVisitor class contain a hard-coded path 
https://github.com/apache/incubator-wayang/blob/main/wayang-api/wayang-api-sql/src/main/java/org/apache/wayang/api/sql/calcite/converter/WayangTableScanVisitor.java#L61

@kbeedkar could you please take a look at this?","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/305/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/305,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5aswNX,incubator-wayang,1521681239,305,NA,kbeedkar,8502905,Kaustubh Beedkar,,NA,2023-04-25T12:09:45Z,2023-04-25T12:09:45Z,I am on it @zkaoudi ,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5aswNX/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/305,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5a0FFU,incubator-wayang,1523601748,305,NA,kbeedkar,8502905,Kaustubh Beedkar,,NA,2023-04-26T15:18:12Z,2023-04-26T15:18:12Z,this issue can be closed.,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5a0FFU/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/307,https://api.github.com/repos/apache/incubator-wayang/issues/307,incubator-wayang,1685221896,307,support other sources,github-actions,,,,OPEN,2023-04-26T15:08:56Z,2023-04-26T15:08:57Z,"support other sources

https://github.com/apache/incubator-wayang/blob/388cce9f8955c4c2e8df7b4094e4a7416340754f/wayang-api/wayang-api-sql/src/main/java/org/apache/wayang/api/sql/calcite/converter/WayangTableScanVisitor.java#L29

```java


package org.apache.wayang.api.sql.calcite.converter;

import org.apache.wayang.api.sql.calcite.rel.WayangTableScan;
import org.apache.wayang.core.plan.wayangplan.Operator;
import org.apache.wayang.postgres.operators.PostgresTableSource;

import java.util.List;


//TODO: create tablesource with column types
//TODO: support other sources
public class WayangTableScanVisitor extends WayangRelNodeVisitor<WayangTableScan> {
    WayangTableScanVisitor(WayangRelConverter wayangRelConverter) {
        super(wayangRelConverter);

```

99bc2ee657704ab5291a8d9cad23691d2915d256","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/307/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/312,https://api.github.com/repos/apache/incubator-wayang/issues/312,incubator-wayang,1689961098,312,hard-coded for now - retrieve URL from CsvTranslatableTable under source,github-actions,,,,CLOSED,2023-04-30T15:25:47Z,2023-05-15T07:25:23Z,"hard-coded for now - retrieve URL from CsvTranslatableTable under source

https://github.com/apache/incubator-wayang/blob/9f4ccc9b37583d60990988ce688776a01646609c/wayang-api/wayang-api-sql/src/main/java/org/apache/wayang/api/sql/calcite/rel/WayangTableScan.java#L96

```java

        return table.getRowType().getFieldNames();
    }

    // TODO: hard-coded for now - retrieve URL from CsvTranslatableTable under source
    public String getSourcePath() {
//        System.out.println(table.unwrap(CsvTranslatableTable.class).source());
        return ""file:/C:/incubator-Wayang-CrossPlatform/incubator-wayang-SQL/wayang-api/wayang-api-sql/src/test/resources/data1.csv""; }

}

```

77738d035f2b8a73994538bb3ff218562c3f5ea0","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/312/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/312,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5cOlCZ,incubator-wayang,1547325593,312,NA,github-actions,,,,NA,2023-05-15T07:25:22Z,2023-05-15T07:25:22Z,Closed in efe729c3427af7411501e36661f6d0b480f08429,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5cOlCZ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/325,https://api.github.com/repos/apache/incubator-wayang/issues/325,incubator-wayang,1714330363,325,Update to the Dashboard Backend Build Process,github-actions,,,,CLOSED,2023-05-17T17:19:22Z,2023-07-20T15:03:14Z,"Update to the Dashboard Backend Build Process

push:

branches: [ main ]

paths:

- 'hackit-backend/**'

pull_request:

branches: [ main ]

paths:

- 'hackit-backend/**'

jobs:

build:

- uses: actions/checkout@v2

- name: Set up JDK 17

uses: actions/setup-java@v2

with:

java-version: '17'

distribution: 'adopt'

cache: maven

- name: Build with Maven

run: cd hackit-backend ; mvn clean verify compile package --file pom.xml

https://github.com/apache/incubator-wayang/blob/0b5b6282bab567c66eb82abc5c87cc5e4d9dd9ec/.github/workflows/build-backend.yaml#L18

```yaml

# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the ""License""); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This workflow will build the backend service

#TODO Update to the Dashboard Backend Build Process

#name: build back-end

#on:
#  push:
#    branches: [ main ]
#    paths:
#      - 'hackit-backend/**'
#  pull_request:
#    branches: [ main ]
#    paths:
#      - 'hackit-backend/**'
#jobs:
#  build:
#
#    runs-on: ubuntu-latest
#
#    steps:
#      - uses: actions/checkout@v2
#      - name: Set up JDK 17
#        uses: actions/setup-java@v2
#        with:
#          java-version: '17'
#          distribution: 'adopt'
#          cache: maven
#      - name: Build with Maven
#        run: cd hackit-backend ; mvn clean verify compile package --file pom.xml

```

5b52deac5577d778d7911d67cd6f326f52a1a0ad","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/325/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/325,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5h_tdV,incubator-wayang,1644091221,325,NA,glauesppen,8548856,Glaucia Esppenchutz,g.esppen@gmail.com,NA,2023-07-20T15:02:44Z,2023-07-20T15:02:44Z,Duplicate,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5h_tdV/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/326,https://api.github.com/repos/apache/incubator-wayang/issues/326,incubator-wayang,1714330411,326,Update to the Dashboard WebApp Build Process,github-actions,,,,CLOSED,2023-05-17T17:19:24Z,2023-11-01T08:06:44Z,"Update to the Dashboard WebApp Build Process

push:

branches: [ main ]

paths:

- 'hackit-web/**'

pull_request:

branches: [ main ]

paths:

- 'hackit-web/**'

jobs:

build:

- uses: actions/checkout@v2

- name: Set up node

uses: actions/setup-node@master

with:

cache: node

- name: change folder to hackit-web

run: cd hackit-web

- name: Installing project dependencies

run: npm install

- name: Building the project

run: npm run build

https://github.com/apache/incubator-wayang/blob/0b5b6282bab567c66eb82abc5c87cc5e4d9dd9ec/.github/workflows/build-frontend.yaml#L17

```yaml

# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the ""License""); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This workflow will build the backend service
#TODO Update to the Dashboard WebApp Build Process
#
#name: build front-end
#
#on:
#  push:
#    branches: [ main ]
#    paths:
#      - 'hackit-web/**'
#  pull_request:
#    branches: [ main ]
#    paths:
#      - 'hackit-web/**'
#jobs:
#  build:
#
#    runs-on: ubuntu-latest
#
#    steps:
#      - uses: actions/checkout@v2
#      - name: Set up node
#        uses: actions/setup-node@master
#        with:
#          cache: node
#      - name: change folder to hackit-web
#        run: cd hackit-web
#      - name: Installing project dependencies
#        run: npm install
#      - name: Building the project
#        run: npm run build

```

e8ed887e30c1f63d6b9251ac23716a447423b4df","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/326/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/326,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5qm1kB,incubator-wayang,1788565761,326,NA,github-actions,,,,NA,2023-11-01T08:06:44Z,2023-11-01T08:06:44Z,Closed in b03020de7bff804ff3ca77203395960918f4d68e,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5qm1kB/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/329,https://api.github.com/repos/apache/incubator-wayang/issues/329,incubator-wayang,1760600332,329,Fix code scanning alert - Building a command line with string concatenation,2pk03,1323575,Alexander Alten-Lorenz,,CLOSED,2023-06-16T13:02:17Z,2023-06-16T13:52:20Z,"<!-- Warning: The suggested title contains the alert rule name. This can expose security information. -->

Tracking issue for:
- [ ] https://github.com/apache/incubator-wayang/security/code-scanning/2
","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/329/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/342,https://api.github.com/repos/apache/incubator-wayang/issues/342,incubator-wayang,1905702174,342,fix scala mentions in release notes,pjfanning,11783444,PJ Fanning,,CLOSED,2023-09-20T20:52:00Z,2023-10-27T11:59:51Z,"Scala releases include 2.11, 2.12 and more recently 2.13 and 3.

The Wayang release notes keep referring to Scala 11 and 12 when I think you mean 2.11 and 2.12.

Examples:
* https://lists.apache.org/thread/l6y7v3y1f76hrhblz5f1znptn0dqhh9n
* https://github.com/apache/incubator-wayang/blob/main/RELEASE_NOTES","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/342/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/342,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5qQ0WN,incubator-wayang,1782793613,342,NA,2pk03,1323575,Alexander Alten-Lorenz,,NA,2023-10-27T11:59:51Z,2023-10-27T11:59:51Z,fixed and merged. Thank you!,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5qQ0WN/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/360,https://api.github.com/repos/apache/incubator-wayang/issues/360,incubator-wayang,1965443163,360,other parameters,github-actions,,,,OPEN,2023-10-27T12:37:42Z,2023-10-27T12:37:43Z,"other parameters

https://github.com/apache/incubator-wayang/blob/897797899866f373f93e5672b36d5e34611faece/wayang-commons/wayang-basic/src/main/java/org/apache/wayang/basic/operators/KMeansOperator.java#L30

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.basic.operators;

import org.apache.wayang.basic.data.Tuple2;
import org.apache.wayang.core.api.Configuration;
import org.apache.wayang.core.optimizer.cardinality.CardinalityEstimator;
import org.apache.wayang.core.plan.wayangplan.UnaryToUnaryOperator;
import org.apache.wayang.core.types.DataSetType;

import java.util.Optional;

public class KMeansOperator extends UnaryToUnaryOperator<double[], Tuple2<double[], Integer>> {
    // TODO other parameters
    protected int k;

    public KMeansOperator(int k) {
        super(DataSetType.createDefaultUnchecked(double[].class),
                DataSetType.createDefaultUnchecked(Tuple2.class),
                false);
        this.k = k;
    }

    public KMeansOperator(KMeansOperator that) {
        super(that);
        this.k = that.k;
    }

    public int getK() {
        return k;
    }

    // TODO support fit and transform

    @Override
    public Optional<CardinalityEstimator> createCardinalityEstimator(int outputIndex, Configuration configuration) {
        // TODO
        return super.createCardinalityEstimator(outputIndex, configuration);
    }
}

```

5f597cd5aef6e34f7ecdbfad76fb780d46d41a09","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/360/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/361,https://api.github.com/repos/apache/incubator-wayang/issues/361,incubator-wayang,1965443225,361,support fit and transform,github-actions,,,,OPEN,2023-10-27T12:37:44Z,2023-10-27T12:37:45Z,"support fit and transform

https://github.com/apache/incubator-wayang/blob/897797899866f373f93e5672b36d5e34611faece/wayang-commons/wayang-basic/src/main/java/org/apache/wayang/basic/operators/KMeansOperator.java#L49

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.basic.operators;

import org.apache.wayang.basic.data.Tuple2;
import org.apache.wayang.core.api.Configuration;
import org.apache.wayang.core.optimizer.cardinality.CardinalityEstimator;
import org.apache.wayang.core.plan.wayangplan.UnaryToUnaryOperator;
import org.apache.wayang.core.types.DataSetType;

import java.util.Optional;

public class KMeansOperator extends UnaryToUnaryOperator<double[], Tuple2<double[], Integer>> {
    // TODO other parameters
    protected int k;

    public KMeansOperator(int k) {
        super(DataSetType.createDefaultUnchecked(double[].class),
                DataSetType.createDefaultUnchecked(Tuple2.class),
                false);
        this.k = k;
    }

    public KMeansOperator(KMeansOperator that) {
        super(that);
        this.k = that.k;
    }

    public int getK() {
        return k;
    }

    // TODO support fit and transform

    @Override
    public Optional<CardinalityEstimator> createCardinalityEstimator(int outputIndex, Configuration configuration) {
        // TODO
        return super.createCardinalityEstimator(outputIndex, configuration);
    }
}

```

ce3bd2058f392a74234f683fb354e2a2cc52b8f0","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/361/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/362,https://api.github.com/repos/apache/incubator-wayang/issues/362,incubator-wayang,1965443273,362,need DataFrameChannel?,github-actions,,,,OPEN,2023-10-27T12:37:46Z,2023-10-27T12:37:47Z,"need DataFrameChannel?

https://github.com/apache/incubator-wayang/blob/897797899866f373f93e5672b36d5e34611faece/wayang-platforms/wayang-spark/code/main/java/org/apache/wayang/spark/operators/ml/SparkKMeansOperator.java#L55

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.spark.operators.ml;

import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.ml.clustering.KMeans;
import org.apache.spark.ml.clustering.KMeansModel;
import org.apache.spark.ml.linalg.Vector;
import org.apache.spark.ml.linalg.Vectors;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;
import org.apache.wayang.basic.data.Tuple2;
import org.apache.wayang.basic.operators.KMeansOperator;
import org.apache.wayang.core.optimizer.OptimizationContext;
import org.apache.wayang.core.plan.wayangplan.ExecutionOperator;
import org.apache.wayang.core.platform.ChannelDescriptor;
import org.apache.wayang.core.platform.ChannelInstance;
import org.apache.wayang.core.platform.lineage.ExecutionLineageNode;
import org.apache.wayang.core.util.Tuple;
import org.apache.wayang.spark.channels.RddChannel;
import org.apache.wayang.spark.execution.SparkExecutor;
import org.apache.wayang.spark.operators.SparkExecutionOperator;

import java.util.*;

public class SparkKMeansOperator extends KMeansOperator implements SparkExecutionOperator {

    public SparkKMeansOperator(int k) {
        super(k);
    }

    public SparkKMeansOperator(KMeansOperator that) {
        super(that);
    }

    @Override
    public List<ChannelDescriptor> getSupportedInputChannels(int index) {
        // TODO need DataFrameChannel?
        return Arrays.asList(RddChannel.UNCACHED_DESCRIPTOR, RddChannel.CACHED_DESCRIPTOR);
    }

    @Override
    public List<ChannelDescriptor> getSupportedOutputChannels(int index) {
        // TODO need DataFrameChannel?
        return Collections.singletonList(RddChannel.UNCACHED_DESCRIPTOR);
    }

    @Override
    public Tuple<Collection<ExecutionLineageNode>, Collection<ChannelInstance>> evaluate(
            ChannelInstance[] inputs,
            ChannelInstance[] outputs,
            SparkExecutor sparkExecutor,
            OptimizationContext.OperatorContext operatorContext) {
        assert inputs.length == this.getNumInputs();
        assert outputs.length == this.getNumInputs();

        final RddChannel.Instance input = (RddChannel.Instance) inputs[0];
        final RddChannel.Instance output = (RddChannel.Instance) outputs[0];

        final JavaRDD<double[]> inputRdd = input.provideRdd();
        final JavaRDD<Data> dataRdd = inputRdd.map(Data::new);
        final Dataset<Row> df = SparkSession.builder().getOrCreate().createDataFrame(dataRdd, Data.class);
        final KMeansModel model = new KMeans()
                .setK(this.k)
                .fit(df);

        final Dataset<Row> transform = model.transform(df);
        final JavaRDD<Tuple2<double[], Integer>> outputRdd = transform.toJavaRDD()
                .map(row -> new Tuple2<>(((Vector) row.get(0)).toArray(), (Integer) row.get(1)));

        this.name(outputRdd);
        output.accept(outputRdd, sparkExecutor);

        return ExecutionOperator.modelLazyExecution(inputs, outputs, operatorContext);
    }

    // TODO support fit and transform

    @Override
    public boolean containsAction() {
        return false;
    }

    public static class Data {
        private final Vector features;


        public Data(Vector features) {
            this.features = features;
        }

        public Data(double[] features) {
            this.features = Vectors.dense(features);
        }

        public Vector getFeatures() {
            return features;
        }

        @Override
        public String toString() {
            return ""Data{"" +
                    ""features="" + features +
                    '}';
        }

        @Override
        public boolean equals(Object o) {
            if (this == o) return true;
            if (!(o instanceof Data)) return false;
            Data data = (Data) o;
            return Objects.equals(features, data.features);
        }

        @Override
        public int hashCode() {
            return Objects.hash(features);
        }
    }
}

```

bf0ae8055e229f8ccd3f6550b68ee2be4bde3acc","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/362/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/363,https://api.github.com/repos/apache/incubator-wayang/issues/363,incubator-wayang,1965443325,363,need DataFrameChannel?,github-actions,,,,OPEN,2023-10-27T12:37:48Z,2023-10-27T12:37:49Z,"need DataFrameChannel?

https://github.com/apache/incubator-wayang/blob/897797899866f373f93e5672b36d5e34611faece/wayang-platforms/wayang-spark/code/main/java/org/apache/wayang/spark/operators/ml/SparkKMeansOperator.java#L55

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.spark.operators.ml;

import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.ml.clustering.KMeans;
import org.apache.spark.ml.clustering.KMeansModel;
import org.apache.spark.ml.linalg.Vector;
import org.apache.spark.ml.linalg.Vectors;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;
import org.apache.wayang.basic.data.Tuple2;
import org.apache.wayang.basic.operators.KMeansOperator;
import org.apache.wayang.core.optimizer.OptimizationContext;
import org.apache.wayang.core.plan.wayangplan.ExecutionOperator;
import org.apache.wayang.core.platform.ChannelDescriptor;
import org.apache.wayang.core.platform.ChannelInstance;
import org.apache.wayang.core.platform.lineage.ExecutionLineageNode;
import org.apache.wayang.core.util.Tuple;
import org.apache.wayang.spark.channels.RddChannel;
import org.apache.wayang.spark.execution.SparkExecutor;
import org.apache.wayang.spark.operators.SparkExecutionOperator;

import java.util.*;

public class SparkKMeansOperator extends KMeansOperator implements SparkExecutionOperator {

    public SparkKMeansOperator(int k) {
        super(k);
    }

    public SparkKMeansOperator(KMeansOperator that) {
        super(that);
    }

    @Override
    public List<ChannelDescriptor> getSupportedInputChannels(int index) {
        // TODO need DataFrameChannel?
        return Arrays.asList(RddChannel.UNCACHED_DESCRIPTOR, RddChannel.CACHED_DESCRIPTOR);
    }

    @Override
    public List<ChannelDescriptor> getSupportedOutputChannels(int index) {
        // TODO need DataFrameChannel?
        return Collections.singletonList(RddChannel.UNCACHED_DESCRIPTOR);
    }

    @Override
    public Tuple<Collection<ExecutionLineageNode>, Collection<ChannelInstance>> evaluate(
            ChannelInstance[] inputs,
            ChannelInstance[] outputs,
            SparkExecutor sparkExecutor,
            OptimizationContext.OperatorContext operatorContext) {
        assert inputs.length == this.getNumInputs();
        assert outputs.length == this.getNumInputs();

        final RddChannel.Instance input = (RddChannel.Instance) inputs[0];
        final RddChannel.Instance output = (RddChannel.Instance) outputs[0];

        final JavaRDD<double[]> inputRdd = input.provideRdd();
        final JavaRDD<Data> dataRdd = inputRdd.map(Data::new);
        final Dataset<Row> df = SparkSession.builder().getOrCreate().createDataFrame(dataRdd, Data.class);
        final KMeansModel model = new KMeans()
                .setK(this.k)
                .fit(df);

        final Dataset<Row> transform = model.transform(df);
        final JavaRDD<Tuple2<double[], Integer>> outputRdd = transform.toJavaRDD()
                .map(row -> new Tuple2<>(((Vector) row.get(0)).toArray(), (Integer) row.get(1)));

        this.name(outputRdd);
        output.accept(outputRdd, sparkExecutor);

        return ExecutionOperator.modelLazyExecution(inputs, outputs, operatorContext);
    }

    // TODO support fit and transform

    @Override
    public boolean containsAction() {
        return false;
    }

    public static class Data {
        private final Vector features;


        public Data(Vector features) {
            this.features = features;
        }

        public Data(double[] features) {
            this.features = Vectors.dense(features);
        }

        public Vector getFeatures() {
            return features;
        }

        @Override
        public String toString() {
            return ""Data{"" +
                    ""features="" + features +
                    '}';
        }

        @Override
        public boolean equals(Object o) {
            if (this == o) return true;
            if (!(o instanceof Data)) return false;
            Data data = (Data) o;
            return Objects.equals(features, data.features);
        }

        @Override
        public int hashCode() {
            return Objects.hash(features);
        }
    }
}

```

bf0ae8055e229f8ccd3f6550b68ee2be4bde3acc","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/363/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/364,https://api.github.com/repos/apache/incubator-wayang/issues/364,incubator-wayang,1965443378,364,support fit and transform,github-actions,,,,OPEN,2023-10-27T12:37:50Z,2023-10-27T12:37:51Z,"support fit and transform

https://github.com/apache/incubator-wayang/blob/897797899866f373f93e5672b36d5e34611faece/wayang-platforms/wayang-spark/code/main/java/org/apache/wayang/spark/operators/ml/SparkKMeansOperator.java#L94

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.spark.operators.ml;

import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.ml.clustering.KMeans;
import org.apache.spark.ml.clustering.KMeansModel;
import org.apache.spark.ml.linalg.Vector;
import org.apache.spark.ml.linalg.Vectors;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;
import org.apache.wayang.basic.data.Tuple2;
import org.apache.wayang.basic.operators.KMeansOperator;
import org.apache.wayang.core.optimizer.OptimizationContext;
import org.apache.wayang.core.plan.wayangplan.ExecutionOperator;
import org.apache.wayang.core.platform.ChannelDescriptor;
import org.apache.wayang.core.platform.ChannelInstance;
import org.apache.wayang.core.platform.lineage.ExecutionLineageNode;
import org.apache.wayang.core.util.Tuple;
import org.apache.wayang.spark.channels.RddChannel;
import org.apache.wayang.spark.execution.SparkExecutor;
import org.apache.wayang.spark.operators.SparkExecutionOperator;

import java.util.*;

public class SparkKMeansOperator extends KMeansOperator implements SparkExecutionOperator {

    public SparkKMeansOperator(int k) {
        super(k);
    }

    public SparkKMeansOperator(KMeansOperator that) {
        super(that);
    }

    @Override
    public List<ChannelDescriptor> getSupportedInputChannels(int index) {
        // TODO need DataFrameChannel?
        return Arrays.asList(RddChannel.UNCACHED_DESCRIPTOR, RddChannel.CACHED_DESCRIPTOR);
    }

    @Override
    public List<ChannelDescriptor> getSupportedOutputChannels(int index) {
        // TODO need DataFrameChannel?
        return Collections.singletonList(RddChannel.UNCACHED_DESCRIPTOR);
    }

    @Override
    public Tuple<Collection<ExecutionLineageNode>, Collection<ChannelInstance>> evaluate(
            ChannelInstance[] inputs,
            ChannelInstance[] outputs,
            SparkExecutor sparkExecutor,
            OptimizationContext.OperatorContext operatorContext) {
        assert inputs.length == this.getNumInputs();
        assert outputs.length == this.getNumInputs();

        final RddChannel.Instance input = (RddChannel.Instance) inputs[0];
        final RddChannel.Instance output = (RddChannel.Instance) outputs[0];

        final JavaRDD<double[]> inputRdd = input.provideRdd();
        final JavaRDD<Data> dataRdd = inputRdd.map(Data::new);
        final Dataset<Row> df = SparkSession.builder().getOrCreate().createDataFrame(dataRdd, Data.class);
        final KMeansModel model = new KMeans()
                .setK(this.k)
                .fit(df);

        final Dataset<Row> transform = model.transform(df);
        final JavaRDD<Tuple2<double[], Integer>> outputRdd = transform.toJavaRDD()
                .map(row -> new Tuple2<>(((Vector) row.get(0)).toArray(), (Integer) row.get(1)));

        this.name(outputRdd);
        output.accept(outputRdd, sparkExecutor);

        return ExecutionOperator.modelLazyExecution(inputs, outputs, operatorContext);
    }

    // TODO support fit and transform

    @Override
    public boolean containsAction() {
        return false;
    }

    public static class Data {
        private final Vector features;


        public Data(Vector features) {
            this.features = features;
        }

        public Data(double[] features) {
            this.features = Vectors.dense(features);
        }

        public Vector getFeatures() {
            return features;
        }

        @Override
        public String toString() {
            return ""Data{"" +
                    ""features="" + features +
                    '}';
        }

        @Override
        public boolean equals(Object o) {
            if (this == o) return true;
            if (!(o instanceof Data)) return false;
            Data data = (Data) o;
            return Objects.equals(features, data.features);
        }

        @Override
        public int hashCode() {
            return Objects.hash(features);
        }
    }
}

```

3f31a326ba75f6759cc6fd58baf76d28ad75c033","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/364/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/371,https://api.github.com/repos/apache/incubator-wayang/issues/371,incubator-wayang,1990691740,371,Add load profile estimators,github-actions,,,,OPEN,2023-11-13T13:44:23Z,2023-11-13T13:44:23Z,"Add load profile estimators

https://github.com/apache/incubator-wayang/blob/f68bf88d8cf86f826771ffc74b171d82fcb23f23/wayang-platforms/wayang-jdbc-template/src/main/java/org/apache/wayang/jdbc/operators/SqlToRddOperator.java#L100

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.jdbc.operators;

import org.apache.spark.api.java.JavaRDD;
import org.apache.wayang.basic.data.Record;
import org.apache.wayang.core.optimizer.OptimizationContext;
import org.apache.wayang.core.plan.wayangplan.UnaryToUnaryOperator;
import org.apache.wayang.core.platform.ChannelDescriptor;
import org.apache.wayang.core.platform.ChannelInstance;
import org.apache.wayang.core.platform.lineage.ExecutionLineageNode;
import org.apache.wayang.core.types.DataSetType;
import org.apache.wayang.core.util.JsonSerializable;
import org.apache.wayang.core.util.Tuple;
import org.apache.wayang.core.util.json.WayangJsonObj;
import org.apache.wayang.jdbc.channels.SqlQueryChannel;
import org.apache.wayang.jdbc.platform.JdbcPlatformTemplate;
import org.apache.wayang.spark.channels.RddChannel;
import org.apache.wayang.spark.execution.SparkExecutor;
import org.apache.wayang.spark.operators.SparkExecutionOperator;

import java.sql.Connection;
import java.util.Collection;
import java.util.Collections;
import java.util.Iterator;
import java.util.List;
import java.util.stream.Collectors;
import java.util.stream.StreamSupport;

public class SqlToRddOperator extends UnaryToUnaryOperator<Record, Record> implements SparkExecutionOperator, JsonSerializable {

    private final JdbcPlatformTemplate jdbcPlatform;

    public SqlToRddOperator(JdbcPlatformTemplate jdbcPlatform) {
        this(jdbcPlatform, DataSetType.createDefault(Record.class));
    }

    public SqlToRddOperator(JdbcPlatformTemplate jdbcPlatform, DataSetType<Record> dataSetType) {
        super(dataSetType, dataSetType, false);
        this.jdbcPlatform = jdbcPlatform;
    }

    protected SqlToRddOperator(SqlToRddOperator that) {
        super(that);
        this.jdbcPlatform = that.jdbcPlatform;
    }

    @Override
    public List<ChannelDescriptor> getSupportedInputChannels(int index) {
        return Collections.singletonList(this.jdbcPlatform.getSqlQueryChannelDescriptor());
    }

    @Override
    public List<ChannelDescriptor> getSupportedOutputChannels(int index) {
        return Collections.singletonList(RddChannel.UNCACHED_DESCRIPTOR);
    }

    @Override
    public Tuple<Collection<ExecutionLineageNode>, Collection<ChannelInstance>> evaluate(
            ChannelInstance[] inputs,
            ChannelInstance[] outputs,
            SparkExecutor executor,
            OptimizationContext.OperatorContext operatorContext) {
        // Cast the inputs and outputs.
        final SqlQueryChannel.Instance input = (SqlQueryChannel.Instance) inputs[0];
        final RddChannel.Instance output = (RddChannel.Instance) outputs[0];

        JdbcPlatformTemplate producerPlatform = (JdbcPlatformTemplate) input.getChannel().getProducer().getPlatform();
        final Connection connection = producerPlatform
                .createDatabaseDescriptor(executor.getConfiguration())
                .createJdbcConnection();

        Iterator<Record> resultSetIterator = new SqlToStreamOperator.ResultSetIterator(connection, input.getSqlQuery());
        Iterable<Record> resultSetIterable = () -> resultSetIterator;

        // Convert the ResultSet to a JavaRDD.
        JavaRDD<Record> resultSetRDD = executor.sc.parallelize(
                StreamSupport.stream(resultSetIterable.spliterator(), false).collect(Collectors.toList()),
                executor.getNumDefaultPartitions()
        );

        output.accept(resultSetRDD, executor);

        // TODO: Add load profile estimators
        ExecutionLineageNode queryLineageNode = new ExecutionLineageNode(operatorContext);
        queryLineageNode.addPredecessor(input.getLineage());
        ExecutionLineageNode outputLineageNode = new ExecutionLineageNode(operatorContext);
        output.getLineage().addPredecessor(outputLineageNode);

        return queryLineageNode.collectAndMark();
    }

    @Override
    public boolean containsAction() {
        return false;
    }

    @Override
    public WayangJsonObj toJson() {
        return null;
    }
}

```

62397f497b5acae872a796cd27739ccd938d6efe","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/371/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/373,https://api.github.com/repos/apache/incubator-wayang/issues/373,incubator-wayang,1994446533,373,This is actually automatically done by the maven-release-plugin:prepare goal The...,github-actions,,,,OPEN,2023-11-15T10:03:46Z,2023-11-15T10:03:47Z,"This is actually automatically done by the maven-release-plugin:prepare goal Therefore it could be removed

https://github.com/apache/incubator-wayang/blob/d75a5723989928ac2e633d76bf665b2a5cb3eaf1/pom.xml#L394

```xml


            - Prevents thrid-party snapshot dependencies in projects
        -->
        <!-- TODO: This is actually automatically done by the maven-release-plugin:prepare goal Therefore it could be removed -->
        <profile>
            <id>pre-release</id>
            <build>

```

804459869284a1d6ffb17aa59d9037716a1b8901","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/373/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/374,https://api.github.com/repos/apache/incubator-wayang/issues/374,incubator-wayang,1994446630,374,deprecated class -> put input in a singleton list,github-actions,,,,OPEN,2023-11-15T10:03:49Z,2023-11-15T10:03:50Z,"deprecated class -> put input in a singleton list

https://github.com/apache/incubator-wayang/blob/d75a5723989928ac2e633d76bf665b2a5cb3eaf1/wayang-ml4all/src/main/java/org/apache/wayang/ml4all/abstraction/api/UpdateLocal.java#L39

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.ml4all.abstraction.api;

import org.apache.wayang.ml4all.abstraction.plan.ML4allGlobalVars;

public abstract class UpdateLocal<R, V> extends LogicalOperator {

    /**
     * Computes the new value of the global variable
     *
     * @param input the ouput of the aggregate of the {@link Compute}
     * @param context
     */
    public abstract R process(V input, ML4allGlobalVars context);

    /**
     * Assigns the new value of the global variable to the {@link ML4allGlobalVars}
     * @param input the output of the process method
     * @param context
     * @return the new {@link ML4allGlobalVars}
     */
    public abstract ML4allGlobalVars assign (R input, ML4allGlobalVars context); //TODO: deprecated class -> put input in a singleton list
}

```

740b580635afb6fbe8268d92f3e9e34392eb5132","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/374/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/375,https://api.github.com/repos/apache/incubator-wayang/issues/375,incubator-wayang,1994446688,375,check why this does not work because of the List<V> generic type,github-actions,,,,OPEN,2023-11-15T10:03:51Z,2023-11-15T10:03:52Z,"check why this does not work because of the List<V> generic type

public void open(ExecutionContext executionContext) {

context = executionContext.<ML4allGlobalVars>getBroadcast(""context"").iterator().next();

https://github.com/apache/incubator-wayang/blob/d75a5723989928ac2e633d76bf665b2a5cb3eaf1/wayang-ml4all/src/main/java/org/apache/wayang/ml4all/abstraction/plan/wrappers/AssignWrapper.java#L26

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.ml4all.abstraction.plan.wrappers;

import org.apache.wayang.ml4all.abstraction.api.Update;
import org.apache.wayang.ml4all.abstraction.plan.ML4allGlobalVars;

import java.util.List;

public class AssignWrapper<R> extends LogicalOperatorWrapperWithContext<ML4allGlobalVars, List<R>> { //TODO:check why this does not work because of the List<V> generic type

    Update<R,?> logOp;

    public AssignWrapper(Update logOp) {
        this.logOp = logOp;
    }

    @Override
    public ML4allGlobalVars apply(List<R> o) {
        ML4allGlobalVars newContext = context.clone();
        return this.logOp.assign(o, newContext);
    }

    @Override
    public void initialise() {

    }

//    @Override
//    public void open(ExecutionContext executionContext) {
//        context = executionContext.<ML4allGlobalVars>getBroadcast(""context"").iterator().next();
//
//    }
}

```

c3d0a623a7d8e7bac13e2adf6316762638dd2b33","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/375/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/378,https://api.github.com/repos/apache/incubator-wayang/issues/378,incubator-wayang,2003945472,378,SqlContext has no option to configure platforms,juripetersen,43411515,Juri Petersen,,CLOSED,2023-11-21T10:23:41Z,2023-11-22T03:20:21Z,"The SqlContext's constructor hard-codes three platforms and provides no options to customise the desired plugins and therefore used platforms:

```java
public SqlContext(Configuration configuration) throws SQLException {
        Configuration configuration1 = configuration.fork(String.format(""SqlContext(%s)"", configuration.getName()));

        wayangContext = new WayangContext(configuration1)
                .withPlugin(Java.basicPlugin())
                .withPlugin(Spark.basicPlugin())
                .withPlugin(Postgres.plugin());

        calciteSchema = SchemaUtils.getSchema(configuration);
    }
```

A proposed solution would be to change `SqlContext` so that it extends `WayangContext`, providing the desired functionality.","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/378/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/378,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5shTgb,incubator-wayang,1820669979,378,NA,kbeedkar,8502905,Kaustubh Beedkar,,NA,2023-11-21T10:45:17Z,2023-11-21T10:45:17Z,@juripetersen Indeed. Can you go ahead with your proposed solution and create a PR?,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5shTgb/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/378,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5shVAl,incubator-wayang,1820676133,378,NA,juripetersen,43411515,Juri Petersen,,NA,2023-11-21T10:49:00Z,2023-11-21T10:49:00Z,@kbeedkar the PR is now linked.,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5shVAl/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/380,https://api.github.com/repos/apache/incubator-wayang/issues/380,incubator-wayang,2017014191,380,New plugin which replaces postgres plugin and can add any jdbc platform.,Vigneshwar2002,104296716,Vigneshwar,,CLOSED,2023-11-29T16:47:36Z,2023-12-05T07:54:29Z,"The current wayang architecture becomes tedious when we want to add a new JDBC platforms. one can see from postgres and sqlite3 modules that there is a lot of code redundancy.

So we can write a new plugin that can add any jdbc plaform by simply taking the corresponding jdbc driver through configuration.

we can change the API usage as below.
`WayangContext wayangContext = new WayangContext(configuration)
                .withPlugin(Java.basicPlugin())
                .withPlugin(GenericJdbc.plugin())
                ;`
` configuration.setProperty(""wayang.postgres.jdbc.driverName"", ""org.postgresql.Driver"");`
` TableSource person = new GenericJdbcTableSource(""postgres"",""person"");
`

User has to provide the name of the jdbc platform on which his table resides.","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/380/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/380,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5tNxzD,incubator-wayang,1832328387,380,NA,kbeedkar,8502905,Kaustubh Beedkar,,NA,2023-11-29T16:53:26Z,2023-11-29T16:53:26Z,"To be clear, it does not replace the existing PostgresSql platform, but adds a new plugin, that allows
- support different jdbc platforms
- multiple instances of the same DBMS ","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5tNxzD/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/380,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5trfh-,incubator-wayang,1840117886,380,NA,2pk03,1323575,Alexander Alten-Lorenz,,NA,2023-12-05T06:57:38Z,2023-12-05T06:57:38Z,"Thank you, I checked and would +1 on this! ","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5trfh-/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/383,https://api.github.com/repos/apache/incubator-wayang/issues/383,incubator-wayang,2025511025,383,Load ChannelInstances from executionState? (as of now there is no input into Pos...,github-actions,,,,OPEN,2023-12-05T07:54:47Z,2023-12-05T07:54:48Z,"Load ChannelInstances from executionState? (as of now there is no input into PostgreSQL).

this.connection.close();

} catch (SQLException e) {

this.logger.error(""Could not close JDBC connection to PostgreSQL correctly."", e);

}

https://github.com/apache/incubator-wayang/blob/5e6a07edaae3e7ebac9ac73814f95bafe741845d/wayang-platforms/wayang-generic-jdbc/src/main/java/org/apache/wayang/genericjdbc/execution/GenericJdbcExecutor.java#L80

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.genericjdbc.execution;

import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.apache.wayang.basic.channels.FileChannel;
import org.apache.wayang.core.api.Job;
import org.apache.wayang.core.api.exception.WayangException;
import org.apache.wayang.core.optimizer.OptimizationContext;
import org.apache.wayang.core.plan.executionplan.Channel;
import org.apache.wayang.core.plan.executionplan.ExecutionStage;
import org.apache.wayang.core.plan.executionplan.ExecutionTask;
import org.apache.wayang.core.plan.wayangplan.Operator;
import org.apache.wayang.core.platform.ExecutionState;
import org.apache.wayang.core.platform.Executor;
import org.apache.wayang.core.platform.ExecutorTemplate;
import org.apache.wayang.core.platform.Platform;
import org.apache.wayang.core.util.WayangCollections;
import org.apache.wayang.core.util.fs.FileSystem;
import org.apache.wayang.core.util.fs.FileSystems;
import org.apache.wayang.jdbc.channels.SqlQueryChannel;
import org.apache.wayang.genericjdbc.operators.GenericJdbcExecutionOperator;
import org.apache.wayang.genericjdbc.operators.GenericJdbcFilterOperator;
import org.apache.wayang.genericjdbc.operators.GenericJdbcProjectionOperator;
import org.apache.wayang.genericjdbc.operators.GenericJdbcTableSource;
import org.apache.wayang.genericjdbc.platform.GenericJdbcPlatform;
import org.apache.wayang.jdbc.compiler.FunctionCompiler;


import java.io.IOException;
import java.io.OutputStreamWriter;
import java.io.UncheckedIOException;
import java.sql.Connection;
import java.sql.ResultSet;
import java.sql.ResultSetMetaData;
import java.sql.SQLException;
import java.util.ArrayList;
import java.util.Collection;
import java.util.Set;
import java.util.stream.Collectors;

/**
 * {@link Executor} implementation for the {@link GenericJdbcPlatform}.
 */
public class GenericJdbcExecutor extends ExecutorTemplate {

    private final GenericJdbcPlatform platform;

    private final Connection connection = null;

    private final Logger logger = LogManager.getLogger(this.getClass());

    private final FunctionCompiler functionCompiler = new FunctionCompiler();

    public GenericJdbcExecutor(GenericJdbcPlatform platform, Job job) {
        super(job.getCrossPlatformExecutor());
        this.platform = platform;
//        this.connection = this.platform.createDatabaseDescriptor(job.getConfiguration()).createJdbcConnection();
    }

    @Override
    public void execute(ExecutionStage stage, OptimizationContext optimizationContext, ExecutionState executionState) {
        // TODO: Load ChannelInstances from executionState? (as of now there is no input into PostgreSQL).
        Collection<?> startTasks = stage.getStartTasks();
        Collection<?> termTasks = stage.getTerminalTasks();

        // Verify that we can handle this instance.
        assert startTasks.size() == 1 : ""Invalid jdbc stage: multiple sources are not currently supported"";
        ExecutionTask startTask = (ExecutionTask) startTasks.toArray()[0];
        assert termTasks.size() == 1 : ""Invalid JDBC stage: multiple terminal tasks are not currently supported."";
        ExecutionTask termTask = (ExecutionTask) termTasks.toArray()[0];
        assert startTask.getOperator() instanceof GenericJdbcTableSource : ""Invalid JDBC stage: Start task has to be a TableSource"";

        // Extract the different types of ExecutionOperators from the stage.
        GenericJdbcTableSource tableOp = (GenericJdbcTableSource) startTask.getOperator();
        SqlQueryChannel.Instance tipChannelInstance = this.instantiateOutboundChannel(startTask, optimizationContext);
        Collection<ExecutionTask> filterTasks = new ArrayList<>(4);
        ExecutionTask projectionTask = null;
        Set<ExecutionTask> allTasks = stage.getAllTasks();
        assert allTasks.size() <= 3;
        ExecutionTask nextTask = this.findGenericJdbcExecutionOperatorTaskInStage(startTask, stage);
        while (nextTask != null) {
            // Evaluate the nextTask.
            if (nextTask.getOperator() instanceof GenericJdbcFilterOperator) {
                filterTasks.add(nextTask);
            } else if (nextTask.getOperator() instanceof GenericJdbcProjectionOperator) {
                assert projectionTask == null; //Allow one projection operator per stage for now.
                projectionTask = nextTask;

            } else {
                throw new WayangException(String.format(""Unsupported JDBC execution task %s"", nextTask.toString()));
            }

            // Move the tipChannelInstance.
            tipChannelInstance = this.instantiateOutboundChannel(nextTask, optimizationContext, tipChannelInstance);

            // Go to the next nextTask.
            nextTask = this.findGenericJdbcExecutionOperatorTaskInStage(nextTask, stage);
        }

        // Create the SQL query.
        String tableName = this.getSqlClause(tableOp);
        String jdbcName = tableOp.jdbcName;
        Collection<String> conditions = filterTasks.stream()
                .map(ExecutionTask::getOperator)
                .map(this::getSqlClause)
                .collect(Collectors.toList());
        String projection = projectionTask == null ? ""*"" : this.getSqlClause(projectionTask.getOperator());
        String query = this.createSqlQuery(tableName, conditions, projection);
        tipChannelInstance.setSqlQuery(query);
        tipChannelInstance.setJdbcName(jdbcName);

        // Return the tipChannelInstance.
        executionState.register(tipChannelInstance);
    }

    /**
     * Retrieves the follow-up {@link ExecutionTask} of the given {@code task} unless it is not comprising a
     * {@link GenericJdbcExecutionOperator} and/or not in the given {@link ExecutionStage}.
     *
     * @param task  whose follow-up {@link ExecutionTask} is requested; should have a single follower
     * @param stage in which the follow-up {@link ExecutionTask} should be
     * @return the said follow-up {@link ExecutionTask} or {@code null} if none
     */
    private ExecutionTask findGenericJdbcExecutionOperatorTaskInStage(ExecutionTask task, ExecutionStage stage) {
        assert task.getNumOuputChannels() == 1;
        final Channel outputChannel = task.getOutputChannel(0);
        final ExecutionTask consumer = WayangCollections.getSingle(outputChannel.getConsumers());
        return consumer.getStage() == stage && consumer.getOperator() instanceof GenericJdbcExecutionOperator ?
                consumer :
                null;
    }

    /**
     * Instantiates the outbound {@link SqlQueryChannel} of an {@link ExecutionTask}.
     *
     * @param task                whose outbound {@link SqlQueryChannel} should be instantiated
     * @param optimizationContext provides information about the {@link ExecutionTask}
     * @return the {@link SqlQueryChannel.Instance}
     */
    private SqlQueryChannel.Instance instantiateOutboundChannel(ExecutionTask task,
                                                                       OptimizationContext optimizationContext) {
        assert task.getNumOuputChannels() == 1 : String.format(""Illegal task: %s."", task);
        assert task.getOutputChannel(0) instanceof SqlQueryChannel : String.format(""Illegal task: %s."", task);

        SqlQueryChannel outputChannel = (SqlQueryChannel) task.getOutputChannel(0);
        OptimizationContext.OperatorContext operatorContext = optimizationContext.getOperatorContext(task.getOperator());
        return outputChannel.createInstance(this, operatorContext, 0);
    }

    /**
     * Instantiates the outbound {@link SqlQueryChannel} of an {@link ExecutionTask}.
     *
     * @param task                       whose outbound {@link SqlQueryChannel} should be instantiated
     * @param optimizationContext        provides information about the {@link ExecutionTask}
     * @param predecessorChannelInstance preceeding {@link SqlQueryChannel.Instance} to keep track of lineage
     * @return the {@link SqlQueryChannel.Instance}
     */
    private SqlQueryChannel.Instance instantiateOutboundChannel(ExecutionTask task,
                                                                       OptimizationContext optimizationContext,
                                                                       SqlQueryChannel.Instance predecessorChannelInstance) {
        final SqlQueryChannel.Instance newInstance = this.instantiateOutboundChannel(task, optimizationContext);
        newInstance.getLineage().addPredecessor(predecessorChannelInstance.getLineage());
        return newInstance;
    }

    /**
     * Creates a SQL query.
     *
     * @param tableName  the table to be queried
     * @param conditions conditions for the {@code WHERE} clause
     * @param projection projection for the {@code SELECT} clause
     * @return the SQL query
     */
    protected String createSqlQuery(String tableName, Collection<String> conditions, String projection) {
        StringBuilder sb = new StringBuilder(1000);
        sb.append(""SELECT "").append(projection).append("" FROM "").append(tableName);
        if (!conditions.isEmpty()) {
            sb.append("" WHERE "");
            String separator = """";
            for (String condition : conditions) {
                sb.append(separator).append(condition);
                separator = "" AND "";
            }
        }
        sb.append(';');
        return sb.toString();
    }

    /**
     * Creates a SQL clause that corresponds to the given {@link Operator}.
     *
     * @param operator for that the SQL clause should be generated
     * @return the SQL clause
     */
    private String getSqlClause(Operator operator) {
        return ((GenericJdbcExecutionOperator) operator).createSqlClause(this.connection, this.functionCompiler);
    }

    @Override
    public void dispose() {
//        try {
//            this.connection.close();
//        } catch (SQLException e) {
//            this.logger.error(""Could not close JDBC connection to PostgreSQL correctly."", e);
//        }
        return;
    }

    @Override
    public Platform getPlatform() {
        return this.platform;
    }


    private void saveResult(FileChannel.Instance outputFileChannelInstance, ResultSet rs) throws IOException, SQLException {
        // Output results.
        final FileSystem outFs = FileSystems.getFileSystem(outputFileChannelInstance.getSinglePath()).get();
        try (final OutputStreamWriter writer = new OutputStreamWriter(outFs.create(outputFileChannelInstance.getSinglePath()))) {
            while (rs.next()) {
                //System.out.println(rs.getInt(1) + "" "" + rs.getString(2));
                ResultSetMetaData rsmd = rs.getMetaData();
                for (int i = 1; i <= rsmd.getColumnCount(); i++) {
                    writer.write(rs.getString(i));
                    if (i < rsmd.getColumnCount()) {
                        writer.write('\t');
                    }
                }
                if (!rs.isLast()) {
                    writer.write('\n');
                }
            }
        } catch (UncheckedIOException e) {
            throw e.getCause();
        }
    }
}

```

7a42fa55604535c1107f2822d76f2fccb089c23e","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/383/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/384,https://api.github.com/repos/apache/incubator-wayang/issues/384,incubator-wayang,2026154210,384,Jdbc and Postgres do not support JoinOperators yet,juripetersen,43411515,Juri Petersen,,CLOSED,2023-12-05T13:06:03Z,2023-12-06T13:44:08Z,"The Postgres Platform only supports simple select-project queries for now.
Introducing Joins would expand the possibilities of using Postgres with Wayang.

I will open a pull request and propose a solution to this.","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/384/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/384,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5tt9EA,incubator-wayang,1840763136,384,NA,kbeedkar,8502905,Kaustubh Beedkar,,NA,2023-12-05T13:09:09Z,2023-12-05T13:09:09Z,"At the moment only simple projections and filters can be pushed down. Supporting join push downs is welcomed.

","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5tt9EA/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/384,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5tt9on,incubator-wayang,1840765479,384,NA,zkaoudi,10105712,Zoi Kaoudi,,NA,2023-12-05T13:10:39Z,2023-12-05T13:10:39Z,+1,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5tt9on/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/386,https://api.github.com/repos/apache/incubator-wayang/issues/386,incubator-wayang,2056900156,386,Add Support for Apache Kafka ,kamir,1241122,Mirko Kämpf,mirko.kaempf@gmail.com,OPEN,2023-12-27T04:33:21Z,2023-12-27T04:33:21Z,"Besides the following processing platforms: 

[Java 8 Streams]
[Apache Spark](https://spark.apache.org/)
[GraphChi](https://github.com/GraphChi/graphchi-java)
[Postgres](http://www.postgresql.org/)
[SQLite](https://www.sqlite.org/)
[Apache Flink](https://flink.apache.org/)

it is suggested to also support Apache Kafka.

This issue is considered to be an umbrella for other issues, related to that topic. I expect it to be open for some time, until we can say: Apache Wayang supports Apache Kafka as a processing platform (even if today it is not yet 100% clear in which scope that will be)","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/386/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/387,https://api.github.com/repos/apache/incubator-wayang/issues/387,incubator-wayang,2056909604,387,Define Scope for Apache Kafka Support,kamir,1241122,Mirko Kämpf,mirko.kaempf@gmail.com,OPEN,2023-12-27T04:51:41Z,2024-08-13T11:45:02Z,"This issue is related to #386 .

**In this issue we want to identify the scope of Apache Wayang - Apache Kafka support.**

Apache Kafka does not offer a processing engine. KStreams and KSQLDB have been developed for ""Kafka internal streaming processing"". But it has been decided to discontinue KSQLDB. Instead, Apache Flink has been selected as the new event streaming processing system on top of Apache Kafka. But besides Apache Flink, there is the KStreams library. KSQLDB has been created using the KStreams event stream processing framework.

Why not to use ksqlDB? (from Google Search)
ksqlDB is inefficient with long-running or high-cardinality aggregation. Routing, filtering, and running basic transformations over streaming data are the strengths of ksqlDB, and while it can perform some aggregations, it will suffer under more complex scenarios requiring large amounts of state.27.07.2023

With this in mind I suggest to define 2 scopes for Apache Kafka support in Apache Wayang:

**Scope 1:** Support Apache Kafka Source and Sink components in Apache Wayang plans. 
**Scope 2:** Support KStreams for ""native Kafka Streaming processing"" coordinated by Apache Wayang.

","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/387/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/387,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5vdSLC,incubator-wayang,1869947586,387,NA,kamir,1241122,Mirko Kämpf,mirko.kaempf@gmail.com,NA,2023-12-27T04:56:20Z,2023-12-27T04:56:20Z,"I suggest to start with implementing a Kafka-Source and a Kafka-Sink components, so that existing Apache Wayang applications can get input directly from Kafka topics and store results directly in such topics.
This will not yet give us the full ""Apache Kafka support as a processing platform for Apache Wayang"" - but it is a starting point for interacting with the data which lives in Apache Kafka topics.","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5vdSLC/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/387,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5veZ6O,incubator-wayang,1870241422,387,NA,zkaoudi,10105712,Zoi Kaoudi,,NA,2023-12-27T11:59:40Z,2023-12-27T11:59:40Z,"+1

A kafka source+sink would be awesome. ","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5veZ6O/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/387,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5y6RDK,incubator-wayang,1927876810,387,NA,kamir,1241122,Mirko Kämpf,mirko.kaempf@gmail.com,NA,2024-02-05T19:23:35Z,2024-02-05T19:23:35Z,"I am back on this task working out a simple KafkaSource component, reading plain text messages from a Kafka cluster, comparable with the JavaFileSource, which can read file, line by line from HTTP URLs now.","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5y6RDK/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/387,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6IQkov,incubator-wayang,2286045743,387,NA,kamir,1241122,Mirko Kämpf,mirko.kaempf@gmail.com,NA,2024-08-13T11:45:01Z,2024-08-13T11:45:01Z,Started merging the feature via branch mk-feature-2,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6IQkov/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/390,https://api.github.com/repos/apache/incubator-wayang/issues/390,incubator-wayang,2076083318,390,How much faster is Apache Wayang than other frameworks? ,section9-lab,22140958,Tachikoma,,CLOSED,2024-01-11T08:56:18Z,2024-01-30T08:25:41Z,"How much faster is Apache Wayang than other frameworks?

Is there a Benchmark data comparison chart?

","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/390/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/390,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5wdWg_,incubator-wayang,1886742591,390,NA,2pk03,1323575,Alexander Alten-Lorenz,,NA,2024-01-11T09:49:59Z,2024-01-11T09:49:59Z,"We did some, here's a blogpost about: https://www.blossomsky.io/blog/benchmarking-datablooms-blossom-achieving-faster-and-more-efficient-big-data-analytics","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5wdWg_/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/390,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5yOIQm,incubator-wayang,1916306470,390,NA,2pk03,1323575,Alexander Alten-Lorenz,,NA,2024-01-30T08:25:41Z,2024-01-30T08:25:41Z,"We updated the website, here's the benchmark:
https://wayang.apache.org/docs/introduction/benchmark","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M5yOIQm/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/391,https://api.github.com/repos/apache/incubator-wayang/issues/391,incubator-wayang,2076467018,391,other parameters,github-actions,,,,OPEN,2024-01-11T12:13:01Z,2024-01-11T12:13:01Z,"other parameters

https://github.com/apache/incubator-wayang/blob/f8d4a8efb107a2073f2c8ac4dedc0fb4b0474859/wayang-commons/wayang-basic/src/main/java/org/apache/wayang/basic/operators/LinearRegressionOperator.java#L32

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.basic.operators;

import org.apache.wayang.basic.data.Tuple2;
import org.apache.wayang.basic.model.LinearRegressionModel;
import org.apache.wayang.core.api.Configuration;
import org.apache.wayang.core.optimizer.cardinality.CardinalityEstimator;
import org.apache.wayang.core.plan.wayangplan.UnaryToUnaryOperator;
import org.apache.wayang.core.types.DataSetType;

import java.util.Optional;

public class LinearRegressionOperator extends UnaryToUnaryOperator<Tuple2<double[], Double>, LinearRegressionModel> {

    // TODO other parameters
    protected boolean fitIntercept;

    public LinearRegressionOperator(boolean fitIntercept) {
        super(DataSetType.createDefaultUnchecked(Tuple2.class),
                DataSetType.createDefaultUnchecked(LinearRegressionModel.class),
                false);
        this.fitIntercept = fitIntercept;
    }

    public LinearRegressionOperator(LinearRegressionOperator that) {
        super(that);
        this.fitIntercept = that.fitIntercept;
    }

    public boolean getFitIntercept() {
        return fitIntercept;
    }

    @Override
    public Optional<CardinalityEstimator> createCardinalityEstimator(int outputIndex, Configuration configuration) {
        // TODO
        return super.createCardinalityEstimator(outputIndex, configuration);
    }
}

```

7762fbaaac2b0864cf60a0525957f81cc67a3035","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/391/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/392,https://api.github.com/repos/apache/incubator-wayang/issues/392,incubator-wayang,2076467085,392,createDefaultUnchecked or createDefault?,github-actions,,,,CLOSED,2024-01-11T12:13:03Z,2024-03-30T12:13:31Z,"createDefaultUnchecked or createDefault?

https://github.com/apache/incubator-wayang/blob/f8d4a8efb107a2073f2c8ac4dedc0fb4b0474859/wayang-commons/wayang-basic/src/main/java/org/apache/wayang/basic/operators/ModelTransformOperator.java#L49

```java

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.basic.operators;

import com.fasterxml.jackson.core.type.TypeReference;
import org.apache.wayang.basic.data.Tuple2;
import org.apache.wayang.basic.model.Model;
import org.apache.wayang.core.api.Configuration;
import org.apache.wayang.core.optimizer.cardinality.CardinalityEstimator;
import org.apache.wayang.core.plan.wayangplan.BinaryToUnaryOperator;
import org.apache.wayang.core.types.DataSetType;
import org.apache.wayang.core.util.TypeConverter;

import java.util.Optional;

public class ModelTransformOperator<X, Y> extends BinaryToUnaryOperator<Model<X, Y>, X, Tuple2<X, Y>> {

    public static ModelTransformOperator<double[], Integer> kMeans() {
        // The type of TypeReference cannot be omitted, to avoid the following error.
        // error: cannot infer type arguments for TypeReference<T>, reason: cannot use '<>' with anonymous inner classes
        return new ModelTransformOperator<>(new TypeReference<double[]>() {}, new TypeReference<Tuple2<double[], Integer>>() {});
    }

    public static ModelTransformOperator<double[], Double> linearRegression() {
        return new ModelTransformOperator<>(new TypeReference<double[]>() {}, new TypeReference<Tuple2<double[], Double>>() {});
    }

    public static ModelTransformOperator<double[], Integer> decisionTreeClassification() {
        return new ModelTransformOperator<>(new TypeReference<double[]>() {}, new TypeReference<Tuple2<double[], Integer>>() {});
    }

    public ModelTransformOperator(DataSetType<X> inType, DataSetType<Tuple2<X, Y>> outType) {
        // TODO createDefaultUnchecked or createDefault?
        super(DataSetType.createDefaultUnchecked(Model.class), inType, outType, false);
    }

    public ModelTransformOperator(Class<X> inType, Class<Tuple2<X, Y>> outType) {
        this(DataSetType.createDefault(inType), DataSetType.createDefault(outType));
    }

    public ModelTransformOperator(TypeReference<X> inType, TypeReference<Tuple2<X, Y>> outType) {
        this(TypeConverter.convert(inType), TypeConverter.convert(outType));
    }

    public ModelTransformOperator(ModelTransformOperator<X, Y> that) {
        super(that);
    }

    @Override
    public Optional<CardinalityEstimator> createCardinalityEstimator(int outputIndex, Configuration configuration) {
        // TODO
        return super.createCardinalityEstimator(outputIndex, configuration);
    }
}

```

aca807d476ffbf08e2b05a7fbaa4b8227e06aa32","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/392/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/392,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M544U1H,incubator-wayang,2028031303,392,NA,github-actions,,,,NA,2024-03-30T12:13:30Z,2024-03-30T12:13:30Z,Closed in b0b60543e2317f19ea845f7fdbc21a6a4641d2ef,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M544U1H/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/393,https://api.github.com/repos/apache/incubator-wayang/issues/393,incubator-wayang,2076467192,393,cached or uncached?,github-actions,,,,CLOSED,2024-01-11T12:13:06Z,2024-03-30T12:13:33Z,"cached or uncached?

https://github.com/apache/incubator-wayang/blob/f8d4a8efb107a2073f2c8ac4dedc0fb4b0474859/wayang-platforms/wayang-spark/code/main/java/org/apache/wayang/spark/operators/ml/SparkKMeansOperator.java#L73

```java


    @Override
    public List<ChannelDescriptor> getSupportedInputChannels(int index) {
        // TODO cached or uncached?
        return Arrays.asList(RddChannel.UNCACHED_DESCRIPTOR, RddChannel.CACHED_DESCRIPTOR);
    }

    @Override
    public List<ChannelDescriptor> getSupportedOutputChannels(int index) {
        return Collections.singletonList(CollectionChannel.DESCRIPTOR);
    }

    @Override

```

eb967794c4ff90a335e971aba356afc7ef134b87","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/393/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/393,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M544U1P,incubator-wayang,2028031311,393,NA,github-actions,,,,NA,2024-03-30T12:13:32Z,2024-03-30T12:13:32Z,Closed in b0b60543e2317f19ea845f7fdbc21a6a4641d2ef,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M544U1P/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/405,https://api.github.com/repos/apache/incubator-wayang/issues/405,incubator-wayang,2144612177,405,CostModel configurations do not get copied in new Configuration(parent),juripetersen,43411515,Juri Petersen,,CLOSED,2024-02-20T15:14:00Z,2024-02-29T07:48:15Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/405/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/410,https://api.github.com/repos/apache/incubator-wayang/issues/410,incubator-wayang,2151366444,410,Add GitHub banner to website,2pk03,1323575,Alexander Alten-Lorenz,,CLOSED,2024-02-23T15:56:56Z,2024-02-26T09:59:17Z,Would be nice to have a banner at the Wayang website to advertise stargazing.,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/410/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/410,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M51DCbm,incubator-wayang,1963730662,410,NA,2pk03,1323575,Alexander Alten-Lorenz,,NA,2024-02-26T09:59:17Z,2024-02-26T09:59:17Z,PR and merged: https://github.com/apache/incubator-wayang-website/pull/35,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M51DCbm/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/411,https://api.github.com/repos/apache/incubator-wayang/issues/411,incubator-wayang,2163197235,411,CardinalityRepository is unusable,juripetersen,43411515,Juri Petersen,,CLOSED,2024-03-01T11:26:02Z,2024-03-04T11:49:01Z,"As of now, the code in the CardinalityRepository is commented.
However, especially for ML use cases, sampling and storing measured cardinalities can be an essential step.

I think we should try to fix the code to provide this functionality to users.","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/411/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/411,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M51miF6,incubator-wayang,1973035386,411,NA,juripetersen,43411515,Juri Petersen,,NA,2024-03-01T11:40:32Z,2024-03-01T11:40:32Z,"Desirable output can resemble this:

```json
{""inputs"":[{""name"":""in"",""index"":0,""isBroadcast"":false,""lowerBound"":206,""upperBound"":206,""confidence"":1.0}],""operator"":{""class"":""org.apache.wayang.spark.operators.SparkFlatMapOperator""},""output"":{""name"":""out"",""index"":0,""cardinality"":1759}}
{""inputs"":[{""name"":""in"",""index"":0,""isBroadcast"":false,""lowerBound"":206,""upperBound"":206,""confidence"":1.0}],""operator"":{""class"":""org.apache.wayang.basic.operators.FlatMapOperator""},""output"":{""name"":""out"",""index"":0,""cardinality"":1759}}
{""inputs"":[{""name"":""in"",""index"":0,""isBroadcast"":false,""lowerBound"":206,""upperBound"":206,""confidence"":1.0}],""operator"":{""class"":""org.apache.wayang.java.operators.JavaFlatMapOperator""},""output"":{""name"":""out"",""index"":0,""cardinality"":1759}}
{""inputs"":[{""name"":""in"",""index"":0,""isBroadcast"":false,""lowerBound"":1759,""upperBound"":1759,""confidence"":1.0}],""operator"":{""class"":""org.apache.wayang.basic.operators.FilterOperator""},""output"":{""name"":""out"",""index"":0,""cardinality"":1611}}
{""inputs"":[{""name"":""in"",""index"":0,""isBroadcast"":false,""lowerBound"":1759,""upperBound"":1759,""confidence"":1.0}],""operator"":{""class"":""org.apache.wayang.spark.operators.SparkFilterOperator""},""output"":{""name"":""out"",""index"":0,""cardinality"":1611}}
{""inputs"":[{""name"":""in"",""index"":0,""isBroadcast"":false,""lowerBound"":1759,""upperBound"":1759,""confidence"":1.0}],""operator"":{""class"":""org.apache.wayang.java.operators.JavaFilterOperator""},""output"":{""name"":""out"",""index"":0,""cardinality"":1611}}
{""inputs"":[{""name"":""in"",""index"":0,""isBroadcast"":false,""lowerBound"":1611,""upperBound"":1611,""confidence"":1.0}],""operator"":{""class"":""org.apache.wayang.basic.operators.MapOperator""},""output"":{""name"":""out"",""index"":0,""cardinality"":1611}}
{""inputs"":[{""name"":""in"",""index"":0,""isBroadcast"":false,""lowerBound"":1611,""upperBound"":1611,""confidence"":1.0}],""operator"":{""class"":""org.apache.wayang.spark.operators.SparkMapOperator""},""output"":{""name"":""out"",""index"":0,""cardinality"":1611}}
{""inputs"":[{""name"":""in"",""index"":0,""isBroadcast"":false,""lowerBound"":1611,""upperBound"":1611,""confidence"":1.0}],""operator"":{""class"":""org.apache.wayang.java.operators.JavaMapOperator""},""output"":{""name"":""out"",""index"":0,""cardinality"":1611}}
{""inputs"":[{""name"":""in"",""index"":0,""isBroadcast"":false,""lowerBound"":1611,""upperBound"":1611,""confidence"":1.0}],""operator"":{""class"":""org.apache.wayang.basic.operators.ReduceByOperator""},""output"":{""name"":""out"",""index"":0,""cardinality"":493}}
{""inputs"":[{""name"":""in"",""index"":0,""isBroadcast"":false,""lowerBound"":1611,""upperBound"":1611,""confidence"":1.0}],""operator"":{""class"":""org.apache.wayang.spark.operators.SparkReduceByOperator""},""output"":{""name"":""out"",""index"":0,""cardinality"":493}}
{""inputs"":[{""name"":""in"",""index"":0,""isBroadcast"":false,""lowerBound"":1611,""upperBound"":1611,""confidence"":1.0}],""operator"":{""class"":""org.apache.wayang.java.operators.JavaReduceByOperator""},""output"":{""name"":""out"",""index"":0,""cardinality"":493}}

```
 ","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M51miF6/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/411,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M51miWn,incubator-wayang,1973036455,411,NA,juripetersen,43411515,Juri Petersen,,NA,2024-03-01T11:41:19Z,2024-03-01T11:41:19Z,"Requires configuration like this:

```java
Configuration config = new Configuration();
config.setProperty(""wayang.core.log.enabled"", ""true"");
config.setProperty(""wayang.core.log.cardinalities"", filePath);
config.setProperty(""wayang.core.optimizer.instrumentation"", ""org.apache.wayang.core.profiling.FullInstrumentationStrategy"");
```","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M51miWn/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/414,https://api.github.com/repos/apache/incubator-wayang/issues/414,incubator-wayang,2181042448,414,Add sample method,github-actions,,,,OPEN,2024-03-12T08:43:53Z,2024-03-12T08:43:54Z,"Add sample method

https://github.com/apache/incubator-wayang/blob/d44a00a45f2e3ab9b2abd08a1b4c1aa94750a3f1/wayang-api/wayang-api-json/src/main/scala/operatorfromjson/unary/SampleOperatorFromJson.scala#L35

```scala

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.json.operatorfromjson.unary

import com.fasterxml.jackson.annotation.JsonTypeName
import org.apache.wayang.api.json.operatorfromjson.OperatorFromJson

@JsonTypeName(OperatorFromJson.OperatorNames.Sample)
case class SampleOperatorFromJson(override val id: Long,
                                  override val input: Array[Long],
                                  override val output: Array[Long],
                                  override val cat: String,
                                  override val operatorName: String,
                                  val data: SampleOperatorFromJson.Data)
  extends OperatorFromJson(id, input, output, cat, operatorName) {
}

object SampleOperatorFromJson {
  // TODO: Add sample method
  case class Data(sampleSize: Int)
}


```

9871c5a93e213670c7caffd7945884051cb6f3cb","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/414/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/417,https://api.github.com/repos/apache/incubator-wayang/issues/417,incubator-wayang,2193629450,417,[Question] How to print/explain plans?,wangxiaoying,5569610,Xiaoying Wang,xiaoying_wang@sfu.ca,CLOSED,2024-03-18T23:07:47Z,2024-08-06T08:47:17Z,Is there a way to explain (print out) the logical and physical plan for wayang?,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/417/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/417,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M53kTqG,incubator-wayang,2006006406,417,NA,kbeedkar,8502905,Kaustubh Beedkar,,NA,2024-03-19T07:00:42Z,2024-03-19T07:00:42Z,A quick and dirty solution as a workaround:  https://github.com/apache/incubator-wayang/blob/b134ec4a8b8038486025b47091920d1a85d3f298/wayang-api/wayang-api-sql/src/test/java/org/apache/wayang/api/sql/SqlToWayangRelTest.java#L109,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M53kTqG/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/417,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M53lC97,incubator-wayang,2006200187,417,NA,zkaoudi,10105712,Zoi Kaoudi,,NA,2024-03-19T08:02:36Z,2024-03-19T08:02:36Z,"Besides that, @juripetersen is currently implementing an explain() functionality in the plan builder that will print the logical, inflated, and physical plans. It should be ready soon :)","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M53lC97/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/417,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M53rmPR,incubator-wayang,2007917521,417,NA,wangxiaoying,5569610,Xiaoying Wang,xiaoying_wang@sfu.ca,NA,2024-03-19T18:58:59Z,2024-03-19T18:58:59Z,"Thanks @kbeedkar @zkaoudi  for the quick reply : )

> Besides that, @juripetersen is currently implementing an explain() functionality in the plan builder that will print the logical, inflated, and physical plans. It should be ready soon :)

Looking forward to this feature! I tried the one using `PlanTraversal` as suggested above, but it seems like the result is hard to read. For example, the Q1 and Q3 plan it printed from the `wayang-benchmark` TPCH test is as follows:

```
Q1:
Map[Calculate result fields]LocalCallbackSink[collect()]Map[Post-process line item aggregates]ReduceBy[Aggregate line items]PostgresTableSource[Load LINEITEM table]Filter[Filter line items]Map[Project line items]

Q3:
Map[Project customer-order join product]Filter[Filter line items]LocalCallbackSink[collect()]PostgresTableSource[Load LINEITEM table]Map[Extract customer ID]PostgresTableSource[Load ORDERS table]Join[Join CO with line items]PostgresTableSource[Load CUSTOMER table]Map[Unpack orders]Map[Project orders]Map[Extract line item data]Map[Project CO-line-item join product]Map[Project customers]Filter[Filter customers]Join[Join customers with orders]Map[Project line items]Filter[Filter orders]ReduceBy[Aggregate revenue]
```

It is a bit confusing how to interpret these outputs.","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M53rmPR/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/417,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M54NQyT,incubator-wayang,2016742547,417,NA,zkaoudi,10105712,Zoi Kaoudi,,NA,2024-03-24T09:06:10Z,2024-03-24T09:06:10Z,"Hi @wangxiaoying,

I assume you saw the last merged commit adding the explain functionality. Let us know if you have any further questions. More than happy to help out.","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M54NQyT/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/417,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M54gOsu,incubator-wayang,2021714734,417,NA,wangxiaoying,5569610,Xiaoying Wang,xiaoying_wang@sfu.ca,NA,2024-03-27T00:38:19Z,2024-03-27T00:38:19Z,"> Hi @wangxiaoying,
> 
> I assume you saw the last merged commit adding the explain functionality. Let us know if you have any further questions. More than happy to help out.

Thank you, I will definitely try!","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M54gOsu/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/418,https://api.github.com/repos/apache/incubator-wayang/issues/418,incubator-wayang,2195949828,418,Revisit benchmark jobs,zkaoudi,10105712,Zoi Kaoudi,,OPEN,2024-03-19T20:31:38Z,2024-08-06T11:45:36Z,The jobs in the wayang-benchmark module need to be rewritten/cleaned: either because they are using the foundational java plan building way (the Java ones) or because they are using some hardcoded paths,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/418/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/418,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6HXfQZ,incubator-wayang,2271081497,418,NA,Aryant01,108977687,Aryant Kumar,,NA,2024-08-06T11:38:24Z,2024-08-06T11:38:24Z,"Hey @zkaoudi. Can you please assign me to this issue. I would like to work on it.
","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6HXfQZ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/418,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6HXiT1,incubator-wayang,2271094005,418,NA,zkaoudi,10105712,Zoi Kaoudi,,NA,2024-08-06T11:45:35Z,2024-08-06T11:45:35Z,Just did that :),"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6HXiT1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/420,https://api.github.com/repos/apache/incubator-wayang/issues/420,incubator-wayang,2198464848,420,WordCount using Flink not working,zkaoudi,10105712,Zoi Kaoudi,,CLOSED,2024-03-20T20:08:20Z,2024-10-21T14:00:18Z,"I tried to run the Wordcount with Flink and got this error:

Exception in thread ""main"" org.apache.wayang.core.api.exception.WayangException: Executing T[FlinkReduceBy[Add counters]] failed.
	at org.apache.wayang.flink.execution.FlinkExecutor.execute(FlinkExecutor.java:113)
	at org.apache.wayang.core.platform.PushExecutorTemplate.execute(PushExecutorTemplate.java:73)
	at org.apache.wayang.core.platform.PushExecutorTemplate$StageExecution.execute(PushExecutorTemplate.java:195)
	at org.apache.wayang.core.platform.PushExecutorTemplate$StageExecution.doExecute(PushExecutorTemplate.java:166)
	at org.apache.wayang.core.util.OneTimeExecutable.tryExecute(OneTimeExecutable.java:41)
	at org.apache.wayang.core.util.OneTimeExecutable.execute(OneTimeExecutable.java:54)
	at org.apache.wayang.core.platform.PushExecutorTemplate$StageExecution.executeStage(PushExecutorTemplate.java:156)
	at org.apache.wayang.core.platform.PushExecutorTemplate.execute(PushExecutorTemplate.java:61)
	at org.apache.wayang.core.platform.CrossPlatformExecutor.execute(CrossPlatformExecutor.java:378)
	at org.apache.wayang.core.platform.CrossPlatformExecutor.executeSingleStage(CrossPlatformExecutor.java:248)
	at org.apache.wayang.core.platform.CrossPlatformExecutor.runToBreakpoint(CrossPlatformExecutor.java:320)
	at org.apache.wayang.core.platform.CrossPlatformExecutor.executeUntilBreakpoint(CrossPlatformExecutor.java:156)
	at org.apache.wayang.core.api.Job.execute(Job.java:525)
	at org.apache.wayang.core.api.Job.doExecute(Job.java:309)
	at org.apache.wayang.core.util.OneTimeExecutable.tryExecute(OneTimeExecutable.java:41)
	at org.apache.wayang.core.util.OneTimeExecutable.execute(OneTimeExecutable.java:54)
	at org.apache.wayang.core.api.Job.execute(Job.java:244)
	at org.apache.wayang.core.api.WayangContext.execute(WayangContext.java:120)
	at org.apache.wayang.core.api.WayangContext.execute(WayangContext.java:108)
	at org.apache.wayang.api.PlanBuilder.buildAndExecute(PlanBuilder.scala:105)
	at org.apache.wayang.api.DataQuanta.collect(DataQuanta.scala:758)
	at org.apache.wayang.api.DataQuantaBuilder.collect(DataQuantaBuilder.scala:369)
	at org.apache.wayang.api.DataQuantaBuilder.collect$(DataQuantaBuilder.scala:367)
	at org.apache.wayang.api.BasicDataQuantaBuilder.collect(DataQuantaBuilder.scala:448)
	at org.apache.wayang.apps.wordcount.WordCount.main(WordCount.java:76)
Caused by: java.lang.IllegalArgumentException
	at org.apache.flink.shaded.asm5.org.objectweb.asm.ClassReader.<init>(Unknown Source)
	at org.apache.flink.shaded.asm5.org.objectweb.asm.ClassReader.<init>(Unknown Source)
	at org.apache.flink.shaded.asm5.org.objectweb.asm.ClassReader.<init>(Unknown Source)
	at org.apache.flink.api.java.ClosureCleaner.getClassReader(ClosureCleaner.java:148)
	at org.apache.flink.api.java.ClosureCleaner.cleanThis0(ClosureCleaner.java:115)
	at org.apache.flink.api.java.ClosureCleaner.clean(ClosureCleaner.java:75)
	at org.apache.flink.api.java.DataSet.clean(DataSet.java:186)
	at org.apache.flink.api.java.operators.UnsortedGrouping.reduce(UnsortedGrouping.java:147)
	at org.apache.wayang.flink.operators.FlinkReduceByOperator.evaluate(FlinkReduceByOperator.java:101)
	at org.apache.wayang.flink.execution.FlinkExecutor.execute(FlinkExecutor.java:104)
	... 24 more","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/420/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/420,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6AtLN6,incubator-wayang,2159326074,420,NA,paulk-asert,280016,Paul King,paulk@asert.com.au,NA,2024-06-10T21:37:04Z,2024-06-10T21:37:04Z,ASM ClassReader often fails when reading an unsupported JDK class version. Perhaps try using a different JDK version?,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6AtLN6/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/420,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6QpZpt,incubator-wayang,2426772077,420,NA,zkaoudi,10105712,Zoi Kaoudi,,NA,2024-10-21T14:00:16Z,2024-10-21T14:00:16Z,Works now,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6QpZpt/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/423,https://api.github.com/repos/apache/incubator-wayang/issues/423,incubator-wayang,2209642179,423,Performance issue on TPCH comparing with sparksql,wangxiaoying,5569610,Xiaoying Wang,xiaoying_wang@sfu.ca,OPEN,2024-03-27T01:35:42Z,2024-04-12T16:33:11Z,"### Description

I'm trying to run TPC-H Q3 and compare the performance between Wayang and SparkSQL under the following setup:

* Running both Spark (3.5.1) and Wayang on a local VM with 32 CPU cores and 128GB memory
* Running a postgres instance that maintains all the TPC-H tables (sf=10) on a remote VM

I try to keep the spark setting the same on both runs. And for Q3 wayang took around 3 minutes while spark took only 40 seconds.

### To reproduce

To run Wayang, I compile the project locally (using **tag 1.0.0**) and use the benchmark code under `wayang-benchmark` directly: `./wayang-1.0.0-SNAPSHOT/bin/wayang-submit org.apache.wayang.apps.tpch.TpcH exp\(123\) spark,postgres file:///path/to/wayang.properties Q3`

The wayang.properties file is like the following:
```
wayang.postgres.jdbc.url = jdbc:postgresql://{POSTGRES_IP}:{POSTGRES_PORT}/{TPCH_DB}
wayang.postgres.jdbc.user = {POSTGRES_USER}
wayang.postgres.jdbc.password = {POSTGRES_PASSWORD}

spark.master = local[32]
spark.driver.memory = 110G
spark.executor.memory = 110G
spark.executor.cores = 32
wayang.giraph.hdfs.tempdir = file:///tmp/result/

spark.rdd.compress = true
spark.log.level = INFO
```

To run Spark, I use the following code:
```python
import sys
import time
from pyspark.sql import SparkSession
from contexttimer import Timer

SPARK_JARS = ""path/to/jar/postgresql-42.3.8.jar""
POSTGRES_URL = ""jdbc:postgresql://{POSTGRES_IP}:{POSTGRES_PORT}/{TPCH_DB}""
POSTGRES_USER = ""{POSTGRES_USER}""
POSTGRES_PASSWORD = ""{POSTGRES_PASSWORD}""

TPCH_Q3 = """"""SELECT
    l_orderkey,
    sum(l_extendedprice * (1 - l_discount)) AS revenue,
    o_orderdate,
    o_shippriority
FROM
    customer,
    orders,
    lineitem
WHERE
    c_mktsegment = 'BUILDING'
    AND c_custkey = o_custkey
    AND l_orderkey = o_orderkey
    AND o_orderdate < CAST('1995-03-15' AS date)
    AND l_shipdate > CAST('1995-03-15' AS date)
GROUP BY
    l_orderkey,
    o_orderdate,
    o_shippriority
ORDER BY
    revenue DESC,
    o_orderdate""""""

def registerPostgres(spark, tables, url):
    for name in tables:
        spark.sql(f""""""
            CREATE TEMPORARY VIEW {name}
            USING org.apache.spark.sql.jdbc
            OPTIONS (
              driver ""org.postgresql.Driver"",
              url ""{url}"",
              dbtable ""public.{name}"",
              user '{POSTGRES_USER}',
              password '{POSTGRES_PASSWORD}',
              pushDownAggregate 'true'
            )
            """""")
            

def registerViews(spark):
    registerPostgres(spark, [""lineitem"", ""customer"", ""orders"", ""nation"", ""region"", ""supplier"", ""part"", ""partsupp""], POSTGRES_URL)


def run_query(spark, query):
    with Timer() as timer:
        df = spark.sql(query)
        df.collect()
    print(f""get {df.count()} rows, {len(df.columns)} cols"")
    print(f""plan: {df.explain()}"")
    print(f""took {timer.elapsed:.2f} in total"")
    # print(df)
    print()
    sys.stdout.flush()

        

if __name__ == '__main__':

    spark = (
        SparkSession.builder.master(""local[32]"")
        .appName(""test-spark"")
        .config(""spark.jars"", SPARK_JARS)
        .config(""spark.executor.memory"", ""110g"")
        .config(""spark.driver.memory"", ""110g"")
        .config(""spark.log.level"", ""INFO"")
        .config(""spark.ui.port"", ""4040"")
        .getOrCreate()
    )

    print(spark.sparkContext.getConf().getAll())
    registerViews(spark)

    run_query(spark, TPCH_Q3)
    time.sleep(2)
    spark.stop()

```

### Some investigation

The queries that are used to fetch data from postgres using both platforms, which are basically the same (filter and projection pushdown are enabled).

I try to print the logs of spark execution as much as I can to see the difference between the two.  One significant overhead I found is that wayang produces much larger `ShuffleMapTask` for join than spark does (~46500000 bytes v.s. 8000 bytes), which causes ~2 seconds to serialize each task (64 tasks in total) one by one and result in a 1 minutes overhead. On the other hand, the serialization time on spark is negligible.

I'm not very familiar with spark execution, so I'm not sure why it is the case. Can anyone give me a pointer? Is there anything I'm missing such as the way I run the query or something in configuration? Thank you!","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/423/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/423,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M54mOmZ,incubator-wayang,2023287193,423,NA,wangxiaoying,5569610,Xiaoying Wang,xiaoying_wang@sfu.ca,NA,2024-03-27T16:49:09Z,2024-03-27T16:49:09Z,"Just in case it might be helpful, here is a log snippet related to the serialization overhead of spark execution with wayang I mentioned above:
```
24/03/26 18:18:26 WARN TaskSetManager: Stage 2 contains a task of very large size (45404 KiB). The maximum recommended task size is 1000 KiB.
24/03/26 18:18:26 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 0) (10.155.96.97, executor driver, partition 0, PROCESS_LOCAL, 46494022 bytes) 
24/03/26 18:18:26 INFO TaskSetManager: start serialize task 1...
24/03/26 18:18:26 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 1)
24/03/26 18:18:26 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 1)
24/03/26 18:18:28 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 1)
24/03/26 18:18:28 INFO TaskSetManager: finish serialize task 1...
24/03/26 18:18:28 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 1) (10.155.96.97, executor driver, partition 1, PROCESS_LOCAL, 46490225 bytes) 
24/03/26 18:18:28 INFO TaskSetManager: start serialize task 2...
24/03/26 18:18:28 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 2)
24/03/26 18:18:28 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 2)
24/03/26 18:18:29 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 2)
24/03/26 18:18:29 INFO TaskSetManager: finish serialize task 2...
24/03/26 18:18:29 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 2) (10.155.96.97, executor driver, partition 2, PROCESS_LOCAL, 46488713 bytes) 
24/03/26 18:18:29 INFO TaskSetManager: start serialize task 3...
24/03/26 18:18:29 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 3)
24/03/26 18:18:29 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 3)
24/03/26 18:18:31 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 3)
24/03/26 18:18:31 INFO TaskSetManager: finish serialize task 3...
24/03/26 18:18:31 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 3) (10.155.96.97, executor driver, partition 3, PROCESS_LOCAL, 46488685 bytes) 
24/03/26 18:18:31 INFO TaskSetManager: start serialize task 4...
24/03/26 18:18:31 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 4)
24/03/26 18:18:31 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 4)
24/03/26 18:18:32 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 4)
24/03/26 18:18:32 INFO TaskSetManager: finish serialize task 4...
24/03/26 18:18:32 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 4) (10.155.96.97, executor driver, partition 4, PROCESS_LOCAL, 46486155 bytes) 
24/03/26 18:18:32 INFO TaskSetManager: start serialize task 5...
24/03/26 18:18:32 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 5)
24/03/26 18:18:32 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 5)
24/03/26 18:18:34 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 5)
24/03/26 18:18:34 INFO TaskSetManager: finish serialize task 5...
24/03/26 18:18:34 INFO TaskSetManager: Starting task 5.0 in stage 2.0 (TID 5) (10.155.96.97, executor driver, partition 5, PROCESS_LOCAL, 46490264 bytes) 
24/03/26 18:18:34 INFO TaskSetManager: start serialize task 6...
24/03/26 18:18:34 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 6)
24/03/26 18:18:34 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 6)
24/03/26 18:18:36 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 6)
24/03/26 18:18:36 INFO TaskSetManager: finish serialize task 6...
24/03/26 18:18:36 INFO TaskSetManager: Starting task 6.0 in stage 2.0 (TID 6) (10.155.96.97, executor driver, partition 6, PROCESS_LOCAL, 46488245 bytes) 
24/03/26 18:18:36 INFO TaskSetManager: start serialize task 7...
24/03/26 18:18:36 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 7)
24/03/26 18:18:36 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 7)
24/03/26 18:18:38 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 7)
24/03/26 18:18:38 INFO TaskSetManager: finish serialize task 7...
24/03/26 18:18:38 INFO TaskSetManager: Starting task 7.0 in stage 2.0 (TID 7) (10.155.96.97, executor driver, partition 7, PROCESS_LOCAL, 46487068 bytes) 
24/03/26 18:18:38 INFO TaskSetManager: start serialize task 8...
24/03/26 18:18:38 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 8)
24/03/26 18:18:38 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 8)
24/03/26 18:18:40 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 8)
24/03/26 18:18:40 INFO TaskSetManager: finish serialize task 8...
24/03/26 18:18:40 INFO TaskSetManager: Starting task 8.0 in stage 2.0 (TID 8) (10.155.96.97, executor driver, partition 8, PROCESS_LOCAL, 46489857 bytes) 
24/03/26 18:18:40 INFO TaskSetManager: start serialize task 9...
24/03/26 18:18:40 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 9)
24/03/26 18:18:40 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 9)
24/03/26 18:18:41 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 9)
24/03/26 18:18:41 INFO TaskSetManager: finish serialize task 9...
24/03/26 18:18:41 INFO TaskSetManager: Starting task 9.0 in stage 2.0 (TID 9) (10.155.96.97, executor driver, partition 9, PROCESS_LOCAL, 46489664 bytes) 
24/03/26 18:18:41 INFO TaskSetManager: start serialize task 10...
24/03/26 18:18:41 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 10)
24/03/26 18:18:41 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 10)
24/03/26 18:18:43 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 10)
24/03/26 18:18:43 INFO TaskSetManager: finish serialize task 10...
24/03/26 18:18:43 INFO TaskSetManager: Starting task 10.0 in stage 2.0 (TID 10) (10.155.96.97, executor driver, partition 10, PROCESS_LOCAL, 46488355 bytes) 
24/03/26 18:18:43 INFO TaskSetManager: start serialize task 11...
24/03/26 18:18:43 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 11)
24/03/26 18:18:43 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 11)
24/03/26 18:18:44 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 11)
24/03/26 18:18:44 INFO TaskSetManager: finish serialize task 11...
24/03/26 18:18:44 INFO TaskSetManager: Starting task 11.0 in stage 2.0 (TID 11) (10.155.96.97, executor driver, partition 11, PROCESS_LOCAL, 46488438 bytes) 
24/03/26 18:18:44 INFO TaskSetManager: start serialize task 12...
24/03/26 18:18:44 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 12)
24/03/26 18:18:44 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 12)
24/03/26 18:18:46 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 12)
24/03/26 18:18:46 INFO TaskSetManager: finish serialize task 12...
24/03/26 18:18:46 INFO TaskSetManager: Starting task 12.0 in stage 2.0 (TID 12) (10.155.96.97, executor driver, partition 12, PROCESS_LOCAL, 46488729 bytes) 
24/03/26 18:18:46 INFO TaskSetManager: start serialize task 13...
24/03/26 18:18:46 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 13)
24/03/26 18:18:46 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 13)
24/03/26 18:18:48 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 13)
24/03/26 18:18:48 INFO TaskSetManager: finish serialize task 13...
24/03/26 18:18:48 INFO TaskSetManager: Starting task 13.0 in stage 2.0 (TID 13) (10.155.96.97, executor driver, partition 13, PROCESS_LOCAL, 46486309 bytes) 
24/03/26 18:18:48 INFO TaskSetManager: start serialize task 14...
24/03/26 18:18:48 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 14)
24/03/26 18:18:48 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 14)
24/03/26 18:18:50 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 14)
24/03/26 18:18:50 INFO TaskSetManager: finish serialize task 14...
24/03/26 18:18:50 INFO TaskSetManager: Starting task 14.0 in stage 2.0 (TID 14) (10.155.96.97, executor driver, partition 14, PROCESS_LOCAL, 46489736 bytes) 
24/03/26 18:18:50 INFO TaskSetManager: start serialize task 15...
24/03/26 18:18:50 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 15)
24/03/26 18:18:50 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 15)
24/03/26 18:18:51 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 15)
24/03/26 18:18:51 INFO TaskSetManager: finish serialize task 15...
24/03/26 18:18:51 INFO TaskSetManager: Starting task 15.0 in stage 2.0 (TID 15) (10.155.96.97, executor driver, partition 15, PROCESS_LOCAL, 46489059 bytes) 
24/03/26 18:18:51 INFO TaskSetManager: start serialize task 16...
24/03/26 18:18:51 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 16)
24/03/26 18:18:51 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 16)
24/03/26 18:18:53 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 16)
24/03/26 18:18:53 INFO TaskSetManager: finish serialize task 16...
24/03/26 18:18:53 INFO TaskSetManager: Starting task 16.0 in stage 2.0 (TID 16) (10.155.96.97, executor driver, partition 16, PROCESS_LOCAL, 46488938 bytes) 
24/03/26 18:18:53 INFO TaskSetManager: start serialize task 17...
24/03/26 18:18:53 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 17)
24/03/26 18:18:53 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 17)
24/03/26 18:18:54 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 17)
24/03/26 18:18:54 INFO TaskSetManager: finish serialize task 17...
24/03/26 18:18:54 INFO TaskSetManager: Starting task 17.0 in stage 2.0 (TID 17) (10.155.96.97, executor driver, partition 17, PROCESS_LOCAL, 46485930 bytes) 
24/03/26 18:18:54 INFO TaskSetManager: start serialize task 18...
24/03/26 18:18:54 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 18)
24/03/26 18:18:54 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 18)
24/03/26 18:18:56 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 18)
24/03/26 18:18:56 INFO TaskSetManager: finish serialize task 18...
24/03/26 18:18:56 INFO TaskSetManager: Starting task 18.0 in stage 2.0 (TID 18) (10.155.96.97, executor driver, partition 18, PROCESS_LOCAL, 46486144 bytes) 
24/03/26 18:18:56 INFO TaskSetManager: start serialize task 19...
24/03/26 18:18:56 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 19)
24/03/26 18:18:56 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 19)
24/03/26 18:18:58 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 19)
24/03/26 18:18:58 INFO TaskSetManager: finish serialize task 19...
24/03/26 18:18:58 INFO TaskSetManager: Starting task 19.0 in stage 2.0 (TID 19) (10.155.96.97, executor driver, partition 19, PROCESS_LOCAL, 46491094 bytes) 
24/03/26 18:18:58 INFO TaskSetManager: start serialize task 20...
24/03/26 18:18:58 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 20)
24/03/26 18:18:58 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 20)
24/03/26 18:18:59 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 20)
24/03/26 18:18:59 INFO TaskSetManager: finish serialize task 20...
24/03/26 18:18:59 INFO TaskSetManager: Starting task 20.0 in stage 2.0 (TID 20) (10.155.96.97, executor driver, partition 20, PROCESS_LOCAL, 46492332 bytes) 
24/03/26 18:18:59 INFO TaskSetManager: start serialize task 21...
24/03/26 18:18:59 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 21)
24/03/26 18:18:59 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 21)
24/03/26 18:19:01 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 21)
24/03/26 18:19:01 INFO TaskSetManager: finish serialize task 21...
24/03/26 18:19:01 INFO TaskSetManager: Starting task 21.0 in stage 2.0 (TID 21) (10.155.96.97, executor driver, partition 21, PROCESS_LOCAL, 46485583 bytes) 
24/03/26 18:19:01 INFO TaskSetManager: start serialize task 22...
24/03/26 18:19:01 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 22)
24/03/26 18:19:01 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 22)
24/03/26 18:19:03 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 22)
24/03/26 18:19:03 INFO TaskSetManager: finish serialize task 22...
24/03/26 18:19:03 INFO TaskSetManager: Starting task 22.0 in stage 2.0 (TID 22) (10.155.96.97, executor driver, partition 22, PROCESS_LOCAL, 46488872 bytes) 
24/03/26 18:19:03 INFO TaskSetManager: start serialize task 23...
24/03/26 18:19:03 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 23)
24/03/26 18:19:03 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 23)
24/03/26 18:19:04 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 23)
24/03/26 18:19:04 INFO TaskSetManager: finish serialize task 23...
24/03/26 18:19:04 INFO TaskSetManager: Starting task 23.0 in stage 2.0 (TID 23) (10.155.96.97, executor driver, partition 23, PROCESS_LOCAL, 46489351 bytes) 
24/03/26 18:19:04 INFO TaskSetManager: start serialize task 24...
24/03/26 18:19:04 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 24)
24/03/26 18:19:04 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 24)
24/03/26 18:19:06 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 24)
24/03/26 18:19:06 INFO TaskSetManager: finish serialize task 24...
24/03/26 18:19:06 INFO TaskSetManager: Starting task 24.0 in stage 2.0 (TID 24) (10.155.96.97, executor driver, partition 24, PROCESS_LOCAL, 46486199 bytes) 
24/03/26 18:19:06 INFO TaskSetManager: start serialize task 25...
24/03/26 18:19:06 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 25)
24/03/26 18:19:06 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 25)
24/03/26 18:19:08 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 25)
24/03/26 18:19:08 INFO TaskSetManager: finish serialize task 25...
24/03/26 18:19:08 INFO TaskSetManager: Starting task 25.0 in stage 2.0 (TID 25) (10.155.96.97, executor driver, partition 25, PROCESS_LOCAL, 46485572 bytes) 
24/03/26 18:19:08 INFO TaskSetManager: start serialize task 26...
24/03/26 18:19:08 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 26)
24/03/26 18:19:08 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 26)
24/03/26 18:19:09 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 26)
24/03/26 18:19:09 INFO TaskSetManager: finish serialize task 26...
24/03/26 18:19:09 INFO TaskSetManager: Starting task 26.0 in stage 2.0 (TID 26) (10.155.96.97, executor driver, partition 26, PROCESS_LOCAL, 46486711 bytes) 
24/03/26 18:19:09 INFO TaskSetManager: start serialize task 27...
24/03/26 18:19:09 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 27)
24/03/26 18:19:09 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 27)
24/03/26 18:19:11 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 27)
24/03/26 18:19:11 INFO TaskSetManager: finish serialize task 27...
24/03/26 18:19:11 INFO TaskSetManager: Starting task 27.0 in stage 2.0 (TID 27) (10.155.96.97, executor driver, partition 27, PROCESS_LOCAL, 46491886 bytes) 
24/03/26 18:19:11 INFO TaskSetManager: start serialize task 28...
24/03/26 18:19:11 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 28)
24/03/26 18:19:11 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 28)
24/03/26 18:19:13 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 28)
24/03/26 18:19:13 INFO TaskSetManager: finish serialize task 28...
24/03/26 18:19:13 INFO TaskSetManager: Starting task 28.0 in stage 2.0 (TID 28) (10.155.96.97, executor driver, partition 28, PROCESS_LOCAL, 46490368 bytes) 
24/03/26 18:19:13 INFO TaskSetManager: start serialize task 29...
24/03/26 18:19:13 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 29)
24/03/26 18:19:13 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 29)
24/03/26 18:19:14 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 29)
24/03/26 18:19:14 INFO TaskSetManager: finish serialize task 29...
24/03/26 18:19:14 INFO TaskSetManager: Starting task 29.0 in stage 2.0 (TID 29) (10.155.96.97, executor driver, partition 29, PROCESS_LOCAL, 46489395 bytes) 
24/03/26 18:19:14 INFO TaskSetManager: start serialize task 30...
24/03/26 18:19:14 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 30)
24/03/26 18:19:14 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 30)
24/03/26 18:19:16 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 30)
24/03/26 18:19:16 INFO TaskSetManager: finish serialize task 30...
24/03/26 18:19:16 INFO TaskSetManager: Starting task 30.0 in stage 2.0 (TID 30) (10.155.96.97, executor driver, partition 30, PROCESS_LOCAL, 46488916 bytes) 
24/03/26 18:19:16 INFO TaskSetManager: start serialize task 31...
24/03/26 18:19:16 INFO JavaSerializerInstance: before serialize stream ShuffleMapTask(2, 31)
24/03/26 18:19:16 INFO JavaSerializerInstance: after serialize stream ShuffleMapTask(2, 31)
24/03/26 18:19:17 INFO JavaSerializerInstance: after write object ShuffleMapTask(2, 31)
```

```","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M54mOmZ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/423,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M54mbKf,incubator-wayang,2023338655,423,NA,zkaoudi,10105712,Zoi Kaoudi,,NA,2024-03-27T17:11:00Z,2024-03-27T17:11:00Z,"Thanks for all the info @wangxiaoying. I can take a look at it next week.

In the meantime, can you confirm that the operations executed in postgres and in Spark with SparkSQL are the same when executed in Wayang? In Wayang you can actually force each operator where to be executed with the .withPlatform() method so that you make sure that the plans are the same. ","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M54mbKf/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/423,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M54o3m_,incubator-wayang,2023979455,423,NA,wangxiaoying,5569610,Xiaoying Wang,xiaoying_wang@sfu.ca,NA,2024-03-27T21:00:23Z,2024-03-27T21:00:23Z,"Thank you @zkaoudi for the quick response!

> In the meantime, can you confirm that the operations executed in postgres and in Spark with SparkSQL are the same when executed in Wayang?

Yes. I checked the log at postgres side. Here is the query fetching related log when using wayang:
```
2024-03-27 20:33:44.571 UTC [13283] LOG:  execute <unnamed>: SELECT l_orderkey, l_extendedprice, l_discount FROM LINEITEM WHERE l_shipDate > date('1995-03-15')
2024-03-27 20:34:10.255 UTC [13284] LOG:  execute <unnamed>: BEGIN
2024-03-27 20:34:10.256 UTC [13284] LOG:  execute <unnamed>: SET extra_float_digits = 3
2024-03-27 20:34:10.256 UTC [13284] LOG:  execute <unnamed>: SET application_name = 'PostgreSQL JDBC Driver'
2024-03-27 20:34:10.257 UTC [13284] LOG:  execute <unnamed>: COMMIT
2024-03-27 20:34:10.258 UTC [13284] LOG:  execute <unnamed>: SELECT c_custkey FROM CUSTOMER WHERE c_mktsegment LIKE 'BUILDING%'
2024-03-27 20:34:10.774 UTC [13285] LOG:  execute <unnamed>: BEGIN
2024-03-27 20:34:10.775 UTC [13285] LOG:  execute <unnamed>: SET extra_float_digits = 3
2024-03-27 20:34:10.775 UTC [13285] LOG:  execute <unnamed>: SET application_name = 'PostgreSQL JDBC Driver'
2024-03-27 20:34:10.776 UTC [13285] LOG:  execute <unnamed>: COMMIT
2024-03-27 20:34:10.810 UTC [13285] LOG:  execute <unnamed>: SELECT o_orderkey, o_custkey, o_orderdate, o_shippriority FROM ORDERS WHERE o_orderdate < date('1995-03-15')
```

And this is the log when using sparksql:
```
2024-03-27 20:37:25.668 UTC [13302] LOG:  execute <unnamed>: SELECT ""c_custkey"",""c_mktsegment"" FROM public.customer  WHERE (""c_custkey"" IS NOT NULL)
2024-03-27 20:37:25.701 UTC [13300] LOG:  execute <unnamed>: SELECT ""o_orderkey"",""o_custkey"",""o_orderdate"",""o_shippriority"" FROM public.orders  WHERE (""o_orderdate"" IS NOT NULL) AND (""o_orderdate"" < '1995-03-15') AND (""o_custkey"" IS NOT NULL) AND (""o_orderkey"" IS NOT NULL)
2024-03-27 20:37:25.701 UTC [13301] LOG:  execute <unnamed>: SELECT ""l_orderkey"",""l_extendedprice"",""l_discount"" FROM public.lineitem  WHERE (""l_shipdate"" IS NOT NULL) AND (""l_shipdate"" > '1995-03-15') AND (""l_orderkey"" IS NOT NULL)
```

In general, postgres does similar computation under the two setups. It seems like sparksql would generate additional filters with ""IS NOT NULL"", but it won't really filter our any data since the TPC-H dataset does not contain NULL value. In addition it didn't pushdown the `LIKE 'BUILDING%'` predicate as wayang does, which may cause more data to transfer for spark (although the table is not that big comparing to lineitem).

**P.S.**
Another thing I found when I check the log is that spark would issue the three sql queries in parallel, while wayang issue them one by one (shows in the timestamp of the log). I tried to enable parallelism in wayang by setting `wayang.core.optimizer.enumeration.parallel-tasks = true`, however it gives me an exception:
```
        Exception in thread ""Thread-0"" java.util.ConcurrentModificationException
	at java.base/java.util.HashMap.computeIfAbsent(HashMap.java:1134)
	at org.apache.wayang.core.platform.CrossPlatformExecutor.getOrCreateExecutorFor(CrossPlatformExecutor.java:391)
	at org.apache.wayang.core.platform.CrossPlatformExecutor$ParallelExecutionThread.run(CrossPlatformExecutor.java:1104)
	at java.base/java.lang.Thread.run(Thread.java:834)
```
I think it is due to the racing on the `executors` member inside the `CrossPlatformExecutor.java`.

This can be one of the reason for the performance difference, but I think the later execution difference inside spark platform is more significant in terms of the whole query.","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M54o3m_/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/423,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M55Oq-2,incubator-wayang,2033889206,423,NA,zkaoudi,10105712,Zoi Kaoudi,,NA,2024-04-03T08:23:20Z,2024-04-03T08:23:20Z,"Hi @wangxiaoying,

before digging into the details and just to make sure we are comparing same installations, I was wondering whether you are using the same Spark version for both runs.","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M55Oq-2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/423,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M55Qkps,incubator-wayang,2034387564,423,NA,zkaoudi,10105712,Zoi Kaoudi,,NA,2024-04-03T12:00:13Z,2024-04-03T12:00:13Z,"Hi again,

I would suggest two things to check:

1) The type of join that Spark SQL uses. Wayang's current join operator maps to the corresponding join in RDDs, which if I'm not mistaken is implemented as as hash join. Maybe Spark SQL uses a broadcast join and thus, the difference in the data transferred?

2) I'm not very familiar with the views in Spark, but when one registers the temporary views are they materialized in memory? If so, the timer you have would measure data accessed via memory. But again not sure how the temp views in Spark work. Maybe you could time the registerviews method to check this out.
","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M55Qkps/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/423,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M55ZctI,incubator-wayang,2036714312,423,NA,kbeedkar,8502905,Kaustubh Beedkar,,NA,2024-04-04T09:48:37Z,2024-04-04T09:48:37Z,The performance difference also stems from the current implementation of the Postgres To Spark channel conversion; https://github.com/apache/incubator-wayang/blob/e89191332dc9357526c8342cf4706652b3ebaa74/wayang-platforms/wayang-jdbc-template/src/main/java/org/apache/wayang/jdbc/operators/SqlToRddOperator.java#L46,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M55ZctI/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/423,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M55xsh7,incubator-wayang,2043070587,423,NA,wangxiaoying,5569610,Xiaoying Wang,xiaoying_wang@sfu.ca,NA,2024-04-08T15:33:12Z,2024-04-08T15:33:12Z,"> Hi @wangxiaoying,
> 
> before digging into the details and just to make sure we are comparing same installations, I was wondering whether you are using the same Spark version for both runs.

Sorry for the late reply, I was out for last week. Yes, I can confirm this.","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M55xsh7/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/423,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M55yWpX,incubator-wayang,2043243095,423,NA,wangxiaoying,5569610,Xiaoying Wang,xiaoying_wang@sfu.ca,NA,2024-04-08T16:59:14Z,2024-04-08T16:59:14Z,"> 1. The type of join that Spark SQL uses. Wayang's current join operator maps to the corresponding join in RDDs, which if I'm not mistaken is implemented as as hash join. Maybe Spark SQL uses a broadcast join and thus, the difference in the data transferred?

Yes, I think the executed join algorithms are different from the two approaches. Below is the default physical plan generated by spark:
```
+- == Final Plan ==
   *(8) Sort [revenue#138 DESC NULLS LAST, o_orderdate#58 ASC NULLS FIRST], true, 0
   +- AQEShuffleRead coalesced
      +- ShuffleQueryStage 5
         +- Exchange rangepartitioning(revenue#138 DESC NULLS LAST, o_orderdate#58 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [plan_id=448]
            +- *(7) HashAggregate(keys=[l_orderkey#0, o_orderdate#58, o_shippriority#61], functions=[sum((l_extendedprice#5 * (1 - l_discount#6)))])
               +- *(7) HashAggregate(keys=[l_orderkey#0, o_orderdate#58, o_shippriority#61], functions=[partial_sum((l_extendedprice#5 * (1 - l_discount#6)))])
                  +- *(7) Project [o_orderdate#58, o_shippriority#61, l_orderkey#0, l_extendedprice#5, l_discount#6]
                     +- *(7) SortMergeJoin [o_orderkey#54], [l_orderkey#0], Inner
                        :- *(5) Sort [o_orderkey#54 ASC NULLS FIRST], false, 0
                        :  +- AQEShuffleRead coalesced
                        :     +- ShuffleQueryStage 4
                        :        +- Exchange hashpartitioning(o_orderkey#54, 200), ENSURE_REQUIREMENTS, [plan_id=341]
                        :           +- *(4) Project [o_orderkey#54, o_orderdate#58, o_shippriority#61]
                        :              +- *(4) BroadcastHashJoin [c_custkey#36], [o_custkey#55], Inner, BuildLeft, false
                        :                 :- BroadcastQueryStage 3
                        :                 :  +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=225]
                        :                 :     +- AQEShuffleRead local
                        :                 :        +- ShuffleQueryStage 0
                        :                 :           +- Exchange hashpartitioning(c_custkey#36, 200), ENSURE_REQUIREMENTS, [plan_id=132]
                        :                 :              +- *(1) Project [c_custkey#36]
                        :                 :                 +- *(1) Filter (staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, c_mktsegment#42, 10, true, false, true) = BUILDING  )
                        :                 :                    +- *(1) Scan JDBCRelation(public.customer) [numPartitions=1] [c_custkey#36,c_mktsegment#42] PushedFilters: [*IsNotNull(c_custkey)], ReadSchema: struct<c_custkey:int,c_mktsegment:string>
                        :                 +- AQEShuffleRead local
                        :                    +- ShuffleQueryStage 1
                        :                       +- Exchange hashpartitioning(o_custkey#55, 200), ENSURE_REQUIREMENTS, [plan_id=139]
                        :                          +- *(2) Scan JDBCRelation(public.orders) [numPartitions=1] [o_orderkey#54,o_custkey#55,o_orderdate#58,o_shippriority#61] PushedFilters: [*IsNotNull(o_orderdate), *LessThan(o_orderdate,1995-03-15), *IsNotNull(o_custkey), *IsNotNull(o_..., ReadSchema: struct<o_orderkey:int,o_custkey:int,o_orderdate:date,o_shippriority:int>
                        +- *(6) Sort [l_orderkey#0 ASC NULLS FIRST], false, 0
                           +- AQEShuffleRead coalesced
                              +- ShuffleQueryStage 2
                                 +- Exchange hashpartitioning(l_orderkey#0, 200), ENSURE_REQUIREMENTS, [plan_id=150]
                                    +- *(3) Scan JDBCRelation(public.lineitem) [numPartitions=1] [l_orderkey#0,l_extendedprice#5,l_discount#6] PushedFilters: [*IsNotNull(l_shipdate), *GreaterThan(l_shipdate,1995-03-15), *IsNotNull(l_orderkey)], ReadSchema: struct<l_orderkey:int,l_extendedprice:decimal(15,2),l_discount:decimal(15,2)>
```

I tried to add config: `.config(""spark.sql.join.preferSortMergeJoin"", ""false"")` when building the spark session so the `SortMergeJoin` above will become a `HashJoin`, but the performance does not changes much. `BoradcastJoin` is still used though.

> 2. I'm not very familiar with the views in Spark, but when one registers the temporary views are they materialized in memory? If so, the timer you have would measure data accessed via memory. But again not sure how the temp views in Spark work. Maybe you could time the registerviews method to check this out.

Spark uses lazy evaluation so the view creation does not take much time (only some metadata will be fetched). And as I have shown above in the postgres log, spark does fetch the three tables (with projection and filter pushdown) during runtime like wayang does.

I still think one key difference is task serialization, where wayang creates much larger spark tasks (>40MB) that makes serialization overhead no longer negligible, but I'm not sure why such big tasks are created.
","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M55yWpX/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/423,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M55yZlg,incubator-wayang,2043255136,423,NA,zkaoudi,10105712,Zoi Kaoudi,,NA,2024-04-08T17:06:06Z,2024-04-08T17:06:06Z,"Thanks @wangxiaoying. I guess the broadcast join reduces the amount of data shuffled for this specific dataset/query. Could you disable the broadcast join in Spark to make sure if the difference comes from the join only? 
Sth like: spark.conf.set(""spark.sql.autoBroadcastJoinThreshold"", -1) That would at least make equal the amount of data shuffled to better understand the performance difference.

","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M55yZlg/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/423,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M55yoKG,incubator-wayang,2043314822,423,NA,wangxiaoying,5569610,Xiaoying Wang,xiaoying_wang@sfu.ca,NA,2024-04-08T17:42:31Z,2024-04-08T17:42:31Z,"> Thanks @wangxiaoying. I guess the broadcast join reduces the amount of data shuffled for this specific dataset/query. Could you disable the broadcast join in Spark to make sure if the difference comes from the join only? Sth like: spark.conf.set(""spark.sql.autoBroadcastJoinThreshold"", -1) That would at least make equal the amount of data shuffled to better understand the performance difference.

Hi @zkaoudi , I set the config of `autoBroadcastJoinThreashold` to 1048576 (10485760 by default) since setting this value too small will make both joins `SortMergeJoin` instead of `HashJoin` (as this [post](https://stackoverflow.com/questions/57987613/spark-sortmergejoin-is-not-changing-to-shufflehashjoin) shows).  Here is the result plan with two hash joins:

```
   *(6) Sort [revenue#138 DESC NULLS LAST, o_orderdate#58 ASC NULLS FIRST], true, 0
   +- AQEShuffleRead coalesced
      +- ShuffleQueryStage 4
         +- Exchange rangepartitioning(revenue#138 DESC NULLS LAST, o_orderdate#58 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [plan_id=350]
            +- *(5) HashAggregate(keys=[l_orderkey#0, o_orderdate#58, o_shippriority#61], functions=[sum((l_extendedprice#5 * (1 - l_discount#6)))])
               +- *(5) HashAggregate(keys=[l_orderkey#0, o_orderdate#58, o_shippriority#61], functions=[partial_sum((l_extendedprice#5 * (1 - l_discount#6)))])
                  +- *(5) Project [o_orderdate#58, o_shippriority#61, l_orderkey#0, l_extendedprice#5, l_discount#6]
                     +- *(5) ShuffledHashJoin [o_orderkey#54], [l_orderkey#0], Inner, BuildLeft
                        :- AQEShuffleRead coalesced
                        :  +- ShuffleQueryStage 3
                        :     +- Exchange hashpartitioning(o_orderkey#54, 200), ENSURE_REQUIREMENTS, [plan_id=266]
                        :        +- *(4) Project [o_orderkey#54, o_orderdate#58, o_shippriority#61]
                        :           +- *(4) ShuffledHashJoin [c_custkey#36], [o_custkey#55], Inner, BuildLeft
                        :              :- AQEShuffleRead coalesced
                        :              :  +- ShuffleQueryStage 0
                        :              :     +- Exchange hashpartitioning(c_custkey#36, 200), ENSURE_REQUIREMENTS, [plan_id=132]
                        :              :        +- *(1) Project [c_custkey#36]
                        :              :           +- *(1) Filter (staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, c_mktsegment#42, 10, true, false,
 true) = BUILDING  )
                        :              :              +- *(1) Scan JDBCRelation(public.customer) [numPartitions=1] [c_custkey#36,c_mktsegment#42] PushedFilters: [*IsNotNull(c_custkey)], ReadSchema: struct<c_c
ustkey:int,c_mktsegment:string>
                        :              +- AQEShuffleRead coalesced
                        :                 +- ShuffleQueryStage 1
                        :                    +- Exchange hashpartitioning(o_custkey#55, 200), ENSURE_REQUIREMENTS, [plan_id=139]
                        :                       +- *(2) Scan JDBCRelation(public.orders) [numPartitions=1] [o_orderkey#54,o_custkey#55,o_orderdate#58,o_shippriority#61] PushedFilters: [*IsNotNull(o_orderdate)
, *LessThan(o_orderdate,1995-03-15), *IsNotNull(o_custkey), *IsNotNull(o_..., ReadSchema: struct<o_orderkey:int,o_custkey:int,o_orderdate:date,o_shippriority:int>
                        +- AQEShuffleRead coalesced
                           +- ShuffleQueryStage 2
                              +- Exchange hashpartitioning(l_orderkey#0, 200), ENSURE_REQUIREMENTS, [plan_id=150]
                                 +- *(3) Scan JDBCRelation(public.lineitem) [numPartitions=1] [l_orderkey#0,l_extendedprice#5,l_discount#6] PushedFilters: [*IsNotNull(l_shipdate), *GreaterThan(l_shipdate,1995
-03-15), *IsNotNull(l_orderkey)], ReadSchema: struct<l_orderkey:int,l_extendedprice:decimal(15,2),l_discount:decimal(15,2)>
```

The performance does not change much (still ~40s).","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M55yoKG/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/423,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M56KvrH,incubator-wayang,2049637063,423,NA,zkaoudi,10105712,Zoi Kaoudi,,NA,2024-04-11T12:57:17Z,2024-04-11T12:57:17Z,"To go around the potential performance issue of the Postgres To Spark channel conversion you could add the Java platform and see what you get. 
So sth like:
./wayang-1.0.0-SNAPSHOT/bin/wayang-submit org.apache.wayang.apps.tpch.TpcH exp\(123\) spark,postgres,java file:///path/to/wayang.properties Q3","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M56KvrH/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/423,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M56UHGF,incubator-wayang,2052092293,423,NA,wangxiaoying,5569610,Xiaoying Wang,xiaoying_wang@sfu.ca,NA,2024-04-12T16:33:11Z,2024-04-12T16:33:11Z,"> To go around the potential performance issue of the Postgres To Spark channel conversion you could add the Java platform and see what you get. So sth like: ./wayang-1.0.0-SNAPSHOT/bin/wayang-submit org.apache.wayang.apps.tpch.TpcH exp(123) spark,postgres,java file:///path/to/wayang.properties Q3

Thanks @zkaoudi for the suggestion. Adding java improves the overall performance (since the final plan won't involve the usage of spark). It results in 44 seconds (similar but still a little bit inferior comparing to sparksql (40 seconds). ","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M56UHGF/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/430,https://api.github.com/repos/apache/incubator-wayang/issues/430,incubator-wayang,2263007607,430,Add all plugins,github-actions,,,,OPEN,2024-04-25T08:33:18Z,2024-08-06T13:27:54Z,"Add all plugins

3. Add plugins

https://github.com/apache/incubator-wayang/blob/b67b404ed7cc3349991844ab6b7b5c4af29c2574/wayang-api/wayang-api-scala-java/src/main/scala/org/apache/wayang/api/serialization/customserializers/MultiContextDeserializer.scala#L78

```scala

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */


package org.apache.wayang.api.serialization.customserializers

import com.fasterxml.jackson.core.{JsonParser, JsonProcessingException}
import com.fasterxml.jackson.core.`type`.TypeReference
import com.fasterxml.jackson.databind.{DeserializationContext, JsonDeserializer, JsonNode}
import com.fasterxml.jackson.databind.jsontype.TypeDeserializer
import org.apache.wayang.api.MultiContext
import org.apache.wayang.api.serialization.SerializationUtils.mapper
import org.apache.wayang.core.api.Configuration
import org.apache.wayang.java.Java
import org.apache.wayang.postgres.Postgres
import org.apache.wayang.spark.Spark
import org.apache.wayang.sqlite3.Sqlite3

import java.io.IOException

class MultiContextDeserializer extends JsonDeserializer[MultiContext] {

  override def deserializeWithType(p: JsonParser, ctxt: DeserializationContext, typeDeserializer: TypeDeserializer): AnyRef = {
    this.deserialize(p, ctxt)
  }

  @throws[IOException]
  @throws[JsonProcessingException]
  override def deserialize(jp: JsonParser, ctxt: DeserializationContext): MultiContext = {

    // Deserialize each field of MultiContext separately
    val node: JsonNode = jp.getCodec.readTree(jp)

    val configurationParser: JsonParser = node.get(""configuration"").traverse(jp.getCodec)
    val configuration: Configuration = mapper.readValue(configurationParser, classOf[Configuration])

    val sinkParser: JsonParser = node.get(""sink"").traverse(jp.getCodec)
    val sink: Option[MultiContext.UnarySink] = mapper.readValue(sinkParser, new TypeReference[Option[MultiContext.UnarySink]]() {})

    val pluginsParser: JsonParser = node.get(""plugins"").traverse(jp.getCodec)
    val plugins: List[String] = mapper.readValue(pluginsParser, new TypeReference[List[String]]() {})

    //
    // Create the whole deserialized multi context
    //
    // 1. Add configuration
    val multiContext = new MultiContext(configuration)

    // 2. Add sink
    sink match {
      case Some(MultiContext.TextFileSink(url)) =>
        println(s""It's a TextFileSink with url: $url"")
        multiContext.withTextFileSink(url)
      case Some(MultiContext.ObjectFileSink(url)) =>
        println(s""It's an ObjectFileSink with url: $url"")
        multiContext.withObjectFileSink(url)
      case None =>
        println(""No sink defined"")
      case _ =>
        println(""Unknown sink type"")
    }

    // TODO: Add all plugins
    // 3. Add plugins
    val javaPluginName = Java.basicPlugin.getClass.getName
    val sparkPluginName = Spark.basicPlugin.getClass.getName
    val postgresPluginName = Postgres.plugin().getClass.getName
    // val flinkPluginName = Flink.basicPlugin().getClass.getName
    val sqlite3PluginName = Sqlite3.plugin().getClass.getName

    plugins.foreach {
      case pluginName if pluginName == javaPluginName => multiContext.register(Java.basicPlugin())
      case pluginName if pluginName == sparkPluginName => multiContext.register(Spark.basicPlugin())
      case pluginName if pluginName == postgresPluginName => multiContext.register(Postgres.plugin())
      // case pluginName if pluginName == flinkPluginName => multiContext.register(Flink.basicPlugin())
      case pluginName if pluginName == sqlite3PluginName => multiContext.register(Sqlite3.plugin())
      case _ => println(""Unknown plugin detected"")
    }

    multiContext
  }
}


```

3faf7c0b35880576ada4079a1dfa5524f5522691","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/430/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/430,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6HQl1G,incubator-wayang,2269273414,430,NA,Aryant01,108977687,Aryant Kumar,,NA,2024-08-05T14:54:07Z,2024-08-05T14:54:07Z,"Is this issue is still in consideration? I would like to work on this. Can you please assign me to this issue?
","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6HQl1G/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/430,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6HYS_c,incubator-wayang,2271293404,430,NA,Aryant01,108977687,Aryant Kumar,,NA,2024-08-06T13:26:54Z,2024-08-06T13:26:54Z,"Hey @zkaoudi , I have added two more plugins: Hadoop and GraphChi. 
`// Add all plugins
    val javaPluginName = Java.basicPlugin().getClass.getName
    val sparkPluginName = Spark.basicPlugin().getClass.getName
    val postgresPluginName = Postgres.plugin().getClass.getName
    val sqlite3PluginName = Sqlite3.plugin().getClass.getName
    val flinkPluginName = Flink.basicPlugin().getClass.getName
    val hadoopPluginName = Hadoop.basicPlugin().getClass.getName
    val graphchiPluginName = GraphChi.basicPlugin().getClass.getName

    plugins.foreach {
      case pluginName if pluginName == javaPluginName => multiContext.register(Java.basicPlugin())
      case pluginName if pluginName == sparkPluginName => multiContext.register(Spark.basicPlugin())
      case pluginName if pluginName == postgresPluginName => multiContext.register(Postgres.plugin())
      case pluginName if pluginName == sqlite3PluginName => multiContext.register(Sqlite3.plugin())
      case pluginName if pluginName == flinkPluginName => multiContext.register(Flink.basicPlugin())
      case pluginName if pluginName == hadoopPluginName => multiContext.register(Hadoop.basicPlugin())
      case pluginName if pluginName == graphchiPluginName => multiContext.register(GraphChi.basicPlugin())
      case _ => println(""Unknown plugin detected"")
    }`

Am I missing something? If that's all i had to do, can you please tell how do I get an approval to make the pool request. I am new to open source contributions. Thankyou.","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6HYS_c/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/431,https://api.github.com/repos/apache/incubator-wayang/issues/431,incubator-wayang,2263007666,431,Check hard coded output index 0,github-actions,,,,OPEN,2024-04-25T08:33:20Z,2024-04-25T08:33:20Z,"Check hard coded output index 0

operator.asInstanceOf[OperatorBase].setCardinalityEstimator(0, cardinalityEstimator)  // Add to operator

then it means this node is the output of a loop operator

then it means we have already parsed that node and associated it to an operator

then it means we have already parsed that node and associated it to an operator

https://github.com/apache/incubator-wayang/blob/b67b404ed7cc3349991844ab6b7b5c4af29c2574/wayang-api/wayang-api-scala-java/src/main/scala/org/apache/wayang/api/serialization/customserializers/OperatorDeserializer.scala#L136

```scala

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */


package org.apache.wayang.api.serialization.customserializers

import com.fasterxml.jackson.core.JsonParser
import com.fasterxml.jackson.core.`type`.TypeReference
import com.fasterxml.jackson.databind.jsontype.TypeDeserializer
import com.fasterxml.jackson.databind.node.ArrayNode
import com.fasterxml.jackson.databind.{DeserializationContext, JsonDeserializer, JsonNode}
import org.apache.wayang.api.serialization.SerializationUtils.mapper
import org.apache.wayang.api.serialization.customserializers.OperatorDeserializer.{inputSlotOwnerIdMap, outputSlotOwnerIdMap}
import org.apache.wayang.basic.data.Record
import org.apache.wayang.basic.operators._
import org.apache.wayang.basic.types.RecordType
import org.apache.wayang.core.api.exception.WayangException
import org.apache.wayang.core.function.FunctionDescriptor.{SerializableIntUnaryOperator, SerializableLongUnaryOperator}
import org.apache.wayang.core.function._
import org.apache.wayang.core.optimizer.cardinality.CardinalityEstimator
import org.apache.wayang.core.plan.wayangplan.{LoopHeadOperator, Operator, OperatorBase}
import org.apache.wayang.core.platform.Platform
import org.apache.wayang.core.types.DataSetType
import org.apache.wayang.jdbc.operators.JdbcTableSource
import org.apache.wayang.postgres.operators.PostgresTableSource
import org.apache.wayang.sqlite3.operators.Sqlite3TableSource

import scala.collection.JavaConverters._
import scala.collection.mutable

class OperatorDeserializer extends JsonDeserializer[Operator] {

  // Define a type for the deserialization function
  private type DeserializerFunction = (JsonParser, JsonNode) => Operator

  // Map type names to deserialization functions
  private val deserializers: Map[String, DeserializerFunction] = Map(

    // Source
    ""TextFileSource"" -> deserializeTextFileSource,
    ""ObjectFileSource"" -> deserializeObjectFileSource,
    ""CollectionSource"" -> deserializeCollectionSource,
    ""Sqlite3TableSource"" -> deserializeSqlite3TableSource,
    ""PostgresTableSource"" -> deserializePostgresTableSource,

    // Unary
    ""MapOperator"" -> deserializeMapOperator,
    ""MapPartitionsOperator"" -> deserializeMapPartitionsOperator,
    ""FilterOperator"" -> deserializeFilterOperator,
    ""FlatMapOperator"" -> deserializeFlatMapOperator,
    ""SampleOperator"" -> deserializeSampleOperator,
    ""ReduceByOperator"" -> deserializeReduceByOperator,
    ""MaterializedGroupByOperator"" -> deserializeMaterializedGroupByOperator,
    ""GlobalReduceOperator"" -> deserializeGlobalReduceOperator,
    ""GlobalMaterializedGroupOperator"" -> deserializeGlobalMaterializedGroupOperator,
    ""GroupByOperator"" -> deserializeGroupByOperator,
    ""ReduceOperator"" -> deserializeReduceOperator,
    ""SortOperator"" -> deserializeSortOperator,
    ""ZipWithIdOperator"" -> deserializeZipWithIdOperator,
    ""DistinctOperator"" -> deserializeDistinctOperator,
    ""CountOperator"" -> deserializeCountOperator,

    // Binary
    ""CartesianOperator"" -> deserializeCartesianOperator,
    ""UnionAllOperator"" -> deserializeUnionAllOperator,
    ""IntersectOperator"" -> deserializeIntersectOperator,
    ""JoinOperator"" -> deserializeJoinOperator,
    ""CoGroupOperator"" -> deserializeCoGroupOperator,

    // Loop
    ""DoWhileOperator"" -> deserializeDoWhileOperator,
    ""RepeatOperator"" -> deserializeRepeatOperator,

    /*
        ""LocalCallbackSink"" -> deserializeLocalCallbackSink,
     */
  )


  override def deserialize(jp: JsonParser, ctxt: DeserializationContext): Operator = {
    val objectIdMap = OperatorDeserializer.operatorIdMap.get()
    val jsonNodeOperator: JsonNode = mapper.readTree(jp)

    // If operator does not have any fields (or equivalently the standard @type field)
    // and is just a number (a Jackson id of an output slot),
    // then it means we have already parsed that operator and already stored it,
    // so return the stored one
    if (jsonNodeOperator.get(""@type"") == null) {
      objectIdMap.get(jsonNodeOperator.asLong()) match {
        case Some(operator) => return operator
        case None => throw new WayangException(s""Can't deserialize operator with id ${jsonNodeOperator.asLong()}"")
      }
    }

    val typeName = jsonNodeOperator.get(""@type"").asText
    val id = jsonNodeOperator.get(""@id"").asLong
    // println(s""Processing operator $typeName"")

    deserializers.get(typeName) match {

      case Some(deserializeFunc) =>

        // Deserialize operator
        val operator = deserializeFunc(jp, jsonNodeOperator)

        // Add target platforms
        val targetPlatformsNode: JsonNode = jsonNodeOperator.get(""targetPlatforms"")
        targetPlatformsNode.asInstanceOf[ArrayNode].elements().asScala.foreach(   // Iterate over json array
          platformStringNode => {
            val platform = mapper.treeToValue(platformStringNode, classOf[Platform])  // Custom Platform deserializer gets called here
            operator.addTargetPlatform(platform)  // Add to operator
          }
        )

        // Add target platforms
        val cardinalityEstimatorsNode: JsonNode = jsonNodeOperator.get(""cardinalityEstimators"")
        cardinalityEstimatorsNode.asInstanceOf[ArrayNode].elements().asScala.foreach(   // Iterate over json array
          cardinalityEstimatorNode => {
            val cardinalityEstimator = mapper.treeToValue(cardinalityEstimatorNode, classOf[CardinalityEstimator])  // Custom Platform deserializer gets called here

            // TODO: Check hard coded output index 0
            operator.asInstanceOf[OperatorBase].setCardinalityEstimator(0, cardinalityEstimator)  // Add to operator
          }
        )

        // Store in map id -> operator
        objectIdMap.put(id, operator)
        // println(s""\tStoring $typeName with id ${id}"")

        // Connect to input operators and return
        connectToInputOperatorsAndReturn(jsonNodeOperator, operator)

      // If no deserialization function is matched, throw error
      case None =>
        throw new IllegalArgumentException(s""Unknown type: $typeName"")
    }
  }


  //
  // Custom deserialization functions for each type
  //
  private def deserializeTextFileSource(jp: JsonParser, rootNode: JsonNode): Operator = {
    val inputUrl = rootNode.get(""inputUrl"").asText
    new TextFileSource(inputUrl)
  }

  private def deserializeObjectFileSource(jp: JsonParser, rootNode: JsonNode): Operator = {
    val inputUrl = rootNode.get(""inputUrl"").asText
    val tClass = mapper.treeToValue(rootNode.get(""tClass""), classOf[Class[AnyRef]])
    new ObjectFileSource(inputUrl, tClass)
  }

  private def deserializeCollectionSource(jp: JsonParser, rootNode: JsonNode): Operator = {
    val collection = mapper.treeToValue(rootNode.get(""collection""), classOf[Iterable[AnyRef]])
    val t = mapper.treeToValue(rootNode.get(""type""), classOf[DataSetType[AnyRef]])
    new CollectionSource(collection.asJavaCollection, t)
  }

  private def deserializeSqlite3TableSource(jp: JsonParser, rootNode: JsonNode): Operator = {
    val tableName = mapper.treeToValue(rootNode.get(""tableName""), classOf[String])
    val t = mapper.treeToValue(rootNode.get(""type""), classOf[DataSetType[Record]])
    new Sqlite3TableSource(tableName, t.getDataUnitType.asInstanceOf[RecordType].getFieldNames: _*)
  }

  private def deserializePostgresTableSource(jp: JsonParser, rootNode: JsonNode): Operator = {
    val tableName = mapper.treeToValue(rootNode.get(""tableName""), classOf[String])
    val t = mapper.treeToValue(rootNode.get(""type""), classOf[DataSetType[Record]])
    new PostgresTableSource(tableName, t.getDataUnitType.asInstanceOf[RecordType].getFieldNames: _*)
  }

  private def deserializeMapOperator(jp: JsonParser, rootNode: JsonNode): Operator = {
    val functionDescriptor = mapper.treeToValue(rootNode.get(""functionDescriptor""), classOf[TransformationDescriptor[AnyRef, AnyRef]])
    new MapOperator(functionDescriptor)
  }

  private def deserializeMapPartitionsOperator(jp: JsonParser, rootNode: JsonNode): Operator = {
    val functionDescriptor = mapper.treeToValue(rootNode.get(""functionDescriptor""), classOf[MapPartitionsDescriptor[AnyRef, AnyRef]])
    new MapPartitionsOperator(functionDescriptor)
  }

  private def deserializeFilterOperator(jp: JsonParser, rootNode: JsonNode): Operator = {
    val predicateDescriptor = mapper.treeToValue(rootNode.get(""predicateDescriptor""), classOf[PredicateDescriptor[AnyRef]])
    new FilterOperator(predicateDescriptor)
  }

  private def deserializeFlatMapOperator(jp: JsonParser, rootNode: JsonNode): Operator = {
    val functionDescriptor = mapper.treeToValue(rootNode.get(""functionDescriptor""), classOf[FlatMapDescriptor[AnyRef, AnyRef]])
    new FlatMapOperator(functionDescriptor)
  }

  private def deserializeSampleOperator(jp: JsonParser, rootNode: JsonNode): Operator = {
    val sampleSizeFunction = mapper.treeToValue(rootNode.get(""sampleSizeFunction""), classOf[SerializableIntUnaryOperator])
    val typeValue = mapper.treeToValue(rootNode.get(""type""), classOf[DataSetType[AnyRef]])
    val sampleMethod = mapper.treeToValue(rootNode.get(""sampleMethod""), classOf[SampleOperator.Methods])
    val seedFunction = mapper.treeToValue(rootNode.get(""seedFunction""), classOf[SerializableLongUnaryOperator])
    new SampleOperator(sampleSizeFunction, typeValue, sampleMethod, seedFunction)
  }

  private def deserializeReduceByOperator(jp: JsonParser, rootNode: JsonNode): Operator = {
    val keyDescriptor = mapper.treeToValue(rootNode.get(""keyDescriptor""), classOf[TransformationDescriptor[AnyRef, AnyRef]])
    val reduceDescriptor = mapper.treeToValue(rootNode.get(""reduceDescriptor""), classOf[ReduceDescriptor[AnyRef]])
    new ReduceByOperator(keyDescriptor, reduceDescriptor)
  }

  private def deserializeMaterializedGroupByOperator(jp: JsonParser, rootNode: JsonNode): Operator = {
    val keyDescriptor = mapper.treeToValue(rootNode.get(""keyDescriptor""), classOf[TransformationDescriptor[AnyRef, AnyRef]])
    new MaterializedGroupByOperator(keyDescriptor)
  }

  private def deserializeGlobalReduceOperator(jp: JsonParser, rootNode: JsonNode): Operator = {
    val reduceDescriptor = mapper.treeToValue(rootNode.get(""reduceDescriptor""), classOf[ReduceDescriptor[AnyRef]])
    new GlobalReduceOperator(reduceDescriptor)
  }

  private def deserializeGlobalMaterializedGroupOperator(jp: JsonParser, rootNode: JsonNode): Operator = {
    val inputType = mapper.treeToValue(rootNode.get(""inputType""), classOf[DataSetType[AnyRef]])
    val outputType = mapper.treeToValue(rootNode.get(""outputType""), classOf[DataSetType[java.lang.Iterable[AnyRef]]])
    new GlobalMaterializedGroupOperator(inputType, outputType)
  }

  private def deserializeGroupByOperator(jp: JsonParser, rootNode: JsonNode): Operator = {
    val keyDescriptor = mapper.treeToValue(rootNode.get(""keyDescriptor""), classOf[TransformationDescriptor[AnyRef, AnyRef]])
    new GroupByOperator(keyDescriptor)
  }

  private def deserializeReduceOperator(jp: JsonParser, rootNode: JsonNode): Operator = {
    val reduceDescriptor = mapper.treeToValue(rootNode.get(""reduceDescriptor""), classOf[ReduceDescriptor[AnyRef]])
    val inputType = mapper.treeToValue(rootNode.get(""inputType""), classOf[DataSetType[AnyRef]])
    val outputType = mapper.treeToValue(rootNode.get(""outputType""), classOf[DataSetType[AnyRef]])
    new ReduceOperator(reduceDescriptor, inputType, outputType)
  }

  private def deserializeSortOperator(jp: JsonParser, rootNode: JsonNode): Operator = {
    val keyDescriptor = mapper.treeToValue(rootNode.get(""keyDescriptor""), classOf[TransformationDescriptor[AnyRef, AnyRef]])
    new SortOperator(keyDescriptor)
  }

  private def deserializeZipWithIdOperator(jp: JsonParser, rootNode: JsonNode): Operator = {
    val inputType = mapper.treeToValue(rootNode.get(""inputType""), classOf[DataSetType[AnyRef]])
    new ZipWithIdOperator(inputType)
  }

  private def deserializeDistinctOperator(jp: JsonParser, rootNode: JsonNode): Operator = {
    val inputType = mapper.treeToValue(rootNode.get(""inputType""), classOf[DataSetType[AnyRef]])
    new DistinctOperator(inputType)
  }

  private def deserializeCountOperator(jp: JsonParser, rootNode: JsonNode): Operator = {
    val inputType = mapper.treeToValue(rootNode.get(""inputType""), classOf[DataSetType[AnyRef]])
    new CountOperator(inputType)
  }

  private def deserializeCartesianOperator(jp: JsonParser, rootNode: JsonNode): Operator = {
    val inputType0 = mapper.treeToValue(rootNode.get(""inputType0""), classOf[DataSetType[AnyRef]])
    val inputType1 = mapper.treeToValue(rootNode.get(""inputType1""), classOf[DataSetType[AnyRef]])
    new CartesianOperator(inputType0, inputType1)
  }

  private def deserializeUnionAllOperator(jp: JsonParser, rootNode: JsonNode): Operator = {
    val inputType0 = mapper.treeToValue(rootNode.get(""inputType0""), classOf[DataSetType[AnyRef]])
    new UnionAllOperator(inputType0)
  }

  private def deserializeIntersectOperator(jp: JsonParser, rootNode: JsonNode): Operator = {
    val inputType0 = mapper.treeToValue(rootNode.get(""inputType0""), classOf[DataSetType[AnyRef]])
    new IntersectOperator(inputType0)
  }

  private def deserializeJoinOperator(jp: JsonParser, rootNode: JsonNode): Operator = {
    val keyDescriptor0 = mapper.treeToValue(rootNode.get(""keyDescriptor0""), classOf[TransformationDescriptor[AnyRef, AnyRef]])
    val keyDescriptor1 = mapper.treeToValue(rootNode.get(""keyDescriptor1""), classOf[TransformationDescriptor[AnyRef, AnyRef]])
    new JoinOperator(keyDescriptor0, keyDescriptor1)
  }

  private def deserializeCoGroupOperator(jp: JsonParser, rootNode: JsonNode): Operator = {
    val keyDescriptor0 = mapper.treeToValue(rootNode.get(""keyDescriptor0""), classOf[TransformationDescriptor[AnyRef, AnyRef]])
    val keyDescriptor1 = mapper.treeToValue(rootNode.get(""keyDescriptor1""), classOf[TransformationDescriptor[AnyRef, AnyRef]])
    new CoGroupOperator(keyDescriptor0, keyDescriptor1)
  }

  private def deserializeDoWhileOperator(jp: JsonParser, rootNode: JsonNode): Operator = {
    val inputType = mapper.treeToValue(rootNode.get(""inputType""), classOf[DataSetType[AnyRef]])
    val convergenceType = mapper.treeToValue(rootNode.get(""convergenceType""), classOf[DataSetType[AnyRef]])
    val criterionDescriptor = mapper.treeToValue(rootNode.get(""criterionDescriptor""), classOf[PredicateDescriptor[java.util.Collection[AnyRef]]])
    val numExpectedIterations = mapper.treeToValue(rootNode.get(""numExpectedIterations""), classOf[Integer])
    new DoWhileOperator(inputType, convergenceType, criterionDescriptor, numExpectedIterations)
  }

  private def deserializeRepeatOperator(jp: JsonParser, rootNode: JsonNode): Operator = {
    val numIterations = mapper.treeToValue(rootNode.get(""numIterations""), classOf[Integer])
    val typeValue = mapper.treeToValue(rootNode.get(""type""), classOf[DataSetType[AnyRef]])
    new RepeatOperator(numIterations, typeValue)
  }


  private def connectToInputOperatorsAndReturn(node: JsonNode, operator: Operator): Operator = {
    val inputOperators = getInputOperators(node)
    for ((inputOperator, index) <- inputOperators.zipWithIndex) {
      val thisOutputIndex = if (isLoopOutput(node)) 1 else 0
      inputOperator.connectTo(thisOutputIndex, operator, index)
    }
    operator
  }

  // If the inputSlot->occupant->outputSlot has the ""finOut"" name,
  // then it means this node is the output of a loop operator
  private def isLoopOutput(node: JsonNode): Boolean = {
    val inputSlots = node.get(""inputSlots"")
    if (inputSlots != null && inputSlots.isArray && inputSlots.size() == 1) {
      // For each input slot
      inputSlots.elements().forEachRemaining { inputSlot =>
        // Access occupant
        if (inputSlot.get(""occupant"") != null) {
          val outputSlot = inputSlot.get(""occupant"")
          // Access owner
          if (outputSlot.get(""name"") != null) {
            val name = outputSlot.get(""name"").asText()
            return name == ""finOut""
          }
        }
      }
    }
    return false
  }

  private def getInputOperators(node: JsonNode): List[Operator] = {

    var inputOperators: List[Operator] = List()

    // Navigate to inputSlots
    val inputSlots = node.get(""inputSlots"")
    if (inputSlots != null && inputSlots.isArray) {

      // For each input slot
      inputSlots.elements().forEachRemaining { inputSlot =>

        // Access occupant
        if (inputSlot.get(""@id"") != null) {

          val inputSlotId = inputSlot.get(""@id"").asLong()
          // println(s""Processing input slot with id ${inputSlotId}"")

          val outputSlot = inputSlot.get(""occupant"")

          // Access owner
          if (outputSlot.get(""@id"") != null) {

            val outputSlotId = outputSlot.get(""@id"").asLong
            // println(s""Processing output slot with id ${outputSlotId}"")

            val owner = outputSlot.get(""owner"")

            // Deserialize the nested owner operator and add it into list to be returned
            val jsonParser = owner.traverse(mapper)
            jsonParser.nextToken()
            val inputOperator = mapper.readValue[Operator](jsonParser, classOf[Operator])
            inputOperators = inputOperators :+ inputOperator

            // println(s""\tStoring input slot with id ${inputSlotId}"")
            inputSlotOwnerIdMap.get().put(inputSlotId, inputOperator)
            // println(s""\tStoring output slot with id ${outputSlotId}"")
            outputSlotOwnerIdMap.get().put(outputSlotId, inputOperator)
          }

          // If owner does not have any fields and is just a number (a Jackson id of an output slot),
          // then it means we have already parsed that node and associated it to an operator
          else {
            val inputOperator = outputSlotOwnerIdMap.get().get(outputSlot.asLong)
            inputOperator match {
              case Some(operator) => inputOperators = inputOperators :+ operator
              case None => throw new WayangException(s""Can't find output slot ${outputSlot.asLong}"")
            }
          }
        }

        // If occupant does not have any fields and is just a number a Jackson id of an input slot),
        // then it means we have already parsed that node and associated it to an operator
        else {
          val inputOperator = inputSlotOwnerIdMap.get().get(inputSlot.asLong)
          inputOperator match {
            case Some(operator) => inputOperators = inputOperators :+ operator
            case None => throw new WayangException(s""Can't find input slot ${inputSlot.asLong}"")
          }
        }
      }
    }

    inputOperators
  }


  override def deserializeWithType(p: JsonParser, ctxt: DeserializationContext, typeDeserializer: TypeDeserializer): Operator = {
    deserialize(p, ctxt)
  }


  override def deserializeWithType(p: JsonParser, ctxt: DeserializationContext, typeDeserializer: TypeDeserializer, intoValue: Operator): Operator = {
    deserialize(p, ctxt)
  }
}


object OperatorDeserializer {

  // operator serialization id -> operator
  private val operatorIdMap: ThreadLocal[mutable.Map[Long, Operator]] = ThreadLocal.withInitial(() => mutable.Map[Long, Operator]())

  // input slot serialization id  -> input slot owner
  private val inputSlotOwnerIdMap: ThreadLocal[mutable.Map[Long, Operator]] = ThreadLocal.withInitial(() => mutable.Map[Long, Operator]())

  // output slot serialization id  -> input slot owner
  private val outputSlotOwnerIdMap: ThreadLocal[mutable.Map[Long, Operator]] = ThreadLocal.withInitial(() => mutable.Map[Long, Operator]())

}

```

5d64dab1d2619ee95d457233857019ee46f8dd95","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/431/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/432,https://api.github.com/repos/apache/incubator-wayang/issues/432,incubator-wayang,2263007732,432,Add all platforms,github-actions,,,,OPEN,2024-04-25T08:33:22Z,2024-04-25T08:33:22Z,"Add all platforms

https://github.com/apache/incubator-wayang/blob/b67b404ed7cc3349991844ab6b7b5c4af29c2574/wayang-api/wayang-api-scala-java/src/main/scala/org/apache/wayang/api/serialization/customserializers/PlatformDeserializer.scala#L35

```scala

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */


package org.apache.wayang.api.serialization.customserializers

import com.fasterxml.jackson.core.JsonParser
import com.fasterxml.jackson.databind.{DeserializationContext, JsonDeserializer}
import org.apache.wayang.core.api.exception.WayangException
import org.apache.wayang.core.platform.Platform
import org.apache.wayang.java.Java
import org.apache.wayang.postgres.Postgres
import org.apache.wayang.spark.Spark

class PlatformDeserializer extends JsonDeserializer[Platform]{

  override def deserialize(p: JsonParser, ctxt: DeserializationContext): Platform = {
    val className = p.getValueAsString

    // TODO: Add all platforms
    if (className == Java.platform().getClass.getName) {
      Java.platform()
    } else if (className == Spark.platform().getClass.getName) {
      Spark.platform()
    } else if (className == Postgres.platform().getClass.getName) {
      Postgres.platform()
    } else {
      throw new WayangException(s""Can't deserialize platform: $className"")
    }
  }

}

```

a448f974b31f1c68fefebf35a05ad51f4b9eab1a","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/432/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/433,https://api.github.com/repos/apache/incubator-wayang/issues/433,incubator-wayang,2263007781,433,Is this okay?,github-actions,,,,OPEN,2024-04-25T08:33:23Z,2024-04-25T08:33:24Z,"Is this okay?

https://github.com/apache/incubator-wayang/blob/b67b404ed7cc3349991844ab6b7b5c4af29c2574/wayang-api/wayang-api-scala-java/src/main/scala/org/apache/wayang/api/serialization/mixins/ConfigurationAndContextMixIns.scala#L49

```scala

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.serialization.mixins

import com.fasterxml.jackson.annotation.{JsonIdentityInfo, JsonIgnore, JsonSubTypes, JsonTypeInfo, ObjectIdGenerators}
import org.apache.logging.log4j.Logger
import org.apache.wayang.api.{MultiContext, DataQuanta, PlanBuilder}
import org.apache.wayang.core.api.configuration.{CollectionProvider, ExplicitCollectionProvider, KeyValueProvider, MapBasedKeyValueProvider, ValueProvider}
import org.apache.wayang.core.function.FunctionDescriptor
import org.apache.wayang.core.mapping.Mapping
import org.apache.wayang.core.optimizer.ProbabilisticDoubleInterval
import org.apache.wayang.core.optimizer.cardinality.CardinalityEstimator
import org.apache.wayang.core.optimizer.channels.ChannelConversion
import org.apache.wayang.core.optimizer.costs.{LoadProfileEstimator, LoadProfileToTimeConverter, TimeToCostConverter}
import org.apache.wayang.core.optimizer.enumeration.PlanEnumerationPruningStrategy
import org.apache.wayang.core.plan.wayangplan.{ExecutionOperator, OutputSlot}
import org.apache.wayang.core.platform.Platform
import org.apache.wayang.core.profiling.{CardinalityRepository, InstrumentationStrategy}

import java.util.function.ToDoubleFunction

object ConfigurationAndContextMixIns {


  @JsonTypeInfo(use = JsonTypeInfo.Id.NAME, include = JsonTypeInfo.As.PROPERTY, property = ""@type"")
  @JsonSubTypes(Array(
    new JsonSubTypes.Type(value = classOf[MultiContext], name = ""MultiContext""),
  ))
  abstract class WayangContextMixIn {
    @JsonIgnore
    private var logger: Logger = _

    // TODO: Is this okay?
    @JsonIgnore
    private var cardinalityRepository: CardinalityRepository = _
  }




  @JsonIdentityInfo(generator = classOf[ObjectIdGenerators.IntSequenceGenerator], property = ""@id"")
  abstract class ConfigurationMixIn {
    @JsonIgnore
    private var cardinalityEstimatorProvider: KeyValueProvider[OutputSlot[_], CardinalityEstimator] = _

    @JsonIgnore
    private var udfSelectivityProvider: KeyValueProvider[FunctionDescriptor, ProbabilisticDoubleInterval] = _

    @JsonIgnore
    private var operatorLoadProfileEstimatorProvider: KeyValueProvider[ExecutionOperator, LoadProfileEstimator] = _

    @JsonIgnore
    private var functionLoadProfileEstimatorProvider: KeyValueProvider[FunctionDescriptor, LoadProfileEstimator] = _

    @JsonIgnore
    private var loadProfileEstimatorCache: MapBasedKeyValueProvider[String, LoadProfileEstimator] = _

    @JsonIgnore
    private var loadProfileToTimeConverterProvider: KeyValueProvider[Platform, LoadProfileToTimeConverter] = _

    @JsonIgnore
    private var timeToCostConverterProvider: KeyValueProvider[Platform, TimeToCostConverter] = _

    @JsonIgnore
    private var costSquasherProvider: ValueProvider[ToDoubleFunction[ProbabilisticDoubleInterval]] = _

    @JsonIgnore
    private var platformStartUpTimeProvider: KeyValueProvider[Platform, Long] = _

    @JsonIgnore
    private var platformProvider: ExplicitCollectionProvider[Platform] = _

    @JsonIgnore
    private var mappingProvider: ExplicitCollectionProvider[Mapping] = _

    @JsonIgnore
    private var channelConversionProvider: ExplicitCollectionProvider[ChannelConversion] = _

    @JsonIgnore
    private var pruningStrategyClassProvider: CollectionProvider[Class[PlanEnumerationPruningStrategy]] = _

    @JsonIgnore
    private var instrumentationStrategyProvider: ValueProvider[InstrumentationStrategy] = _
  }

  @JsonTypeInfo(use = JsonTypeInfo.Id.NAME, include = JsonTypeInfo.As.PROPERTY, property = ""@type"")
  @JsonSubTypes(Array(
    new JsonSubTypes.Type(value = classOf[MultiContext.TextFileSink], name = ""MultiContextTextFileSink""),
    new JsonSubTypes.Type(value = classOf[MultiContext.ObjectFileSink], name = ""MultiContextObjectFileSink""
    ))
  )
  abstract class MultiContextUnarySinkMixIn {
  }

  abstract class MultiContextPlanBuilderMixIn {
    @JsonIgnore
    private var multiContextMap: Map[Long, MultiContext] = _

    @JsonIgnore
    private var dataQuantaMap: Map[Long, DataQuanta[_]] = _

    @JsonIgnore
    private var planBuilderMap: Map[Long, PlanBuilder] = _
  }

}

```

2c95d92ffed3267f43f23d0a9bfb1ca404e85775","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/433/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/434,https://api.github.com/repos/apache/incubator-wayang/issues/434,incubator-wayang,2263007837,434,Add more estimator mixins,github-actions,,,,OPEN,2024-04-25T08:33:25Z,2024-04-25T08:33:26Z,"Add more estimator mixins

https://github.com/apache/incubator-wayang/blob/b67b404ed7cc3349991844ab6b7b5c4af29c2574/wayang-api/wayang-api-scala-java/src/main/scala/org/apache/wayang/api/serialization/mixins/EstimatorMixIns.scala#L115

```scala

/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * ""License""); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.wayang.api.serialization.mixins

import com.fasterxml.jackson.annotation.{JsonCreator, JsonProperty, JsonSubTypes, JsonTypeInfo, JsonTypeName}
import org.apache.wayang.core.api.Configuration
import org.apache.wayang.core.function.FunctionDescriptor
import org.apache.wayang.core.function.FunctionDescriptor.SerializableToDoubleBiFunction
import org.apache.wayang.core.optimizer.cardinality.{AggregatingCardinalityEstimator, CardinalityEstimate, DefaultCardinalityEstimator, FallbackCardinalityEstimator, FixedSizeCardinalityEstimator, SwitchForwardCardinalityEstimator}
import org.apache.wayang.core.optimizer.costs.{ConstantLoadProfileEstimator, DefaultEstimatableCost, DefaultLoadEstimator, IntervalLoadEstimator, LoadEstimator, NestableLoadProfileEstimator}

object EstimatorMixIns {


  @JsonTypeInfo(use = JsonTypeInfo.Id.NAME, include = JsonTypeInfo.As.PROPERTY, property = ""@type"")
  @JsonSubTypes(Array(
    new JsonSubTypes.Type(value = classOf[DefaultLoadEstimator], name = ""DefaultLoadEstimator""),
    new JsonSubTypes.Type(value = classOf[IntervalLoadEstimator], name = ""IntervalLoadEstimator""),
  ))
  abstract class LoadEstimatorMixIn {
  }

  abstract class DefaultLoadEstimatorMixIn {
    @JsonCreator
    def this(@JsonProperty(""numInputs"") numInputs: Int,
             @JsonProperty(""numOutputs"") numOutputs: Int,
             @JsonProperty(""correctnessProbability"") correctnessProbability: Double,
             @JsonProperty(""nullCardinalityReplacement"") nullCardinalityReplacement: CardinalityEstimate,
             @JsonProperty(""singlePointFunction"") singlePointFunction: LoadEstimator.SinglePointEstimationFunction) = {
      this()
    }
  }

  abstract class CardinalityEstimateMixIn {
    @JsonCreator
    def this(@JsonProperty(""lowerEstimate"") lowerEstimate: Long,
             @JsonProperty(""upperEstimate"") upperEstimate: Long,
             @JsonProperty(""correctnessProb"") correctnessProb: Double,
             @JsonProperty(""isOverride"") isOverride: Boolean) = {
      this()
    }
  }


  abstract class ProbabilisticDoubleIntervalMixIn {
    @JsonCreator
    def this(@JsonProperty(""lowerEstimate"") lowerEstimate: Double,
             @JsonProperty(""upperEstimate"") upperEstimate: Double,
             @JsonProperty(""correctnessProb"") correctnessProb: Double,
             @JsonProperty(""isOverride"") isOverride: Boolean) = {
      this()
    }
  }

  @JsonTypeInfo(use = JsonTypeInfo.Id.NAME, include = JsonTypeInfo.As.PROPERTY, property = ""@type"")
  @JsonSubTypes(Array(
    new JsonSubTypes.Type(value = classOf[ConstantLoadProfileEstimator], name = ""ConstantLoadProfileEstimator""),
    new JsonSubTypes.Type(value = classOf[NestableLoadProfileEstimator], name = ""NestableLoadProfileEstimator""),
  ))
  abstract class LoadProfileEstimatorMixIn {
  }

  @JsonTypeName(""nestableLoadProfileEstimator"")
  abstract class NestableLoadProfileEstimatorMixIn {
    @JsonCreator
    def this (@JsonProperty(""cpuLoadEstimator"") cpuLoadEstimator : LoadEstimator,
              @JsonProperty(""ramLoadEstimator"") ramLoadEstimator: LoadEstimator,
              @JsonProperty(""diskLoadEstimator"") diskLoadEstimator: LoadEstimator,
              @JsonProperty(""networkLoadEstimator"") networkLoadEstimator: LoadEstimator,
              @JsonProperty(""resourceUtilizationEstimator"") resourceUtilizationEstimator: SerializableToDoubleBiFunction[Array[Long], Array[Long]],
              @JsonProperty(""overheadMillis"") overheadMillis: Long,
              @JsonProperty(""configurationKey"") configurationKey: String
             ) = {
      this()
    }
  }

  @JsonTypeInfo(use = JsonTypeInfo.Id.NAME, include = JsonTypeInfo.As.PROPERTY, property = ""@type"")
  @JsonSubTypes(Array(
    new JsonSubTypes.Type(value = classOf[AggregatingCardinalityEstimator], name = ""AggregatingCardinalityEstimator""),
    new JsonSubTypes.Type(value = classOf[DefaultCardinalityEstimator], name = ""DefaultCardinalityEstimator""),
    new JsonSubTypes.Type(value = classOf[FallbackCardinalityEstimator], name = ""FallbackCardinalityEstimator""),
    new JsonSubTypes.Type(value = classOf[FixedSizeCardinalityEstimator], name = ""FixedSizeCardinalityEstimator""),
    new JsonSubTypes.Type(value = classOf[SwitchForwardCardinalityEstimator], name = ""SwitchForwardCardinalityEstimator""),
  ))
  abstract class CardinalityEstimatorMixIn {
  }

  abstract class DefaultCardinalityEstimatorMixIn {
    @JsonCreator
    def this(@JsonProperty(""certaintyProb"") certaintyProb: Double,
             @JsonProperty(""numInputs"") numInputs: Int,
             @JsonProperty(""isAllowMoreInputs"") isAllowMoreInputs: Boolean,
             @JsonProperty(""singlePointEstimator"") singlePointEstimator: FunctionDescriptor.SerializableToLongBiFunction[Array[Long], Configuration]) = {
      this()
    }
  }

  // TODO: Add more estimator mixins

  @JsonTypeInfo(use = JsonTypeInfo.Id.NAME, include = JsonTypeInfo.As.PROPERTY, property = ""@type"")
  @JsonSubTypes(Array(
    new JsonSubTypes.Type(value = classOf[DefaultEstimatableCost], name = ""DefaultEstimatableCost""),
  ))
  abstract class EstimatableCostMixIn {
  }

}

```

1437c126d1770530f7402862f101b2128fd92629","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/434/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/438,https://api.github.com/repos/apache/incubator-wayang/issues/438,incubator-wayang,2286989917,438,"key should be given by ""udf""",github-actions,,,,OPEN,2024-05-09T06:27:29Z,2024-05-09T06:27:29Z,"key should be given by ""udf""

UDF specifies reducer function

https://github.com/apache/incubator-wayang/blob/c25c6561bf786d76d0dc717b28cf15885c269232/python/old_code/pywayang/src/pywy/orchestrator/dataquanta.py#L104

```python

#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the ""License""); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

from pywy.graph.graph import Graph
from pywy.graph.traversal import Traversal
from pywy.protobuf.planwriter import MessageWriter
from pywy.orchestrator.operator import Operator
import pywy.orchestrator.operator
import itertools
import collections
import logging
from functools import reduce


# Wraps a Source operation to create an iterable
class DataQuantaBuilder:
    def __init__(self, descriptor):
        self.descriptor = descriptor

    def source(self, source):

        if type(source) is str:
            source_ori = open(source, ""r"")
        else:
            source_ori = source
        return DataQuanta(
            Operator(
                operator_type=""source"",
                udf=source,
                iterator=iter(source_ori),
                previous=[],
                python_exec=False
            ),
            descriptor=self.descriptor
        )


# Wraps an operation over an iterable
class DataQuanta:
    def __init__(self, operator=None, descriptor=None):
        self.operator = operator
        self.descriptor = descriptor
        if self.operator.is_source():
            self.descriptor.add_source(self.operator)
        if self.operator.is_sink():
            self.descriptor.add_sink(self.operator)

    # Operational Functions
    def filter(self, udf):
        def func(iterator):
            return filter(udf, iterator)

        return DataQuanta(
            Operator(
                operator_type=""filter"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def flatmap(self, udf):

        def auxfunc(iterator):
            return itertools.chain.from_iterable(map(udf, iterator))

        def func(iterator):
            mapped = map(udf, iterator)
            flattened = flatten_single_dim(mapped)
            yield from flattened

        def flatten_single_dim(mapped):
            for item in mapped:
                for subitem in item:
                    yield subitem

        return DataQuanta(
            Operator(
                operator_type=""flatmap"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def group_by(self, udf):
        def func(iterator):
            # TODO key should be given by ""udf""
            return itertools.groupby(iterator, key=operator.itemgetter(0))
            #return itertools.groupby(sorted(iterator), key=itertools.itemgetter(0))

        return DataQuanta(
            Operator(
                operator_type=""group_by"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def map(self, udf):
        def func(iterator):
            return map(udf, iterator)

        return DataQuanta(
            Operator(
                operator_type=""map"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    # Key specifies pivot dimensions
    # UDF specifies reducer function
    def reduce_by_key(self, keys, udf):

        op = Operator(
            operator_type=""reduce_by_key"",
            udf=udf,
            previous=[self.operator],
            python_exec=False
        )

        print(len(keys), keys)
        for i in range(0, len(keys)):
            """"""if keys[i] is int:
                op.set_parameter(""vector_position|""+str(i), keys[i])
            else:
                op.set_parameter(""dimension_key|""+str(i), keys[i])""""""

            # TODO maybe would be better just leave the number as key
            op.set_parameter(""dimension|""+str(i+1), keys[i])

        return DataQuanta(
            op,
            descriptor=self.descriptor
        )

    def reduce(self, udf):
        def func(iterator):
            return reduce(udf, iterator)

        return DataQuanta(
            Operator(
                operator_type=""reduce"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def sink(self, path, end=""\n""):
        def consume(iterator):
            with open(path, 'w') as f:
                for x in iterator:
                    f.write(str(x) + end)

        def func(iterator):
            consume(iterator)
            # return self.__run(consume)

        return DataQuanta(
            Operator(
                operator_type=""sink"",

                udf=path,
                # To execute directly uncomment
                # udf=func,

                previous=[self.operator],
                python_exec=False
            ),
            descriptor=self.descriptor
        )

    def sort(self, udf):

        def func(iterator):
            return sorted(iterator, key=udf)

        return DataQuanta(
            Operator(
                operator_type=""sort"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    # This function allow the union to be performed by Python
    # Nevertheless, current configuration runs it over Java
    def union(self, other):

        def func(iterator):
            return itertools.chain(iterator, other.operator.getIterator())

        return DataQuanta(
            Operator(
                operator_type=""union"",
                udf=func,
                previous=[self.operator, other.operator],
                python_exec=False
            ),
            descriptor=self.descriptor
        )

    def __run(self, consumer):
        consumer(self.operator.getIterator())

    # Execution Functions
    def console(self, end=""\n""):
        def consume(iterator):
            for x in iterator:
                print(x, end=end)

        self.__run(consume)

    # Only for debugging purposes!
    # To execute the plan directly in the program driver
    def execute(self):
        logging.warn(""DEBUG Execution"")
        logging.info(""Reminder to swap SINK UDF value from path to func"")
        logging.debug(self.operator.previous[0].operator_type)
        if self.operator.is_sink():
            logging.debug(self.operator.operator_type)
            logging.debug(self.operator.udf)
            logging.debug(len(self.operator.previous))
            self.operator.udf(self.operator.previous[0].getIterator())
        else:
            logging.error(""Plan must call execute from SINK type of operator"")
            raise RuntimeError

    # Converts Python Functional Plan to valid Wayang Plan
    def to_wayang_plan(self):

        sinks = self.descriptor.get_sinks()
        if len(sinks) == 0:
            return

        graph = Graph()
        graph.populate(self.descriptor.get_sinks())

        # Uncomment to check the Graph built
        # graph.print_adjlist()

        # Function to be consumed by Traverse
        # Separates Python Plan into a List of Pipelines
        def define_pipelines(node1, current_pipeline, collection):
            def store_unique(pipe_to_insert):
                for pipe in collection:
                    if equivalent_lists(pipe, pipe_to_insert):
                        return
                collection.append(pipe_to_insert)

            def equivalent_lists(l1, l2):
                if collections.Counter(l1) == collections.Counter(l2):
                    return True
                else:
                    return False

            if not current_pipeline:
                current_pipeline = [node1]

            elif node1.operator.is_boundary():
                store_unique(current_pipeline.copy())
                current_pipeline.clear()
                current_pipeline.append(node1)

            else:
                current_pipeline.append(node1)

            if node1.operator.sink:
                store_unique(current_pipeline.copy())
                current_pipeline.clear()

            return current_pipeline

        # Works over the graph
        trans = Traversal(
            graph=graph,
            origin=self.descriptor.get_sources(),
            # udf=lambda x, y, z: d(x, y, z)
            # UDF always will receive:
            # x: a Node object,
            # y: an object representing the result of the last iteration,
            # z: a collection to store final results inside your UDF
            udf=lambda x, y, z: define_pipelines(x, y, z)
        )

        # Gets the results of the traverse process
        collected_stages = trans.get_collected_data()

        # Passing the Stages to a Wayang message writer
        writer = MessageWriter()
        a = 0
        # Stage is composed of class Node objects
        for stage in collected_stages:
            a += 1
            logging.info(""///"")
            logging.info(""stage"" + str(a))
            writer.process_pipeline(stage)

        writer.set_dependencies()

        # Uses a file to provide the plan
        # writer.write_message(self.descriptor)

        # Send the plan to Wayang REST api directly
        writer.send_message(self.descriptor)

```

c1f2ed0fa73244efb915223a8c6334a93055dc1c","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/438/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/439,https://api.github.com/repos/apache/incubator-wayang/issues/439,incubator-wayang,2286989959,439,maybe would be better just leave the number as key,github-actions,,,,OPEN,2024-05-09T06:27:31Z,2024-05-09T06:27:31Z,"maybe would be better just leave the number as key

udf=func,

Nevertheless, current configuration runs it over Java

To execute the plan directly in the program driver

graph.print_adjlist()

Separates Python Plan into a List of Pipelines

UDF always will receive:

x: a Node object,

y: an object representing the result of the last iteration,

z: a collection to store final results inside your UDF

writer.write_message(self.descriptor)

https://github.com/apache/incubator-wayang/blob/c25c6561bf786d76d0dc717b28cf15885c269232/python/old_code/pywayang/src/pywy/orchestrator/dataquanta.py#L150

```python

#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the ""License""); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

from pywy.graph.graph import Graph
from pywy.graph.traversal import Traversal
from pywy.protobuf.planwriter import MessageWriter
from pywy.orchestrator.operator import Operator
import pywy.orchestrator.operator
import itertools
import collections
import logging
from functools import reduce


# Wraps a Source operation to create an iterable
class DataQuantaBuilder:
    def __init__(self, descriptor):
        self.descriptor = descriptor

    def source(self, source):

        if type(source) is str:
            source_ori = open(source, ""r"")
        else:
            source_ori = source
        return DataQuanta(
            Operator(
                operator_type=""source"",
                udf=source,
                iterator=iter(source_ori),
                previous=[],
                python_exec=False
            ),
            descriptor=self.descriptor
        )


# Wraps an operation over an iterable
class DataQuanta:
    def __init__(self, operator=None, descriptor=None):
        self.operator = operator
        self.descriptor = descriptor
        if self.operator.is_source():
            self.descriptor.add_source(self.operator)
        if self.operator.is_sink():
            self.descriptor.add_sink(self.operator)

    # Operational Functions
    def filter(self, udf):
        def func(iterator):
            return filter(udf, iterator)

        return DataQuanta(
            Operator(
                operator_type=""filter"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def flatmap(self, udf):

        def auxfunc(iterator):
            return itertools.chain.from_iterable(map(udf, iterator))

        def func(iterator):
            mapped = map(udf, iterator)
            flattened = flatten_single_dim(mapped)
            yield from flattened

        def flatten_single_dim(mapped):
            for item in mapped:
                for subitem in item:
                    yield subitem

        return DataQuanta(
            Operator(
                operator_type=""flatmap"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def group_by(self, udf):
        def func(iterator):
            # TODO key should be given by ""udf""
            return itertools.groupby(iterator, key=operator.itemgetter(0))
            #return itertools.groupby(sorted(iterator), key=itertools.itemgetter(0))

        return DataQuanta(
            Operator(
                operator_type=""group_by"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def map(self, udf):
        def func(iterator):
            return map(udf, iterator)

        return DataQuanta(
            Operator(
                operator_type=""map"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    # Key specifies pivot dimensions
    # UDF specifies reducer function
    def reduce_by_key(self, keys, udf):

        op = Operator(
            operator_type=""reduce_by_key"",
            udf=udf,
            previous=[self.operator],
            python_exec=False
        )

        print(len(keys), keys)
        for i in range(0, len(keys)):
            """"""if keys[i] is int:
                op.set_parameter(""vector_position|""+str(i), keys[i])
            else:
                op.set_parameter(""dimension_key|""+str(i), keys[i])""""""

            # TODO maybe would be better just leave the number as key
            op.set_parameter(""dimension|""+str(i+1), keys[i])

        return DataQuanta(
            op,
            descriptor=self.descriptor
        )

    def reduce(self, udf):
        def func(iterator):
            return reduce(udf, iterator)

        return DataQuanta(
            Operator(
                operator_type=""reduce"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    def sink(self, path, end=""\n""):
        def consume(iterator):
            with open(path, 'w') as f:
                for x in iterator:
                    f.write(str(x) + end)

        def func(iterator):
            consume(iterator)
            # return self.__run(consume)

        return DataQuanta(
            Operator(
                operator_type=""sink"",

                udf=path,
                # To execute directly uncomment
                # udf=func,

                previous=[self.operator],
                python_exec=False
            ),
            descriptor=self.descriptor
        )

    def sort(self, udf):

        def func(iterator):
            return sorted(iterator, key=udf)

        return DataQuanta(
            Operator(
                operator_type=""sort"",
                udf=func,
                previous=[self.operator],
                python_exec=True
            ),
            descriptor=self.descriptor
        )

    # This function allow the union to be performed by Python
    # Nevertheless, current configuration runs it over Java
    def union(self, other):

        def func(iterator):
            return itertools.chain(iterator, other.operator.getIterator())

        return DataQuanta(
            Operator(
                operator_type=""union"",
                udf=func,
                previous=[self.operator, other.operator],
                python_exec=False
            ),
            descriptor=self.descriptor
        )

    def __run(self, consumer):
        consumer(self.operator.getIterator())

    # Execution Functions
    def console(self, end=""\n""):
        def consume(iterator):
            for x in iterator:
                print(x, end=end)

        self.__run(consume)

    # Only for debugging purposes!
    # To execute the plan directly in the program driver
    def execute(self):
        logging.warn(""DEBUG Execution"")
        logging.info(""Reminder to swap SINK UDF value from path to func"")
        logging.debug(self.operator.previous[0].operator_type)
        if self.operator.is_sink():
            logging.debug(self.operator.operator_type)
            logging.debug(self.operator.udf)
            logging.debug(len(self.operator.previous))
            self.operator.udf(self.operator.previous[0].getIterator())
        else:
            logging.error(""Plan must call execute from SINK type of operator"")
            raise RuntimeError

    # Converts Python Functional Plan to valid Wayang Plan
    def to_wayang_plan(self):

        sinks = self.descriptor.get_sinks()
        if len(sinks) == 0:
            return

        graph = Graph()
        graph.populate(self.descriptor.get_sinks())

        # Uncomment to check the Graph built
        # graph.print_adjlist()

        # Function to be consumed by Traverse
        # Separates Python Plan into a List of Pipelines
        def define_pipelines(node1, current_pipeline, collection):
            def store_unique(pipe_to_insert):
                for pipe in collection:
                    if equivalent_lists(pipe, pipe_to_insert):
                        return
                collection.append(pipe_to_insert)

            def equivalent_lists(l1, l2):
                if collections.Counter(l1) == collections.Counter(l2):
                    return True
                else:
                    return False

            if not current_pipeline:
                current_pipeline = [node1]

            elif node1.operator.is_boundary():
                store_unique(current_pipeline.copy())
                current_pipeline.clear()
                current_pipeline.append(node1)

            else:
                current_pipeline.append(node1)

            if node1.operator.sink:
                store_unique(current_pipeline.copy())
                current_pipeline.clear()

            return current_pipeline

        # Works over the graph
        trans = Traversal(
            graph=graph,
            origin=self.descriptor.get_sources(),
            # udf=lambda x, y, z: d(x, y, z)
            # UDF always will receive:
            # x: a Node object,
            # y: an object representing the result of the last iteration,
            # z: a collection to store final results inside your UDF
            udf=lambda x, y, z: define_pipelines(x, y, z)
        )

        # Gets the results of the traverse process
        collected_stages = trans.get_collected_data()

        # Passing the Stages to a Wayang message writer
        writer = MessageWriter()
        a = 0
        # Stage is composed of class Node objects
        for stage in collected_stages:
            a += 1
            logging.info(""///"")
            logging.info(""stage"" + str(a))
            writer.process_pipeline(stage)

        writer.set_dependencies()

        # Uses a file to provide the plan
        # writer.write_message(self.descriptor)

        # Send the plan to Wayang REST api directly
        writer.send_message(self.descriptor)

```

4007edad25359b7cf4fd6b6f97879ecbcbfb9c48","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/439/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/440,https://api.github.com/repos/apache/incubator-wayang/issues/440,incubator-wayang,2286990007,440,create reduce by,github-actions,,,,OPEN,2024-05-09T06:27:33Z,2024-05-09T06:27:33Z,"create reduce by

.reduce_by(reducer) \

.flatmap(lambda elem: elem.split(""|""))

.map(lambda elem: (elem, elem.split(""|""))) \

L_RETURNFLAG 8

L_LINESTATUS 9

L_QUANTITY 4

L_EXTENDEDPRICE 5

discount 6

tax 7

https://github.com/apache/incubator-wayang/blob/c25c6561bf786d76d0dc717b28cf15885c269232/python/old_code/pywayang/src/pywy/orchestrator/execdirectly.py#L114

```python

#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the ""License""); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

from pywy.orchestrator.plan import Descriptor
from pywy.orchestrator.dataquanta import DataQuantaBuilder
import datetime


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_sort(descriptor):
    plan = DataQuantaBuilder(descriptor)
    sink_dataquanta = \
        plan.source(""../test/words.txt"") \
            .sort(lambda elem: elem.lower()) \
            .sink(""../test/output.txt"", end="""")
    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_sort_filter(descriptor):
    plan = DataQuantaBuilder(descriptor)
    sink_dataquanta = \
        plan.source(""../test/words.txt"") \
            .sort(lambda elem: elem.lower()) \
            .filter(lambda elem: str(elem).startswith(""f"")) \
            .sink(""../test/output.txt"", end="""")
    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_filter_text(descriptor):
    plan = DataQuantaBuilder(descriptor)

    sink_dataquanta = \
        plan.source(""../test/words.txt"") \
            .filter(lambda elem: str(elem).startswith(""f"")) \
            .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_filter(descriptor):
    plan = DataQuantaBuilder(descriptor)

    sink_dataquanta = \
        plan.source(""../test/numbers.txt"") \
            .filter(lambda elem: int(elem) % 2 != 0) \
            .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_basic(descriptor):
    plan = DataQuantaBuilder(descriptor)

    sink_dataquanta = \
        plan.source(""../test/lines.txt"") \
            .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_junction(descriptor):

    plan = DataQuantaBuilder(descriptor)

    dq_source_a = plan.source(""../test/lines.txt"")
    dq_source_b = plan.source(""../test/morelines.txt"") \
        .filter(lambda elem: str(elem).startswith(""I""))
    dq_source_c = plan.source(""../test/lastlines.txt"") \
        .filter(lambda elem: str(elem).startswith(""W""))

    sink_dataquanta = dq_source_a.union(dq_source_b) \
        .union(dq_source_c) \
        .sort(lambda elem: elem.lower()) \
        .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


def plan_java_junction(descriptor):

    plan = DataQuantaBuilder(descriptor)

    dq_source_a = plan.source(""../test/lines.txt"")
    dq_source_b = plan.source(""../test/morelines.txt"")
    sink_dataquanta = dq_source_a.union(dq_source_b) \
        .filter(lambda elem: str(elem).startswith(""I"")) \
        .sort(lambda elem: elem.lower()) \
        .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


def plan_tpch_q1(descriptor):

    #TODO create reduce by
    plan = DataQuantaBuilder(descriptor)

    def reducer(obj1, obj2):
        return obj1[0]

    sink = plan.source(""../test/lineitem.txt"") \
        .map(lambda elem: elem.split(""|"")) \
        .filter(lambda elem: datetime.datetime.strptime(elem[10], '%Y-%m-%d') <= datetime.datetime.strptime(""1998-09-02"", '%Y-%m-%d')) \
        .map(lambda elem:
           [elem[8], elem[9], elem[4], elem[5],
            float(elem[5]) * (1 - float(elem[6])),
            float(elem[5]) * (1 - float(elem[6])) * (1 + float(elem[7])),
            elem[4], elem[5],
            elem[6], 1]) \
        .sink(""../test/output.txt"", end="""")
        # .group_by(lambda elem: elem) \
        # .reduce_by(reducer) \
        # .flatmap(lambda elem: elem.split(""|""))
        # .map(lambda elem: (elem, elem.split(""|""))) \
        # L_RETURNFLAG 8
        # L_LINESTATUS 9
        # L_QUANTITY 4
        # L_EXTENDEDPRICE 5
        # discount 6
        # tax 7

    return dq_source_b


def plan_full_java(descriptor):

    plan = DataQuantaBuilder(descriptor)

    dq_source_a = plan.source(""../test/lines.txt"")
    dq_source_b = plan.source(""../test/morelines.txt"")
    sink_dataquanta = dq_source_a.union(dq_source_b) \
        .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


if __name__ == '__main__':

    # Plan will contain general info about the Wayang Plan created here
    descriptor = Descriptor()

    plan_dataquanta_sink = plan_tpch_q1(descriptor)
    plan_dataquanta_sink.execute()

```

06296b40237c1727ab4da714fdb181df2e2932ae","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/440/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/441,https://api.github.com/repos/apache/incubator-wayang/issues/441,incubator-wayang,2286990056,441,create reduce by,github-actions,,,,OPEN,2024-05-09T06:27:34Z,2024-08-06T11:37:29Z,"create reduce by

plan_dataquanta_sink.console()

https://github.com/apache/incubator-wayang/blob/c25c6561bf786d76d0dc717b28cf15885c269232/python/old_code/pywayang/src/pywy/orchestrator/main.py#L114

```python

#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the ""License""); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

from pywy.orchestrator.plan import Descriptor
from pywy.orchestrator.dataquanta import DataQuantaBuilder
import datetime


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_sort(descriptor):
    plan = DataQuantaBuilder(descriptor)
    sink_dataquanta = \
        plan.source(""../test/words.txt"") \
            .sort(lambda elem: elem.lower()) \
            .sink(""../test/output.txt"", end="""")
    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_sort_filter(descriptor):
    plan = DataQuantaBuilder(descriptor)
    sink_dataquanta = \
        plan.source(""../test/words.txt"") \
            .sort(lambda elem: elem.lower()) \
            .filter(lambda elem: str(elem).startswith(""f"")) \
            .sink(""../test/output.txt"", end="""")
    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_filter_text(descriptor):
    plan = DataQuantaBuilder(descriptor)

    sink_dataquanta = \
        plan.source(""../test/words.txt"") \
            .filter(lambda elem: str(elem).startswith(""f"")) \
            .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_filter(descriptor):
    plan = DataQuantaBuilder(descriptor)

    sink_dataquanta = \
        plan.source(""../test/numbers.txt"") \
            .filter(lambda elem: int(elem) % 2 != 0) \
            .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_basic(descriptor):
    plan = DataQuantaBuilder(descriptor)

    sink_dataquanta = \
        plan.source(""../test/lines.txt"") \
            .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


# Returns the Sink Executable Dataquanta of a DEMO plan
def plan_junction(descriptor):

    plan = DataQuantaBuilder(descriptor)

    dq_source_a = plan.source(""../test/lines.txt"")
    dq_source_b = plan.source(""../test/morelines.txt"") \
        .filter(lambda elem: str(elem).startswith(""I""))
    dq_source_c = plan.source(""../test/lastlines.txt"") \
        .filter(lambda elem: str(elem).startswith(""W""))

    sink_dataquanta = dq_source_a.union(dq_source_b) \
        .union(dq_source_c) \
        .sort(lambda elem: elem.lower()) \
        .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


def plan_java_junction(descriptor):

    plan = DataQuantaBuilder(descriptor)

    dq_source_a = plan.source(""../test/lines.txt"")
    dq_source_b = plan.source(""../test/morelines.txt"")
    sink_dataquanta = dq_source_a.union(dq_source_b) \
        .filter(lambda elem: str(elem).startswith(""I"")) \
        .sort(lambda elem: elem.lower()) \
        .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


def plan_tpch_q1(descriptor):

    # TODO create reduce by
    plan = DataQuantaBuilder(descriptor)

    def reducer(obj1, obj2):
        return obj1[0], obj1[1], obj1[2] + obj2[2], obj1[3] + obj2[3], obj1[4] + obj2[4], obj1[5] + obj2[5], \
               obj1[6] + obj2[6], obj1[7] + obj2[7], obj1[8] + obj2[8], obj1[9] + obj2[9]

    sink = plan.source(""../test/lineitem.txt"") \
        .map(lambda elem: elem.split(""|"")) \
        .sink(""../test/output.txt"", end="""")
    """"""
        .filter(lambda elem: datetime.datetime.strptime(elem[10], '%Y-%m-%d') <= datetime.datetime.strptime('1998-09-02', '%Y-%m-%d')) \
        .map(lambda elem:
             [elem[8], elem[9], elem[4], elem[5],
              float(elem[5]) * (1 - float(elem[6])),
              float(elem[5]) * (1 - float(elem[6])) * (1 + float(elem[7])),
              elem[4], elem[5],
              elem[6], 1]) \
        .sink(""../test/output.txt"", end="""")""""""
        # .reduce_by_key([0, 1], reducer) \


    return sink


def plan_full_java(descriptor):

    plan = DataQuantaBuilder(descriptor)

    dq_source_a = plan.source(""../test/lines.txt"")
    dq_source_b = plan.source(""../test/morelines.txt"")
    sink_dataquanta = dq_source_a.union(dq_source_b) \
        .sink(""../test/output.txt"", end="""")

    return sink_dataquanta


def plan_wordcount(descriptor):

    plan = DataQuantaBuilder(descriptor)
    sink_wordcount = plan.source(""../test/lineitem.txt"") \
        .filter(lambda elem: len(str(elem).split(""|"")[0]) < 4) \
        .flatmap(lambda elem: str(elem).split(""|"")) \
        .sink(""../test/output.txt"", end="""")

    return sink_wordcount


if __name__ == '__main__':

    # Plan will contain general info about the Wayang Plan created here
    descriptor = Descriptor()
    descriptor.add_plugin(Descriptor.Plugin.spark)
    descriptor.add_plugin(Descriptor.Plugin.java)

    plan_dataquanta_sink = plan_wordcount(descriptor)
    # plan_dataquanta_sink.execute()
    # plan_dataquanta_sink.console()

    plan_dataquanta_sink.to_wayang_plan()

```

fdb3eb31032a7177317967ac4f1a9ed72e2b36f0","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/441/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/441,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6HQkbx,incubator-wayang,2269267697,441,NA,Aryant01,108977687,Aryant Kumar,,NA,2024-08-05T14:51:31Z,2024-08-05T14:51:31Z,"Hey. I would like to work on this issue. Can you please assign this to me?
","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6HQkbx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/441,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6HWQYy,incubator-wayang,2270758450,441,NA,zkaoudi,10105712,Zoi Kaoudi,,NA,2024-08-06T09:00:42Z,2024-08-06T09:00:42Z,"Hi, this issue is resolved in the PR we just merged. Would you like to take on this one: 
https://github.com/apache/incubator-wayang/issues/418 ?","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6HWQYy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/441,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6HXe2j,incubator-wayang,2271079843,441,NA,Aryant01,108977687,Aryant Kumar,,NA,2024-08-06T11:37:28Z,2024-08-06T11:37:28Z,"@zkaoudi sure. I would like to take take that.
","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6HXe2j/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/442,https://api.github.com/repos/apache/incubator-wayang/issues/442,incubator-wayang,2286990085,442,Why managing previous and predecessors per separate?,github-actions,,,,OPEN,2024-05-09T06:27:36Z,2024-05-09T06:27:37Z,"Why managing previous and predecessors per separate?

https://github.com/apache/incubator-wayang/blob/c25c6561bf786d76d0dc717b28cf15885c269232/python/old_code/pywayang/src/pywy/orchestrator/operator.py#L69

```python

#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the ""License""); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

import pickle
import cloudpickle
from pywy.config.config_reader import get_source_types
from pywy.config.config_reader import get_sink_types
from pywy.config.config_reader import get_boundary_types
import logging

pickle_protocol = pickle.HIGHEST_PROTOCOL


# Describes an Operation over an intermediate result
# Each operation could be processed by Python or Java platforms
class Operator:

    def __init__(
            self, operator_type=None, udf=None, previous=None,
            iterator=None, python_exec=False
    ):

        # Operator ID
        self.id = id(self)

        # Operator Type
        self.operator_type = operator_type

        # Set Boundaries
        if self.operator_type in get_boundary_types():
            self.boundary = True
        else:
            self.boundary = False

        # UDF Function
        self.udf = udf

        # Source types must come with an Iterator
        self.iterator = iterator
        if operator_type in get_source_types():
            if iterator is None:
                print(""Source Operator Type without an Iterator"")
                raise
            else:
                self.source = True
        else:
            self.source = False

        # Sink Operators
        if operator_type in get_sink_types():
            self.sink = True
        else:
            self.sink = False

        # TODO Why managing previous and predecessors per separate?
        self.previous = previous

        self.successor = []
        self.predecessor = []

        self.parameters = {}

        # Set predecessors and successors from previous
        if self.previous:
            for prev in self.previous:
                if prev is not None:
                    prev.set_successor(self)
                    self.set_predecessor(prev)

        self.python_exec = python_exec

        logging.info(""Operator:"" + str(self.getID()) + "", type:"" + self.operator_type + "", PythonExecutable: "" +
                     str(self.python_exec) +
                     "", is boundary: "" + str(self.is_boundary()) + "", is source: "" +
                     str(self.source) + "", is sink: "" + str(self.sink))

    def getID(self):
        return self.id

    def is_source(self):
        return self.source

    def is_sink(self):
        return self.sink

    def is_boundary(self):
        return self.boundary

    def serialize_udf(self):
        self.udf = cloudpickle.dumps(self.udf)

    def getIterator(self):
        if self.is_source():
            return self.iterator
        # TODO this should iterate through previous REDESIGN
        return self.udf(self.previous[0].getIterator())

    def set_parameter(self, key, value):
        self.parameters[key] = value

    def set_successor(self, suc):
        if (not self.is_sink()) and self.successor.count(suc) == 0:
            self.successor.append(suc)

    def set_predecessor(self, suc):
        if self.predecessor.count(suc) == 0:
            self.predecessor.append(suc)

```

ea17eb1209cadc4bb2dbe95f752590de9723a51d","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/442/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/443,https://api.github.com/repos/apache/incubator-wayang/issues/443,incubator-wayang,2286990121,443,this should iterate through previous REDESIGN,github-actions,,,,OPEN,2024-05-09T06:27:38Z,2024-05-09T06:27:38Z,"this should iterate through previous REDESIGN

https://github.com/apache/incubator-wayang/blob/c25c6561bf786d76d0dc717b28cf15885c269232/python/old_code/pywayang/src/pywy/orchestrator/operator.py#L109

```python

#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the ""License""); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

import pickle
import cloudpickle
from pywy.config.config_reader import get_source_types
from pywy.config.config_reader import get_sink_types
from pywy.config.config_reader import get_boundary_types
import logging

pickle_protocol = pickle.HIGHEST_PROTOCOL


# Describes an Operation over an intermediate result
# Each operation could be processed by Python or Java platforms
class Operator:

    def __init__(
            self, operator_type=None, udf=None, previous=None,
            iterator=None, python_exec=False
    ):

        # Operator ID
        self.id = id(self)

        # Operator Type
        self.operator_type = operator_type

        # Set Boundaries
        if self.operator_type in get_boundary_types():
            self.boundary = True
        else:
            self.boundary = False

        # UDF Function
        self.udf = udf

        # Source types must come with an Iterator
        self.iterator = iterator
        if operator_type in get_source_types():
            if iterator is None:
                print(""Source Operator Type without an Iterator"")
                raise
            else:
                self.source = True
        else:
            self.source = False

        # Sink Operators
        if operator_type in get_sink_types():
            self.sink = True
        else:
            self.sink = False

        # TODO Why managing previous and predecessors per separate?
        self.previous = previous

        self.successor = []
        self.predecessor = []

        self.parameters = {}

        # Set predecessors and successors from previous
        if self.previous:
            for prev in self.previous:
                if prev is not None:
                    prev.set_successor(self)
                    self.set_predecessor(prev)

        self.python_exec = python_exec

        logging.info(""Operator:"" + str(self.getID()) + "", type:"" + self.operator_type + "", PythonExecutable: "" +
                     str(self.python_exec) +
                     "", is boundary: "" + str(self.is_boundary()) + "", is source: "" +
                     str(self.source) + "", is sink: "" + str(self.sink))

    def getID(self):
        return self.id

    def is_source(self):
        return self.source

    def is_sink(self):
        return self.sink

    def is_boundary(self):
        return self.boundary

    def serialize_udf(self):
        self.udf = cloudpickle.dumps(self.udf)

    def getIterator(self):
        if self.is_source():
            return self.iterator
        # TODO this should iterate through previous REDESIGN
        return self.udf(self.previous[0].getIterator())

    def set_parameter(self, key, value):
        self.parameters[key] = value

    def set_successor(self, suc):
        if (not self.is_sink()) and self.successor.count(suc) == 0:
            self.successor.append(suc)

    def set_predecessor(self, suc):
        if self.predecessor.count(suc) == 0:
            self.predecessor.append(suc)

```

4baec02253eb7358e50ee51940e28e5b8b26a89f","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/443/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/444,https://api.github.com/repos/apache/incubator-wayang/issues/444,incubator-wayang,2286990159,444,not necesary it it 0,github-actions,,,,OPEN,2024-05-09T06:27:40Z,2024-05-09T06:27:40Z,"not necesary it it 0

https://github.com/apache/incubator-wayang/blob/c25c6561bf786d76d0dc717b28cf15885c269232/python/old_code/src/pywy/core/core.py#L165

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

from typing import Set, Iterable

from pywy.core.executor import Executor
from pywy.core.platform import Platform
from pywy.core.mapping import Mapping
from pywy.graph.graph import WayangGraph
from pywy.graph.types import WGraphOfVec, NodeOperator, NodeVec
from pywy.operators import SinkOperator


class TranslateContext:
    """"""TranslateContext contextual variables a parameters for the translation
    """"""
    pass


class Plugin:
    """""" TODO: enrich this documentation
    A plugin contributes the following components to a :class:`Context`
    - mappings
    - channels
    - configurations
    In turn, it may require several :clas:`Platform`s for its operation.
    """"""

    platforms: Set[Platform]
    mappings: Mapping
    translate_context: TranslateContext

    def __init__(
            self,
            platforms: Set[Platform],
            mappings: Mapping = Mapping(),
            translate_context: TranslateContext = None):
        self.platforms = platforms
        self.mappings = mappings
        self.translate_context = translate_context

    def get_mappings(self) -> Mapping:
        return self.mappings

    def get_executor(self) -> Executor:
        pass

    def __str__(self):
        return ""Platforms: {}, Mappings: {}"".format(str(self.platforms), str(self.mappings))

    def __repr__(self):
        return self.__str__()


class PywyPlan:
    """"""A PywyPlan consists of a set of :py:class:`pywy.operators.base.PywyOperator`

    the operator inside PywyPlan follow a Directed acyclic graph(DAG), and describe
    how the execution needs to be performed

    Attributes
    ----------
    graph : :py:class:`pywy.graph.graph.WayangGraph`
       Graph that describe the DAG, and it provides the iterable properties to
       the PywyPlan
    plugins : :obj:`set` of :py:class:`pywy.core.plugin.Plugin`
        plugins is the set of possible platforms that can be uses to execute
        the PywyPlan
    sinks : :py:class:`typing.Iterable` of :py:class:`pywy.operators.sink.SinkOperator`
        The list of sink operators, this describe the end of the pipeline, and
        they are used to build the `graph`
    """"""
    graph: WayangGraph

    def __init__(self, plugins: Set[Plugin], sinks: Iterable[SinkOperator]):
        """"""basic Constructor of PywyPlan

        this constructor set the plugins and sinks element, and it prepares
        everything for been executed

        Parameters
        ----------
        plugins
            Description of `plugins`.
        sinks
            Description of `sinks`.
        """"""
        self.plugins = plugins
        self.sinks = sinks
        self.set_graph()

    def set_graph(self):
        """""" it builds the :py:class:`pywy.graph.graph.WayangGraph` of the current PywyPlan
        """"""
        self.graph = WGraphOfVec(self.sinks)

    def execute(self):
        """""" Execute the plan with the plugin provided at the moment of creation
        """"""
        plug = next(iter(self.plugins))
        trs: Translator = Translator(plug, self)
        new_plan = trs.translate()
        plug.get_executor().execute(new_plan)


class Translator:
    """"""Translator use the :py:class:`pywy.core.Mapping` to convert the :py:class:`pywy.operators.base.PywyOperator`

    Translator take a plan a produce the executable version of the plan using as tool
    the :py:class:`pywy.core.Mapping` of the :py:class:`pywy.core.core.Plugin` and convert
    the :py:class:`pywy.operators.base.PywyOperator` into an executable version inside
    the :py:class:`pywy.core.Platform`

    Attributes
    ----------
    plugin : :py:class:`pywy.core.core.Plugin`
        plugin use in the translation
    plan : :py:class:`pywy.core.core.PywyPlan`
        Plan to be translated by the translator
    translate_context: :py:class:`pywy.core.core.TranslateContext`
        context used by the translates at runtime in some case is not needed
    """"""

    plugin: Plugin
    plan: PywyPlan
    translate_context: TranslateContext

    def __init__(self, plugin: Plugin, plan: PywyPlan):
        self.plugin = plugin
        self.plan = plan
        self.translate_context = plugin.translate_context

    def translate(self):
        mappings: Mapping = self.plugin.get_mappings()
        graph = WGraphOfVec(self.plan.sinks)

        translate = self.translate_context

        def translate2plugin(current_op: NodeVec, next_op: NodeVec):
            if current_op is None:
                return

            if current_op.current[1] is None:
                current_op.current[1] = mappings.get_instanceof(current_op.current[0], **{'translate_context': translate})

            if next_op is None:
                return
            if next_op.current[1] is None:
                next_op.current[1] = mappings.get_instanceof(next_op.current[0], **{'translate_context': translate})

            # TODO not necesary it it 0
            current_op.current[1].connect(0, next_op.current[1], 0)

        graph.traversal(graph.starting_nodes, translate2plugin)

        node = []
        for elem in graph.starting_nodes:
            node.append(elem.current[1])

        return PywyPlan({self.plugin}, node)

```

50574c50e01265688b1ec7db7a12a77fa5fb8295","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/444/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/447,https://api.github.com/repos/apache/incubator-wayang/issues/447,incubator-wayang,2286990194,447,enrich this documentation,github-actions,,,,OPEN,2024-05-09T06:27:42Z,2024-05-09T06:27:42Z,"enrich this documentation

A plugin contributes the following components to a :class:`Context`

- mappings

- channels

- configurations

In turn, it may require several :clas:`Platform`s for its operation.

https://github.com/apache/incubator-wayang/blob/c25c6561bf786d76d0dc717b28cf15885c269232/python/old_code/src/pywy/core/core.py#L35

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

from typing import Set, Iterable

from pywy.core.executor import Executor
from pywy.core.platform import Platform
from pywy.core.mapping import Mapping
from pywy.graph.graph import WayangGraph
from pywy.graph.types import WGraphOfVec, NodeOperator, NodeVec
from pywy.operators import SinkOperator


class TranslateContext:
    """"""TranslateContext contextual variables a parameters for the translation
    """"""
    pass


class Plugin:
    """""" TODO: enrich this documentation
    A plugin contributes the following components to a :class:`Context`
    - mappings
    - channels
    - configurations
    In turn, it may require several :clas:`Platform`s for its operation.
    """"""

    platforms: Set[Platform]
    mappings: Mapping
    translate_context: TranslateContext

    def __init__(
            self,
            platforms: Set[Platform],
            mappings: Mapping = Mapping(),
            translate_context: TranslateContext = None):
        self.platforms = platforms
        self.mappings = mappings
        self.translate_context = translate_context

    def get_mappings(self) -> Mapping:
        return self.mappings

    def get_executor(self) -> Executor:
        pass

    def __str__(self):
        return ""Platforms: {}, Mappings: {}"".format(str(self.platforms), str(self.mappings))

    def __repr__(self):
        return self.__str__()


class PywyPlan:
    """"""A PywyPlan consists of a set of :py:class:`pywy.operators.base.PywyOperator`

    the operator inside PywyPlan follow a Directed acyclic graph(DAG), and describe
    how the execution needs to be performed

    Attributes
    ----------
    graph : :py:class:`pywy.graph.graph.WayangGraph`
       Graph that describe the DAG, and it provides the iterable properties to
       the PywyPlan
    plugins : :obj:`set` of :py:class:`pywy.core.plugin.Plugin`
        plugins is the set of possible platforms that can be uses to execute
        the PywyPlan
    sinks : :py:class:`typing.Iterable` of :py:class:`pywy.operators.sink.SinkOperator`
        The list of sink operators, this describe the end of the pipeline, and
        they are used to build the `graph`
    """"""
    graph: WayangGraph

    def __init__(self, plugins: Set[Plugin], sinks: Iterable[SinkOperator]):
        """"""basic Constructor of PywyPlan

        this constructor set the plugins and sinks element, and it prepares
        everything for been executed

        Parameters
        ----------
        plugins
            Description of `plugins`.
        sinks
            Description of `sinks`.
        """"""
        self.plugins = plugins
        self.sinks = sinks
        self.set_graph()

    def set_graph(self):
        """""" it builds the :py:class:`pywy.graph.graph.WayangGraph` of the current PywyPlan
        """"""
        self.graph = WGraphOfVec(self.sinks)

    def execute(self):
        """""" Execute the plan with the plugin provided at the moment of creation
        """"""
        plug = next(iter(self.plugins))
        trs: Translator = Translator(plug, self)
        new_plan = trs.translate()
        plug.get_executor().execute(new_plan)


class Translator:
    """"""Translator use the :py:class:`pywy.core.Mapping` to convert the :py:class:`pywy.operators.base.PywyOperator`

    Translator take a plan a produce the executable version of the plan using as tool
    the :py:class:`pywy.core.Mapping` of the :py:class:`pywy.core.core.Plugin` and convert
    the :py:class:`pywy.operators.base.PywyOperator` into an executable version inside
    the :py:class:`pywy.core.Platform`

    Attributes
    ----------
    plugin : :py:class:`pywy.core.core.Plugin`
        plugin use in the translation
    plan : :py:class:`pywy.core.core.PywyPlan`
        Plan to be translated by the translator
    translate_context: :py:class:`pywy.core.core.TranslateContext`
        context used by the translates at runtime in some case is not needed
    """"""

    plugin: Plugin
    plan: PywyPlan
    translate_context: TranslateContext

    def __init__(self, plugin: Plugin, plan: PywyPlan):
        self.plugin = plugin
        self.plan = plan
        self.translate_context = plugin.translate_context

    def translate(self):
        mappings: Mapping = self.plugin.get_mappings()
        graph = WGraphOfVec(self.plan.sinks)

        translate = self.translate_context

        def translate2plugin(current_op: NodeVec, next_op: NodeVec):
            if current_op is None:
                return

            if current_op.current[1] is None:
                current_op.current[1] = mappings.get_instanceof(current_op.current[0], **{'translate_context': translate})

            if next_op is None:
                return
            if next_op.current[1] is None:
                next_op.current[1] = mappings.get_instanceof(next_op.current[0], **{'translate_context': translate})

            # TODO not necesary it it 0
            current_op.current[1].connect(0, next_op.current[1], 0)

        graph.traversal(graph.starting_nodes, translate2plugin)

        node = []
        for elem in graph.starting_nodes:
            node.append(elem.current[1])

        return PywyPlan({self.plugin}, node)

```

f8cbbad2e7b20fd8850fb8bd0a0b3e142bc8d593","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/447/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/448,https://api.github.com/repos/apache/incubator-wayang/issues/448,incubator-wayang,2286990230,448,check for the case where the index matter,github-actions,,,,OPEN,2024-05-09T06:27:43Z,2024-05-09T06:27:44Z,"check for the case where the index matter

https://github.com/apache/incubator-wayang/blob/c25c6561bf786d76d0dc717b28cf15885c269232/python/old_code/src/pywy/platforms/jvm/operator/jvm_unary_flatmap.py#L62

```python

#
#  Licensed to the Apache Software Foundation (ASF) under one or more
#  contributor license agreements.  See the NOTICE file distributed with
#  this work for additional information regarding copyright ownership.
#  The ASF licenses this file to You under the Apache License, Version 2.0
#  (the ""License""); you may not use this file except in compliance with
#  the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an ""AS IS"" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

from typing import Set, List, Type
from itertools import chain

from pywy.core.channel import CH_T, ChannelDescriptor
from pywy.operators.unary import FlatmapOperator
from pywy.platforms.jvm.channels import DISPATCHABLE_CHANNEL_DESCRIPTOR, DispatchableChannel
from pywy.platforms.jvm.operator.jvm_execution_operator import JVMExecutionOperator
from pywy.platforms.commons.channels import (
    CommonsCallableChannel
)
from pywy.platforms.jvm.serializable.wayang_jvm_operator import WayangJVMMappartitionOperator, WayangJVMOperator


class JVMFlatmapOperator(FlatmapOperator, JVMExecutionOperator):

    def __init__(self, origin: FlatmapOperator = None, **kwargs):
        fm_function = None if origin is None else origin.fm_function
        super().__init__(fm_function)
        self.set_context(**kwargs)

    def execute(self, inputs: List[Type[CH_T]], outputs: List[Type[CH_T]]):
        self.validate_channels(inputs, outputs)
        udf = self.fm_function
        if isinstance(inputs[0], DispatchableChannel):
            py_in_dispatch_channel: DispatchableChannel = inputs[0]
            py_out_dispatch_channel: DispatchableChannel = outputs[0]

            def func(iterator):
                return chain.from_iterable(map(udf, iterator))

            py_out_dispatch_channel.accept_callable(
                CommonsCallableChannel.concatenate(
                    func,
                    py_in_dispatch_channel.provide_callable()
                )
            )

            op: WayangJVMOperator = py_in_dispatch_channel.provide_dispatchable()

            if isinstance(op, WayangJVMMappartitionOperator):
                py_out_dispatch_channel.accept_dispatchable(op)
                return

            current: WayangJVMMappartitionOperator = WayangJVMMappartitionOperator(self.name)
            # TODO check for the case where the index matter
            op.connect_to(0, current, 0)
            self.close_operator(op)
            py_out_dispatch_channel.accept_dispatchable(current)

        else:
            raise Exception(""Channel Type does not supported"")

    def get_input_channeldescriptors(self) -> Set[ChannelDescriptor]:
        return {DISPATCHABLE_CHANNEL_DESCRIPTOR}

    def get_output_channeldescriptors(self) -> Set[ChannelDescriptor]:
        return {DISPATCHABLE_CHANNEL_DESCRIPTOR}

```

a0e00e9d708aa85292080382017bfe2eb174f24e","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/448/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/449,https://api.github.com/repos/apache/incubator-wayang/issues/449,incubator-wayang,2286990339,449,Properly type this in the future,github-actions,,,,OPEN,2024-05-09T06:27:48Z,2024-05-09T06:27:49Z,"Properly type this in the future

https://github.com/apache/incubator-wayang/blob/c25c6561bf786d76d0dc717b28cf15885c269232/wayang-api/wayang-api-python/src/main/java/org/apache/wayang/api/python/executor/ProcessFeeder.java#L104

```java

             * Byte Array cases
             */
            else if (obj instanceof Byte[] || obj instanceof byte[]) {
                writeBytes(obj, dataOut);
            }
            /**
             * String case
             * */
            else if (obj instanceof String) {
                writeUTF((String) obj, dataOut);
            }

            // TODO: Properly type this in the future
            else if (obj instanceof Object) {
                writeUTF(String.valueOf(obj), dataOut);
            }

            /**
             * Key, Value case
             * */
            else if (obj instanceof Map.Entry) {
                writeKeyValue((Map.Entry) obj, dataOut);
            }

            else{
                throw new WayangException(""Unexpected element type "" + obj.getClass());
            }

        } catch (IOException e) {
            e.printStackTrace();
        }

```

b486b16bbf5753fbec1338c4d5250e7197caa056","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/449/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/450,https://api.github.com/repos/apache/incubator-wayang/issues/450,incubator-wayang,2286990635,450,watch if is it possible to put it with parameters,github-actions,,,,CLOSED,2024-05-09T06:28:02Z,2024-08-06T08:40:01Z,"watch if is it possible to put it with parameters

https://github.com/apache/incubator-wayang/blob/c25c6561bf786d76d0dc717b28cf15885c269232/wayang-commons/wayang-serializable/pom.xml#L91

```xml

<?xml version=""1.0"" encoding=""UTF-8""?>
<!--
  Licensed to the Apache Software Foundation (ASF) under one
  or more contributor license agreements.  See the NOTICE file
  distributed with this work for additional information
  regarding copyright ownership.  The ASF licenses this file
  to you under the Apache License, Version 2.0 (the
  ""License""); you may not use this file except in compliance
  with the License.  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing,
  software distributed under the License is distributed on an
  ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
  KIND, either express or implied.  See the License for the
  specific language governing permissions and limitations
  under the License.
  -->
<project xmlns=""http://maven.apache.org/POM/4.0.0""
         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
    <parent>
        <artifactId>wayang-commons</artifactId>
        <groupId>org.apache.wayang</groupId>
        <version>0.7.1</version>
    </parent>
    <modelVersion>4.0.0</modelVersion>

    <artifactId>wayang-serializable</artifactId>
    <version>0.7.1</version>
    <packaging>jar</packaging>

    <properties>
        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
        <protobuf.version>3.15.2</protobuf.version>
        <protoc.version>3.15.2</protoc.version>
        <maven.compiler.source>1.8</maven.compiler.source>
        <maven.compiler.target>1.8</maven.compiler.target>
    </properties>

    <dependencyManagement>
        <dependencies>
            <dependency>
                <groupId>org.apache.wayang</groupId>
                <artifactId>wayang-commons</artifactId>
                <version>0.7.1</version>
                <type>pom</type>
                <scope>import</scope>
            </dependency>
        </dependencies>
    </dependencyManagement>

    <dependencies>
        <dependency>
            <groupId>com.google.protobuf</groupId>
            <artifactId>protobuf-java</artifactId>
            <version>${protobuf.version}</version>
        </dependency>
    </dependencies>
    <build>
        <extensions>
            <extension>
                <groupId>kr.motd.maven</groupId>
                <artifactId>os-maven-plugin</artifactId>
                <version>1.6.2</version>
            </extension>
        </extensions>
        <plugins>
            <plugin>
                <groupId>org.xolstice.maven.plugins</groupId>
                <artifactId>protobuf-maven-plugin</artifactId>
                <version>0.5.1</version>
                <configuration>
                    <protocArtifact>com.google.protobuf:protoc:${protoc.version}:exe:${os.detected.classifier}</protocArtifact>
                </configuration>
                <executions>
                    <execution>
                        <goals>
                            <goal>compile</goal>
                            <goal>compile-python</goal>
                            <goal>test-compile</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>
        </plugins>
        <!-- Copy all the protobuf code to the folder PyWayang -->
        <resources>
            <resource>
                <!-- TODO: watch if is it possible to put it with parameters -->
                <directory>${basedir}/target/generated-sources/protobuf/python</directory><!-- from -->
                <targetPath>${basedir}/../../pywayang/protobuf</targetPath><!-- to -->
                <includes><!-- Only python files -->
                    <include>**/*.py</include>
                </includes>
            </resource>
        </resources>
    </build>

</project>

```

6268890184ef9fb56ec2e471bd7225dadb36fff3","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/450/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/450,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6HQf34,incubator-wayang,2269249016,450,NA,Aryant01,108977687,Aryant Kumar,,NA,2024-08-05T14:43:11Z,2024-08-05T14:43:11Z,Hey! Can you please assign this issue to me. I would like to work on this. ,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6HQf34/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/450,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6HWE19,incubator-wayang,2270711165,450,NA,github-actions,,,,NA,2024-08-06T08:39:59Z,2024-08-06T08:39:59Z,Closed in 3fa3c3891d46291c0dc4818d2d6550c7440fd9a9,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6HWE19/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/458,https://api.github.com/repos/apache/incubator-wayang/issues/458,incubator-wayang,2462435591,458,Add feature for reading a textfile from URLs,kamir,1241122,Mirko Kämpf,mirko.kaempf@gmail.com,CLOSED,2024-08-13T05:45:08Z,2024-08-13T11:43:17Z,"After cleaning the branches we have now a clear pull request with 4 files. 

It allows us to specify a URL for the Java and Scala File-Source.","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/458/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/458,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6IQjn7,incubator-wayang,2286041595,458,NA,kamir,1241122,Mirko Kämpf,mirko.kaempf@gmail.com,NA,2024-08-13T11:43:15Z,2024-08-13T11:43:15Z,PR has been merged.,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6IQjn7/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/465,https://api.github.com/repos/apache/incubator-wayang/issues/465,incubator-wayang,2482803748,465,FAILED UNIT TEST - Cloud based build is blocked,kamir,1241122,Mirko Kämpf,mirko.kaempf@gmail.com,CLOSED,2024-08-23T10:10:35Z,2024-09-05T09:18:16Z,"[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.wayang.java.test.KafkaClientTest
> 0 ... 
*** [TOPIC-Name] banking-tx-small-csv ***
>   Read from topic ... 
> 1 ... 
null
null
null
null
null
null
Error:  Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.04 s <<< FAILURE! - in org.apache.wayang.java.test.KafkaClientTest
Error:  org.apache.wayang.java.test.KafkaClientTest.testReadFromKafkaTopic  Time elapsed: 0.022 s  <<< ERROR!
java.lang.NullPointerException
	at org.apache.wayang.java.test.KafkaClientTest.getDefaultProperties(KafkaClientTest.java:113)
	at org.apache.wayang.java.test.KafkaClientTest.testReadFromKafkaTopic(KafkaClientTest.java:49)

[INFO] Running org.apache.wayang.java.execution.JavaExecutorTest
### 13 ... 
### 11 ... 


Error:    JavaKafkaTopicSourceTest.testReadFromKafkaTopic:94 » NullPointer

Error:    KafkaClientTest.testReadFromKafkaTopic:49->getDefaultProperties:113 » NullPointer","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/465/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/465,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6K8JLr,incubator-wayang,2331022059,465,NA,kamir,1241122,Mirko Kämpf,mirko.kaempf@gmail.com,NA,2024-09-05T09:18:14Z,2024-09-05T09:18:14Z,"The tests have temporarily been deactivated.
","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6K8JLr/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/469,https://api.github.com/repos/apache/incubator-wayang/issues/469,incubator-wayang,2507246827,469,Restructure the Kafka related operators,kamir,1241122,Mirko Kämpf,mirko.kaempf@gmail.com,OPEN,2024-09-05T09:21:14Z,2024-09-05T12:00:14Z,"Proposal:

We create a **wayang-kafka** module inside of **wayang-platforms**.
This leads to a cleaner approach to add these operators. 

Right now we edit both **wayang-java** and **wayang-spark**, where both of them contain versions of operators related to reading and writing to Kafka. 

Conceptually, having all implementations for the specific APIs in **wayang-kafka** would be neat. 

Then you could have wayang-kafka/src/main/java/JavaKafkaOperator wayang-kafka/src/main/java/SparkKafkaOperator etc. and the respective platforms themselves don't have to concern about Kafka.

It is planned to implement this as soon as the initial demos for Kafka integration are ready.

Target: Release 1.1 - Q1-2025.","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/469/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/469,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6K9F6h,incubator-wayang,2331270817,469,NA,zkaoudi,10105712,Zoi Kaoudi,,NA,2024-09-05T11:23:01Z,2024-09-05T11:23:01Z,"To take this further, we create another module called wayang-io (or some other name) and inside this parent module we place the wayang-kafka module that @kamir mentioned above. The reason for that being: Kafka is not a processing platform, only reads or writes data. So inside wayang-io we can have all the data sources and the data sinks.","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6K9F6h/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/469,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6K9WYb,incubator-wayang,2331338267,469,NA,2pk03,1323575,Alexander Alten-Lorenz,,NA,2024-09-05T12:00:13Z,2024-09-05T12:00:13Z,+1 - that's a great idea! There we can also put our REST API or pure storage modules.,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6K9WYb/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/477,https://api.github.com/repos/apache/incubator-wayang/issues/477,incubator-wayang,2578760586,477,Http connection in JavaTextFileSource inside an exception,zkaoudi,10105712,Zoi Kaoudi,,OPEN,2024-10-10T12:52:47Z,2024-10-10T12:52:47Z,"Currently, the code for reading files remotely through an Http call in the JavaTextFileSource is inside a catch (Exception e):

https://github.com/apache/incubator-wayang/blob/31b5a295186f3d6d9ac3e0a18b2adf15b2304cc4/wayang-platforms/wayang-java/src/main/java/org/apache/wayang/java/operators/JavaTextFileSource.java#L98 

This is problematic because, if a user just passes the wrong path to a local file, the exception message they get a Java class cast error instead of a file-does-not-exist error.","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/477/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/482,https://api.github.com/repos/apache/incubator-wayang/issues/482,incubator-wayang,2658911133,482,Move JavaCSVTableSource operator from sql-api to the Java platform,zkaoudi,10105712,Zoi Kaoudi,,OPEN,2024-11-14T14:00:43Z,2024-11-14T14:30:19Z,"There is a Java csv source operator inside the wayang sql api:
[JavaCSVTableSource](https://github.com/apache/incubator-wayang/blob/main/wayang-api/wayang-api-sql/src/main/java/org/apache/wayang/api/sql/sources/fs/JavaCSVTableSource.java).

We should move it to the wayang-platforms/wayang-java module, specifically [here](https://github.com/apache/incubator-wayang/tree/main/wayang-platforms/wayang-java/src/main/java/org/apache/wayang/java/operators) and rename it to JavaCSVFileSource because it is reading from a file and not a table in the database.","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/482/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/482,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6Tm5I9,incubator-wayang,2476446269,482,NA,kbeedkar,8502905,Kaustubh Beedkar,,NA,2024-11-14T14:07:54Z,2024-11-14T14:07:54Z,"Makes sense, the reason to call it JavaCSVTableSource was that it expects the csv file to adhere to a certain format. Specifically, comma separated colname:type header row. This is required to create an appropriate schema to query against.","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6Tm5I9/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/493,https://api.github.com/repos/apache/incubator-wayang/issues/493,incubator-wayang,2807941796,493,NOTICE file does not need to paste in the Apache license,pjfanning,11783444,PJ Fanning,,CLOSED,2025-01-23T21:24:53Z,2025-02-05T13:38:04Z,"https://github.com/apache/incubator-wayang/blob/main/NOTICE#L13

The copyright is enough - `Copyright 2016 Sebastian Kruse`

Something like

```
Some of the files under
wayang-commons/wayang-utils-profile-db/src/main/java/org/apache/wayang/commons/util/profiledb
are licensed under the Apache License, Version 2.0.
Copyright 2016 Sebastian Kruse
```

Please also add 2025 to the Apache copyright at top of the NOTICE.","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/493/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/494,https://api.github.com/repos/apache/incubator-wayang/issues/494,incubator-wayang,2807950013,494,add 2025 to Apache copyright on Wayang website,pjfanning,11783444,PJ Fanning,,OPEN,2025-01-23T21:28:02Z,2025-01-23T21:28:02Z,"* https://github.com/apache/incubator-wayang-website/
* https://wayang.apache.org/","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/494/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/495,https://api.github.com/repos/apache/incubator-wayang/issues/495,incubator-wayang,2808017201,495,wayang jars should have META-INF LICENSE and NOTICE,pjfanning,11783444,PJ Fanning,,OPEN,2025-01-23T22:04:31Z,2025-02-05T12:16:50Z,"Apache License and mention any 3rd party source like profiledb source.

Example missing them:
https://repository.apache.org/content/repositories/orgapachewayang-1021/org/apache/wayang/wayang-core/1.0.0/
wayang-core jar","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/495/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/495,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6dJozP,incubator-wayang,2636549327,495,NA,pjfanning,11783444,PJ Fanning,,NA,2025-02-05T12:06:55Z,2025-02-05T12:06:55Z,@zkaoudi this is a release blocker for me,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6dJozP/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-wayang/issues/495,https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6dJuQh,incubator-wayang,2636571681,495,NA,zkaoudi,10105712,Zoi Kaoudi,,NA,2025-02-05T12:16:49Z,2025-02-05T12:16:49Z,I managed to fix that in the release branch. ,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/comments/IC_kwDOEzEL1M6dJuQh/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/498,https://api.github.com/repos/apache/incubator-wayang/issues/498,incubator-wayang,2826856257,498,Update zio http to a released version,zkaoudi,10105712,Zoi Kaoudi,,OPEN,2025-02-03T09:05:30Z,2025-02-03T09:05:30Z,There is a dependency in the wayang-api/wayang-api-json/pom.xml to 3.0.0-RC5. We should update that to the latest 3.0.1,"{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/498/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/501,https://api.github.com/repos/apache/incubator-wayang/issues/501,incubator-wayang,2835163581,501,Minor edits in LICENSE/NOTICE files,zkaoudi,10105712,Zoi Kaoudi,,OPEN,2025-02-06T10:42:09Z,2025-02-06T10:42:09Z,"- The LICENSE in the source distribution should mention that
Unsigned16 and Random16 are copied from Hadoop (in wayang-benchmark).
- apache-wayang-utils-profile-db-1.0.0-incubating.jar META-INF/LICENSE
and META-INF/NOTICE should mention code copied from profiledb. The
other jars are OK
","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/501/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-wayang/issues/502,https://api.github.com/repos/apache/incubator-wayang/issues/502,incubator-wayang,2835164795,502,Binary files in source distribution,zkaoudi,10105712,Zoi Kaoudi,,OPEN,2025-02-06T10:42:40Z,2025-02-06T10:42:40Z,"- Some binary files are present in the source distribution (images in
the wayang-doc)
","{""url"": ""https://api.github.com/repos/apache/incubator-wayang/issues/502/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
