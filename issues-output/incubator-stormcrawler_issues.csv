type,issue_url,comment_url,repo_name,id,issue_num,title,user_login,user_id,user_name,user_email,issue_state,created_at,updated_at,body,reactions
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1,incubator-stormcrawler,15728933,1,Apache Tika & Storm = FileNotFoundException,tammomueller,2523111,Tammo,,CLOSED,2013-06-19T06:17:01Z,2016-03-16T12:30:04Z,"Hi,

I am unable to run in LocalCluster mode (actually haven't tried to deploy this).
I am always getting a FileNotFoundException. Can you actually run this code without any issues?

4518 [Thread-10] INFO  backtype.storm.daemon.supervisor - Copying resources at jar:file:/Users/tammomueller/.m2/repository/edu/ucar/netcdf/4.2-min/netcdf-4.2-min.jar!/resources to /var/folders/wj/bplcpvpd07s525n5vnfm0gyw0000gn/T//cc4ea00d-14a5-41b6-8178-7bb2a2f8da46/supervisor/stormdist/crawl-1-1371622362/resources
4524 [Thread-10] ERROR backtype.storm.event - Error when processing event
java.io.FileNotFoundException: Source 'file:/Users/tammomueller/.m2/repository/edu/ucar/netcdf/4.2-min/netcdf-4.2-min.jar!/resources' does not exist
    at org.apache.commons.io.FileUtils.copyDirectory(FileUtils.java:1368) ~[commons-io-2.4.jar:2.4]
    at org.apache.commons.io.FileUtils.copyDirectory(FileUtils.java:1261) ~[commons-io-2.4.jar:2.4]
    at org.apache.commons.io.FileUtils.copyDirectory(FileUtils.java:1230) ~[commons-io-2.4.jar:2.4]
    at backtype.storm.daemon.supervisor$fn__5073.invoke(supervisor.clj:452) ~[storm-core-0.9.0-wip17.jar:na]
    at clojure.lang.MultiFn.invoke(MultiFn.java:172) ~[clojure-1.4.0.jar:na]
    at backtype.storm.daemon.supervisor$mk_synchronize_supervisor$this__4986.invoke(supervisor.clj:290) ~[storm-core-0.9.0-wip17.jar:na]

Same issue reported on storm and Tika:
https://github.com/nathanmarz/storm/issues/82
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE5NjY5MTE5,incubator-stormcrawler,19669119,1,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2013-06-19T08:19:40Z,2013-06-19T08:19:40Z,"I can run it fine from Eclipse 

5092 [Thread-5] INFO  backtype.storm.daemon.supervisor - Extracting resources from jar at /home/pebble/.m2/repository/edu/ucar/netcdf/4.2-min/netcdf-4.2-min.jar to /tmp/66664fdc-dce0-4289-8ecf-7af09c135a8a/supervisor/stormdist/crawl-1-1371629861/resources

Maybe try and call : 'mvn clean install' from the command line? It looks like a Maven related issue
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE5NjY5MTE5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE5ODAzODYw,incubator-stormcrawler,19803860,1,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2013-06-21T08:27:13Z,2013-06-21T08:27:13Z,"I ran the topology on a distributed cluster without any issues. Can you confirm that you are still having the same problem?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE5ODAzODYw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE5ODE4NjA0,incubator-stormcrawler,19818604,1,NA,tammomueller,2523111,Tammo,,NA,2013-06-21T14:21:12Z,2013-06-21T14:21:12Z,"I can run it through eclipse, but not maven command line. Haven't deployed it yet, but will update this thread once it's done.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE5ODE4NjA0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE5ODIxMDMy,incubator-stormcrawler,19821032,1,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2013-06-21T15:00:02Z,2013-06-21T15:00:02Z,"How do you call Maven? I use Maven to build the jars but I haven't tried running the code with it. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE5ODIxMDMy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE5ODI2MjI0,incubator-stormcrawler,19826224,1,NA,tammomueller,2523111,Tammo,,NA,2013-06-21T16:30:08Z,2013-06-21T16:30:08Z,"mvn compile exec:java -Dexec.classpathScope=compile -Dexec.mainClass=com.digitalpebble.storm.crawler.CrawlTopology

See:
https://github.com/nathanmarz/storm-starter#maven
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE5ODI2MjI0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE5ODU2ODcz,incubator-stormcrawler,19856873,1,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2013-06-22T13:34:10Z,2013-06-22T13:34:10Z,"I can reproduce the issue but it is not really specific to this project but pertaining more to Storm and/or Maven. As a workaround you can call it from the command line by specifying the storm jars as well as the uber one generated with mvn or run the code from Eclipse. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE5ODU2ODcz/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/9,https://api.github.com/repos/apache/incubator-stormcrawler/issues/9,incubator-stormcrawler,42229379,9,Possible bug in getHashForURL method of ShardedQueue,jakekdodd,6845693,Jake K. Dodd,,CLOSED,2014-09-08T18:46:52Z,2014-09-08T20:52:27Z,"I think that the statement:

``` java
return (ip.hashCode() & Integer.MAX_VALUE) % queueNumber
```

in the `getHashForURL` method of `com.digitalpebble.storm.fetchqueue.ShardedQueue` should instead be:

``` java
return (ip.hashCode() & Integer.MAX_VALUE) % numQueues
```

where `numQueues` is the `ShardedQueue.numQueues` property. From my reading of the code, I'm assuming that `getHashForURL` ought to return the `queueNumber` for the URL for sharing, rather than requiring it as an input.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/9/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/9,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU0ODg1MzEz,incubator-stormcrawler,54885313,9,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2014-09-08T20:52:27Z,2014-09-08T20:52:27Z,"Yes, it makes sense and is probably what I had in mind but chose a bad name for the variable. Have now committed this, thanks!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU0ODg1MzEz/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/10,https://api.github.com/repos/apache/incubator-stormcrawler/issues/10,incubator-stormcrawler,42342476,10,nextTuple() blocks in the BlockingURLSpout,jakekdodd,6845693,Jake K. Dodd,,CLOSED,2014-09-09T19:39:19Z,2014-09-12T14:59:10Z,"The topmost infinite loop in BlockingURLSpout causes the `nextTuple()` method to block. Because Storm runs `nextTuple()`, `ack()`, and `fail()` on the same thread, I think this prevents the spout from functioning properly (see last paragraph of the interface description in https://storm.incubator.apache.org/apidocs/backtype/storm/spout/ISpout.html).

I've got a version that removes the infinite loop and seems to function as expected, but I need to run a few more tests first. In the meantime, if you get a chance to take a chance to look at BlockingURLSpout, let me know if you agree that this is an issue.  
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/10/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/10,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1MDg5MTcy,incubator-stormcrawler,55089172,10,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2014-09-10T09:08:14Z,2014-09-10T09:08:14Z,"Yes, you are completely right. This class has not been used much as I now tend to use a spout for a specific source (like RabbitMQ) with as many instances as there are partitions and leveraging topology.max.spout.pending instead of maxLiveURLsPerQueue.
I've fixed this in :
[master d73b6bb] issue #10 : nextTuple() blocks in the BlockingURLSpout

Could you please give it a try?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1MDg5MTcy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/10,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1MTE3MDk0,incubator-stormcrawler,55117094,10,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2014-09-10T13:48:23Z,2014-09-10T13:48:23Z,"Yep absolutely, I'll take a look and let you know how it goes! I'm doing something similar right now with Redis, and I'm considering a partitioned Kafka topic as a potentially better solution. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1MTE3MDk0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/10,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1MTE3Njgw,incubator-stormcrawler,55117680,10,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2014-09-10T13:52:33Z,2014-09-10T13:52:33Z,"I haven't used Kafka yet but from what I've see it would be quite a natural fit.
BTW do you index the documents and if so, what with?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1MTE3Njgw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/10,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1MTIxNDMw,incubator-stormcrawler,55121430,10,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2014-09-10T14:18:12Z,2014-09-10T14:18:12Z,"Kafka is great, I definitely recommend giving it a try. It works especially well when combined with message serialization with something like Avro.

As for indexing, right now we're just dumping the URL, title, and parsed content into Elasticsearch. The plan is to also store metadata and the raw content in HBase. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1MTIxNDMw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/10,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1MTMzMTM4,incubator-stormcrawler,55133138,10,NA,kkrugler,66217,Ken Krugler,ken@transpac.com,NA,2014-09-10T15:30:39Z,2014-09-10T15:30:39Z,"I like Kafka (and Avro too). In fact I like Kafka so much I got sidetracked on looking into Samza (http://samza.incubator.apache.org/) as a potential option (vs. Storm), so that I could re-use my Hadoop 2 cluster for crawling.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1MTMzMTM4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/10,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1MTM2MDIz,incubator-stormcrawler,55136023,10,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2014-09-10T15:48:48Z,2014-09-10T15:48:48Z,"Hi Ken

And what's your verdict re-Storm vs Samza? I was under the impression that
Storm had more momentum as a community.
Didn't I read somewhere that Storm would be able to run on YARN at some
point? There was https://github.com/yahoo/storm-yarn but it seems to have
stalled.

J.

On 10 September 2014 16:30, Ken Krugler notifications@github.com wrote:

> I like Kafka (and Avro too). In fact I like Kafka so much I got
> sidetracked on looking into Samza (http://samza.incubator.apache.org/) as
> a potential option (vs. Storm), so that I could re-use my Hadoop 2 cluster
> for crawling.
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/DigitalPebble/storm-crawler/issues/10#issuecomment-55133138
> .

## 
- Open Source Solutions for Text Engineering   http://www.digitalpebble.com
  http://www.digitalpebble.com*
  _http://digitalpebble.blogspot.com http://digitalpebble.blogspot.com/_
  https://twitter.com/digitalpebble
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1MTM2MDIz/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/10,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1MTM3OTAw,incubator-stormcrawler,55137900,10,NA,kkrugler,66217,Ken Krugler,ken@transpac.com,NA,2014-09-10T16:00:26Z,2014-09-10T16:00:26Z,"I haven't reached a verdict yet :) I like some aspects of Storm better (e.g. having a field-oriented Tuple format makes some things easier). Storm started soon, and thus has greater adoption. But not having to maintain a separate infrastructure is a beautiful thing. As you note, the storm-yarn project seems to have stalled out. So net-net...not sure yet.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1MTM3OTAw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/10,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1MTM4OTU4,incubator-stormcrawler,55138958,10,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2014-09-10T16:06:38Z,2014-09-10T16:06:38Z,"I'm also curious to hear your opinion on Samza. I'm aware that it exists, but not of much else beyond that. Didn't realize it was so closely integrated with Kafka until now.

Julien, regarding Storm-on-YARN, you might find [this](http://hortonworks.com/labs/storm/) interesting. Hortonworks HDP 2.1 ships with Storm, although not on YARN, and the next phase is a Storm-on-YARN implementation. Not certain, but I remember reading at some point that Hortonworks was partnering with Yahoo! for that.

Although to be honest, I'm not sure that I see the benefit of a YARN-based Storm, other than the possible benefits of Hadoop's security policies. It's already perfectly feasible to run Storm alongside Hadoop on a cluster
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1MTM4OTU4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/10,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1NDEyMTQ3,incubator-stormcrawler,55412147,10,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2014-09-12T14:39:07Z,2014-09-12T14:39:07Z,"@jakekdodd can this issue be closed?

Don't know if you noticed but I released 0.1 yesterday and it is now available in Maven Central. Should make it easier to extend it from your project.

Shall we continue the discussion on [http://groups.google.com/group/digitalpebble]? There are quite a few things we can discuss there instead of doing so in the issues ;-) 

Thanks

Julien
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1NDEyMTQ3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/10,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1NDE1MDEy,incubator-stormcrawler,55415012,10,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2014-09-12T14:59:09Z,2014-09-12T14:59:09Z,"Yup! See you on the google group.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1NDE1MDEy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/16,https://api.github.com/repos/apache/incubator-stormcrawler/issues/16,incubator-stormcrawler,46737886,16,Make protocol defined via configuration,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2014-10-24T13:23:41Z,2014-10-31T13:04:16Z,"[https://github.com/DigitalPebble/storm-crawler/blob/master/src/main/java/com/digitalpebble/storm/crawler/protocol/ProtocolFactory.java] currently hardcodes the protocol implementation to use. We need to make it configurable like we do for URL filters etc...
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/16/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/16,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU2ODI1,incubator-stormcrawler,61256825,16,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2014-10-31T13:04:16Z,2014-10-31T13:04:16Z,"[https://github.com/DigitalPebble/storm-crawler/commit/e9c0966a4b23e4c10e4c0aaa7b57d77ffd32a8df]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMjU2ODI1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/23,https://api.github.com/repos/apache/incubator-stormcrawler/issues/23,incubator-stormcrawler,48692603,23,Replace HTTP protocol implementation,jakekdodd,6845693,Jake K. Dodd,,CLOSED,2014-11-13T21:13:34Z,2015-04-22T10:41:13Z,"Before I did anything with this, wanted to check and see if there was a reason why HTTP 1.0 was hardcoded. Right now, line 167 of HttpResponse sets the protocol version to 1.0, regardless of whether `http.useHttp11: true` is set in the configuration:

``` java
StringBuffer reqStr = new StringBuffer(""GET "");
            if (http.useProxy()) {
                reqStr.append(url.getProtocol() + ""://"" + host + portString
                        + path);
            } else {
                reqStr.append(path);
            }

            reqStr.append("" HTTP/1.0\r\n"");
```

Is this intentional?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/23/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/23,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMDI4NTIw,incubator-stormcrawler,63028520,23,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2014-11-14T09:20:24Z,2014-11-14T09:20:24Z,"Not really. As you probably noticed, the code for the protocol is a port from the Nutch equivalent. It's just that  I forgot to do that. Not sure that the protocol implementation does anything about the features of 1.1 [http://www8.org/w8-papers/5c-protocols/key/key.html] anyway. 

Ideally we should replace this low level stuff by an external library like [http://hc.apache.org/] if possible. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMDI4NTIw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/23,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMDcxNTgw,incubator-stormcrawler,63071580,23,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2014-11-14T14:31:25Z,2014-11-14T14:31:25Z,"Looks like HttpResponse has a mechanism for handling chunked Transfer-Encoding, which is in HTTP/1.1. I didn't read through the whole class, so it's possible there are a few other things from HTTP/1.1 in there.

I'll try this out with 1.1 enabled, and see if everything works as expected. The fact that this is still hardcoded in Nutch's protocol-http plugin, and only protocol-httpclient works with 1.1,  makes me wonder if something breaks with 1.1 enabled.

And +1 for using an external library. Nutch's protocol-httpclient looks like a good starting point
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMDcxNTgw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/23,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMDcyNDMy,incubator-stormcrawler,63072432,23,NA,kkrugler,66217,Ken Krugler,ken@transpac.com,NA,2014-11-14T14:37:40Z,2014-11-14T14:37:40Z,"There was a not-complete stab at creating an HTTP fetcher in crawler-commons that I started while ago. And I think that Oleg did some work in the Droids project to create a few custom HttpClient classes that would make it more resilient to broken response headers and such, IIRC.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMDcyNDMy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/23,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMDcyODE0,incubator-stormcrawler,63072814,23,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2014-11-14T14:40:15Z,2014-11-14T14:40:15Z,"@jakekdodd Nutch's protocol-httpclient is not very reliable and uses a deprecated version of the API. Better to start from a clean slate I think.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMDcyODE0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/23,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMDc2ODg1,incubator-stormcrawler,63076885,23,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2014-11-14T15:08:34Z,2014-11-14T15:08:34Z,"@jnioche huh, good to know. The [google-http-java-client](https://code.google.com/p/google-http-java-client/) is another one we might want to examine. I haven't used it personally, but it utilizes Apache HttpClient, and Google's stuff tends to work pretty well. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMDc2ODg1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/23,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkwOTQzMDA1,incubator-stormcrawler,90943005,23,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-04-08T15:02:50Z,2015-04-08T15:02:50Z,"I've made good progress on a HTTP implementation based on  [http://hc.apache.org/]. Will commit post 0.5 release
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkwOTQzMDA1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/24,https://api.github.com/repos/apache/incubator-stormcrawler/issues/24,incubator-stormcrawler,48767625,24,RobotsURLFilter,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2014-11-14T10:19:44Z,2015-08-27T09:21:03Z,"The filtering of URLs based on the robots.txt directives is done within the Fetcher for an incoming URL. It would be efficient to be able to filter on the outlinks so that URLs do not get added to the queues  (or any other form of persistence) if they can't be fetched anyway.

We should provide a RobotsURLFilter for this where we'd refetch the robots.txt file for a given URL and store it in a cache. The additional cost of pulling the robots.txt would be outweighed by the benefits of not adding unnecessary URLs to the queues. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/24/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/24,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3MjMxMzA1,incubator-stormcrawler,67231305,24,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2014-12-16T21:02:39Z,2014-12-16T21:02:39Z,"I'm working on this now; a few observations:
- We could potentially avoid fetching the rules a second time if they can be serialized and included in the metadata
- If we need to fetch and parse the rules a second time, it should happen outside of the filter itself. Making an HTTP request within the filter would lead to non-deterministic performance when filtering, which seems like a pain.

Have you started this? If not, I'll give it a go. It looks to me like the easiest approach, until we have more sophisticated metadata serialization, would be to include the raw text of the robots.txt file in the metadata and re-parse before filtering. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3MjMxMzA1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/24,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3MjM5ODMw,incubator-stormcrawler,67239830,24,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2014-12-16T21:57:13Z,2014-12-16T21:57:13Z,"I haven't started on this. Your approach makes complete sense, the way I was thinking about this was that we'd need re-fetching and parsing only once per hostname since the subsequent URLs would be in the cache so it would note be a big deal + there would be cases where we'd get links to external sites for which we wouldn't necessarily have fetched the robots already. I was also concerned about bloating the metadata too much or introducing changes into other components.

One way around the issue of fetching + parsing once when filtering would be to have the robots info stored in an external cache (Redis?) within a bespoke protocol implementation and connect to the same cache within the filter. Makes the whole thing more complex. I'd be tempted to stick to the simplest scenario for now and just refetch + parse, knowing that in practice it probably won't affect the performance very much and for cases where it does a more complex approach could be used.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3MjM5ODMw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/24,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3MjQ2Nzc0,incubator-stormcrawler,67246774,24,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2014-12-16T22:42:30Z,2014-12-16T22:42:30Z,">  there would be cases where we'd get links to external sites

I couldn't think of a solution to that issue, we'll probably need to limit the robots filtering to outlinks with the same hostname as the source page.

> I was also concerned about bloating the metadata too much

Me too--have you seen cases of huge robots.txt files? One way to limit the bloat would be to remove robots.txt from the metadata after filtering, so it's only carried in the tuple that travels between the fetcher and parser. 

I like the idea of using an external cache, but that would be a burdensome requirement and barrier to entry for people wanting to use SC. What if we abstract the cache implementation within `RobotRulesParser`? This would enable users to plug in their own caching system. We could include a default cache that would have no outside dependencies.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3MjQ2Nzc0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/24,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3MzUxOTM1,incubator-stormcrawler,67351935,24,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2014-12-17T16:45:32Z,2014-12-17T16:45:32Z,"> Me too--have you seen cases of huge robots.txt files? 

Is that huge [http://www.amazon.com/robots.txt]? We could at least keep only the part relevant to the user-agent

> One way to limit the bloat would be to remove robots.txt from the metadata after filtering, so it's only carried in the tuple that travels between the fetcher and parser.

hmm, that's more assumptions that we'd need to make explicit. 

> What if we abstract the cache implementation within RobotRulesParser? This would enable users to plug in their own caching system. We could include a default cache that would have no outside dependencies.

good idea

One thing though is that the filters are currently used within the parsing step but there is no reason why people could not use them somewhere else e.g. in a spout. In that case we wouldn't be able to leverage the metadata at all. 

I'd be tempted to have a basic implementation doing an extra fetch+parse->cache and add an optimisation that would look in the metadata in case there is something interesting there.

This filter is just an idea I had and is not super high on my priority list, what I wouldn't want is to make other components more complex than necessary because of it. Of course if we can make other parts better / more generic then great!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3MzUxOTM1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/24,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3MzUyODk4,incubator-stormcrawler,67352898,24,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2014-12-17T16:51:10Z,2014-12-17T16:51:10Z,"Check out #40 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3MzUyODk4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/24,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTM2MDEyMQ==,incubator-stormcrawler,135360121,24,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-08-27T09:20:56Z,2015-08-27T09:20:56Z,"Have implemented the simple version I originally had in mind. See #178
We can of course add a more sophisticated one based on the discussions we had here later on; for now this does exactly the job for small vertical crawls.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTM2MDEyMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/25,https://api.github.com/repos/apache/incubator-stormcrawler/issues/25,incubator-stormcrawler,48768125,25,Protocol interface to take metadata into account,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2014-11-14T10:23:55Z,2014-12-04T09:44:12Z,"Ideally we should be able to access the metadata for a URL from the protocol implementations. One motivation for this is that we could use different resources (e.g. scripts for processing AJAX) based on the value of a metadatum.

What would be the best way of doing this? add a separate method? if so would what would the FetcherBolt do? Replace the existing method with the one handling metadata? This way if a protocol implementation does not need the metadata it could simply ignore them.

Any thoughts on this?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/25/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/25,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMTk4Nzg2,incubator-stormcrawler,63198786,25,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2014-11-16T00:20:13Z,2014-11-16T00:20:13Z,"Maybe make make `ProtocolFactory.getProtocol()` a variadic method, so that in the fetcher bolt `protocolFactory.getProtocol(u)` would become `protocolFactory.getProtocol(u, metadata)` if metadata is present? Alternatively, the metadata could be added as an argument to `protocol.getProtocolOutput()`. I guess it depends on whether the metadata would be needed in setting up the protocol (in which case it would be needed by the factory), or just when generating the request. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMTk4Nzg2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/25,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1NTc4MzI2,incubator-stormcrawler,65578326,25,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2014-12-04T09:44:12Z,2014-12-04T09:44:12Z,"Implemented by [https://github.com/DigitalPebble/storm-crawler/commit/bade3806c2db8a0592cdd8c4acb4c5c027f80a68]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1NTc4MzI2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/29,https://api.github.com/repos/apache/incubator-stormcrawler/issues/29,incubator-stormcrawler,49149849,29,Update <developers> section of pom.xml,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2014-11-17T21:48:21Z,2014-11-17T23:22:57Z,"Jake, could you add yourself to the pom?
Thanks!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/29/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/29,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMzk1OTAw,incubator-stormcrawler,63395900,29,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2014-11-17T23:22:57Z,2014-11-17T23:22:57Z,"Done!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMzk1OTAw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/31,https://api.github.com/repos/apache/incubator-stormcrawler/issues/31,incubator-stormcrawler,50523608,31,Xpath expressions don't match when element name is set,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2014-12-01T13:27:27Z,2015-01-15T09:41:35Z,"As shown in the test [https://github.com/DigitalPebble/storm-crawler/commit/7cf89baec8297fc4e725d6d06be5f1145d6194c1], the XPathFilter does not extract the data when an element name is specified. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/31/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/31,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMDM4OTA2,incubator-stormcrawler,70038906,31,NA,GuiForget,2585258,Gui Forget,,NA,2015-01-15T04:36:25Z,2015-01-15T04:36:25Z,"This test passes when I use the JSoupParserBolt... So seems like another Tika Parser issue... I'll try to dig into it
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMDM4OTA2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/32,https://api.github.com/repos/apache/incubator-stormcrawler/issues/32,incubator-stormcrawler,50973827,32,Add handling of cookies to HTTP protocol,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2014-12-04T13:15:55Z,2017-04-09T14:21:14Z,"The cookies info could be stored in the metadata (and inherited from the parent URL) and used by the Protocol implementation.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/32/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/32,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NDQwODQ1Mw==,incubator-stormcrawler,284408453,32,NA,foromer4,10501096,Omer Schleifer,foromer4@gmail.com,NA,2017-03-06T14:20:55Z,2017-03-06T14:20:55Z,"I would like to implement this. @jnioche, could you please add some info on what classes should be changed to save and read these stored cookies? 
from what I can tell. JSoupParserBolt might be the place to detect cookies.
However, I'm not sure how to do it only once for each website?
Does Storm crawler keep info to connect each url to a specific parent url?
ANd does it store infromation for the parent url?
thanks","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NDQwODQ1Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/32,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NDQzODYzNQ==,incubator-stormcrawler,284438635,32,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-06T15:56:41Z,2017-03-06T15:56:41Z,"Here is how I see it. You should only need to modify things at the protocol level. Basically, the cookies are stored as text in the metadata of the parent URL, transferred to the outlinks which get persisted to the status in the usual ways, see https://github.com/DigitalPebble/storm-crawler/wiki/MetadataTransfer. 

When the tuple for an outlink is sent down the topology, we'll need to convert the info from the metadata into cookies in the [getProtocolOutput() method](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/protocol/httpclient/HttpProtocol.java#L124) so that the low level protocol stuff sends it.

> from what I can tell. JSoupParserBolt might be the place to detect cookies.

Nope. Cookies are nothing more than http headers with an attitude.

> However, I'm not sure how to do it only once for each website?

We don't. We could have different cookies information for different URLs belonging to the same host or domain.

> Does Storm crawler keep info to connect each url to a specific parent url? 

Part of the optional path info in the metadatam see Wiki page about MetadataTransfer

> ANd does it store information for the parent url?

Like any other URL, nothing more.

Hope this helps

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NDQzODYzNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/32,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NTM3NjU2Mg==,incubator-stormcrawler,285376562,32,NA,foromer4,10501096,Omer Schleifer,foromer4@gmail.com,NA,2017-03-09T15:06:20Z,2017-03-09T15:06:20Z,"@jnioche , So you want the crawler to visit a ceratin page and collect from the response the cookies, and then use the same cookies for discovered links? and if it find other cookies in the discovered links add them also to their ""child links"" and so on?

Might it be beneficial to set the desired cookies once per site , or per regex in the config, instead of passing them from parent to child? ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NTM3NjU2Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/32,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NTQxMTQyNA==,incubator-stormcrawler,285411424,32,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-09T16:57:11Z,2017-03-09T16:57:11Z,"> if it find other cookies in the discovered links add them also to their ""child links"" and so on?

they would replace the existing ones instead of adding to them I think

> Might it be beneficial to set the desired cookies once per site , 

there is no global repository for sites info in SC

> or per regex in the config, instead of passing them from parent to child?

you could set them as seed metadata instead of keeping them in the config and have an option in the protocol implementation to NOT replace an existing value. This would be more flexible I think as you could modify it on the fly instead of relaunching the topology

which problem are you trying to solve or to put it differently, any reason you think my suggestion is a bad idea? 

Thanks
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NTQxMTQyNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/32,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NTkyOTY1Mw==,incubator-stormcrawler,285929653,32,NA,foromer4,10501096,Omer Schleifer,foromer4@gmail.com,NA,2017-03-12T08:17:46Z,2017-03-12T08:17:46Z,"Well I definitely see the value of passing cookie from url to discovered link - and will start working on this as you suggested. In addition,  I can think of some cases where you would want to set up specific cookies in advance (for example session cookies ,as login is hard to do sometimes in a crawler)","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NTkyOTY1Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/32,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NTk0NDM4OA==,incubator-stormcrawler,285944388,32,NA,foromer4,10501096,Omer Schleifer,foromer4@gmail.com,NA,2017-03-12T13:25:16Z,2017-03-12T13:25:16Z,"@jnioche  , I started looking at the solution you suggested and ran into an issue.
It seems that in order to get the cookies I need to add a cookie store to the [httpClinet](http://stackoverflow.com/questions/8733758/how-can-i-get-the-cookies-from-httpclient).

Now the problem as I see it is that in order to get the cookies, I need to make the HttpClient a member of [HttpProtocol](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/protocol/httpclient/HttpProtocol.java), and since HttpProtocol itself is being reused over and over again (stored in a cache , provided by [ProtocolFactory](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/protocol/ProtocolFactory.java)) it will be a problem.

Possible solution:
Add flag for ""useCookies"" , when this flag in on, ProtocolFactory will return a new instance per request.
Of course it might incur a performance penalty (hence the flag).
Please let me know if this seems right to you.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NTk0NDM4OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/32,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NjA3MTgxMw==,incubator-stormcrawler,286071813,32,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-13T10:39:30Z,2017-03-13T10:39:30Z,"Hi @foromer4 

You don't need a cookie store. The advantage of passing it as metadata is that we don't expect the protocol instance to persist anything or have any prerequisites. The cookies (if any) can simply be added to the header like this\:

```
    List<Cookie> cookies = CookieConverter.getCookies(datum, url);

    for (Cookie c : cookies)
      httpget.setHeader(""Cookie"", c.getName() + ""="" + c.getValue());
```

as for the CookieConverter.getCookies method, it simply populates a list of BasicClientCookie instances from the metadata key values.

There should be nothing special to do on receiving the cookies, as I said, they are just normal HTTP response metadata.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NjA3MTgxMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/32,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NjEwOTAxNw==,incubator-stormcrawler,286109017,32,NA,foromer4,10501096,Omer Schleifer,foromer4@gmail.com,NA,2017-03-13T13:38:42Z,2017-03-13T13:38:42Z,"Hi @jnioche, sorry for being difficult, I just want to make sure I understand.
If you do not want to persist the cookies, only to use the cookies in the http headers of the response as the cookies to the output link, why can't we use the exiting MetaData field of `_response_headers` as it is already saved in [HttpProtocol.handleResponse](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/protocol/httpclient/HttpProtocol.java#L202)?

We can than use [MetadataTransfer.getMetaForOutlink ](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/protocol/httpclient/HttpProtocol.java#L124) as you suggested to set the cookie to the output link.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NjEwOTAxNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/32,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NjEzMDY2MA==,incubator-stormcrawler,286130660,32,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-13T14:52:08Z,2017-03-13T14:52:08Z,"> Hi @jnioche, sorry for being difficult, I just want to make sure I understand.

don't worry you are not being difficult at all. 

> If you do not want to persist the cookies, only to use the cookies in the http headers of the response as the cookies to the output link, why can't we use the exiting MetaData field of _response_headers as it is already saved in HttpProtocol.handleResponse?

that field is optional and contains ALL the key/values returned by the server. It can get quite large and would not typically passed on to the outlinks. Also it you want to inject the cookie into on a per seed basis then having a separate key to do it would be cleaner. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NjEzMDY2MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/32,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NjEzNzg2MA==,incubator-stormcrawler,286137860,32,NA,foromer4,10501096,Omer Schleifer,foromer4@gmail.com,NA,2017-03-13T15:14:25Z,2017-03-13T15:14:25Z,"Thanks for clarifying, i will be back from vacation next week, and will do
it

On Mar 13, 2017 4:52 PM, ""Julien Nioche"" <notifications@github.com> wrote:

> Hi @jnioche <https://github.com/jnioche>, sorry for being difficult, I
> just want to make sure I understand.
>
> don't worry you are not being difficult at all.
>
> If you do not want to persist the cookies, only to use the cookies in the
> http headers of the response as the cookies to the output link, why can't
> we use the exiting MetaData field of _response_headers as it is already
> saved in HttpProtocol.handleResponse?
>
> that field is optional and contains ALL the key/values returned by the
> server. It can get quite large and would not typically passed on to the
> outlinks. Also it you want to inject the cookie into on a per seed basis
> then having a separate key to do it would be cleaner.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/DigitalPebble/storm-crawler/issues/32#issuecomment-286130660>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AKA76MTMQb1yVuX46R8vIiD8s1ohRM4Oks5rlVgagaJpZM4DEPfS>
> .
>
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NjEzNzg2MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/32,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NjQ5MDAzMQ==,incubator-stormcrawler,286490031,32,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-14T17:04:15Z,2017-03-14T17:04:15Z,"Here is some code which you could use as a starting point [https://gist.github.com/jnioche/6141308519694b5c57d4fbd45d5990ac]. It was written for Nutch but could easily be adapted to SC.

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NjQ5MDAzMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/32,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4OTI3ODg0Ng==,incubator-stormcrawler,289278846,32,NA,foromer4,10501096,Omer Schleifer,foromer4@gmail.com,NA,2017-03-26T12:05:05Z,2017-03-26T12:05:05Z,"I started implementing, and I have another question,
it seems the http headers are stored even if `storeHTTPHeaders` is false.
Inside the iterator, the verbatim only get values if this flag is true,
however the header itself is set in the metadata regardless.

see:
https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/protocol/httpclient/HttpProtocol.java#L188","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4OTI3ODg0Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/32,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4OTM5MTg2OA==,incubator-stormcrawler,289391868,32,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-27T08:49:45Z,2017-03-27T08:49:45Z,"Yes, that's normal. We do want to store the http headers in metadata. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4OTM5MTg2OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/32,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4OTczOTg4MA==,incubator-stormcrawler,289739880,32,NA,foromer4,10501096,Omer Schleifer,foromer4@gmail.com,NA,2017-03-28T11:24:24Z,2017-03-28T11:24:24Z,"Well , finally I believe I'm done, the code is based on your CookieConverter and includes some small fixes and unit tests to it. Before I do a pull request I would like to also test manually end-to-end on a site. Is there any ""debug sandbox"" I should use? or just run the crawler as described [here] and analyze the logs?(http://stormcrawler.net/getting-started/) ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4OTczOTg4MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/32,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4OTc1MDkyNQ==,incubator-stormcrawler,289750925,32,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-28T12:16:06Z,2017-03-28T12:16:06Z,"You can use the archetype to generate a basic config then either:
-  run the java topology from Eclipse in debug mode
- `export STORM_JAR_JVM_OPTS=""-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=localhost:8000""` then `storm jar ...` then remote debug from Eclipse","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4OTc1MDkyNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/32,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5MTQwMTA4OA==,incubator-stormcrawler,291401088,32,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-04-04T05:57:53Z,2017-04-04T05:57:53Z,"Implemented in #449 

@foromer4 any chance you could open a PR to add a description of the config to the WIKI?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5MTQwMTA4OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/32,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5MTgyMzE3Mg==,incubator-stormcrawler,291823172,32,NA,foromer4,10501096,Omer Schleifer,foromer4@gmail.com,NA,2017-04-05T10:42:22Z,2017-04-05T10:42:22Z,"Sure , no problem. Since I don't have access to the main branch, and no way I can see to fork Wiki , what's the MO here?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5MTgyMzE3Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/32,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5MTgyNDI4OA==,incubator-stormcrawler,291824288,32,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-04-05T10:48:12Z,2017-04-05T10:48:12Z,"See https://gist.github.com/larrybotha/10650410
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5MTgyNDI4OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/32,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5Mjc2NzQwOQ==,incubator-stormcrawler,292767409,32,NA,foromer4,10501096,Omer Schleifer,foromer4@gmail.com,NA,2017-04-09T06:34:26Z,2017-04-09T06:34:26Z,"I don't see any way to get the wiki part from the fork. My fork doesn't have wiki in it, if I try to run: 
 

>  git clone https://github.com/foromer4/storm-crawler.wiki.git sc_wiki


I get this error:

> fatal: remote error: access denied or repository not exported: /c/nw/c7/cd/42/93
> 95761/86227349.wiki.git

And it I just clone the wiki, I can't push to master , for lack of permissions.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5Mjc2NzQwOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/32,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5Mjc4NzA1MQ==,incubator-stormcrawler,292787051,32,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-04-09T13:50:29Z,2017-04-09T13:50:29Z,"what about 
```
git clone https://github.com/DigitalPebble/storm-crawler.wiki.git  sc_wiki
cd sc_wiki
git remote add omer https://github.com/foromer4/storm-crawler.wiki.git
DO YOUR CHANGES
git commit -a -m ""message here""
git push -u omer master
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5Mjc4NzA1MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/32,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5Mjc4Nzk0OA==,incubator-stormcrawler,292787948,32,NA,foromer4,10501096,Omer Schleifer,foromer4@gmail.com,NA,2017-04-09T14:06:09Z,2017-04-09T14:06:09Z,"well . I still need to somehow create a fork of storm crawler wiki , which I can't , so doing as you suggested, trying to add a remote I get this error:

> git remote add omer https://github.com/foromer4/storm-crawler.wiki.git
> fatal: Not a git repository (or any of the parent directories): .git


Maybe I need to be able to push to master? or else, is there any way to make the wiki a part of the 
git repo , so that when I fork the repo I also get access to wiki pages? First time editing Wiki not on master , so sorry if I'm missing something obvious here...","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5Mjc4Nzk0OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/32,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5Mjc4ODc4MQ==,incubator-stormcrawler,292788781,32,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-04-09T14:21:14Z,2017-04-09T14:21:14Z,let's keep it simple. I've added you temporarily to a group which should allow you to write to the WIKI. Thanks!,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5Mjc4ODc4MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/33,https://api.github.com/repos/apache/incubator-stormcrawler/issues/33,incubator-stormcrawler,51195730,33,Add If-Modified-Since support to HTTP Protocol,jakekdodd,6845693,Jake K. Dodd,,CLOSED,2014-12-06T20:56:52Z,2014-12-12T16:29:04Z,"Now that the HTTP protocol has access to metadata, maybe we can add support for If-Modified-Since in HTTPResponse? This could significantly boost performance for URLs that are frequently processed by the crawler.

I have an implementation of this already (although not through the metadata). If this is desirable, it'll be a snap for me to contribute it.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/33/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/33,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY2MTg1MzA0,incubator-stormcrawler,66185304,33,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2014-12-08T20:54:25Z,2014-12-08T20:54:25Z,"good idea
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY2MTg1MzA0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/33,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY2NjMzMDk3,incubator-stormcrawler,66633097,33,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2014-12-11T15:16:37Z,2014-12-11T15:16:37Z,"How do you think we should document this as a feature of HTTPResponse? If we're going to be utilizing metadata to alter the behavior of the protocol and response, those behavior changes should be noted somewhere
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY2NjMzMDk3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/33,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY2NzUwMDM2,incubator-stormcrawler,66750036,33,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2014-12-12T09:30:22Z,2014-12-12T09:30:22Z,"We should have a wiki page on the protocol implementations and what is supported. The lack of documentation is one of our main issues at the moment. Any other suggestion?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY2NzUwMDM2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/33,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY2Nzk1MTc4,incubator-stormcrawler,66795178,33,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2014-12-12T16:21:42Z,2014-12-12T16:21:42Z,"Implemented in 0bbe3831fa22b8120db7847645feac70d6a9f2ef , along with some barebones documentation in the wiki
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY2Nzk1MTc4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/33,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY2Nzk2MzM2,incubator-stormcrawler,66796336,33,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2014-12-12T16:29:04Z,2014-12-12T16:29:04Z,"great thanks!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY2Nzk2MzM2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/34,https://api.github.com/repos/apache/incubator-stormcrawler/issues/34,incubator-stormcrawler,51195992,34,Upgrade to Storm 0.9.3,jakekdodd,6845693,Jake K. Dodd,,CLOSED,2014-12-06T21:05:15Z,2014-12-08T18:45:35Z,"There were several important issues resolved in 0.9.3, including one Tika-related fix. I'm currently running my SC topology on 0.9.3 without a hitch, so this should be a non-breaking upgrade.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/34/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/34,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY2MTY0MDYx,incubator-stormcrawler,66164061,34,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2014-12-08T18:45:35Z,2014-12-08T18:45:35Z,"Upgrade completed in d9d80187c7245094f58aecd364a6753c433d787c. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY2MTY0MDYx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/35,https://api.github.com/repos/apache/incubator-stormcrawler/issues/35,incubator-stormcrawler,51678490,35,Provide MetricsConsumer for storing storm metrics with ES,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2014-12-11T12:00:09Z,2015-02-25T15:24:54Z,"Not a core s-c issue but probably a nice feature to have. We already provide an ES bolt, so we already have the ES dependencies in. Would be good to send the metics to ES to disaply with Kibana without having to use logstash|statsd| etc...

See [https://github.com/elasticsearch/elasticsearch-hadoop/issues/325#issuecomment-66472035] for the same issue submitted to elasticsearch-hadoop
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/35/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/35,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc1OTc4OTQw,incubator-stormcrawler,75978940,35,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-02-25T15:23:06Z,2015-02-25T15:23:06Z,"Implemented in [8b6e5] then improved in [8c4a1885ad]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc1OTc4OTQw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/35,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc1OTc5NDU5,incubator-stormcrawler,75979459,35,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-02-25T15:24:54Z,2015-02-25T15:24:54Z,"ping @jakekdodd, just in case you missed it 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc1OTc5NDU5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/37,https://api.github.com/repos/apache/incubator-stormcrawler/issues/37,incubator-stormcrawler,51692619,37,Handling of redirections,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2014-12-11T14:29:34Z,2016-01-29T10:53:29Z,"The FetcherBolt nor the ParserBolt currently do anything specific with the HTTP status returned for a given page and as a result redirections are currently not handled.

One option would be to let whichever component is in charge of the persistence of the URL status i.e. post parsing. Another approach would be to have the parser (and maybe also the fetcher) declare a non-default output (e.g. 'status') and plug that as input to the persistence bolt. 

any thoughts on this? 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/37/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/37,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY2NjMyNjg5,incubator-stormcrawler,66632689,37,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2014-12-11T15:14:00Z,2014-12-11T15:14:00Z,"A couple of thoughts. First, we should give the option to handle redirects within the fetcher itself, and the ability to specify a max number of redirect attempts.

Second, I think that for many status codes, some applications built with SC will want to skip parsing altogether (403, 404, etc.). However I think that this should be an option, and not hardwired behavior.

Let's think about how we can use streams to implement this. Handling redirection within the Fetcher itself is the easiest part to implement--maybe we should do that first?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY2NjMyNjg5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/37,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY2NzQ5MTc2,incubator-stormcrawler,66749176,37,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2014-12-12T09:21:23Z,2014-12-12T09:21:23Z,"> redirects within the Fetcher 

do you meant put the redirected URLs straight into the internal queues? Could do that as an optional behaviour, I think this is the case in Nutch. 

> skipping parsing for non OK codes

let's do that with the status stream within the Fetcher
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY2NzQ5MTc2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/37,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY2Nzg1Nzcy,incubator-stormcrawler,66785772,37,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2014-12-12T15:20:35Z,2014-12-12T15:20:35Z,"> do you meant put the redirected URLs straight into the internal queues? Could do that as an optional behaviour, I think this is the case in Nutch.

Exactly

> let's do that with the status stream within the Fetcher

In the spirit of making these bolts easily extendable, maybe we could implement several event-handling methods that could be overridden in subclasses? For example there might be methods for `handleRedirect()`, `handleForbidden()`, `handleTimeout()`, etc. This would make it easy to emit to a non-default stream, or none at all, upon specific events
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY2Nzg1Nzcy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/37,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY4Njk2NjQ1,incubator-stormcrawler,68696645,37,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-05T11:29:34Z,2015-01-05T11:29:34Z,"Part of it is implemented in #44. Still need to implement case where redirected URLs are sent straight into the internal queues
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY4Njk2NjQ1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/37,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE3NjY5MTkxMw==,incubator-stormcrawler,176691913,37,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-01-29T10:53:29Z,2016-01-29T10:53:29Z,"Will close for now. Redirections can be handled within the protocol implementations if necessary. Better just to treat them with the default behaviour and go through the status stream anyway as the targets might already be known. Keeps the code simpler as well.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE3NjY5MTkxMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/38,https://api.github.com/repos/apache/incubator-stormcrawler/issues/38,incubator-stormcrawler,51693834,38,Sitemap parser,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2014-12-11T14:40:35Z,2015-01-07T12:18:00Z,"It would be good to reuse the parsers from [crawler-commons](https://code.google.com/p/crawler-commons/) to handle sitemaps. Probably simpler to have a separate parser from the Tika-based one and trigger the use of the Sitemap parser based on the presence of an arbitrary metadata like 'parse.sitemap'=true.

The triaging of the tuples based on the metadata could be done in a meta parser wrapping both the tika or sitemap one but probably simpler if that could be done somehow in the topology class. Alternatively the sitemap parser could also wrap the tika parser. 

The output of this parser would not be the same as the Tika based one as it would not generate any textual content or call the parsefilters but consists of URL,Metadata pairs.  Similarly to what I suggested for #37, this bolt could generate a 'status' stream that would be constumed by a persistence bolt. It would also use the default stream to pass on URLs that are not sitemaps.

Question : what happens if we send things down a stream with nothing to consume them?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/38/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/38,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3MjMzMTE2,incubator-stormcrawler,67233116,38,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2014-12-16T21:14:37Z,2014-12-16T21:14:37Z,"What if we create a Tika parser for sitemaps using CC? I'm sure the Tika guys would be happy to have it. We'd have to create a new content type detector, too.

> Question : what happens if we send things down a stream with nothing to consume them?

Nothing, Storm handles it just fine! When a topology is started, Storm builds a DAG of the topology (or something of the sort; I'm not sure of the specifics, but I do know that Storm detects if a bolt subscribes to a non-existent stream and throws an error when the topology is started). So, the tuple-tracking algorithm knows not to wait for an emitted tuple that won't be consumed.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3MjMzMTE2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/38,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3MjM4NDE1,incubator-stormcrawler,67238415,38,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2014-12-16T21:48:22Z,2014-12-16T21:48:22Z,"sitemaps can be in various formats (txt, xml, zipped or not etc...) so there isn't a single mime-type to represent them. Tika will give us the underlying mime-type but can't be of much use for parsing the sitemaps. It is used within CC to handle the underlying mimetypes
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3MjM4NDE1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/38,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3MjQyNTMx,incubator-stormcrawler,67242531,38,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2014-12-16T22:14:14Z,2014-12-16T22:14:14Z,"> sitemaps can be in various formats (txt, xml, zipped or not etc...)

Yeah plain text sitemaps would be an issue. I was thinking of sitemaps that conform for the sitemap.org protocol, in which case a Tika parser which subclasses `XMLParser` could handle it (this is already done with the [Dublin Core XML parser](https://github.com/apache/tika/blob/trunk/tika-parsers/src/main/java/org/apache/tika/parser/xml/DcXMLParser.java), which is actually the default XML parser for Tika).

Let's go back to the metadata idea, then. A user would have to know _a priori_ that a URI is a sitemap. Since we're fetching robots.txt anyways, should we provide a facility for extracting sitemap links? I think we already get this for free with the robots rules parser.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3MjQyNTMx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/38,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3MzQ4MzU3,incubator-stormcrawler,67348357,38,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2014-12-17T16:25:50Z,2014-12-17T16:25:50Z,"> A user would have to know a priori that a URI is a sitemap.

yes. It is not very different from specifying the root URL of a site as a seed

> Since we're fetching robots.txt anyways, should we provide a facility for extracting sitemap links? I think we already get this for free with the robots rules parser.
> could do that as step 2. The metadata to mark them as sitemaps would be added automatically but it is not clear to me when we'd do that. When fetching any URL? As a separate step? Expecting the users to provide it as seeds feels more intuitive. 

I'll start working on an initial implementation soon.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3MzQ4MzU3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/38,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3MzU0OTM1,incubator-stormcrawler,67354935,38,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2014-12-17T17:02:54Z,2014-12-17T17:02:54Z,"> yes. It is not very different from specifying the root URL of a site as a seed

Perfect, this will work well. As we begin to add more input metadata fields (If-Modified-Since is already one, the sitemap flag will be another) let's keep track of them. Eventually it would be nice to provide users with seed serializers/deserializers (to at least JSON and Avro), which will make message queue spouts a snap.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3MzU0OTM1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/38,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY5MDE0NjYw,incubator-stormcrawler,69014660,38,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-07T12:18:00Z,2015-01-07T12:18:00Z,"Implemented in #42 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY5MDE0NjYw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,incubator-stormcrawler,52265939,41,Project reorganization,jakekdodd,6845693,Jake K. Dodd,,CLOSED,2014-12-17T17:12:55Z,2015-01-23T09:42:35Z,"Given our discussion in #24, and previous discussions on Kafka spouts, HBase indexing, etc, we should think about reorganizing the project so that we have a core SDK and external SDK(s). 

I was thinking something like

**root**
&nbsp;&nbsp;&nbsp;&nbsp; `pom.xml`
&nbsp;&nbsp;&nbsp;&nbsp;|-> **crawler-core**
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`pom.xml`
&nbsp;&nbsp;&nbsp;&nbsp;|-> **crawler-external**
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`pom.xml`

The external sub-project would include things that depend on external technologies and libraries.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/41/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3MzU4NjMw,incubator-stormcrawler,67358630,41,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2014-12-17T17:25:25Z,2014-12-17T17:25:25Z,"or do as discussed before have a completely separate project for this [https://github.com/DigitalPebble/spiderling] and provide a crawler that would be fully functional and ready to use. 

I was thinking of a 100% ElasticSearch pipeline where we'd store the url status, content to index, metrics and maybe even the logs. We'd provide schemas for ES (if necessary) as well as Kibana.

We could maybe do both? We already have a few things in the project that are related to external resources (ES for instance).

Storm do something similar [https://github.com/apache/storm/tree/master/external] but have one pom per external resource
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3MzU4NjMw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3NDE2NjA5,incubator-stormcrawler,67416609,41,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2014-12-17T23:29:18Z,2014-12-17T23:29:18Z,"> We could maybe do both? We already have a few things in the project that are related to external resources (ES for instance).
> 
> but have one pom per external resource

This seems like the best option to me. The Elasticsearch bolt would come out of crawler-core, and we'd have a crawler-external subproject with several subprojects itself (one would be crawler-elasticsearch, which would include the indexing bolt, a metrics consumer, maybe other things; another would be crawler-redis, which would include a Redis spout, cache, metrics writer, etc).
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3NDE2NjA5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3NDYyMzQ3,incubator-stormcrawler,67462347,41,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2014-12-18T09:40:03Z,2014-12-18T09:40:03Z,"The only concern I have is to spread ourselves too thin and have to maintain loads of resources related to external projects. My experience with Apache GORA and Nutch 2 has been quite a traumatic one from that perspective. What I like about Storm is that people can maintain their own spouts and bolts while leveraging our core components : it's all in the pom.xml as dependencies. 
It will take some effort to make sure that the external part of the project does not become a dumping ground. I also means that we'll publish a lot more artefacts, but since this should be automatic it should not mean any additional work.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3NDYyMzQ3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3Nzg3NzQ1,incubator-stormcrawler,67787745,41,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2014-12-21T22:28:44Z,2014-12-21T22:28:44Z,"Yeah I hear you on that.

How about I use the spiderling project as a platform to demonstrate some of the externally-dependent spouts and bolts? I'll create several example projects that leverage Redis, Kafka, and some other stuff. Then, if we decide that any of those elements would be generally useful, we can pull them into the core project.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3Nzg3NzQ1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3ODI0Mzg0,incubator-stormcrawler,67824384,41,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2014-12-22T10:50:13Z,2014-12-22T10:50:13Z,"I still think it would make sense to follow your suggestion and have an external directory as some of our stuff could already go there. +1 to use spiderling as a testing ground but I would then pull the most useful things from there into external and maybe not core. What do you think?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3ODI0Mzg0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3ODUzNDg1,incubator-stormcrawler,67853485,41,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2014-12-22T16:01:05Z,2014-12-22T16:01:05Z,"Sounds good to me. What should we name them, sc-core and sc-external?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3ODUzNDg1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3ODU1MTg0,incubator-stormcrawler,67855184,41,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2014-12-22T16:14:16Z,2014-12-22T16:14:16Z,"The directories can simply be core and external. As for the artefacts in pom we could leave core as is and use a suffix for external?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3ODU1MTg0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3ODU2Mjcx,incubator-stormcrawler,67856271,41,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2014-12-22T16:22:30Z,2014-12-22T16:22:30Z,"Yep that works!

How do we want to organize packages in the external directory? We can make it component-oriented (like `com.digitalpebble.storm.crawler.indexing.elasticsearch.*`) or dependency-oriented (like `com.digitalpebble.storm.crawler.elasticsearch.*`)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3ODU2Mjcx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3ODU2ODc4,incubator-stormcrawler,67856878,41,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2014-12-22T16:26:35Z,2014-12-22T16:26:35Z,"Would do the latter. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3ODU2ODc4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3ODU3NjQz,incubator-stormcrawler,67857643,41,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2014-12-22T16:32:16Z,2014-12-22T16:32:16Z,"Ok great, let's do this after we resolve the pending PRs, so we don't have to resolve merge conflicts for those
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3ODU3NjQz/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMDY0ODUz,incubator-stormcrawler,70064853,41,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-15T10:13:56Z,2015-01-15T10:13:56Z,"@DigitalPebble/committers-crawler shall we proceed with this and then release 0.4? Anything else we'd want to put in the release?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMDY0ODUz/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMDk1MzAz,incubator-stormcrawler,70095303,41,NA,GuiForget,2585258,Gui Forget,,NA,2015-01-15T14:46:55Z,2015-01-15T14:46:55Z,"I'm ok with it. The other option is to make 0.5 be just this change + the merge of metadata. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMDk1MzAz/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMDk3MjMz,incubator-stormcrawler,70097233,41,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-01-15T14:58:08Z,2015-01-15T14:58:08Z,"Let's do it--working on the reorganization now.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMDk3MjMz/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMTA4Nzc4,incubator-stormcrawler,70108778,41,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-01-15T16:04:23Z,2015-01-15T16:04:23Z,"Take a look at 780a82c4f3ba6c3f94a61987a7803fa02bdb4c8c and let me know what you think. Clean/compile/test/package all seem to be functioning normally.

Only difference from discussion above is that the submodule artifacts are named 'sc-core' and 'sc-external,' so that we don't have to change the parent project name from 'storm-crawler.' Directories are named 'core' and 'external,' though.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMTA4Nzc4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMTE1NTk5,incubator-stormcrawler,70115599,41,NA,GuiForget,2585258,Gui Forget,,NA,2015-01-15T16:40:13Z,2015-01-15T16:40:13Z,"My early feedback:
- Regarding the artifact names, I assumed sc-core was just to keep it short during the discussion but I see that's the actual name you use. I'd prefer the full name storm-crawler-core
- Exec maven plugin. There's a version 1.3.x now
- in sc-external, I don't think the exec plugin is required
- in sc-external, I don't think you want the test-jar. 
- in both projects, do we still need the big jar? Shouldn't this be done solely in spiderling?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMTE1NTk5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMTE2MjM4,incubator-stormcrawler,70116238,41,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-01-15T16:43:34Z,2015-01-15T16:43:34Z,"Agree on all points there. For consistency, should we also change sc-external to storm-crawler-external?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMTE2MjM4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMTE2Mjg0,incubator-stormcrawler,70116284,41,NA,GuiForget,2585258,Gui Forget,,NA,2015-01-15T16:43:50Z,2015-01-15T16:43:50Z,"Yes, that was implied :)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMTE2Mjg0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMTI2OTM2,incubator-stormcrawler,70126936,41,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-01-15T17:37:56Z,2015-01-15T17:37:56Z,"Should probably add this as a separate issue, but it looks like the javadoc goal still breaks the release profile. @GuiForget I remember you brought this up a while ago...did we have any intended resolution on that?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMTI2OTM2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMTMzNDE3,incubator-stormcrawler,70133417,41,NA,GuiForget,2585258,Gui Forget,,NA,2015-01-15T18:17:02Z,2015-01-15T18:17:02Z,"The resolution was that it worked for @jnioche  :)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMTMzNDE3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMjMxMDU3,incubator-stormcrawler,70231057,41,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-16T09:53:04Z,2015-01-16T09:53:04Z,"+1 to Gui's points above
- bigjar : can explain in Wiki how to do that and it is in Spiderling indeed but I quite liked being able to run in distributed Storm just by tweaking  the CrawlTopology in core.
- should not we move the dependencies from the parent pom to core? 
- will need rebasing to incorporate most recent changes to master?
- I'd move the whole of the metrics package to external as well as the Codahale dependency. The only change it would require would be to remove 

```
import com.digitalpebble.storm.metrics.HistogramMetric;
import com.digitalpebble.storm.metrics.MeterMetric;
import com.digitalpebble.storm.metrics.TimerMetric;
```

from the ParserBolt and rely on the standard `backtype.storm.metric` implementations. The rest of the code in core does not rely on what we have in the metrics package which I think is a good thing. I will open a new issue for refactoring the metrics in ParserBolt.
- Javadoc and release : see #27
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMjMxMDU3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMjMxNDMz,incubator-stormcrawler,70231433,41,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-16T09:56:19Z,2015-01-16T09:56:19Z,"Metrics package : of course it is not external in the sense that it relies on a third party library (although it does with Codahale) but it is external in the sense that it is a non-core component the use of which is completely optional. Longer term we'll see what happens to it and whether it makes sense to keep it or not. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMjMxNDMz/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMjkyOTc4,incubator-stormcrawler,70292978,41,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-01-16T17:52:49Z,2015-01-16T17:52:49Z,"> bigjar : can explain in Wiki how to do that and it is in Spiderling indeed but I quite liked being able to run in distributed Storm just by tweaking the CrawlTopology in core.

Good point, the bigjar for sc-core might have some usefulness in development. Let's leave it in the sc-core pom for now...if it's not being used, we can easily remove it in the future.

> should not we move the dependencies from the parent pom to core?

Yeah the original intent was to keep them in the parent pom so that we could selectively exclude them from child projects. But, for now it seems unlikely that we'll have any child projects of sc-core, so I'll move the deps there.

> Javadoc and release : see #27

In my development environment, running `mvn package -P release` produces a ton of Javadoc-related complaints. @jnioche does that command successfully execute for you?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMjkyOTc4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNDg2NjA4,incubator-stormcrawler,70486608,41,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-19T12:38:10Z,2015-01-19T12:38:10Z,"Only getting :

```
2 warnings
[WARNING] Javadoc Warnings
[WARNING] /data/storm-crawler/src/main/java/com/digitalpebble/storm/crawler/filtering/URLFilterUtil.java:45: warning - @param argument ""configuration"" is not a parameter name.
[WARNING] /data/storm-crawler/src/main/java/com/digitalpebble/storm/crawler/filtering/URLFilterUtil.java:64: warning - @param argument ""target"" is not a parameter name.
[INFO] Building jar: /data/storm-crawler/target/storm-crawler-0.4-SNAPSHOT-javadoc.jar
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 13.447s
[INFO] Finished at: Mon Jan 19 12:37:08 GMT 2015
[INFO] Final Memory: 21M/222M
[INFO] ------------------------------------------------------------------------
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNDg2NjA4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNTI1OTgx,incubator-stormcrawler,70525981,41,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-01-19T16:56:48Z,2015-01-19T16:56:48Z,"New commit b33c073e749792d505cd994261643aef28e4dbbb:
- Test-jar not produced for sc-external with the release profile
- Renamed submodules to storm-crawler-core and storm-crawler-external (will continue to refer to these with the 'sc' prefix in discussions for brevity)
- Bigjar is again included in the sc-core pom
- Added dependencyManagement and pluginManagement sections in the parent pom for reused dependencies; jackson-databind has been included anticipating that we'll have classes in sc-external that use the JSON-driven plugin system.

I avoided refactoring the metrics for now until the metrics in ParserBolt have been refactored. Once that's done, we can move the codehale and librato stuff into sc-external

Also, once we decide it's ready to go, I'll rebase the branch against master so we can fast-forward commit.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNTI1OTgx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNTI3MTI2,incubator-stormcrawler,70527126,41,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-19T17:04:32Z,2015-01-19T17:04:32Z,"> I avoided refactoring the metrics for now until the metrics in ParserBolt have been refactored. Once that's done, we can move the codehale and librato stuff into sc-external

This has been done see #65 

Will check your latest commit on Wednesday.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNTI3MTI2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNTMwMTYz,incubator-stormcrawler,70530163,41,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-01-19T17:25:21Z,2015-01-19T17:25:21Z,"Have rebased against master, with #65 applied the metrics are now located in `com.digitalpebble.storm.crawler.codehale.metrics.*` and `com.digitalpebble.storm.crawler.librato.metrics.*` packages
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNTMwMTYz/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNTU5Nzgz,incubator-stormcrawler,70559783,41,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-19T21:01:06Z,2015-01-19T21:01:06Z,"[https://github.com/DigitalPebble/storm-crawler/tree/project-reorganization/core/src/main/java/com/digitalpebble/storm/metrics] package still appears in core. 

I'd leave the codehale related stuff under `com.digitalpebble.storm.crawler.metrics` as the fact that they leverage codehale is not very important from a functional point of view, whereas the librato related code could be in com.digitalpebble.storm.crawler.metrics.librato.\* maybe? 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNTU5Nzgz/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNTYxMDcz,incubator-stormcrawler,70561073,41,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-01-19T21:08:48Z,2015-01-19T21:08:48Z,"> package still appears in core.

Haven't made and pushed the commit yet, wanted to finish the discussion first so we don't have a bunch of random commits in the history

Regarding:

> I'd leave the codehale related stuff under com.digitalpebble.storm.crawler.metrics

and 

> com.digitalpebble.storm.crawler.metrics.librato.*

That seems more sensible and less verbose to me; the reason why I named the packages `com.digitalpebble.storm.crawler.<dependency name>.metrics.*` was for consistency (mirroring `com.digitalpebble.storm.crawler.elasticsearch.*`). This came from the discussion above where we decided it would be better to organize the packages by dependency, rather than by component.

Still, those package names seem like a mouthful to me. What do you think?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNTYxMDcz/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwODQzODg5,incubator-stormcrawler,70843889,41,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-21T14:16:18Z,2015-01-21T14:16:18Z,"> it would be better to organize the packages by dependency, rather than by component

I agree but I think it is a bit different for the metrics as the dependency does not really matter. Later on we'll have the same sort of components (spout, status updater bolt, indexers, etc...) for different backends (ES, SOLR, HBase) and that's where it will make sense to organise per dependency.

> Still, those package names seem like a mouthful to me.

I am not too bothered about that. Do you have any alternatives in mind?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwODQzODg5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwODU0NTEw,incubator-stormcrawler,70854510,41,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-01-21T15:14:29Z,2015-01-21T15:14:29Z,"Newest commit is cb47e58769bc73435434220ed2988e0e18d49d71
- Codehale-related stuff is in `com.digitalpebble.storm.crawler.metrics.*`
- Librato-related stuff is in `com.digitalpebble.storm.crawler.librato.metrics*`. This is similar to your suggested `com.digitalpebble.storm.crawler.metrics.librato.*`, but will help with consistency if/when we eventually have Elasticsearch/Logstash/Redis/etc. metrics consumers, which would then be organized under their respective dependency packages.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwODU0NTEw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwODYwMzcy,incubator-stormcrawler,70860372,41,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-21T15:44:50Z,2015-01-21T15:44:50Z,"Both core and external's poms contain :

```
    <dependency>
      <groupId>org.apache.storm</groupId>
      <artifactId>storm-core</artifactId>
    </dependency>

    <dependency>
      <groupId>junit</groupId>
      <artifactId>junit</artifactId>
    </dependency>
```

is that necessary given that it is already in the parent pom? Shouldn't they be scoped as `provided` and `test` respectively?

`jackson-databind` is in both the parent and the core pom.

the README will probably need changing to add 'core' in the paths where needed.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwODYwMzcy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwODYxNDgx,incubator-stormcrawler,70861481,41,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-01-21T15:50:23Z,2015-01-21T15:50:23Z,"Yep, when using dependencyManagement, you still need to explicitly state in the child pom that you're using a declared dependency. They inherit the scope from that declared in the parent pom (see documentation [here](http://maven.apache.org/guides/introduction/introduction-to-dependency-mechanism.html#Dependency_Management)).

The `jackson-databind` dependency will probably be used at some point or another by external components, so it's in the parent pom but not declared in `sc-external` until it's actually used
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwODYxNDgx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwODYxNzcy,incubator-stormcrawler,70861772,41,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-21T15:51:53Z,2015-01-21T15:51:53Z,"@jakekdodd thanks for the explanation
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwODYxNzcy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/41,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxMTY5MjYy,incubator-stormcrawler,71169262,41,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-23T09:42:35Z,2015-01-23T09:42:35Z,"Done in #70 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxMTY5MjYy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/43,https://api.github.com/repos/apache/incubator-stormcrawler/issues/43,incubator-stormcrawler,52475022,43,Parser to send tuple to 'status' stream instead of failing,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2014-12-19T11:47:21Z,2015-01-05T11:28:14Z,"The parser currently fails tuples when an exception is caught. This is probably not the right behaviour as the same URL will be refetched and refail again later (unless of course). What we could do instead would be to use the `status` stream to mark the URL as failed and keep track of the reason why it did so. Whichever component is in charge of persisting the URL status can then decide on what to do with it.

This is related to the discussion in #42 

The same logic could be applied to fetch failures as well. Instead of failing them and let the spout handle the logic of keeping track of the number of errors we'd send to the status stream. The advantage of doing this is that the spout wouldn't have to update anything and would just read. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/43/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/43,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY4Njk2NTE3,incubator-stormcrawler,68696517,43,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-05T11:28:13Z,2015-01-05T11:28:13Z,"Implemented in #44 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY4Njk2NTE3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/45,https://api.github.com/repos/apache/incubator-stormcrawler/issues/45,incubator-stormcrawler,52499202,45,Fetcher to dump the content of its queues to the log,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2014-12-19T16:11:53Z,2016-01-27T10:53:39Z,"We could use a very primitive mechanism like checking whether a file exists at an arbitrary location (configurable in the usual way) to get the FetcherBolt to dump the content of its internal queues to the logs. This would be useful as a way of debugging. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/45/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/45,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3NjU5NzUy,incubator-stormcrawler,67659752,45,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2014-12-19T16:22:41Z,2014-12-19T16:22:41Z,"This would definitely be useful. Maybe it should happen when a tick tuple is received. Opacity of the FetcherBolt queues is one of the main reasons I switched to the SimpleFetcherBolt and a heavyweight external queue manager.

Or, if we don't use the tick tuple, the right way to do this would be Zookeeper. Wouldn't add any external dependencies, since Storm already requires it.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3NjU5NzUy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/47,https://api.github.com/repos/apache/incubator-stormcrawler/issues/47,incubator-stormcrawler,52932402,47,Exception in DebugMetricsConsumer,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2014-12-26T17:22:28Z,2015-09-20T10:44:12Z,"java.lang.ClassCastException: java.lang.Integer cannot be cast to java.util.Map
    at com.digitalpebble.storm.metrics.DebugMetricsConsumer.handleDataPoints(DebugMetricsConsumer.java:103) ~[classes/:na]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/47/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/47,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0MTc3NDg0Nw==,incubator-stormcrawler,141774847,47,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-09-20T10:44:12Z,2015-09-20T10:44:12Z,"We removed the metrics related code since.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0MTc3NDg0Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/48,https://api.github.com/repos/apache/incubator-stormcrawler/issues/48,incubator-stormcrawler,53270856,48,NPE in ParserBolt,jakekdodd,6845693,Jake K. Dodd,,CLOSED,2015-01-02T19:06:59Z,2015-01-15T10:12:21Z,"Encountered this while working on the Spiderling.

The NPE stems from a null content byte array, and occurs [here](https://github.com/DigitalPebble/storm-crawler/blob/1ad1cf5b526ac0d81df1e6e10dbad0b5c7492f61/src/main/java/com/digitalpebble/storm/crawler/bolt/ParserBolt.java#L168). I discovered that the offending URL was one that resulted in a 301 redirect. However, the protocol response's content is non-null for several other URLs that result in 301s, so the redirect response may not be the source of the problem.

Console output with stack trace:

```
52998 [Thread-12-parse] ERROR backtype.storm.util - Async loop died!
java.lang.RuntimeException: java.lang.NullPointerException
    at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:128) ~[storm-core-0.9.3.jar:0.9.3]
    at backtype.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:99) ~[storm-core-0.9.3.jar:0.9.3]
    at backtype.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:80) ~[storm-core-0.9.3.jar:0.9.3]
    at backtype.storm.daemon.executor$fn__3441$fn__3453$fn__3500.invoke(executor.clj:748) ~[storm-core-0.9.3.jar:0.9.3]
    at backtype.storm.util$async_loop$fn__464.invoke(util.clj:463) ~[storm-core-0.9.3.jar:0.9.3]
    at clojure.lang.AFn.run(AFn.java:24) [clojure-1.5.1.jar:na]
    at java.lang.Thread.run(Thread.java:745) [na:1.7.0_55]
Caused by: java.lang.NullPointerException: null
    at com.digitalpebble.storm.crawler.bolt.ParserBolt.execute(ParserBolt.java:168) ~[storm-crawler-0.4-SNAPSHOT.jar:na]
    at backtype.storm.daemon.executor$fn__3441$tuple_action_fn__3443.invoke(executor.clj:633) ~[storm-core-0.9.3.jar:0.9.3]
    at backtype.storm.daemon.executor$mk_task_receiver$fn__3364.invoke(executor.clj:401) ~[storm-core-0.9.3.jar:0.9.3]
    at backtype.storm.disruptor$clojure_handler$reify__1447.onEvent(disruptor.clj:58) ~[storm-core-0.9.3.jar:0.9.3]
    at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:125) ~[storm-core-0.9.3.jar:0.9.3]
    ... 6 common frames omitted
```

@jnioche have you seen this before?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/48/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/48,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY4NjkzOTI1,incubator-stormcrawler,68693925,48,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-05T10:59:14Z,2015-01-05T10:59:14Z,"Never got that before. Do you know what URL caused it? Would be good to check that the Fetcher behaves as expected. 
This would not be an issue after committing #44 since the parser would be called only if the http code is Status.FETCHED. Having said that we should check that the content is not null and if so handle it via the status stream (see #43)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY4NjkzOTI1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/48,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY4NzEzODk3,incubator-stormcrawler,68713897,48,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-01-05T14:26:02Z,2015-01-05T14:26:02Z,"Yep, the offending URL is http://www.dailynewslosangeles.com/.

I'm curious about why this particular case produces null content, when typically a 301 results in an empty byte array (I think). It's possible this is a bug in the HTTP implementation--but there might also be a meaningful difference between null content and empty content that we should report to Status.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY4NzEzODk3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/48,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY4NzE4NDk3,incubator-stormcrawler,68718497,48,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-05T14:58:30Z,2015-01-05T14:58:30Z,"It doesn't happen now that I committed  #44 into trunk, however HttpResponse contains a null value for content indeed. 

This is caused by a SocketTimeoutException being thrown by readPlainContent in [HttpResponse](https://github.com/DigitalPebble/storm-crawler/blob/1ad1cf5b526ac0d81df1e6e10dbad0b5c7492f61/src/main/java/com/digitalpebble/storm/crawler/protocol/http/HttpResponse.java#L289). 
As you can see [here](https://github.com/DigitalPebble/storm-crawler/blob/1ad1cf5b526ac0d81df1e6e10dbad0b5c7492f61/src/main/java/com/digitalpebble/storm/crawler/protocol/http/HttpResponse.java#L230) we do nothing about this exception.
We should probably log this exception but also add an empty content array in the finally section so that we never get that null content.

The main issue however is in [readPlainContent](https://github.com/DigitalPebble/storm-crawler/blob/1ad1cf5b526ac0d81df1e6e10dbad0b5c7492f61/src/main/java/com/digitalpebble/storm/crawler/protocol/http/HttpResponse.java#L313) as we shouldn't even try to read from the stream at all if the contentLength is set to 0 by the server.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY4NzE4NDk3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/48,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY4NzIxMDM4,incubator-stormcrawler,68721038,48,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-01-05T15:15:14Z,2015-01-05T15:15:14Z,"Got it, good catch. I'll fix this
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY4NzIxMDM4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/48,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMDY0Njgz,incubator-stormcrawler,70064683,48,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-15T10:12:21Z,2015-01-15T10:12:21Z,"Fixed in [master 4f1339e] NPE in ParserBolt #48
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMDY0Njgz/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/49,https://api.github.com/repos/apache/incubator-stormcrawler/issues/49,incubator-stormcrawler,53618213,49,Use slf4j {} placeholders ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-01-07T10:29:51Z,2015-01-09T16:27:25Z,"We use slf4j everywhere in the project but without making use of placeholders [http://www.slf4j.org/faq.html#logging_performance]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/49/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/50,https://api.github.com/repos/apache/incubator-stormcrawler/issues/50,incubator-stormcrawler,53618312,50,Wiki on SitemapParser,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-01-07T10:30:58Z,2015-01-07T12:17:05Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/50/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/50,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY5MDE0NTg2,incubator-stormcrawler,69014586,50,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-07T12:17:05Z,2015-01-07T12:17:05Z,"See [https://github.com/DigitalPebble/storm-crawler/wiki/SiteMapParserBolt]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY5MDE0NTg2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/51,https://api.github.com/repos/apache/incubator-stormcrawler/issues/51,incubator-stormcrawler,53618407,51,Wiki on use of streams,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-01-07T10:31:48Z,2015-04-10T15:56:27Z,"Need to explain 'status' stream and how it differs from the default one.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/51/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/51,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxMDMxMDIy,incubator-stormcrawler,71031022,51,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-22T14:50:06Z,2015-01-22T14:50:06Z,"See [https://github.com/DigitalPebble/storm-crawler/wiki/statusStream]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxMDMxMDIy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/51,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkxNTk5ODE3,incubator-stormcrawler,91599817,51,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-04-10T15:56:27Z,2015-04-10T15:56:27Z,"Good enough for now I think. Comments and review welcome as usual
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkxNTk5ODE3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/53,https://api.github.com/repos/apache/incubator-stormcrawler/issues/53,incubator-stormcrawler,53855373,53,Change URLFilter interface to optionally take metadata,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-01-09T10:47:38Z,2015-01-28T10:51:29Z,"This would be useful for several use cases such as [https://github.com/PopSugar/storm-crawler-extensions/pull/2] or [https://github.com/DigitalPebble/storm-crawler/pull/46] where in both cases we need to know the source URL of a new link (or rather its domain or hostname).

This is similar to [https://github.com/DigitalPebble/storm-crawler/issues/25].

We'd then be able to enforce the filtering based on whether a URL is from the same hostname or domain as the URL it originates from as a normal URLFilter which would make the code more compact and easier to reuse from various parsing bolts or the Fetcher (e.g. redirections).

Should this be done before or after [https://github.com/DigitalPebble/storm-crawler/pull/36]?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/53/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/53,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY5NTYxNzQ5,incubator-stormcrawler,69561749,53,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-12T12:15:34Z,2015-01-12T12:15:34Z,"The URLs that are filtered in ParserBolt don't have metadata, the metadata are created in the subsequent stages. The URLFilters also don't get access to the config at all, but could could be configured via their bespoke JSON config files.
We could create some temporary metadata just to convey the source URL but in that case wouldn't it be simpler to just pass the source URL directly and have filter(String source, String target)?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY5NTYxNzQ5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/53,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY5OTAyODUx,incubator-stormcrawler,69902851,53,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-14T11:22:45Z,2015-01-14T11:22:45Z,"Have implemented a util class to simplify the filtering of URLs based on the host or domain name of the source URL [https://github.com/DigitalPebble/storm-crawler/commit/c6aa373965e0d8f24e84c97ef21df2c830bad31e] as a temporary solution. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY5OTAyODUx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/53,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxMzc1MjY2,incubator-stormcrawler,71375266,53,NA,GuiForget,2585258,Gui Forget,,NA,2015-01-25T14:34:13Z,2015-01-25T14:34:13Z,"I'm going to work on that so I get more familiar with this piece of the code
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxMzc1MjY2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/54,https://api.github.com/repos/apache/incubator-stormcrawler/issues/54,incubator-stormcrawler,54169948,54,Investigate use of async IO for Fetcher,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-01-13T09:51:28Z,2016-02-09T21:48:08Z,"The fetcher bolts currently block IO. Doing asynchronous IO would certainly provide better throughput. 

[https://jfarcand.wordpress.com/2010/12/21/going-asynchronous-using-asynchttpclient-the-basic/] provides interesting examples
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/54/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/54,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY5NzUxOTk5,incubator-stormcrawler,69751999,54,NA,kkrugler,66217,Ken Krugler,ken@transpac.com,NA,2015-01-13T14:32:26Z,2015-01-13T14:32:26Z,"One data point - Oleg Kalnichevski (main author of HttpClient) has repeatedly said that he thinks sync outperforms async, e.g. ""From my personal experience a decent blocking HTTP client can be
expected to outperform a decent non-blocking HTTP client by 50 to 100%"".

At very massive parallelism using async would definitely make sense, though I've run HttpClient with 2000+ threads on one box with appropriate tuning of thread stack size, etc.

But I also enjoy the asynhttpclient API, and have used it in various projects, so I'm not suggesting that it shouldn't be used. I'm just saying that the most knowledgeable person I know about HTTP comms says it won't be a performance win.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY5NzUxOTk5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/54,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY5OTA3NjI0,incubator-stormcrawler,69907624,54,NA,eshioji,1995924,Enno Shioji,,NA,2015-01-14T12:11:07Z,2015-01-14T12:11:07Z,"Oh sorry I meant to be working on this but got bogged down with lots of things happening in my former company.. Feeling rather guilty... It's much more relaxed now, I could work on this if you want.

As for performance, I think there is definitely a good chance we can score a gain. In the world of web servers, it's been established that non-blocking is advantageous because you interact with clients that are low-performing, resulting in lots of wait time on your end, which you can then reduce by talking to lots of clients at the same time. This seems similar to what we'd have in a crawling situation.

I still have the code for this, so would be easy enough to add.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY5OTA3NjI0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/54,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY5OTE2MDYw,incubator-stormcrawler,69916060,54,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-14T13:33:21Z,2015-01-14T13:33:21Z,"@kkrugler thanks for your comments, very useful as usual.
@eshioji great to hear from you. feel free to create a separate branch to play with. I expect you'd need to modify the protocol interface and/or the Fetcher logic quite a bit
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY5OTE2MDYw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/54,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY5OTI0ODcw,incubator-stormcrawler,69924870,54,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-01-14T14:39:52Z,2015-01-14T14:39:52Z,"Each task of the SimpleFetcherBolt will block IO to make its HTTP request. When using that bolt, concurrency can be achieved by tuning the number of executors (threads) and tasks.

The regular FetcherBolt is already asynchronous from the perspective of Storm, and its concurrency is limited by the number of threads in the pool. The size of the thread pool is functionally equivalent to the max connections in AsyncHTTPClient's connection pool.

So, my best guess is that moving to an async HTTP client library will give us better memory performance, but not necessarily better throughput. My hypothesis is that you'll achieve bandwidth saturation before running out of memory because of too many component executors (in the case of SimpleFetcherBolt) or too many pool threads (in the case of FetcherBolt).
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY5OTI0ODcw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/54,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNzUzNjAw,incubator-stormcrawler,70753600,54,NA,eshioji,1995924,Enno Shioji,,NA,2015-01-20T23:08:07Z,2015-01-20T23:08:07Z,"Created a feature branch: https://github.com/DigitalPebble/storm-crawler/tree/feature/non-blocking-fetcher

I haven't done the fetcher bit yet, but it does illustrate the proposed refactoring on the protocol/robot rule parser interface. Note that I used the Guava classes copied into Storm's source. This will avoid having a dependency to Guava but will tie the code to Storm. Am not sure if this is the right thing to do.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNzUzNjAw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/54,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNzU0NjIy,incubator-stormcrawler,70754622,54,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-01-20T23:16:05Z,2015-01-20T23:16:05Z,"> This will avoid having a dependency to Guava but will tie the code to Storm. Am not sure if this is the right thing to do.

We already switched over to the storm-packaged Guava classes in other locations in the codebase, so I think that's the right approach
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNzU0NjIy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/54,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwODQ1MjI4,incubator-stormcrawler,70845228,54,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-21T14:24:18Z,2015-01-21T14:24:18Z,"I'll have a closer look at this when I get a moment. Quick comment for now : I had a http protocol implementation based on AsyncHttpClient but as it uses Netty as a default provider, this caused all sorts of issues with Storm itself. Probably not a problem anymore now that Storm shaded Netty but worth keeping in mind. See [https://storm.apache.org/2014/11/25/storm093-released.html#reduced-dependency-conflicts]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwODQ1MjI4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/54,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwOTQyMTcz,incubator-stormcrawler,70942173,54,NA,eshioji,1995924,Enno Shioji,,NA,2015-01-21T23:18:25Z,2015-01-21T23:18:25Z,"@jakekdodd Ah I see, thank you!
@jnioche That would be great. Re: dependency clash I didn't have to add Ning's AsyncHttpClient as one of the dependencies apparently already had it. It also seemed to run OK when I did a smoke test. Hopefully it will be fine..
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwOTQyMTcz/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/54,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxNzM1OTk2,incubator-stormcrawler,71735996,54,NA,eshioji,1995924,Enno Shioji,,NA,2015-01-27T21:55:41Z,2015-01-27T21:55:41Z,"@jnioche Did a first pass of the NonBlockingFetcherBolt. It's nowhere complete but it does fetch URLs ok. Would maybe fit for a performance test with a bit more work.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxNzM1OTk2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/54,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE3NjY5MzMyMg==,incubator-stormcrawler,176693322,54,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-01-29T10:58:37Z,2016-01-29T10:58:37Z,"@eshioji I never got to investigate this in more details. The codebase has since evolved an awful lot. From your earlier comments you mentioned that there wouldn't be much gain in using async, is that still what you think? If so shall we close this issue?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE3NjY5MzMyMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/54,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4MjA5MjM0Mw==,incubator-stormcrawler,182092343,54,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-02-09T21:48:08Z,2016-02-09T21:48:08Z,"Closing as there seems to be little interest in this.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4MjA5MjM0Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/55,https://api.github.com/repos/apache/incubator-stormcrawler/issues/55,incubator-stormcrawler,54328567,55,SitemapParser apply filtering to outlinks,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-01-14T14:36:06Z,2015-01-14T16:17:18Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/55/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/55,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY5OTQxNzYx,incubator-stormcrawler,69941761,55,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-14T16:17:10Z,2015-01-14T16:17:10Z,"Implemented in [master 329263c] 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY5OTQxNzYx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/56,https://api.github.com/repos/apache/incubator-stormcrawler/issues/56,incubator-stormcrawler,54381518,56,Pass the storm config when configuring the ParseFilter,GuiForget,2585258,Gui Forget,,CLOSED,2015-01-14T21:47:30Z,2015-01-15T09:29:40Z,"So they can access information shared via the yaml files
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/56/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/56,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY5OTk4NzQ3,incubator-stormcrawler,69998747,56,NA,GuiForget,2585258,Gui Forget,,NA,2015-01-14T21:48:12Z,2015-01-14T21:48:12Z,"I marked it with milestone 0.4 as we may as well make this interface change sooner than later. PR coming soon
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY5OTk4NzQ3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/59,https://api.github.com/repos/apache/incubator-stormcrawler/issues/59,incubator-stormcrawler,54439360,59,Port NUTCH-1825,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-01-15T11:33:49Z,2015-04-22T13:01:42Z,"see [https://issues.apache.org/jira/browse/NUTCH-1825]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/59/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/59,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDk1MTMwNjUw,incubator-stormcrawler,95130650,59,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-04-22T10:43:18Z,2015-04-22T10:43:18Z,"Not needed since we got rid of the protocol code inherited from Nutch #122
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDk1MTMwNjUw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/60,https://api.github.com/repos/apache/incubator-stormcrawler/issues/60,incubator-stormcrawler,54445434,60,update lists of committers in pom.xml,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-01-15T12:47:17Z,2015-01-15T16:30:50Z,"@GuiForget could you please add yourself to that file?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/60/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/61,https://api.github.com/repos/apache/incubator-stormcrawler/issues/61,incubator-stormcrawler,54446268,61,Resource files overridden by ones provided by default in SC ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-01-15T12:57:55Z,2016-03-23T11:49:05Z,"We currently use [http://maven.apache.org/plugins/maven-assembly-plugin/], which is fine but apparently Shade would give us more control. 
One reason why we'd need it is for instance : when an application uses storm crawler as a dependency, it gets the content src/main/resources (e.g. urlfilter config) in the uber-jar but the version coming from the dependency will override any files specified in the project with the same name. To put it differently, we need to use different names for the resources than the ones used by default unless we want to use the default files. 
any thoughts?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/61/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/61,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcyMzIzMjc5,incubator-stormcrawler,72323279,61,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-01-31T15:59:06Z,2015-01-31T15:59:06Z,"Yeah I think using the Shade plugin is the _de facto_ standard for creating uber jars. I'll look into it
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcyMzIzMjc5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/61,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NDQ3NzM2,incubator-stormcrawler,86447736,61,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-03-26T10:43:59Z,2015-03-26T10:43:59Z,"Definitely an issue. Just got an uber jar where the default files from SC overrode the ones specified by my application. As a result all the custom parsing and filtering I had specified got ignored. Will change the title of this issue.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NDQ3NzM2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/61,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTMxNTgw,incubator-stormcrawler,86531580,61,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-03-26T14:12:19Z,2015-03-26T14:12:19Z,"Check out this commit and branch 7ac9a07a1fed4282714d14a12e9666d7c7cdcb1d

It renames the parsing/filtering resources to default-{resource name}, and then excludes the originals from the jar.

However, this doesn't resolve the issue when SC is included as a maven dependency in another project (because the shade plugin is in the bigjar profile, for now). 

What do you think? We can proceed with using the shade plugin to rename the resources during the package phase, or simply name all of them `default-*` to begin with. I think both approaches accomplish the same thing, but renaming the files is easier. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTMxNTgw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/61,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTM3NDAw,incubator-stormcrawler,86537400,61,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-03-26T14:21:50Z,2015-03-26T14:21:50Z,"The issue is mainly when  SC is included as a maven dependency in another project. Also we'd want to have the default files with their original names so that we can rely on them without changing the configuration if we wanted to. 

What we just want to do really is to make sure that the local files systematically overwrite the default ones. Is that something we can do with Maven Shade?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTM3NDAw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/61,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTQ0NjY4,incubator-stormcrawler,86544668,61,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-03-26T14:43:36Z,2015-03-26T14:43:36Z,"Hmm unfortunately I think that's only possible from the user's end.

Though isn't that the point of the `parsefilters.config.file` and the `urlfilters.config.file` configuration options? The user can override the defaults by including their own configuration files. If that weren't the case, then the defaults aren't really 'defaults'--they're just examples. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTQ0NjY4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/61,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTQ1Mjc3,incubator-stormcrawler,86545277,61,NA,GuiForget,2585258,Gui Forget,,NA,2015-03-26T14:44:48Z,2015-03-26T14:44:48Z,"Specifying the file names in the yaml file is what we did in the shopstyle crawler. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTQ1Mjc3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/61,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTY5MzYz,incubator-stormcrawler,86569363,61,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-03-26T15:28:48Z,2015-03-26T15:28:48Z,"> Hmm unfortunately I think that's only possible from the user's end.

I realize I had been inaccurate in my description of the issue. The assumption was that  user builds an uber jar with the same mechanism as we do. I don't think many people will clone the SC code and add their modifications straight onto it but will rather use it as a dependency.

> The user can override the defaults by including their own configuration files.

Which is what I did too. The point here is that if a ppl reuse the same resource names as the default, the behaviour of their crawler won't be what they expect. That's confusing. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTY5MzYz/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/61,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTg3Njg3,incubator-stormcrawler,86587687,61,NA,GuiForget,2585258,Gui Forget,,NA,2015-03-26T15:55:19Z,2015-03-26T15:55:19Z,"But then... isn't the issue for the user when THEY build their uber jar?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTg3Njg3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/61,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTkxNDA2,incubator-stormcrawler,86591406,61,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-03-26T16:01:40Z,2015-03-26T16:01:40Z,"it is, that's exactly what I am on about. Not a core SC issue per-se but one I'd be happy to solve nonetheless, if not here then in spiderling.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTkxNDA2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/61,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTkzMDI3,incubator-stormcrawler,86593027,61,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-03-26T16:03:37Z,2015-03-26T16:03:37Z,"> The point here is that if a ppl reuse the same resource names as the default, the behaviour of their crawler won't be what they expect. That's confusing.

Yeah I agree, one solution would be to rename the defaults by prepending large random strings using the shade plugin. So for example `urfilters.json` would be renamed to something like `a473f5a2bcce41876d5f9a911c3ebe72-urlfilters.json`. That seems silly, but it would work.

> The assumption was that user builds an uber jar with the same mechanism as we do.
> ...
> But then... isn't the issue for the user when THEY build their uber jar?

This is what I was thinking. If a user really wants to have their own `default-*` resources that override the packaged resources, they can use maven shade to rename the packaged resources.

There are a few ways we can solve this...prepending random strings to resources isn't totally bullet proof, but reduces the likelihood that a user would use a colliding resource name to basically 0.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTkzMDI3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/61,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTk2ODA3,incubator-stormcrawler,86596807,61,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-03-26T16:10:44Z,2015-03-26T16:10:44Z,"I'm probably missing something here but there are also cases where the users want to use the default values. If those are renamed then this won't work.

If there is no easy way to control the order in which things are added to the uber jar and hence that the user resources are always added last then we could simply make it very explicit in the documentation (which we will have at some point of course).
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTk2ODA3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/61,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NjA2ODE5,incubator-stormcrawler,86606819,61,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-03-26T16:33:08Z,2015-03-26T16:33:08Z,"If a user doesn't specify `parsefilters.config.file` and `urlfilters.config.file` in the YAML configuration, then the defaults will be used. Right now, as you've pointed out, if a user names their file `urlfilters.json`, and then specifies:

``` yaml
urlfilters.config.file: urlfilters.json
```

 the version packaged with SC will be used instead of the user's. Similarly, if we renamed the packaged version to `default-urlfilters.json`, and the user names their file `default-urlfilters.json`--not an unlikely occurrence--and then sets

``` yaml
urlfilters.config.file: default-urlfilters.json
```

then we have the same problem.

The main issue is that people will come to the SC Github page to get a sense for how to construct these resource files, and will likely copy-paste and use identical names for their resource files. Renaming the resources at package time, before release, is one way to solve that issue.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NjA2ODE5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/61,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIwMDMxMjMyMQ==,incubator-stormcrawler,200312321,61,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-03-23T11:46:48Z,2016-03-23T11:46:48Z,"Done in #4292e91, see #227
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIwMDMxMjMyMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/64,https://api.github.com/repos/apache/incubator-stormcrawler/issues/64,incubator-stormcrawler,54557922,64,Refactoring the metrics in ParserBolt,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-01-16T09:57:02Z,2015-01-16T14:25:12Z,"See discussion in #41 : the metrics package will probably move to 'external' in which case we'll have to refactor ParserBolt so that it uses standard storm metrics instead.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/64/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/64,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMjYwMTUy,incubator-stormcrawler,70260152,64,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-16T14:25:12Z,2015-01-16T14:25:12Z,"implemented in #65 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMjYwMTUy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/66,https://api.github.com/repos/apache/incubator-stormcrawler/issues/66,incubator-stormcrawler,54759227,66,"ParserBolt to send outlinks to status stream, remove from default one?",jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-01-19T12:42:21Z,2015-01-24T17:33:47Z,"The [ParserBolt](https://github.com/DigitalPebble/storm-crawler/blob/master/src/main/java/com/digitalpebble/storm/crawler/bolt/ParserBolt.java) currently sends the outlinks to the default stream alongside the other fields for a document (""url"", ""content"", ""metadata"", ""text""). It would be better to send them to the status stream instead, as we do for the Sitemaps, redirections etc... 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/66/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/66,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwODU4Njg3,incubator-stormcrawler,70858687,66,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-21T15:35:59Z,2015-01-21T15:35:59Z,"If we decide to send the outlinks through the 'status' stream then it would be good to do it before the 0.4 release
@DigitalPebble/committers-crawler  any thoughts on this?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwODU4Njg3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/66,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwODYwOTY0,incubator-stormcrawler,70860964,66,NA,GuiForget,2585258,Gui Forget,,NA,2015-01-21T15:47:55Z,2015-01-21T15:47:55Z,"I'm ok with that
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwODYwOTY0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/66,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwODY2NjY1,incubator-stormcrawler,70866665,66,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-21T16:16:49Z,2015-01-21T16:16:49Z,"see #67 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwODY2NjY1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/68,https://api.github.com/repos/apache/incubator-stormcrawler/issues/68,incubator-stormcrawler,55146232,68,Normalise metadata returned by servers ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-01-22T12:13:20Z,2015-01-28T17:07:41Z,"```
curl -I ""http://twitter.com/home?status=Check+this+out%3ahttp%3a%2f%2fwww.dillards.com%2fwebapp%2fwcs%2fstores%2fservlet%2fProductDisplay%3fcatalogId%3d301%26productId""
HTTP/1.1 301 Moved Permanently
content-length: 0
date: Thu, 22 Jan 2015 12:11:11 UTC
location: https://twitter.com/home?status=Check+this+out%3ahttp%3a%2f%2fwww.dillards.com%2fwebapp%2fwcs%2fstores%2fservlet%2fProductDisplay%3fcatalogId%3d301%26productId
server: tsa_b
set-cookie: guest_id=v1%3A142192867165557827; Domain=.twitter.com; Path=/; Expires=Sat, 21-Jan-2017 12:11:11 UTC
x-connection-hash: ca85b658e4cc93174936c73ea46fa39c
x-response-time: 8
```

where _location_ is in lowercase and our code expects it to be 'Location' in order to work. We could lowercase ALL keys in our metadata or alternatively normalise the key names at the protocol level.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/68/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/68,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxMzc0ODE0,incubator-stormcrawler,71374814,68,NA,GuiForget,2585258,Gui Forget,,NA,2015-01-25T14:20:22Z,2015-01-25T14:20:22Z,"Per RFC, the field names are indeed case insensitive. I would lowercase them all in the protocol
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxMzc0ODE0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/68,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxNDc0MjYz,incubator-stormcrawler,71474263,68,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-01-26T15:06:51Z,2015-01-26T15:06:51Z,"See 527f93699315600ed2861ad34dc6060617afaa18

I identified side effects for:
- `com.digitalpebble.storm.crawler.protocol.HTTPHeaders`
- `com.digitalpebble.storm.crawler.protocol.http.HttpRobotRulesParser`

CrawlTopology seems to run fine, and inspecting the metadata in the debugger confirmed that it's all lowercase.

Can you guys think of any other side effect that need to be addressed? 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxNDc0MjYz/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/68,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxNDk4ODYw,incubator-stormcrawler,71498860,68,NA,GuiForget,2585258,Gui Forget,,NA,2015-01-26T17:22:23Z,2015-01-26T17:22:23Z,"I think that's good. Can't think of anything else
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxNDk4ODYw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/68,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxODczNDI5,incubator-stormcrawler,71873429,68,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-28T17:07:41Z,2015-01-28T17:07:41Z,"Implemented in #77 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxODczNDI5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/71,https://api.github.com/repos/apache/incubator-stormcrawler/issues/71,incubator-stormcrawler,55266706,71,Pre-release tasks,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-01-23T10:30:40Z,2015-01-28T16:32:26Z,"- Apply formatting to the whole code
- update README file to include `core` in paths and jar names
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/71/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/71,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxMTk4NTc1,incubator-stormcrawler,71198575,71,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-01-23T14:17:04Z,2015-01-23T14:17:04Z,"I'll tackle the documentation
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxMTk4NTc1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/71,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxMTk4ODAy,incubator-stormcrawler,71198802,71,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-23T14:18:32Z,2015-01-23T14:18:32Z,"I already updated README 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxMTk4ODAy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/71,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxMjAxNzE1,incubator-stormcrawler,71201715,71,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-01-23T14:38:21Z,2015-01-23T14:38:21Z,"Should we illustrate using `storm-crawler-core` and `storm-crawler-external` as separate maven dependencies?

Also, I was going to create READMEs for each submodule
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxMjAxNzE1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/71,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxMjAyMDcx,incubator-stormcrawler,71202071,71,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-23T14:40:53Z,2015-01-23T14:40:53Z,"Maybe let's just mention -external and show how to use it in Maven. I don't think we need separate READMEs, there isn't much to say about external.
What we should do is have a separate WIKI page describing the resources in external. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxMjAyMDcx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/71,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxMzc0NDEx,incubator-stormcrawler,71374411,71,NA,GuiForget,2585258,Gui Forget,,NA,2015-01-25T14:06:16Z,2015-01-25T14:06:16Z,"I submitted a PR which cleans up the code
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxMzc0NDEx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/71,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxMzc0NzE3,incubator-stormcrawler,71374717,71,NA,GuiForget,2585258,Gui Forget,,NA,2015-01-25T14:16:51Z,2015-01-25T14:16:51Z,"The javadoc issue is also fixed. I'm now able to run `mvn package -P release` without any errors
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxMzc0NzE3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/71,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxNDM5MjMw,incubator-stormcrawler,71439230,71,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-26T10:16:21Z,2015-01-26T10:16:21Z,"thanks, will release shortly
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxNDM5MjMw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/71,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxNDcxMjIx,incubator-stormcrawler,71471221,71,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-01-26T14:48:22Z,2015-01-26T14:48:22Z,"Yep `mvn package -P release` builds the javadocs without any errors. :+1:
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxNDcxMjIx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/71,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxODIxNDYz,incubator-stormcrawler,71821463,71,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-28T11:44:38Z,2015-01-28T11:44:38Z,"The release candidate for 0.4 can be found on :
[https://oss.sonatype.org/content/repositories/comdigitalpebble-1007/com/digitalpebble/]

@DigitalPebble/committers-crawler please have a look at it and confirm that it can be released. 

I opened #76 but this can be done for the next release I think. Thanks!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxODIxNDYz/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/71,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxODIxNzQw,incubator-stormcrawler,71821740,71,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-28T11:46:12Z,2015-01-28T11:46:12Z,"Note that a release tag has already been created [https://github.com/DigitalPebble/storm-crawler/releases/tag/0.4] and the versions have been upped automatically in the code but we can revert to the previous values if you find something serious and we need to spin a new RC.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxODIxNzQw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/71,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxODY2MjY0,incubator-stormcrawler,71866264,71,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-28T16:32:26Z,2015-01-28T16:32:26Z,"Have published the release, the artefacts will be in Maven Central soon. Let's do a 0.4.1 if we find that something is wrong.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxODY2MjY0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/72,https://api.github.com/repos/apache/incubator-stormcrawler/issues/72,incubator-stormcrawler,55279612,72,Missing transitive dependencies,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-01-23T13:10:02Z,2015-01-23T13:26:15Z,"Since refactoring the sources in to core and external, any project declaring SC as a dependency is not getting org.jdom or crawler-commons as transitive dependencies. I am pretty certain this was the case before.

@jakekdodd any idea? 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/72/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/72,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxMTkyNTQw,incubator-stormcrawler,71192540,72,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-23T13:26:15Z,2015-01-23T13:26:15Z,"Apologies. It works fine when declaring -core as a dependency. The confusion came from the fact that the parent POM generates a 'storm-crawler' item as well which does not have all the dependencies.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxMTkyNTQw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/75,https://api.github.com/repos/apache/incubator-stormcrawler/issues/75,incubator-stormcrawler,55743711,75,Document URLFilters and their configuration,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-01-28T11:19:20Z,2015-05-20T11:40:38Z,"Have a separate WIKI page for that
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/75/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/75,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc0MjQzODM5,incubator-stormcrawler,74243839,75,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-02-13T12:02:17Z,2015-02-13T12:02:17Z,"See [https://github.com/DigitalPebble/storm-crawler/wiki/URLFilters]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc0MjQzODM5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/76,https://api.github.com/repos/apache/incubator-stormcrawler/issues/76,incubator-stormcrawler,55745632,76,Fix release artefacts,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-01-28T11:39:00Z,2015-01-31T15:56:34Z,"The release is done with the following commands :

mvn release:clean release:prepare -P release
mvn release:perform -P release

Since refactoring into core and external I am seeing the following 

_uber-jar published for core_ 

.../content/com/digitalpebble/storm-crawler-core/0.4/storm-crawler-core-0.4-jar-with-dependencies.jar

which should not have happened since I specify the 'release' profile.

_generated tests for parent pom_ 

.../com/digitalpebble/storm-crawler/0.4/storm-crawler-0.4-tests.jar

which should not have happened.

Any ideas? I will release 0.4 with these but it would be good to fix that for the next release
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/76/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/76,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxODIwOTI1,incubator-stormcrawler,71820925,76,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-01-28T11:41:20Z,2015-01-28T11:41:20Z,"and maybe rename the parent pom into 'storm-crawler-parent' to prevent any confusion as 'storm-crawler' used to contain the code but does not anymore
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxODIwOTI1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/76,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxODM4MzIw,incubator-stormcrawler,71838320,76,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-01-28T13:58:45Z,2015-01-28T13:58:45Z,"Should be easy fixes, I'll get on that.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxODM4MzIw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/76,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcyMzIzMTc1,incubator-stormcrawler,72323175,76,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-01-31T15:56:34Z,2015-01-31T15:56:34Z,"Addressed in #80 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcyMzIzMTc1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/79,https://api.github.com/repos/apache/incubator-stormcrawler/issues/79,incubator-stormcrawler,55883471,79,SimpleFetcherBolt should use status stream to report error,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-01-29T10:43:50Z,2015-01-31T15:50:45Z,"@jakekdodd want to take care of this one?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/79/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/79,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcyMzIyOTQ1,incubator-stormcrawler,72322945,79,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-01-31T15:50:45Z,2015-01-31T15:50:45Z,"Addressed in e1ab315d39ca2d5919049fb0b36da184a2aefc18
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcyMzIyOTQ1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/83,https://api.github.com/repos/apache/incubator-stormcrawler/issues/83,incubator-stormcrawler,56129135,83,Metadata emitted in fetcher,jakekdodd,6845693,Jake K. Dodd,,CLOSED,2015-01-31T15:55:44Z,2015-05-20T11:40:38Z,"I noticed that, in some places, we emit `response.getMetadata()` and in other places, we emit `metadata` within FetcherBolt and SimpleFetcherBolt.

The `response.getMetadata()` includes all of the original tuple `metadata` (if extant). Is there a reason for emitting only the original tuple `metadata` in some situations? Particularly when emitting to the status stream, it might be beneficial downstream to do something with the HTTP response metadata.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/83/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/83,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMDQ0NDQ1,incubator-stormcrawler,73044445,83,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-02-05T13:19:18Z,2015-02-05T13:19:18Z,"+1
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMDQ0NDQ1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/83,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMTU1OTA2,incubator-stormcrawler,73155906,83,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-02-05T23:56:43Z,2015-02-05T23:56:43Z,"Addressed by 160b9d4dbe850e0f9dfa57f7a9e5253568282d54
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMTU1OTA2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/85,https://api.github.com/repos/apache/incubator-stormcrawler/issues/85,incubator-stormcrawler,56319587,85,URLPartitionerBolt to partition on arbitrary metadata value,jnioche,218319,Julien Nioche,julien@digitalpebble.com,OPEN,2015-02-03T01:15:05Z,2015-02-03T01:15:05Z,"Not a top priority issue but something to keep in mind for later.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/85/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/86,https://api.github.com/repos/apache/incubator-stormcrawler/issues/86,incubator-stormcrawler,56438935,86,Use a single MultiCountMetric in FetcherBolt,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-02-03T21:20:14Z,2015-10-14T16:19:56Z,"[https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/storm/crawler/bolt/FetcherBolt.java#L87]

they are of the same nature, why use 2?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/86/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/86,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcyNzUyODEx,incubator-stormcrawler,72752811,86,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-02-03T22:48:22Z,2015-02-03T22:48:22Z,"Actually they could be of a different nature. one is used for counters while the other is used for gauges. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcyNzUyODEx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/86,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0ODEwNDczMQ==,incubator-stormcrawler,148104731,86,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-10-14T16:19:56Z,2015-10-14T16:19:56Z,"Implemented gauges in [8ccd8a64115cdf7d823b7bd2bde3510d77e88a25] with a better mechanism.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0ODEwNDczMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/87,https://api.github.com/repos/apache/incubator-stormcrawler/issues/87,incubator-stormcrawler,56739871,87,NotSerializableException for Metadata,jakekdodd,6845693,Jake K. Dodd,,CLOSED,2015-02-05T22:27:58Z,2015-05-20T11:40:38Z,"Getting `NotSerializableException: com.digitalpebble.storm.crawler.Metadata` when running CrawlTopology on the master branch. For reference, I'm running the topology in local mode using maven exec.

I'm 99.99% sure that Metadata just needs to implement Serializable (this solves the problem for me). Just wanted to check if CrawlTopology was successfully executing for anyone else after the most recent commits.

Stack trace:

```
15352 [Thread-17-disruptor-executor[6 6]-send-queue] ERROR backtype.storm.util - Async loop died!
java.lang.RuntimeException: java.lang.RuntimeException: java.io.NotSerializableException: com.digitalpebble.storm.crawler.Metadata
    at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:128) ~[storm-core-0.9.3.jar:0.9.3]
    at backtype.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:99) ~[storm-core-0.9.3.jar:0.9.3]
    at backtype.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:80) ~[storm-core-0.9.3.jar:0.9.3]
    at backtype.storm.disruptor$consume_loop_STAR_$fn__1460.invoke(disruptor.clj:94) ~[storm-core-0.9.3.jar:0.9.3]
    at backtype.storm.util$async_loop$fn__464.invoke(util.clj:463) ~[storm-core-0.9.3.jar:0.9.3]
    at clojure.lang.AFn.run(AFn.java:24) [clojure-1.5.1.jar:na]
    at java.lang.Thread.run(Thread.java:745) [na:1.7.0_55]
Caused by: java.lang.RuntimeException: java.io.NotSerializableException: com.digitalpebble.storm.crawler.Metadata
    at backtype.storm.serialization.SerializableSerializer.write(SerializableSerializer.java:41) ~[storm-core-0.9.3.jar:0.9.3]
    at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:568) ~[kryo-2.21.jar:na]
    at com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:75) ~[kryo-2.21.jar:na]
    at com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:18) ~[kryo-2.21.jar:na]
    at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:486) ~[kryo-2.21.jar:na]
    at backtype.storm.serialization.KryoValuesSerializer.serializeInto(KryoValuesSerializer.java:44) ~[storm-core-0.9.3.jar:0.9.3]
    at backtype.storm.serialization.KryoTupleSerializer.serialize(KryoTupleSerializer.java:44) ~[storm-core-0.9.3.jar:0.9.3]
    at backtype.storm.daemon.worker$mk_transfer_fn$fn__3549.invoke(worker.clj:129) ~[storm-core-0.9.3.jar:0.9.3]
    at backtype.storm.daemon.executor$start_batch_transfer__GT_worker_handler_BANG_$fn__3283.invoke(executor.clj:258) ~[storm-core-0.9.3.jar:0.9.3]
    at backtype.storm.disruptor$clojure_handler$reify__1447.onEvent(disruptor.clj:58) ~[storm-core-0.9.3.jar:0.9.3]
    at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:125) ~[storm-core-0.9.3.jar:0.9.3]
    ... 6 common frames omitted
Caused by: java.io.NotSerializableException: com.digitalpebble.storm.crawler.Metadata
    at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1183) ~[na:1.7.0_55]
    at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347) ~[na:1.7.0_55]
    at backtype.storm.serialization.SerializableSerializer.write(SerializableSerializer.java:38) ~[storm-core-0.9.3.jar:0.9.3]
    ... 16 common frames omitted
15353 [Thread-17-disruptor-executor[6 6]-send-queue] ERROR backtype.storm.daemon.executor - 
java.lang.RuntimeException: java.lang.RuntimeException: java.io.NotSerializableException: com.digitalpebble.storm.crawler.Metadata
    at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:128) ~[storm-core-0.9.3.jar:0.9.3]
    at backtype.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:99) ~[storm-core-0.9.3.jar:0.9.3]
    at backtype.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:80) ~[storm-core-0.9.3.jar:0.9.3]
    at backtype.storm.disruptor$consume_loop_STAR_$fn__1460.invoke(disruptor.clj:94) ~[storm-core-0.9.3.jar:0.9.3]
    at backtype.storm.util$async_loop$fn__464.invoke(util.clj:463) ~[storm-core-0.9.3.jar:0.9.3]
    at clojure.lang.AFn.run(AFn.java:24) [clojure-1.5.1.jar:na]
    at java.lang.Thread.run(Thread.java:745) [na:1.7.0_55]
Caused by: java.lang.RuntimeException: java.io.NotSerializableException: com.digitalpebble.storm.crawler.Metadata
    at backtype.storm.serialization.SerializableSerializer.write(SerializableSerializer.java:41) ~[storm-core-0.9.3.jar:0.9.3]
    at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:568) ~[kryo-2.21.jar:na]
    at com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:75) ~[kryo-2.21.jar:na]
    at com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:18) ~[kryo-2.21.jar:na]
    at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:486) ~[kryo-2.21.jar:na]
    at backtype.storm.serialization.KryoValuesSerializer.serializeInto(KryoValuesSerializer.java:44) ~[storm-core-0.9.3.jar:0.9.3]
    at backtype.storm.serialization.KryoTupleSerializer.serialize(KryoTupleSerializer.java:44) ~[storm-core-0.9.3.jar:0.9.3]
    at backtype.storm.daemon.worker$mk_transfer_fn$fn__3549.invoke(worker.clj:129) ~[storm-core-0.9.3.jar:0.9.3]
    at backtype.storm.daemon.executor$start_batch_transfer__GT_worker_handler_BANG_$fn__3283.invoke(executor.clj:258) ~[storm-core-0.9.3.jar:0.9.3]
    at backtype.storm.disruptor$clojure_handler$reify__1447.onEvent(disruptor.clj:58) ~[storm-core-0.9.3.jar:0.9.3]
    at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:125) ~[storm-core-0.9.3.jar:0.9.3]
    ... 6 common frames omitted
Caused by: java.io.NotSerializableException: com.digitalpebble.storm.crawler.Metadata
    at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1183) ~[na:1.7.0_55]
    at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347) ~[na:1.7.0_55]
    at backtype.storm.serialization.SerializableSerializer.write(SerializableSerializer.java:38) ~[storm-core-0.9.3.jar:0.9.3]
    ... 16 common frames omitted
Disconnected from the target VM, address: '127.0.0.1:49418', transport: 'socket'
15370 [Thread-17-disruptor-executor[6 6]-send-queue] ERROR backtype.storm.util - Halting process: (""Worker died"")
java.lang.RuntimeException: (""Worker died"")
    at backtype.storm.util$exit_process_BANG_.doInvoke(util.clj:325) [storm-core-0.9.3.jar:0.9.3]
    at clojure.lang.RestFn.invoke(RestFn.java:423) [clojure-1.5.1.jar:na]
    at backtype.storm.daemon.worker$fn__3808$fn__3809.invoke(worker.clj:452) [storm-core-0.9.3.jar:0.9.3]
    at backtype.storm.daemon.executor$mk_executor_data$fn__3274$fn__3275.invoke(executor.clj:240) [storm-core-0.9.3.jar:0.9.3]
    at backtype.storm.util$async_loop$fn__464.invoke(util.clj:473) [storm-core-0.9.3.jar:0.9.3]
    at clojure.lang.AFn.run(AFn.java:24) [clojure-1.5.1.jar:na]
    at java.lang.Thread.run(Thread.java:745) [na:1.7.0_55]

Process finished with exit code 1
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/87/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/87,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMTQ1MTAw,incubator-stormcrawler,73145100,87,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-02-05T22:37:26Z,2015-02-05T22:37:26Z,"You are not using the [ConfigurableTopology](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/storm/crawler/ConfigurableTopology.java#L58)?
This adds `Config.registerSerialization(conf, Metadata.class);` to the config, which is needed for the Metadata to work.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMTQ1MTAw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/87,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMTQ1OTQw,incubator-stormcrawler,73145940,87,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-02-05T22:42:19Z,2015-02-05T22:42:19Z,"CrawlTopology extends ConfigurableTopology, so at first glance the serialization registration should be taken care of. I'll take a closer look.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMTQ1OTQw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/87,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMTQ2MTMy,incubator-stormcrawler,73146132,87,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-02-05T22:43:28Z,2015-02-05T22:43:28Z,"There it is...the registration only happens when not running in local mode.

``` java
 if (isLocal) {
            LocalCluster cluster = new LocalCluster();
            cluster.submitTopology(name, conf, builder.createTopology());
        }

        else {
            // register Metadata for serialization with FieldsSerializer
            Config.registerSerialization(conf, Metadata.class);
            try {
                StormSubmitter.submitTopology(name, conf,
                        builder.createTopology());
            } catch (Exception e) {
                e.printStackTrace();
                return -1;
            }
        }
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMTQ2MTMy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/87,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMTQ2NTE0,incubator-stormcrawler,73146514,87,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-02-05T22:45:54Z,2015-02-05T22:45:54Z,"Sorry read your email too quickly, should have seen that you were using
CrawlTopology. Weird, I thought the serialization happened only in
distributed mode. Good catch! do you want to patch it or shall I?
Is there another place we should put this in, in case people don't use
ConfigurableTopology?

On 5 February 2015 at 14:43, Jake Dodd notifications@github.com wrote:

> There it is...the registration only happens when not running in local mode.
> 
>  if (isLocal) {
>             LocalCluster cluster = new LocalCluster();
>             cluster.submitTopology(name, conf, builder.createTopology());
>         }
> 
> ```
>     else {
>         // register Metadata for serialization with FieldsSerializer
>         Config.registerSerialization(conf, Metadata.class);
>         try {
>             StormSubmitter.submitTopology(name, conf,
>                     builder.createTopology());
>         } catch (Exception e) {
>             e.printStackTrace();
>             return -1;
>         }
>     }
> ```
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/DigitalPebble/storm-crawler/issues/87#issuecomment-73146132
> .

## 
- Open Source Solutions for Text Engineering   http://www.digitalpebble.com
  http://www.digitalpebble.com*
  _http://digitalpebble.blogspot.com http://digitalpebble.blogspot.com/_
  https://twitter.com/digitalpebble
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMTQ2NTE0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/87,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMTQ3NDYw,incubator-stormcrawler,73147460,87,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-02-05T22:52:28Z,2015-02-05T22:52:28Z,"Yeah I'll look into moving the registration somewhere else and then patch it...at the very least, we can document the fact that a user must manually register Metadata for serialization if they choose to not extend ConfigurableTopology
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMTQ3NDYw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/87,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMTUwMzQ2,incubator-stormcrawler,73150346,87,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-02-05T23:11:59Z,2015-02-05T23:11:59Z,"Patched in 2cb21606d5fae54670922d9897d1938f4388803a.

Will make a new issue for documenting the Metadata registration when not using ConfigurableTopology
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMTUwMzQ2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/88,https://api.github.com/repos/apache/incubator-stormcrawler/issues/88,incubator-stormcrawler,56745200,88,Documenting Metadata registration,jakekdodd,6845693,Jake K. Dodd,,CLOSED,2015-02-05T23:14:18Z,2015-05-12T15:26:18Z,"A user building a topology that doesn't extend ConfigurableTopology will need to manually register Metadata for serialization.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/88/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/88,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMTMyMDE2Mg==,incubator-stormcrawler,101320162,88,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-05-12T15:26:18Z,2015-05-12T15:26:18Z,"[Done](https://github.com/DigitalPebble/storm-crawler/wiki/Registering-Metadata-for-Serialization)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMTMyMDE2Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/89,https://api.github.com/repos/apache/incubator-stormcrawler/issues/89,incubator-stormcrawler,56750964,89,Concurrency issue with ProtocolFactory,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-02-06T00:15:16Z,2015-05-20T11:40:38Z,"I've just found that when looking at the code with Pradan, [ProtocolFactory](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/storm/crawler/protocol/ProtocolFactory.java) caches the Protocol instances so there is exactly one instance within a ProtocolFactory. 

In the FetcherBolt we have a single instance of ProtocolFactory, which is used by all the threads concurrently. The method  getProtocolOutput in the HTTP [protocol](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/storm/crawler/protocol/http/HttpProtocol.java#L205) could be called concurrently. Any shared state like `ifModifiedSince` could then become corrupted.

Pradhan will write a test class to illustrate the issue. We could sync the method but that would create a bottleneck. A simpler approach would be for the ProtocolFactory to create a new instance of the protocol for every request, it might be inexpensive to do so.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/89/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/89,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMTU4MDM4,incubator-stormcrawler,73158038,89,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-02-06T00:15:52Z,2015-02-06T00:15:52Z,"ifModifiedSince could be handled within the HttpResponse instead.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMTU4MDM4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/89,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMTYyNTc4,incubator-stormcrawler,73162578,89,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-02-06T00:59:53Z,2015-02-06T00:59:53Z,"Whoops, that's definitely an oversight on my part in implementing `ifModifiedSince`.

One option would be to overload the `HttpResponse` constructor, like:

``` java
// If-Modified-Since not in metadata
HttpResponse response = new HttpResponse(this, u)

// If-Modified-Since in metadata
HttpResponse response = new HttpResponse(this, u, ifModifiedSince)
```

But I have a sneaking suspicion that, eventually, we'll have other metadata-dependent behaviors for HttpResponse (Gui's ETag example, for instance). So if we're going to overload the constructor, the third argument should probably be the `knownMetadata`; HttpResponse would then be responsible for checking the metadata for behavior-driving keys. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMTYyNTc4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/89,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMjUzNzcw,incubator-stormcrawler,73253770,89,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-02-06T15:29:22Z,2015-02-06T15:29:22Z,"+1 to passing the metadata. do you have time to fix this?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMjUzNzcw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/89,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMjg5NDEy,incubator-stormcrawler,73289412,89,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-02-06T18:40:04Z,2015-02-06T18:40:04Z,"Yep no problem, will be able to tackle it this evening

> On Feb 6, 2015, at 07:29, Julien Nioche notifications@github.com wrote:
> 
> +1 to passing the metadata. do you have time to fix this?
> 
> —
> Reply to this email directly or view it on GitHub.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMjg5NDEy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/89,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMjkzMzQ4,incubator-stormcrawler,73293348,89,NA,pradhanbu,5661085,Pradhan Bagur Umesh,,NA,2015-02-06T19:03:05Z,2015-02-06T19:03:05Z,"Jake, I am writing a test case for this. If its fine with you I can sneak
in the fix along with that.

On Fri, Feb 6, 2015 at 10:40 AM, Jake Dodd notifications@github.com wrote:

> Yep no problem, will be able to tackle it this evening
> 
> > On Feb 6, 2015, at 07:29, Julien Nioche notifications@github.com
> > wrote:
> > 
> > +1 to passing the metadata. do you have time to fix this?
> > 
> > —
> > Reply to this email directly or view it on GitHub.
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/DigitalPebble/storm-crawler/issues/89#issuecomment-73289412
> .
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMjkzMzQ4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/89,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMjk1NjE1,incubator-stormcrawler,73295615,89,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-02-06T19:16:43Z,2015-02-06T19:16:43Z,"Yes absolutely!

> On Feb 6, 2015, at 11:03, Pradhan Bagur Umesh notifications@github.com wrote:
> 
> Jake, I am writing a test case for this. If its fine with you I can sneak
> in the fix along with that.
> 
> On Fri, Feb 6, 2015 at 10:40 AM, Jake Dodd notifications@github.com wrote:
> 
> > Yep no problem, will be able to tackle it this evening
> > 
> > > On Feb 6, 2015, at 07:29, Julien Nioche notifications@github.com
> > > wrote:
> > > 
> > > +1 to passing the metadata. do you have time to fix this?
> > > 
> > > —
> > > Reply to this email directly or view it on GitHub.
> > 
> > —
> > Reply to this email directly or view it on GitHub
> > https://github.com/DigitalPebble/storm-crawler/issues/89#issuecomment-73289412
> > .
> > 
> > —
> > Reply to this email directly or view it on GitHub.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMjk1NjE1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/89,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMzE4MDI1,incubator-stormcrawler,73318025,89,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-02-06T21:43:27Z,2015-02-06T21:43:27Z,"Fixed by Pradhan in #90 
Thanks!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMzE4MDI1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/92,https://api.github.com/repos/apache/incubator-stormcrawler/issues/92,incubator-stormcrawler,58082279,92,[ElasticSearch] Spout for reading URLs from status index,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-02-18T15:29:29Z,2015-05-20T11:40:38Z,"I wrote a StatusUpdaterBolt [master eb5bf73] for ElasticSearch which would be perfectly complemented by a Spout. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/92/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/93,https://api.github.com/repos/apache/incubator-stormcrawler/issues/93,incubator-stormcrawler,58082579,93,Add cache to AbstractStatusUpdaterBolt,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-02-18T15:31:29Z,2015-05-20T11:40:38Z,"The AbstractStatusUpdaterBolt [1f7e546] should help writing bolts to store the status of URLs. I will add an internal cache so that URLs which are already known do not get written as DISCOVERED every time. The cache should be configurable from the usual Storm config. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/93/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/93,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc0ODk5MjUy,incubator-stormcrawler,74899252,93,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-02-18T16:48:51Z,2015-02-18T16:48:51Z,"Implemented in [master 7d1f2dd]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc0ODk5MjUy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/96,https://api.github.com/repos/apache/incubator-stormcrawler/issues/96,incubator-stormcrawler,58891351,96,Track target of redirection,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-02-25T12:05:58Z,2016-04-20T11:48:57Z,"We should store the target of a redirection in the metadata of the redirected URL, regardless of whether the target gets filtered or not.  This will make it easier to debug the behaviour of the Fetcher  
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/96/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/96,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4OTIxMjg0OQ==,incubator-stormcrawler,189212849,96,NA,wombat,571379,Daniel Sachse,mail@wombatsoftware.de,NA,2016-02-26T10:40:17Z,2016-02-26T10:40:17Z,"Yes this sounds good to me - we could need this in our analysis platform. How would you like to store this information in the metadata?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4OTIxMjg0OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/96,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIxMjM5Mzk2Mw==,incubator-stormcrawler,212393963,96,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-04-20T11:48:57Z,2016-04-20T11:48:57Z,"Implemented. Using the key `_redirTo` to track the value of the redirection.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIxMjM5Mzk2Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/97,https://api.github.com/repos/apache/incubator-stormcrawler/issues/97,incubator-stormcrawler,58909324,97,How to write a nice manual for SC?,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-02-25T14:30:49Z,2016-09-20T08:41:20Z,"Use [https://www.gitbook.com/]? 
Just the WIKI?
[asciidoc](http://www.methods.co.nz/asciidoc/)?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/97/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/97,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0NjQ4NDU3NQ==,incubator-stormcrawler,146484575,97,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-10-08T10:11:34Z,2015-10-08T10:11:34Z,"[https://readthedocs.org/]?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0NjQ4NDU3NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/97,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1NjI0NjU3Mg==,incubator-stormcrawler,156246572,97,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-11-12T21:48:43Z,2015-11-12T21:48:43Z,"It would be good to have a specific website for storm-crawler, similar to :
- [Scrapy](http://scrapy.org/)
- [phantomjs](http://phantomjs.org/)
- [https://horizon.io/](https://horizon.io/)

Both are hosted on [GitHub pages](https://pages.github.com/) and use [Jekyll](http://jekyllrb.com/) 
- [https://github.com/scrapy/scrapy.org]
- [https://github.com/ariya/phantomjs/tree/gh-pages]

OTHER RESOURCES
- [Bootstrap](http://getbootstrap.com/)
- [Middleman](https://middlemanapp.com)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1NjI0NjU3Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/97,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1OTk2OTQzOQ==,incubator-stormcrawler,159969439,97,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-11-26T17:55:12Z,2015-11-26T17:55:12Z,"[http://digitalpebble.github.io/storm-crawler] is now live and hosted by GitHub, the content is in the branch  [gh-pages](https://github.com/DigitalPebble/storm-crawler/tree/gh-pages)

The domain [stormcrawler.net](http://stormcrawler.net) redirects to it.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1OTk2OTQzOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/99,https://api.github.com/repos/apache/incubator-stormcrawler/issues/99,incubator-stormcrawler,59489248,99,JSON stringifying metadata keys,jakekdodd,6845693,Jake K. Dodd,,CLOSED,2015-03-02T14:40:03Z,2015-05-20T11:40:38Z,"Was adding support for ETags in HttpResponse when I realized that, when using If-Modified-Since, it's looking for a metadata key actually named 'If-Modified-Since.' I think I originally did this for consistency, but now it seems like a bad idea. First because we're normalizing HTTP headers (so 'if-modified-since' would be better). But more importantly, I think these behavior-changing metadata keys should be JSON compatible. A common use case will be to deserialize known metadata within or directly downstream from the spout, and JSON-compliant key names will be required for many spout types. So, 'ifModifiedSince,' and the ETag key would be 'ifNoneMatch.' 

It's a super simple fix, but because it's changing the contract, I wanted to run it by you guys first.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/99/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/99,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc2NzI4NTE1,incubator-stormcrawler,76728515,99,NA,GuiForget,2585258,Gui Forget,,NA,2015-03-02T15:12:51Z,2015-03-02T15:12:51Z,"No using the same key as the HTTP Header makes more sense to me. To me the key names should reflect what the data is, maybe something like ""cachedEtag"" and ""cachedTimestamp"". 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc2NzI4NTE1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/99,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc2NzMxMDIx,incubator-stormcrawler,76731021,99,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-03-02T15:25:19Z,2015-03-02T15:25:19Z,"That's the idea with ifModifiedSince and ifNoneMatch, but they're using the request header names. Using the response names would be totally OK, too. In that case, cachedEtag and cachedLastModified
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc2NzMxMDIx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/99,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc2NzM0Mjkz,incubator-stormcrawler,76734293,99,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-03-02T15:41:40Z,2015-03-02T15:41:40Z,"Now that I think about it, I like using the response field names more because they do describe the data better, from a user's perspective. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc2NzM0Mjkz/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/99,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3MTYzMjA5,incubator-stormcrawler,77163209,99,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-03-04T14:08:33Z,2015-03-04T14:08:33Z,"Committed in 2c207eefd0522146de5e345ad45edfa11bc02596, need to modify the wiki now
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3MTYzMjA5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/99,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3MTYzODM5,incubator-stormcrawler,77163839,99,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-03-04T14:12:23Z,2015-03-04T14:12:23Z,"Wiki has been updated
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3MTYzODM5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/102,https://api.github.com/repos/apache/incubator-stormcrawler/issues/102,incubator-stormcrawler,59777549,102,Customisable/pluggable MetadataTransfer,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-03-04T10:25:04Z,2015-05-20T11:40:38Z,"We currently have a hardwired, one-size-fits-all MetadataTransfer class. It would be good to be able to define user-specific ones and have them used in the same way regardless of which parser class calls them. These user-defined classes would extend the behaviour of MetadataTransfer.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/102/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/103,https://api.github.com/repos/apache/incubator-stormcrawler/issues/103,incubator-stormcrawler,59778930,103,"Change signature for MetadataTransfer getMetaForOutlink(String sourceURL, Metadata parentMD)",jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-03-04T10:37:43Z,2015-05-20T11:40:38Z,"It would probably make sense to add the targetURL to the method so that the creation of metadata could take that URL into account.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/103/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/104,https://api.github.com/repos/apache/incubator-stormcrawler/issues/104,incubator-stormcrawler,59785789,104,Customisable/pluggable Scheduler instances,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-03-04T11:33:18Z,2016-02-09T21:46:44Z,"We have a default Scheduler implementation and the corresponding interface. We now need a utility class which would allow users to plug their own implementation of Scheduler via the config. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/104/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/104,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4MjA5MTQyNw==,incubator-stormcrawler,182091427,104,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-02-09T21:46:44Z,2016-02-09T21:46:44Z,"Implemented in #245 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4MjA5MTQyNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/105,https://api.github.com/repos/apache/incubator-stormcrawler/issues/105,incubator-stormcrawler,60111428,105,Add remove(String key) method to Metadata ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-03-06T14:54:04Z,2015-05-20T11:40:38Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/105/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/106,https://api.github.com/repos/apache/incubator-stormcrawler/issues/106,incubator-stormcrawler,60320283,106,[Maven] publish src as artefacts,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-03-09T09:55:40Z,2015-05-11T10:58:04Z,"I don't think we publish the src code in a jar as part of the artefacts, do we?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/106/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/106,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc4NDY2MjAy,incubator-stormcrawler,78466202,106,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-03-12T11:53:06Z,2015-03-12T11:53:06Z,"have assigned the issue to you as you are our maven expert ;-)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc4NDY2MjAy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/106,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgxNjkwNjY4,incubator-stormcrawler,81690668,106,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-03-16T14:14:23Z,2015-03-16T14:14:23Z,"""expert"" :)

I'll get on this
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgxNjkwNjY4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/106,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMDg2ODcwNA==,incubator-stormcrawler,100868704,106,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-05-11T10:58:04Z,2015-05-11T10:58:04Z,"We actually do [http://search.maven.org/#search%7Cga%7C1%7Cstorm%20crawler]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMDg2ODcwNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/107,https://api.github.com/repos/apache/incubator-stormcrawler/issues/107,incubator-stormcrawler,60806460,107,Emit status Fetched if server returns a 304,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-03-12T11:43:22Z,2015-05-20T11:40:38Z,"It is currently handled as a redirection. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/107/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/108,https://api.github.com/repos/apache/incubator-stormcrawler/issues/108,incubator-stormcrawler,60806558,108,Normalise HTTP headers,jnioche,218319,Julien Nioche,julien@digitalpebble.com,OPEN,2015-03-12T11:44:13Z,2015-04-22T12:16:10Z,"Port SpellCheckedMetadata from Nutch to cater for variations returned by servers
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/108/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/108,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDk1MTUzNTg5,incubator-stormcrawler,95153589,108,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-04-22T12:16:10Z,2015-04-22T12:16:10Z,"Note : should probably reuse org.apache.http.HttpHeaders instead of having our own version. Need to check whether the Apache http core library has any mechanism for  normalising the keys returned by a server.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDk1MTUzNTg5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/109,https://api.github.com/repos/apache/incubator-stormcrawler/issues/109,incubator-stormcrawler,60807331,109,Use metadata keys last-modified and etag,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-03-12T11:51:48Z,2016-07-04T13:17:21Z,"Allow their use globally via configuration as well as overriding the de/activation on a per URL basis with use.Etag or use.ModifiedSince.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/109/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/109,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIzMDI4ODQ0MQ==,incubator-stormcrawler,230288441,109,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-07-04T13:17:21Z,2016-07-04T13:17:21Z,"To use `etag` and `last-modified`, you now just need to specify 

```
 metadata.persist:
   - etag
   - last-modified
```

in the crawl configuration. This way, the key values will be persisted if returned by the server and used the next time round when querying it.

This can also be set on a per URL basis by setting the K/V in the metadata.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIzMDI4ODQ0MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/110,https://api.github.com/repos/apache/incubator-stormcrawler/issues/110,incubator-stormcrawler,61038256,110,Release 0.5,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-03-13T11:00:28Z,2015-05-27T15:20:00Z,"List the issues we want to include in the next release and do it
- [Maven] publish src as artefacts #106

@DigitalPebble/committers-crawler what else?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/110/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/110,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgxNjk3NTUy,incubator-stormcrawler,81697552,110,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-03-16T14:23:31Z,2015-03-16T14:23:31Z,"The boring stuff, documentation =/

So #88 and #51, and maybe open a new issue for other things to document. Let's rank-order and choose the top 5 items or so? I'd propose
1. Overview
2. FetcherBolt description
3. Parsing/outlink generation (#124)
4. Configuration
5. Streams (#51)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgxNjk3NTUy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/110,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkzOTk1NDU1,incubator-stormcrawler,93995455,110,NA,GuiForget,2585258,Gui Forget,,NA,2015-04-17T14:21:38Z,2015-04-17T14:21:38Z,"I'll take a stab at the parsing one
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkzOTk1NDU1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/110,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDk5MTQ5OTg4,incubator-stormcrawler,99149988,110,NA,rkrombho,198947,Robert Krombholz,,NA,2015-05-05T17:25:35Z,2015-05-05T17:25:35Z,"I'll try the Configuration one. May need some help and reviews for certain parameters as I don't yet understand all of them completely. Working on [my fork](https://github.com/rkrombho/storm-crawler/wiki/Configuration) and submit a PR when it's done.
I'll mark unclear parameters with ??? in the beginning of the description. They will require closer reviews by one of you.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDk5MTQ5OTg4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/110,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDk5MzkzNDQ5,incubator-stormcrawler,99393449,110,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-05-06T09:17:01Z,2015-05-06T09:17:01Z,"Hi @rkrombho. Thanks for volunteering! Let me know when you're done with it and I'll review. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDk5MzkzNDQ5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/110,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMDYyNTU4Nw==,incubator-stormcrawler,100625587,110,NA,rkrombho,198947,Robert Krombholz,,NA,2015-05-10T11:23:04Z,2015-05-10T11:23:04Z,"I'm pretty much done now with documenting Configuration options but it looks like I can't create pull-requests for wiki repositories.
https://github.com/rkrombho/storm-crawler/wiki/Configuration
(formating of the tables is not so nice)

Any proposal on how I should submit this to the project?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMDYyNTU4Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/110,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMDgxMjM3NA==,incubator-stormcrawler,100812374,110,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-05-11T08:21:01Z,2015-05-11T08:21:01Z,"Hi

You should be able to edit the WIKI directly. Just add the Configuration
page and create a link from the main page

Thanks

j.

On 10 May 2015 at 12:23, Robert Krombholz notifications@github.com wrote:

> I'm pretty much done now with documenting Configuration options but it
> looks like I can't create pull-requests for wiki repositories.
> https://github.com/rkrombho/storm-crawler/wiki/Configuration
> (formating of the tables is not so nice)
> 
> Any proposal on how I should submit this to the project?
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/DigitalPebble/storm-crawler/issues/110#issuecomment-100625587
> .

## 
- Open Source Solutions for Text Engineering   http://www.digitalpebble.com
  http://www.digitalpebble.com*
  _http://digitalpebble.blogspot.com http://digitalpebble.blogspot.com/_
  https://twitter.com/digitalpebble
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMDgxMjM3NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/110,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMDg3MDE4Mg==,incubator-stormcrawler,100870182,110,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-05-11T11:09:12Z,2015-05-11T11:09:12Z,"Here's what's left to do before we can release [0.5](https://github.com/DigitalPebble/storm-crawler/milestones/0.5)
- [ ] WIKI Overview (#131)  @jnioche
- [ ] WIKI FetcherBolt description (#132)
- [x] WIKI Parsing/outlink generation (#124) @GuiForget 
- [ ] Documenting Metadata registration (#88) @jakekdodd 

Moved to a future release :
- [x] Change XPath to take a list of regular expressions for a given key (#123) @GuiForget 
- [x] Resource files overridden by ones provided by default in SC (#61) @jnioche
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMDg3MDE4Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/110,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMTMyMDI4Mg==,incubator-stormcrawler,101320282,110,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-05-12T15:26:47Z,2015-05-12T15:26:47Z,"#88 is done
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMTMyMDI4Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/110,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMzg1MzA0Ng==,incubator-stormcrawler,103853046,110,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-05-20T11:37:28Z,2015-05-20T11:37:28Z,"Ok, so waiting for  @GuiForget to comment on #124 and should be OK to release after that
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMzg1MzA0Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/110,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwNTgxNDQzOA==,incubator-stormcrawler,105814438,110,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-05-27T08:15:29Z,2015-05-27T08:15:29Z,"no news from @GuiForget. Release 0.5 done
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwNTgxNDQzOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/110,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwNTk1Mjg4MA==,incubator-stormcrawler,105952880,110,NA,GuiForget,2585258,Gui Forget,,NA,2015-05-27T15:17:36Z,2015-05-27T15:17:36Z,"Sorry @jnioche I haven't had the time to look at this these past weeks. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwNTk1Mjg4MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/110,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwNTk1MzcyNg==,incubator-stormcrawler,105953726,110,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-05-27T15:20:00Z,2015-05-27T15:20:00Z,"no probs @GuiForget !It's just documentation it can be fixed anytime
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwNTk1MzcyNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/112,https://api.github.com/repos/apache/incubator-stormcrawler/issues/112,incubator-stormcrawler,64302624,112,[ElasticSearch] Indexer to extend AbstractIndexerBolt,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-03-25T15:45:32Z,2015-03-25T16:03:04Z,"[master 15a8ca7] introduced the AbstractIndexerBolt which uses the configuration to define what to send to an indexer

The Indexer we have in external for ES should extend this class so that we can configure which fields to send to the indexer via the configuration.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/112/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/114,https://api.github.com/repos/apache/incubator-stormcrawler/issues/114,incubator-stormcrawler,67098135,114,Use JSoupParserBolt in example topologies and move tika parser to external,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-04-08T10:23:03Z,2015-04-15T08:50:11Z,"[master 6a2d145] Added JSoupParserBolt (donated by Shopstyle)

which was the one in [https://github.com/PopSugar/storm-crawler-extensions/tree/master/jsoup-parser]

This should be used instead of the Tika-based one which is not a great option for HTML content.

The Tika parser should probably be moved to external : it has tons of dependencies and this would make the generated jars a lot lighter. It will still be available from external if people need to process non HTML documents.

@DigitalPebble/committers-crawler any thoughts on this?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/114/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/114,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkxMzYyNzE1,incubator-stormcrawler,91362715,114,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-04-09T21:36:01Z,2015-04-09T21:36:01Z,":+1:
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkxMzYyNzE1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/114,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkyMzAwMzIx,incubator-stormcrawler,92300321,114,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-04-13T10:14:36Z,2015-04-13T10:14:36Z,"Looks like we need  to have Xerces as a dependency because of `org/apache/html/dom/HTMLDocumentImpl` which is also used in the JSoupParser if we remove Tika. See [https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/storm/crawler/parse/JSoupDOMBuilder.java#L73]. 
We also need it for `org.apache.xml.serialize.XMLSerializer`
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkyMzAwMzIx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/117,https://api.github.com/repos/apache/incubator-stormcrawler/issues/117,incubator-stormcrawler,68075896,117,Parse could generate output for more than one document ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-04-13T11:36:40Z,2015-06-17T11:02:54Z,"At the moment we get a 1:1 relationship between the input and output of a parsing step. We could have a 1:N instead and more than one document in the output.

This is done in Nutch 1.x where the [ParseResult class](https://github.com/apache/nutch/blob/trunk/src/java/org/apache/nutch/parse/ParseResult.java) is a `Map<String,Parse>` with the [Parse](https://github.com/apache/nutch/blob/trunk/src/java/org/apache/nutch/parse/Parse.java) object containing the text and metadata for a URL.

This is useful for instance when a document can be split into subdocuments e.g. posts in a forum thread and we can't or don't want to fetch the subdocuments individually.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/117/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/117,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkyMzg1Mjc1,incubator-stormcrawler,92385275,117,NA,GuiForget,2585258,Gui Forget,,NA,2015-04-13T14:40:47Z,2015-04-13T14:40:47Z,":+1:  from me as we have product pages with multiple products on it
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkyMzg1Mjc1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/118,https://api.github.com/repos/apache/incubator-stormcrawler/issues/118,incubator-stormcrawler,68540309,118,URLs with escaped characters get double encoded by the BasicURLNormalizer,GuiForget,2585258,Gui Forget,,CLOSED,2015-04-15T01:12:23Z,2015-04-16T14:51:11Z,"http://www.dillards.com/product/ASICS-Womens-GT2000-3-LiteShow%E2%84%A2-Running-Shoes_301_-1_301_504736989

is normalized as 

http://www.dillards.com/product/ASICS-Womens-GT2000-3-LiteShow%25E2%2584%25A2-Running-Shoes_301_-1_301_504736989
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/118/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/120,https://api.github.com/repos/apache/incubator-stormcrawler/issues/120,incubator-stormcrawler,68583417,120,Should we normalize further the URLs,GuiForget,2585258,Gui Forget,,CLOSED,2015-04-15T05:50:14Z,2016-03-03T12:30:49Z,"Based on this page http://en.wikipedia.org/wiki/URL_normalization, I was wondering if should update BasicURLNormalizer to implements the first 2 sections.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/120/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/120,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkzNDI0ODcx,incubator-stormcrawler,93424871,120,NA,kkrugler,66217,Ken Krugler,ken@transpac.com,NA,2015-04-15T14:34:52Z,2015-04-15T14:34:52Z,"I believe the Nutch URL normalizer already does many of these. As well as what's in [Bixo](https://github.com/bixo/bixo/blob/master/src/main/java/bixo/urls/SimpleUrlNormalizer.java). And (of course) I'd recommend pushing that support down into crawler-commons :) No sense in having 8 versions of the same basic functionality.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkzNDI0ODcx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/120,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkzNzIwMDQy,incubator-stormcrawler,93720042,120,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-04-16T12:18:46Z,2015-04-16T12:18:46Z,"+1 to having that in BasicURLNormalizer via a standalone class that we could donate to crawler-commons. 
Our definition of a (URLFilter)[https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/storm/crawler/filtering/URLFilter.java] is probably richer than what we'd need in CC so a simple `public static String normalize(URL url)` would probably do. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkzNzIwMDQy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/120,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkzNzU0Njkz,incubator-stormcrawler,93754693,120,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-04-16T14:53:31Z,2015-04-16T14:53:31Z,"Just found about the handy normalise method in [URI](http://docs.oracle.com/javase/7/docs/api/java/net/URI.html#normalize%28%29). We should definitely add this one-liner to the normaliser
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkzNzU0Njkz/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/120,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkzODU2NTQ3,incubator-stormcrawler,93856547,120,NA,kkrugler,66217,Ken Krugler,ken@transpac.com,NA,2015-04-16T22:49:34Z,2015-04-16T22:49:34Z,"I've got a minor concern about using URL for the normalize() method parameter, and using the URI.normalize() method. When we were doing big web crawls, having to instantiate a URL class for each URL wound up generating a lot of GC activity.

This was typically only an issue (as a percentage of all object creation) when we had a map task that was just doing something simple with a URL...we'd get it as text, then have to create the URL to process it.  So we wound up creating our own custom class to implement some of the required functionality (extract query parameters, get the domain, etc).

Not sure if that's enough of a concern here, but when processing billions of anything it's easy to run into unexpected bottlenecks.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkzODU2NTQ3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/120,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkzOTQ0MzU0,incubator-stormcrawler,93944354,120,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-04-17T08:38:38Z,2015-04-17T08:38:38Z,"We could have a simple approach to begin with (using URI.normalize) and a more efficient one later on if it really becomes an issue. In the context of storm crawler, with all the stuff happening at the same time, I don't think the overhead of using URIs will be very noticeable. As you pointed out this might be different for more specific use cases if we do that in CC.

BTW Nutch has code based on ORO to do that [https://github.com/apache/nutch/blob/trunk/src/plugin/urlnormalizer-basic/src/java/org/apache/nutch/net/urlnormalizer/basic/BasicURLNormalizer.java]. We could benchmark it against using URI.normalize but I am pretty sure the latter will be faster, let alone easier to maintain and read. Of course, this does not mean it can't be done better without URIs.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkzOTQ0MzU0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/120,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDk0Mzg5NjE0,incubator-stormcrawler,94389614,120,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-04-20T08:17:37Z,2015-04-20T08:17:37Z,"FYI see [https://issues.apache.org/jira/browse/NUTCH-1990]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDk0Mzg5NjE0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/120,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDk0NTc5MjU4,incubator-stormcrawler,94579258,120,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2015-04-20T21:59:22Z,2015-04-20T21:59:22Z,"Has anyone tried [http://src.chromium.org/viewvc/chrome/trunk/src/url/]? There are [Python](https://pypi.python.org/pypi/python-google-url/) and [Perl](http://search.cpan.org/~mellery/URL-Google-GURL/lib/URL/Google/GURL.pm) bindings.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDk0NTc5MjU4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/120,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE5MTc0MDAzMw==,incubator-stormcrawler,191740033,120,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-03-03T12:29:39Z,2016-03-03T12:29:39Z,"[c9d0f01] lowercases the protocol and hostname
[3aa3391] URI normalise
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE5MTc0MDAzMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/123,https://api.github.com/repos/apache/incubator-stormcrawler/issues/123,incubator-stormcrawler,69147820,123,Change XPath to take a list of regular expressions for a given key,GuiForget,2585258,Gui Forget,,CLOSED,2015-04-17T14:20:10Z,2015-07-02T07:27:18Z,"Results would be a flatmap of the individual results
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/123/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/123,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkzOTk1MTg0,incubator-stormcrawler,93995184,123,NA,GuiForget,2585258,Gui Forget,,NA,2015-04-17T14:20:27Z,2015-04-17T14:20:27Z,"@jnioche does that make sense? I was thinking of working on that over the week-end
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkzOTk1MTg0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/123,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkzOTk2MTE1,incubator-stormcrawler,93996115,123,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-04-17T14:24:59Z,2015-04-17T14:24:59Z,"Do you mean have more than one xpath expression per label e.g. description below?

```
params"": {
        ""canonical"": ""//*[@rel=\""canonical\""]/@href"",
        ""description"": ""//*[@name=\""description\""]/@content""
      }
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkzOTk2MTE1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/123,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkzOTk2NTIy,incubator-stormcrawler,93996522,123,NA,GuiForget,2585258,Gui Forget,,NA,2015-04-17T14:27:03Z,2015-04-17T14:27:03Z,"Yeah. So I would change it to this:

```
params"": {
        ""canonical"": ""//*[@rel=\""canonical\""]/@href"",
        ""description"":  [""//*[@name=\""description\""]/@content"", ""//*[@name=\""other-description\""]/@content""]
 }
```

Basically single single string and list of string would be supported for backward compatibility
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkzOTk2NTIy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/123,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkzOTk4MzYw,incubator-stormcrawler,93998360,123,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-04-17T14:36:45Z,2015-04-17T14:36:45Z,"makes a lot of sense. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDkzOTk4MzYw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/123,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDExNzk0MTMwNQ==,incubator-stormcrawler,117941305,123,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-07-02T07:27:18Z,2015-07-02T07:27:18Z,"Implemented in #153 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDExNzk0MTMwNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/124,https://api.github.com/repos/apache/incubator-stormcrawler/issues/124,incubator-stormcrawler,69147932,124,Add/Improve documentation on parsing,GuiForget,2585258,Gui Forget,,CLOSED,2015-04-17T14:20:48Z,2015-05-26T10:44:22Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/124/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/124,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMzgwNzQyOQ==,incubator-stormcrawler,103807429,124,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-05-20T08:29:07Z,2015-05-20T08:29:07Z,"[https://github.com/DigitalPebble/storm-crawler/wiki/JSoupParserBolt] already describes the parsing bolt. We should have an additional wiki page for the ParseFilter. Apart from that what else did you have in mind @GuiForget?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMzgwNzQyOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/124,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMzg0MzQ4Nw==,incubator-stormcrawler,103843487,124,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-05-20T11:03:02Z,2015-05-20T11:03:02Z,"[https://github.com/DigitalPebble/storm-crawler/wiki/ParseFilters] done
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMzg0MzQ4Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/124,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMzg1MjQ3Nw==,incubator-stormcrawler,103852477,124,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-05-20T11:36:05Z,2015-05-20T11:36:05Z,"Have just added a description of [https://github.com/DigitalPebble/storm-crawler/wiki/MetadataTransfer].

@GuiForget please let me know if there is anything else you want to add
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMzg1MjQ3Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/124,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwNTQ4NTI0MQ==,incubator-stormcrawler,105485241,124,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-05-26T10:44:22Z,2015-05-26T10:44:22Z,"Closing. @GuiForget please reopen if necessary
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwNTQ4NTI0MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/126,https://api.github.com/repos/apache/incubator-stormcrawler/issues/126,incubator-stormcrawler,70848461,126,Remove fetchqueue stuff,jakekdodd,6845693,Jake K. Dodd,,CLOSED,2015-04-25T03:47:44Z,2015-05-20T11:40:38Z,"I think most, if not all, of the classes in that package are unused.

@jnioche do you have any clients that are using/examining those classes?

If not, should we remove everything outright? Or is there anything worth refactoring and keeping in the project?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/126/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/126,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDk2NTgwMTQy,incubator-stormcrawler,96580142,126,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-04-27T09:17:14Z,2015-04-27T09:17:14Z,"This is mostly old stuff dating from when I started work on SC. I can't remember myself how it is meant to be used and I don't think anyone uses it. Let's remove it unless someone objects within the next 48 hours.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDk2NTgwMTQy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/126,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDk3NDE3Njgy,incubator-stormcrawler,97417682,126,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-04-29T12:53:16Z,2015-04-29T12:53:16Z,"b5f305442fe648a5d734dbdf8f77ff5bef6c640c completed
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDk3NDE3Njgy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/126,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMjQ1Mjc1Ng==,incubator-stormcrawler,102452756,126,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-05-15T16:25:38Z,2015-05-15T16:25:38Z,"There are still config elements related to this [https://github.com/DigitalPebble/storm-crawler/blob/master/core/crawler-conf.yaml#L61] and Constants
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMjQ1Mjc1Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/126,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMjQ1Mjk0NQ==,incubator-stormcrawler,102452945,126,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-05-15T16:26:41Z,2015-05-15T16:26:41Z,"Thanks for catching that, will take care of it
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMjQ1Mjk0NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/126,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMjk1NTQ0MA==,incubator-stormcrawler,102955440,126,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-05-18T07:59:43Z,2015-05-18T07:59:43Z,"Fixed in [master 3995c78] Removed constants and configs from sharded queues + Tika #126
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMjk1NTQ0MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/130,https://api.github.com/repos/apache/incubator-stormcrawler/issues/130,incubator-stormcrawler,75180198,130,[HBase] Write Spout and StatusUpdaterBolt for HBase,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-05-11T10:55:37Z,2016-07-15T13:25:39Z,"Comparable to what we already have for ES; except that we wouldn't need to store or index the content but simply keep the URL status and metadata.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/130/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/130,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIzMjk0OTk2OQ==,incubator-stormcrawler,232949969,130,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-07-15T13:25:39Z,2016-07-15T13:25:39Z,"Storing the binary content into HBase is not difficult to do. As for using it for the status of URLs it is probably not ideal as it does not support secondary indices. Cassandra could be a better option.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIzMjk0OTk2OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/131,https://api.github.com/repos/apache/incubator-stormcrawler/issues/131,incubator-stormcrawler,75181947,131,WIKI page Overview,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-05-11T11:05:29Z,2015-05-20T11:06:56Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/131/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/131,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMTY0ODMyOQ==,incubator-stormcrawler,101648329,131,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-05-13T12:25:16Z,2015-05-13T12:25:16Z,"Started on [https://github.com/DigitalPebble/storm-crawler/wiki/Introduction]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMTY0ODMyOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/132,https://api.github.com/repos/apache/incubator-stormcrawler/issues/132,incubator-stormcrawler,75182029,132,WIKI page FetcherBolt(s),jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-05-11T11:06:04Z,2015-05-15T16:23:03Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/132/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/132,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMjQ1MjMxNA==,incubator-stormcrawler,102452314,132,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-05-15T16:23:03Z,2015-05-15T16:23:03Z,"Done in [https://github.com/DigitalPebble/storm-crawler/wiki/FetcherBolt%28s%29]
comments welcome as usual
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMjQ1MjMxNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/133,https://api.github.com/repos/apache/incubator-stormcrawler/issues/133,incubator-stormcrawler,76770700,133,Tick tuple in SimpleFetcherBolt,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-05-15T15:57:12Z,2015-05-20T11:40:38Z,"[https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/storm/crawler/bolt/SimpleFetcherBolt.java#L160]

@jakekdodd the tick tuples aren't needed, are they? Was it something you copied from the other FetcherBolt?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/133/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/133,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMjQ1MTk3Mw==,incubator-stormcrawler,102451973,133,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-05-15T16:21:00Z,2015-05-15T16:21:00Z,"Yep it was copied over from FetcherBolt, and no it's definitely not needed--I'll take care of it now
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMjQ1MTk3Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/133,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMjQ1MjY5NA==,incubator-stormcrawler,102452694,133,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-05-15T16:25:14Z,2015-05-15T16:25:14Z,"b84231124f7c412074f9c5ce63157599f04bed01 closed
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEwMjQ1MjY5NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/134,https://api.github.com/repos/apache/incubator-stormcrawler/issues/134,incubator-stormcrawler,84219497,134,"[SOLR] Write Spout, StatusUpdaterBolt and Indexer",jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-06-02T21:28:26Z,2015-07-02T07:26:53Z,"Comparable to what we have with ES
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/134/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/136,https://api.github.com/repos/apache/incubator-stormcrawler/issues/136,incubator-stormcrawler,85468567,136,Investigate use of elasticsearch-metrics-reporter-java for MetricsConsumer,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-06-05T08:11:16Z,2015-10-21T10:02:57Z,"See [https://github.com/elastic/elasticsearch-metrics-reporter-java]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/136/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/136,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0OTg0NDAyNw==,incubator-stormcrawler,149844027,136,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-10-21T10:02:57Z,2015-10-21T10:02:57Z,"That library is really geared towards the Codahale one, probably easier just to keep using ours.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0OTg0NDAyNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/137,https://api.github.com/repos/apache/incubator-stormcrawler/issues/137,incubator-stormcrawler,85471212,137,Upgrade to storm 0.9.5,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-06-05T08:26:30Z,2015-06-05T08:35:53Z,"[http://storm.apache.org/2015/06/04/storm095-released.html]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/137/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/139,https://api.github.com/repos/apache/incubator-stormcrawler/issues/139,incubator-stormcrawler,85478562,139,ParseFilter from interface to abstract class,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-06-05T09:08:12Z,2015-07-20T11:20:47Z,"See discussion #129
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/139/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/139,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEyMjg1MzQ5OQ==,incubator-stormcrawler,122853499,139,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-07-20T11:20:47Z,2015-07-20T11:20:47Z,"Implemented in #159 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEyMjg1MzQ5OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/140,https://api.github.com/repos/apache/incubator-stormcrawler/issues/140,incubator-stormcrawler,86167967,140,Organise external content as separate sub-modules,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-06-08T13:02:30Z,2015-06-22T13:22:48Z,"This is something that we had mentioned before in #41.  We currently have everything in external with a whole bunch of dependencies. Instead we should have a think about splitting into separate sub-modules e.g.
- elasticsearch
- tika
- metrics
- solr (see #134)

which is what is done in [storm](https://github.com/apache/storm/blob/master/pom.xml#L15).

An advantage of doing this would be that each module could have its own set of [scripts](https://github.com/DigitalPebble/storm-crawler/blob/master/external/ES_IndexInit.sh) or other resources instead of everything being put in one place.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/140/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/141,https://api.github.com/repos/apache/incubator-stormcrawler/issues/141,incubator-stormcrawler,88355117,141,Update WIKI about ParseFilters and ParseData,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-06-15T08:21:39Z,2015-06-22T13:22:34Z,"#135 introduced a change in the output of the parseFilters as they can now generate multiple documents from the original one
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/141/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/141,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDExNDEwMDM3NQ==,incubator-stormcrawler,114100375,141,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-06-22T13:22:34Z,2015-06-22T13:22:34Z,"Done in [https://github.com/DigitalPebble/storm-crawler/wiki/ParseFilters]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDExNDEwMDM3NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/142,https://api.github.com/repos/apache/incubator-stormcrawler/issues/142,incubator-stormcrawler,88983632,142,Does this crawler support javascript execution?,PatrickHuetter,1142911,Patrick Hütter,p.huetter@encircle360.com,CLOSED,2015-06-17T10:53:33Z,2018-07-29T12:26:45Z,"1) Does this crawler support javascript execution?
2) Does the crawler use selenium? (in this case it should be possible to use phantomJS or any other browser engine)

3) If it doesn't use selenium: Is it possible to integrate selenium easily? (I'm not very deep in the architecture yet, but i would investigate if it's possible)

4) Is it possible to trigger some hooks before extraction? For example: Click on a button before extracting elements, because the button triggers some ajax content load?

5) Is it possible to use a specific proxy for each crawling-job?

I'm asking regarding to my post on sf http://stackoverflow.com/questions/30887701/should-i-use-akka-io-apache-spark-mesos-or-storm-for-a-webcrawling-engine 

If some use-cases would be possible with this project, i would choose it as base and also contribute to it.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/142/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/142,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDExMjc1ODI4Mg==,incubator-stormcrawler,112758282,142,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-06-17T11:15:59Z,2015-06-17T11:15:59Z,"Thanks for getting in touch Patrick

> 1) Does this crawler support javascript execution?

not yet

> 2) Does the crawler use selenium? (in this case it should be possible to use phantomJS or any other browser engine)

not yet but this is something we'd like to do. This would be done by implementing a custom protocol that would delegate the fetching to Selenuim.

> 3) If it doesn't use selenium: Is it possible to integrate selenium easily? (I'm not very deep in the architecture yet, but i would investigate if it's possible)

This has been done by some of users (@GuiForget  & @jakekdodd ) but as a custom ParseFilter IIRC. As I mentioned above this could also be done as a custom protocol implementation.

> 4) Is it possible to trigger some hooks before extraction? For example: Click on a button before extracting elements, because the button triggers some ajax content load?

Well, we have nothing at the moment so everything's possible. The way I see it, we'd be able to pass a navigation script as part of the configuration of the protocol in order to do what you described.

> 5) Is it possible to use a specific proxy for each crawling-job?

Not sure what you mean by crawling job. StormCrawler is not batch driven like for instance Apache Nutch, it runs continuously. Having said that you could have several topologies running at the same time but I am not sure why you'd do that.

Our [http protocol implementation can be configured to use a proxy](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/storm/crawler/protocol/httpclient/HttpProtocol.java#L108) but that would be the same proxy used for the entire topology.

Do you mean https authentication?  Our protocol implementation does not handle that yet but it is definitely doable. Again, we could load the credentials via the configuration.

> If some use-cases would be possible with this project, i would choose it as base and also contribute to it.

That would be great. Apart from the things mentioned here, StormCrawler can already provide quite a few functionalities and you'd be able to leverage the core components (fetcher and parser bolts) without reinventing them. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDExMjc1ODI4Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/142,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDExMzA5ODYxMg==,incubator-stormcrawler,113098612,142,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-06-18T10:08:29Z,2015-06-18T10:08:29Z,"Have opened #144, let's discuss Selenuim there.

@PatrickHuetter please close this issue if you think I've answered all your questions
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDExMzA5ODYxMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/142,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwOTIxMDgyMw==,incubator-stormcrawler,309210823,142,NA,koolma,29179314,,,NA,2017-06-17T11:58:08Z,2017-06-17T11:58:08Z,"Hi @jnioche,
is it still true that stormcrawler is not able to work with JavaScript?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwOTIxMDgyMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/142,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwOTI4NzA5OA==,incubator-stormcrawler,309287098,142,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-06-18T16:15:22Z,2017-06-18T16:15:22Z,"Hi @koolma, see issue mentioned above (#144) in particular 
https://github.com/DigitalPebble/storm-crawler/issues/144#issuecomment-297671725

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwOTI4NzA5OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/142,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQwODY3NDM3NQ==,incubator-stormcrawler,408674375,142,NA,sfaez,34604201,sabereh faez,,NA,2018-07-29T12:24:50Z,2018-07-29T12:24:50Z,"Hi @jnioche 
how we can configure selenium to use , for example in archetype project ?
thanks for answering","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQwODY3NDM3NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/142,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQwODY3NDUwMw==,incubator-stormcrawler,408674503,142,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-07-29T12:26:44Z,2018-07-29T12:26:44Z,"please use stack  overflow for questions. See blog for how to on selenium
plugin
Thanks


On 29 Jul 2018 13:24, ""sfaez"" <notifications@github.com> wrote:

Hi @jnioche <https://github.com/jnioche>
how we can configure selenium to use , for example in archetype project ?

—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub
<https://github.com/DigitalPebble/storm-crawler/issues/142#issuecomment-408674375>,
or mute the thread
<https://github.com/notifications/unsubscribe-auth/AANUz2CBFlYgSEr4B0mPtai0DuESwkoOks5uLamSgaJpZM4FFPel>
.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQwODY3NDUwMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/144,https://api.github.com/repos/apache/incubator-stormcrawler/issues/144,incubator-stormcrawler,89252092,144,Selenium-based protocol implementation,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-06-18T10:06:30Z,2017-04-27T10:07:22Z,"This should allow us to deal with the dynamic content. See discussion #142 
Ideally we'd want to be able to have actions/navigations either programmatically or via configuration.

We could use :
- [selenium](http://seleniumhq.github.io/selenium/docs/api/java/index.html) directly 
- or via [crawljax](https://github.com/crawljax/crawljax)
- [ghostDriver](https://github.com/detro/ghostdriver) with PhantomJS
- [chromedriver](https://code.google.com/p/selenium/wiki/ChromeDriver) via the Selenium API
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/144/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/144,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIxMzM0NzU0MA==,incubator-stormcrawler,213347540,144,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-04-22T09:16:44Z,2016-04-22T09:16:44Z,"Use [jBrowserDriver](https://github.com/MachinePublishers/jBrowserDriver/)? 100% Java and headless. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIxMzM0NzU0MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/144,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIxMzQ0MTQyMA==,incubator-stormcrawler,213441420,144,NA,kkrugler,66217,Ken Krugler,ken@transpac.com,NA,2016-04-22T14:05:06Z,2016-04-22T14:05:06Z,"I think jBrowserDriver required Java 8 - would that be an issue?

Also, in the past we used [HTMLUnit](http://htmlunit.sourceforge.net/), though not without challenges.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIxMzQ0MTQyMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/144,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIxMzUzNzE3MA==,incubator-stormcrawler,213537170,144,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-04-22T18:12:41Z,2016-04-22T18:12:41Z,"@kkrugler could put that in a separate repo so that the requirement for Java 8 does not become necessary for core and the other modules. 

Nutch has a HTMLUnit-based protocol implementation I think but not sure it's been used much yet and I haven't heard on that. There's also a Selenium one.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIxMzUzNzE3MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/144,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2Mjc2NDI2MQ==,incubator-stormcrawler,262764261,144,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-11-24T12:22:09Z,2016-11-24T12:22:09Z,[Example of JS content](http://stackoverflow.com/questions/40784663/how-to-parse-a-javascript-object-from-a-html-page-i-crawl),"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2Mjc2NDI2MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/144,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTg3ODQ2NA==,incubator-stormcrawler,271878464,144,NA,rkrombho,198947,Robert Krombholz,,NA,2017-01-11T14:13:58Z,2017-01-11T14:13:58Z,"Maybe [Geb](http://www.gebish.org/)?

It's very easy to use and based on Selenium WebDriver which means it supports all browser that have a Driver implementation.
It would mean that users could theoretically decide if they want to do headless (e.g. HtmlUnitDriver, PhantomJSDriver), go with a real browser or to use Selenium Grid with a variety of different browsers.

I did some very intensive integration testing with Geb (including waiting for AJAX responses etc.) and it is absolutely awesome.
Would be easy to let the user provide Groovy/Geb scripts that are executed against Page context that is currently being crawled but I have no Idea how this could work with the Protocol Interface.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTg3ODQ2NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/144,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5MzUwODQwMQ==,incubator-stormcrawler,293508401,144,NA,iRajashekharC,17562178,Rajashekhar,rajshekhar.charantimath@gmail.com,NA,2017-04-12T08:24:16Z,2017-04-12T08:24:16Z,"Hi @jnioche - curious to know if the current version of stormcrawler supports this Ajax/Dynamic content parsing?

Thanks
Raj","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5MzUwODQwMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/144,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5MzY4Mzc1Ng==,incubator-stormcrawler,293683756,144,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-04-12T19:33:24Z,2017-04-12T19:33:24Z,"Hi @raaz1234, see branch https://github.com/DigitalPebble/storm-crawler/tree/jBrowserDriver. Not yet merged but please give it a try","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5MzY4Mzc1Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/144,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NTY4NTYxNw==,incubator-stormcrawler,295685617,144,NA,owenrh,2006075,Owen Rees-Hayward,,NA,2017-04-20T11:05:33Z,2017-04-20T11:05:33Z,Hi @jnioche - is it just a case of configuring _http.protocol.implementation_ to use the JBrowserProtocol? Or is more needed to make this work?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NTY4NTYxNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/144,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NTY4OTExMA==,incubator-stormcrawler,295689110,144,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-04-20T11:14:41Z,2017-04-20T11:14:41Z,"Hi @owenrh (am sitting at your desk, will try not to leave crumbs). Yes, should be just that indeed!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NTY4OTExMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/144,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NTgxNDQ0OA==,incubator-stormcrawler,295814448,144,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-04-20T16:59:49Z,2017-04-20T16:59:49Z,@owenrh please have a look at #457,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NTgxNDQ0OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/144,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NzY2ODkyMg==,incubator-stormcrawler,297668922,144,NA,owenrh,2006075,Owen Rees-Hayward,,NA,2017-04-27T09:54:29Z,2017-04-27T09:54:29Z,"@jnioche ha, thanks for the msgs, had an error on my inbox filters so I missed them. Will check it out, ta.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NzY2ODkyMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/144,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NzY3MTcyNQ==,incubator-stormcrawler,297671725,144,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-04-27T10:07:14Z,2017-04-27T10:07:14Z,@owenrh see also http://digitalpebble.blogspot.co.uk/2017/04/crawl-dynamic-content-with-selenium-and.html,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NzY3MTcyNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/146,https://api.github.com/repos/apache/incubator-stormcrawler/issues/146,incubator-stormcrawler,89312416,146,Text exclusion with googleon / googleoff,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-06-18T14:44:19Z,2023-12-05T16:17:13Z,"This can be done by implementing googleon / googleoff, see [doc for Google Search Appliance](https://support.google.com/gsa/answer/6329153?hl=en#57a1e30a-63b2-4470-86a5-94a6c06912be)

We should implement a ParseFilter to restrict the text based on these tags and possibly filter the outlinks as well.

This filter could also have a set of Xpath in its configuration which would allow to restrict the text to the span e.g. `<div id=""content""`
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/146/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/147,https://api.github.com/repos/apache/incubator-stormcrawler/issues/147,incubator-stormcrawler,89320304,147,Enforce robots meta tags ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-06-18T15:17:19Z,2015-07-01T15:37:27Z,"See [http://www.google.com/support/enterprise/static/gsa/docs/admin/70/gsa_doc_set/admin_crawl/preparing.html#1076168]

`<meta name=""robots"" content=""noarchive, nofollow""/>`

as well as  `rel=""nofollow""` attribute  
`<a href=""test1.html"" rel=""nofollow>no follow</a>`
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/147/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/147,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDExMzE5MTY4NA==,incubator-stormcrawler,113191684,147,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-06-18T15:26:49Z,2015-06-18T15:26:49Z,"Nutch equivalent

[https://github.com/apache/nutch/blob/trunk/src/plugin/parse-html/src/java/org/apache/nutch/parse/html/HTMLMetaProcessor.java]

and 

[https://github.com/apache/nutch/blob/trunk/src/java/org/apache/nutch/parse/HTMLMetaTags.java]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDExMzE5MTY4NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/147,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDExMzUyODU0OQ==,incubator-stormcrawler,113528549,147,NA,rkrombho,198947,Robert Krombholz,,NA,2015-06-19T14:16:56Z,2015-06-19T14:16:56Z,"I would really prefer if this behavior could be switched of and on with a configuration flip.
`rel=nofollow` should only be used for ranking links. Crawlers typically still follow those links but remove them from any sort of rank calculation.

Here is what the big search engine cralwers do with it:
https://en.wikipedia.org/wiki/Nofollow#Interpretation_by_the_individual_search_engines

Especially for whole web crawls it may still be important for crawlers to follow those links in order to find new pages irrespective of ranking those type of links.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDExMzUyODU0OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/147,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDExNDA0ODg5Ng==,incubator-stormcrawler,114048896,147,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-06-22T09:23:45Z,2015-06-22T09:23:45Z,"Thanks for your comments @rkrombho 

There seems to be different interpretations of what this is supposed to do indeed. The [doc for GSA](http://www.google.com/support/enterprise/static/gsa/docs/admin/70/gsa_doc_set/admin_crawl/preparing.html#1076168) which I mentioned previously implies that the links are not followed at all (""_The search appliance crawler retrieves and archives the document in the search appliance cache, but does not follow links on the Web page to other documents_"").

Your suggestion of a config switch makes sense. What about having something like `robots.noFollow.strict` with a boolean value, where the outlinks would be filtered out completely when the mode is set to strict and left otherwise?

BTW you could always handle the outlinks in anyway you want if you extracted them from the DOM in a bespoke ParseFilter.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDExNDA0ODg5Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/149,https://api.github.com/repos/apache/incubator-stormcrawler/issues/149,incubator-stormcrawler,90682633,149,Indexer bolts use canonical URL ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-06-24T13:55:58Z,2015-07-20T11:27:57Z,"We already have a parse filter that extracts canonical URLs. We should add to AbstractIndexerBolt the ability to use them instead of the URL when available
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/149/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/149,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDExNzIwNjUyNQ==,incubator-stormcrawler,117206525,149,NA,jorgelbg,1291846,Jorge Luis Betancourt,github@jorgelbg.me,NA,2015-06-30T14:26:45Z,2015-06-30T14:26:45Z,"Adding this in the `AbstractIndexerBolt` means that it should be then optional to use in the indexers? perhaps creating and additional method that returns the right URL based on the Tuple received by the bolt, something like:

``` java
    protected String valueForURL(Tuple tuple) {
        String url = tuple.getStringByField(""url"");
        Metadata metadata = (Metadata) tuple.getValueByField(""metadata"");

        if (metadata.getFirstValue(""canonical"") != null) 
            url = metadata.getFirstValue(""canonical"");

        return url;
    }
```

should work but this must be used instead of the default `url` var extracted from the Tuple in the execute method. This means that we should change this in the existing indexer implementations (ES/Solr/StdOut). Perhaps something like:

``` java
String url = valueForURL(tuple);
...
```

Any thoughts on this? 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDExNzIwNjUyNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/149,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDExNzY3NTIzNA==,incubator-stormcrawler,117675234,149,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-07-01T13:27:54Z,2015-07-01T13:27:54Z,"That's pretty much what I had in mind. Later on we could do the same as in Nutch and for redirections decide which of the source or target URLs is the nicest to display. 

We'd probably need to check that the value of canonical is OK e.g. it belongs to the same domain and make its value absolute if necessary.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDExNzY3NTIzNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/149,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDExODEwNjk4NQ==,incubator-stormcrawler,118106985,149,NA,jorgelbg,1291846,Jorge Luis Betancourt,github@jorgelbg.me,NA,2015-07-02T17:44:01Z,2015-07-02T17:44:01Z,"I'm going to add the validation in the canonical URL and submit a PR with the change.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDExODEwNjk4NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/149,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEyMjg1NDczMQ==,incubator-stormcrawler,122854731,149,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-07-20T11:27:57Z,2015-07-20T11:27:57Z,"Implemented in #161 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEyMjg1NDczMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/154,https://api.github.com/repos/apache/incubator-stormcrawler/issues/154,incubator-stormcrawler,92648759,154,Enforce robots meta instructions with Tika parser,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-07-02T14:14:18Z,2017-04-04T10:16:50Z,"See PR #147 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/154/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/154,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5MTQ1NzA5MQ==,incubator-stormcrawler,291457091,154,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-04-04T10:16:49Z,2017-04-04T10:16:49Z,In practice HTML docs are handled with JSOup and Tika takes care of everything else so we can probably ignore it for now.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5MTQ1NzA5MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/155,https://api.github.com/repos/apache/incubator-stormcrawler/issues/155,incubator-stormcrawler,92664313,155,[SOLR] add README file,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-07-02T15:24:21Z,2015-07-13T13:35:30Z,"as mentioned in #152 we need a README file in external/solr to describe what we have there and how to use it e.g create and configure basic indices, run the topologies etc...
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/155/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/155,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEyMDkyODc1OA==,incubator-stormcrawler,120928758,155,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-07-13T13:35:30Z,2015-07-13T13:35:30Z,"Merged in #157 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEyMDkyODc1OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/156,https://api.github.com/repos/apache/incubator-stormcrawler/issues/156,incubator-stormcrawler,92870764,156,SOLR : investigate use of field collapsing in Spout,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-07-03T13:00:20Z,2015-07-22T09:22:40Z,"See #152 

This would be a way of ensuring a good diversity of URLs in the results.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/156/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/156,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEyMzYzNjQ2Ng==,incubator-stormcrawler,123636466,156,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-07-22T09:22:40Z,2015-07-22T09:22:40Z,"Implemented in #162. Thanks @jorgelbg 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEyMzYzNjQ2Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/158,https://api.github.com/repos/apache/incubator-stormcrawler/issues/158,incubator-stormcrawler,93784417,158,Remove needsDOM() in ParseFilter,jnioche,218319,Julien Nioche,julien@digitalpebble.com,OPEN,2015-07-08T13:04:26Z,2016-01-14T10:57:13Z,"This was provided as a way of avoiding building the DOM structure for when no ParseFilters were requiring it and is used only in the Tika parser.

The RobotsTag extractor requires such a DOM so unless we are able to extract the robots directives differently e.g. via SAX and a custom ContentHandler we should reconsider whether this method is really needed.

The JSoupParseFilter could avoid building the DOM too and extract the values via its org.jsoup.nodes.Document prior to building the DOM (if required).

Related to #154
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/158/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/158,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzMzM1MjEyMQ==,incubator-stormcrawler,133352121,158,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-08-21T09:39:39Z,2015-08-21T09:39:39Z,"The SitemapParserBolt calls the ParseFilters too but does not generate a DOM which can result in a NPE. This has been addressed in [b0d6f59] but relies on needsDOM()
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzMzM1MjEyMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/158,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE3MTYxMjYxMw==,incubator-stormcrawler,171612613,158,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-01-14T10:57:13Z,2016-01-14T10:57:13Z,"The fix in [b0d6f59] is actually quite problematic. Originally `needsDOM()` was merely an optimisation aimed at avoiding the cost of building the DOM if no parse filters needed it.  This meant 'the parsefilter might need a DOM so please provide one' which is not the same as 'this parsefilter _needs_ a DOM' as implied by [b0d6f59].

We could remove the whole thing and instead let the users specify via config whether a DOM should be generated or not. This means that each individual parsefilter should check whether the DOM is not null before trying to process it with Xpath.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE3MTYxMjYxMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/160,https://api.github.com/repos/apache/incubator-stormcrawler/issues/160,incubator-stormcrawler,94728289,160,Remove external/metrics?,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-07-13T14:02:59Z,2015-07-27T15:24:43Z,"unless anyone uses it of course.

@DigitalPebble/committers-crawler thoughts on this?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/160/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/160,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEyMTg0MDAxOA==,incubator-stormcrawler,121840018,160,NA,jorgelbg,1291846,Jorge Luis Betancourt,github@jorgelbg.me,NA,2015-07-16T05:42:33Z,2015-07-16T05:42:33Z,":+1: I don't see any problem
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEyMTg0MDAxOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/160,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEyNTIzOTUzNA==,incubator-stormcrawler,125239534,160,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-07-27T15:06:44Z,2015-07-27T15:06:44Z,"Thanks
@DigitalPebble/committers-crawler anyone else?
Marking as 0.6
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEyNTIzOTUzNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/160,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEyNTI0MTI2MQ==,incubator-stormcrawler,125241261,160,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-07-27T15:14:00Z,2015-07-27T15:14:00Z,"Yeah should be OK to remove it
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEyNTI0MTI2MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/160,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEyNTI0Mzc1OQ==,incubator-stormcrawler,125243759,160,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-07-27T15:24:43Z,2015-07-27T15:24:43Z,"done in [e088b7106d5f5b4b27c893e0a91d050c01d3168f]
thanks!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEyNTI0Mzc1OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/163,https://api.github.com/repos/apache/incubator-stormcrawler/issues/163,incubator-stormcrawler,96517932,163,Release 0.6,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-07-22T09:17:47Z,2015-09-15T11:20:49Z,"[https://github.com/DigitalPebble/storm-crawler/issues?q=is%3Aissue+milestone%3A0.6+is%3Aopen]
#156 is imminent

just #154 left but would be happy to postpone it.

@DigitalPebble/committers-crawler any other issues you'd like to see included in the next release?

I'm keen to release 0.6 this week or next - will be on holiday after that. Any thoughts? 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/163/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/163,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEyNTM3OTYxNA==,incubator-stormcrawler,125379614,163,NA,jorgelbg,1291846,Jorge Luis Betancourt,github@jorgelbg.me,NA,2015-07-27T23:40:44Z,2015-07-27T23:40:44Z,":+1: I don't see any reason not to release, I'm also on holiday so go ahead :smile: 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEyNTM3OTYxNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/163,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTc5MjU1OQ==,incubator-stormcrawler,135792559,163,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-08-28T14:39:55Z,2015-08-28T14:39:55Z,"No progress on #164, will postpone it to the following release.

#177 is the last item for 0.6

@DigitalPebble/committers-crawler anything else you think should be included?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTc5MjU1OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/164,https://api.github.com/repos/apache/incubator-stormcrawler/issues/164,incubator-stormcrawler,97139881,164,Metadata needs to be made immutable before emitting,jakekdodd,6845693,Jake K. Dodd,,CLOSED,2015-07-24T20:24:46Z,2018-06-12T09:41:17Z,"We're getting ConcurrentModificationExceptions on Metadata instances while they're being serialized by Kryo.

According to the Storm docs, all values emitted in a tuple need to be immutable. This bug seems to rear its head when a Metadata instance is emitted from a bolt, and then subsequently modified later in the execute method coincident with Kryo serialization. We've seen this happen in a few places, but most commonly this exception occurs in a StatusStreamBolt that sits downstream of a parser bolt.

Because the StatusStreamBolt isn't actually modifying the metadata--just emitting, and thus serializing it--I believe this happens when a parser bolt and StatusStreamBolt are running on the same JVM.

In any case, the right way to handle this is to always emit an immutable defense snapshot of Metadata. I'd propose a `.copy()` or `.snapshot()` method on Metadata that would return a Guava ImmutableMap and a `.fromSnapshot()` method or something equivalent that returns a Metadata instance from an ImmutableMap
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/164/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/164,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEyNDk3Mjc4Ng==,incubator-stormcrawler,124972786,164,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-07-26T11:21:05Z,2015-07-26T11:21:05Z,"When would fromSnapshot be needed? Would we have to change code to call .snapshot() every time we emit a Metadata? or can do that within Metadata so that it gets called by the serialization mechanism.

Ideally we'd want to find where in the code those Metadata instances survive the emission, because they shouldn't really.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEyNDk3Mjc4Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/164,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEyNTA0NzAyNg==,incubator-stormcrawler,125047026,164,NA,jorgelbg,1291846,Jorge Luis Betancourt,github@jorgelbg.me,NA,2015-07-26T23:03:09Z,2015-07-26T23:03:09Z,"+1 on finding where in the code this is happening, it would be very
helpful.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEyNTA0NzAyNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/164,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEyNTA0Nzg5OA==,incubator-stormcrawler,125047898,164,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-07-26T23:27:21Z,2015-07-26T23:27:21Z,"> When would fromSnapshot be needed?

When converting an ImmutableMap to Metadata after using `tuple.getValueByField()`. The alternative would be to have `.snapshot()` return a defense copy of Metadata, and then we could do `Metadata metadata = (Metadata) tuple.getValueByField(""md"")` as usual. This would still be a mutable object, however.

> Would we have to change code to call .snapshot() every time we emit a Metadata?

Unfortunately, yeah =/

> Ideally we'd want to find where in the code those Metadata instances survive the emission, because they shouldn't really.
> 
> +1 on finding where in the code this is happening, it would be very
> helpful.

Any time we emit metadata in a tuple, and then continue through the `execute()` method where we potentially perform operations on the metadata. As for where that happens, exactly, we'd have to do a full review of every single bolt to figure that out. I think we should, just so we're aware. Unfortunately the stack trace looks identical to the one described [here](https://storm.apache.org/documentation/Troubleshooting.html), so I don't have the exact location in the topology where the concurrent modification happens--only the name of the bolt where the serialization is happening and the exception is thrown.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEyNTA0Nzg5OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/164,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEyNTExNDgyNg==,incubator-stormcrawler,125114826,164,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-07-27T07:54:33Z,2015-07-27T07:54:33Z,"What about having a poor-man's implementation of immutability so that the underlying implementation of the Map does not change - which IIUC would save us having to do fromSnapshot(). We could add a method to turn the Metadata into an immutable state (e.g. `lock()`) and call that prior just before we emit so that we'd get the exception not in the serialization process but in wherever the Metadata instances are used when they shouldn't? That should help us find where in the code our problems are.

I see it as a debugging mechanism more than anything else. It could be used to detect such issues and avoid having to do a defensive copy when emitting.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEyNTExNDgyNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/164,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEyNjgwODk2OQ==,incubator-stormcrawler,126808969,164,NA,jakekdodd,6845693,Jake K. Dodd,,NA,2015-07-31T20:48:32Z,2015-07-31T20:48:32Z,"https://storm.apache.org/apidocs/backtype/storm/task/OutputCollector.html

ctrl +f ""The emitted values must be immutable."" :smiley: 

I'm not sure how the `lock()` mechanism would help us find the source of the problem. We would need to unlock the Metadata instance after Kryo has finished the serialization--how would we know when that happens?

We don't have to change the underlying implementation of the Map itself (the `md` member of Metadata). The `snapshot()` method would just return a new `ImmutableMap` object with a copy of `md`'s data. The `fromSnapshot()` method would copy all of an ImmutableMap's data into the mutable `md` of a new Metadata instance.

The other alternative I gave, to have the `snapshot()` method just return a new copy of Metadata (different object, same data) would obviate the need for a `fromSnapshot()` method to reconstruct a Metadata instance. But I still think this is unsafe
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEyNjgwODk2OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/164,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzMTgxOTU1Nw==,incubator-stormcrawler,131819557,164,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-08-17T13:35:11Z,2015-08-17T13:35:11Z,"> We would need to unlock the Metadata instance after Kryo has finished the serialization--how would we know when that happens?

We would not unlock it. The idea is that the serialization would work fine but whichever part of the code still operates on the metadata after it has been sent to the output would get an immutable exception. This way we'd be able to fix the problem in the first place, which is simpler than adding the snapshot/fromSnapshot logic.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzMTgxOTU1Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/164,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzMzQ1MjA2Ng==,incubator-stormcrawler,133452066,164,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-08-21T14:53:42Z,2015-08-21T14:53:42Z,"@jakekdodd I've just pushed a new branch called 164 which adds a lock mechanism to the Metadata and calls it in the JsoupParser whenever we emit a metadata. Could you please give it a try and see where you are getting UnsupportedOperationException? 

Again, I'd prefer not to have to enforce the lock/unlock mechanism systematically but just fix the incorrect use of Metadata.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzMzQ1MjA2Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/164,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4ODc0NjU5OA==,incubator-stormcrawler,288746598,164,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-23T14:59:32Z,2017-03-23T14:59:32Z,Not seen since and probably due to some incorrect bespoke code. Closing for now but could be reopened if anyone had the same problem  ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4ODc0NjU5OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/164,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NjI2MTA5NQ==,incubator-stormcrawler,396261095,164,NA,nitindahiya,11920415,,,NA,2018-06-11T14:22:31Z,2018-06-11T14:22:31Z,"Hi @jnioche @jakekdodd, 

I am also seeing ConcurrentModificationExceptions when i am using metadata map in a bolt.

So i have a bolt, let us say, AvroBolt, which needs to create avro record for every metadata key-value pair.

But iterating over the metadata and creating and emiting a avro record throws the concurrent modification exception, when running in local mode, not tried on distirbuted mode yet.

What is strange is the fact that the following code throws exception

```
        Metadata metadata = (Metadata) tuple.getValueByField(""metadata"");
        Iterator<Map.Entry<String, String[]>> it = metadata.asMap().entrySet().iterator();
        Map<String, String[]> clonedMap = new HashMap<>();
        List<Avro> nfaList = new ArrayList<>();
        while (it.hasNext()) {
            Map.Entry<String, String[]> pair = it.next();
            clonedMap.put(pair.getKey(), pair.getValue());
            }
```
but the code below does not, and works just fine

```
        Metadata metadata = (Metadata) tuple.getValueByField(""metadata"");
        Iterator<Map.Entry<String, String[]>> it = metadata.asMap().entrySet().iterator();
        Map<String, String[]> clonedMap = new HashMap<>();
        List<Avro> nfaList = new ArrayList<>();
        while (it.hasNext()) {
            Map.Entry<String, String[]> pair = it.next();
            System.out.println(pair.getKey());
            System.out.println(pair.getValue());
            }
```
I just can't assign the key/val to any variable.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NjI2MTA5NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/164,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NjUzMDM1OA==,incubator-stormcrawler,396530358,164,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-06-12T09:41:16Z,2018-06-12T09:41:16Z,"@nitindahiya I don't think this is related to the issue we were discussing at the time, if it did, you'd have the same problem in the second code. 

Not clear why this would happen on the clonedMap either.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NjUzMDM1OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/165,https://api.github.com/repos/apache/incubator-stormcrawler/issues/165,incubator-stormcrawler,97413405,165,JsoupParserBolt : add config to prevent any outlinks from being sent,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-07-27T08:40:32Z,2015-08-21T12:22:30Z,"The default JsoupParserBolt could be extended to implement an additional boolean field preventing any outlinks from being sent to the status stream at all. 

The Tika based parser has such a mechanism => [parser.emitOutlinks](https://github.com/DigitalPebble/storm-crawler/blob/master/external/tika/src/main/java/com/digitalpebble/storm/crawler/tika/ParserBolt.java#L96).
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/165/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/165,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzMzQwNzkzOA==,incubator-stormcrawler,133407938,165,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-08-21T12:22:30Z,2015-08-21T12:22:30Z,"Was probably tired that day :-( we already have that 
[https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/storm/crawler/bolt/JSoupParserBolt.java#L119]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzMzQwNzkzOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/166,https://api.github.com/repos/apache/incubator-stormcrawler/issues/166,incubator-stormcrawler,97486898,166,[external] SQL spout and status updater,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-07-27T15:13:49Z,2015-08-26T09:44:41Z,"Small crawls don't necessarily need scalable storage and could fit within a SQL table. 

We could have a spout and status updater to persist data to persist data to SQL. From my experience with Nutch this was something that many people tried to use (except it never got implemented correctly and the license of some of the components was not kosher for an ASF project).

We could reuse or extend the code in [https://github.com/apache/storm/tree/master/external/storm-jdbc] if appropriate.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/166/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/168,https://api.github.com/repos/apache/incubator-stormcrawler/issues/168,incubator-stormcrawler,100720361,168,NPE in function MetadataTransfert.filter(),ludovic-boutros,13764888,Ludovic Boutros ,,CLOSED,2015-08-13T09:05:36Z,2015-08-27T13:50:36Z,"Hi,

the parameter 'metadata' can be null in the function MetadataTransfert.filter().
It throws a NPE later.

Just adding the test and returning 'md' fix this issue.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/168/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/168,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTM2MDU2Mg==,incubator-stormcrawler,135360562,168,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-08-27T09:21:57Z,2015-08-27T09:21:57Z,"@ludovic-boutros did you get the NPE after I reverted your PR? Would be good to find where we get a null metadata.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTM2MDU2Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/168,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTM5MzcxNg==,incubator-stormcrawler,135393716,168,NA,ludovic-boutros,13764888,Ludovic Boutros ,,NA,2015-08-27T11:28:22Z,2015-08-27T11:28:22Z,"Not yet. I will try soon.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTM5MzcxNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/168,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTQwMzQzMA==,incubator-stormcrawler,135403430,168,NA,ludovic-boutros,13764888,Ludovic Boutros ,,NA,2015-08-27T12:10:40Z,2015-08-27T12:10:40Z,"Ok I reproduce the issue while running the Solr seed injector example. 
Will try to figure out what's wrong here.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTQwMzQzMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/168,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTQwMzcxNQ==,incubator-stormcrawler,135403715,168,NA,ludovic-boutros,13764888,Ludovic Boutros ,,NA,2015-08-27T12:12:38Z,2015-08-27T12:12:38Z,"It seems that the FileSpout emits null metadata...
Edit:
If the URL file is a simple list of URLs, the scheme deserializes null metadata. The object is not initialized.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTQwMzcxNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/168,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTQyNjk3Nw==,incubator-stormcrawler,135426977,168,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-08-27T13:24:56Z,2015-08-27T13:24:56Z,"So this would mean that [https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/storm/crawler/bolt/URLPartitionerBolt.java#L69] should also check for the value of metadata. In the case you found we were emitting a field metadata but with a null value. I've fixed this in [d46138f]. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTQyNjk3Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/168,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTQyOTczOQ==,incubator-stormcrawler,135429739,168,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-08-27T13:32:57Z,2015-08-27T13:32:57Z,"@ludovic-boutros please close this issue if you are confident that the problem is now solved. Thanks
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTQyOTczOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/177,https://api.github.com/repos/apache/incubator-stormcrawler/issues/177,incubator-stormcrawler,103207425,177,[External][Solr] The Solr storage should use 'autoSoftCommit' and 'autoCommit',ludovic-boutros,13764888,Ludovic Boutros ,,CLOSED,2015-08-26T08:27:18Z,2015-09-01T21:17:10Z,"Currently the Solr storage modules send hard commits to Solr. 

I think this is not the good way to proceed.
These commits cause too much pressure on Solr. See the following screenshot.

![capture d ecran 2015-08-12 a 10 10 18](https://cloud.githubusercontent.com/assets/13764888/9488752/5a1f5b62-4bdc-11e5-82c4-ca2e59235618.png)

Instead, these modules should let Solr commit the documents with 'autoCommit' and 'autoSoftCommit' sections in the 'solrconfig' file.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/177/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/177,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTAwNTg1Nw==,incubator-stormcrawler,135005857,177,NA,jorgelbg,1291846,Jorge Luis Betancourt,github@jorgelbg.me,NA,2015-08-26T13:07:47Z,2015-08-26T13:07:47Z,"I think the more generic approach could be make this an option in the configuration file? In some cases I've seen than relying only on autoCommit or autoSoftCommit can be ""problematic"" that's why the module issue a hard commit every now and then. What do you think?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTAwNTg1Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/177,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTA3NTI1Mg==,incubator-stormcrawler,135075252,177,NA,ludovic-boutros,13764888,Ludovic Boutros ,,NA,2015-08-26T15:47:21Z,2015-08-26T15:47:21Z,"Hi @jorgelbg,

I think that the usage of Solr in SC can be considered as a NRT use case.
In this type of use cases, I think explicit hard commits are not a good solution.

I really don't like having explicit commits in my code ;)

I've never had any bad experiences with autocommits, could you elaborate a bit please ? 

Another solution could be to remove explicit hard commits and add a _commitWithin_ parameter to each _add_ command ?

This would be an additional parameter. That would work too I think.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTA3NTI1Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/177,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTA3OTk5OA==,incubator-stormcrawler,135079998,177,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-08-26T16:03:09Z,2015-08-26T16:03:09Z,"@ludovic-boutros did you get an improvement to the perfs of the status updater by using soft commits? 

I expected the commit strategy (auto|soft|hard) to be done entirely on the SOLR config side and not at all in the code. Is that required because the client buffers the docs to index? Isn't there another SOLR client implementation which has a max doc / max time parameter? 

The current implementation would be problematic when a few docs are processed e.g. end of a crawl as we would not get the minimal size before we commit. See [https://github.com/DigitalPebble/storm-crawler/blob/master/external/aws/src/main/java/com/digitalpebble/stormcrawler/aws/bolt/CloudSearchConstants.java#L27] for how I handled that for CloudSearch.

@jorgelbg the handling of errors is incorrect. At the moment you just log the error which means that the input tuple gets acked. It would need to be failed either explicitely or by rethrowing the exception so that AbstractStatusUpdaterBolt can deal with it.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTA3OTk5OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/177,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTEwNDg1OQ==,incubator-stormcrawler,135104859,177,NA,ludovic-boutros,13764888,Ludovic Boutros ,,NA,2015-08-26T16:46:47Z,2015-08-26T16:46:47Z,"@jnioche I've tested with _commitWithin_ and it works quite well. 
But I would prefer a strategy in the solrconfig file too.

I'm currently implementing this strategy: 
- no explicit commit in the code
- autocommit, autosoftcommit in the solr config file

and I think I will test with a standard SolrHttpClient which will send synchronously the documents. 
This way, it will be far easier to handle errors correctly.

Is it ok for you @jorgelbg and @jnioche ?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTEwNDg1OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/177,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTEwODg3OQ==,incubator-stormcrawler,135108879,177,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-08-26T17:03:02Z,2015-08-26T17:03:02Z,"Sounds good. Thanks
On 26 Aug 2015 17:46, ""ludovic-boutros"" notifications@github.com wrote:

> @jnioche https://github.com/jnioche I've tested with _commitWithin_ and
> it works quite well.
> But I would prefer a strategy in the solrconfig file too.
> 
> I'm currently implementing this strategy:
> - no explicit commit in the code
> - autocommit, autosoftcommit in the solr config file
> 
> and I think I will test with a standard SolrHttpClient which will send
> synchronously the documents.
> This way, it will be far easier to handle errors correctly.
> 
> Is it ok for you @jorgelbg https://github.com/jorgelbg and @jnioche
> https://github.com/jnioche ?
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/DigitalPebble/storm-crawler/issues/177#issuecomment-135104859
> .
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTEwODg3OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/177,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTEyNDY5Nw==,incubator-stormcrawler,135124697,177,NA,jorgelbg,1291846,Jorge Luis Betancourt,github@jorgelbg.me,NA,2015-08-26T17:59:44Z,2015-08-26T17:59:44Z,"@ludovic-boutros  In a separated project I've worked some time ago we had some troubles with the memory usage on the autocommit/autosoftcommit issue, this features works on a time/number of docs approach, since the length of the documents we were storing in Solr was changing a lot we faced some problems when configuring a low autocommit/autosoftcommint value caused the server to spent a lot of time writing to disk, a high value caused some OOM exceptions and server to crash; right now we use a combination of both, we have a relative long time for an autocommit configured in the solrconfig.xml and we issue some hard commits when indexing, kind of having an hybrid approach, which is what I've tried to mimmic here. 

@jnioche Actually the ConcurrentUpdateSolrClient queue the documents/requests which maximize the throughput of the IndexerBolt, I'm not aware on any SolrClient with docs/max time parameter (ES does a better job here on the client side), although this can be accomplished by configuration in the solrconfig.xml, file. The CUSC client does have a max queue size parameter which I exposed in the storm crawler configuration. 

if your only strategy is is based on hard commits then yes the document will be added/sent to Solr but not committed until the batch size is reached, but leveraging this with the autocommit/autosoftcommit the results will be available for search and will be committed eventually. 

If any error happens when the add/commit is issued against Solr the tuple is failed https://github.com/DigitalPebble/storm-crawler/blob/master/external/solr/src/main/java/com/digitalpebble/storm/crawler/solr/bolt/IndexerBolt.java#L144. The particular implementation of ConcurrentUpdateSolrClient will fail the entire batch and not report back which particular document failed is this what you meant? 

I don't have any trouble with getting this responsibility out of SC, in this case will handle all of this in the Solr side. 

@ludovic-boutros I would love to hear back from the SolrHttpClient test, we switched to CUSC mainly to increase the throughput of our indexer (the other project). 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTEyNDY5Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/177,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTE2NTcxMA==,incubator-stormcrawler,135165710,177,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-08-26T20:45:24Z,2015-08-26T20:45:24Z,"@jorgelbg re-error handling :I am talking about the StatusUpdater, not the indexing bolt. 

I was thinking about CUSC but had not realised it was returned by `connection.getClient()`; for some reason I thought we could also specify a max time but that's probably me confusing with ES.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTE2NTcxMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/177,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTIwMzQyNg==,incubator-stormcrawler,135203426,177,NA,jorgelbg,1291846,Jorge Luis Betancourt,github@jorgelbg.me,NA,2015-08-26T23:18:07Z,2015-08-26T23:18:07Z,"@jnioche Yes, ES does support this scenario, but not any Solr client I'm afraid.

About the error, you're right, sorry my bad! in the StatusUpdater the Exception is just logged, in this case I can throw a new `RuntimeException()` that will be caught by the `AbstractStatusUpdaterBolt`. The other way is not logging the exception at all at let it get caught directly by the `AbstractStatusUpdaterBolt`. The first is implemented in https://github.com/jorgelbg/storm-crawler/tree/solr-statusupdater-error. But since we're leaving the commit logic outside of storm crawler, then I should remove the commits on the entire solr module right?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTIwMzQyNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/177,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTMyNzk0OQ==,incubator-stormcrawler,135327949,177,NA,ludovic-boutros,13764888,Ludovic Boutros ,,NA,2015-08-27T07:53:24Z,2015-08-27T07:53:24Z,"@jorgelbg Hopefully I will be ready tomorrow for a PR. I will let you know if we need to create batches with something like a callback mechanism in order to acknowledge tuples correctly.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTMyNzk0OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/177,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTMzODI3NQ==,incubator-stormcrawler,135338275,177,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-08-27T08:23:15Z,2015-08-27T08:23:15Z,"> But since we're leaving the commit logic outside of storm crawler, then I should remove the commits on the entire solr module right?

yes, we should have the same behaviour for both the StatusUpdater and the IndexingBolt.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTMzODI3NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/177,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTMzODc5OQ==,incubator-stormcrawler,135338799,177,NA,jorgelbg,1291846,Jorge Luis Betancourt,github@jorgelbg.me,NA,2015-08-27T08:26:36Z,2015-08-27T08:26:36Z,"Ok, I'll wait until @ludovic-boutros wraps things up and then we can review the PR, if thats ok. The module README file also needs to be updated to remove the `solr.TYPE.commit.size` configuration option, but thats easy :)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTMzODc5OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/177,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTQ1NjI2NA==,incubator-stormcrawler,135456264,177,NA,ludovic-boutros,13764888,Ludovic Boutros ,,NA,2015-08-27T14:44:28Z,2015-08-27T14:44:28Z,"Ok, here is what I can observe now with a _HttpSolrClient_, auto commit and auto soft commit:

![capture d ecran 2015-08-27 a 16 30 54](https://cloud.githubusercontent.com/assets/13764888/9523366/f02bcdf4-4cd9-11e5-906e-f860b9a6fc4e.png)

It could require some tuning depending on the hardware/sharding.

I think we should not use the _ConcurrentUpdateSolrServer_ class because the updates are asynchronous and this means that the behavior would be different in a sharded environment (the _CouldSolrClient_ is synchronous).

The PR will follow today or tomorrow. It simplifies the code, which is always good.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTQ1NjI2NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/177,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTY2MzUxNQ==,incubator-stormcrawler,135663515,177,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-08-28T07:41:33Z,2015-08-28T07:41:33Z,"thanks @ludovic-boutros sounds great!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTY2MzUxNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/177,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTcyMzI5Ng==,incubator-stormcrawler,135723296,177,NA,ludovic-boutros,13764888,Ludovic Boutros ,,NA,2015-08-28T09:53:09Z,2015-08-28T09:53:09Z,"PR done.
Comments welcome ;)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNTcyMzI5Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/177,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNjgwNTIzMg==,incubator-stormcrawler,136805232,177,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-09-01T17:31:15Z,2015-09-01T17:31:15Z,"@jorgelbg did you have a look at this? 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNjgwNTIzMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/182,https://api.github.com/repos/apache/incubator-stormcrawler/issues/182,incubator-stormcrawler,104901556,182,Fix Solr module documentation (commit size parameter),ludovic-boutros,13764888,Ludovic Boutros ,,CLOSED,2015-09-04T14:31:55Z,2015-09-21T20:08:22Z,"The documentation of the Solr external storage module contains batch and commit size parameters.
They have been removed since the usage of autoCommit/autoSoftCommit in Solr.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/182/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/182,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNzc4MDkyNg==,incubator-stormcrawler,137780926,182,NA,jorgelbg,1291846,Jorge Luis Betancourt,github@jorgelbg.me,NA,2015-09-04T16:19:53Z,2015-09-04T16:19:53Z,"I'm going to commit the change to the README in the afternoon.

On Fri, Sep 4, 2015 at 10:31 AM, ludovic-boutros notifications@github.com
wrote:

> The documentation of the Solr external storage module contains batch and
> commit size parameters.
> They have been removed since the usage of autoCommit/autoSoftCommit in
> Solr.
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/DigitalPebble/storm-crawler/issues/182.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNzc4MDkyNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/182,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0MTc3NDg5Nw==,incubator-stormcrawler,141774897,182,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-09-20T10:46:10Z,2015-09-20T10:46:10Z,"@jorgelbg could you please amend the README file? Thanks!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0MTc3NDg5Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/182,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0MjA5NDkzMQ==,incubator-stormcrawler,142094931,182,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-09-21T20:08:22Z,2015-09-21T20:08:22Z,"Fixed in #189
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0MjA5NDkzMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/183,https://api.github.com/repos/apache/incubator-stormcrawler/issues/183,incubator-stormcrawler,104905054,183,Add bufferization in the Solr indexing process,ludovic-boutros,13764888,Ludovic Boutros ,,CLOSED,2015-09-04T14:48:28Z,2017-02-18T12:51:19Z,"Currently, each document to be indexed is directly sent to Solr.
This allows a very easy acknowledgement mechanism of Storm tuples.

In order to improve the throughput, a bufferization mechanism could be implemented.

This mechanism should take in account:
- non-cloud and cloud modes.
- correct errors management and tuple acknowlegement.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/183/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/183,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNzc4MDQxOQ==,incubator-stormcrawler,137780419,183,NA,jorgelbg,1291846,Jorge Luis Betancourt,github@jorgelbg.me,NA,2015-09-04T16:17:24Z,2015-09-04T16:17:24Z,"I think we can extend the CUSC class, essentially this class does all the queuing for us, provides the threads to empty the queue as quickly as possible and provides a `handleError()` method that can be used to implement our own logic, by default this method only logs the error.

By default the CUSC client queues requests, meaning that if we keep 1 doc per request in the queue we can handle the case for one document failing to be indexed and then fail the tuple, this means that the acknowledge/failed action will be taken by the client instead of the bolt. The problem with Solr is that when a add request is made with several documents inside the batch fails and not report the actual doc that caused the error, but in the end will continue to send one doc per request if we want to ack/fail the actual document/tuple, the problem is we still get to send one doc per request.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNzc4MDQxOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/183,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNzc5MTgxNg==,incubator-stormcrawler,137791816,183,NA,ludovic-boutros,13764888,Ludovic Boutros ,,NA,2015-09-04T17:00:00Z,2015-09-04T17:00:00Z,"So true. I think it does not worth it.

And it is not recommended to use CUSC with SolrCloud.
The improvements are on the Solr side I think. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDEzNzc5MTgxNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/183,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3ODk5MTk0OQ==,incubator-stormcrawler,278991949,183,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-02-10T16:32:01Z,2017-02-10T16:32:01Z,Note to self \: http://lucene.apache.org/solr/6_4_1/solr-solrj/index.html?org/apache/solr/client/solrj/impl/ConcurrentUpdateSolrClient.html,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3ODk5MTk0OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/185,https://api.github.com/repos/apache/incubator-stormcrawler/issues/185,incubator-stormcrawler,106535253,185,WARC bolt,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-09-15T11:21:54Z,2016-04-11T16:13:24Z,"We've been working on a WARC generator for Nutch lately, doing the same with SC should be quite straightforward.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/185/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/185,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE2NTQ2MTYwMA==,incubator-stormcrawler,165461600,185,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-12-17T14:10:19Z,2015-12-17T14:10:19Z,"The WARC files should probably be generated on HDFS, see [https://github.com/apache/storm/tree/master/external/storm-hdfs]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE2NTQ2MTYwMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/185,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIwODQzMDIzMA==,incubator-stormcrawler,208430230,185,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-04-11T16:13:24Z,2016-04-11T16:13:24Z,"Now available as an external repo at [https://github.com/DigitalPebble/sc-warc]. This might make it to the main repo based on users' feedback. Marking as closed for now.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIwODQzMDIzMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/187,https://api.github.com/repos/apache/incubator-stormcrawler/issues/187,incubator-stormcrawler,107177226,187,Remove PrinterBolt and IndexerBolt.java,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-09-18T10:33:16Z,2015-09-24T10:13:23Z,"[PrinterBolt](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/storm/crawler/bolt/PrinterBolt.java) is not as useful as [StdOutIndexer](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/storm/crawler/indexing/StdOutIndexer.java), which extends AbstractIndexerBolt and provides a similar functionality.

As for [IndexerBolt.jav](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/storm/crawler/bolt/IndexerBolt.java), I doubt anyone ever uses it. All it does is add a level of abstraction over the actual implementation used. In practice it is just as quick to declare the right class in the topology directly compared to having to do that via configuration.

@DigitalPebble/committers-crawler any thoughts on this?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/187/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/187,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0MTU0NzkxMg==,incubator-stormcrawler,141547912,187,NA,jorgelbg,1291846,Jorge Luis Betancourt,github@jorgelbg.me,NA,2015-09-18T19:37:13Z,2015-09-18T19:37:13Z,":+1: on removing PrinterBolt, perhaps for testing purposes to do some sort of debugging could be helpful but this is very easy to implement if anyone need it.

 I agree that defining the configuration key is as easy as defining the right class in the topology, I would say even more logical, because you need to implement the topology class according to your needs and later on specify the FQDN in the configuration file, so :+1:. The only case I can think of for keeping IndexerBolt around is for quickly switching the indexer implementation, but how often this could be used? 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0MTU0NzkxMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/187,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0MTY5NTgwOA==,incubator-stormcrawler,141695808,187,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-09-19T18:22:44Z,2015-09-19T18:22:44Z,"> perhaps for testing purposes to do some sort of debugging could be helpful 

we have StdOutIndexer exactly for that purpose

> how often this could be used

close to never I'd think

It probably creates more confusion than anything else

thanks for your comments
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0MTY5NTgwOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/187,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0MjMxMzQ3Mw==,incubator-stormcrawler,142313473,187,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-09-22T14:57:29Z,2015-09-22T14:57:29Z,"We could add a simple bolt extending AbstractStatusUpdaterBolt, comparable to what StdOutIndexer does for the indexing. It would display the nextFetch Date for instance and would be useful for debugging. We can then remove the PrinterBolt
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0MjMxMzQ3Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/187,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0MjMyMjg3Ng==,incubator-stormcrawler,142322876,187,NA,jorgelbg,1291846,Jorge Luis Betancourt,github@jorgelbg.me,NA,2015-09-22T15:24:15Z,2015-09-22T15:24:15Z,"What I meant with the debug purposes was basically to take a peek into the data sent between bolts, the StdOutIndexer does a great job for debugging what gets indexed/persisted in your storage. 

The alternative provided with a simple extending AbstractStatusUpdaterBolt looks like a great solution, although again since the PrinterBolt is so easy to implement perhaps the debugging thinking I was using is not required at all, but guess that providing the new bolt doesn't do any harm.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0MjMyMjg3Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/187,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0Mjg3ODE0OA==,incubator-stormcrawler,142878148,187,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-09-24T09:56:32Z,2015-09-24T09:56:32Z,"@jorgelbg see [https://issues.apache.org/jira/browse/STORM-954] in the upcoming 0.11.0. This would be a nicer way of having a generic debugger than the PrinterBolt
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0Mjg3ODE0OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/187,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0Mjg4MTc0Mw==,incubator-stormcrawler,142881743,187,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-09-24T10:13:23Z,2015-09-24T10:13:23Z,"Implemented in [56e19ea7b60389bb2acd07b59caa32dd28a31290]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0Mjg4MTc0Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/190,https://api.github.com/repos/apache/incubator-stormcrawler/issues/190,incubator-stormcrawler,107941302,190,AbstractIndexingBolt to use status stream in declareOutputFields,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-09-23T15:06:47Z,2015-10-23T13:09:50Z,"We currently use StatusStreamBolt post-parsing to notify the status updater that a web page has been successfully processed, however there could be situations where the we have an indexing bolt (e.g. SOLR, ES or Cloudsearch) which could encounter an issue while processing the document. The tuple would be failed, however there is no guarantee that the status updater hasn't already updated the status for that URL.

See [ESCrawlTopology](https://github.com/DigitalPebble/storm-crawler/blob/master/external/elasticsearch/src/main/java/com/digitalpebble/storm/crawler/elasticsearch/ESCrawlTopology.java#L67) for instance. 

What we could do would be to implement declareOutputFields in AbstractIndexingBolt so that it uses the status stream and make so that the bolts extending it emit the tuples on that stream. As a result we would be sure that a URL would have its status updated ONLY if it has been indexed successfully. Of course the topology class does not have to connect the output of the indexer to the status updater and could chose to use the StatusStreamBolt as we do now.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/190/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/190,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1MDU2NjcyMQ==,incubator-stormcrawler,150566721,190,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-10-23T13:09:49Z,2015-10-23T13:09:49Z,"Implemented in [b1363b0]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1MDU2NjcyMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/191,https://api.github.com/repos/apache/incubator-stormcrawler/issues/191,incubator-stormcrawler,108095571,191,[ElasticSearch] Compare ES module with storm-elasticsearch,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-09-24T09:44:06Z,2016-03-10T16:41:37Z,"See [https://github.com/apache/storm/pull/573]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/191/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/191,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0Mjg3ODQzOQ==,incubator-stormcrawler,142878439,191,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-09-24T09:58:30Z,2015-09-24T09:58:30Z,"So now there is a library from Elastic + one from Storm + ours ?!?!?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0Mjg3ODQzOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/191,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0OTg0NjEzMQ==,incubator-stormcrawler,149846131,191,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-10-21T10:13:21Z,2015-10-21T10:13:21Z,"That library currently doesn't have a spout we could use or a metrics handler. It has resources for Trident - which we don't need. 

It has some test classes we could take as example to run a dummy ES index.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0OTg0NjEzMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/191,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4MzM4NjY4NQ==,incubator-stormcrawler,183386685,191,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-02-12T16:03:12Z,2016-02-12T16:03:12Z,"storm-elasticsearch does not use bulkprocessor; it uses TransportClient, whereas we use nodeBuilder when ES is on the localhost.

The wrapper around the client ([StormElasticSearchClient](https://github.com/apache/storm/blob/master/external/storm-elasticsearch/src/main/java/org/apache/storm/elasticsearch/common/StormElasticSearchClient.java))  is shared by the various instances of a bolt. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4MzM4NjY4NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/192,https://api.github.com/repos/apache/incubator-stormcrawler/issues/192,incubator-stormcrawler,108097928,192,[SOLR] Compare SOLR module with one from Storm and Lucid,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-09-24T09:57:46Z,2016-11-01T13:25:38Z,"SOLR connector [apache/storm#665]

@jorgelbg did you know about that?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/192/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/192,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0MjkwNjkxNA==,incubator-stormcrawler,142906914,192,NA,ludovic-boutros,13764888,Ludovic Boutros ,,NA,2015-09-24T11:51:50Z,2015-09-24T11:51:50Z,"The main differences I can see at first glance are:
- I like the commit strategy abstraction and the ack management (A batch is acked (or not) in globality)  
- I do not like the fact that only hard commit seems to be used (This should be configurable)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0MjkwNjkxNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/192,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0Mjk2MTMwOA==,incubator-stormcrawler,142961308,192,NA,jorgelbg,1291846,Jorge Luis Betancourt,github@jorgelbg.me,NA,2015-09-24T15:22:01Z,2015-09-24T15:22:01Z,"I didn't know about this, looks very interesting, on a more closer look:
- Only provide support for SolrCloud and no way of using a non distributed Solr server
- Provide an abstraction/mapping layer that use some endpoints to fetch the Solr schema
- The implemented commit strategy is based on a document count threshold
- The ack/fail mechanism uses a queue when the commit is issued against Solr, then the queued tuples are acked/failed (the entire batch)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0Mjk2MTMwOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/192,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIwMDc0OTAxMg==,incubator-stormcrawler,200749012,192,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-03-24T09:16:10Z,2016-03-24T09:16:10Z,"There is also one from Lucid [https://github.com/lucidworks/storm-solr]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIwMDc0OTAxMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/192,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NzU2NTUzOQ==,incubator-stormcrawler,257565539,192,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-11-01T13:25:38Z,2016-11-01T13:25:38Z,"Closing for now, hasn't been much interest in the SOLR module lately.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NzU2NTUzOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/193,https://api.github.com/repos/apache/incubator-stormcrawler/issues/193,incubator-stormcrawler,108296444,193,Add default config file in resources,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-09-25T09:58:13Z,2015-10-16T08:18:54Z,"We currently have a class listing some of the constants and an [example of conf file](https://github.com/DigitalPebble/storm-crawler/blob/master/core/crawler-conf.yaml) for users to use at runtime. 

It would be good to have a default config file in the resources which would be used to list all the known configs as well as their default values. This would get loaded automatically  when using a [ConfigurableTopology](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/storm/crawler/ConfigurableTopology.java) and the values would then be overridden by whatever the users specify in their custom conf files. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/193/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/193,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0NDYxMzU4Mw==,incubator-stormcrawler,144613583,193,NA,jorgelbg,1291846,Jorge Luis Betancourt,github@jorgelbg.me,NA,2015-10-01T03:56:20Z,2015-10-01T03:56:20Z,"+1 I don't see any reason not to have this, it would make things even easier to understand where the default value is coming for a given setting.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0NDYxMzU4Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/193,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0ODM4MzMzMA==,incubator-stormcrawler,148383330,193,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-10-15T13:18:58Z,2015-10-15T13:18:58Z,"Implemented in [22d7e19]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0ODM4MzMzMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/194,https://api.github.com/repos/apache/incubator-stormcrawler/issues/194,incubator-stormcrawler,108547904,194,Ack tick tuples,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-09-27T16:59:42Z,2015-09-28T09:07:49Z,"According to [http://www.michael-noll.com/blog/2014/09/15/apache-storm-training-deck-and-tutorial/] slide 85 - tick tuples must be acked.

 This should be done in [https://github.com/DigitalPebble/storm-crawler/blob/20890f11a6ca02ce37c1d56134637191716428d3/core/src/main/java/com/digitalpebble/storm/crawler/bolt/FetcherBolt.java#L777] and [https://github.com/DigitalPebble/storm-crawler/blob/ffecc00ed4634026b2ecf93332d3e6314c725aab/external/aws/src/main/java/com/digitalpebble/stormcrawler/aws/bolt/CloudSearchIndexerBolt.java#L186].

Must also check that it does not happen in other parts of the code.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/194/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/194,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0MzY4NTM0Ng==,incubator-stormcrawler,143685346,194,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-09-28T09:07:49Z,2015-09-28T09:07:49Z,"Fixed in [ef5197a]]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0MzY4NTM0Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/196,https://api.github.com/repos/apache/incubator-stormcrawler/issues/196,incubator-stormcrawler,109991905,196,FileSpout chokes on very large files,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-10-06T11:50:22Z,2015-10-13T14:16:45Z,"Instead of loading everything into memory it could buffer lines and read only when needed.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/196/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/196,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0NzcxMDcyOA==,incubator-stormcrawler,147710728,196,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-10-13T13:15:21Z,2015-10-13T13:15:21Z,"thanks @mattburns 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0NzcxMDcyOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/196,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0NzcyNzczOQ==,incubator-stormcrawler,147727739,196,NA,jorgelbg,1291846,Jorge Luis Betancourt,github@jorgelbg.me,NA,2015-10-13T14:16:33Z,2015-10-13T14:16:33Z,"I took a shot at this issue :) but using `FileUtils.lineIterator` from commons-io instead https://github.com/jorgelbg/storm-crawler/commit/e088a2560da7b4bb1c78ed4f151d0b6add24ad9b
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0NzcyNzczOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/197,https://api.github.com/repos/apache/incubator-stormcrawler/issues/197,incubator-stormcrawler,110421701,197,[ElasticSearch] store metadata as structured object,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-10-08T10:41:26Z,2015-10-21T10:06:55Z,"We currently put everything into a single line with tab separated values but could use a map of objects which would allow to query on the metadata values. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/197/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/197,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0NzUyMzE5MQ==,incubator-stormcrawler,147523191,197,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-10-12T21:07:03Z,2015-10-12T21:07:03Z,"Doesn't have to be a nested object but could simply be the use of a common prefix e.g. 'metadata' with [dynamic mapping](https://www.elastic.co/guide/en/elasticsearch/guide/current/custom-dynamic-mapping.html)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0NzUyMzE5MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/197,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0Nzc0MTkzNw==,incubator-stormcrawler,147741937,197,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-10-13T15:00:36Z,2015-10-13T15:00:36Z,"First version in 
[metadataAsMap c0a7da3] store metadata as structured object

Need to find how to define properties for any field within the 'metadata' object.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0Nzc0MTkzNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/197,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0Nzg0MzAzNA==,incubator-stormcrawler,147843034,197,NA,jorgelbg,1291846,Jorge Luis Betancourt,github@jorgelbg.me,NA,2015-10-13T20:30:25Z,2015-10-13T20:30:25Z,"With the current implementation the metadata gets indexed as an `object` field if we rely on dynamic mapping right? At least looks that way on a small test I did: 

``` json
""_source"": {
   ""url"": ""http://addons.firefoxmania.uci.cu"",
   ""status"": ""DISCOVERED"",
   ""metadata"": {
      ""url.path"": [
         ""http://firefoxmania.uci.cu""
      ],
      ""depth"": [
         ""1""
      ]
   },
   ""nextFetchDate"": ""2015-10-13T19:33:25.902Z""
}
```

couldn't this cause some sort of error if the values in the `metadata` object are multivalued? as described in [object arrays](https://www.elastic.co/guide/en/elasticsearch/guide/current/complex-core-fields.html#object-arrays) and [nested objects](https://www.elastic.co/guide/en/elasticsearch/guide/current/nested-objects.html)? This could be fixed by forcing metadata to be a `nested` like you suggested initially. 

Using the custom dynamic mapping would mean to ""flatten"" the metadata object? getting each field with something like `metadata.fieldname` ?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0Nzg0MzAzNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/197,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0Nzg1NTc3NQ==,incubator-stormcrawler,147855775,197,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-10-13T21:14:07Z,2015-10-13T21:14:07Z,"@jorgelbg the metadata values are backed by an array 

```
builder.array(mdKey, values);
```

so this will be fine when there are multiple values.

Having a nested would be an overkill I think.

> Using the custom dynamic mapping would mean to ""flatten"" the metadata object? getting each field with something like metadata.fieldname ?

I don't think so. Apparently there is a  `path_match` which we could use with e.g. `metadata.*` as a value so that we could make those fields indexable but not analysed nor stored.

This should be a lot better than the current storage we have where we put all the metadata key values on a single line with tab separations.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0Nzg1NTc3NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/197,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0Nzg2NTAzNQ==,incubator-stormcrawler,147865035,197,NA,jorgelbg,1291846,Jorge Luis Betancourt,github@jorgelbg.me,NA,2015-10-13T21:55:27Z,2015-10-13T21:55:27Z,"@jnioche Indeed is a lot better than before.

Actually using the default `object` type give some ""flat"" object style, for instance, in the document I posted, I can issue a query against a `metadata.depth` or `metadata.url.path`, taking a closer look on [inner objects](https://www.elastic.co/guide/en/elasticsearch/guide/current/complex-core-fields.html#_how_inner_objects_are_indexed) shows that basically when an `object` type is used, Elasticsearch flattens internally the structure, otherwise using the `nested` type cause some internal documents to be created.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0Nzg2NTAzNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/197,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0OTg0NDcwMg==,incubator-stormcrawler,149844702,197,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-10-21T10:06:55Z,2015-10-21T10:06:55Z,"Implemented in #201 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0OTg0NDcwMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/198,https://api.github.com/repos/apache/incubator-stormcrawler/issues/198,incubator-stormcrawler,110449562,198,[ElasticSearch] Spout one instance per ES shard,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-10-08T13:20:59Z,2016-01-27T09:30:52Z,"[22e06aa1] added a check that throws an exception if more than one spout instance is created

we might want to have more than once instance but get each instance to connect directly to a given ES shard. The number of shard could be detected automatically instead of being set manually.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/198/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/198,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0NzY3MzU4Mw==,incubator-stormcrawler,147673583,198,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-10-13T10:20:04Z,2015-10-13T10:20:04Z,"See [https://github.com/elastic/elasticsearch-hadoop/blob/master/storm/src/main/java/org/elasticsearch/storm/EsSpout.java#L118]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE0NzY3MzU4Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/198,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE3MDk0NzcwNQ==,incubator-stormcrawler,170947705,198,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-01-12T15:30:29Z,2016-01-12T15:30:29Z,"Implemented in #232 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE3MDk0NzcwNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/199,https://api.github.com/repos/apache/incubator-stormcrawler/issues/199,incubator-stormcrawler,110459268,199,Use Maven-Shade everywhere,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-10-08T14:08:53Z,2015-10-09T13:17:05Z,"I got into an issue when using a jar built with the maven-assembly-plugin. We should check that shade is used everywhere.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/199/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/202,https://api.github.com/repos/apache/incubator-stormcrawler/issues/202,incubator-stormcrawler,112555759,202,Change Status to ERROR when FETCH_ERROR above threshold,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-10-21T10:16:35Z,2015-10-22T13:01:44Z,"Should be done in the [AbstractStatusUpdaterBolt](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/storm/crawler/persistence/AbstractStatusUpdaterBolt.java) post filtering of metadata (so that the corresponding key value gets written without having to configure it) and before the scheduler is called (so that the backend gets the right value).
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/202/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/204,https://api.github.com/repos/apache/incubator-stormcrawler/issues/204,incubator-stormcrawler,113016227,204,Release 0.7,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-10-23T13:11:56Z,2015-11-03T15:28:19Z,"@DigitalPebble/committers-crawler any objections? Anything you think we should include?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/204/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/204,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1MzM4ODQ4Ng==,incubator-stormcrawler,153388486,204,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-11-03T15:28:19Z,2015-11-03T15:28:19Z,"Done. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1MzM4ODQ4Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/205,https://api.github.com/repos/apache/incubator-stormcrawler/issues/205,incubator-stormcrawler,114078356,205,URL normalisation : Illegal character in query ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-10-29T15:41:11Z,2016-03-03T11:56:20Z,"```
2015-10-29T15:38:07.623+0000 c.d.s.c.b.SimpleFetcherBolt [ERROR] Exception while fetching http://www.quanjing.com/search.aspx?q=top-651451||1|60|1|2||||&Fr=4
java.lang.IllegalArgumentException: Illegal character in query at index 48: http://www.quanjing.com/search.aspx?q=top-651451||1|60|1|2||||&Fr=4
    at java.net.URI.create(URI.java:852) ~[na:1.8.0_66]
    at org.apache.http.client.methods.HttpGet.<init>(HttpGet.java:69) ~[stormjar.jar:na]
    at com.digitalpebble.storm.crawler.protocol.httpclient.HttpProtocol.getProtocolOutput(HttpProtocol.java:133) ~[stormjar.jar:na]
```

Ideally these URLs should be normalised to be URI compatible. In the meantime we could add a basic URL filter which tries to convert them into URIs and discards them if that throws an exception. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/205/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/205,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1NTgyMDQ2MQ==,incubator-stormcrawler,155820461,205,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-11-11T15:40:14Z,2015-11-11T15:40:14Z,"See [PR in CC](https://github.com/crawler-commons/crawler-commons/pull/106)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1NTgyMDQ2MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/205,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE3NDk3MjAwNA==,incubator-stormcrawler,174972004,205,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-01-26T12:06:23Z,2016-01-26T12:06:23Z,"```
171422 [FetcherThread] ERROR c.d.s.c.b.FetcherBolt - Exception while fetching http://vins.lemonde.fr?utm_source=LeMonde_partenaire_hp&utm_medium=EMPLACEMENT PARTENAIRE&utm_term=&utm_content=&utm_campaign=LeMonde_partenaire_hp
java.lang.IllegalArgumentException: Illegal character in query at index 78: http://vins.lemonde.fr?utm_source=LeMonde_partenaire_hp&utm_medium=EMPLACEMENT PARTENAIRE&utm_term=&utm_content=&utm_campaign=LeMonde_partenaire_hp
    at java.net.URI.create(URI.java:852) ~[?:1.8.0_72]
    at org.apache.http.client.methods.HttpGet.<init>(HttpGet.java:69) ~[httpclient-4.4.1.jar:4.4.1]
    at com.digitalpebble.storm.crawler.protocol.httpclient.HttpProtocol.getProtocolOutput(HttpProtocol.java:123) ~[classes/:?]
    at com.digitalpebble.storm.crawler.bolt.FetcherBolt$FetcherThread.run(FetcherBolt.java:499) [classes/:?]
Caused by: java.net.URISyntaxException: Illegal character in query at index 78: http://vins.lemonde.fr?utm_source=LeMonde_partenaire_hp&utm_medium=EMPLACEMENT PARTENAIRE&utm_term=&utm_content=&utm_campaign=LeMonde_partenaire_hp
    at java.net.URI$Parser.fail(URI.java:2848) ~[?:1.8.0_72]
    at java.net.URI$Parser.checkChars(URI.java:3021) ~[?:1.8.0_72]
    at java.net.URI$Parser.parseHierarchical(URI.java:3111) ~[?:1.8.0_72]
    at java.net.URI$Parser.parse(URI.java:3053) ~[?:1.8.0_72]
    at java.net.URI.<init>(URI.java:588) ~[?:1.8.0_72]
    at java.net.URI.create(URI.java:850) ~[?:1.8.0_72]
    ... 3 more
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE3NDk3MjAwNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/205,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE5MTcyNDk1NQ==,incubator-stormcrawler,191724955,205,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-03-03T11:56:20Z,2016-03-03T11:56:20Z,"Implemented basic mechanism in 04eec35 using the code from crawler-commons (which took it from Nutch)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE5MTcyNDk1NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/206,https://api.github.com/repos/apache/incubator-stormcrawler/issues/206,incubator-stormcrawler,114105357,206,HTTP protocol should allow to limit amount of content fetched,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-10-29T17:38:24Z,2016-02-26T13:19:32Z,"The previous implementation we had which was taken from Nutch could do that but not the one we currently have. This is useful for cases where the URL points to a multimedia stream for instance.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/206/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/206,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1MjI2NDEzOA==,incubator-stormcrawler,152264138,206,NA,kkrugler,66217,Ken Krugler,ken@transpac.com,NA,2015-10-29T17:50:08Z,2015-10-29T17:50:08Z,"By ""limit content fetched"" do you mean it shouldn't fetch content that has a mime type other than ones of interest? Or is there some multi-part content where you want to skip pieces of the content stream?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1MjI2NDEzOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/206,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1MjI2NDc2MA==,incubator-stormcrawler,152264760,206,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-10-29T17:52:12Z,2015-10-29T17:52:12Z,"Simply that it should stop fetching past a given byte length, similar to what `http.content.limit` does in Nutch.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1MjI2NDc2MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/206,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1MjI2NTQ0Mw==,incubator-stormcrawler,152265443,206,NA,kkrugler,66217,Ken Krugler,ken@transpac.com,NA,2015-10-29T17:54:39Z,2015-10-29T17:54:39Z,"For the SimpleHttpFetcher in bixo (not sure about what's in crawler-commons) we have a default limit, and a per-mime type limit. That way you can avoid truncating binary content (like PDFs, Word docs, etc) where the parser will choke if the content is truncated. That still leaves the issue of gzipped content, where truncation also causes a problem
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1MjI2NTQ0Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/206,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1MjI2NzEwNw==,incubator-stormcrawler,152267107,206,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-10-29T18:00:29Z,2015-10-29T18:00:29Z,"Makes sense to truncate per mime type indeed. I can see how you do that in [https://github.com/bixo/bixo/blob/master/src/main/java/bixo/fetcher/SimpleHttpFetcher.java#L460].
Doing that indiscriminately would be good enough for now, ideally without having to hack the HttpClient code too much.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1MjI2NzEwNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/206,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1MjMwNzA1MQ==,incubator-stormcrawler,152307051,206,NA,jorgelbg,1291846,Jorge Luis Betancourt,github@jorgelbg.me,NA,2015-10-29T20:20:27Z,2015-10-29T20:20:27Z,"+1
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1MjMwNzA1MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/207,https://api.github.com/repos/apache/incubator-stormcrawler/issues/207,incubator-stormcrawler,114137229,207,Store the metadata field in the status collection to be searchable,jorgelbg,1291846,Jorge Luis Betancourt,github@jorgelbg.me,CLOSED,2015-10-29T20:19:38Z,2015-10-31T11:50:03Z,"Similar to #197 #201 but for Solr, in this case since Solr have a different approach to nested objects/documents, perhaps a better approach could be to flatten the metadata field using a prefix, combined with a dynamic setting? 

Thoughts on this are welcome, I think that using nested documents could be an overkill, plus since Solr doesn't ""hide"" the child documents the status collection will be packed with additional metadata/child documents.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/207/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/207,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1MjMzMTMwMA==,incubator-stormcrawler,152331300,207,NA,ludovic-boutros,13764888,Ludovic Boutros ,,NA,2015-10-29T21:19:02Z,2015-10-29T21:19:02Z,"@jorgelbg That would be great. I also agree with the flattening of the metadata.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1MjMzMTMwMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/207,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1MjQ1NzIwMQ==,incubator-stormcrawler,152457201,207,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-10-30T08:15:36Z,2015-10-30T08:15:36Z,"+1 thanks!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1MjQ1NzIwMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/207,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1MjUzMDQwOA==,incubator-stormcrawler,152530408,207,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-10-30T13:47:49Z,2015-10-30T13:47:49Z,"@jorgelbg shall we mark it for release 0.7?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1MjUzMDQwOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/207,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1MjU0MzMyMw==,incubator-stormcrawler,152543323,207,NA,jorgelbg,1291846,Jorge Luis Betancourt,github@jorgelbg.me,NA,2015-10-30T14:39:24Z,2015-10-30T14:39:24Z,"@jnioche yes sure! I'll submit a PR later today
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1MjU0MzMyMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/208,https://api.github.com/repos/apache/incubator-stormcrawler/issues/208,incubator-stormcrawler,114242039,208,FetcherBolts do not handle malformed URLs properly,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-10-30T10:25:13Z,2015-10-30T10:56:51Z,"FetcherBolt neither acks nor fails tuples containing a malformed URL; it does not generate a tuple with an error status on the status stream either.

SimpleFetcherBolt acks the tuples but does not generate a tuple with an error status on the status stream.

I've written a test case to illustrate this and will commit it alongside a fix.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/208/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/208,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1MjQ5NTUyOA==,incubator-stormcrawler,152495528,208,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-10-30T10:56:51Z,2015-10-30T10:56:51Z,"Fixed in [66e8747fca40c4fee579b1f8379d21f16c663f70] and previous commit
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1MjQ5NTUyOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/211,https://api.github.com/repos/apache/incubator-stormcrawler/issues/211,incubator-stormcrawler,115070492,211,Discover sitemap files automatically from robots.txt ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-11-04T14:54:21Z,2015-11-27T14:44:36Z,"We already have resources to process sitemap files but at the moment these URLs must be either used as seed or generated e.g. by custom parsefilters.  We could have an option to discover them automatically from the robots.txt files.

The Fetcher bolts [https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/storm/crawler/bolt/FetcherBolt.java#L436] already access the robots file so this would merely be a matter of calling `rules.getSitemaps()`.

The drawbacks would be that the sitemap URLs would be sent to the _status_ stream for _every_ URL and not just once, but since the abstract status updater has an internal cache the sitemap URLs would not be fetched more than once. ~~The other disadvantage would be that the sitemap URLs would be added indiscriminately - even if their content is not relevant to a particular crawl~~. The sitemap URLs are filtered just like any redirection or outlink. If they are not relevant they can easily be excluded.  
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/211/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/211,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE2MDE1MjgxOQ==,incubator-stormcrawler,160152819,211,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-11-27T14:43:30Z,2015-11-27T14:43:30Z,"Implemented in [92f9701]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE2MDE1MjgxOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/212,https://api.github.com/repos/apache/incubator-stormcrawler/issues/212,incubator-stormcrawler,115381993,212,Fails run CrawlTopology with java.lang.NoClassDefFoundError: org/w3c/dom/ElementTraversal,jiangytcn,1834365,Jiang Yitao ,jiangyitao.jyt@alibaba-inc.com,CLOSED,2015-11-05T21:47:16Z,2015-11-07T10:41:34Z,"Hi, 
I just clone the repository, followed the guide to run the topology in local cluster, but unluckily failed with following exceptions

7493 [Thread-22-sitemap] ERROR backtype.storm.util - Async loop died!
java.lang.NoClassDefFoundError: org/w3c/dom/ElementTraversal
        at java.lang.ClassLoader.defineClass1(Native Method) ~[na:1.7.0_80]
        at java.lang.ClassLoader.defineClass(ClassLoader.java:800) ~[na:1.7.0_80]
        at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) ~[na:1.7.0_80]
        at java.net.URLClassLoader.defineClass(URLClassLoader.java:449) ~[na:1.7.0_80]
        at java.net.URLClassLoader.access$100(URLClassLoader.java:71) ~[na:1.7.0_80]
        at java.net.URLClassLoader$1.run(URLClassLoader.java:361) ~[na:1.7.0_80]
        at java.net.URLClassLoader$1.run(URLClassLoader.java:355) ~[na:1.7.0_80]
        at java.security.AccessController.doPrivileged(Native Method) ~[na:1.7.0_80]
        at java.net.URLClassLoader.findClass(URLClassLoader.java:354) ~[na:1.7.0_80]
        at java.lang.ClassLoader.loadClass(ClassLoader.java:425) ~[na:1.7.0_80]
        at java.lang.ClassLoader.loadClass(ClassLoader.java:358) ~[na:1.7.0_80]
        at org.apache.xerces.parsers.AbstractDOMParser.startDocument(Unknown Source) ~[xercesImpl-2.11.0.jar:na]
        at org.apache.xerces.impl.dtd.XMLDTDValidator.startDocument(Unknown Source) ~[xercesImpl-2.11.0.jar:na]
        at org.apache.xerces.impl.XMLDocumentScannerImpl.startEntity(Unknown Source) ~[xercesImpl-2.11.0.jar:na]
        at org.apache.xerces.impl.XMLVersionDetector.startDocumentParsing(Unknown Source) ~[xercesImpl-2.11.0.jar:na]
        at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source) ~[xercesImpl-2.11.0.jar:na]
        at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source) ~[xercesImpl-2.11.0.jar:na]
        at org.apache.xerces.parsers.XMLParser.parse(Unknown Source) ~[xercesImpl-2.11.0.jar:na]
        at org.apache.xerces.parsers.DOMParser.parse(Unknown Source) ~[xercesImpl-2.11.0.jar:na]
        at org.apache.xerces.jaxp.DocumentBuilderImpl.parse(Unknown Source) ~[xercesImpl-2.11.0.jar:na]
        at com.digitalpebble.storm.crawler.filtering.regex.RegexURLNormalizer.readConfiguration(RegexURLNormalizer.java:168) ~[classes/:na]
        at com.digitalpebble.storm.crawler.filtering.regex.RegexURLNormalizer.readRules(RegexURLNormalizer.java:156) ~[classes/:na]
        at com.digitalpebble.storm.crawler.filtering.regex.RegexURLNormalizer.configure(RegexURLNormalizer.java:89) ~[classes/:na]
        at com.digitalpebble.storm.crawler.filtering.URLFilters.configure(URLFilters.java:136) ~[classes/:na]
        at com.digitalpebble.storm.crawler.filtering.URLFilters.<init>(URLFilters.java:68) ~[classes/:na]
        at com.digitalpebble.storm.crawler.bolt.SiteMapParserBolt.prepare(SiteMapParserBolt.java:298) ~[classes/:na]
        at backtype.storm.daemon.executor$fn__3439$fn__3451.invoke(executor.clj:692) ~[storm-core-0.9.5.jar:0.9.5]
        at backtype.storm.util$async_loop$fn__460.invoke(util.clj:461) ~[storm-core-0.9.5.jar:0.9.5]
        at clojure.lang.AFn.run(AFn.java:24) [clojure-1.5.1.jar:na]
        at java.lang.Thread.run(Thread.java:745) [na:1.7.0_80]
Caused by: java.lang.ClassNotFoundException: org.w3c.dom.ElementTraversal
        at java.net.URLClassLoader$1.run(URLClassLoader.java:366) ~[na:1.7.0_80]
        at java.net.URLClassLoader$1.run(URLClassLoader.java:355) ~[na:1.7.0_80]
        at java.security.AccessController.doPrivileged(Native Method) ~[na:1.7.0_80]
        at java.net.URLClassLoader.findClass(URLClassLoader.java:354) ~[na:1.7.0_80]
        at java.lang.ClassLoader.loadClass(ClassLoader.java:425) ~[na:1.7.0_80]
        at java.lang.ClassLoader.loadClass(ClassLoader.java:358) ~[na:1.7.0_80]
        ... 30 common frames omitted
7494 [Thread-22-sitemap] ERROR backtype.storm.daemon.executor - 
java.lang.NoClassDefFoundError: org/w3c/dom/ElementTraversal
        at java.lang.ClassLoader.defineClass1(Native Method) ~[na:1.7.0_80]
        at java.lang.ClassLoader.defineClass(ClassLoader.java:800) ~[na:1.7.0_80]
        at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) ~[na:1.7.0_80]
        at java.net.URLClassLoader.defineClass(URLClassLoader.java:449) ~[na:1.7.0_80]
        at java.net.URLClassLoader.access$100(URLClassLoader.java:71) ~[na:1.7.0_80]
        at java.net.URLClassLoader$1.run(URLClassLoader.java:361) ~[na:1.7.0_80]
        at java.net.URLClassLoader$1.run(URLClassLoader.java:355) ~[na:1.7.0_80]
        at java.security.AccessController.doPrivileged(Native Method) ~[na:1.7.0_80]
        at java.net.URLClassLoader.findClass(URLClassLoader.java:354) ~[na:1.7.0_80]
        at java.lang.ClassLoader.loadClass(ClassLoader.java:425) ~[na:1.7.0_80]
        at java.lang.ClassLoader.loadClass(ClassLoader.java:358) ~[na:1.7.0_80]
        at org.apache.xerces.parsers.AbstractDOMParser.startDocument(Unknown Source) ~[xercesImpl-2.11.0.jar:na]
        at org.apache.xerces.impl.dtd.XMLDTDValidator.startDocument(Unknown Source) ~[xercesImpl-2.11.0.jar:na]
        at org.apache.xerces.impl.XMLDocumentScannerImpl.startEntity(Unknown Source) ~[xercesImpl-2.11.0.jar:na]
        at org.apache.xerces.impl.XMLVersionDetector.startDocumentParsing(Unknown Source) ~[xercesImpl-2.11.0.jar:na]
        at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source) ~[xercesImpl-2.11.0.jar:na]
        at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source) ~[xercesImpl-2.11.0.jar:na]
        at org.apache.xerces.parsers.XMLParser.parse(Unknown Source) ~[xercesImpl-2.11.0.jar:na]
        at org.apache.xerces.parsers.DOMParser.parse(Unknown Source) ~[xercesImpl-2.11.0.jar:na]
        at org.apache.xerces.jaxp.DocumentBuilderImpl.parse(Unknown Source) ~[xercesImpl-2.11.0.jar:na]
        at com.digitalpebble.storm.crawler.filtering.regex.RegexURLNormalizer.readConfiguration(RegexURLNormalizer.java:168) ~[classes/:na]
        at com.digitalpebble.storm.crawler.filtering.regex.RegexURLNormalizer.readRules(RegexURLNormalizer.java:156) ~[classes/:na]
        at com.digitalpebble.storm.crawler.filtering.regex.RegexURLNormalizer.configure(RegexURLNormalizer.java:89) ~[classes/:na]
        at com.digitalpebble.storm.crawler.filtering.URLFilters.configure(URLFilters.java:136) ~[classes/:na]
        at com.digitalpebble.storm.crawler.filtering.URLFilters.<init>(URLFilters.java:68) ~[classes/:na]
        at com.digitalpebble.storm.crawler.bolt.SiteMapParserBolt.prepare(SiteMapParserBolt.java:298) ~[classes/:na]
        at backtype.storm.daemon.executor$fn__3439$fn__3451.invoke(executor.clj:692) ~[storm-core-0.9.5.jar:0.9.5]
        at backtype.storm.util$async_loop$fn__460.invoke(util.clj:461) ~[storm-core-0.9.5.jar:0.9.5]
        at clojure.lang.AFn.run(AFn.java:24) [clojure-1.5.1.jar:na]
        at java.lang.Thread.run(Thread.java:745) [na:1.7.0_80]
Caused by: java.lang.ClassNotFoundException: org.w3c.dom.ElementTraversal
        at java.net.URLClassLoader$1.run(URLClassLoader.java:366) ~[na:1.7.0_80]
        at java.net.URLClassLoader$1.run(URLClassLoader.java:355) ~[na:1.7.0_80]
        at java.security.AccessController.doPrivileged(Native Method) ~[na:1.7.0_80]
        at java.net.URLClassLoader.findClass(URLClassLoader.java:354) ~[na:1.7.0_80]
        at java.lang.ClassLoader.loadClass(ClassLoader.java:425) ~[na:1.7.0_80]
        at java.lang.ClassLoader.loadClass(ClassLoader.java:358) ~[na:1.7.0_80]
        ... 30 common frames omitted
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/212/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/212,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1NDM3NDUxOQ==,incubator-stormcrawler,154374519,212,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-11-06T10:32:50Z,2015-11-06T10:32:50Z,"Thanks @jiangyt.  This is strange, this class should be available as a dependency of Xerces.

Which command did you run to start the topology?

java -version? Did you install Storm on your machine?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1NDM3NDUxOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/212,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1NDY2MDIyOQ==,incubator-stormcrawler,154660229,212,NA,jiangytcn,1834365,Jiang Yitao ,jiangyitao.jyt@alibaba-inc.com,NA,2015-11-07T08:53:24Z,2015-11-07T08:53:24Z,"Hi @jnioche  here's my environments

<pre><code>[yitao@yitao-dev core]$ cat /etc/issue.net 
Red Hat Enterprise Linux Workstation release 6.7 (Santiago)
Kernel \r on an \m
[yitao@yitao-dev core]$ lsb_release 
LSB Version:    :base-4.0-amd64:base-4.0-noarch:core-4.0-amd64:core-4.0-noarch:graphics-4.0-amd64:graphics-4.0-noarch:printing-4.0-amd64:printing-4.0-noarch
</code></pre>

java -version

<pre><code>java version ""1.7.0_80""
Java(TM) SE Runtime Environment (build 1.7.0_80-b15)
Java HotSpot(TM) 64-Bit Server VM (build 24.80-b11, mixed mode
</code></pre>

runs in local mode, havn't installed Storm

<pre><code>mvn clean compile exec:java -Dstorm.topology=com.digitalpebble.storm.crawler.CrawlTopology -Dexec.args=""-conf crawler-conf.yaml -local""
</code></pre>
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1NDY2MDIyOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/212,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1NDY4MTI3OQ==,incubator-stormcrawler,154681279,212,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-11-07T09:49:30Z,2015-11-07T09:49:30Z,"I can't reproduce the issue at all. What OS and version of Maven are you on?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1NDY4MTI3OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/212,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1NDY4ODM3Mw==,incubator-stormcrawler,154688373,212,NA,jiangytcn,1834365,Jiang Yitao ,jiangyitao.jyt@alibaba-inc.com,NA,2015-11-07T10:06:38Z,2015-11-07T10:06:38Z,"Apache Maven 3.0.5 (r01de14724cdef164cd33c7c8c2fe155faf9602da; 2013-02-19 21:51:28+0800)
Maven home: /usr/local/maven
Java version: 1.7.0_80, vendor: Oracle Corporation
Java home: /opt/software/jdk1.7.0_80/jre
Default locale: en_US, platform encoding: UTF-8
OS name: ""linux"", version: ""2.6.32-573.3.1.el6.x86_64"", arch: ""amd64"", family: ""unix""
OS: Red Hat Enterprise Linux Workstation release 6.7 (Santiago)

I have tried 0.6 & 0.7 both have the same issue
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1NDY4ODM3Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/212,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1NDY4ODkxOA==,incubator-stormcrawler,154688918,212,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-11-07T10:23:01Z,2015-11-07T10:23:01Z,"Could you delete the Maven cache (e.g. ~/.m2/repository/) and try again?

On 7 November 2015 at 10:06, Yitao Jiang notifications@github.com wrote:

> Apache Maven 3.0.5 (r01de14724cdef164cd33c7c8c2fe155faf9602da; 2013-02-19
> 21:51:28+0800)
> Maven home: /usr/local/maven
> Java version: 1.7.0_80, vendor: Oracle Corporation
> Java home: /opt/software/jdk1.7.0_80/jre
> Default locale: en_US, platform encoding: UTF-8
> OS name: ""linux"", version: ""2.6.32-573.3.1.el6.x86_64"", arch: ""amd64"",
> family: ""unix""
> OS: Red Hat Enterprise Linux Workstation release 6.7 (Santiago)
> 
> I have tried 0.6 & 0.7 both have the same issue
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/DigitalPebble/storm-crawler/issues/212#issuecomment-154688373
> .

## 
- Open Source Solutions for Text Engineering   http://www.digitalpebble.com
  http://www.digitalpebble.com*
  _http://digitalpebble.blogspot.com http://digitalpebble.blogspot.com/_
  https://twitter.com/digitalpebble
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1NDY4ODkxOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/212,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1NDY5MDY3OQ==,incubator-stormcrawler,154690679,212,NA,jiangytcn,1834365,Jiang Yitao ,jiangyitao.jyt@alibaba-inc.com,NA,2015-11-07T10:41:34Z,2015-11-07T10:41:34Z,"yeah, it works. Thank you.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1NDY5MDY3OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/213,https://api.github.com/repos/apache/incubator-stormcrawler/issues/213,incubator-stormcrawler,116345467,213,[SOLR] Check that not more than one instance of the Spout exists,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-11-11T14:31:39Z,2015-11-17T13:45:26Z,"Similar to what we do in [ElasticSearchSpout](https://github.com/DigitalPebble/storm-crawler/blob/master/external/elasticsearch/src/main/java/com/digitalpebble/storm/crawler/elasticsearch/persistence/ElasticSearchSpout.java#L118). Having more than one instance of the SOLR Spout would potentially send the same URLs down the topology more than once. 
Later on we could enforce sharding based on hostname/domain etc... and make so that there is one instance of the spout per shard. 

@jorgelbg what do you think?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/213/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/213,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1NzE1MjgwNA==,incubator-stormcrawler,157152804,213,NA,jorgelbg,1291846,Jorge Luis Betancourt,github@jorgelbg.me,NA,2015-11-16T19:58:38Z,2015-11-16T19:58:38Z,"This sounds great! I see one additional outcome, since we'll have 1 spout per shard we can add the ability to also use this shard keys for routing withing SolrCloud. We discussed about this some time ago, and even if SolrCloud does the routing automatically, this could be useful on some cases.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1NzE1MjgwNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/214,https://api.github.com/repos/apache/incubator-stormcrawler/issues/214,incubator-stormcrawler,116360872,214,[ElasticSearch] Kibana visualizations aggregated per host,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-11-11T15:43:10Z,2023-12-05T16:18:21Z,"It would be useful to get the average pages fetched per sec and average bytes per sec aggregated per host.
it is currently done per instance of the fetcher (whether it is a SimpleFetcherBolt or FetcherBolt), having that per machine would make more sense
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/214/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/214,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5tvVud,incubator-stormcrawler,1841126301,214,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-12-05T16:18:21Z,2023-12-05T16:18:21Z,No activity for more than 8 years. Closing,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5tvVud/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/215,https://api.github.com/repos/apache/incubator-stormcrawler/issues/215,incubator-stormcrawler,116727751,215,Provide a Maven Archetype,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-11-13T09:03:29Z,2015-12-17T14:40:31Z,"This would make it easier for new users to bootstrap a new crawler from a simple template. The archetype would generate :
- a pom file with all the minimal dependencies needed by SC
- a simple configuration file
- url and parse filter configuration files
- an example topology class

See [https://maven.apache.org/guides/mini/guide-creating-archetypes.html] for instructions.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/215/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/215,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1OTg3NTUxOQ==,incubator-stormcrawler,159875519,215,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-11-26T10:45:10Z,2015-11-26T10:45:10Z,"@jakekdodd just wanted to bring this to your attention as you'd expressed an interest before
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1OTg3NTUxOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/215,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE2NTQ2ODgxMQ==,incubator-stormcrawler,165468811,215,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-12-17T14:40:31Z,2015-12-17T14:40:31Z,"Next step : remove the resources and config file from core altogether. A new project can be generated using the archetype or by copying the files from there manually. See #227

Closing for now.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE2NTQ2ODgxMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/216,https://api.github.com/repos/apache/incubator-stormcrawler/issues/216,incubator-stormcrawler,117368250,216,StatusUpdaterBolts must be able to ack/fail explicitly,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-11-17T14:42:17Z,2016-03-02T07:37:30Z,"The class [AbstractStatusUpdaterBolt](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/storm/crawler/persistence/AbstractStatusUpdaterBolt.java) currently acks each tuple after calling the store method. Some implementations e.g. ElasticSearch one have a buffering client which means that we don't know instantly whether an update has succeeded or failed. We could change the abstract class so that extensions can fail or ack themselves.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/216/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/216,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4OTIxNTQyMA==,incubator-stormcrawler,189215420,216,NA,wombat,571379,Daniel Sachse,mail@wombatsoftware.de,NA,2016-02-26T10:43:36Z,2016-02-26T10:43:36Z,"I also experienced the problem in the last couple of days where we had some connection issues with ES and the tuples were gone
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4OTIxNTQyMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/216,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4OTIxODAyMw==,incubator-stormcrawler,189218023,216,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-02-26T10:48:01Z,2016-02-26T10:48:01Z,"you mean they'd been acked regardless of whether the ES indexing has succeeded? Maybe try the branch in #241, should fix it
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4OTIxODAyMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/216,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4OTI0MDg5OQ==,incubator-stormcrawler,189240899,216,NA,wombat,571379,Daniel Sachse,mail@wombatsoftware.de,NA,2016-02-26T11:52:37Z,2016-02-26T11:52:37Z,"@jnioche yes, they were acked although indexing failed. Thanks - Will try later
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4OTI0MDg5OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/217,https://api.github.com/repos/apache/incubator-stormcrawler/issues/217,incubator-stormcrawler,117464233,217,Replace isTickTuple(),jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-11-17T22:17:33Z,2016-01-21T15:56:25Z,"and use the generic storm-core/src/jvm/backtype/storm/utils/TupleUtils.java class instead
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/217/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/217,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1NzY4ODM4NA==,incubator-stormcrawler,157688384,217,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-11-18T11:50:10Z,2015-11-18T11:50:10Z,"[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.2:compile (default-compile) on project storm-crawler-core: Compilation failure: Compilation failure:
[ERROR] /data/storm-crawler/core/src/main/java/com/digitalpebble/storm/crawler/bolt/FetcherBolt.java:[67,28] cannot find symbol
[ERROR] symbol:   class TupleUtils
[ERROR] location: package backtype.storm.utils
[ERROR] /data/storm-crawler/core/src/main/java/com/digitalpebble/storm/crawler/bolt/FetcherBolt.java:[790,13] cannot find symbol
[ERROR] symbol:   variable TupleUtils
[ERROR] location: class com.digitalpebble.storm.crawler.bolt.FetcherBolt
[ERROR] -> [Help 1]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1NzY4ODM4NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/217,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE2MDE0NjQyNA==,incubator-stormcrawler,160146424,217,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-11-27T14:05:46Z,2015-11-27T14:05:46Z,"The class is not in the 0.9.6 jar but in the 0.10.0 one. We should be able to make that change once we move to the latter.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE2MDE0NjQyNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/218,https://api.github.com/repos/apache/incubator-stormcrawler/issues/218,incubator-stormcrawler,117618093,218,Change groupId in pom.xml,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-11-18T16:00:34Z,2015-12-03T13:46:59Z,"We currently use `<groupId>com.digitalpebble</groupId>`

but according to [https://maven.apache.org/guides/mini/guide-naming-conventions.html] this should be used to 'identify your project uniquely across all projects'.

We should probably use something like  `<groupId>com.digitalpebble.stormcrawler</groupId>`  or `<groupId>com.digitalpebble.storm-crawler</groupId>` instead.

If so what should we use for the  artifactId? Do we need to repeat 'storm-crawler' as we currently do e.g. `<artifactId>storm-crawler-elasticsearch</artifactId>` or just go for `<artifactId>elasticsearch</artifactId>`?

@DigitalPebble/committers-crawler thoughts please! 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/218/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/218,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1Nzk5OTE5OQ==,incubator-stormcrawler,157999199,218,NA,ludovic-boutros,13764888,Ludovic Boutros ,,NA,2015-11-19T09:25:20Z,2015-11-19T09:25:20Z,"Apache Camel repeats 'camel' for the different modules and I like it. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1Nzk5OTE5OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/218,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1ODAxMjM4NA==,incubator-stormcrawler,158012384,218,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-11-19T10:11:30Z,2015-11-19T10:11:30Z,"@ludovic-boutros thanks. storm do that for the external modules too. 

I am leaning towards using 'stormcrawler' instead of 'storm-crawler' in both the groupid and artefactid - any thoughts on this?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1ODAxMjM4NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/218,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE2MTY0NDEzMw==,incubator-stormcrawler,161644133,218,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-12-03T13:46:59Z,2015-12-03T13:46:59Z,"[master d349dc2] Change groupId in pom.xml #218
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE2MTY0NDEzMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/219,https://api.github.com/repos/apache/incubator-stormcrawler/issues/219,incubator-stormcrawler,118281000,219,JsoupDOMBuilder not copying in-line JavaScript and CSS Styles,rkrombho,198947,Robert Krombholz,,CLOSED,2015-11-22T18:49:40Z,2016-04-15T11:39:39Z,"The Method `com.digitalpebble.storm.crawler.parse.JSoupDOMBuilder.createDOM` does not copy data from JSoup DataNodes (http://jsoup.org/apidocs/org/jsoup/nodes/DataNode.html) into the resulting DOM.

This causes the resulting DOM to not contain any JavaScript of in-line CSS Style text.
This prevents ParseFilters from being able to analyze contents of `script` tags.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/219/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/219,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1OTIwODA1NA==,incubator-stormcrawler,159208054,219,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-11-24T09:35:52Z,2015-11-24T09:35:52Z,"Thanks @rkrombho. Do you have a patch for this or a unit test we could use?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1OTIwODA1NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/219,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1OTM4Njk1OA==,incubator-stormcrawler,159386958,219,NA,rkrombho,198947,Robert Krombholz,,NA,2015-11-24T19:53:22Z,2015-11-24T19:53:22Z,"Yes, will raise a pr when I find the time
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE1OTM4Njk1OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/219,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIxMDQyODU1Mw==,incubator-stormcrawler,210428553,219,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-04-15T11:39:39Z,2016-04-15T11:39:39Z,"@rkrombho  should be fixed. See unit test included in patch. Please reopen if it does not work as expected
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIxMDQyODU1Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/221,https://api.github.com/repos/apache/incubator-stormcrawler/issues/221,incubator-stormcrawler,119154237,221,[Elasticsearch] upgrade to version 5,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-11-27T08:47:22Z,2017-04-05T12:58:11Z,"Amazon Elasticsearch does not support the native protocol and requires a REST based client like [Jest](https://github.com/searchbox-io/Jest). It would be good to have that as well
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/221/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/221,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIzMTMzMDA1Mg==,incubator-stormcrawler,231330052,221,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-07-08T10:41:58Z,2016-07-08T10:41:58Z,"[Elasticsearch 5](https://www.elastic.co/blog/elastic-stack-release-5-0-0-alpha-4) will provide 

> ""a low-level Java HTTP/REST client. It provides a simple HTTP client with minimal dependencies, which handles sniffing, logging, round robinning of requests, and retry on node failure.""
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIzMTMzMDA1Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/221,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3NjkwNjg4NA==,incubator-stormcrawler,276906884,221,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-02-02T09:23:35Z,2017-02-02T09:23:35Z,"Search-time field collapsing with paging is EXACTLY what we need for our spouts!

[https://www.elastic.co/guide/en/elasticsearch/reference/5.x/search-request-collapse.html] but won't be there until 5.3","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3NjkwNjg4NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/221,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3ODA0MTM1MA==,incubator-stormcrawler,278041350,221,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-02-07T15:51:03Z,2017-02-07T15:51:03Z,"Am having problems with the log dependencies which conflict with the ones in Storm

https://www.elastic.co/guide/en/elasticsearch/client/java-api/current/_using_another_logger.html

Worth noticing that [ES-Hadoop](https://github.com/elastic/elasticsearch-hadoop) does not use the Java client (which causes the log dependency) but handles things through REST.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3ODA0MTM1MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/221,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3ODA3NzAyMw==,incubator-stormcrawler,278077023,221,NA,kkrugler,66217,Ken Krugler,ken@transpac.com,NA,2017-02-07T17:35:26Z,2017-02-07T17:35:26Z,"Elastic is pushing hard for everyone to transition to the REST client, versus the Java (Transport or Node) client.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3ODA3NzAyMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/221,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4MzYyMTQxNA==,incubator-stormcrawler,283621414,221,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-02T10:52:32Z,2017-03-02T10:52:32Z,Fixed the log dependency problem by updating the versions in Storm for the branches [1.0.x](https://github.com/apache/storm/pull/1946) and [1.x](https://github.com/apache/storm/pull/1947). There is also an open PR for [2.x](https://github.com/apache/storm/pull/1969). Have used the branch _es5_ and it works great. Might wait for Elasticseach 5.3 to be released as it will contain the field collapsing mentioned earlier. Will open a sub-branch specifically for that and test the perfs vs using aggregations. ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4MzYyMTQxNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/222,https://api.github.com/repos/apache/incubator-stormcrawler/issues/222,incubator-stormcrawler,119185973,222,MaxDepthFilter not considered correctly?,wombat,571379,Daniel Sachse,mail@wombatsoftware.de,CLOSED,2015-11-27T12:09:45Z,2015-11-27T13:42:58Z,"Hey folks,

I cloned the repo, set the MaxDepthFilter to 10 and removed all urls from RandomURLSpout but one. Afterwards I started the Topology locally and expected to discover the urls and crawl the site until maxDepth of 10 is reached or no new URLs are available.

But what I see is that it only crawls the first page and then I see no more crawling activity.

Any thoughts?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/222/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/222,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE2MDEyOTE3Ng==,incubator-stormcrawler,160129176,222,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-11-27T12:24:48Z,2015-11-27T12:24:48Z,"Hi @w0mbat

That's normal.  In the example [CrawlTopology](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/storm/crawler/CrawlTopology.java) the StdOutStatusUpdater just dumps the URLs discovered to the standard output. They do not get added to the Spout.

In a real life topology you'd use an external storage e.g. Elasticsearch, MySQL, RabbitMQ etc... see the corresponding modules for examples and instructions. You'd also connect to an indexer like SOLR or ES.

Now what we could do would be to modify the RandomURLSpout (e.g. with a public static Map) containing the URLs and Metadata and add a StatusUpdater for it. Obviously this would work only in local mode when both the spout and updater are in the same JVM.

Does this make sense?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE2MDEyOTE3Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/222,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE2MDE0MTY2Mg==,incubator-stormcrawler,160141662,222,NA,wombat,571379,Daniel Sachse,mail@wombatsoftware.de,NA,2015-11-27T13:40:39Z,2015-11-27T13:40:39Z,"Hey @jnioche

Thanks for the quick feedback!
I quickly hacked on the proposed solution and yes, it works!
Sure, its currently only to see how things are playing together and whats possible!

Best

Daniel
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE2MDE0MTY2Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/222,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE2MDE0MTk3Mg==,incubator-stormcrawler,160141972,222,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-11-27T13:42:57Z,2015-11-27T13:42:57Z,"> I quickly hacked on the proposed solution and yes, it works!

cool. Feel free to send a PR if you could spare the time. It would be a useful feature
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE2MDE0MTk3Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/226,https://api.github.com/repos/apache/incubator-stormcrawler/issues/226,incubator-stormcrawler,122508360,226,[status] subscribes from non-existent stream: [status] of component [index],GasparPizarro,3129848,,,CLOSED,2015-12-16T13:58:48Z,2015-12-16T16:46:47Z,"I'm working with storm-crawler-core-0.8-SNAPSHOT and storm-crawler-solr-0.6 and cannot plug the status bolt with the indexer bolt through the `StatusStreamName` stream, even though the code in AbstractIndexerBolt says  

```
declarer.declareStream(com.digitalpebble.storm.crawler.Constants.StatusStreamName, new Fields(""url"", ""metadata"", ""status""));
```

I'm receiving this error:

```
backtype.storm.daemon.nimbus - Topology submission exception. (topology name='crawl') #<InvalidTopologyException InvalidTopologyException(msg:Component: [status] subscribes from non-existent stream: [status] of component [index])
```

My topology is this:

```
public class CrawlTopology extends ConfigurableTopology {

    public static void main(String[] args) throws Exception {
        ConfigurableTopology.start(new CrawlTopology(), args);
    }

    @Override
    protected int run(String[] args) {
        TopologyBuilder builder = new TopologyBuilder();
        builder.setSpout(""spout"", new QueueSpout()); //Receives messages from a amqp queue
        builder.setBolt(""partitioner"", new URLPartitionerBolt()).shuffleGrouping(""spout"");
        builder.setBolt(""fetch"", new FetcherBolt()).fieldsGrouping(""partitioner"", new Fields(""key""));
        builder.setBolt(""parse"", new JSoupParserBolt()).localOrShuffleGrouping(""fetch"");
        builder.setBolt(""index"", new IndexerBolt()).localOrShuffleGrouping(""parse"");
        builder.setBolt(""status"", new MongoStatusUpdater()) //Sends received tuples to a mongo database
                .localOrShuffleGrouping(""parse"", Constants.StatusStreamName)
                .localOrShuffleGrouping(""index"", Constants.StatusStreamName);
        return submit(""crawl"", conf, builder);
    }
}
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/226/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/226,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE2NTEzMDY4Nw==,incubator-stormcrawler,165130687,226,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-12-16T14:47:33Z,2015-12-16T14:47:33Z,"storm-crawler-solr-0.6 is not compatible with the change in AbstractIndexerBolt [https://github.com/DigitalPebble/storm-crawler/issues/190]. You should use storm-crawler-solr-0.8-SNAPSHOT instead 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE2NTEzMDY4Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/226,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE2NTE3MTM4MA==,incubator-stormcrawler,165171380,226,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2015-12-16T16:46:47Z,2015-12-16T16:46:47Z,"@GasparPizarro 

BTW MongoStatusUpdater should also subscribe to the tuples on status stream coming from the Fetcher, you'll never get notified of redirections otherwise  
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE2NTE3MTM4MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/227,https://api.github.com/repos/apache/incubator-stormcrawler/issues/227,incubator-stormcrawler,122746963,227,Remove configuration resources from core module,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-12-17T14:40:07Z,2016-03-23T11:46:16Z,"A new project can be generated using the [archetype](https://github.com/DigitalPebble/storm-crawler/tree/master/archetype) or by copying the files from there manually. We don't need the config elements in core, these would be specified by the user or generated by the archetype.

Note : crawler-default.yaml would remain in core to provide default values.

This would also fixe #61 as well. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/227/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/227,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE5NDkwNzE2NA==,incubator-stormcrawler,194907164,227,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-03-10T15:35:11Z,2016-03-10T15:35:11Z,"Removing the configuration files from core causes some tests to fail. Postponing this issue.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE5NDkwNzE2NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/227,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIwMDMxMjE4NQ==,incubator-stormcrawler,200312185,227,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-03-23T11:46:16Z,2016-03-23T11:46:16Z,"Done in #4292e91

core now has no URL or ParseFilters loaded by default, nor does it have an example of Topology. This will prevent confusion about what it used and overridden when building the uber jars. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIwMDMxMjE4NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/228,https://api.github.com/repos/apache/incubator-stormcrawler/issues/228,incubator-stormcrawler,122949466,228,Deactivate _all field for status and metrics indices,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-12-18T13:32:05Z,2016-01-08T11:08:18Z,"The catch all field is more useful for textual content e.g. coming from documents but not so much for the status and metrics indices. 

Disabling it should reduce the size of the indices on disk.

[https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-all-field.html#disabling-all-field]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/228/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/229,https://api.github.com/repos/apache/incubator-stormcrawler/issues/229,incubator-stormcrawler,123777777,229,Move to Storm 0.10.0,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2015-12-24T08:59:30Z,2016-01-21T15:23:03Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/229/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/229,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE3MzYwNDU1NQ==,incubator-stormcrawler,173604555,229,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-01-21T15:23:02Z,2016-01-21T15:23:02Z,"Done in #220
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE3MzYwNDU1NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/230,https://api.github.com/repos/apache/incubator-stormcrawler/issues/230,incubator-stormcrawler,125389737,230,Custom priority,mattburns,1316126,Matt Burns,,CLOSED,2016-01-07T13:01:11Z,2016-02-26T10:17:59Z,"Allow a config setting to use a custom priority field instead of nextFetchDate or random. For example, you could choose the field in the status index you wish to sort by. Something like `es.status.custom.sort: ""priority""`

That way, when you populate the status index, you can just thing to the front of the queue by setting their priority to `1`.

As a happy side effect, this can solve the current random sorting problem I've been seeing of `field_data` being filled with hashes of the `_uid`. If you want random sorting then you could simply store the hash of the `_uid` in the `priority` field then custom sort on that.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/230/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/230,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4OTIwNTQ4MA==,incubator-stormcrawler,189205480,230,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-02-26T10:17:59Z,2016-02-26T10:17:59Z,"Added es.status.sort.field: ""nextFetchDate"" for ElasticSearchSpout 
AggregationSpout could already sort within a bucket with `es.status.bucket.sort.field: ""nextFetchDate""` 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4OTIwNTQ4MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/233,https://api.github.com/repos/apache/incubator-stormcrawler/issues/233,incubator-stormcrawler,127681275,233,Field collapsing in ES Spout,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-01-20T13:23:14Z,2016-01-28T12:25:54Z,"The ES Spout currently sorts per _nextFetchDate_ which offers very few guarantees regarding the diversity of hosts retrieved by the queries. This is improved by randomizing the results, however the latter has an impact on the memory used by ES for the field caching. Limiting the field caching leads to poor performance  and the eviction mechanism slows the queries quite a lot.

A more natural solution to the problem would be to use [Field Collapsing](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-metrics-top-hits-aggregation.html) e.g. on the _metadata.hostname_ field. This would guarantee a good diversity of hosts and optimal performance for the crawler.

Below is an example of what the ElasticSearch query would look like

``` json
{
  ""query"": {
    ""range"": {
      ""nextFetchDate"": {
        ""lt"": ""now""
      }
    }
  },
  ""size"": 0,
  ""aggs"": {
    ""hostname"": {
      ""terms"": {
        ""field"": ""metadata.hostname"",
        ""size"": 50
      },
      ""aggs"": {
        ""top_tags_hits"": {
          ""top_hits"": {
            ""size"": 5
          }
        }
      }
    }
  }
}
```

This is of course compatible with the sharding mechanism in #232 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/233/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/235,https://api.github.com/repos/apache/incubator-stormcrawler/issues/235,incubator-stormcrawler,127946453,235,SitemapParser fails when server returns Content-Type: application/octet-stream,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-01-21T15:13:41Z,2016-01-21T15:45:21Z,"e.g. [https://vimeo.com/sitemap/master.xml.gz]

This is due to the way crawler-commons handles the mime-types when given explicitly. Instead we should a) modify CC so that we can pass the mimetype as a hint or b) when it is an octet-stream call the CC method which does the detection with Tika.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/235/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/239,https://api.github.com/repos/apache/incubator-stormcrawler/issues/239,incubator-stormcrawler,129434040,239,Indexers use canonical URL for the status,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-01-28T12:14:19Z,2016-01-28T12:24:15Z,"This is due to an incorrect use of the method AbstractIndexerBolt.valueForURL() which causes some of the indexers to send the canonical URL for the status. As a result the original URL never gets updated and keeps being refetched over and over.

FYI @ jorgelbg see 1ef9cc16a92ed8950

Note this affects the SOLR, Elasticsearch and CloudSearch indexers. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/239/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/240,https://api.github.com/repos/apache/incubator-stormcrawler/issues/240,incubator-stormcrawler,129445830,240,MemorySpout does not work in distributed mode,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-01-28T13:00:36Z,2016-03-10T16:40:38Z,"but is fine locally
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/240/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/240,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE5NDkzODAyNA==,incubator-stormcrawler,194938024,240,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-03-10T16:30:33Z,2016-03-10T16:30:33Z,"Pretty simple actually : see [https://groups.google.com/d/msg/storm-user/N4xoNJIUHiw/tRnxR7lqrfYJ]
The bolts are created locally then serialized. The static field probably doesn't get serialized, so instead we should use a non-static field with the constructor and populate the static field within the open method.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE5NDkzODAyNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/242,https://api.github.com/repos/apache/incubator-stormcrawler/issues/242,incubator-stormcrawler,129760854,242,ES Metrics : name field does not need to be analysed,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-01-29T13:04:06Z,2016-01-31T16:23:57Z,"[https://github.com/DigitalPebble/storm-crawler/blob/master/external/elasticsearch/ES_IndexInit.sh#L72]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/242/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/243,https://api.github.com/repos/apache/incubator-stormcrawler/issues/243,incubator-stormcrawler,129762635,243,FetcherBolts : add counter for bytes fetched ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-01-29T13:13:23Z,2016-02-09T21:42:22Z,"which is not an average per doc nor an average per sec
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/243/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/243,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4MjA4OTUzNg==,incubator-stormcrawler,182089536,243,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-02-09T21:42:19Z,2016-02-09T21:42:19Z,"[master ec233c1] FetcherBolts : add counter for bytes fetched #243
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4MjA4OTUzNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/246,https://api.github.com/repos/apache/incubator-stormcrawler/issues/246,incubator-stormcrawler,131010112,246,Reduce metrics chatter,mattburns,1316126,Matt Burns,,CLOSED,2016-02-03T12:31:25Z,2016-02-09T21:42:41Z,"When writing metrics to Elasticsearch, the index can get big enough to affect performance of Elasticsearch. Here are my thoughts on things that may help reduce the burden on Elasticsearch:
1. Log fewer stats
   1. Configurable (crawler-conf) whitelist/blacklist of metric names?
   2. Maybe just skip writing of internal ones (starting with ""__"") used by storm-ui.
2. Log less frequently
   1. Configurable granularity of update frequency (time bucket size currently hardcoded to 10 seconds)
3. Regularly prune the DB
   1. Have two indexes (metrics-fine and metrics-coarse?) one with high resolution (update frequency) but short TTL*, and the other the opposite.
   2. Have a silly utility class that can prune the metrics index using a . eg, ""delete metrics older than X"" or ""delete metrics with name Y""
   3. Use the new [delete by query plugin](https://www.elastic.co/guide/en/elasticsearch/plugins/2.2/plugins-delete-by-query.html)?

*Note, [elastic have deprecated _ttl](https://www.elastic.co/guide/en/elasticsearch/reference/2.2/mapping-ttl-field.html), we should probably move to index-per-timeframe?

What are your thoughts to those suggestions? I'd prefer logging less over pruning because it also reduces the network chatter etc. I'm tempted by the whitelist/blacklist idea because it seems pretty straight forward. I was thinking you could specify something like this in the crawler-conf:

```
metrics.whitelist:
- fetcher_counter.fetched
- fetcher_counter.exception
```

Thoughts?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/246/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/246,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE3OTIyMDY3OQ==,incubator-stormcrawler,179220679,246,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-02-03T13:08:53Z,2016-02-03T13:08:53Z,"Black/whitelist would be a good initial approach, followed by configurable per component update frequency.
I am less keen on the regular pruning of the DB too. Having 2 indices fine vs coarse would be tricky as for pruning this is pretty much what _ttl does. Since we are on ES 1.x for now we can just use it. Later on we could indeed look at index-per-timeframe.

I expect that the more bolt instances (e.g. SimpleFetcher) in a topology, the more acute the problem becomes.

The metrics index could be handled by a separate ES machine to avoid degrading the perf of the one used for the status and/or index.

As a side note, the metrics part of the ES plugin is not specific to StormCrawler so I was wondering whether to contribute it to Storm [https://github.com/apache/storm/tree/master/external/storm-elasticsearch/src/main/java/org/apache/storm/elasticsearch] or release it separately. I would maybe base it on Jest (see #221) so that users could index to the AWS Elasticsearch service which does not support the native API. Do you have any thoughts on this? 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE3OTIyMDY3OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/246,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE3OTIzNzA0Mg==,incubator-stormcrawler,179237042,246,NA,mattburns,1316126,Matt Burns,,NA,2016-02-03T13:38:49Z,2016-02-03T13:38:49Z,"Agreed.
Your thoughts about the SimpleFetcherBolt highlight a good point. For instance, I've configured my `fetcher_counter.fetched` metric to bucket into 30 second intervals. If there was one bolt, I would have 20 metrics written in a 10 minute period. However, I have 200 fetcher tasks and therefore I get ~4000. I can't just multiply the interval by the number of fetchers because they all stay in sync. You can see from this graph how my 200 tasks all attempt to write their metrics at the same time every 30 seconds:

![image](https://cloud.githubusercontent.com/assets/1316126/12783560/36bd74b6-ca7a-11e5-9f8c-d0644722d446.png)

I have no strong feelings either way about where the ES plugin belongs :)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE3OTIzNzA0Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/246,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4MTk0Njk1Mg==,incubator-stormcrawler,181946952,246,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-02-09T16:36:40Z,2016-02-09T16:36:40Z,"@mattburns what about being able to configure the metrics frequency per component? Would this still be useful and if so should we reopen this issue?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4MTk0Njk1Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/246,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4MTk2MjI3OQ==,incubator-stormcrawler,181962279,246,NA,mattburns,1316126,Matt Burns,,NA,2016-02-09T17:14:09Z,2016-02-09T17:14:09Z,"Yeah, that would be very useful. The following code is in the SimpleFetcherBolt:

```
this.eventCounter = context.registerMetric(""fetcher_counter"", new MultiCountMetric(), 10);
```

The `10` be configurable, but there should be also be a way for eventCounter to be shared across all bolts of this type rather than each bolt constructing its own?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4MTk2MjI3OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/246,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4MjA2NzI5Mg==,incubator-stormcrawler,182067292,246,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-02-09T21:04:32Z,2016-02-09T21:04:32Z,"The counter could be shared by being a static field however this would not be across all bots, just the ones that live in the same JVM. Moreover I think it makes sense to be able to get the stats per instance.

Will make the change for configuring the time for the SimpleFetcherBolt only as it is likely to be the component we use the most instances of.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4MjA2NzI5Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/246,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4MjA3MTI3NQ==,incubator-stormcrawler,182071275,246,NA,mattburns,1316126,Matt Burns,,NA,2016-02-09T21:19:02Z,2016-02-09T21:19:02Z,"Ok, cool, per JVM would be fine :)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4MjA3MTI3NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/246,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4MjA4NDU2OA==,incubator-stormcrawler,182084568,246,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-02-09T21:34:32Z,2016-02-09T21:34:32Z,"We can now configure how often the metrics will be generated for both flavours of FetcherBolts. 
`fetcher.metrics.time.bucket.secs: 10`

@mattburns - nope. I'd rather keep the info per instance ;-)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4MjA4NDU2OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/249,https://api.github.com/repos/apache/incubator-stormcrawler/issues/249,incubator-stormcrawler,131767139,249,Sitemap : add option to filter out URLs older than give threshold,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-02-05T21:54:11Z,2016-02-16T12:08:39Z,"For instance if we know that a sitemap will be revisited daily, we could reduce the number of discovered URLs sent to the status bolt if they haven't been revisited in the last 24 hours.  
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/249/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/249,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4NDY1ODUyOA==,incubator-stormcrawler,184658528,249,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-02-16T12:08:39Z,2016-02-16T12:08:39Z,"Implemented in 96834eb
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4NDY1ODUyOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/252,https://api.github.com/repos/apache/incubator-stormcrawler/issues/252,incubator-stormcrawler,133311671,252,Remove links to self,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-02-12T18:32:04Z,2016-02-25T22:16:59Z,"Some pages contain links to themselves. We could have a URLFilter to deal with those.
Similarly if a page contains the same outlink (maybe with different anchors), we should send them down the topology only once.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/252/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/252,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4OTAwOTI5NA==,incubator-stormcrawler,189009294,252,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-02-25T22:16:59Z,2016-02-25T22:16:59Z,"The JSoupParserBolt already dedups outlinks. 

[master 263294a] Added SelfURLFilter#252
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE4OTAwOTI5NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/253,https://api.github.com/repos/apache/incubator-stormcrawler/issues/253,incubator-stormcrawler,133418940,253,Delete gone pages from index,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-02-13T10:02:43Z,2017-04-20T10:46:19Z,"Conceptually it is not the same as an ERROR status - which occur for instance when a document is not parsable or has something wrong with it.
A document could become GONE if it has had N consecutive FETCH_ERRORS or if the server returned a HTTP code 410. A GONE document could be revisited based on the scheduling but should be deleted in an index. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/253/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/253,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0NzMyODM4OA==,incubator-stormcrawler,247328388,253,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-09-15T13:31:27Z,2016-09-15T13:31:27Z,"An ERROR status would probably have a corresponding NEVER FETCH conventional value for the nextFetchDate (epoch 1/1/1970?) Such value would also be useful for FETCHED documents when we do not want to ever reprocess them. At the moment we just set a ridiculously large value like in 10 years time
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0NzMyODM4OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/253,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NjczNDE5NQ==,incubator-stormcrawler,286734195,253,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-15T13:01:43Z,2017-03-15T13:01:43Z,"See SO discussion on http://stackoverflow.com/questions/42810272/tell-stormcrawler-to-delete-pages-from-es-index-after-they-have-been-deleted-on

>  In the meantime we could delete the ERROR status (even if most of them would not have been added to ES), the difficulty being that the indexing is done on the default stream i.e. docs which have been fetched and parsed whereas the status info gets sent to the status stream by the various bolts. We could have a bespoke bolt for deletions - it would just need the URL and nothing else: to use it we could modify AbstractStatusUpdaterBolt so that it emits the URLs to delete onto a special stream e.g. 'deletion' and connect our bespoke ES delete bolt to it. Does this make sense? Please feel free to contribute to the discussion on the link below. Thanks!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NjczNDE5NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/253,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NTE5NTI5Mw==,incubator-stormcrawler,295195293,253,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-04-19T09:54:07Z,2017-04-19T09:54:07Z,"Renamed the issue. Adding a separate status is probably not practical as the status is typically not carried through the topology. We could add a key value in the metadata to indicate when a page was successfully fetched or indexed last to delete only the ones that get ERRORed but had been fetched. As an initial step, deleting documents even though they never got fetched is not really a problem. 

Having said that, we might need to track the canonical value so that we can delete the doc based on the same URL as was used while indexing. The trouble being that we could end up deleting the canonical representation of the page even though only one of the possible variations got lost. Tricky. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NTE5NTI5Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/259,https://api.github.com/repos/apache/incubator-stormcrawler/issues/259,incubator-stormcrawler,135062497,259,ES config to accept multiple addresses at host:port format,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-02-20T11:22:26Z,2016-03-31T08:11:15Z,"The TransportClient can be configured with multiple transport addresses, our configuration patterns should allow that e.g. 

``` json
es.indexer.adresses:
- localhost:9300
- remote:9300
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/259/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/260,https://api.github.com/repos/apache/incubator-stormcrawler/issues/260,incubator-stormcrawler,135062852,260,ES use NodeClient only if no address is specified,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-02-20T11:27:29Z,2016-02-20T16:03:10Z,"We currently use the NodeClient if the hostname is localhost however it would be better to use it only if no address is specified. The ES cluster could be reachable even if no nodes are on localhost. We might also want to use the TransportClient even if the ES instance is running on localhost.
This should make things cleaner and easier to understand
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/260/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/262,https://api.github.com/repos/apache/incubator-stormcrawler/issues/262,incubator-stormcrawler,136765015,262,AggregatedSpout to filter in the past,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-02-26T17:49:52Z,2016-03-02T07:39:11Z,"The AggregatedSpout struggles on larger shards when there are hundreds of millions of docs which all satisfy the nextFetchDate query e.g. they've all been injected at the same time. This is due to the fact that the aggregation and counts of hits per bucket has to operate on an extremely large number of docs.

Instead of filtering on nextFetchDate < NOW, we could get the lowest value for nextFetchDate returned and find automatically a time span (e.g. 1 hour) which returns as many documents as possible while minimizing the number of candidates for bucketing. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/262/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/262,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE5MTExMzA4Mg==,incubator-stormcrawler,191113082,262,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-03-02T07:39:10Z,2016-03-02T07:39:10Z,"Not an ideal solution as this could harm the diversity of URLs. 
The [sampler aggregation](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-sampler-aggregation.html) in ES 2.x is a more promising approach 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE5MTExMzA4Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/265,https://api.github.com/repos/apache/incubator-stormcrawler/issues/265,incubator-stormcrawler,139868495,265,Limit size of the Robots cache ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-03-10T12:06:37Z,2016-03-10T14:35:32Z,"We currently use an unbounded Hashtable, if the crawl lasts for a long time and hits many different hosts this might lead to an OOME. Best to use a proper LRU cache with a limited number or entries and/or TTL. This would have the advantage that if a change happens to the robots.txt we'd get the newer version instead of using the old one over and over.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/265/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/265,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE5NDg3NDA3NA==,incubator-stormcrawler,194874074,265,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-03-10T14:35:32Z,2016-03-10T14:35:32Z,"Fixed in [master 9888de1]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE5NDg3NDA3NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/266,https://api.github.com/repos/apache/incubator-stormcrawler/issues/266,incubator-stormcrawler,141592796,266,Add option to JSoupParser to pass non-HTML docs to the default stream,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-03-17T14:06:51Z,2016-03-17T14:13:33Z,"In the current version the JSoupParserBolt sends an ERROR tuple to the status stream, instead we could have an option to pass documents it cannot parse to the default stream so that another parser implementation can have a go. This would be useful e.g. to chain the JSoup parser - which generates a good DOM for XPath extraction, with the Tika one which gives rubbish DOM but can handle all sorts of file formats.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/266/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/267,https://api.github.com/repos/apache/incubator-stormcrawler/issues/267,incubator-stormcrawler,141843843,267,Allow other links to be considered outlinks,mattburns,1316126,Matt Burns,,CLOSED,2016-03-18T11:42:19Z,2016-04-22T09:14:47Z,"Our crawler is focussed on finding images. It would be nice if it were possible to optimise for this.

Currently if the following html is parsed, only `image1.jpg` will be added to the status queue:

```
<a href=""image1.jpg"">
    <img src=""image1-thumb.jpg""/>
</a>
<img src=""image2.jpg""/>
```

It would be nice if I could specify a config, or a custom parse filter, etc so that all images found in the `img[src]` attribute are added to the status queue as well so that the above example added all three images to the outlinks.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/267/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/267,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE5OTgxNTI3NA==,incubator-stormcrawler,199815274,267,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-03-22T13:30:17Z,2016-03-22T13:30:17Z,"Could be done as a ParseFilter with the XPath expressions specified in the YAML config. This would have the advantage of working for JSoup but also potentially for the Tika based parser.  
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDE5OTgxNTI3NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/267,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIxMjM5NTAzNA==,incubator-stormcrawler,212395034,267,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-04-20T11:52:15Z,2016-04-20T11:52:15Z,"Related [http://stackoverflow.com/questions/36722755/crawling-video-with-apache-nutch]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIxMjM5NTAzNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/269,https://api.github.com/repos/apache/incubator-stormcrawler/issues/269,incubator-stormcrawler,143214777,269,Specify name of the topology via config,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-03-24T10:50:28Z,2016-03-24T16:14:05Z,"could be done in the config file and/or using the standard -c option on the command line.

Storm uses [topology.name](https://github.com/apache/storm/blob/master/storm-core/src/jvm/org/apache/storm/Config.java#L1977) after the topology has been submitted. We could use the same value before submitting it?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/269/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/270,https://api.github.com/repos/apache/incubator-stormcrawler/issues/270,incubator-stormcrawler,143230908,270,ES AggregationSpout sort buckets by oldest nextFetchDate,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-03-24T12:23:18Z,2016-03-24T16:19:00Z,"It currently sorts the buckets by the number of results they contain. While this works fine on crawls where the number of URLs is limited, it can turn into a vicious circle : some domains get larger and larger while many never get fetched at all. 

Instead we should have the option to sort the buckets by oldest nextFetchDate, regardless of the size of the buckets

We currently query like this 

``` json
GET status/_search?pretty=true&preference=_shards:1
{
  ""query"": {
    ""range"": {
      ""nextFetchDate"": {
        ""lt"": ""now""
      }
    }
  },
  ""size"": 0,
  ""aggs"": {
    ""hostname"": {
      ""terms"": {
        ""field"": ""metadata.hostname"",
        ""size"": 50
      },
      ""aggs"": {
        ""docs"": {
          ""top_hits"": {
            ""size"": 5,
            ""explain"": false,
            ""sort"": [
              {
                ""nextFetchDate"": {
                  ""order"": ""asc""
                }
              }
            ]
          }
        }
      }
    }
  }
}
```

instead we should do 

```
GET status/_search?pretty=true&preference=_shards:1
{
  ""query"": {
    ""range"": {
      ""nextFetchDate"": {
        ""lt"": ""now""
      }
    }
  },
  ""size"": 0,
  ""aggs"": {
    ""hostname"": {
      ""terms"": {
        ""field"": ""metadata.hostname"",
        ""size"": 50,
        ""order"": {
          ""top_hit"": ""asc""
        }
      },
      ""aggs"": {
        ""docs"": {
          ""top_hits"": {
            ""size"": 5,
            ""explain"": false,
            ""sort"": [
              {
                ""nextFetchDate"": {
                  ""order"": ""asc""
                }
              }
            ]
          }
        },
        ""top_hit"": {
          ""min"": {
            ""field"": ""nextFetchDate""
          }
        }
      }
    }
  }
}
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/270/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/270,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIwMDg3MjAwNA==,incubator-stormcrawler,200872004,270,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-03-24T14:55:36Z,2016-03-24T14:55:36Z,"alternatively could use the sample aggregation in ES 2.x 

[https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-sampler-aggregation.html]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIwMDg3MjAwNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/272,https://api.github.com/repos/apache/incubator-stormcrawler/issues/272,incubator-stormcrawler,143945995,272,Tika parser : dedup outlinks,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-03-28T10:24:52Z,2016-04-01T14:25:35Z,"The Tika bolt currently does not deduplicate the outlinks. This makes the status updating step less efficient as we clog the buffers with redundant information 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/272/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/273,https://api.github.com/repos/apache/incubator-stormcrawler/issues/273,incubator-stormcrawler,148652209,273,apply option to ignore robots in filter method of abstract indexer,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-04-15T12:52:17Z,2023-12-05T16:22:44Z,"the option is used for the directives coming from robots.txt - we could also use that when processing the ones from http and or the html content
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/273/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/273,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1MzI1MDE0Mg==,incubator-stormcrawler,253250142,273,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-10-12T15:38:40Z,2016-10-12T15:38:40Z,"we have only one config at the moment which prevents the robots files from being fetched but we might want to have a separate config to ignore the directives, possibly still fetching the robots though to have the sitemaps. this new config could be used to prevent the directives from HTML or HTTP to be applied.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1MzI1MDE0Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/273,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5tvX2-,incubator-stormcrawler,1841135038,273,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-12-05T16:22:43Z,2023-12-05T16:22:43Z,No activity - closing,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5tvX2-/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/278,https://api.github.com/repos/apache/incubator-stormcrawler/issues/278,incubator-stormcrawler,151572981,278,FetcherBolt simplify access to OutputCollector,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-04-28T07:59:41Z,2016-06-17T10:49:10Z,"It looks as if the OutputCollectors are now thread safe and we should not need to emit from the main thread, use the tick tuples to flush etc...

Needs confirming but if it does we could greatly simplify the code of the FetcherBolt.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/278/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/278,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIxNTY1MTE0Nw==,incubator-stormcrawler,215651147,278,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-04-29T07:47:08Z,2016-04-29T07:47:08Z,"Possible with Storm 1.x only, see [https://issues.apache.org/jira/browse/STORM-841]. Can do that once we've merged [https://github.com/DigitalPebble/storm-crawler/tree/storm1.0]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIxNTY1MTE0Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/278,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNTUzOTI1Mw==,incubator-stormcrawler,225539253,278,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-06-13T10:01:58Z,2016-06-13T10:01:58Z,"This depends on #294 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNTUzOTI1Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/279,https://api.github.com/repos/apache/incubator-stormcrawler/issues/279,incubator-stormcrawler,151592279,279,Check that the status gets modified for pages that return 304,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-04-28T09:34:15Z,2016-04-29T09:20:56Z,"[SimpleFetcherBolt](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/storm/crawler/bolt/SimpleFetcherBolt.java#L352) does nothing about it so the pages are parsed as usual.

[FetcherBolt](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/storm/crawler/bolt/FetcherBolt.java#L539) skips the parsing but probably doesn't update the status either.

Need to check if/how we handle conditional requests as a server would return a [304 ](https://httpstatuses.com/304) only in such cases, although in practice I have seen servers do so even with a non-conditional one.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/279/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/279,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIxNTM2NzUxOA==,incubator-stormcrawler,215367518,279,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-04-28T09:35:46Z,2016-04-28T09:35:46Z,"Maybe it would make sense to share the code that handles that between the *FetcherBolt implementations? a super class? 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIxNTM2NzUxOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/279,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIxNTM3Njc5Mw==,incubator-stormcrawler,215376793,279,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-04-28T10:10:59Z,2016-04-28T10:10:59Z,"[https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/storm/crawler/protocol/httpclient/HttpProtocol.java#L131] uses the values for the keys _cachedLastModified_ and _cachedEtag_  if present in the metadata. 

At the moment these k/v are not stored automatically See #99 and #109 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIxNTM3Njc5Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/279,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIxNTM3OTI4OA==,incubator-stormcrawler,215379288,279,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-04-28T10:23:47Z,2016-04-28T10:23:47Z,"Note to self : need unit test with an embedded web server.
[http://wiremock.org/]
or classes from HTTPClient itself [https://thecarlhall.wordpress.com/2010/03/25/unit-testing-with-httpclients-localtestserver/]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIxNTM3OTI4OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/279,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIxNTM5MzQwMw==,incubator-stormcrawler,215393403,279,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-04-28T11:24:45Z,2016-04-28T11:24:45Z,"Added fix for FetcherBolt + attempt at writing a Junit test with an embedded server in a separate branch (does not work yet but it's a start)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIxNTM5MzQwMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/281,https://api.github.com/repos/apache/incubator-stormcrawler/issues/281,incubator-stormcrawler,152724812,281,ES metrics - remove filtering,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-05-03T08:36:27Z,2017-04-27T14:40:56Z,"as this will be handled by Storm see [https://github.com/apache/storm/pull/1324]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/281/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/281,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNTQ5MDkzMw==,incubator-stormcrawler,225490933,281,NA,HeartSaVioR,1317309,Jungtaek Lim,kabhwan.opensource@gmail.com,NA,2016-06-13T05:16:49Z,2016-06-13T05:16:49Z,"FYI: I merged this into Storm 1.x-branch, planned to be released as 1.1.0.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNTQ5MDkzMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/281,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNTUxNjE0NA==,incubator-stormcrawler,225516144,281,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-06-13T08:18:09Z,2016-06-13T08:18:09Z,"@HeartSaVioR thanks for the heads up. I'll port our code to Storm 1.x soon. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNTUxNjE0NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/282,https://api.github.com/repos/apache/incubator-stormcrawler/issues/282,incubator-stormcrawler,153425833,282,Simplify MetadataTransfer,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-05-06T10:43:25Z,2016-06-10T07:32:53Z,"We currently have a coded logic for persisting _depth_ and _url.path_ to the status storage. Other metadata have to be specified in the configuration file as a value of _metadata.transfer_. 

We could add _depth_ and _url.path_ to the default configuration instead, as well as __redirTo_ or _error.cause_. These can always be overridden by the users if necessary.

The logic of incrementing the _depth_ value would still be done by the MetadataTransfer class. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/282/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/282,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNDkyNzYxMQ==,incubator-stormcrawler,224927611,282,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-06-09T15:15:19Z,2016-06-09T15:15:19Z,"There is an additional problem which is that we currently do not distinguish between metadata that we transfer to outlinks and the ones we just filter to persist.

For instance isFeed is useful for marking that a URL is a newsfeed but this should not be transferred to the outlinks. A transferred md should always be persisted but not all persisted ones should be transferred.

I'll look into having 2 separate configs and/or use a convention to mark whether a given metadata key should be only persisted and not transferred. The former can cause some redundancy but is clearer.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNDkyNzYxMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/282,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNDkyNzk0NQ==,incubator-stormcrawler,224927945,282,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-06-09T15:16:20Z,2016-06-09T15:16:20Z,"Q: is __redirTo_ also transferred to the outlinks?

A: yes. definitely a bug
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNDkyNzk0NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/282,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNTExMzA0Mw==,incubator-stormcrawler,225113043,282,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-06-10T07:32:53Z,2016-06-10T07:32:53Z,"Closing for now, the suggestion for depth and url path is not that crucial compared to what #293 brings
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNTExMzA0Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/283,https://api.github.com/repos/apache/incubator-stormcrawler/issues/283,incubator-stormcrawler,153427292,283,Custom scheduling based on metadata,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-05-06T10:53:28Z,2016-06-09T13:13:24Z,"The default scheduler determines when a page should be re-fetched based on its status only and the same value is used regardless of the nature of a page e.g. RSS feed, sitemap, content page etc...

We could add a basic mechanism where a page could use an arbitrary key value in its metadata to set its nextFetchDate when it has been successfully fetched.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/283/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/283,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNDYwODE4MA==,incubator-stormcrawler,224608180,283,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-06-08T14:32:21Z,2016-06-08T14:32:21Z,"This could be used initially for #291 so that feed URLs get refetched more frequently than the pages they point to
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNDYwODE4MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/283,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNDg5MDE4NQ==,incubator-stormcrawler,224890185,283,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-06-09T13:13:24Z,2016-06-09T13:13:24Z,"Implemented in [e3ed3bb]

```
# custom fetch interval to be used when a document has the key/value in its metadata
# and has been fetched succesfully (value in minutes)
# fetchInterval.isFeed=true: 10
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNDg5MDE4NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/284,https://api.github.com/repos/apache/incubator-stormcrawler/issues/284,incubator-stormcrawler,153428307,284,Add bolt for parsing RSS feeds,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-05-06T11:00:04Z,2016-06-09T13:13:58Z,"Could be based on [ROME](https://github.com/rometools/rome) and follow the same logic as the SitemapParserBolt i.e. pass on to the next component on the default stream unless an arbitrary key value is found in the metadata (e.g. _isFeed=true_) or a matching mimetype is found in the metadata.

This bolt will then parse the content of the document and generate outlinks on the status stream. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/284/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/285,https://api.github.com/repos/apache/incubator-stormcrawler/issues/285,incubator-stormcrawler,155705651,285,Upgrade to Tika 1.13,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-05-19T10:37:30Z,2016-05-19T14:51:30Z,"[https://tika.apache.org/1.13/index.html]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/285/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/286,https://api.github.com/repos/apache/incubator-stormcrawler/issues/286,incubator-stormcrawler,156116562,286,Add Flux equivalent of the example topology class ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-05-21T19:00:30Z,2016-06-23T08:39:51Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/286/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/286,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNzE2NDExNA==,incubator-stormcrawler,227164114,286,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-06-20T14:47:21Z,2016-06-20T14:47:21Z,"- made sure that serialization is done properly as this is handled by the ConfigurableTopology 6b3c179c273737e553b4c1890221a7cd3556dcf8

**TODO**
- check that the default configuration gets loaded (for the same reason)

Flux file could contain something like

```
includes:
    - resource: true
      file: ""/crawler-default.yaml""
      override: false

    - resource: false
      file: ""crawler-conf.yaml""
      override: false
```

however this fails as crawler-default.yaml does not contain a root `config:` element. One option would be to modify the existing code so that it can handle config file with or without such a root element, the same config files could then be used by Flux OR the ConfigurableTopology.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNzE2NDExNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/286,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNzQwOTE2Mw==,incubator-stormcrawler,227409163,286,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-06-21T11:09:47Z,2016-06-21T11:09:47Z,"[flux 0c6e08a] allows the config to be loaded from a root 'config' key
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNzQwOTE2Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/290,https://api.github.com/repos/apache/incubator-stormcrawler/issues/290,incubator-stormcrawler,159134930,290,Add mimetype as a field for indexing ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-06-08T10:52:12Z,2016-06-23T11:23:04Z,"with some normalisation e.g. to remove charset or variants
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/290/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/290,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNTUzMzE0Nw==,incubator-stormcrawler,225533147,290,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-06-13T09:35:07Z,2016-06-13T09:35:07Z,"could use [https://tika.apache.org/1.12/api/org/apache/tika/mime/MimeType.html#getExtension()] as a value for the field or the [normalised media type](https://tika.apache.org/1.12/api/org/apache/tika/mime/MimeType.html#getType%28%29).

Unlike Nutch there aren't any index filters in SC so we'd have to generate an arbitrary metadata key value with a parsefilter 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNTUzMzE0Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/290,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNzk5NzU1MQ==,incubator-stormcrawler,227997551,290,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-06-23T09:31:17Z,2016-06-23T09:31:17Z,"Alternatively could also use [https://google.github.io/guava/releases/19.0/api/docs/com/google/common/net/MediaType.html] but that won't help with the normalisation or detection.

This could be done by the parsers instead to avoid guessing the value, we could have an abstract Parser class definining the tuples, handling the outlinks etc... as well as doing the detection.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNzk5NzU1MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/290,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNzk5OTEzMQ==,incubator-stormcrawler,227999131,290,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-06-23T09:37:50Z,2016-06-23T09:37:50Z,"The Tika parser is likely to use the AutoDetectParser which will do the detection anyway and put the value in Metadata.CONTENT_TYPE, so we don't need to do it again.

~~Could modify the Tika parser so that it takes the mimetype from the server as a clue~~ => done in #302

The value guessed from Tika will be stored in 'parse.Content-Type' whereas the original will be in 'content-type'. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNzk5OTEzMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/290,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyODAxMTE1MQ==,incubator-stormcrawler,228011151,290,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-06-23T10:31:24Z,2016-06-23T10:31:24Z,"See #303 to detect mimetype with JSoupParser bolt, we'd then use the same key as the one used by Tika  'parse.Content-Type'
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyODAxMTE1MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/290,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyODAyMDc2OA==,incubator-stormcrawler,228020768,290,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-06-23T11:23:04Z,2016-06-23T11:23:04Z,"Now that #303 has been committed we should get values for 'parse.Content-Type' regardless of the parser implementation used; adding the mimetype as a field is trivial 

```
indexer.md.mapping:
- parse.Content-Type=contentType
```

The value is not normalised but this could be done later on.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyODAyMDc2OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/292,https://api.github.com/repos/apache/incubator-stormcrawler/issues/292,incubator-stormcrawler,159370723,292,Tika NoSuchMethodError,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-06-09T10:01:09Z,2016-10-13T10:30:11Z,"This occurred after moving to 1.13. The pom gets the right version though. This does not happen with 1.12, will revert to that

```
java.lang.NoSuchMethodError: org.apache.tika.parser.ParseContext.getDocumentBuilder()Ljavax/xml/parsers/DocumentBuilder; at org.apache.tika.parser.pdf.PDFParser.loadDOM(PDFParser.java:602) at org.apache.tika.parser.pdf.PDFParser.extractMetadata(PDFParser.java:203) at org.apache.tika.parser.pdf.PDFParser.parse(PDFParser.java:136) at org.apache.tika.parser.CompositeParser.parse(CompositeParser.java:281) at org.apache.tika.parser.CompositeParser.parse(CompositeParser.java:281) at org.apache.tika.parser.AutoDetectParser.parse(AutoDetectParser.java:120) at com.digitalpebble.storm.crawler.tika.ParserBolt.execute(ParserBolt.java:185)
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/292/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/292,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1MzI3NDI5OQ==,incubator-stormcrawler,253274299,292,NA,tballison,6739646,Tim Allison,tallison@apache.org,NA,2016-10-12T17:03:24Z,2016-10-12T17:03:24Z,"Is this a bug in Tika or a version conflict in the storm-crawler ecosystem?  I'd strongly encourage using 1.13 at this particular point in the code because of this [CVE](http://seclists.org/oss-sec/2016/q2/413)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1MzI3NDI5OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/292,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1MzQ2Nzc4OQ==,incubator-stormcrawler,253467789,292,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-10-13T09:50:47Z,2016-10-13T09:50:47Z,"Thanks @tballison. Will look into it again.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1MzQ2Nzc4OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/292,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1MzQ3NjM3Nw==,incubator-stormcrawler,253476377,292,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-10-13T10:30:11Z,2016-10-13T10:30:11Z,"Can't reproduce the problem. I can use Tika 1.13 in a topology running in Eclipse as well as using the Storm command both in local and deployed mode. Marking as closed for now.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1MzQ3NjM3Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/294,https://api.github.com/repos/apache/incubator-stormcrawler/issues/294,incubator-stormcrawler,159910416,294,Port code to Storm 1.x,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-06-13T09:42:17Z,2016-06-16T10:14:57Z,"Most of the work has been done in a separate branch [https://github.com/DigitalPebble/storm-crawler/tree/storm1.0] but recent modifications need to be added to it.

We'd benefit from all the improvements in [Storm 1.x](http://storm.apache.org/2016/04/12/storm100-released.html)

There is a number of tasks that depend on this :
- FetcherBolt simplify access to OutputCollector #278
- ES metrics - remove filtering #281
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/294/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/296,https://api.github.com/repos/apache/incubator-stormcrawler/issues/296,incubator-stormcrawler,160391526,296,Remote TTL from metrics index,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-06-15T10:42:12Z,2016-06-17T12:38:56Z,"Could replace with a daily rolling index or let users delete with a query when gets too large [https://www.elastic.co/guide/en/elasticsearch/plugins/current/plugins-delete-by-query.html]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/296/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/297,https://api.github.com/repos/apache/incubator-stormcrawler/issues/297,incubator-stormcrawler,160429300,297,HTTP use cookie spec standard,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-06-15T13:59:39Z,2016-06-20T09:16:51Z,"[https://hc.apache.org/httpcomponents-client-ga/httpclient/apidocs/org/apache/http/client/config/CookieSpecs.html#STANDARD] instead of the DEFAULT one.

see [https://issues.apache.org/jira/browse/HTTPCLIENT-1640]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/297/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/299,https://api.github.com/repos/apache/incubator-stormcrawler/issues/299,incubator-stormcrawler,160865193,299,AggregationSpout to use sampling,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-06-17T11:10:35Z,2016-06-29T20:01:26Z,"Queries take more and more time as the index gets larger. As an example, I am seeing querying taking over 3 secs on a status index containing 70M docs. Es 2.x has a sampling method which could be useful for speeding things up. There is also I think a mechanism for [profiling queries](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-profile.html) which would give some insights into why the aggregation takes time.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/299/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/299,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNzA5MjE2OA==,incubator-stormcrawler,227092168,299,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-06-20T09:24:00Z,2016-06-20T09:24:00Z,"Now that the status index contains 200M docs, some queries take up to 15 secs (depending on the shard size).
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNzA5MjE2OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/299,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNzA5NTg0Nw==,incubator-stormcrawler,227095847,299,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-06-20T09:40:21Z,2016-06-20T09:40:21Z,"the queries we send currently look like this 

```
curl -Xget ""http://localhost:9200/status/_search?pretty=true&preference=_shards:0"" -d'
{
  ""from"": 0,
  ""size"": 0,
  ""query"": {
    ""range"": {
      ""nextFetchDate"": {
        ""from"": null,
        ""to"": ""2016-06-20T09:31:03.743Z"",
        ""include_lower"": true,
        ""include_upper"": true
      }
    }
  },
  ""explain"": false,
  ""aggregations"": {
    ""partition"": {
      ""terms"": {
        ""field"": ""metadata.hostname"",
        ""size"": 100,
        ""order"": {
          ""top_hit"": ""asc""
        }
      },
      ""aggregations"": {
        ""docs"": {
          ""top_hits"": {
            ""size"": 3,
            ""explain"": false,
            ""sort"": [
              {
                ""nextFetchDate"": {
                  ""order"": ""asc""
                }
              }
            ]
          }
        },
        ""top_hit"": {
          ""min"": {
            ""field"": ""nextFetchDate""
          }
        }
      }
    }
  }
}'
```

which took 6 secs
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNzA5NTg0Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/299,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNzA5NzA0OQ==,incubator-stormcrawler,227097049,299,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-06-20T09:45:42Z,2016-06-20T09:45:42Z,"Using the [sampler aggregation](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-sampler-aggregation.html)

the following query takes only 3 secs

```
GET status/_search
{
  ""query"": {
    ""range"": {
      ""nextFetchDate"": {
        ""lt"": ""now""
      }
    }
  },
  ""size"": 0,
  ""aggs"": {
    ""sample"": {
      ""sampler"": {
        ""field"": ""_routing"",
        ""shard_size"": 300, 
        ""max_docs_per_value"": 3
      },
      ""aggs"": {
        ""hostname"": {
          ""terms"": {
            ""field"": ""_routing"",
            ""size"": 100
          },
          ""aggs"": {
            ""docs"": {
              ""top_hits"": {
                ""size"": 3,
                ""explain"": false,
                ""sort"": [
                  {
                    ""nextFetchDate"": {
                      ""order"": ""asc""
                    }
                  }
                ]
              }
            }
          }
        }
      }
    }
  }
}
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyNzA5NzA0OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/299,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyODEwNTc3OQ==,incubator-stormcrawler,228105779,299,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-06-23T16:28:14Z,2016-06-23T16:28:14Z,"could be simplified into 

``` json
{
  ""query"": {
    ""range"": {
      ""nextFetchDate"": {
        ""lt"": ""now""
      }
    }
  },
  ""size"": 0,
  ""aggs"": {
    ""sample"": {
      ""sampler"": {
        ""field"": ""_routing"",
        ""shard_size"": 300,
        ""max_docs_per_value"": 3
      },
      ""aggs"": {
        ""docs"": {
          ""top_hits"": {
            ""size"": 300,
            ""explain"": false
          }
        }
      }
    }
  }
}
```

This does not give any guarantee that the older documents will be returned first but has better performance when the index gets large (32 vs 44 sec on a shard containing 75M docs)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyODEwNTc3OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/300,https://api.github.com/repos/apache/incubator-stormcrawler/issues/300,incubator-stormcrawler,161162036,300,Change version numbers to 1.0-SNAPSHOT,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-06-20T10:15:42Z,2016-06-20T10:24:25Z,"Following a consultation on Twitter, and since we are now running on Storm 1.x, the next release will be 1.0. The versions need changing in the poms
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/300/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/302,https://api.github.com/repos/apache/incubator-stormcrawler/issues/302,incubator-stormcrawler,161882192,302,Provide clues to Tika parser for indentification of mimetype,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-06-23T09:48:29Z,2016-06-23T09:51:14Z,"e.g. filename and mime type returned by server
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/302/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/303,https://api.github.com/repos/apache/incubator-stormcrawler/issues/303,incubator-stormcrawler,161890211,303,JSoupParser detects mimetype with Tika,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-06-23T10:30:04Z,2016-06-23T11:18:55Z,"JSoupParser bolt currently can't handle pages for which the server returned no mimetype e.g.
[http://ask.39.net/question/41000455.html]

we should use Tika to detect the mimetype for us
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/303/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/303,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyODAyMDAxNw==,incubator-stormcrawler,228020017,303,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-06-23T11:18:55Z,2016-06-23T11:18:55Z,"Implemented in [master 0c18986]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyODAyMDAxNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/304,https://api.github.com/repos/apache/incubator-stormcrawler/issues/304,incubator-stormcrawler,161897991,304,SubDocumentsFilterTest should not use a sitemap file,jnioche,218319,Julien Nioche,julien@digitalpebble.com,OPEN,2016-06-23T11:15:44Z,2016-09-15T15:17:41Z,"this currently uses the JSoupParser - which works only because we allow it to parse when no mimetype is available. We should have a minimalistic HTML doc to do the same OR use the RSS feed and generate subdocuments for each feed item
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/304/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/304,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0NzM1ODYyOQ==,incubator-stormcrawler,247358629,304,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-09-15T15:17:41Z,2016-09-15T15:17:41Z,"The FeedParserBolt does not provide a DOM for the filters to operate on. We could demonstrate the functionality on a HTML doc instead or use JSoupParser on a feed. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0NzM1ODYyOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/306,https://api.github.com/repos/apache/incubator-stormcrawler/issues/306,incubator-stormcrawler,162333918,306,Rename packages to com.digitalpebble.stormcrawler,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-06-26T16:00:25Z,2016-07-04T11:59:27Z,"instead of `com.digitalpebble.storm.crawler` as we currently do.

Now would be a good time to do it as the next release will be 1.0 

com.digitalpebble.storm contains only the subpackage crawler and the whole project is about storm crawler

our poms use <groupId>com.digitalpebble.stormcrawler</groupId>, the packages should reflect the same logic

Thoughts?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/306/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/306,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyODYwODMyOA==,incubator-stormcrawler,228608328,306,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-06-26T16:02:10Z,2016-06-26T16:02:10Z,"Poll on [https://twitter.com/stormcrawlerapi/status/747097497148002305] 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyODYwODMyOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/307,https://api.github.com/repos/apache/incubator-stormcrawler/issues/307,incubator-stormcrawler,162605754,307,Flux : config element not read properly,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-06-28T05:32:49Z,2016-06-28T09:49:09Z,"fetcher.threads.number is set to 10 which is the default value despite setting it to 50 in the custom config
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/307/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/307,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyOTAwMTU0OQ==,incubator-stormcrawler,229001549,307,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-06-28T09:41:15Z,2016-06-28T09:41:15Z,"See [https://github.com/apache/storm/blob/master/external/flux/flux-core/src/main/java/org/apache/storm/flux/parser/FluxParser.java#L162]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIyOTAwMTU0OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/308,https://api.github.com/repos/apache/incubator-stormcrawler/issues/308,incubator-stormcrawler,162605982,308,Upgrade to Java 8,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-06-28T05:34:36Z,2016-07-01T09:13:46Z,"consultation on https://twitter.com/stormcrawlerapi/status/747354528140398596
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/308/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/309,https://api.github.com/repos/apache/incubator-stormcrawler/issues/309,incubator-stormcrawler,163010059,309,error.cause vs error.source ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-06-29T19:44:16Z,2016-06-29T20:00:52Z,"Some bolts use _error.source_ to give an indication of why an ERROR status has been generated :
- FeedParserBolt
- JSoupParserBolt
- SitemapParserBolt

while others user _error.cause_ :
- FetcherBolt
- SimpleFetcherBolt
- AbstractStatusUpdaterBolt

The former is used with _Constants.STATUS_ERROR_MESSAGE_. 

They actually mean slightly different things. 'source' is used when encountering an exception and 'error message` provides some background whereas 'cause' is for special cases which are not necessarily exceptions e.g not allowed by robots.

We should add cause to the constants and source to the default values to persist.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/309/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/311,https://api.github.com/repos/apache/incubator-stormcrawler/issues/311,incubator-stormcrawler,163635592,311,FetcherBolt : internal queues keep growing,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-07-04T09:17:23Z,2016-09-07T14:43:06Z,"Even when tuples get a timeout, they remain in the FetcherBolt internal queues which keep growing as a result. These URLs are not considered in flight and the spouts keep generating new ones.

We could discard the content of the queues when we know that they have been sitting there for longer than the tuple timeout.

In addition to this we could also stop ingesting new URLs when the total number of URLs in the internal queues reaches a configurable value. The new tuples would then wait in the standard Storm queues, which can be used by the backpressure mechanism.  
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/311/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/311,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0NTMwMzAyMg==,incubator-stormcrawler,245303022,311,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-09-07T14:43:05Z,2016-09-07T14:43:05Z,"Added `fetcher.max.urls.in.queues` to block as described above. Does not remove the URLs from queues as such but at least would allow to use the backpressure.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0NTMwMzAyMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/312,https://api.github.com/repos/apache/incubator-stormcrawler/issues/312,incubator-stormcrawler,163835674,312,URLFilter based on metadata,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-07-05T12:09:25Z,2016-07-08T10:38:08Z,"Make it 100% configurable and use e.g. to prevent outlinks from being followed on pages discovered by sitemap files (isSitemap=false). 

Note : the filter is applied based on the metadata of the parent page
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/312/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/312,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIzMDgwNDc3Mw==,incubator-stormcrawler,230804773,312,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-07-06T15:17:49Z,2016-07-06T15:17:49Z,"Still need to add tests for the MetadataFilter 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIzMDgwNDc3Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/313,https://api.github.com/repos/apache/incubator-stormcrawler/issues/313,incubator-stormcrawler,164510664,313,Add WARC module to main repo,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-07-08T11:20:48Z,2016-10-24T09:48:44Z,"It is currently used in [https://github.com/DigitalPebble/sc-warc] - which works on HDFS only.
We might want it in core, irrespective of where it is being stored onto. For instance we might have add code for storing into Amazon S3.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/313/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/313,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIzNDE5Mzc3MQ==,incubator-stormcrawler,234193771,313,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-07-21T08:47:37Z,2016-07-21T08:47:37Z,"or move the whole warc repo as a submodule of SC and make the format class reusable by other implementations?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIzNDE5Mzc3MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/313,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NDIyMzI2NA==,incubator-stormcrawler,254223264,313,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2016-10-17T14:28:04Z,2016-10-17T14:28:04Z,"Although based on HDFS it allows writing to a local file. Writing to S3 should also be possible via HDFS using `s3a://` as scheme/protocol and given that s3a support libraries are installed.

Having the WARC bolt in the main repo would simplify to synchronize its dependencies with that of stormcrawler.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NDIyMzI2NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/313,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NDUzNDAyMg==,incubator-stormcrawler,254534022,313,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-10-18T14:56:49Z,2016-10-18T14:56:49Z,"Seems to be some consensus on https://twitter.com/stormcrawlerapi/status/788021645957009410
I will port the code to the main repo.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NDUzNDAyMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/314,https://api.github.com/repos/apache/incubator-stormcrawler/issues/314,incubator-stormcrawler,164831932,314,ESStatusUpdater delayed FETCHED status writes,hironroy,5359094,Hiron Roy,,CLOSED,2016-07-11T13:03:38Z,2016-07-28T07:01:14Z,"Hi, thanks for all the great work you guys have been doing on Storm Crawler!

When I run my crawl topology on a Storm Cluster (instead of on a local cluster), I'm not seeing any ""FETCHED"" statuses appear in the ES `status` index for a day or so. After the ""FETCHED"" statuses start appearing (after a day), they update at a rate that reflects the fetch rate.

Is this expected behavior? Am I configuring the ESStatusUpdater incorrectly?

Thanks in advance for any guidance and help! 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/314/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/314,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIzMTc1NTIzNw==,incubator-stormcrawler,231755237,314,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-07-11T14:42:15Z,2016-07-11T14:42:15Z,"Hi, thanks for your kind words.

This is definitely not the expected behaviour. The FETCHED should indeed match the fetch rate but should not take a day to appear on the index.

Can you share your ES and crawl configs? What sort of pages do you crawl for? Do they contain many outlinks? Any messages on the logs?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIzMTc1NTIzNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/314,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIzMjA2NDkyMw==,incubator-stormcrawler,232064923,314,NA,hironroy,5359094,Hiron Roy,,NA,2016-07-12T14:28:57Z,2016-07-12T14:28:57Z,"Thanks! I'll be troubleshooting tonight, at which time, I'll compile and share my configs and logs.

To familiarize myself with storm-crawler, I've been pointing at Reddit's home page and limiting the crawl to subreddit and topic comment pages. There are a lot outlinks being emitted for the average page.

With basic poking around and grep-ing the Storm-Supervisor logs, I haven't found any error messages. I'm in the middle of setting up Logstash, so I'll be able to provide more details shortly.

Additionally, I'm going to install the BigHead plugin to my ES instance and see if the issue lies in the indexing performance.

Thanks Again. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIzMjA2NDkyMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/314,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIzMjIxODUyNw==,incubator-stormcrawler,232218527,314,NA,hironroy,5359094,Hiron Roy,,NA,2016-07-13T00:08:25Z,2016-07-13T00:08:25Z,"Got caught up with other work tasks, but will get on this tomorrow morning.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIzMjIxODUyNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/314,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIzMzY3MTU4Mg==,incubator-stormcrawler,233671582,314,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-07-19T15:33:44Z,2016-07-19T15:33:44Z,"Hi @hironroy - still an issue or can we close this?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIzMzY3MTU4Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/314,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIzNDM0NjQyMA==,incubator-stormcrawler,234346420,314,NA,hironroy,5359094,Hiron Roy,,NA,2016-07-21T18:45:02Z,2016-07-21T18:45:02Z,"Looking at the performance metrics of the ES instance, I think the bottleneck is occurring there, so closing the issue makes sense. If I find anything that contradicts that, I'll update you. Thanks!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIzNDM0NjQyMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/314,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIzNDM3OTAwMQ==,incubator-stormcrawler,234379001,314,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-07-21T20:47:02Z,2016-07-21T20:47:02Z,"OK. It makes sense to give ES plenty of memory and fast disks in write-heavy situations e.g. when there's many outlinks discovered.
Having said that, it should definitely not take a day for the status to get updated. 
Wondering whether it could be that you get tuple timeouts on the URLs fetched because they have too many outlinks to write to ES first and so they get removed from the cache in the spout and get replayed next time round. If you look at the logs, do you see the same URLS being refetched again and again? 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIzNDM3OTAwMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/315,https://api.github.com/repos/apache/incubator-stormcrawler/issues/315,incubator-stormcrawler,164874684,315,Adaptative URL filter to normalize URLs based on canonical tag,jnioche,218319,Julien Nioche,julien@digitalpebble.com,OPEN,2016-07-11T16:07:43Z,2019-04-26T20:13:59Z,"Such a filter could compare the parameters of a URL with the canonical tag found in the page (if any) and  determine after a while which parameters can be safely removed in order to normalise the URL.

The aim is similar to the [clean-param extension of the robots protocol by Yandex](https://yandex.com/support/webmaster/controlling-robot/robots-txt.xml#clean-param) where sites can specify how URLs can be normalised.

TODO compare with [research.google.com/pubs/archive/35210.pdf]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/315/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/315,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4Njk4MzUxOA==,incubator-stormcrawler,486983518,315,NA,sandrohoerler,37837015,Zandeer,,NA,2019-04-26T09:00:25Z,2019-04-26T09:00:25Z,"If a canonical metatag is found on a page, the `AbstractIndexerBolt#valueForUrl` method returns the targetUrl concatinated with the canonical url found on the page. This issue is can be reproduced by crawling `https://www.geotest.ch/kompetenzen/naturgefahren/massnahmenplanung.html`. Is this a known issue?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4Njk4MzUxOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/315,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4NzAxNDg3MQ==,incubator-stormcrawler,487014871,315,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-04-26T10:47:27Z,2019-04-26T10:47:27Z,"hi @sandrohoerler 

blame the web page ;-)

`<link rel=""canonical"" href=""http://www.geotest.ch/https://www.geotest.ch/kompetenzen/naturgefahren/massnahmenplanung.html"">
`","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4NzAxNDg3MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/315,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4NzAxOTUwMw==,incubator-stormcrawler,487019503,315,NA,sandrohoerler,37837015,Zandeer,,NA,2019-04-26T11:06:46Z,2019-04-26T11:06:46Z,"@jnioche Haha, sorry for that ;) This wasn't a good example i think. But we encouter the same problem if we crawl 
`https://www.hoteljob.ch/`. It leads to `https://www.hoteljob.ch/https://www.hoteljob.ch/job-suchen`. And here `<link rel=""canonical"" href=""www.hoteljob.ch/job-suchen"">` should be properly set :-). Also every persistet subsite url is unusable like `https://www.hoteljob.ch/arbeitgeber/park-kafi-kreuzlingen/www.hoteljob.ch/arbeitgeber/park-kafi-kreuzlingen/567033 ` and its `<link rel=""canonical"" href=""www.hoteljob.ch/arbeitgeber/park-kafi-kreuzlingen/567033"">`

This should be a better example :-)","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4NzAxOTUwMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/315,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4NzA1NzMyMA==,incubator-stormcrawler,487057320,315,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-04-26T13:30:36Z,2019-04-26T13:30:36Z,"From the Javadoc of **java.net.URL.URL(URL context, String spec) throws MalformedURLException**

> 
> Creates a URL by parsing the given spec within a specified context. The new URL is created from the given context URL and the spec argument as described in RFC2396 ""Uniform Resource Identifiers : Generic * Syntax"" :
> 
>           <scheme>://<authority><path>?<query>#<fragment>
>  
> The reference is parsed into the scheme, authority, path, query and fragment parts. If the path component is empty and the scheme, authority, and query components are undefined, then the new URL is a reference to the current document. Otherwise, the fragment and query parts present in the spec are used in the new URL.
> If the scheme component is defined in the given spec and does not match the scheme of the context, then the new URL is created as an absolute URL based on the spec alone. Otherwise the scheme component is inherited from the context URL.
> 
> If the authority component is present in the spec then the spec is treated as absolute and the spec authority and path will replace the context authority and path. If the authority component is absent in the spec then the authority of the new URL will be inherited from the context.
> 
> If the spec's path component begins with a slash character ""/"" then the path is treated as absolute and the spec path replaces the context path.
> 
> Otherwise, the path is treated as a relative path and is appended to the context path, as described in RFC2396. Also, in this case, the path is canonicalized through the removal of directory changes made by occurrences of "".."" and ""."".
> 
> For a more detailed description of URL parsing, refer to RFC2396.

The value found in the HTML is neither relative nor absolute which is why we get that. Again, blame the site. 

You could write a URLFilter to rewrite such URLs so that the outlinks are fixed but that won't help much with the sitemaps.

Can you use StackOverflow if you have more questions? ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4NzA1NzMyMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/315,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4NzEzNDU3OQ==,incubator-stormcrawler,487134579,315,NA,sandrohoerler,37837015,Zandeer,,NA,2019-04-26T17:21:07Z,2019-04-26T17:21:07Z,Thank you and sorry for disturbing you,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4NzEzNDU3OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/315,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4NzE4Njk2Nw==,incubator-stormcrawler,487186967,315,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-04-26T20:13:58Z,2019-04-26T20:13:58Z,You haven't disturbed me at all! I am glad you are using SC and thankful that you are taking the time to report potential issues,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4NzE4Njk2Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/316,https://api.github.com/repos/apache/incubator-stormcrawler/issues/316,incubator-stormcrawler,165312365,316,Frontera + SC?,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-07-13T12:50:29Z,2016-10-10T13:08:08Z,"[https://github.com/scrapinghub/frontera] is used with Scrapy to handle distribution and URL frontier management. It should be possible to write resources so that Frontera delegates the fetching and parsing to StormCrawler.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/316/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/317,https://api.github.com/repos/apache/incubator-stormcrawler/issues/317,incubator-stormcrawler,166335723,317,HTTP protocol : store response headers verbatim in metadata ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-07-19T13:48:03Z,2016-07-21T11:37:52Z,"[WARCRecordFormat](https://github.com/DigitalPebble/sc-warc/blob/master/src/main/java/com/digitalpebble/stormcrawler/warc/WARCRecordFormat.java#L66) uses the value of the metadata key `_response.headers_` to include the HTTP headers in the WARC representation. The  WARCTypeValue  would then be 'response' instead of `resource`.

Similarly we'll need to store the request for [https://github.com/DigitalPebble/sc-warc/issues/1]
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/317/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/317,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIzNDIxNTIxNA==,incubator-stormcrawler,234215214,317,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-07-21T10:23:19Z,2016-07-21T10:23:19Z,"Storing the request headers is not easily doable with httpclient as the user agent info is not accessible from the httpget object.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIzNDIxNTIxNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/317,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIzNDIyOTI0Ng==,incubator-stormcrawler,234229246,317,NA,anjackson,87843,Andy Jackson,anj@anjackson.net,NA,2016-07-21T11:37:52Z,2016-07-21T11:37:52Z,"In case it's useful in the future, I think [this is how Heritrix does it](https://github.com/internetarchive/heritrix3/blob/124907341f8b4b3e921c03721d77d52b33ea96e0/modules/src/main/java/org/archive/modules/fetcher/FetchHTTPRequest.java#L628). i.e. it wraps the input and output streams at the socket level and records what happens so it can be picked apart afterwards.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIzNDIyOTI0Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/319,https://api.github.com/repos/apache/incubator-stormcrawler/issues/319,incubator-stormcrawler,170142797,319,NoNodeAvailableException thrown when calling StatusUpdaterBolt.cleanup(),mattburns,1316126,Matt Burns,,CLOSED,2016-08-09T11:25:14Z,2016-08-23T06:42:57Z,"Actually thrown when closing the `BulkProcessor` in `ElasticSearchConnection`.

```
org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{****}{****/****:9300}]
    at org.elasticsearch.client.transport.TransportClientNodesService.ensureNodesAreAvailable(TransportClientNodesService.java:290) ~[elasticsearch-2.3.1.jar:2.3.1]
    at org.elasticsearch.client.transport.TransportClientNodesService.execute(TransportClientNodesService.java:207) ~[elasticsearch-2.3.1.jar:2.3.1]
    at org.elasticsearch.client.transport.support.TransportProxyClient.execute(TransportProxyClient.java:55) ~[elasticsearch-2.3.1.jar:2.3.1]
    at org.elasticsearch.client.transport.TransportClient.doExecute(TransportClient.java:288) ~[elasticsearch-2.3.1.jar:2.3.1]
    at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:359) ~[elasticsearch-2.3.1.jar:2.3.1]
    at org.elasticsearch.client.support.AbstractClient.bulk(AbstractClient.java:436) ~[elasticsearch-2.3.1.jar:2.3.1]
    at org.elasticsearch.action.bulk.Retry$AbstractRetryHandler.execute(Retry.java:219) ~[elasticsearch-2.3.1.jar:2.3.1]
    at org.elasticsearch.action.bulk.Retry.withAsyncBackoff(Retry.java:72) ~[elasticsearch-2.3.1.jar:2.3.1]
    at org.elasticsearch.action.bulk.BulkRequestHandler$AsyncBulkRequestHandler.execute(BulkRequestHandler.java:123) [elasticsearch-2.3.1.jar:2.3.1]
    at org.elasticsearch.action.bulk.BulkProcessor.execute(BulkProcessor.java:312) [elasticsearch-2.3.1.jar:2.3.1]
    at org.elasticsearch.action.bulk.BulkProcessor.awaitClose(BulkProcessor.java:240) [elasticsearch-2.3.1.jar:2.3.1]
    at org.elasticsearch.action.bulk.BulkProcessor.close(BulkProcessor.java:212) [elasticsearch-2.3.1.jar:2.3.1]
    at com.digitalpebble.stormcrawler.elasticsearch.ElasticSearchConnection.close(ElasticSearchConnection.java:166) [storm-crawler-elasticsearch-1.0.jar:?]
    at com.digitalpebble.stormcrawler.elasticsearch.persistence.StatusUpdaterBolt.cleanup(StatusUpdaterBolt.java:200) [storm-crawler-elasticsearch-1.0.jar:?]
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/319/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/321,https://api.github.com/repos/apache/incubator-stormcrawler/issues/321,incubator-stormcrawler,170455320,321,SimpleFetcherBolt not encoding spaces,ndtreviv,1530653,Nathan Trevivian,,CLOSED,2016-08-10T16:04:51Z,2016-08-10T17:23:42Z,"We've come across several `illegal character in path` errors in our logs, eg:

```
java.lang.IllegalArgumentException: Illegal character in path at index 48: http://www.laznianowa.pl//upload/files/molinezja fot.g.gazik 1.jpg
```

In this case, the URL is sort-of fine, so long as spaces are URL encoded.

Stack trace example:

```
java.lang.IllegalArgumentException: Illegal character in path at index 50: http://www.laznianowa.pl//upload/files/fakir9_fot. grzegorz ziemiaski.jpg
    at java.net.URI.create(URI.java:859) ~[?:1.7.0_101]
    at org.apache.http.client.methods.HttpGet.<init>(HttpGet.java:69) ~[stormjar.jar:?]
    at com.digitalpebble.storm.crawler.protocol.httpclient.HttpProtocol.getProtocolOutput(HttpProtocol.java:127) ~[stormjar.jar:?]
    at com.digitalpebble.storm.crawler.bolt.SimpleFetcherBolt.execute(SimpleFetcherBolt.java:333) [stormjar.jar:?]
```

Is there something we need to do to ensure that the spaces are encoded before SimpleFetcherBolt attempts to fetch them?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/321/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/321,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIzODkzOTA5OQ==,incubator-stormcrawler,238939099,321,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-08-10T17:23:18Z,2016-08-10T17:23:18Z,"Hi @ndtreviv 
This is not handled at the Fetcher level or even by the Protocol but through the URL filtering. The [BasicURLNormalizer](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/filtering/basic/BasicURLNormalizer.java) should already do it, you just need to add it to the URL filtering configuration. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDIzODkzOTA5OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/323,https://api.github.com/repos/apache/incubator-stormcrawler/issues/323,incubator-stormcrawler,170678884,323,Documentation: Kibana dashboard import and typos,sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2016-08-11T15:46:13Z,2016-08-19T15:54:13Z,"- to import the dashboard config kibana.json: need to create index patterns first, see #322
- typos in the Wiki, see [diff](https://github.com/sebastian-nagel/storm-crawler/wiki/Configuration/_compare/6481df1e1107a982e4038792ee3c6aea1fc9625f...aa7e898b801ffcbe5d9ed0a7bdd2fbc491a5c0ba?diff=unified)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/323/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/323,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0MTA1NzE3Mw==,incubator-stormcrawler,241057173,323,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-08-19T15:54:13Z,2016-08-19T15:54:13Z,"Wiki fixed, thanks!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0MTA1NzE3Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/324,https://api.github.com/repos/apache/incubator-stormcrawler/issues/324,incubator-stormcrawler,172272983,324,Can't seem to run the basic build - getting a java.io.FileNotFoundException ,sagistrauss,7079172,Sagi Strauss,,CLOSED,2016-08-20T14:13:30Z,2017-03-21T16:33:54Z,"Hey im trying to get a simple example running but when i build from the archetype and run 
`mvn clean compile exec:java -Dexec.mainClass=CrawlTopology -Dexec.args=""-conf crawler-conf.yaml -local""`
i get an error, it complains that it is missing a file in `flux-core.jar!/resources`
now iv'e went into the jar and the folder is there. 
how can i go about troubleshooting this issue, please help.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/324/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/324,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0MTMyOTE3Ng==,incubator-stormcrawler,241329176,324,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-08-22T06:59:14Z,2016-08-22T06:59:14Z,"Thanks, I can reproduce the problem and will look into it. In the meantime, using the storm command should work as a workaround
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0MTMyOTE3Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/324,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0MjAxNDg1MQ==,incubator-stormcrawler,242014851,324,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-08-24T10:02:29Z,2016-08-24T10:02:29Z,"Here is the full stack trace

```
11334 [Thread-8] INFO  o.a.s.d.supervisor - Copying resources at jar:file:/home/julien/.m2/repository/org/apache/storm/flux-core/1.0.1/flux-core-1.0.1.jar!/resources to /tmp/2f218499-138a-4770-afe8-26ff1d92a125/supervisor/stormdist/crawl-1-1472032813/resources
11335 [Thread-8] ERROR o.a.s.event - Error when processing event
java.io.FileNotFoundException: Source 'file:/home/julien/.m2/repository/org/apache/storm/flux-core/1.0.1/flux-core-1.0.1.jar!/resources' does not exist
    at org.apache.storm.shade.org.apache.commons.io.FileUtils.copyDirectory(FileUtils.java:1368) ~[storm-core-1.0.1.jar:1.0.1]
    at org.apache.storm.shade.org.apache.commons.io.FileUtils.copyDirectory(FileUtils.java:1261) ~[storm-core-1.0.1.jar:1.0.1]
    at org.apache.storm.shade.org.apache.commons.io.FileUtils.copyDirectory(FileUtils.java:1230) ~[storm-core-1.0.1.jar:1.0.1]
    at org.apache.storm.daemon.supervisor$fn__9359.invoke(supervisor.clj:1194) ~[storm-core-1.0.1.jar:1.0.1]
    at clojure.lang.MultiFn.invoke(MultiFn.java:243) ~[clojure-1.7.0.jar:?]
    at org.apache.storm.daemon.supervisor$mk_synchronize_supervisor$this__9078$fn__9096.invoke(supervisor.clj:582) ~[storm-core-1.0.1.jar:1.0.1]
    at org.apache.storm.daemon.supervisor$mk_synchronize_supervisor$this__9078.invoke(supervisor.clj:581) ~[storm-core-1.0.1.jar:1.0.1]
    at org.apache.storm.event$event_manager$fn__8630.invoke(event.clj:40) [storm-core-1.0.1.jar:1.0.1]
    at clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]
    at java.lang.Thread.run(Thread.java:745) [?:1.8.0_101]
```

the `resources` directory does exist in the jar though.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0MjAxNDg1MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/324,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0MjAxNjUyOA==,incubator-stormcrawler,242016528,324,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-08-24T10:10:14Z,2016-08-24T10:10:14Z,"The same issue happens when calling the Flux topology from Maven

`mvn clean compile exec:java -Dexec.mainClass=org.apache.storm.flux.Flux -Dexec.args=""--local crawler.flux""`

It does not happen when executing it from Eclipse
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0MjAxNjUyOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/324,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0MjAzMTkzMg==,incubator-stormcrawler,242031932,324,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-08-24T11:27:32Z,2016-08-24T11:27:32Z,"Reported in https://issues.apache.org/jira/browse/STORM-2055

Another workaround if you don't use Flux is simply to remove flux core from the dependencies in pom.xml  
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0MjAzMTkzMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/324,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1MzQ3NTI3MA==,incubator-stormcrawler,253475270,324,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-10-13T10:24:36Z,2016-10-13T10:24:36Z,"interestingly the same issue happens when removing Flux from the dependencies but adding storm-crawler-tika

```
java.io.FileNotFoundException: Source 'file:/home/pebble/.m2/repository/edu/ucar/grib/4.5.5/grib-4.5.5.jar!/resources' does not exist
    at org.apache.storm.shade.org.apache.commons.io.FileUtils.checkFileRequirements(FileUtils.java:1405) ~[storm-core-1.0.2.jar:1.0.2]
    at org.apache.storm.shade.org.apache.commons.io.FileUtils.copyDirectory(FileUtils.java:1368) ~[storm-core-1.0.2.jar:1.0.2]
    at org.apache.storm.shade.org.apache.commons.io.FileUtils.copyDirectory(FileUtils.java:1268) ~[storm-core-1.0.2.jar:1.0.2]
    at org.apache.storm.shade.org.apache.commons.io.FileUtils.copyDirectory(FileUtils.java:1237) ~[storm-core-1.0.2.jar:1.0.2]
    at org.apache.storm.daemon.supervisor$fn__9436.invoke(supervisor.clj:1178) ~[storm-core-1.0.2.jar:1.0.2]
    at clojure.lang.MultiFn.invoke(MultiFn.java:243) ~[clojure-1.7.0.jar:?]
    at org.apache.storm.daemon.supervisor$mk_synchronize_supervisor$this__9163$fn__9181.invoke(supervisor.clj:579) ~[storm-core-1.0.2.jar:1.0.2]
    at org.apache.storm.daemon.supervisor$mk_synchronize_supervisor$this__9163.invoke(supervisor.clj:578) ~[storm-core-1.0.2.jar:1.0.2]
    at org.apache.storm.event$event_manager$fn__8735.invoke(event.clj:40) [storm-core-1.0.2.jar:1.0.2]
    at clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]
    at java.lang.Thread.run(Thread.java:745) [?:1.8.0_101]
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1MzQ3NTI3MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/324,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1OTY5MTUzOA==,incubator-stormcrawler,259691538,324,NA,zakaf,3315213,Dongkeun Lee,,NA,2016-11-10T13:37:12Z,2016-11-10T13:37:12Z,"same issue here. Can't seem to add tika and i previously removed flux due to the @sageeki 's  issue.

<pre><code>java.io.FileNotFoundException: Source 'file:\C:\Users\Dongkeun\.m2\repository\edu\ucar\grib\4.5.5\grib-4.5.5.jar!\resources' does not exist
    at org.apache.storm.shade.org.apache.commons.io.FileUtils.checkFileRequirements(FileUtils.java:1405) ~[storm-core-1.0.2.jar:1.0.2]
    at org.apache.storm.shade.org.apache.commons.io.FileUtils.copyDirectory(FileUtils.java:1368) ~[storm-core-1.0.2.jar:1.0.2]
    at org.apache.storm.shade.org.apache.commons.io.FileUtils.copyDirectory(FileUtils.java:1268) ~[storm-core-1.0.2.jar:1.0.2]
    at org.apache.storm.shade.org.apache.commons.io.FileUtils.copyDirectory(FileUtils.java:1237) ~[storm-core-1.0.2.jar:1.0.2]
    at org.apache.storm.daemon.supervisor$fn__9436.invoke(supervisor.clj:1178) ~[storm-core-1.0.2.jar:1.0.2]
    at clojure.lang.MultiFn.invoke(MultiFn.java:243) ~[clojure-1.7.0.jar:?]
    at org.apache.storm.daemon.supervisor$mk_synchronize_supervisor$this__9163$fn__9181.invoke(supervisor.clj:579) ~[storm-core-1.0.2.jar:1.0.2]
    at org.apache.storm.daemon.supervisor$mk_synchronize_supervisor$this__9163.invoke(supervisor.clj:578) ~[storm-core-1.0.2.jar:1.0.2]
    at org.apache.storm.event$event_manager$fn__8735.invoke(event.clj:40) [storm-core-1.0.2.jar:1.0.2]
    at clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]
    at java.lang.Thread.run(Thread.java:745) [?:1.8.0_111]</code></pre>
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1OTY5MTUzOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/324,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1OTcwMjAzMA==,incubator-stormcrawler,259702030,324,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-11-10T14:22:59Z,2016-11-10T14:22:59Z,"@ldkz2524 please use the storm command for now. I reported the issue in Storm but there hasn't been progress on that front. Thanks!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1OTcwMjAzMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/324,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDg5NDA0Nw==,incubator-stormcrawler,270894047,324,NA,normansuesstrunk,6747520,Norman Süsstrunk,,NA,2017-01-06T12:26:00Z,2017-01-06T12:26:00Z,"i can run the Class locally in Eclipse with the following vm arguments: 
```
-conf crawler-conf.yaml -local
```
This seems to work fine so far. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDg5NDA0Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/324,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4ODEzNzQ2NA==,incubator-stormcrawler,288137464,324,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-21T16:33:48Z,2017-03-21T16:33:48Z,Fixed by upgrading to Storm 1.0.3 3bf149f,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4ODEzNzQ2NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/325,https://api.github.com/repos/apache/incubator-stormcrawler/issues/325,incubator-stormcrawler,172915201,325,POM for projects from archetypes should use Java 8,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-08-24T10:16:10Z,2016-08-24T11:30:36Z,"see #308 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/325/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/326,https://api.github.com/repos/apache/incubator-stormcrawler/issues/326,incubator-stormcrawler,172932122,326,Archetype : proper handling of user-provided package names,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-08-24T11:53:28Z,2016-08-24T11:54:08Z,"Currently the package names provided by the users when generating a project from the archetype are not reflected in the Java code nor in the README. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/326/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/327,https://api.github.com/repos/apache/incubator-stormcrawler/issues/327,incubator-stormcrawler,174226689,327,adding a dateLastProcessed field?,owenrh,2006075,Owen Rees-Hayward,,CLOSED,2016-08-31T09:31:23Z,2016-09-06T10:46:26Z,"Hi,

We're looking to add some additional diagnostic capability to the _status_ index by adding a _dateLastProcessed_ field.  

We could push it in as a metadata field in our own crawler code, but we were wondering if it would make sense as a top-level field that most storm-crawler users would benefit from?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/327/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/327,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0MzcyODE5Mg==,incubator-stormcrawler,243728192,327,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-08-31T10:49:16Z,2016-08-31T10:49:16Z,"Thanks @owenrh (and great to see that you joined @mattburns and his gang)

Would that value be different from the fetch date? If so it could be added by the AbstractStatusUpdaterBolt, if not then it would be created by the Fetcher bolt implementations and be called e.g. lastFetchDate to mirror nextFetchDate. Having this could be useful for implementing an adaptive scheduling and it would be good for diagnostics indeed. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0MzcyODE5Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/327,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0MzczMjM1MQ==,incubator-stormcrawler,243732351,327,NA,owenrh,2006075,Owen Rees-Hayward,,NA,2016-08-31T11:09:53Z,2016-08-31T11:09:53Z,"Thanks for getting back to me so quickly Julien.

Re: fetch date - it would be the timestamp of the last attempted fetch, so either _lastFetchDate_ or _lastProcessedDate_ would make sense. I think I suggested the latter just because I felt it didn't imply a successful fetch, which I thought _lastFetchDate_ might. (But maybe that's just a matter of documentation).

If you think it would be useful in the core then I'm happy to create a PR for it, and mod the AbstractStatusUpdaterBolt.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0MzczMjM1MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/329,https://api.github.com/repos/apache/incubator-stormcrawler/issues/329,incubator-stormcrawler,175234191,329,Should 403 response codes result in status of ERROR?,owenrh,2006075,Owen Rees-Hayward,,CLOSED,2016-09-06T12:27:40Z,2016-09-06T14:12:48Z,"The [_Status.fromHTTPCode_ ](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/persistence/Status.java) method currently returns a _FETCH_ERROR_ status for 403 response codes. Would it make more sense to return an _ERROR_ status as a 403 seems like a permanent crawl error?

I guess the same could maybe said for 404s? Possibly, maybe, or not.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/329/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/329,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0NDkzNzUwNQ==,incubator-stormcrawler,244937505,329,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-09-06T12:40:26Z,2016-09-06T12:40:26Z,"It would be logical to do so but in practice a 403 is not always a definitive error - it is sometimes used when you hit a server too hard and get temporarily blacklisted. When trying the same URL again a bit later you get the URL fine. Same for a 404, under stress some servers would throw them but not when working in a normal load.
There is (or at least I think so) a logic in the scheduler to turn a FETCH_ERROR into a hard ERROR after n attempts. ERROR means ""don't even try again"" e.g. something that breaks the parser whereas FETCH_ERROR gives it another chance.
PS: can you post questions on Stackoverflow with the label stormcrawler? That would boost the visibility of the project there :-)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0NDkzNzUwNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/329,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0NDk2MjE5Mg==,incubator-stormcrawler,244962192,329,NA,owenrh,2006075,Owen Rees-Hayward,,NA,2016-09-06T14:11:04Z,2016-09-06T14:11:04Z,"Yeah, I suspected it might not be as trivial as that. 

Just looking at the data some test data with the new metadata.lastProcessedDate I can see we're getting throttled with 404s. I think in terms of increasing our throughput we're going to have to become host-aware and think about some other options. Hmm, needs a bit more thought : )

(Will defo Stackoverflow it next time!)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0NDk2MjE5Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/331,https://api.github.com/repos/apache/incubator-stormcrawler/issues/331,incubator-stormcrawler,177180218,331,Conventional never refetch Date for nextFetchDate,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-09-15T13:42:19Z,2016-09-15T14:59:25Z,"The persistence classes could enforce a mechanism whereby URL must be > Date(0) in order to be fetchable. This convention would allow to specify -1 for the scheduling so that URLs are never refetched.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/331/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/331,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0NzM0NjkwMg==,incubator-stormcrawler,247346902,331,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-09-15T14:37:06Z,2016-09-15T14:37:06Z,"Date(Long.MAX_VALUE) is a better option as it does not require to change the logic in the spouts. And conceptually NEVER has probably  more to do with the future than the past. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0NzM0NjkwMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/334,https://api.github.com/repos/apache/incubator-stormcrawler/issues/334,incubator-stormcrawler,177823594,334,Add intelligence to AggregationSpout re:host availability,ndtreviv,1530653,Nathan Trevivian,,CLOSED,2016-09-19T15:54:46Z,2019-10-29T14:22:24Z,"Currently, if there are a number of URLs associated with a single domain, and that domain itself either no longer exists, or has a robots.txt rule denying access, there is no intelligence to handle that. The spout will emit all URLs to be processed regardless.

There is a certain amount of handling to cater for this (eg: cached robots rules) to ensure that when they are processed, they are processed quickly, but this could potentially be improved.

This is an enhancement request, therefore, for domains in the status index to be given a priority/scoring system that is updated with feedback from the fetcher bolt. 

If the URL 404s, or has an SSL error, and the root domain does the same, then the priority/score should be reduced.
If the robots.txt denies access, again the priority/score should be reduced.

The ""Top N Hosts"" query in the AggregationSpout should then take this priority/scoring into account.

Other things to consider are: 
- How many times a request to the root domain should be retried (in case of bad load-balancer, for example)
- How long before those hosts are retried once de-prioritised?
- How many times the hosts should be retried before giving up entirely?

There are probably a bunch of other things that need discussing when you get into the weeds of it, but this sort of intelligence would definitely improve overall throughput and would be a massive boon.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/334/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/334,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU0NzQ0NDU3OQ==,incubator-stormcrawler,547444579,334,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-10-29T14:22:23Z,2019-10-29T14:22:23Z,"Implemented  in ""Pluggable URLBuffer and Hybrid Elasticsearch spout (#752)""","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU0NzQ0NDU3OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/335,https://api.github.com/repos/apache/incubator-stormcrawler/issues/335,incubator-stormcrawler,178176554,335,DefaultScheduler ignores settings,JeffBolle,18576812,Jeffrey Bolle,,CLOSED,2016-09-20T20:50:01Z,2016-09-27T13:52:33Z,"I believe the recent commit (a2e47204cb2fd7c089cac7764d803a6013b867a9) to DefaultScheduler introduced a bug where the scheduler now does not set different times for the different status values. 

line 121:
`cal.add(Calendar.MINUTE, checkMetadata(metadata));`

should be:
`cal.add(Calendar.MINUTE, minutesIncrement);`

since all of the calls to cal.add(...) were moved from the case statement and consolidated. However, the final cal.add statement was simply copied from the previous FETCH case and the new variable, minutesIncrement was never used, except for the -1 check.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/335/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/335,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0ODQzNTc0NQ==,incubator-stormcrawler,248435745,335,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-09-20T21:11:41Z,2016-09-20T21:11:41Z,"Thanks @JeffBolle, much appreciated. I might release a patch version in a couple of days.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0ODQzNTc0NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/335,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0ODU1NjAzMw==,incubator-stormcrawler,248556033,335,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-09-21T09:15:25Z,2016-09-21T09:15:25Z," @JeffBolle great to see that you are using SC BTW. Any chance we could add your company to the list of users?  
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0ODU1NjAzMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/335,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0OTg2NjQ2NA==,incubator-stormcrawler,249866464,335,NA,JeffBolle,18576812,Jeffrey Bolle,,NA,2016-09-27T13:35:33Z,2016-09-27T13:35:33Z,"@jnioche Sorry for the delay. We are still in the proof of concept phase and not ready to publicly support quite yet.  I'm sure you understand.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0OTg2NjQ2NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/335,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0OTg3MTA4Mg==,incubator-stormcrawler,249871082,335,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-09-27T13:52:33Z,2016-09-27T13:52:33Z,"@JeffBolle no probs. Would be interested in your feedback on SC once your initial experiments are done : what you liked or not? why it worked for you or not? Thanks
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0OTg3MTA4Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/337,https://api.github.com/repos/apache/incubator-stormcrawler/issues/337,incubator-stormcrawler,178546234,337,ES error when parsing never refetch date,sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2016-09-22T08:04:00Z,2016-09-22T12:04:15Z,"Setting `fetchInterval.default: -1` to indicate that a page should never be refetched (see #331) causes an error in Elasticsearch:

```
[2016-09-21 13:51:45,354][DEBUG]... failed to execute bulk item (index) index {[status][status][...,""nextFetchDate"":""292278994-08-17T07:12:55.807Z""}]}
MapperParsingException[failed to parse [nextFetchDate]]; nested: IllegalFieldValueException[Cannot parse ""292278994-08-17T07:12:55.807Z"": Value 292278994 for 
year must be in the range [-292275054,292278993]];
        at org.elasticsearch.index.mapper.FieldMapper.parse(FieldMapper.java:329)
...
Caused by: org.joda.time.IllegalFieldValueException: Cannot parse ""292278994-08-17T07:12:55.807Z"": Value 292278994 for year must be in the range [-292275054,2
92278993]
        at org.joda.time.field.FieldUtils.verifyValueBounds(FieldUtils.java:234)
        at org.joda.time.chrono.BasicYearDateTimeField.set(BasicYearDateTimeField.java:83)
        at org.joda.time.format.DateTimeParserBucket$SavedField.set(DateTimeParserBucket.java:568)
        at org.joda.time.format.DateTimeParserBucket.computeMillis(DateTimeParserBucket.java:447)
        at org.joda.time.format.DateTimeParserBucket.doParseMillis(DateTimeParserBucket.java:182)
        at org.joda.time.format.DateTimeFormatter.parseMillis(DateTimeFormatter.java:780)
        at org.elasticsearch.index.mapper.core.DateFieldMapper$DateFieldType.parseStringValue(DateFieldMapper.java:362)
```

The error is caused by an overflow with timezones and `new Date(Long.MAX_VALUE)`, see https://github.com/JodaOrg/joda-time/commit/d7774f13ad2dc7cf7295bb8376c21bbf5c662fc4.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/337/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/337,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0ODg0NTk3Mg==,incubator-stormcrawler,248845972,337,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-09-22T08:51:08Z,2016-09-22T08:51:08Z,"We could adopt another arbitrary value instead of Long.MAX_VALUE. I thought initially about using epoch but that required modifying all the spouts. Also using such a large value might have an impact on the storage in ES. Any suggestions? 100 years from now?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0ODg0NTk3Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/337,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0ODg1MjI1MA==,incubator-stormcrawler,248852250,337,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2016-09-22T09:23:22Z,2016-09-22T09:23:22Z,"I've tested successfully

```
public static final Date NEVER = new Date(
            Long.MAX_VALUE - 1000L * 60 * 60 * 24 * 365 * 2);
```

(two years before to be sure that the year does not overflow). Works, but a constant date far in the future is fine as well. Should be clear at a first glance that it means never, e.g. 2099-12-31 and it should be a constant to save storage space and make it easier to search for never-refetch items.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0ODg1MjI1MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/340,https://api.github.com/repos/apache/incubator-stormcrawler/issues/340,incubator-stormcrawler,178914095,340,Delay in updates to status index,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-09-23T16:01:04Z,2016-10-10T09:44:11Z,"Sebastian observed that his WARC files contained between 10-15% duplicates when crawling with ES. The most likely explanation is that there is a delay between the moment where an update is committed to the ES index and reflected in the search and when the corresponding tuple is acked (which happens a lot sooner). This issue is more likely on small crawls where the diversity of URLs is low.

One way around it is to set `es.status.min.delay.queries` to a larger value than the default 2 secs i.e. the minimal amount of time allowed between two queries to ES. By setting it to 60 secs, Seb saw a drop to  0.5-1% duplicates. This means that it can take more than a minute between the moment a tuple is acked and when the update is reflected in the search results.

Idea : we could remove the tuples from the beingProcessed hash after some additional time, this way we wouldn't refetch the same URL too soon. The various ES spouts have an overlap in code, we could create an abstract class and share the functionality there.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/340/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/340,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0OTI1Mzg1MA==,incubator-stormcrawler,249253850,340,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2016-09-23T17:30:47Z,2016-09-23T17:30:47Z,"The URLs fetched twice have in common that they are fetched shortly before ES is queried for new URLs:

```
...
2016-09-22 11:37:24.751 c.d.s.e.p.StatusUpdaterBolt [INFO] Bulk response 1, waitAck 0, acked 1
2016-09-22 11:37:25.128 c.d.s.b.FetcherBolt [INFO] [Fetcher #5] Fetched https://www.theguardian.com/football/2016/sep/21/swansea-city-manchester-city-efl-cup-match-report with status 200 in msec 32
2016-09-22 11:37:25.520 c.d.s.b.FetcherBolt [INFO] [Fetcher #5] Fetched http://www.elwatan.com/hebdo/arts-et-lettres/parler-et-lire-02-07-2016-324272_159.php with status 200 in msec 210
2016-09-22 11:37:25.658 c.d.s.e.p.StatusUpdaterBolt [INFO] Bulk response 1, waitAck 0, acked 1
2016-09-22 11:37:25.892 c.d.s.e.p.StatusUpdaterBolt [INFO] Bulk response 1, waitAck 0, acked 1
2016-09-22 11:37:25.972 c.d.s.e.p.AggregationSpout [INFO] [spout #1]  Populating buffer with nextFetchDate <= 2016-09-22T11:37:25.972+0000
2016-09-22 11:37:25.972 c.d.s.e.p.AggregationSpout [INFO] [spout #6]  Populating buffer with nextFetchDate <= 2016-09-22T11:37:25.972+0000
2016-09-22 11:37:25.977 c.d.s.e.p.AggregationSpout [INFO] [spout #1]  ES query returned 0 hits from 0 buckets in 4 msec with 0 already being processed
2016-09-22 11:37:25.982 c.d.s.e.p.AggregationSpout [INFO] [spout #1]  Not enough time elapsed since 2016-09-22T11:37:25.972+0000 - sleeping for 59990
2016-09-22 11:37:25.982 c.d.s.e.p.AggregationSpout [INFO] [spout #3]  Populating buffer with nextFetchDate <= 2016-09-22T11:37:25.982+0000
2016-09-22 11:37:25.984 c.d.s.e.p.AggregationSpout [INFO] [spout #7]  Populating buffer with nextFetchDate <= 2016-09-22T11:37:25.984+0000
2016-09-22 11:37:25.985 c.d.s.e.p.AggregationSpout [INFO] [spout #8]  Populating buffer with nextFetchDate <= 2016-09-22T11:37:25.985+0000
2016-09-22 11:37:25.985 c.d.s.e.p.AggregationSpout [INFO] [spout #6]  ES query returned 90 hits from 1 buckets in 10 msec with 41 already being processed
2016-09-22 11:37:25.987 c.d.s.e.p.AggregationSpout [INFO] [spout #7]  ES query returned 0 hits from 0 buckets in 2 msec with 0 already being processed
...
2016-09-22 11:38:34.652 c.d.s.b.FetcherBolt [INFO] [Fetcher #5] Fetched https://www.theguardian.com/football/2016/sep/21/swansea-city-manchester-city-efl-cup-match-report with status 200 in msec 46
...
2016-09-22 11:39:04.788 c.d.s.b.FetcherBolt [INFO] [Fetcher #5] Fetched http://www.elwatan.com/hebdo/arts-et-lettres/parler-et-lire-02-07-2016-324272_159.php with status 200 in msec 201
...
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0OTI1Mzg1MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/340,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0OTMwMjI2OQ==,incubator-stormcrawler,249302269,340,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-09-23T21:05:52Z,2016-09-23T21:05:52Z,"Thanks @sebastian-nagel, this explains why the min.delay.queries param does not work for all URLs. 

> This means that it can take more than a minute between the moment a tuple is acked and when the update is reflected in the search results.

that was actually incorrect (and reassuring)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0OTMwMjI2OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/340,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0OTMwNjk5OA==,incubator-stormcrawler,249306998,340,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2016-09-23T21:29:10Z,2016-09-23T21:29:10Z,"Couldn't it be that the document from El Watan is fetched at 11:37:25.520, acked at 11:37:25.892, and 80 ms later at 11:37:25.972 spout 6 asks for new URLs and gets 90 back at 11:37:25.985. Just one possibility, and 80ms is quite short. Once the URL is queued in Fetcher, it will be fetched again, right? But this may happen later. Attached the full log: [worker.log.zip](https://github.com/DigitalPebble/storm-crawler/files/490701/worker.log.zip)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0OTMwNjk5OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/340,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0OTM1MzE4NA==,incubator-stormcrawler,249353184,340,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-09-24T08:36:02Z,2016-09-24T08:36:02Z,"yes, we are saying the same thing. The min.delay.queries param doesn't help with URLs at the end of the buffer as the time is counted since the previous request to ES was completed. 

> Once the URL is queued in Fetcher, it will be fetched again, right?

yes, once it's in, it's in! the same applies to URLs that sit in the Fetcher internal queues for too long and get failed() because of a timeout. The spout releases them and chances are that they get returned again by the ES query and go straight back to the Fetcher queue.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0OTM1MzE4NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/340,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0OTU4MDE4OA==,incubator-stormcrawler,249580188,340,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2016-09-26T14:10:13Z,2016-09-26T14:10:13Z,"First patch which keeps the items longer to avoid duplicates
- by now only AggregationSpout is changed
- needs testing at scale
- bundled shared methods and variables in AbstractElasticSearchSpout
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0OTU4MDE4OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/340,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0OTY5Nzc0Nw==,incubator-stormcrawler,249697747,340,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2016-09-26T21:07:10Z,2016-09-26T21:07:10Z,"... and this patch causes the worker to fail sometimes while placing items in the deletion queue/cache:

```
2016-09-26 16:45:37.765 o.a.s.util [ERROR] Async loop died!
java.lang.AssertionError
        at com.google.common.cache.LocalCache$Segment.evictEntries(LocalCache.java:2670) ~[stormjar.jar:?]
        at com.google.common.cache.LocalCache$Segment.put(LocalCache.java:2887) ~[stormjar.jar:?]
        at com.google.common.cache.LocalCache.put(LocalCache.java:4149) ~[stormjar.jar:?]
        at com.google.common.cache.LocalCache$LocalManualCache.put(LocalCache.java:4754) ~[stormjar.jar:?]
        at com.digitalpebble.stormcrawler.elasticsearch.persistence.AbstractElasticSearchSpout$InProcessMap.remove(AbstractElasticSearchSpout.java:84) ~[stormjar.jar:?]
        at com.digitalpebble.stormcrawler.elasticsearch.persistence.AggregationSpout.ack(AggregationSpout.java:398) ~[stormjar.jar:?]
        at org.apache.storm.daemon.executor$ack_spout_msg.invoke(executor.clj:445) ~[storm-core-1.0.1.jar:1.0.1]
...
2016-09-26 16:44:41.827 o.a.s.util [ERROR] Halting process: (""Worker died"")
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI0OTY5Nzc0Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/340,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1MTY0NDQ2NQ==,incubator-stormcrawler,251644465,340,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-10-05T11:00:38Z,2016-10-05T11:00:38Z,"Let's first put things in an abstract class (#347) then look at this delay cache business
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1MTY0NDQ2NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/341,https://api.github.com/repos/apache/incubator-stormcrawler/issues/341,incubator-stormcrawler,179220630,341,Remove StatusStreamBolt,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-09-26T12:55:14Z,2016-09-29T12:41:25Z,"Deprecated and replaced by the **com.digitalpebble.stormcrawler.indexing.DummyIndexer**

Need to update [https://github.com/DigitalPebble/storm-crawler/wiki/statusStream] and SQL crawl topology which uses it.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/341/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/343,https://api.github.com/repos/apache/incubator-stormcrawler/issues/343,incubator-stormcrawler,180012491,343,Apply crawl delay after fetching robots.txt,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-09-29T10:34:32Z,2020-07-15T16:25:19Z,"We currently proceed to fetching a URL straight after getting the robots.txt without waiting for the crawl delay which might have been set by it or our own default value. To do that we'd need to know whether the robots rules came from the cache or a http request. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/343/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/343,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NzUyMDk5NA==,incubator-stormcrawler,257520994,343,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-11-01T09:18:04Z,2016-11-01T09:18:04Z,"Not worth bothering I think. This happens only once and then the robots is cached
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NzUyMDk5NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/343,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NDY5NTY1NA==,incubator-stormcrawler,284695654,343,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-07T11:25:54Z,2017-03-07T11:25:54Z,Knowing whether a robots comes from the cache would also help generate more accurate metrics about the # of requests sent.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NDY5NTY1NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/343,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1ODg2MzU4Mg==,incubator-stormcrawler,658863582,343,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-07-15T16:25:19Z,2020-07-15T16:25:19Z,"a bit tricky to do with the FetcherBolt as the URL would get acked even if it was reinjected into the queue. Easier to do with the SimpleFetcherBolt but again, not sure it's worth the trouble especially since #405 is not an issue anymore

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1ODg2MzU4Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/344,https://api.github.com/repos/apache/incubator-stormcrawler/issues/344,incubator-stormcrawler,180038511,344,Fix links to code in Wiki,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-09-29T12:42:38Z,2016-10-03T15:26:38Z,"Since we changed the packages to stormcrawler, all links to storm/crawler should be rewritten
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/344/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/344,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1MDk3NzM3Mw==,incubator-stormcrawler,250977373,344,NA,valencik,5440389,Andrew Valencik,,NA,2016-10-02T15:37:07Z,2016-10-02T15:37:07Z,"I was going to do this myself as a small thank you, but it appears GitHub doesn't support pull requests on Wikis.
You can however clone the wiki, edit locally, and push the changes.
So the following should work (tested locally on Mac OS X):

```
git clone https://github.com/DigitalPebble/storm-crawler.wiki.git
cd storm-crawler.wiki
sed -i '' 's:digitalpebble/storm/crawler:digitalpebble/storm-crawler:' *.md
```

There are 36 instances of `storm/crawler` that should change.
However this will also add newlines to the ending of files without them, so you'll end up with more than 36 line changes.

Thanks!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1MDk3NzM3Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/344,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1MTEzNzQ1Mw==,incubator-stormcrawler,251137453,344,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-10-03T15:26:38Z,2016-10-03T15:26:38Z,"Thanks @valencik 

I had to use 
`sed -i 's:digitalpebble/storm/crawler/:digitalpebble/stormcrawler/:' *.md` without hyphen and do a manual fix in one of the files, but this seems to have done the trick.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1MTEzNzQ1Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/345,https://api.github.com/repos/apache/incubator-stormcrawler/issues/345,incubator-stormcrawler,180832261,345,Metadata keys with multiple values not indexed correctly in ES,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-10-04T08:24:55Z,2016-10-04T09:33:38Z,"When a metadata entry has multiple values, only the last value gets indexed in ES, and not the whole set.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/345/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/346,https://api.github.com/repos/apache/incubator-stormcrawler/issues/346,incubator-stormcrawler,180835170,346,JSoupParser needs to handle exceptions from mimetype ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-10-04T08:39:55Z,2016-10-04T09:36:19Z,"instead of just propagating them as we do - which crashes the topo over and over.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/346/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/347,https://api.github.com/repos/apache/incubator-stormcrawler/issues/347,incubator-stormcrawler,181123180,347,Add AbstractElasticSearchSpout,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-10-05T11:00:07Z,2016-10-06T12:58:06Z,"We currently have 3 different types of Spouts for Elasticsearch - all with their advantages and weaknesses. These 3 classes have an awful lot of code in common and also at least one common problem, as pointed out in #340. It would be more elegant to have an AbstractClass to simplify things. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/347/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/347,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1MTY1MjMyOQ==,incubator-stormcrawler,251652329,347,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-10-05T11:46:39Z,2016-10-05T11:46:39Z,"Actually SamplerAggregationSpout extends AggregationSpout, so there is no need for it to extend the abstract class directly 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1MTY1MjMyOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/350,https://api.github.com/repos/apache/incubator-stormcrawler/issues/350,incubator-stormcrawler,181433703,350,Handle redirections via meta tag,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-10-06T14:38:56Z,2016-10-31T11:25:27Z,"We currently don't handle redirs in html, a page such as the one below gets treated as fetched and gets indexed with an empty content, outlinks do not get discovered

```
 <html>    
  <head>      
    <meta http-equiv=""refresh"" content=""0;URL=http://www.apollocolors.com/site"" />    
  </head>    
</html>     
```

at the very least we should treat the link as discovered but ideally the main URL should get REDIRECTIOn
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/350/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/350,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NzI2OTUzNA==,incubator-stormcrawler,257269534,350,NA,prokopidis,9032538,Prokopis Prokopidis,prokopis@ilsp.gr,NA,2016-10-31T11:20:49Z,2016-10-31T11:20:49Z,"I think that a content attribute with one or more spaces between `;` and `URL` like `content=""0; URL=http://www.apollocolors.com/site""` is not handled by RefreshTag. Perhaps the class could use a pattern match like

```
    private static XPathExpression expression;
    static Matcher matcher = Pattern.compile(""^.*;\\s*URL=(.+)$"", Pattern.CASE_INSENSITIVE).matcher("""");
...
        if (StringUtils.isBlank(value))
            return null;
        // 0;URL=http://www.apollocolors.com/site
        if (matcher.reset(value).matches()) {
            return matcher.group(1);
        }
...
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NzI2OTUzNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/350,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NzI3MDMyNw==,incubator-stormcrawler,257270327,350,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-10-31T11:25:27Z,2016-10-31T11:25:27Z,"thanks @prokopidis. Good point, would you mind opening a PR for this with a test?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NzI3MDMyNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/351,https://api.github.com/repos/apache/incubator-stormcrawler/issues/351,incubator-stormcrawler,181636034,351,Status index - fields stored unecessarily,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-10-07T10:34:43Z,2016-10-07T12:16:32Z,"we store the source, so it should not be necessary to store individual fields on top of that
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/351/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/352,https://api.github.com/repos/apache/incubator-stormcrawler/issues/352,incubator-stormcrawler,181983659,352,URLs with \ should be URLencoded,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-10-10T10:39:43Z,2016-10-10T10:43:45Z,"Some browsers turn them into / but the correct way would be to URLEncode them, e.g.

""http://www.voltaix.com/\\SDS\\Silicon\\Trisilane\\Trisilane_SI050_USENG.pdf""
=>
""http://www.voltaix.com/%5CSDS%5CSilicon%5CTrisilane%5CTrisilane_SI050_USENG.pdf""

Currently these URLs get filtered as they are not valid URIs
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/352/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/353,https://api.github.com/repos/apache/incubator-stormcrawler/issues/353,incubator-stormcrawler,181999812,353,Add super class for bolts using the status stream ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-10-10T12:13:10Z,2016-10-14T13:36:20Z,"The fetcher bolt implementations and the parsers generate redirections and / or outlinks. All have in common that they can define URL filters, handle redirections as well as generate the same sort of output. We could have an abstract class to do all this 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/353/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/354,https://api.github.com/repos/apache/incubator-stormcrawler/issues/354,incubator-stormcrawler,182289075,354,Generate MD5 signature ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-10-11T15:03:36Z,2016-10-24T13:22:26Z,"Could be done as a ParseFilter and could be used to detect duplicates in an external process.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/354/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/354,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1Mjk0Nzc4Mw==,incubator-stormcrawler,252947783,354,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-10-11T15:15:41Z,2016-10-11T15:15:41Z,"The signature could be done on the binary content or the extracted text
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1Mjk0Nzc4Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/354,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1Mjk0OTU1Mg==,incubator-stormcrawler,252949552,354,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-10-11T15:21:19Z,2016-10-11T15:21:19Z,"as a starting point we could do the same as [Nutch](https://github.com/apache/nutch/search?utf8=%E2%9C%93&q=%22extends+Signature%22)

```
    byte[] data = content.getContent();
    if (data == null)
      data = content.getUrl().getBytes();
    return MD5Hash.digest(data).getDigest();
```

```
public class TextMD5Signature extends Signature {

  Signature fallback = new MD5Signature();

  public byte[] calculate(Content content, Parse parse) {
    String text = parse.getText();

    if (text == null || text.length() == 0) {
      return fallback.calculate(content, parse);
    }

    return MD5Hash.digest(text).getDigest();
  }
}
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1Mjk0OTU1Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/357,https://api.github.com/repos/apache/incubator-stormcrawler/issues/357,incubator-stormcrawler,182561898,357,Combine JSoupParser with Tika,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-10-12T15:47:55Z,2016-10-12T15:56:07Z,"The DOM generated by Tika is not as good as the one coming from JSoup (Tika has that annoying habit of filtering things). We can't simply connect the Tika bolt to the Jsoup one on the standard stream as the docs would be reparsed. We could check that the text is empty in the Tika bolt however since the parsing of richer formats like PDF or DOC takes longer than the HTML with JSoup, we'd end up with a nice traffic jam in the Tika bolt whereas having a separate bolt to direct docs without text to Tika in a separate stream would keep optimal performance.

Assuming that `jsoup.treat.non.html.as.error: false`

We could use that new bolt as follows 

```
      builder.setBolt(""jsoup"", new JSoupParserBolt())
              .localOrShuffleGrouping(""sitemap"");
       builder.setBolt(""shunt"", new RedirectionBolt())
              .localOrShuffleGrouping(""jsoup"");
       builder.setBolt(""tika"", new ParserBolt())
              .localOrShuffleGrouping(""shunt"", ""tika"");
       builder.setBolt(""indexer"", new IndexingBolt(), numWorkers)
              .localOrShuffleGrouping(""shunt"").localOrShuffleGrouping(""tika"");
```

This way HTML docs would go straight to the indexing without waiting in the queues for the Tika bolt.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/357/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/358,https://api.github.com/repos/apache/incubator-stormcrawler/issues/358,incubator-stormcrawler,182581841,358,Tika parser may not be parsing embedded documents,tballison,6739646,Tim Allison,tallison@apache.org,CLOSED,2016-10-12T17:12:44Z,2016-10-13T13:16:35Z,"If calling Tika's parse() with 4 parameters (using the ParseContext), you need to add a Parser.class to the ParseContext to handle embedded documents.

See [TIKA-2096](https://issues.apache.org/jira/browse/TIKA-2096) for a proposal to fix our API in Tika 2.0, and for a list of other projects (including Tika!) that fell victim to this.

I'd open a PR, but I can't quickly see how to test Tika.  I'd recommend grabbing our [test_recursive_embedded.docx](https://git-wip-us.apache.org/repos/asf?p=tika.git;a=blob_plain;f=tika-server/src/test/resources/test_recursive_embedded.docx;hb=HEAD).
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/358/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/358,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1MzUwMzA4Nw==,incubator-stormcrawler,253503087,358,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-10-13T12:47:42Z,2016-10-13T12:47:42Z,"Thanks @tballison, I've implemented your suggestion and created a test environment for Tika, which will be useful for other things as well.

Just to check that I understand it properly : when dealing with embedded docs, is there a way to separate each individual subdoc or does it all get lumped up in a single object? StormCrawler can generate discrete subdocuments from an original one so we could use that.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1MzUwMzA4Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/358,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1MzUwOTk3NA==,incubator-stormcrawler,253509974,358,NA,tballison,6739646,Tim Allison,tallison@apache.org,NA,2016-10-13T13:16:35Z,2016-10-13T13:16:35Z,"Well, now that you mention it, :), see https://github.com/DigitalPebble/storm-crawler/issues/361.  Let me know if you have any questions.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1MzUwOTk3NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/361,https://api.github.com/repos/apache/incubator-stormcrawler/issues/361,incubator-stormcrawler,182786525,361,Allow indexing of embedded documents/attachments as individual docs,tballison,6739646,Tim Allison,tallison@apache.org,OPEN,2016-10-13T13:16:08Z,2016-10-13T13:16:08Z,"Tika's legacy behavior was to concatenate the content of embedded documents into one handler and ignore metadata from embedded documents.  This was probably driven by the desire to allow Tika to handle reads and writes in a streaming fashion.

If you're willing to forego streaming and are willing to store the extracted content in memory, you might consider Jukka Zitting's and Nick Burch's ""RecursiveParserWrapper"" which returns a list of Metadata objects for each input file.  The first Metadata object in the list represents the container document and then the rest represent each embedded document.  The ""text"" for each document/embedded document is stored in each metadata object by the RecursiveParserWrapper.TIKA_CONTENT key.

You can see the output in Json format via tika-app's -J command or the /rmeta endpoint in tika-server.

See recursiveParserWrapperExample() [in this example](https://git-wip-us.apache.org/repos/asf?p=tika.git;a=blob;f=tika-example/src/main/java/org/apache/tika/example/ParsingExample.java;h=5b8a9f36cd2e1bce9bc1e4443fb6e5fd23bb9302;hb=1b72a3863b8eeb5f4f5d290e5f02c7d072b1cd9b).  You can specify whether you want the content as text, HTML or XHTML via the BasicContentHandlerFactory.HANDLER_TYPE.

This is critical for maintaining metadata from embedded objects.  Imagine, as one use case, you have a zip of jpegs with lat/longs, this will allow you to index each individually.

See [SOLR-7229](https://issues.apache.org/jira/browse/SOLR-7229) for work to integrate this into Solr's DIH...I haven't gotten around to submitting a PR for that. :(
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/361/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/363,https://api.github.com/repos/apache/incubator-stormcrawler/issues/363,incubator-stormcrawler,183390166,363,URL Normalisation - remove parameters where the value is a 32-bit hash ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-10-17T11:22:48Z,2016-10-18T12:37:50Z,"a regex like '[a-fA-F\d]{32}' should do the trick. This would be useful for getting rid of session IDs, timestamps etc...

e.g.

[http://www.florida-chemical.com/Diacetone-Alcohol-DAA-99.html?xid_0b629=12854b827878df26423d933a5baf86d5] 

would be turned into 

[http://www.florida-chemical.com/Diacetone-Alcohol-DAA-99.html] 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/363/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/364,https://api.github.com/repos/apache/incubator-stormcrawler/issues/364,incubator-stormcrawler,183460891,364,Language ID filter,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-10-17T16:15:11Z,2016-11-04T11:52:06Z,"It would be useful to have a language identification module running as a ParseFilter. Could use the one in Tika as a starting point.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/364/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/364,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NDQ5NDcwNw==,incubator-stormcrawler,254494707,364,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-10-18T12:40:14Z,2016-10-18T12:40:14Z,"Tika now uses [https://github.com/optimaize/language-detector], we might as well use that directly. The dependency is 1.9MB in size. Should it be in the main repo though? 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NDQ5NDcwNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/364,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NDg3ODQwNA==,incubator-stormcrawler,254878404,364,NA,kkrugler,66217,Ken Krugler,ken@transpac.com,NA,2016-10-19T17:11:04Z,2016-10-19T17:11:04Z,"Side note - [Yalder](https://github.com/kkrugler/yalder) is another option that (in Tika 2.0) will likely be the default language detector (faster, better accuracy, more languages). But I've stalled out on getting a real release cut, so not ready for prime time yet.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NDg3ODQwNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/364,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NDk0NzI2Ng==,incubator-stormcrawler,254947266,364,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-10-19T21:32:43Z,2016-10-19T21:32:43Z,"Thanks @kkrugler, will keep an eye on it.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NDk0NzI2Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/366,https://api.github.com/repos/apache/incubator-stormcrawler/issues/366,incubator-stormcrawler,183975319,366,Filtering : treat path parameters as query parameters,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-10-19T14:19:23Z,2016-10-19T21:37:52Z,"> Each path segment may include a sequence of parameters, indicated by the semicolon "";"" character.

such as 

[http://www.maroongroupllc.com/maroon/login/auth;jsessionid=8DBFC2FEDBD740BBC8B4D1A504A6DE7F]

Although quite rare, it should be possible to treat such path parameters as query parameters and filter them accordingly.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/366/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/366,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NDg3ODA0OQ==,incubator-stormcrawler,254878049,366,NA,kkrugler,66217,Ken Krugler,ken@transpac.com,NA,2016-10-19T17:09:37Z,2016-10-19T17:09:37Z,"Feels like URL normalization should make its way into crawler-commons. This is a good example of all the ""interesting"" edge cases that we don't want everyone to have to independently find/support in every project.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NDg3ODA0OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/366,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NDk0Nzc2OQ==,incubator-stormcrawler,254947769,366,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-10-19T21:34:44Z,2016-10-19T21:34:44Z,"I completely agree @kkrugler. The next release of CC will contain [https://github.com/crawler-commons/crawler-commons/blob/master/src/main/java/crawlercommons/filters/basic/BasicURLNormalizer.java] which is a good start but we should improve it with cases like this one.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NDk0Nzc2OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/367,https://api.github.com/repos/apache/incubator-stormcrawler/issues/367,incubator-stormcrawler,184436072,367,fieldsGrouping for input to StatusUpdaterBolt,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-10-21T09:10:09Z,2016-10-21T09:11:13Z,"If multiple instances of status updater bolt are used, _localorshufflegrouping_ is a poor choice as the internal cache of the AbstractStatusUpdaterBolt would not be hit consistently for DISCOVERED URLs. Instead we should group by the URL field. 

The example topology generated by the archetype uses a single instance of the status updater bolt but we will group by URL for educational purposes and also so that users are on an optimal setup when using the archetype as a starting point.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/367/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/368,https://api.github.com/repos/apache/incubator-stormcrawler/issues/368,incubator-stormcrawler,184807539,368,BasicURLFilter to remove URLs based on path repetition and max length,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-10-24T10:48:45Z,2016-10-24T11:30:25Z,"The path repetition is very useful in most crawls there inevitably are sites that generate recursive URLs and rapidly take over everything else. We had a regex based filter inherited from Nutch but it is very slow. Instead we can put that functionality in a new BasicURLFilter which could also remove URLs based on their length. 

These filters are meant to be super fast and so should be used early in the filtering chain.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/368/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/369,https://api.github.com/repos/apache/incubator-stormcrawler/issues/369,incubator-stormcrawler,185052262,369,"[ElasticSearch] ""Result window is too large""",prokopidis,9032538,Prokopis Prokopidis,prokopis@ilsp.gr,CLOSED,2016-10-25T08:35:55Z,2016-11-01T16:48:06Z,"Hi and thanks for SC. We have the following issue while running the elasticsearch module. Things work as expected in the beginning but after a while and with around 10800/80 discovered/fetched urls, the process dies with a ""Result window is too large"" message:

```
$ cd ~/src/storm-crawler/external/elasticsearch
$ cp ../../core/src/main/resources/crawler-default.yaml ./crawl-conf.yaml
$ mkdir -p src/main/resources
$ cp ../../archetype/src/main/resources/archetype-resources/src/main/resources/urlfilters.json src/main/resources/
$ grep hostURL -i -A4  src/main/resources/urlfilters.json 
      ""class"": ""com.digitalpebble.stormcrawler.filtering.host.HostURLFilter"",
      ""name"": ""HostURLFilter"",
      ""params"": {
        ""ignoreOutsideHost"": false,
        ""ignoreOutsideDomain"": true
      }
$ echo ""https://en.wikipedia.org/wiki/Main_Page"" > seeds.txt
$ ./ES_IndexInit.sh 
$ mvn clean install -P bigjar
$ storm jar target/storm-crawler-elasticsearch-*-SNAPSHOT.jar com.digitalpebble.stormcrawler.elasticsearch.ESSeedInjector . seeds.txt -local -conf es-conf.yaml -ttl 60
...
67995 [SessionTracker] INFO  o.a.s.s.o.a.z.s.SessionTrackerImpl - SessionTrackerImpl exited loop!
$ storm jar target/storm-crawler-elasticsearch-*-SNAPSHOT.jar com.digitalpebble.stormcrawler.elasticsearch.ESCrawlTopology -local -conf es-conf.yaml -conf crawl-conf.yaml
...
40816 [Thread-26-spout-executor[18 18]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2016-10-25T11:09:28.192+0300
40836 [Thread-26-spout-executor[18 18]] ERROR o.a.s.util - Async loop died!
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
        at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:206) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:152) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:46) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:872) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:850) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.transport.TransportService$4.onFailure(TransportService.java:387) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[?:1.8.0_91]
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[?:1.8.0_91]
        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_91]
Caused by: org.elasticsearch.search.query.QueryPhaseExecutionException: Result window is too large, from + size must be less than or equal to: [10000] but was [10100]. See the scroll api for a more efficient way to request large data sets. This limit can be set by changing the [index.max_result_window] index level parameter.
        at org.elasticsearch.search.internal.DefaultSearchContext.preProcess(DefaultSearchContext.java:212) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.search.query.QueryPhase.preProcess(QueryPhase.java:103) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.search.SearchService.createContext(SearchService.java:689) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:633) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.search.SearchService.executeDfsPhase(SearchService.java:264) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.search.action.SearchServiceTransportAction$SearchDfsTransportHandler.messageReceived(SearchServiceTransportAction.java:360) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.search.action.SearchServiceTransportAction$SearchDfsTransportHandler.messageReceived(SearchServiceTransportAction.java:357) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:77) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:376) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        ... 3 more
40850 [Thread-26-spout-executor[18 18]] ERROR o.a.s.d.executor - 
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
        at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:206) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:152) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:46) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:872) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:850) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.transport.TransportService$4.onFailure(TransportService.java:387) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[?:1.8.0_91]
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[?:1.8.0_91]
        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_91]
Caused by: org.elasticsearch.search.query.QueryPhaseExecutionException: Result window is too large, from + size must be less than or equal to: [10000] but was [10100]. See the scroll api for a more efficient way to request large data sets. This limit can be set by changing the [index.max_result_window] index level parameter.
        at org.elasticsearch.search.internal.DefaultSearchContext.preProcess(DefaultSearchContext.java:212) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.search.query.QueryPhase.preProcess(QueryPhase.java:103) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.search.SearchService.createContext(SearchService.java:689) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:633) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.search.SearchService.executeDfsPhase(SearchService.java:264) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.search.action.SearchServiceTransportAction$SearchDfsTransportHandler.messageReceived(SearchServiceTransportAction.java:360) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.search.action.SearchServiceTransportAction$SearchDfsTransportHandler.messageReceived(SearchServiceTransportAction.java:357) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:77) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:376) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[storm-crawler-elasticsearch-1.2-SNAPSHOT.jar:?]
        ... 3 more
40852 [Thread-30-fetch-executor[9 9]] WARN  c.d.s.p.h.HttpProtocol - HTTP content trimmed to 65536
40852 [Thread-30-fetch-executor[9 9]] INFO  c.d.s.b.SimpleFetcherBolt - [Fetcher #9] Fetched https://cy.wikiquote.org/wiki/Hafan with status 200 in 125 after waiting 0
40860 [Thread-50-parse-executor[15 15]] INFO  c.d.s.b.JSoupParserBolt - Parsing : starting https://cy.wikiquote.org/wiki/Hafan
40864 [Thread-14-fetch-executor[8 8]] INFO  c.d.s.b.SimpleFetcherBolt - [Fetcher #8] Fetched https://be-x-old.wikipedia.org/wiki/%D0%93%D0%B0%D0%BB%D0%BE%D1%9E%D0%BD%D0%B0%D1%8F_%D1%81%D1%82%D0%B0%D1%80%D0%BE%D0%BD%D0%BA%D0%B0 with status 301 in 62 after waiting 0
40871 [Thread-50-parse-executor[15 15]] INFO  c.d.s.b.JSoupParserBolt - Parsed https://cy.wikiquote.org/wiki/Hafan in 9 msec
40935 [Thread-48-fetch-executor[4 4]] INFO  c.d.s.b.SimpleFetcherBolt - [Fetcher #4] Fetched https://lists.wikimedia.org/mailman/listinfo/wikipedia-l with status 200 in 246 after waiting 999
40939 [Thread-50-parse-executor[15 15]] INFO  c.d.s.b.JSoupParserBolt - Parsing : starting https://lists.wikimedia.org/mailman/listinfo/wikipedia-l
40944 [Thread-50-parse-executor[15 15]] INFO  c.d.s.b.JSoupParserBolt - Parsed https://lists.wikimedia.org/mailman/listinfo/wikipedia-l in 3 msec
41075 [Thread-26-spout-executor[18 18]] ERROR o.a.s.util - Halting process: (""Worker died"")
java.lang.RuntimeException: (""Worker died"")
        at org.apache.storm.util$exit_process_BANG_.doInvoke(util.clj:341) [storm-core-1.0.2.jar:1.0.2]
        at clojure.lang.RestFn.invoke(RestFn.java:423) [clojure-1.7.0.jar:?]
        at org.apache.storm.daemon.worker$fn__8659$fn__8660.invoke(worker.clj:761) [storm-core-1.0.2.jar:1.0.2]
        at org.apache.storm.daemon.executor$mk_executor_data$fn__7875$fn__7876.invoke(executor.clj:274) [storm-core-1.0.2.jar:1.0.2]
        at org.apache.storm.util$async_loop$fn__624.invoke(util.clj:494) [storm-core-1.0.2.jar:1.0.2]
        at clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]
        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_91]
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/369/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/369,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NTk3Mzk4NQ==,incubator-stormcrawler,255973985,369,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-10-25T08:41:56Z,2016-10-25T08:41:56Z,"Thanks @prokopidis for reporting this. You could use the AggregationSpout as an alternative but I'll have a look at this in the meantime.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NTk3Mzk4NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/369,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NTk3NzMxOQ==,incubator-stormcrawler,255977319,369,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-10-25T08:56:31Z,2016-10-25T08:56:31Z,"The param 'es.status.max.secs.date' should be set to prevent deep paging, see [https://github.com/DigitalPebble/storm-crawler/blob/master/external/elasticsearch/src/main/java/com/digitalpebble/stormcrawler/elasticsearch/persistence/ElasticSearchSpout.java#L59]. It is inactive by default but it would be a good idea to set it in es-conf.yaml so that users are more aware of it.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NTk3NzMxOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/369,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NTk3ODQwNA==,incubator-stormcrawler,255978404,369,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-10-25T09:01:08Z,2016-10-25T09:01:08Z,"@prokopidis could you please give the change I just committed a try? Thanks!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NTk3ODQwNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/369,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NTk5NTkxOA==,incubator-stormcrawler,255995918,369,NA,prokopidis,9032538,Prokopis Prokopidis,prokopis@ilsp.gr,NA,2016-10-25T10:18:28Z,2016-10-25T10:18:28Z,"The `es.status.max.secs.date: 100` is read from the conf when the spout is opened, but the same error occurs.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NTk5NTkxOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/369,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NjAwMzc0Mw==,incubator-stormcrawler,256003743,369,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-10-25T10:58:52Z,2016-10-25T10:58:52Z,"Ok, there are several issues here. The main one is that ElasticSearchSpout does not throttle the calls to ES, like the AggregationSpout(s) do. In your case it means that we quickly send far too many requests without  es.status.max.secs.date having time to kick in. I'll move the throttling from AggregationSpout to the abstract class and force ESS to use it.

The trouble in your case is that you are copying the default config values from '../../core/src/main/resources/crawler-default.yaml' - these are loaded from the jars anyway and are missing some configs that can be found in [https://github.com/DigitalPebble/storm-crawler/blob/master/archetype/src/main/resources/archetype-resources/crawler-conf.yaml] like max spout pending. The latter sets a limit to the # of URLs in process and blocks the spout. Since you are not specifying it, the spout reads constantly from ES and pushes the URLs to the topology. This is a recipe for disaster, especially since your crawl uses a single domain, the URLs will get stuck in the internal queues and in the best case time out or lead to a memory exception.

Either use the archetype and add the ES bits that are missing or build by hand but in that case don't use the default conf file. Makes sense?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NjAwMzc0Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/369,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NjAyMjc5Mw==,incubator-stormcrawler,256022793,369,NA,prokopidis,9032538,Prokopis Prokopidis,prokopis@ilsp.gr,NA,2016-10-25T12:38:11Z,2016-10-25T12:38:11Z,"Thank you @jnioche for the explanation and the solutions. Perhaps it would be helpful if the link to the archetypes conf was mentioned as a starting point in the ES module documentation.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NjAyMjc5Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/369,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NjAyNTAwMg==,incubator-stormcrawler,256025002,369,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-10-25T12:48:43Z,2016-10-25T12:48:43Z,"You are welcome @prokopidis. See #370 for a PR which adds ad delay between calls to ES in the ESSpout.

> Perhaps it would be helpful if the link to the archetypes conf was mentioned as a starting point in the ES module documentation

Could do or we could add some instructions on how to modify the files generated by a call to the archetype 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NjAyNTAwMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/369,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NzYyMDMxNg==,incubator-stormcrawler,257620316,369,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-11-01T16:48:06Z,2016-11-01T16:48:06Z,"@prokopidis see #372 for resources and instructions on using the archetype with ES
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NzYyMDMxNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/371,https://api.github.com/repos/apache/incubator-stormcrawler/issues/371,incubator-stormcrawler,186543051,371,Spouts : load results with a non-blocking call,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-11-01T14:10:26Z,2016-11-21T11:14:30Z,"We currently block the nextTuple when executing an Elasticsearch query and as such prevent ack/fails to happen. Instead, we should execute the ES query with a non-blocking call and return as soon as possible. This would possibly require the access to the buffer to be synchronized and an additional check that we are not already querying.  ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/371/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/371,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2MDMwMjQxMQ==,incubator-stormcrawler,260302411,371,NA,XciD,6586344,Adrien,,NA,2016-11-14T10:38:16Z,2016-11-14T10:38:16Z,"I've done something similar on my spouts, as you say, in order to don't block `nextTuple`, `ack`and `fail` methods

I will try to generify
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2MDMwMjQxMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/371,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2MDM2NjE2Mg==,incubator-stormcrawler,260366162,371,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-11-14T15:28:45Z,2016-11-14T15:28:45Z,"That would be great. Thanks

On 14 Nov 2016 11:38, ""XciD"" notifications@github.com wrote:

> I've done something similar on my spouts, as you say, in order to don't
> block nextTuple, ackand fail methods
> 
> I will try to generify
> 
> —
> You are receiving this because you were assigned.
> Reply to this email directly, view it on GitHub
> https://github.com/DigitalPebble/storm-crawler/issues/371#issuecomment-260302411,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AANUz7pU-_2mAVPigeaOOUHpliAaz7o2ks5q-DoZgaJpZM4KmIPs
> .
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2MDM2NjE2Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/372,https://api.github.com/repos/apache/incubator-stormcrawler/issues/372,incubator-stormcrawler,186572560,372,Add Flux files for ES,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-11-01T16:02:16Z,2016-11-01T16:47:19Z,Having Flux files would be useful e.g. to use ES with a project generated from the archetype ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/372/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/372,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NzYyMDEwOA==,incubator-stormcrawler,257620108,372,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-11-01T16:47:19Z,2016-11-01T16:47:19Z,"**NOTE** 
Need to configure metrics via config 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1NzYyMDEwOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/375,https://api.github.com/repos/apache/incubator-stormcrawler/issues/375,incubator-stormcrawler,187725148,375,JSoupParser does not dedup outlinks properly,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-11-07T14:28:27Z,2017-02-28T11:24:01Z,Needs verifying but [http://love123.blog.so-net.ne.jp/archive/c15355316-1] generates multiple instances of the same outlink as they don't get deduped **post normalisation**. This results in an unnecessary number of additions to the status index.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/375/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/376,https://api.github.com/repos/apache/incubator-stormcrawler/issues/376,incubator-stormcrawler,188237475,376,ES - settings done via configuration ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-11-09T12:36:29Z,2016-11-09T12:51:17Z,"We should be able to configure the settings for a given ES connection via the config e.g.

```yaml
  es.status.settings:
    cluster.name: ""elasticsearch""
    request.headers.X-Found-Cluster: ""blablabla""
    action.bulk.compress: ""false""
    shield.transport.ssl: ""false""
```
including the cluster name. This would be useful for connecting to a Shield-enabled cluster.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/376/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/377,https://api.github.com/repos/apache/incubator-stormcrawler/issues/377,incubator-stormcrawler,188238995,377,ES - remove Node client,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-11-09T12:44:34Z,2016-11-09T13:04:44Z,Not available in 5.x and did not work with 2.x anyway. ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/377/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/378,https://api.github.com/repos/apache/incubator-stormcrawler/issues/378,incubator-stormcrawler,188243994,378,Es - add plugin to the clients via configuration,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-11-09T13:11:20Z,2016-11-10T11:10:50Z,"e.g. to add Shield plugin

The configuration could specify the full class name of the plugin ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/378/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/379,https://api.github.com/repos/apache/incubator-stormcrawler/issues/379,incubator-stormcrawler,188458839,379,URLs of Status.REDIRECTION in metadata.depth calculation,prokopidis,9032538,Prokopis Prokopidis,prokopis@ilsp.gr,CLOSED,2016-11-10T09:29:18Z,2016-11-10T10:01:12Z,"Suppose SC is used to collect all content up to depth 1 from a site www.example.com and that this seed URL immediately leads via meta- or server-side redirection to www.example.com/en-us/. Does this mean that the latter will be the only entry with metadata.depth 1 in the status index and that ""actual"" depth 1 URLs will never be fetched? 

If yes, is there a way to change this behaviour (i.e. to skip the the redirection URL in metadata.depth calculation), maybe from the crawl configuration file?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/379/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/379,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1OTY0OTEwOA==,incubator-stormcrawler,259649108,379,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-11-10T10:01:05Z,2016-11-10T10:01:05Z,"Correct, redirections are not treated differently from outlinks, see [https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/util/MetadataTransfer.java#L162].

There is currently no way to circumvent this. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI1OTY0OTEwOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/380,https://api.github.com/repos/apache/incubator-stormcrawler/issues/380,incubator-stormcrawler,189643262,380,Add Grafana schema to display metrics stored in ES ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-11-16T09:29:33Z,2017-03-03T14:39:42Z,@XciD any chance you could share a generic schema for this?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/380/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/382,https://api.github.com/repos/apache/incubator-stormcrawler/issues/382,incubator-stormcrawler,190686247,382,bulkProcessor : set number of concurrent requests via config,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-11-21T11:12:04Z,2016-11-21T11:13:01Z,"It is currently set to 1 in the code. Instead we'll use 

```
  es.status.concurrentRequests: x
```","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/382/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/383,https://api.github.com/repos/apache/incubator-stormcrawler/issues/383,incubator-stormcrawler,190690452,383,Upgrade to SOLR 6.4.0,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-11-21T11:31:20Z,2017-02-18T12:52:14Z,"@jorgelbg is that the version you used? Any chance you could look at this one?
Thanks!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/383/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/383,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3ODk0OTE0NQ==,incubator-stormcrawler,278949145,383,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-02-10T14:04:49Z,2017-02-10T14:04:49Z,"Investigate Streaming API at the same time 

https://cwiki.apache.org/confluence/display/solr/Streaming+Expressions","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3ODk0OTE0NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/383,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4MDg0Mzc0OQ==,incubator-stormcrawler,280843749,383,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-02-18T12:52:10Z,2017-02-18T12:52:10Z,Done in #424 ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4MDg0Mzc0OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/384,https://api.github.com/repos/apache/incubator-stormcrawler/issues/384,incubator-stormcrawler,190973728,384,Allow fieldNameForRoutingKey to be outside metadata and use a different key for spouts,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-11-22T11:23:59Z,2016-11-22T12:01:04Z,It would be good not to assume that the StatusUpdater bolt will use a field to store the value used for sharding explicitly as a separate field and that this will be in the metadata object. This value could not be set at all and the spouts could use the '_routing' field instead. We should also define a separate config name for the spouts to avoid any confusion.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/384/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/385,https://api.github.com/repos/apache/incubator-stormcrawler/issues/385,incubator-stormcrawler,191065893,385,ES: use SHA256 as doc_id,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-11-22T17:03:19Z,2016-12-16T15:55:48Z,instead of the document's URL. The URL is stored as a separate field anyway. Would there be a gain in performance? There would certainly be a gain in size as all the URLs no matter how large or small would all be represented in 64 chars.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/385/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/385,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2MjUwNjg4MQ==,incubator-stormcrawler,262506881,385,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2016-11-23T13:01:51Z,2016-11-23T13:01:51Z,"Good idea. The ES document API is not easy to use with URLs as IDs because of the configurable routing (by host/domain/ip) and because reserved characters (`/?+&`) have to be escaped.
- a [URL-safe base64 encoding](https://en.wikipedia.org/wiki/Base64#URL_applications) similar to [ES autogenerated IDs](https://www.elastic.co/guide/en/elasticsearch/guide/current/index-doc.html#_autogenerating_ids) would shorten id strings by 30%
- could also think about a compound id as in [Ahad's crawler](/commoncrawl/commoncrawl-crawler/blob/master/src/org/commoncrawl/protocol/protocol.jr) (see [slides](http://www.slideshare.net/hadoopusergroup/building-a-scalable-web-crawler-with-hadoop?qid=fc300654-aa09-49d9-8292-52922f98716e&v=qf1&b=&from_search=6) page 10)","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2MjUwNjg4MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/386,https://api.github.com/repos/apache/incubator-stormcrawler/issues/386,incubator-stormcrawler,191281344,386,Custom schedule based on metadata for non-success pages,sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2016-11-23T14:14:57Z,2017-01-12T08:39:16Z,"#283 adds a custom schedule triggered by metadata for all successfully fetched pages. It is not applied to non-success fetches (redirects and errors). However, in certain cases (see commoncrawl/news-crawl#14) it's desirable to have a custom fetch schedule which is takes both metadata and status into account.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/386/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/386,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2Mjc0NDE1OQ==,incubator-stormcrawler,262744159,386,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-11-24T10:36:04Z,2016-11-24T10:36:04Z,"Good idea. We could perhaps have the status in the param name e.g.

`fetchInterval.FETCH_ERROR.isFeed=true: 10`

or change to a structured object instead which would be a tad cleaner

```
custom.fetchInterval:
       metadata.key: ""isFeed""
       metadata.value: ""true""
       status: ""FETCHED""
       value: 10       
```

@sebastian-nagel what do you think?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2Mjc0NDE1OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/386,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2Mjc1MjczNg==,incubator-stormcrawler,262752736,386,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2016-11-24T11:17:26Z,2016-11-24T11:17:26Z,"The first looks quite simple and intuitive. Of course, in the very rare case that a meta data key is ""ERROR.xyz"" it would break existing rules. The second form could be made even more extensible, e.g., to match all feeds which are not ""FETCHED"" by a single expression. But then it would resemble a boolean query of the status storage.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2Mjc1MjczNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/386,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTg2NDI4OQ==,incubator-stormcrawler,271864289,386,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-11T13:09:28Z,2017-01-11T13:09:28Z,"@sebastian-nagel please see #406 

Thanks!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTg2NDI4OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/386,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MjAwMzk3Nw==,incubator-stormcrawler,272003977,386,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2017-01-11T21:41:59Z,2017-01-11T21:41:59Z,+1 lgtm,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MjAwMzk3Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/387,https://api.github.com/repos/apache/incubator-stormcrawler/issues/387,incubator-stormcrawler,191482498,387,Upgrade to Crawler-Commons 0.7,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-11-24T10:21:45Z,2016-11-24T10:29:25Z,"https://github.com/crawler-commons/crawler-commons#24th-november-2016----crawler-commons-07-released

Contains various bugfixes and performance improvements as well as a URLFilter interface and basic normalisation implementation.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/387/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/388,https://api.github.com/repos/apache/incubator-stormcrawler/issues/388,incubator-stormcrawler,193493459,388,Harcoded limit to the max # connections allowed by protocol,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-12-05T13:14:57Z,2016-12-05T13:16:37Z,"https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/protocol/httpclient/HttpProtocol.java#L69

this can be a bottleneck when using more than 200 fetcher threads per JVM. Instead, we should set this value to be == to the number of fetching threads","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/388/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/389,https://api.github.com/repos/apache/incubator-stormcrawler/issues/389,incubator-stormcrawler,194597296,389,Generate metrics about status counts,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-12-09T13:30:59Z,2017-03-20T13:19:05Z,"We have a visualization for Kibana which gives us an instant breakdown of the number of URL per status. We could add a bespoke Bolt which would run an aggregation query every N secs to report the counts per status value, this way we'd be able to visualise the evolution of the counts over time. This bolt shouldn't need to be connected to any other one in the topology.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/389/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/389,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NDY4MzM2MA==,incubator-stormcrawler,284683360,389,NA,mattburns,1316126,Matt Burns,,NA,2017-03-07T10:31:36Z,2017-03-07T10:31:36Z,"This would be a good visualisation to have. I'd like to see how the counts of each status changed over time. The closest thing I have is the status after processing the discovered urls:

<img width=""633"" alt=""screen shot 2017-03-07 at 09 36 44"" src=""https://cloud.githubusercontent.com/assets/1316126/23650761/29feed60-031b-11e7-8ef8-c4ed6e9e3214.png"">

A bespoke bolt that polls the counts at time intervals would work, and the data would be fast to query. The downside is that it always needs to be running, but not a problem I suppose if you had it dangling off every topology that modifies the status index... but then you only want one running...

An alternative is to record a metric every time you update the status index. eg. If you inject 5 DISCOVERED statuses then you might write a metric: `metric.count.discovered: +5`. If you then fetched 3 of them, and therefore update 3 docs from DISCOVERED to FETCHED, then you would append two more metrics: `metric.count.discovered: -3` and `metric.count.fetched: +3`.
If you wanted to know the count of DISCOVERED status docs at any point in time, you would sum all the values of `metric.count.discovered` where the timestamp was <= the time you care about.

I'm not sure it's any better, in fact, it might not work at all, just throwing it out there as an alternative ;)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NDY4MzM2MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/389,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NDcyODUxOA==,incubator-stormcrawler,284728518,389,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-07T13:59:54Z,2017-03-07T13:59:54Z,"> I'd like to see how the counts of each status changed over time. 

that's exactly what this would do. Think about it as the equivalent of the status table we have in Kibana but evolving over time. The nice thing about that is that the filters in Kibana would be applied to it e.g when selecting one particular domain we could see the evolution of its status counts in isolation.

> An alternative is to record a metric every time you update the status index. eg. If you inject 5 DISCOVERED statuses then you might write a metric: metric.count.discovered: +5.

There is no guarantee that they don't already exist in ES. The DISCOVERED tuples are added to ES only if they don't exist but we don't know in the status updater whether it is the case or not

> If you then fetched 3 of them, and therefore update 3 docs from DISCOVERED to FETCHED, then you would append two more metrics: metric.count.discovered: -3 and metric.count.fetched: +3.

We don't know their previous status in the updater bolt\: they could be FETCH_ERROR and then FETCHED or RE-FETCHED etc...

> If you wanted to know the count of DISCOVERED status docs at any point in time, you would sum all the values of metric.count.discovered where the timestamp was <= the time you care about.

assuming the worker has not crashed and been restarted + you'd need to track the timestamps

> I'm not sure it's any better, in fact, it might not work at all, just throwing it out there as an alternative ;)

Thanks! We could build approximations based on your suggestions and they would work regardless of  the backend for storing the status but we might as well get the exact numbers straight from ES.

Thanks for your comments
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NDcyODUxOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/389,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NzQzMDcwMQ==,incubator-stormcrawler,287430701,389,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-17T18:10:29Z,2017-03-17T18:10:29Z,Need to check that it is working properly...,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NzQzMDcwMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/389,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4Nzc1MDY0NA==,incubator-stormcrawler,287750644,389,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-20T12:54:10Z,2017-03-20T12:54:10Z,"Needs to be connected to another bolt in order to be initialised and receive tuples. Fixed in a0b42e19a5e6cb3595f0adc15ca07952c0c7e688. 

Ideally the search should be done in a non-blocking so as to not clog the entire topology. Fixed in 29d4e88ac54f3888001221766402374d7a212117","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4Nzc1MDY0NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/391,https://api.github.com/repos/apache/incubator-stormcrawler/issues/391,incubator-stormcrawler,196085072,391,Slow charset detection ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-12-16T15:32:06Z,2016-12-16T15:54:00Z,"The charset detection can take up to 50% of the time spent in the execute() method of JSoupParserBolt. This is due to using the whole document content for the detection instead, we should use the N first bytes of the content only (N being configurable) or even set it to 0 to rely only on the value returned by the server if any.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/391/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/392,https://api.github.com/repos/apache/incubator-stormcrawler/issues/392,incubator-stormcrawler,196411782,392,[ElasticSearch] The cluster.name parameter does not work from conf file,Laurent-Hervaud,20163356,Laurent Hervaud,,CLOSED,2016-12-19T13:19:50Z,2016-12-21T11:03:29Z,"Connection with elasticsearch not working if cluster name different than elasticsearch.
The parameter cluster.name: ""myclustername"" (ex : es-stormcrawler) has no effect.
It's working only if your cluster name is elasticsearch (default)
The same for all 3 parameters (es.indexer.settings, es.metrics.settings, es.status.settings)","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/392/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/392,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2ODQ4NDI4NA==,incubator-stormcrawler,268484284,392,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-12-21T10:07:02Z,2016-12-21T10:07:02Z,"Hi @Laurent-Hervaud. 

The way the cluster name is specified has changed since 1.2; as shown in [es-conf.yaml](https://github.com/DigitalPebble/storm-crawler/blob/master/external/elasticsearch/es-conf.yaml)

```
  es.status.settings:
    cluster.name: ""blabla"" 
```

Feel free to reopen this issue if necessary.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2ODQ4NDI4NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/392,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2ODQ4NjE0NA==,incubator-stormcrawler,268486144,392,NA,Laurent-Hervaud,20163356,Laurent Hervaud,,NA,2016-12-21T10:15:51Z,2016-12-21T10:15:51Z,"I known but this parameter is not use properly. If the es cluster name different than elasticsearch, no query or index will work with ES. 
My conf :

  es.status.settings:
    cluster.name: ""es-stormcrawler""","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2ODQ4NjE0NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/392,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2ODQ4NjgxMw==,incubator-stormcrawler,268486813,392,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-12-21T10:18:35Z,2016-12-21T10:18:35Z,I just checked and it worked fine for me. Could it be the formatting e.g. no spaces before cluster.name? ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2ODQ4NjgxMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/392,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2ODQ5NDI3OQ==,incubator-stormcrawler,268494279,392,NA,Laurent-Hervaud,20163356,Laurent Hervaud,,NA,2016-12-21T10:55:15Z,2016-12-21T10:55:15Z,"It's work for me too. Sorry... 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2ODQ5NDI3OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/392,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2ODQ5NDcwMw==,incubator-stormcrawler,268494703,392,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-12-21T10:57:36Z,2016-12-21T10:57:36Z,No problem. Glad we found what the problem was,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2ODQ5NDcwMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/392,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2ODQ5NTgyNw==,incubator-stormcrawler,268495827,392,NA,Laurent-Hervaud,20163356,Laurent Hervaud,,NA,2016-12-21T11:03:29Z,2016-12-21T11:03:29Z,"Ok I found. Not working with StormCrawler Maven Archetype (version 1.2).
Resolved with 1.3 snapshot","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2ODQ5NTgyNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/393,https://api.github.com/repos/apache/incubator-stormcrawler/issues/393,incubator-stormcrawler,196727510,393,[ElasticSearch] ES 2.4.x not support for dots in field names,Laurent-Hervaud,20163356,Laurent Hervaud,,CLOSED,2016-12-20T17:08:58Z,2016-12-21T10:38:25Z,"Error in ES log : MapperParsingException[Field name [metadata.hostname] cannot contain '.']
The status index is not working with ES
Solution : modify parameter es.status.routing.fieldname in es-conf file (ex : es.status.routing.fieldname: ""metadata_hostname"")

https://www.elastic.co/guide/en/elasticsearch/reference/2.4/dots-in-names.html","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/393/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/393,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2ODQ4NDg3NA==,incubator-stormcrawler,268484874,393,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-12-21T10:10:04Z,2016-12-21T10:10:04Z,"Thanks for reporting this @Laurent-Hervaud. This is due to a recent change I made since 1.2, will fix it shortly. The solution is to normalise the value just like we do for the keys in the metadata ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2ODQ4NDg3NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/393,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2ODQ4NjU1NA==,incubator-stormcrawler,268486554,393,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-12-21T10:17:31Z,2016-12-21T10:17:31Z,@Laurent-Hervaud I've just pushed a fix for this. Could you give it a try and let me know if it fixes it? Thanks again for reporting this.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2ODQ4NjU1NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/393,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2ODQ5MTEwOA==,incubator-stormcrawler,268491108,393,NA,Laurent-Hervaud,20163356,Laurent Hervaud,,NA,2016-12-21T10:38:25Z,2016-12-21T10:38:25Z,"@jnioche Ok, I have tested and it is fixed. Thanks","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2ODQ5MTEwOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/394,https://api.github.com/repos/apache/incubator-stormcrawler/issues/394,incubator-stormcrawler,197174004,394,SimpleFetcherBolt does not handle redirections properly,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-12-22T13:25:30Z,2016-12-22T13:25:39Z,"Since the introduction of StatusEmitterBolt, SimpleFetcherBolt does not use the config handled by the superclass and as a result does not follow redirections.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/394/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/394,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2ODc5ODkwMg==,incubator-stormcrawler,268798902,394,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-12-22T13:25:39Z,2016-12-22T13:25:39Z,Fixed in [067e77f2f05694],"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2ODc5ODkwMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/395,https://api.github.com/repos/apache/incubator-stormcrawler/issues/395,incubator-stormcrawler,197520776,395,Configuration of resources,MyraBaba,17505439,,,CLOSED,2016-12-26T00:47:19Z,2016-12-27T19:33:17Z,"Hi,

We started to test stormcrawler. We are coming from the WW I (Nutch :).)

1 - is there any way to give command line paramethers such as:

maxdepth
checkValidURI  etc.  which is normally located at the resources folder. If we change it from the file and compile again ( big jar)   it is working. Is there any solution that doenst need recompiling ? 

2 - Where we can find the full parameters list  that we can use to configure all aspects of the crawler

thx","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/395/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/395,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2OTE4OTgwOA==,incubator-stormcrawler,269189808,395,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-12-26T09:23:32Z,2016-12-26T09:23:32Z,"Hi

1. I am afraid not. These values are taken from the file only and need recompiling and restarting the topology

2. See [https://github.com/DigitalPebble/storm-crawler/wiki/Configuration] and the default values [https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/resources/crawler-default.yaml]","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2OTE4OTgwOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/395,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2OTM3MTg2MA==,incubator-stormcrawler,269371860,395,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-12-27T19:31:56Z,2016-12-27T19:31:56Z,"I replied too quickly (blame Christmas) - if you look at [https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/filtering/URLFilter.java#L40] you'll see that the URL filters get the configuration - which will be overridden by any key values passed on the command line. This means that in theory the conf set in the JSON file could be overridden by the config. The trouble is that the filters do not necessarily implement it, e.g. [https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/filtering/depth/MaxDepthFilter.java].

This could be implemented of course, or you can extend a variant of the filters provided to handle that.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2OTM3MTg2MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/395,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2OTM3MjA0MQ==,incubator-stormcrawler,269372041,395,NA,MyraBaba,17505439,,,NA,2016-12-27T19:33:17Z,2016-12-27T19:33:17Z,"thanks..  will look into it and let you know.

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2OTM3MjA0MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/396,https://api.github.com/repos/apache/incubator-stormcrawler/issues/396,incubator-stormcrawler,197688756,396,Slow fetching -,MyraBaba,17505439,,,CLOSED,2016-12-27T11:21:01Z,2017-01-03T09:59:40Z,"Hi ,

This is obviously a configuration issue. But I couldnt find elsewhere  to write:

I couldnt get the full throttle of the storm crawler. I have plenty bandwidth
![image](https://cloud.githubusercontent.com/assets/17505439/21498655/a3e4f90c-cc3f-11e6-956a-b6843c1c3494.png)
 and resources. 

I seed 400 urls (which is only 80 of them taken inside the ES I dont know why) . and : 

etcher.server.delay: 0.2
  fetcher.server.min.delay: 0.0
  fetcher.queue.mode: ""byHost""
  fetcher.threads.per.queue: 2
  fetcher.threads.number: 200
  fetcher.max.urls.in.queues: -1

depth is 3 also.

When I look i didnt see much bandwidth usage. What else the other option to get %100 speed and the power of the storm crawler ? testing local now and more than enough resources.  

Is there any config that I missed ? 

 ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/396/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/396,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2OTM3MDEzMg==,incubator-stormcrawler,269370132,396,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-12-27T19:18:10Z,2016-12-27T19:18:10Z,"> I  seed 400 urls (which is only 80 of them taken inside the ES I dont know why) 

Try with a larger TTL value if you use one

Can you describe your topology + share your full config including the ES one? ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2OTM3MDEzMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/396,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2OTM3MDgxNw==,incubator-stormcrawler,269370817,396,NA,MyraBaba,17505439,,,NA,2016-12-27T19:23:35Z,2016-12-27T19:23:35Z,"here the config files for the elasticsearch example folders:

crawler-config:

```
# Default configuration for StormCrawler
# This is used to make the default values explicit and list the most common configurations.
# Do not modify this file but instead provide a custom one with the parameter -config
# when launching your extension of ConfigurableTopology.

config:
  fetcher.server.delay: 0.2
  fetcher.server.min.delay: 0.0
  fetcher.queue.mode: ""byHost""
  fetcher.threads.per.queue: 2
  fetcher.threads.number: 200
  fetcher.max.urls.in.queues: -1

  # time bucket to use for the metrics sent by the Fetcher
  fetcher.metrics.time.bucket.secs: 10

  # alternative values are ""byIP"" and ""byDomain""
  partition.url.mode: ""byHost""

  # metadata to transfer to the outlinks
  # used by Fetcher for redirections, sitemapparser, etc...
  # these are also persisted for the parent document (see below)
  # metadata.transfer:
  # - customMetadataName

  # lists the metadata to persist to storage
  # these are not transfered to the outlinks
  metadata.persist:
   - _redirTo
   - error.cause
   - error.source
   - isSitemap
   - isFeed

  metadata.track.path: true
  metadata.track.depth: true

  http.agent.name: ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.98 Safari/537.36""
  http.agent.version: ""1.0""
  http.agent.description: ""A StormCrawler-based crawler""
  http.agent.url: ""http://someorganization.com/""
  http.agent.email: ""someone@someorganization.com""

  http.accept.language: ""en-us,en-gb,en;q=0.7,*;q=0.3""
  http.accept: ""text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8""
  http.content.limit: -1
  http.store.responsetime: true
  http.store.headers: false
  http.timeout: 10000

  http.robots.403.allow: true

  parsefilters.config.file: ""parsefilters.json""
  urlfilters.config.file: ""urlfilters.json""

  # should the URLs be removed when a page is marked as noFollow
  robots.noFollow.strict: false

  protocols: ""http,https""
  http.protocol.implementation: ""com.digitalpebble.stormcrawler.protocol.httpclient.HttpProtocol""
  https.protocol.implementation: ""com.digitalpebble.stormcrawler.protocol.httpclient.HttpProtocol""

  # no url or parsefilters by default
  # parsefilters.config.file: ""parsefilters.json""
  # urlfilters.config.file: ""urlfilters.json""

  # JSoupParserBolt
  jsoup.treat.non.html.as.error: true
  parser.emitOutlinks: true
  track.anchors: true
  detect.mimetype: true
  detect.charset.maxlength: 2048

  # whether the sitemap parser should try to
  # determine whether a page is a sitemap based
  # on its content if it is missing the K/V in the metadata
  sitemap.sniffContent: false

  # filters URLs in sitemaps based on their modified Date (if any)
  sitemap.filter.hours.since.modified: -1

  # whether to add any sitemaps found in the robots.txt to the status stream
  # used by fetcher bolts. sitemap.sniffContent must be set to true if the
  # discovery is enabled
  sitemap.discovery: false

  # Default implementation of Scheduler
  scheduler.class: ""com.digitalpebble.stormcrawler.persistence.DefaultScheduler""

  # revisit a page daily (value in minutes)
  # set it to -1 to never refetch a page
  fetchInterval.default: -1

  # revisit a page with a fetch error after 2 hours (value in minutes)
  # set it to -1 to never refetch a page
  fetchInterval.fetch.error: 120

  # never revisit a page with an error (or set a value in minutes)
  fetchInterval.error: -1
  fetcher.server.delay: 0.2
  # custom fetch interval to be used when a document has the key/value in its metadata
  # and has been fetched succesfully (value in minutes)
  # fetchInterval.isFeed=true: 10

  # max number of successive fetch errors before changing status to ERROR
  max.fetch.errors: 3

  # Guava cache use by AbstractStatusUpdaterBolt for DISCOVERED URLs
  status.updater.use.cache: true
  status.updater.cache.spec: ""maximumSize=10000,expireAfterAccess=1h""

  # configuration for the classes extending AbstractIndexerBolt
  # indexer.md.filter: ""someKey=aValue""
  indexer.url.fieldname: ""url""
  indexer.text.fieldname: ""content""
  indexer.canonical.name: ""canonical""
  indexer.md.mapping:
  - parse.title=title
  - parse.keywords=keywords
  - parse.description=description

```

----

and es-conf:

```

# configuration for Elasticsearch resources
  
config:
  # ES indexer bolt
  es.indexer.addresses: ""localhost:9300""
  es.indexer.index.name: ""index""
  es.indexer.doc.type: ""doc""
  es.indexer.create: false
  es.indexer.settings:
    cluster.name: ""elasticsearch""
  
  # ES metricsConsumer
  es.metrics.addresses: ""localhost:9300""
  es.metrics.index.name: ""metrics""
  es.metrics.doc.type: ""datapoint""
  es.metrics.settings:
    cluster.name: ""elasticsearch""
  
  # ES metrics whitelist. Only metrics in this list will be written to ES
  # es.metrics.whitelist:
  # - fetcher_counter
  # - fetcher_average.bytes_fetched
  
  # ES metrics blacklist. Never write these metrics to ES
  # es.metrics.blacklist:
  # - __receive.capacity
  # - __receive.read_pos
  
  # ES spout and persistence bolt
  es.status.addresses: ""localhost:9300""
  es.status.index.name: ""status""
  es.status.doc.type: ""status""
  # the routing is done on the value of 'partition.url.mode'
  es.status.routing: true
  # stores the value used for the routing as a separate field
  es.status.routing.fieldname: ""metadata.hostname""
  es.status.bulkActions: 500
  es.status.flushInterval: ""5s""
  es.status.concurrentRequests: 1
  es.status.settings:
    cluster.name: ""elasticsearch""
  
  # used by spouts - time in secs for which the URLs will be considered for fetching after a ack of fail
  es.status.ttl.purgatory: 30
  
  # Min time (in msecs) to allow between 2 successive queries to ES
  es.status.min.delay.queries: 2000
  
  # ElasticSearchSpout
  # ES Spout throttling. Uses the value of 'partition.url.mode' for the bucket key.
  es.status.max.inflight.urls.per.bucket: -1
  es.status.sort.field: ""nextFetchDate""
  # limits the deep paging by resetting the start offset for the ES query 
  es.status.max.secs.date: 100
  
  # AggregationSpout
  es.status.max.buckets: 50
  es.status.max.urls.per.bucket: 2
  # field to group the URLs into buckets
  es.status.bucket.field: ""_routing""
  # field to sort the URLs within a bucket
  es.status.bucket.sort.field: ""nextFetchDate""
  # field to sort the buckets
  es.status.global.sort.field: ""nextFetchDate""

  topology.metrics.consumer.register:
       - class: ""com.digitalpebble.stormcrawler.elasticsearch.metrics.MetricsConsumer""
         parallelism.hint: 1
```

```
  topology.workers: 1
  topology.message.timeout.secs: 300
  topology.max.spout.pending: 10
  topology.debug: false
  fetcher.max.urls.in.queues: -1

  # mandatory when using Flux
  topology.kryo.register:
    - com.digitalpebble.stormcrawler.Metadata

  # metadata to transfer to the outlinks
  # used by Fetcher for redirections, sitemapparser, etc...
  # these are also persisted for the parent document (see below)
  # metadata.transfer:
  # - customMetadataName

  # lists the metadata to persist to storage
  # these are not transfered to the outlinks
  metadata.persist:
   - _redirTo
   - error.cause
   - error.source
   - isSitemap
   - isFeed
   
#
#  http.agent.name: ""Anonymous Coward""
#  http.agent.version: ""1.0""
#  http.agent.description: ""A StormCrawler-based crawler""
#  http.agent.url: ""http://someorganization.com/""
#  http.agent.email: ""someone@someorganization.com""
#

```






","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2OTM3MDgxNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/396,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2OTM3MjgxMg==,incubator-stormcrawler,269372812,396,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-12-27T19:39:21Z,2016-12-27T19:39:21Z,"Using [https://github.com/DigitalPebble/storm-crawler/blob/master/external/elasticsearch/src/main/java/com/digitalpebble/stormcrawler/elasticsearch/ESCrawlTopology.java]? Make sure the number of shards is the same as what the ES init script specified. 

` topology.max.spout.pending: 10` is likely to be too low for 200 threads.

The AggregationSpout or SamplerAggregationSpout is likely to give you better performance, especially as the index starts growing. I might change the example topology to that 



","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2OTM3MjgxMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/396,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2OTM3OTYwNQ==,incubator-stormcrawler,269379605,396,NA,MyraBaba,17505439,,,NA,2016-12-27T20:38:36Z,2016-12-27T20:38:36Z,"Number of shards:

in the ESCrawlTopology.java:

```
TopologyBuilder builder = new TopologyBuilder();

int numWorkers = ConfUtils.getInt(getConf(), ""topology.workers"", 2);

int numFetchers = ConfUtils.getInt(getConf(), ""fetcher.threads.number"",
        50);

// set to the real number of shards ONLY if es.status.routing is set to
// true in the configuration
int numShards = 10;   //  IT WAS 1 .  I CHANGED to 10

```

in the ES init script there is different shard numbers:  

```
# deletes and recreates a status index with a bespoke schema

curl -s -XDELETE 'http://localhost:9200/status/' >  /dev/null

echo ""Deleted status index""

# http://localhost:9200/status/_mapping/status?pretty

echo ""Creating status index with mapping""

curl -s -XPOST localhost:9200/status -d '
{
   ""settings"": {
      ""index"": {
         ""number_of_shards"": 10,
         ""number_of_replicas"": 1,
         ""refresh_interval"": ""5s""
      }
   },
   ""mappings"": {
      ""status"": {
         ""dynamic_templates"": [{
            ""metadata"": {
               ""path_match"": ""metadata.*"",
               ""match_mapping_type"": ""string"",
               ""mapping"": {
                  ""type"": ""string"",
                  ""index"": ""not_analyzed""
               }
            }
         }],
         ""_source"": {
            ""enabled"": true
         },
         ""_all"": {
            ""enabled"": false
         },
         ""properties"": {
            ""nextFetchDate"": {
               ""type"": ""date"",
               ""format"": ""dateOptionalTime""
            },
            ""status"": {
               ""type"": ""string"",
               ""index"": ""not_analyzed""
            },
            ""url"": {
               ""type"": ""string"",
               ""index"": ""not_analyzed""
            }
         }
      }
   }
}'

# deletes and recreates a status index with a bespoke schema

curl -s -XDELETE 'http://localhost:9200/metrics*/' >  /dev/null

echo """"
echo ""Deleted metrics index""

echo ""Creating metrics index with mapping""

# http://localhost:9200/metrics/_mapping/status?pretty
curl -s -XPOST localhost:9200/_template/storm-metrics-template -d '
{
  ""template"": ""metrics*"",
  ""settings"": {
    ""index"": {
      ""number_of_shards"": 1,
      ""refresh_interval"": ""5s""
    },
    ""number_of_replicas"" : 0
  },
  ""mappings"": {
    ""datapoint"": {
      ""_all"":            { ""enabled"": false },
      ""_source"":         { ""enabled"": true },
      ""properties"": {
          ""name"": {
            ""type"": ""string"",
            ""index"": ""not_analyzed""
          },
          ""srcComponentId"": {
            ""type"": ""string"",
            ""index"": ""not_analyzed""
          },
          ""srcTaskId"": {
            ""type"": ""long""
          },
          ""srcWorkerHost"": {
            ""type"": ""string"",
            ""index"": ""not_analyzed""
          },
          ""srcWorkerPort"": {
            ""type"": ""long""
          },
          ""timestamp"": {
            ""type"": ""date"",
            ""format"": ""dateOptionalTime""
          },
          ""value"": {
            ""type"": ""double""
          }
      }
    }
  }
}'

echo """"

```

For The topology.max.spout.pending: change to 100 


Basicly we are currently crawling daily almost 30M url (including all parsing , meta data , indexing etc.)

We try to understand advantages (specially for the speeding up the process) of the storm-crawler first of all..







> On 27 Ara 2016, at 22:39, Julien Nioche <notifications@github.com> wrote:
> 
> Using [https://github.com/DigitalPebble/storm-crawler/blob/master/external/elasticsearch/src/main/java/com/digitalpebble/stormcrawler/elasticsearch/ESCrawlTopology.java]? Make sure the number of shards is the same as what the ES init script specified.
> 
> topology.max.spout.pending: 10 is likely to be too low for 200 threads.
> 
> The AggregationSpout or SamplerAggregationSpout is likely to give you better performance, especially as the index starts growing. I might change the example topology to that
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub <https://github.com/DigitalPebble/storm-crawler/issues/396#issuecomment-269372812>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AQscn56xb8pCSAHMParMrmBfwvg1I5gXks5rMWlqgaJpZM4LWNgj>.
> 

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2OTM3OTYwNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/396,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2OTQ4MTkyNg==,incubator-stormcrawler,269481926,396,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-12-28T14:10:49Z,2016-12-28T14:10:49Z,"the max.spout.pending value is per spout instance. You are using 10 which is also the # of shards, so it's all good.

Note that the screenshots you took are probably an average over the fetcher bolt instances - you have 50 of them. A better way of assessing the speed and bottlenecks is by looking at the Storm UI on port 8080 and in the resulting index.

using the FetcherBolt (a single instance will do) will give you multithreading per host - which the SimpleFetcherBolt won't do + more intelligible metrics. As I pointed out earlier you'll get better perfs with the AggregationBolt. 

In any way, check the Storm UI and logs to get a better understanding of the perfs. SC give you plenty of options for fine-tuning and it takes a bit of time to get used to the way it works.

For the sake of comparison \: I'll be publishing a blog post next week with a comparison with Apache Nutch on a single machine over 1K seed URLs. Don't want to spoil the suspense but StormCrawler comes on top ;-) ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2OTQ4MTkyNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/396,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2OTYyNTkzMQ==,incubator-stormcrawler,269625931,396,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-12-29T12:49:00Z,2016-12-29T12:49:00Z,"Closing for now - feel free to open a new issue if you find something which looks like a bug or want a new features. For general questions, the mailing list or stack overflow would probably be better. Thanks!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2OTYyNTkzMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/396,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2OTg5MDk1Mg==,incubator-stormcrawler,269890952,396,NA,MyraBaba,17505439,,,NA,2017-01-01T03:28:20Z,2017-01-01T03:28:20Z,"Hi  Again,

As you suggested I change the fetcher to the FetcherBolt  instead of the SimpleFetcherBolt  in the elastic search  config. Now I have a lot of error:

org.apache.http.conn.ConnectionPoolTimeoutException: Timeout waiting for connection from pool



**********
68648 [Thread-24-spout-executor[33 33]] INFO  c.d.s.e.p.ElasticSearchSpout - ES query returned 100 hits in 67 msec
68653 [Thread-66-spout-executor[27 27]] INFO  c.d.s.e.p.ElasticSearchSpout - ES query returned 100 hits in 72 msec
68653 [Thread-48-fetch-executor[13 13]] INFO  c.d.s.b.FetcherBolt - [Fetcher #13] Threads : 5	queues : 4	in_queues : 1090
68654 [Thread-15-fetch-executor[7 7]] INFO  c.d.s.b.FetcherBolt - [Fetcher #7] Threads : 3	queues : 2	in_queues : 207
68654 [Thread-50-fetch-executor[6 6]] INFO  c.d.s.b.FetcherBolt - [Fetcher #6] Threads : 5	queues : 9	in_queues : 1045
68654 [Thread-50-fetch-executor[6 6]] INFO  c.d.s.b.FetcherBolt - [Fetcher #6] Threads : 5	queues : 9	in_queues : 1046
68655 [Thread-15-fetch-executor[7 7]] INFO  c.d.s.b.FetcherBolt - [Fetcher #7] Threads : 3	queues : 2	in_queues : 208
68660 [FetcherThread] ERROR c.d.s.b.FetcherBolt - Exception while fetching http://www.ajansspor.com/futbol/takim/bate_borisov/
org.apache.http.conn.ConnectionPoolTimeoutException: Timeout waiting for connection from pool
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.leaseConnection(PoolingHttpClientConnectionManager.java:286) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager$1.get(PoolingHttpClientConnectionManager.java:263) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:190) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:184) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:184) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:71) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:220) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:164) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:139) ~[httpclient-4.4.1.jar:4.4.1]
	at com.digitalpebble.stormcrawler.protocol.httpclient.HttpProtocol.getProtocolOutput(HttpProtocol.java:148) ~[classes/:?]
	at com.digitalpebble.stormcrawler.bolt.FetcherBolt$FetcherThread.run(FetcherBolt.java:493) [classes/:?]
68660 [Thread-15-fetch-executor[7 7]] INFO  c.d.s.b.FetcherBolt - [Fetcher #7] Threads : 3	queues : 2	in_queues : 209
68662 [Thread-50-fetch-executor[6 6]] INFO  c.d.s.b.FetcherBolt - [Fetcher #6] Threads : 5	queues : 9	in_queues : 1047
68662 [Thread-50-fetch-executor[6 6]] INFO  c.d.s.b.FetcherBolt - [Fetcher #6] Threads : 5	queues : 9	in_queues : 1048
68663 [Thread-15-fetch-executor[7 7]] INFO  c.d.s.b.FetcherBolt - [Fetcher #7] Threads : 3	queues : 2	in_queues : 210
68663 [Thread-48-fetch-executor[13 13]] INFO  c.d.s.b.FetcherBolt - [Fetcher #13] Threads : 5	queues : 4	in_queues : 1091
68663 [Thread-48-fetch-executor[13 13]] INFO  c.d.s.b.FetcherBolt - [Fetcher #13] Threads : 5	queues : 4	in_queues : 1092
68666 [Thread-68-spout-executor[29 29]] INFO  c.d.s.e.p.ElasticSearchSpout - ES query returned 100 hits in 82 msec
68672 [FetcherThread] INFO  c.d.s.b.FetcherBolt - [Fetcher #15] Fetched http://www.sporx.com/motorsporlari/diger/ with status 200 in msec 290
68672 [FetcherThread] ERROR c.d.s.b.FetcherBolt - Exception while fetching http://www.sporx.com/rio2016/_assets/ajax/branslar.php?id=35
org.apache.http.NoHttpResponseException: The target server failed to respond
	at org.apache.http.impl.conn.DefaultHttpResponseParser.parseHead(DefaultHttpResponseParser.java:143) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.conn.DefaultHttpResponseParser.parseHead(DefaultHttpResponseParser.java:57) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.io.AbstractMessageParser.parse(AbstractMessageParser.java:261) ~[httpcore-4.4.1.jar:4.4.1]
	at org.apache.http.impl.DefaultBHttpClientConnection.receiveResponseHeader(DefaultBHttpClientConnection.java:165) ~[httpcore-4.4.1.jar:4.4.1]
	at org.apache.http.impl.conn.CPoolProxy.receiveResponseHeader(CPoolProxy.java:167) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.protocol.HttpRequestExecutor.doReceiveResponse(HttpRequestExecutor.java:272) ~[httpcore-4.4.1.jar:4.4.1]
	at org.apache.http.protocol.HttpRequestExecutor.execute(HttpRequestExecutor.java:124) ~[httpcore-4.4.1.jar:4.4.1]
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:271) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:184) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:184) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:71) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:220) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:164) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:139) ~[httpclient-4.4.1.jar:4.4.1]
	at com.digitalpebble.stormcrawler.protocol.httpclient.HttpProtocol.getProtocolOutput(HttpProtocol.java:148) ~[classes/:?]
	at com.digitalpebble.stormcrawler.bolt.FetcherBolt$FetcherThread.run(FetcherBolt.java:493) [classes/:?]
68673 [FetcherThread] ERROR c.d.s.b.FetcherBolt - Exception while fetching http://www.star.com.tr/teog-sinav-bilgisi/
org.apache.http.conn.ConnectionPoolTimeoutException: Timeout waiting for connection from pool
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.leaseConnection(PoolingHttpClientConnectionManager.java:286) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager$1.get(PoolingHttpClientConnectionManager.java:263) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:190) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:184) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:184) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:71) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:220) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:164) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:139) ~[httpclient-4.4.1.jar:4.4.1]
	at com.digitalpebble.stormcrawler.protocol.httpclient.HttpProtocol.getProtocolOutput(HttpProtocol.java:148) ~[classes/:?]
	at com.digitalpebble.stormcrawler.bolt.FetcherBolt$FetcherThread.run(FetcherBolt.java:493) [classes/:?]
68673 [FetcherThread] ERROR c.d.s.b.FetcherBolt - Exception while fetching http://www.star.com.tr/teog-sinav-bilgisi/
org.apache.http.conn.ConnectionPoolTimeoutException: Timeout waiting for connection from pool
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.leaseConnection(PoolingHttpClientConnectionManager.java:286) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager$1.get(PoolingHttpClientConnectionManager.java:263) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:190) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:184) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:184) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:71) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:220) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:164) ~[httpclient-4.4.1.jar:4.4.1]
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:139) ~[httpclient-4.4.1.jar:4.4.1]
	at com.digitalpebble.stormcrawler.protocol.httpclient.HttpProtocol.getProtocolOutput(HttpProtocol.java:148) ~[classes/:?]
	at com.digitalpebble.stormcrawler.bolt.FetcherBolt$FetcherThread.run(FetcherBolt.java:493) [classes/:?] 

********************

> On 28 Ara 2016, at 17:10, Julien Nioche <notifications@github.com> wrote:
> 
> the max.spout.pending value is per spout instance. You are using 10 which is also the # of shards, so it's all good.
> 
> Note that the screenshots you took are probably an average over the fetcher bolt instances - you have 50 of them. A better way of assessing the speed and bottlenecks is by looking at the Storm UI on port 8080 and in the resulting index.
> 
> using the FetcherBolt (a single instance will do) will give you multithreading per host - which the SimpleFetcherBolt won't do + more intelligible metrics. As I pointed out earlier you'll get better perfs with the AggregationBolt.
> 
> In any way, check the Storm UI and logs to get a better understanding of the perfs. SC give you plenty of options for fine-tuning and it takes a bit of time to get used to the way it works.
> 
> For the sake of comparison : I'll be publishing a blog post next week with a comparison with Apache Nutch on a single machine over 1K seed URLs. Don't want to spoil the suspense but StormCrawler comes on top ;-)
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub <https://github.com/DigitalPebble/storm-crawler/issues/396#issuecomment-269481926>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AQscn-ZFowBq8kf67n9PiLYMRUqFlNPmks5rMm3qgaJpZM4LWNgj>.
> 

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2OTg5MDk1Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/396,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDA4MTI4Nw==,incubator-stormcrawler,270081287,396,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-03T09:59:40Z,2017-01-03T09:59:40Z,"You should use only 1 instance of the FetcherBolt per worker - they are all competing for connections from the protocol.
The difference between the SimpleFetcherBolt and the FetcherBolt is that the latter is a single instance creating sub fetching threads whereas the SFB instances are the fetching threads.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDA4MTI4Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/397,https://api.github.com/repos/apache/incubator-stormcrawler/issues/397,incubator-stormcrawler,198092750,397,Native Heron support,MyraBaba,17505439,,,CLOSED,2016-12-30T01:28:18Z,2016-12-30T07:51:03Z,"Hi,

We know there is a a way to transferring to the Twitter's Heron (replacement to the Storm) from the current system .

Do you have a plan to change  to  native Heron based structure ? ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/397/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/397,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2OTc0MjYzOQ==,incubator-stormcrawler,269742639,397,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-12-30T07:51:03Z,2016-12-30T07:51:03Z,"> Do you have a plan to change to native Heron based structure ?

No. We're staying on Apache Storm for the foreseeable future.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2OTc0MjYzOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/398,https://api.github.com/repos/apache/incubator-stormcrawler/issues/398,incubator-stormcrawler,198118371,398,Tika : NoSuchMethodError,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2016-12-30T08:24:27Z,2017-01-03T10:30:25Z,"Getting 
`java.lang.NoSuchMethodError: org.apache.tika.parser.ParseContext.getDocumentBuilder()Ljavax/xml/parsers/DocumentBuilder;`
when parsing \:
https://www.chemours.com/Glypure/en_US/assets/downloads/glypure-skin-care-formulations-technical-information.pdf
https://www.chemours.com/news/news-releases/20160803-chemours-announces-3rd-qtr-dividend.pdf
https://www.chemours.com/Titanium_Technologies/en_US/assets/downloads/Ti-Pure-R-350-for-polyolefins.pdf

The right parser (PDF) is used. I'll try with Tika standalone. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/398/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/398,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2OTc0NTc4Mg==,incubator-stormcrawler,269745782,398,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2016-12-30T08:33:28Z,2016-12-30T08:33:28Z,"Tested with tika-app-1.13.jar, which parses the doc fine. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI2OTc0NTc4Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/398,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDA4NjQyNQ==,incubator-stormcrawler,270086425,398,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-03T10:30:25Z,2017-01-03T10:30:25Z,Was due to a mismatch between the version of the tika core dependency and the tika parser one but fine now that we upgraded to crawler commons 0.7 ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDA4NjQyNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/399,https://api.github.com/repos/apache/incubator-stormcrawler/issues/399,incubator-stormcrawler,198744126,399,per url depth & regex filter,MyraBaba,17505439,,,CLOSED,2017-01-04T16:07:44Z,2018-06-06T15:23:34Z,"feature wish 👍 

There will be a very useful if we can submit the seed list with depth and url filter regex  per url as an option.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/399/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/399,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDYwMzY0MA==,incubator-stormcrawler,270603640,399,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-05T09:44:41Z,2017-01-05T09:44:41Z,Having a mechanism to set a non default max depth per seed is a good idea and the regex one could be useful too but would you mind giving me an example of that so that I can have a better picture of what you are trying to achieve?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDYwMzY0MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/399,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDYwNTk1Nw==,incubator-stormcrawler,270605957,399,NA,MyraBaba,17505439,,,NA,2017-01-05T09:55:52Z,2017-01-05T09:55:52Z,"I have different type of urls (news , portal , blog etc.) So each one needs different follow rules.

Such as:

http://edition.cnn.com/ <http://edition.cnn.com/> 

I wan to follow only if url includes “politics”  at 4 level depth ie : http://edition.cnn.com/2017/01/04/politics/us-intelligence-trump/index.html <http://edition.cnn.com/2017/01/04/politics/us-intelligence-trump/index.html> 

so  the url seed could be :

  http://edition.cnn.com/ <http://edition.cnn.com/> , 4 , regex     

So I can crawl the url if it fits the regex pattern at level of depth.

If there is no depth  or regex parameter  it should be fall the system default.

ie:

http://edition.cnn.com/ <http://edition.cnn.com/> , 4    Follow to 4.level depth with system default url filter.

I hope I gave you an idea.


We found it that it will be very usefull if there is a such feature.




> On 5 Oca 2017, at 12:44, Julien Nioche <notifications@github.com> wrote:
> 
> Having a mechanism to set a non default max depth per seed is a good idea and the regex one could be useful too but would you mind giving me an example of that so that I can have a better picture of what you are trying to achieve?
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub <https://github.com/DigitalPebble/storm-crawler/issues/399#issuecomment-270603640>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AQscn5-J0vPUJeHOxr6iPODlguiR5KTYks5rPLuLgaJpZM4Lax5B>.
> 

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDYwNTk1Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/399,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDg3NDkzNA==,incubator-stormcrawler,270874934,399,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-06T10:25:00Z,2017-01-06T10:25:00Z,"@MyraBaba I have implemented your suggestion for the custom depth per URL, see [f46b1ab].
You can now specify 'max.depth=X' in the seed metadata; it will be passed on to the outlinks automatically.
Could you please give it a try? Thanks","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDg3NDkzNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/399,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDkyOTA0NQ==,incubator-stormcrawler,270929045,399,NA,MyraBaba,17505439,,,NA,2017-01-06T15:35:15Z,2017-01-06T15:35:15Z,"I will test soonest possible and let you know.

so seed list like this:

http://www.nccv.com , max.depth=3

right ?




> On 6 Oca 2017, at 13:25, Julien Nioche <notifications@github.com> wrote:
> 
> @MyraBaba <https://github.com/MyraBaba> I have implemented your suggestion for the custom depth per URL, see [f46b1ab <https://github.com/DigitalPebble/storm-crawler/commit/f46b1abe3797a7b7b8a4cbe4e4a01ea2e61483c6>].
> You can now specify 'max.depth=X' in the seed metadata; it will be passed on to the outlinks automatically.
> Could you please give it a try? Thanks
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub <https://github.com/DigitalPebble/storm-crawler/issues/399#issuecomment-270874934>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AQscn1V9qE4kRhrJxDFMgtUSrhTN6pTjks5rPhZ-gaJpZM4Lax5B>.
> 

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDkyOTA0NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/399,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDk0MjE3NQ==,incubator-stormcrawler,270942175,399,NA,MyraBaba,17505439,,,NA,2017-01-06T16:29:11Z,2017-01-06T16:29:11Z,"I made seed.txt  like   :   http://www.haberturk.com.tr , max_depth = 1

 made

it gaves error:  7871 [FetcherThread] ERROR c.d.s.b.FetcherBolt - Exception while fetching http://www.haberturk.com.tr , max_depth = 1


 obviously i missed something ?




> On 6 Oca 2017, at 13:25, Julien Nioche <notifications@github.com> wrote:
> 
> @MyraBaba <https://github.com/MyraBaba> I have implemented your suggestion for the custom depth per URL, see [f46b1ab <https://github.com/DigitalPebble/storm-crawler/commit/f46b1abe3797a7b7b8a4cbe4e4a01ea2e61483c6>].
> You can now specify 'max.depth=X' in the seed metadata; it will be passed on to the outlinks automatically.
> Could you please give it a try? Thanks
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub <https://github.com/DigitalPebble/storm-crawler/issues/399#issuecomment-270874934>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AQscn1V9qE4kRhrJxDFMgtUSrhTN6pTjks5rPhZ-gaJpZM4Lax5B>.
> 

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDk0MjE3NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/399,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDk0MzQyOQ==,incubator-stormcrawler,270943429,399,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-06T16:34:30Z,2017-01-06T16:34:30Z,"Check the topology code, unless you specified otherwise, the FileSpout uses com.digitalpebble.stormcrawler.util.StringTabScheme to deserialise from the text file. It expects tabs as separator between the URL and the key values.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDk0MzQyOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/399,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDk0NzE0MQ==,incubator-stormcrawler,270947141,399,NA,MyraBaba,17505439,,,NA,2017-01-06T16:50:06Z,2017-01-06T16:50:06Z,"Thanks ..

I tested now with the TAB  both 1 depth and 2 depth for http://www.haberturk.com.tr
It  gave REDIRECTION and not followed for both 1 and 2 depth test.

here output
FYI

9849 [Thread-85-spout-executor[36 36]] INFO  c.d.s.e.p.ElasticSearchSpout - ES query returned 0 hits in 358 msec
11423 [FetcherThread] INFO  c.d.s.b.FetcherBolt - [Fetcher #20] Fetched http://www.haberturk.com.tr with status 302 in msec 49
11432 [FetcherThread] INFO  c.d.s.b.FetcherBolt - [Fetcher #20] Fetched http://www.haberturk.com.tr with status 302 in msec 60
11466 [FetcherThread] INFO  c.d.s.b.FetcherBolt - [Fetcher #20] Fetched http://www.haberturk.com.tr with status 302 in msec 40
11472 [FetcherThread] INFO  c.d.s.b.FetcherBolt - [Fetcher #20] Fetched http://www.haberturk.com.tr with status 302 in msec 39
11497 [Thread-79-spout-executor[37 37]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:26.737+0300
11497 [Thread-57-spout-executor[31 31]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:26.737+0300
11497 [Thread-45-spout-executor[38 38]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:26.737+0300
11497 [Thread-37-spout-executor[35 35]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:26.737+0300
11498 [Thread-85-spout-executor[36 36]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:26.738+0300
11502 [Thread-29-spout-executor[33 33]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:26.742+0300
11502 [Thread-21-spout-executor[32 32]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:26.742+0300
11502 [Thread-73-spout-executor[29 29]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:26.742+0300
11502 [Thread-89-spout-executor[34 34]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:26.742+0300
11502 [Thread-51-spout-executor[30 30]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:26.742+0300
11517 [FetcherThread] INFO  c.d.s.b.FetcherBolt - [Fetcher #20] Fetched http://www.haberturk.com.tr with status 302 in msec 51
11524 [FetcherThread] INFO  c.d.s.b.FetcherBolt - [Fetcher #20] Fetched http://www.haberturk.com.tr with status 302 in msec 51
11563 [Thread-37-spout-executor[35 35]] INFO  c.d.s.e.p.ElasticSearchSpout - ES query returned 1 hits in 65 msec
11565 [Thread-51-spout-executor[30 30]] INFO  c.d.s.e.p.ElasticSearchSpout - ES query returned 1 hits in 62 msec
11565 [Thread-85-spout-executor[36 36]] INFO  c.d.s.e.p.ElasticSearchSpout - ES query returned 1 hits in 66 msec
11565 [Thread-45-spout-executor[38 38]] INFO  c.d.s.e.p.ElasticSearchSpout - ES query returned 1 hits in 68 msec
11565 [Thread-89-spout-executor[34 34]] INFO  c.d.s.e.p.ElasticSearchSpout - ES query returned 1 hits in 63 msec
11565 [Thread-79-spout-executor[37 37]] INFO  c.d.s.e.p.ElasticSearchSpout - ES query returned 1 hits in 68 msec
11565 [Thread-57-spout-executor[31 31]] INFO  c.d.s.e.p.ElasticSearchSpout - ES query returned 1 hits in 68 msec
11565 [Thread-21-spout-executor[32 32]] INFO  c.d.s.e.p.ElasticSearchSpout - ES query returned 1 hits in 63 msec
11567 [Thread-29-spout-executor[33 33]] INFO  c.d.s.e.p.ElasticSearchSpout - ES query returned 1 hits in 65 msec
11567 [Thread-73-spout-executor[29 29]] INFO  c.d.s.e.p.ElasticSearchSpout - ES query returned 1 hits in 65 msec
11580 [FetcherThread] INFO  c.d.s.b.FetcherBolt - [Fetcher #20] Fetched http://www.haberturk.com.tr with status 302 in msec 62
11587 [FetcherThread] INFO  c.d.s.b.FetcherBolt - [Fetcher #20] Fetched http://www.haberturk.com.tr with status 302 in msec 61
11633 [FetcherThread] INFO  c.d.s.b.FetcherBolt - [Fetcher #20] Fetched http://www.haberturk.com.tr with status 302 in msec 52
11642 [FetcherThread] INFO  c.d.s.b.FetcherBolt - [Fetcher #20] Fetched http://www.haberturk.com.tr with status 302 in msec 55
12488 [elasticsearch[Madcap][listener][T#1]] WARN  c.d.s.e.p.StatusUpdaterBolt - Could not find unacked tuple for 5443acfb013beaaa0fd654216e058ed3a0223ce65c13825ac7685ce068c71a9e
12488 [elasticsearch[Madcap][listener][T#1]] WARN  c.d.s.e.p.StatusUpdaterBolt - Could not find unacked tuple for 5443acfb013beaaa0fd654216e058ed3a0223ce65c13825ac7685ce068c71a9e
12491 [elasticsearch[Madcap][listener][T#1]] WARN  c.d.s.e.p.StatusUpdaterBolt - Could not find unacked tuple for 5443acfb013beaaa0fd654216e058ed3a0223ce65c13825ac7685ce068c71a9e
12491 [elasticsearch[Madcap][listener][T#1]] WARN  c.d.s.e.p.StatusUpdaterBolt - Could not find unacked tuple for 5443acfb013beaaa0fd654216e058ed3a0223ce65c13825ac7685ce068c71a9e
12491 [elasticsearch[Madcap][listener][T#1]] WARN  c.d.s.e.p.StatusUpdaterBolt - Could not find unacked tuple for 5443acfb013beaaa0fd654216e058ed3a0223ce65c13825ac7685ce068c71a9e
12491 [elasticsearch[Madcap][listener][T#1]] WARN  c.d.s.e.p.StatusUpdaterBolt - Could not find unacked tuple for 5443acfb013beaaa0fd654216e058ed3a0223ce65c13825ac7685ce068c71a9e
12491 [elasticsearch[Madcap][listener][T#1]] WARN  c.d.s.e.p.StatusUpdaterBolt - Could not find unacked tuple for 5443acfb013beaaa0fd654216e058ed3a0223ce65c13825ac7685ce068c71a9e
12491 [elasticsearch[Madcap][listener][T#1]] WARN  c.d.s.e.p.StatusUpdaterBolt - Could not find unacked tuple for 5443acfb013beaaa0fd654216e058ed3a0223ce65c13825ac7685ce068c71a9e
12491 [elasticsearch[Madcap][listener][T#1]] WARN  c.d.s.e.p.StatusUpdaterBolt - Could not find unacked tuple for 5443acfb013beaaa0fd654216e058ed3a0223ce65c13825ac7685ce068c71a9e
12491 [elasticsearch[Madcap][listener][T#1]] INFO  c.d.s.e.p.StatusUpdaterBolt - Bulk response 10, waitAck 0, acked 10
13499 [Thread-57-spout-executor[31 31]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:26.737+0300
13499 [Thread-37-spout-executor[35 35]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:26.737+0300
13502 [Thread-85-spout-executor[36 36]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:26.738+0300
13502 [Thread-21-spout-executor[32 32]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:26.742+0300
13502 [Thread-79-spout-executor[37 37]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:26.737+0300
13508 [Thread-45-spout-executor[38 38]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:26.737+0300
13508 [Thread-51-spout-executor[30 30]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:26.742+0300
13508 [Thread-73-spout-executor[29 29]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:26.742+0300
13508 [Thread-89-spout-executor[34 34]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:26.742+0300
13513 [Thread-29-spout-executor[33 33]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:26.742+0300
13536 [Thread-37-spout-executor[35 35]] INFO  c.d.s.e.p.ElasticSearchSpout - ES query returned 0 hits in 37 msec
13536 [Thread-57-spout-executor[31 31]] INFO  c.d.s.e.p.ElasticSearchSpout - ES query returned 0 hits in 37 msec
13538 [Thread-79-spout-executor[37 37]] INFO  c.d.s.e.p.ElasticSearchSpout - ES query returned 0 hits in 36 msec
13538 [Thread-85-spout-executor[36 36]] INFO  c.d.s.e.p.ElasticSearchSpout - ES query returned 0 hits in 36 msec
13539 [Thread-21-spout-executor[32 32]] INFO  c.d.s.e.p.ElasticSearchSpout - ES query returned 0 hits in 37 msec
13549 [Thread-51-spout-executor[30 30]] INFO  c.d.s.e.p.ElasticSearchSpout - ES query returned 0 hits in 41 msec
13549 [Thread-73-spout-executor[29 29]] INFO  c.d.s.e.p.ElasticSearchSpout - ES query returned 0 hits in 41 msec
13550 [Thread-45-spout-executor[38 38]] INFO  c.d.s.e.p.ElasticSearchSpout - ES query returned 0 hits in 42 msec
13552 [Thread-89-spout-executor[34 34]] INFO  c.d.s.e.p.ElasticSearchSpout - ES query returned 0 hits in 44 msec
13554 [Thread-29-spout-executor[33 33]] INFO  c.d.s.e.p.ElasticSearchSpout - ES query returned 0 hits in 41 msec
15500 [Thread-57-spout-executor[31 31]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:30.739+0300
15500 [Thread-37-spout-executor[35 35]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:30.739+0300
15502 [Thread-21-spout-executor[32 32]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:30.742+0300
15512 [Thread-51-spout-executor[30 30]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:30.752+0300
15512 [Thread-45-spout-executor[38 38]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:30.752+0300
15512 [Thread-85-spout-executor[36 36]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:30.752+0300
15512 [Thread-89-spout-executor[34 34]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:30.752+0300
15512 [Thread-79-spout-executor[37 37]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:30.752+0300
15514 [Thread-73-spout-executor[29 29]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:30.754+0300
15524 [Thread-29-spout-executor[33 33]] INFO  c.d.s.e.p.ElasticSearchSpout - Populating buffer with nextFetchDate <= 2017-01-06T19:40:30.764+0300
15583 [Thread-57-spout-executor[31 31]] INFO  c.d.s.e.p.ElasticSearchSpout - ES query returned 0 hits in 83 msec
15583 [Thread-37-spout-executor[35 35]] INFO  c.d.s.e.p.ElasticSearchSpout - ES query returned 0 hits in 83 msec
15584 [Thread-21-spout-executor[32 32]] INFO  c.d.s.e.p.ElasticSearchSpout - ES query returned 0 hits in 82 msec


> On 6 Oca 2017, at 19:34, Julien Nioche <notifications@github.com> wrote:
> 
> Check the topology code, unless you specified otherwise, the FileSpout uses com.digitalpebble.stormcrawler.util.StringTabScheme to deserialise from the text file. It expects tabs as separator between the URL and the key values.
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub <https://github.com/DigitalPebble/storm-crawler/issues/399#issuecomment-270943429>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AQscn9R9qznfFDIxjuh3UqUkejQ671Irks5rPm0XgaJpZM4Lax5B>.
> 

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDk0NzE0MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/399,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDk2MTQ2OQ==,incubator-stormcrawler,270961469,399,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-06T17:51:48Z,2017-01-06T17:51:48Z,"Looks like you are not sharding per host or domain. As a result all the spout instances run the same query to ES.

Check your url filters, it could be that you are preventing redirections across domains : _haberturk.com.tr_ is not the same domain as _haberturk.com_

BTW I'll be running a workshop next month in Berlin [https://twitter.com/digitalpebble/status/816398939368919040] and will cover the basics of SC","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDk2MTQ2OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/399,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDk2MjIwMg==,incubator-stormcrawler,270962202,399,NA,MyraBaba,17505439,,,NA,2017-01-06T17:54:54Z,2017-01-06T17:54:54Z,"I will check and let you know.

I will be travelling also next month may be I can find a window to visit Berlin.



> On 6 Oca 2017, at 20:51, Julien Nioche <notifications@github.com> wrote:
> 
> Looks like you are not sharding per host or domain. As a result all the spout instances run the same query to ES.
> 
> Check your url filters, it could be that you are preventing redirections across domains : haberturk.com.tr is not the same domain as haberturk.com
> 
> BTW I'll be running a workshop next month in Berlin [https://twitter.com/digitalpebble/status/816398939368919040] and will cover the basics of SC
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub <https://github.com/DigitalPebble/storm-crawler/issues/399#issuecomment-270961469>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AQscn-S9UrRn5wtY0EjFt0MKeQ4grqTYks5rPn81gaJpZM4Lax5B>.
> 

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDk2MjIwMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/399,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTM4Mzg1Mg==,incubator-stormcrawler,271383852,399,NA,MyraBaba,17505439,,,NA,2017-01-09T19:33:01Z,2017-01-09T19:33:01Z,"I tested for max_depth=1 and max_depth=0  for different domain

:

http://www.hurriyet.com.tr/deniz-baykal-halkin-haberi-yok-40331335	max_depth=1
http://www.haberturk.com/gundem/haber/1346487-omer-halisdemirin-babasindan-fethi-sekinin-ailesine-ziyaret	max_depth=0

:


You know the elasticsearch adress login information.  When I checked the status=FETCHED  it looks very hight to me..  

max_depth = 1 should only follow 1 link further right ?  and max_depth = 0  for the only the given url. (Such as I have 10.000 link and only want to crawl that link no follow.)

Let me know after you checked elastic search..

ie: per url  regex could be helpful 

thx

> On 6 Oca 2017, at 19:29, PrometheusWillSurvive <prometheus.willsurvive@gmail.com> wrote:
> 
> I made seed.txt  like   :   http://www.haberturk.com.tr <http://www.haberturk.com.tr/> , max_depth = 1
> 
>  made
> 
> it gaves error:  7871 [FetcherThread] ERROR c.d.s.b.FetcherBolt - Exception while fetching http://www.haberturk.com.tr <http://www.haberturk.com.tr/> , max_depth = 1
> 
> 
>  obviously i missed something ?
> 
> 
> 
> 
>> On 6 Oca 2017, at 13:25, Julien Nioche <notifications@github.com <mailto:notifications@github.com>> wrote:
>> 
>> @MyraBaba <https://github.com/MyraBaba> I have implemented your suggestion for the custom depth per URL, see [f46b1ab <https://github.com/DigitalPebble/storm-crawler/commit/f46b1abe3797a7b7b8a4cbe4e4a01ea2e61483c6>].
>> You can now specify 'max.depth=X' in the seed metadata; it will be passed on to the outlinks automatically.
>> Could you please give it a try? Thanks
>> 
>> —
>> You are receiving this because you were mentioned.
>> Reply to this email directly, view it on GitHub <https://github.com/DigitalPebble/storm-crawler/issues/399#issuecomment-270874934>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AQscn1V9qE4kRhrJxDFMgtUSrhTN6pTjks5rPhZ-gaJpZM4Lax5B>.
>> 
> 

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTM4Mzg1Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/399,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTU0ODMyMw==,incubator-stormcrawler,271548323,399,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-10T11:07:24Z,2017-01-10T11:07:24Z,"> Let me know after you checked elastic search..

not clear what your question is + you would learn a bit about StormCrawler and Elasticsearch by investigating things by yourself. 

why are you putting an _ and not a . for the metadata name?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTU0ODMyMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/399,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTU4OTQwNA==,incubator-stormcrawler,271589404,399,NA,MyraBaba,17505439,,,NA,2017-01-10T14:30:01Z,2017-01-10T14:30:01Z,"Sorry it is my mistake. All is fine now. 

> On 10 Oca 2017, at 14:07, Julien Nioche <notifications@github.com> wrote:
> 
> Let me know after you checked elastic search..
> 
> not clear what your question is + you would learn a bit about StormCrawler and Elasticsearch by investigating things by yourself.
> 
> why are you putting an _ and not a . for the metadata name?
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub <https://github.com/DigitalPebble/storm-crawler/issues/399#issuecomment-271548323>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AQscn4poWrJ824YHC7f0OiFSPfP5TVDRks5rQ2ZtgaJpZM4Lax5B>.
> 

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTU4OTQwNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/399,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2NDA3NDMzMA==,incubator-stormcrawler,364074330,399,NA,hatemalimam,3439970,Hatem Alimam,me@hatemalimam.com,NA,2018-02-08T10:48:40Z,2018-02-08T10:48:40Z,"How about a set of regex per seed ?
for example I would like to fetch from bbc.com where domain contains for example sport/football,
whereas from edition.ccn.com everything with sport/golf in the URL... can I pass a set of regex to be tested against a seed ?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2NDA3NDMzMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/399,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2NDI1NzgwOA==,incubator-stormcrawler,364257808,399,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-02-08T21:42:25Z,2018-02-08T21:42:25Z,"This has not been implemented yet, so everything's possible. Do you know you can use the existing file-based regex url filter to have as many patterns as you like? ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2NDI1NzgwOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/399,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2NDI2MTMwNA==,incubator-stormcrawler,364261304,399,NA,hatemalimam,3439970,Hatem Alimam,me@hatemalimam.com,NA,2018-02-08T21:55:01Z,2018-02-08T21:55:01Z,"After reading the source code I managed to implement my own seeds regex url filter, it's basically a key (domain) value (list of rules) based map. it's working fine, and each domain has its own regex file txt. it would be nice to have such feature implemented here.

Thanks for the reply.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2NDI2MTMwNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/399,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2NDI2NTI2Mg==,incubator-stormcrawler,364265262,399,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-02-08T22:08:48Z,2018-02-08T22:08:48Z,"Well, all contributions are always welcome and encouraged! Feel free to open a PR if you can.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2NDI2NTI2Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/399,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NDk3NzQ0Mg==,incubator-stormcrawler,394977442,399,NA,noerw,7880552,Norwin,,NA,2018-06-06T07:57:54Z,2018-06-06T07:57:54Z,"I would be interested in the RegEx filter per URL as well (I have a URL specific domain white- / blacklist in mind). I could possibly provide an implementation, but I would need to get familiar with the codebase first.

Also: I tried to use `metadata.max.depth` (set to `3` for each URL), and noticed that Metadata only seems to accept Strings and Lists of Strings. So this option only works if the value is passed as String (`""3""`).
Is that intended? It seems rather counter intuitive.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NDk3NzQ0Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/399,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NTA2MjE4NQ==,incubator-stormcrawler,395062185,399,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-06-06T13:08:53Z,2018-06-06T13:08:53Z,"Hi @noerw, thanks for your feedback. Why would you like to pass the url filters via the seed's metadata when you can use the existing URL filter implementations? Setting the rules in the metadata means that you can't modify them afterwards (or it would be very difficult) and you'd be making the status index a lot heavier. With the existing implementation, you can at least rebuild the jar and restart the topology.
What I might implement instead is a new implementation of the URL filter based on a JSON file and organised per hostname or domain, with #569 we'll even be able to refresh the resources from ES without restarting the topology.

> Also: I tried to use metadata.max.depth (set to 3 for each URL), and noticed that Metadata only seems to accept Strings and Lists of Strings. So this option only works if the value is passed as String (""3"").

Not clear what you mean. Either you set the max depth in the config of the MaxDepthFilter which will take an int and will work for all the seeds, or you specify it in the seeds file as key value and you should not need an quotes
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NTA2MjE4NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/399,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NTA2NDgxOQ==,incubator-stormcrawler,395064819,399,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-06-06T13:17:34Z,2018-06-06T13:17:34Z,see #578 ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NTA2NDgxOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/399,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NTA4MzIzNg==,incubator-stormcrawler,395083236,399,NA,noerw,7880552,Norwin,,NA,2018-06-06T14:12:53Z,2018-06-06T14:12:53Z,"Thanks for the quick reply!
> Not clear what you mean. Either you set the max depth in the config of the MaxDepthFilter which will take an int and will work for all the seeds, or you specify it in the seeds file as key value and you should not need an quotes

I don't have a seeds file, but get my seed URLs from Elasticsearch, where they are [inserted with custom metadata](https://github.com/52North/ecmwf-dataset-crawl/blob/master/controller/src/elastic/controllers/crawls.ts#L65-L77). Inserting `max.depth` as String works fine, while integers throw:
```js
Caused by: java.lang.ClassCastException: java.base/java.lang.Integer cannot be cast to java.base/java.util.List
        at com.digitalpebble.stormcrawler.elasticsearch.persistence.AbstractSpout.fromKeyValues(AbstractSpout.java:374) ~[crawler-alpha.jar:?]
        at com.digitalpebble.stormcrawler.elasticsearch.persistence.AggregationSpout.onResponse(AggregationSpout.java:247) ~[crawler-alpha.jar:?]
        at com.digitalpebble.stormcrawler.elasticsearch.persistence.AggregationSpout.onResponse(AggregationSpout.java:71) [crawler-alpha.jar:?]
        at org.elasticsearch.client.RestHighLevelClient$1.onSuccess(RestHighLevelClient.java:546) [crawler-alpha.jar:?]
```
**edit:**
> Why would you like to pass the url filters via the seed's metadata when you can use the existing URL filter implementations? [...] What I might implement instead is a new implementation of the URL filter based on a JSON file and organised per hostname or domain

I outlined my use case in https://github.com/DigitalPebble/storm-crawler/issues/578#issuecomment-395083901. Your proposed solution would work just as well for that use case and is far more efficient!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NTA4MzIzNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/399,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NTEwODkzMw==,incubator-stormcrawler,395108933,399,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-06-06T15:23:33Z,2018-06-06T15:23:33Z,"OK, thanks for the explanation about the depth as integer. Metadata in SC are <String,String[]> and the mapping in ES reflects that. If all your seeds use the same max depth, it would make sense to simply configure the MaxDepthFilter.

Closing the issue as we won't implement the mechanism suggested","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NTEwODkzMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/400,https://api.github.com/repos/apache/incubator-stormcrawler/issues/400,incubator-stormcrawler,198747433,400,Limit fetch to seed list,Laurent-Hervaud,20163356,Laurent Hervaud,,CLOSED,2017-01-04T16:20:27Z,2017-01-06T13:34:05Z,"I not found good way to limit my crawl to my seed list :
 - in MaxDepthFilter ""maxDepth"": 0 not working (0 value same as empty, better -1 ?)
 - in HostURLFilter, nothing for ignoreInsideHost (inlinks)

I found a trick with RegexURLFilter : 
\# ignore all
-.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/400/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/400,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDYwNjQ5MQ==,incubator-stormcrawler,270606491,400,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-05T09:58:26Z,2017-01-05T09:58:26Z,"Hi @Laurent-Hervaud, thanks for your comments

`parser.emitOutlinks: false` does exactly that for the JSoupParserBolt, as for the redirections you can prevent them with `redirections.allowed: false`

What you are trying to achieve can also be done by the topology itself i.e. disconnecting all inputs on the status streams going to the status updater bolt (assuming you are using one).

I take your point about maxdepth filter - it should use -1 and treat 0 as a no follow. Feel free to open a new issue for this.

Thanks



","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDYwNjQ5MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/400,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDY2Mjg5NQ==,incubator-stormcrawler,270662895,400,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-05T14:56:12Z,2017-01-05T14:56:12Z,"Closing for now, feel free to reopen it","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDY2Mjg5NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/400,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDg3NDU3Mg==,incubator-stormcrawler,270874572,400,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-06T10:23:03Z,2017-01-06T10:23:03Z,"@Laurent-Hervaud, I have implemented your suggestion for the handling of 0 in maxdepth filter. See [f46b1ab], this should deal with both outlinks and redirs. Could you please give it a try (and also confirm that the solution I gave yesterday also works)?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDg3NDU3Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/400,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDg4MjkxMA==,incubator-stormcrawler,270882910,400,NA,Laurent-Hervaud,20163356,Laurent Hervaud,,NA,2017-01-06T11:09:11Z,2017-01-06T11:09:11Z,"Hi @jnioche 
It's not working is masdept > -1. It's like metadata.track.depth was false ? No depth in ES status index
I think there is problem in /util/MetadataTransfer.java line 162.

It's ok for the solution with parser.emitOutlinks: false","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDg4MjkxMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/400,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDg4NzMyNA==,incubator-stormcrawler,270887324,400,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-06T11:36:52Z,2017-01-06T11:36:52Z,"Thanks @Laurent-Hervaud 

I've fixed a bug in [8bbc551] and added a test class. Would you mind giving it another try? Thanks","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDg4NzMyNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/400,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDkwNDA3Ng==,incubator-stormcrawler,270904076,400,NA,Laurent-Hervaud,20163356,Laurent Hervaud,,NA,2017-01-06T13:34:05Z,2017-01-06T13:34:05Z,"I confirm that's all is working (maxdept -1;0;1)
Good job @jnioche !","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDkwNDA3Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/401,https://api.github.com/repos/apache/incubator-stormcrawler/issues/401,incubator-stormcrawler,199046545,401,Malformed escape pair,MyraBaba,17505439,,,CLOSED,2017-01-05T20:05:52Z,2017-01-09T17:00:28Z,"In our crawl test we found that some of the urls didnt fully encoded for fetch. We have below errors.

I assume is coming from '%' .

FYI
FetcherBolt [ERROR] Exception while fetching http://www.hurriyet.com.tr/index/?d=20160328&p=13&s=ni%u011fde
java.lang.IllegalArgumentException: Malformed escape pair at index 54: http://www.hurriyet.com.tr/index/?d=20160328&p=13&s=ni%u011fde
	at java.net.URI.create(URI.java:852) ~[?:1.8.0_111]
	at org.apache.http.client.methods.HttpGet.<init>(HttpGet.java:69) ~[stormjar.jar:?]
	at com.digitalpebble.stormcrawler.protocol.httpclient.HttpProtocol.getProtocolOutput(HttpProtocol.java:130) ~[stormjar.jar:?]
	at com.digitalpebble.stormcrawler.bolt.FetcherBolt$FetcherThread.run(FetcherBolt.java:493) [stormjar.jar:?]
Caused by: java.net.URISyntaxException: Malformed escape pair at index 54: http://www.hurriyet.com.tr/index/?d=20160328&p=13&s=ni%u011fde
	at java.net.URI$Parser.fail(URI.java:2848) ~[?:1.8.0_111]
	at java.net.URI$Parser.scanEscape(URI.java:2978) ~[?:1.8.0_111]
	at java.net.URI$Parser.scan(URI.java:3001) ~[?:1.8.0_111]
	at java.net.URI$Parser.checkChars(URI.java:3019) ~[?:1.8.0_111]
	at java.net.URI$Parser.parseHierarchical(URI.java:3111) ~[?:1.8.0_111]
	at java.net.URI$Parser.parse(URI.java:3053) ~[?:1.8.0_111]
	at java.net.URI.<init>(URI.java:588) ~[?:1.8.0_111]
	at java.net.URI.create(URI.java:850) ~[?:1.8.0_111]
	... 3 more
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/401/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/401,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDg2ODI5Ng==,incubator-stormcrawler,270868296,401,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-06T09:50:44Z,2017-01-06T09:50:44Z,"You should use the BasicURLNormalizer \: it will check whether a URL is a valid URI before adding it to the index. I've just committed a change to it [96c5a04] which dumps the original URL before normalization.

We can't do much to fix the problem - if it's due to some incorrect normalization - unless we know the original form of the URL. Any chance you could rerun the crawl and look for 'Invalid URI ' in the logs? Alternatively, if you track the path, you should be able to look for it in the status index if you use ES and then by looking at the content of the page the outlink was found in, we could find out what the original URL was. Thanks!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDg2ODI5Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/401,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDkwNzYzMg==,incubator-stormcrawler,270907632,401,NA,MyraBaba,17505439,,,NA,2017-01-06T13:56:42Z,2017-01-06T13:56:42Z,"I can give you to acces to ES head plugin access for your investigation if you want to your private email.

 There is almost 2M url from storm crawler bot fetched and error.



> On 6 Oca 2017, at 12:50, Julien Nioche <notifications@github.com> wrote:
> 
> You should use the BasicURLNormalizer : it will check whether a URL is a valid URI before adding it to the index. I've just committed a change to it [96c5a04 <https://github.com/DigitalPebble/storm-crawler/commit/96c5a04d67e9636c2d33c101c3bc0725435463fc>] which dumps the original URL before normalization.
> 
> We can't do much to fix the problem - if it's due to some incorrect normalization - unless we know the original form of the URL. Any chance you could rerun the crawl and look for 'Invalid URI ' in the logs? Alternatively, if you track the path, you should be able to look for it in the status index if you use ES and then by looking at the content of the page the outlink was found in, we could find out what the original URL was. Thanks!
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub <https://github.com/DigitalPebble/storm-crawler/issues/401#issuecomment-270868296>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AQscn8ENLT6tx6C0cCIGWJ94qWcizVopks5rPg51gaJpZM4LcEtV>.
> 

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDkwNzYzMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/401,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDkxNDg2OQ==,incubator-stormcrawler,270914869,401,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-06T14:35:01Z,2017-01-06T14:35:01Z,"I could have a quick look. Do you have Kibana installed?
There are many reasons why URLs can get an error status e.g. prevented by robots.txt 
Please send to stormcrawler@digitalpebble.com
Thanks","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDkxNDg2OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/401,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDkxNjk0Ng==,incubator-stormcrawler,270916946,401,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-06T14:44:33Z,2017-01-06T14:44:33Z,"```json
{
""_index"": ""status"",
""_type"": ""status"",
""_id"": ""0865f11138e80af308041532ed4f8e04cec228d9f749e8c5a82a0ce7fc5f56ad"",
""_version"": 4,
""_score"": 1,
""_routing"": ""www.hurriyet.com.tr"",
""_source"": {
""url"": ""http://www.hurriyet.com.tr/index/?d=20160328&p=13&s=ni%u011fde"",
""status"": ""FETCH_ERROR"",
""metadata"": {
""url%2Epath"": [
""http://www.hurriyet.com.tr/index/?d=20160328&p=13""
],
""depth"": [
""1""
],
""fetch%2Eerror%2Ecount"": [
""2""
],
""hostname"": ""www.hurriyet.com.tr""
},
""nextFetchDate"": ""2017-01-06T07:35:51.112Z""
}
}
```

the originating page contains 
```
<a href=""http://www.hurriyet.com.tr/index/?d=20160328&amp;p=13&amp;s=ni%u011fde""
```

will have a closer look later","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDkxNjk0Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/401,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDkyMDU1Nw==,incubator-stormcrawler,270920557,401,NA,MyraBaba,17505439,,,NA,2017-01-06T15:00:01Z,2017-01-06T15:00:01Z,"My humble idea is its caused from ‘%’  sign is not encoded …  

Browser can resolve it but as you know using java.URL like visiting the Queen at the Buckingham Palace. :)  

> On 6 Oca 2017, at 17:44, Julien Nioche <notifications@github.com> wrote:
> 
> {
> ""_index"": ""status"",
> ""_type"": ""status"",
> ""_id"": ""0865f11138e80af308041532ed4f8e04cec228d9f749e8c5a82a0ce7fc5f56ad"",
> ""_version"": 4,
> ""_score"": 1,
> ""_routing"": ""www.hurriyet.com.tr"",
> ""_source"": {
> ""url"": ""http://www.hurriyet.com.tr/index/?d=20160328&p=13&s=ni%u011fde"",
> ""status"": ""FETCH_ERROR"",
> ""metadata"": {
> ""url%2Epath"": [
> ""http://www.hurriyet.com.tr/index/?d=20160328&p=13""
> ],
> ""depth"": [
> ""1""
> ],
> ""fetch%2Eerror%2Ecount"": [
> ""2""
> ],
> ""hostname"": ""www.hurriyet.com.tr""
> },
> ""nextFetchDate"": ""2017-01-06T07:35:51.112Z""
> }
> }
> the originating page contains
> 
> <a href=""http://www.hurriyet.com.tr/index/?d=20160328&amp;p=13&amp;s=ni%u011fde""
> will have a closer look later
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub <https://github.com/DigitalPebble/storm-crawler/issues/401#issuecomment-270916946>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AQscnzHKBHy4fKYfnv3bFutfbE7lU5HYks5rPlNTgaJpZM4LcEtV>.
> 

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDkyMDU1Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/401,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTI1OTE1OQ==,incubator-stormcrawler,271259159,401,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-09T11:08:03Z,2017-01-09T11:08:03Z,"See https://en.wikipedia.org/wiki/Percent-encoding#Non-standard_implementations

> There exists a non-standard encoding for Unicode characters: %uxxxx, where xxxx is a UTF-16 code unit represented as four hexadecimal digits. 

In your case the character ğ is represented with in the `%u011f` sequence by the server, which is non-standard way of encoding. The correct representation should be '%C4%9F`. 

I'll fix this shortly.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTI1OTE1OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/401,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTI3MjU0Mw==,incubator-stormcrawler,271272543,401,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-09T12:27:01Z,2017-01-09T12:27:01Z,"Fixed in [master d79a076] URLNormalizer : Decode non-standard percent encoding prior to re-encoding

Thanks @MyraBaba for reporting this, could you please give it a try? BTW make sure your topology contains the BasicURLNormalizer.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTI3MjU0Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/401,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTM0MDE3Ng==,incubator-stormcrawler,271340176,401,NA,MyraBaba,17505439,,,NA,2017-01-09T16:57:59Z,2017-01-09T16:57:59Z,"I will give a try soon .. We have now -27 Celsius degree here..  :))

not much time recent days. Feeding almost 100+ animals living in the nature . Mostly carrying warm food to them..

I will also few question and confusing point . I will also address them which I believe usefull for others also.

thx


> On 9 Oca 2017, at 15:27, Julien Nioche <notifications@github.com> wrote:
> 
> Fixed in [master d79a076 <https://github.com/DigitalPebble/storm-crawler/commit/d79a076e78c071ded8c2473d3827aa9c74c7538c>] URLNormalizer : Decode non-standard percent encoding prior to re-encoding
> 
> Thanks @MyraBaba <https://github.com/MyraBaba> for reporting this, could you please give it a try? BTW make sure your topology contains the BasicURLNormalizer.
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub <https://github.com/DigitalPebble/storm-crawler/issues/401#issuecomment-271272543>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AQscnyXvdlo8AXxEU0LNuZYQyJwgznjvks5rQieWgaJpZM4LcEtV>.
> 

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTM0MDE3Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/401,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTM0MDg1MA==,incubator-stormcrawler,271340850,401,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-09T17:00:27Z,2017-01-09T17:00:27Z,"> not much time recent days. Feeding almost 100+ animals living in the nature . Mostly carrying warm food to them..

I am intrigued :-)

> I will also few question and confusing point . I will also address them which I believe usefull for others also.

please use stackoverflow with the tag 'stormcrawler' for general questions

Thanks

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTM0MDg1MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/402,https://api.github.com/repos/apache/incubator-stormcrawler/issues/402,incubator-stormcrawler,199177069,402,Reinitialize depth to 1 when changing host or domain,Laurent-Hervaud,20163356,Laurent Hervaud,,CLOSED,2017-01-06T11:23:52Z,2017-01-09T10:02:24Z,"It wood be a good improvement the possibility to have a parameter for reinitalize the depth metadata when the outlink change host or domain.
In this case we can control depth by host or domain and not only from the seed list.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/402/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/402,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTI0NjkwNA==,incubator-stormcrawler,271246904,402,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-09T10:02:19Z,2017-01-09T10:02:19Z,"You could extend [MetadataTransfer](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/util/MetadataTransfer.java) for that. There would probably be subtleties to add, like checking whether the target URL correspond to the root of the hostname. It depends on the particular logic of your crawl. Don't think this should be part of the core code though, again, this should be easy to achieve as-is.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTI0NjkwNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/403,https://api.github.com/repos/apache/incubator-stormcrawler/issues/403,incubator-stormcrawler,199183041,403,Error when running storm in local mode without storm installed ,normansuesstrunk,6747520,Norman Süsstrunk,,CLOSED,2017-01-06T12:03:54Z,2017-01-06T12:20:18Z,"After a fresh bootstrap of a stormcrawler project with the mvn archetype command, i tried to run the example with 

```sh
mvn clean compile exec:java -Dexec.mainClass=[package].CrawlTopology -Dexec.args=""-conf crawler-conf.yaml -local""

The app gets started and crashes with the following error: 

``` 
194391 [Thread-7-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down
194401 [Thread-7] INFO  o.a.s.d.supervisor - Copying resources at jar:file:/home/suesstnorma1/.m2/repository/org/apache/storm/flux-core/1.0.2/flux-core-1.0.2.jar!/resources to /tmp/bb8f0408-35d1-4451-b03d-ecd4b18dd7d2/supervisor/stormdist/crawl-1-1483700678/resources
194401 [Thread-7] ERROR o.a.s.event - Error when processing event
java.io.FileNotFoundException: Source 'file:/home/suesstnorma1/.m2/repository/org/apache/storm/flux-core/1.0.2/flux-core-1.0.2.jar!/resources' does not exist
	at org.apache.storm.shade.org.apache.commons.io.FileUtils.checkFileRequirements(FileUtils.java:1405) ~[storm-core-1.0.2.jar:1.0.2]
	at org.apache.storm.shade.org.apache.commons.io.FileUtils.copyDirectory(FileUtils.java:1368) ~[storm-core-1.0.2.jar:1.0.2]
	at org.apache.storm.shade.org.apache.commons.io.FileUtils.copyDirectory(FileUtils.java:1268) ~[storm-core-1.0.2.jar:1.0.2]
	at org.apache.storm.shade.org.apache.commons.io.FileUtils.copyDirectory(FileUtils.java:1237) ~[storm-core-1.0.2.jar:1.0.2]
	at org.apache.storm.daemon.supervisor$fn__9436.invoke(supervisor.clj:1178) ~[storm-core-1.0.2.jar:1.0.2]
	at clojure.lang.MultiFn.invoke(MultiFn.java:243) ~[clojure-1.7.0.jar:?]
	at org.apache.storm.daemon.supervisor$mk_synchronize_supervisor$this__9163$fn__9181.invoke(supervisor.clj:579) ~[storm-core-1.0.2.jar:1.0.2]
	at org.apache.storm.daemon.supervisor$mk_synchronize_supervisor$this__9163.invoke(supervisor.clj:578) ~[storm-core-1.0.2.jar:1.0.2]
	at org.apache.storm.event$event_manager$fn__8735.invoke(event.clj:40) [storm-core-1.0.2.jar:1.0.2]
	at clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_111]
194408 [Thread-7] ERROR o.a.s.util - Halting process: (""Error when processing an event"")
java.lang.RuntimeException: (""Error when processing an event"")
	at org.apache.storm.util$exit_process_BANG_.doInvoke(util.clj:341) [storm-core-1.0.2.jar:1.0.2]
	at clojure.lang.RestFn.invoke(RestFn.java:423) [clojure-1.7.0.jar:?]
	at org.apache.storm.event$event_manager$fn__8735.invoke(event.clj:48) [storm-core-1.0.2.jar:1.0.2]
	at clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_111]
```

I cleaned my local maven repo and re-executed, but it did not help. 

Many thanks","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/403/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/403,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDg5MTcyNA==,incubator-stormcrawler,270891724,403,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-06T12:08:15Z,2017-01-06T12:08:15Z,"Hi @normansuesstrunk 

This is a known issue, see #324

I will remove the instructions from the README generated by the archetype. You will need to install Storm to run StormCrawler.

Thanks!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDg5MTcyNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/403,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDg5MzAwMQ==,incubator-stormcrawler,270893001,403,NA,normansuesstrunk,6747520,Norman Süsstrunk,,NA,2017-01-06T12:17:47Z,2017-01-06T12:17:47Z,many thanks. i searched through the issues but i missed that one. sorry for that. ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDg5MzAwMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/403,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDg5MzMxMw==,incubator-stormcrawler,270893313,403,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-06T12:20:18Z,2017-01-06T12:20:18Z,"no problem, this is a useful reminder for me to fix the README file! thanks!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MDg5MzMxMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/404,https://api.github.com/repos/apache/incubator-stormcrawler/issues/404,incubator-stormcrawler,199497449,404,AbstractSpout -Fail,kanwarkakkar,18175033,Kanwarjeet singh,,CLOSED,2017-01-09T08:18:35Z,2017-01-18T10:27:13Z,"I am using AggregationSpout and sometimes crawler fails for certain domains  and is unpredictable. I am using 50 Fetcher threads and FetcherBolt ( Instead of SimpleFetcherBolt)
Here is the log 
```
519405 [elasticsearch[Pyro][listener][T#1]] INFO  c.d.s.e.p.AggregationSpout -  ES query returned 76 hits from 50 buckets in 4 msec with 76 already being processed
1519879 [Thread-50-spout-executor[17 17]] INFO  c.d.s.e.p.AbstractSpout -   Fail for https://www.godaddy.com
1519879 [Thread-50-spout-executor[17 17]] INFO  c.d.s.e.p.AbstractSpout -   Fail for https://se.godaddy.com/email/professional-email
1519879 [Thread-50-spout-executor[17 17]] INFO  c.d.s.e.p.AbstractSpout -   Fail for https://fi.godaddy.com
1519879 [Thread-50-spout-executor[17 17]] INFO  c.d.s.e.p.AbstractSpout -   Fail for https://pe.godaddy.com/websites/free-domain
1519879 [Thread-50-spout-executor[17 17]] INFO  c.d.s.e.p.AbstractSpout -   Fail for https://dk.godaddy.com
1519879 [Thread-50-spout-executor[17 17]] INFO  c.d.s.e.p.AbstractSpout -   Fail for https://nl.godaddy.com/email/professional-email
1519879 [Thread-50-spout-executor[17 17]] INFO  c.d.s.e.p.AbstractSpout -   Fail for https://ar.godaddy.com
1519879 [Thread-50-spout-executor[17 17]] INFO  c.d.s.e.p.AbstractSpout -   Fail for https://pe.auctions.godaddy.com/trppricing.aspx
1519879 [Thread-50-spout-executor[17 17]] INFO  c.d.s.e.p.AbstractSpout -   Fail for http://www.djubo.com/hotel-case-study/colonels-retreat.html
1519879 [Thread-50-spout-executor[17 17]] INFO  c.d.s.e.p.AbstractSpout -   Fail for https://pt.godaddy.com
1519879 [Thread-50-spout-executor[17 17]] INFO  c.d.s.e.p.AbstractSpout -   Fail for https://hk.godaddy.com/en
1519879 [Thread-50-spout-executor[17 17]] INFO  c.d.s.e.p.AbstractSpout -   Fail for https://pe.godaddy.com/hosting
1519879 [Thread-50-spout-executor[17 17]] INFO  c.d.s.e.p.AbstractSpout -   Fail for https://ph.godaddy.com
1519879 [Thread-50-spout-executor[17 17]] INFO  c.d.s.e.p.AbstractSpout -   Fail for https://kr.auctions.godaddy.com
1519879 [Thread-50-spout-executor[17 17]] INFO  c.d.s.e.p.AbstractSpout -   Fail for https://www.godaddy.com/es
1519879 [Thread-50-spout-executor[17 17]] INFO  c.d.s.e.p.AbstractSpout -   Fail for https://id.godaddy.com
1519880 [Thread-50-spout-executor[17 17]] INFO  c.d.s.e.p.AbstractSpout -   Fail for https://fr.godaddy.com

```","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/404/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/404,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTI0NTc2Mg==,incubator-stormcrawler,271245762,404,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-09T09:56:32Z,2017-01-09T09:56:32Z,"Hi. What the logs mean is that you are getting timeouts for these URLs. Storm has a timeout threshold after which the fail method of the spout is called on the corresponding tuples e.g. so that they can be replayed.
There is nothing wrong with the spout itself. What the logs also indicate is that all the URLs that are being pulled from the status index are already being processed. This confirms the assumption that something is clogging the topology.
Use the UI to see which component is blocking and check the metrics and logs. Good luck! ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTI0NTc2Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/404,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTI1MDI3OA==,incubator-stormcrawler,271250278,404,NA,kanwarkakkar,18175033,Kanwarjeet singh,,NA,2017-01-09T10:20:31Z,2017-01-09T10:20:31Z,"Thanks for the comments, will look into the problem.
Edit: I had something that was blocking the Fetcher bolt. Figured it out.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTI1MDI3OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/405,https://api.github.com/repos/apache/incubator-stormcrawler/issues/405,incubator-stormcrawler,199821421,405,org.apache.http.NoHttpResponseException: The target server failed to respond,Laurent-Hervaud,20163356,Laurent Hervaud,,CLOSED,2017-01-10T13:29:47Z,2020-07-15T16:22:24Z,"I have a lot of FETCH_ERROR (about ten percent on one million french url).
On debug i can see this error : org.apache.http.NoHttpResponseException: The target server failed to respond
Sometimes, it's working after many retries ?
Here some of the url :
http://www.serigraph-herault.fr/
http://www.courtage-mayenne.fr/
http://www.alur-diagnostics-sete.fr/
Is there something wrong with HttpProtocol.java and org.apache.http.impl.client.HttpClients ?
I purchase my investigations","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/405/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/405,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTU4Mzg2Ng==,incubator-stormcrawler,271583866,405,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-10T14:08:04Z,2017-01-10T14:08:04Z,Could it be that you are at the limits of your bandwidth? How many fetch threads are you using?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTU4Mzg2Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/405,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTYwMzc3Mg==,incubator-stormcrawler,271603772,405,NA,Laurent-Hervaud,20163356,Laurent Hervaud,,NA,2017-01-10T15:23:26Z,2017-01-10T15:23:26Z,"I was thinking that first, but i have the same error with just 1 url in the seed list","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTYwMzc3Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/405,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTYwNzE5OA==,incubator-stormcrawler,271607198,405,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-10T15:34:53Z,2017-01-10T15:34:53Z,The 3 sites you mentioned earlier all point to the same server (193.252.138.58). Could it be that you got blacklisted by them? ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTYwNzE5OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/405,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTgwMDQ1NA==,incubator-stormcrawler,271800454,405,NA,Laurent-Hervaud,20163356,Laurent Hervaud,,NA,2017-01-11T07:46:40Z,2017-01-11T07:46:40Z,"I know for the same server. It's the first web hosting company in France for professionnal.
I try multiple test in local and on aws for blacklist. All is working with a simple curl. I also try with Nutch and it's working. I also try multiple user agent.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTgwMDQ1NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/405,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTg0NTk4Mw==,incubator-stormcrawler,271845983,405,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-11T11:31:45Z,2017-01-11T11:31:45Z,"I can't reproduce the issue.

```
6493 [FetcherThread] INFO  c.d.s.b.FetcherBolt - [Fetcher #3] Fetched http://www.serigraph-herault.fr/ with status 200 in msec 363
6521 [FetcherThread] INFO  c.d.s.b.FetcherBolt - [Fetcher #3] Fetched http://www.alur-diagnostics-sete.fr/ with status 200 in msec 393
6530 [FetcherThread] INFO  c.d.s.b.FetcherBolt - [Fetcher #3] Fetched http://www.courtage-mayenne.fr/ with status 200 in msec 402
```","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTg0NTk4Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/405,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTg3Mzc5OA==,incubator-stormcrawler,271873798,405,NA,Laurent-Hervaud,20163356,Laurent Hervaud,,NA,2017-01-11T13:53:56Z,2017-01-11T13:53:56Z,"I found the mistake in HttpProtocol.java by enabling AutomaticRetries :
        builder = HttpClients.custom().setUserAgent(userAgent)
                .setConnectionManager(CONNECTION_MANAGER)
                .setConnectionManagerShared(true).disableRedirectHandling();
        //.disableAutomaticRetries();

Here the result log :
12932 [Thread-48-fetch-executor[14 14]] INFO  o.a.h.i.e.RetryExec - I/O exception (org.apache.http.NoHttpResponseException) caught when processing request to {}->http://www.serigraph-herault.fr:80: The target server failed to respond
12933 [Thread-48-fetch-executor[14 14]] INFO  o.a.h.i.e.RetryExec - Retrying request to {}->http://www.serigraph-herault.fr:80
13300 [Thread-48-fetch-executor[14 14]] INFO  c.d.s.b.SimpleFetcherBolt - [Fetcher #14] Fetched http://www.serigraph-herault.fr with status 200 in 371 after waiting 0

Why disabling AutomaticRetries and RedirectHandling ?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTg3Mzc5OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/405,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTg4MDU3Ng==,incubator-stormcrawler,271880576,405,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-11T14:22:33Z,2017-01-11T14:22:33Z,"I would not call that a mistake. Retrying the URL does not explain why it failed in the first place, as you pointed out initially, it worked after retrying

> Why disabling AutomaticRetries and RedirectHandling ?
1. retries -> because we want to control politeness and to be efficient, there is no point trying again right away when it is likely that it will fail, when we could be fetching from a different server
2. redirect -> politeness again and also the target URL could already be known and perhaps even fetched 

you can set the schedule for fetch_errors to a low value so that the URL gets eligible for re-fetching soon.

It would be interesting to know why it fails on the first attempt.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MTg4MDU3Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/405,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MjQyOTA0Mw==,incubator-stormcrawler,272429043,405,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-13T12:08:56Z,2017-01-13T12:08:56Z,Closing for now. Please reopen if necessary.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MjQyOTA0Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/405,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NDY4NDMyMA==,incubator-stormcrawler,284684320,405,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-07T10:35:29Z,2017-03-07T10:35:29Z,"Note for self\: seeing the same problem with 
- http://www.ancestry.com/
- http://www.onlinesbi.com/

The explanation can be found here
http://stackoverflow.com/questions/10558791/apache-httpclient-interim-error-nohttpresponseexception

The issue does not happen when specifying `http.skip.robots=true`, my interpretation of this is that the server closes the connection prematurely when we try to get the robots and when we query for the main URL straight away, we get this issue.  

Setting a retry value at the protocol level is one possible solution but as pointed out earlier such URLs get retried by stormcrawler later on anyway - with the politeness.

A better approach is suggested in http://stackoverflow.com/questions/10570672/get-nohttpresponseexception-for-load-testing/10680629 i.e. set a lower validate-before-reuse time

```
connectionManager = new PoolingHttpClientConnectionManager();
connectionManager.setValidateAfterInactivity(connectionValidateLimit);
```

but even if we set a low value for setValidateAfterInactivity(), this would not get applied unless we applied the politeness setting between the call to robots.txt and the fetching of the URL, for which I had opened (and closed) #343.

As a quick test, I added a call to Thread.sleep call to the HttpRobotRulesParser for a few seconds and the fetches were successful after that! I will reopen #343 but make the behavior configurable. Ideally, the FetcherBolt could - if configured to be polite after querying robots - pop the URL back into the queue and deal with another queue until the politeness delay has passed. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NDY4NDMyMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/405,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM4NTc4OTkxNQ==,incubator-stormcrawler,385789915,405,NA,abhishekransingh,14769750,Abhishek,,NA,2018-05-01T21:04:37Z,2018-05-01T21:04:37Z,"Another way to retry is if you're using Spring, then you can use @Retryable. Here is the code snippet:

> 	@Retryable(maxAttemptsExpression =  ""#{${startup.job.max.try}}"", 
			   value = {NoHttpResponseException.class}, 
			   backoff = @Backoff(delayExpression = ""#{${startup.job.delay}}"", multiplierExpression = ""#{${startup.job.multiplier}}""))
	public void callHttpEndpint() throws IOException  {
//Your code to call HTTP REST Endpoint here
}
>","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM4NTc4OTkxNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/405,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUwMTM2MzU4OQ==,incubator-stormcrawler,501363589,405,NA,ade90036,6196152,,,NA,2019-06-12T16:56:05Z,2019-06-12T16:56:05Z,@jnioche why robot.txt has anything to do with this issue? Is the underline httpclient trying too had to be smart?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUwMTM2MzU4OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/405,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1ODg2MjA2Mg==,incubator-stormcrawler,658862062,405,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-07-15T16:22:24Z,2020-07-15T16:22:24Z,"Can't reproduce the problem, probably fixed itself by upgrading the version of httpclient","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1ODg2MjA2Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/408,https://api.github.com/repos/apache/incubator-stormcrawler/issues/408,incubator-stormcrawler,201265195,408,Add cleanup() method to protocol implementations,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-01-17T12:26:18Z,2017-01-17T12:46:14Z,as well as ProtocolFactory and call it from the cleanup method of the FetcherBolts. This will give the protocol implementations a chance of releasing any external resources. ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/408/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/409,https://api.github.com/repos/apache/incubator-stormcrawler/issues/409,incubator-stormcrawler,201535179,409,Sitemap file not detected,kanwarkakkar,18175033,Kanwarjeet singh,,CLOSED,2017-01-18T10:35:25Z,2017-01-18T16:03:16Z,"I am trying to crawl sitemap with extension .xml.  e.g https://keywordcountry.com/sitemap.xml but it is not parsing the sitemap. After debugging I found out in [SiteMapParserBolt.java ](https://github.com/DigitalPebble/storm-crawler/blob/b1d942ed1f1e8807baa5c46d0fa159e03693c28c/core/src/main/java/com/digitalpebble/stormcrawler/bolt/SiteMapParserBolt.java) at line number 104  **Bytes.indexOf(beginning, clue)**  is returning **-1** and not processing it further. In JSoupParserBolt.java it is giving exception of content type application/xml","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/409/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/409,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MzQ2MDI2Mw==,incubator-stormcrawler,273460263,409,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-18T12:14:07Z,2017-01-18T12:14:07Z,"hi @kanwarkakkar 

The explanation for this is that the the SitemapParserBolt can't guess that the file is a sitemap because the clue it uses (_http://www.sitemaps.org/schemas/sitemap/0.9_) is located beyond the 200 chars limit. We could change this to a higher value and/or make it configurable or add different clues e.g. if file is named sitemap.xml.

The exception is JSoupParserBolt is expected.

There are already a number of things you can do to fix the problem. First, make sure `isSitemap` is listed in `metadata.persist`

1. if your seed file lists this particular URL then you can add the key value _isSitemap=true_ separated from the URL by a tab
2. if not, set 'sitemapsAutoDiscovery: true' in the config, this will persist _isSitemap=true_ and discover any sitemaps from the robots.txt

I'll add an additional clue to the detection and make the char limit greater and configurable.

Thanks
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MzQ2MDI2Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/409,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MzUxNzA1Ng==,incubator-stormcrawler,273517056,409,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-18T16:03:16Z,2017-01-18T16:03:16Z,@kanwarkakkar I made the offset configurable. Decided not to add the clue based on the filename in the end. ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3MzUxNzA1Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/411,https://api.github.com/repos/apache/incubator-stormcrawler/issues/411,incubator-stormcrawler,201876321,411,Simplify pom files for modules,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-01-19T14:33:00Z,2017-01-19T14:41:59Z,"They all contain something like 

```xml

	<build>
		<plugins>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-compiler-plugin</artifactId>
			</plugin>
		</plugins>
	</build>

	<profiles>
		<profile>
			<id>release</id>
			<build>
				<plugins>
					<plugin>
						<groupId>org.apache.maven.plugins</groupId>
						<artifactId>maven-source-plugin</artifactId>
					</plugin>

					<!-- no test jar for storm-crawler-external -->
					<plugin>
						<groupId>org.apache.maven.plugins</groupId>
						<artifactId>maven-jar-plugin</artifactId>
						<version>2.5</version>
						<executions>
							<execution>
								<id>attach-test</id>
								<phase>none</phase>
							</execution>
						</executions>
					</plugin>

					<plugin>
						<groupId>org.apache.maven.plugins</groupId>
						<artifactId>maven-javadoc-plugin</artifactId>
					</plugin>
				</plugins>
			</build>
		</profile>
	</profiles>

	<dependencies>

		<dependency>
			<groupId>org.apache.storm</groupId>
			<artifactId>storm-core</artifactId>
		</dependency>

		<dependency>
			<groupId>com.digitalpebble.stormcrawler</groupId>
			<artifactId>storm-crawler-core</artifactId>
			<version>${project.version}</version>
		</dependency>

		<dependency>
			<groupId>junit</groupId>
			<artifactId>junit</artifactId>
		</dependency>
```

instead they should all extend a common parent pom ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/411/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/412,https://api.github.com/repos/apache/incubator-stormcrawler/issues/412,incubator-stormcrawler,201882077,412,Simplify pom for core module,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-01-19T14:54:39Z,2017-01-19T14:55:14Z,The core module currently builds an uber-jar and defines an execute task for Maven. This is not needed now that the topology classes and resources have been moved to the archetype. The core module is just a module like any other one in external.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/412/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/413,https://api.github.com/repos/apache/incubator-stormcrawler/issues/413,incubator-stormcrawler,201888530,413,Avoid duplication of formatting rules,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-01-19T15:18:50Z,2017-01-19T15:19:55Z,"we currently have the formatting rules both at the root of the project but also in the external directory. Now that we have a parent pom file for the external modules, we can change the location of the file in it so that it point to the file at the root.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/413/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/414,https://api.github.com/repos/apache/incubator-stormcrawler/issues/414,incubator-stormcrawler,202504066,414,ES : remove uberjar from build + simplify instructions,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-01-23T11:03:02Z,2017-01-23T12:10:03Z,"The instructions should assume that a fully-formed project has been generated by the archetype, this will help focus on the parts that are specific to ES. We can also remove the topology classes and rely on the Flux files and/or modify the default topology class generated by the archetype.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/414/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/414,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3NDQ3Mjg0Mw==,incubator-stormcrawler,274472843,414,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-23T12:10:03Z,2017-01-23T12:10:03Z,Left the topology classes for injecting and crawling. Might remove them later,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3NDQ3Mjg0Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/415,https://api.github.com/repos/apache/incubator-stormcrawler/issues/415,incubator-stormcrawler,203128453,415,Clear error.cause / error.source after successful refetch/reprocessing,sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2017-01-25T15:08:59Z,2017-01-26T15:34:10Z,"The metadata fields error.cause / error.source should be cleared if the error has disappeared after a successful re-fetch and successful reprocessing (parsing) of a page/document. A status record such as
```
        ""url"" : ""http://www.strandgut.de/aktuell/feed/"",
        ""status"" : ""FETCHED""
        ""hostname"" : ""strandgut.de"",
        ""nextFetchDate"" : ""2017-01-25T13:30:18.000Z"",
        ""metadata"" : {
          ""last-modified"" : [ ""Mon, 23 Jan 2017 10:31:13 UTC"" ],
          ""error%2Ecause"" : [ ""maxFetchErrors"" ],
          ""fetch%2EstatusCode"" : [ ""200"" ],
          ""isFeed"" : [ ""true"" ]
        },
```
does not indicate any error, but a cleared (empty/non-existent) error cause/source field would avoid confusion and simplify aggregation of error types.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/415/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/415,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3NTQxODkwMQ==,incubator-stormcrawler,275418901,415,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2017-01-26T15:34:10Z,2017-01-26T15:34:10Z,Thanks!,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3NTQxODkwMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/416,https://api.github.com/repos/apache/incubator-stormcrawler/issues/416,incubator-stormcrawler,203174762,416,not serializable exception caused by kryo.writeobject(),rch49,25350955,,,CLOSED,2017-01-25T17:49:43Z,2017-01-26T08:19:42Z,"Hi!
I'm writing a storm topology in which the object transmitted between bolds are opencv:Mat. The problem is that these object are not serializable and opencv:MAt are not tansmitted. I've write a custom serialization using kryo. But I'm still getting not serializable exception caused by kryo.writeobject().
Any suggestion Please!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/416/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/416,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3NTI0OTI0MQ==,incubator-stormcrawler,275249241,416,NA,rch49,25350955,,,NA,2017-01-25T22:11:45Z,2017-01-25T22:11:45Z,"this is the exception I'm getting:
java.lang.RuntimeException: java.lang.RuntimeException: java.io.NotSerializableException: org.opencv.core.Mat
        at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:135) ~[storm-core-0.9.6.jar:0.9.6]
        at backtype.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:106) ~[storm-core-0.9.6.jar:0.9.6]
        at backtype.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:80) ~[storm-core-0.9.6.jar:0.9.6]
        at backtype.storm.disruptor$consume_loop_STAR_$fn__1458.invoke(disruptor.clj:94) ~[storm-core-0.9.6.jar:0.9.6]
        at backtype.storm.util$async_loop$fn__460.invoke(util.clj:463) ~[storm-core-0.9.6.jar:0.9.6]
        at clojure.lang.AFn.run(AFn.java:24) [clojure-1.5.1.jar:na]
        at java.lang.Thread.run(Thread.java:745) [na:1.8.0_111]
Caused by: java.lang.RuntimeException: java.io.NotSerializableException: org.opencv.core.Mat
        at backtype.storm.serialization.SerializableSerializer.write(SerializableSerializer.java:41) ~[storm-core-0.9.6.jar:0.9.6]
        at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:501) ~[kryo-2.21.jar:na]
        at com.mycompany.app.DataBeankryo.write(DataBeankryo.java:24) ~[stormjar.jar:na]
        at com.mycompany.app.DataBeankryo.write(DataBeankryo.java:10) ~[stormjar.jar:na]
        at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:568) ~[kryo-2.21.jar:na]
        at com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:75) ~[kryo-2.21.jar:na]
        at com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:18) ~[kryo-2.21.jar:na]
        at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:486) ~[kryo-2.21.jar:na]
        at backtype.storm.serialization.KryoValuesSerializer.serializeInto(KryoValuesSerializer.java:44) ~[storm-core-0.9.6.jar:0.9.6]
        at backtype.storm.serialization.KryoTupleSerializer.serialize(KryoTupleSerializer.java:44) ~[storm-core-0.9.6.jar:0.9.6]
        at backtype.storm.daemon.worker$mk_transfer_fn$fn__4425.invoke(worker.clj:130) ~[storm-core-0.9.6.jar:0.9.6]
        at backtype.storm.daemon.executor$start_batch_transfer__GT_worker_handler_BANG_$fn__3281.invoke(executor.clj:259) ~[storm-core-0.9.6.j$
        at backtype.storm.disruptor$clojure_handler$reify__1445.onEvent(disruptor.clj:58) ~[storm-core-0.9.6.jar:0.9.6]
        at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:132) ~[storm-core-0.9.6.jar:0.9.6]
        ... 6 common frames omitted
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3NTI0OTI0MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/416,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3NTMzMDkzMg==,incubator-stormcrawler,275330932,416,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-01-26T08:19:42Z,2017-01-26T08:19:42Z,This is unrelated to StormCrawler. ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3NTMzMDkzMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/417,https://api.github.com/repos/apache/incubator-stormcrawler/issues/417,incubator-stormcrawler,204798443,417,Receiving org.apache.storm.utils.NimbusLeaderNotFoundException as executed CrawlTopology,isspek,6966175,isspek,,CLOSED,2017-02-02T07:08:02Z,2017-02-02T09:07:58Z,"I created  new StormCrawler-based project by following steps described in [I](https://github.com/DigitalPebble/storm-crawler). Without modifying crawler-confer.yaml, I executed CrawlTopology.java which comes with the project and then I received error as below:

```
org.apache.storm.utils.NimbusLeaderNotFoundException: Could not find leader nimbus from seed hosts [localhost]. Did you specify a valid list of nimbus hosts for config nimbus.seeds?
	at org.apache.storm.utils.NimbusClient.getConfiguredClientAs(NimbusClient.java:90)
	at org.apache.storm.StormSubmitter.topologyNameExists(StormSubmitter.java:371)
	at org.apache.storm.StormSubmitter.submitTopologyAs(StormSubmitter.java:233)
	at org.apache.storm.StormSubmitter.submitTopology(StormSubmitter.java:311)
	at org.apache.storm.StormSubmitter.submitTopology(StormSubmitter.java:157)
	at com.digitalpebble.stormcrawler.ConfigurableTopology.submit(ConfigurableTopology.java:85)
        at com.mycompany.crawler.CrawlTopology.run(CrawlTopology.java:68)
	at com.digitalpebble.stormcrawler.ConfigurableTopology.start(ConfigurableTopology.java:50)
	at com.mycompany.crawler.CrawlTopology.main(CrawlTopology.java:38)
```
I searched Google what the problem causes, it seems related Zookeper. But I am using Tomcat server. What should I do for preventing this error?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/417/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/417,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3Njg5NTk2NA==,incubator-stormcrawler,276895964,417,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2017-02-02T08:26:35Z,2017-02-02T08:26:35Z,"How was the CrawlTopology executed? Normally, the execution is done by Storm:
```
storm jar .../path/to/storm-crawler.jar com.digitalpebble.stormcrawler.CrawlTopology -conf ...
```","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3Njg5NTk2NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/417,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3NjkwMDY1Mg==,incubator-stormcrawler,276900652,417,NA,isspek,6966175,isspek,,NA,2017-02-02T08:52:47Z,2017-02-02T08:52:47Z,"@sebastian-nagel I created it as Maven Project in Eclipse. I wanted to figure out how crawler works. So I executed main method by running as application in Eclipse and then I got these errors. I haven't installed Storm on my machine, because it is already in pom. Should I install it on my machine?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3NjkwMDY1Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/417,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3NjkwMjAxOQ==,incubator-stormcrawler,276902019,417,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-02-02T09:00:00Z,2017-02-02T09:00:00Z,"Add `-local and conf crawler-conf.yaml` as argument to the topology class. You don't have to run it with Storm, it works with Eclipse. If local is not specified, it tries to connect to a Storm cluster and since you haven't installed one you are getting this error","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3NjkwMjAxOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/417,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3NjkwMjM3NA==,incubator-stormcrawler,276902374,417,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2017-02-02T09:01:47Z,2017-02-02T09:01:47Z,The wiki contains a description how to [run the topology locally](https://github.com/DigitalPebble/storm-crawler/wiki/Configuration).,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3NjkwMjM3NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/417,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3NjkwMzY0MA==,incubator-stormcrawler,276903640,417,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-02-02T09:07:58Z,2017-02-02T09:07:58Z,"@sebastian-nagel that wiki page needs fixing. Running with mvn-exec does not work, see #324 

The README file generated by the archetype contains the correct instructions i.e run it with Storm installed (but it also works with Eclipse and is a good way of debugging)","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3NjkwMzY0MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/418,https://api.github.com/repos/apache/incubator-stormcrawler/issues/418,incubator-stormcrawler,204813468,418,Adaptive fetch scheduler: do not compare persisted signatures if HTTP 304 not modified ,sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2017-02-02T08:49:30Z,2017-02-03T16:32:14Z,"If both the current and previous signatures are persisted, [AdaptiveScheduler](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/persistence/AdaptiveScheduler.java) does not consider ""HTTP 304 not modified"" responses. In case, both persisted signatures differ, the document is erroneously considered to have changed.

Seen with the following page:
```
      ""_source"" : {
        ""url"" : ""http://www.africa-live.de/feed/"",
        ""status"" : ""FETCHED"",
        ""metadata"" : {
          ""last-modified"" : [ ""Thu, 02 Feb 2017 08:00:42 UTC"" ],
          ""signature"" : [ ""37fd0574c3f8705fb59e9a42424af5ae"" ],
          ""fetchInterval"" : [ ""90"" ],
          ""isFeed"" : [ ""true"" ],
          ""fetch%2EstatusCode"" : [ ""200"" ],
          ""signatureChangeDate"" : [ ""Thu, 02 Feb 2017 08:00:42 UTC"" ],
          ""signatureOld"" : [ ""c482a2a931d54e3e01e297fa0aed2e46"" ]
        },
```
and the adaptive scheduler detects erroneously that the ""Signature has changed"":
```
2017-02-02 08:45:42.813 c.d.s.b.FetcherBolt [INFO] [Fetcher #8] Fetched http://www.africa-live.de/feed/ with status 304 in msec 661
2017-02-02 08:45:42.815 c.d.s.p.AdaptiveScheduler [DEBUG] Scheduling status: FETCHED, metadata: last-modified: Thu, 02 Feb 2017 08:00:42 UTC
signature: 37fd0574c3f8705fb59e9a42424af5ae
fetchInterval: 90
isFeed: true
fetch.statusCode: 200
signatureChangeDate: Thu, 02 Feb 2017 08:00:42 UTC
signatureOld: c482a2a931d54e3e01e297fa0aed2e46
...
2017-02-02 08:45:42.815 c.d.s.p.AdaptiveScheduler [DEBUG] Signature has changed, fetchInterval decreased from 90 to 90
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/418/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/418,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3NjkwMzgyMg==,incubator-stormcrawler,276903822,418,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2017-02-02T09:08:48Z,2017-02-02T09:08:48Z,There is also a second problem: the HTTP 304 status code isn't passed as metadata `fetch.statusCode` to the AdaptiveScheduler. It's overwritten in FetcherBolt by the persisted status code (here: 200).,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3NjkwMzgyMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/420,https://api.github.com/repos/apache/incubator-stormcrawler/issues/420,incubator-stormcrawler,204988003,420,DefaultSchedule: configuration of custom schedule with status and metadata not deterministic,sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2017-02-02T20:31:32Z,2017-03-03T14:42:56Z,"Custom schedule rules based on status and metadata are prioritized by their order in the configuration file (see [1](https://github.com/DigitalPebble/storm-crawler/commit/cf3e07f58e8656fa62a60112a2950e8c919408f1#diff-a2a0d55a1e9f8b09634a3874b7aa3633R64)). However, the order from the configuration file is not preserved, configuration properties in the configuration map passed to DefaultScheduler.init(Map stormConf) seem to be in random order.

The test units in [DefaultSchedulerTest]() also use a simple HashMap instead of a order-preserving structure. Renaming the metadata key (e.g., to ""aTestKey"") can make the tests fail.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/420/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/420,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3NzIwNjIwMw==,incubator-stormcrawler,277206203,420,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2017-02-03T09:47:51Z,2017-02-03T09:47:51Z,"As a partial work-around one can specify rules for all 4 statuses (FETCHED, REDIRECTION, ERROR, FETCH_ERROR). Of course, this is not solution if a priority between competing metadata keys is desired.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3NzIwNjIwMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/421,https://api.github.com/repos/apache/incubator-stormcrawler/issues/421,incubator-stormcrawler,205158397,421,Seed injectors to normalize String > URL > String,sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2017-02-03T13:34:30Z,2017-02-09T10:46:35Z,"If the round trip conversion String <> java.net.URL yields a different URL string, the crawl topology fails to properly update the status of fetched items. This happens if injected URLs contain trailing white space (cf. commoncrawl/news-crawl#16), but may also affect `file:///` URLs (cf. [NUTCH-1483](https://issues.apache.org/jira/browse/NUTCH-1483?focusedCommentId=14176160&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14176160)).

One solution could be to consequently apply the conversion String > URL > String, esp. in the injectors, or to reject all URLs which would otherwise cause troubles.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/421/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/421,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3NzI5MTU5Ng==,incubator-stormcrawler,277291596,421,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-02-03T16:20:42Z,2017-02-03T16:20:42Z,I was thinking about having a URLFilteringBolt that could be used in front of a status updater. This would be useful when injecting but also for ppl using many instances of SimpleFetcherBolts where each one of them has its own copy of the URL filters.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3NzI5MTU5Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/421,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3NzI5NTc0Mg==,incubator-stormcrawler,277295742,421,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2017-02-03T16:35:58Z,2017-02-03T16:35:58Z,"Good idea, for the injector a minimal filter which just makes sure that the URL string is a valid URL and is preserved as is would be fine. It's hard to figure out what's going wrong if the key is changed on its way through the topology.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3NzI5NTc0Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/421,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3ODYwNzc0NQ==,incubator-stormcrawler,278607745,421,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2017-02-09T10:46:35Z,2017-02-09T10:46:35Z,Thanks! Verified that URLs are filtered and normalized during injection.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI3ODYwNzc0NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/425,https://api.github.com/repos/apache/incubator-stormcrawler/issues/425,incubator-stormcrawler,208734232,425,Provide custom stream grouping to group by host / domain / IP ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-02-19T18:05:09Z,2017-02-20T11:30:27Z,"This would implement CustomStreamGrouping and would simplify cases where we want e.g. one instance of a status updater per shard. Some classes currently handle the sharding internally but it would be more elegant to do that using the stream grouping. This could also be used as an alternative to the URLPartitionerBolt, the spouts would send to the fetchers directly using the custom grouping.

The fields grouping is currently what we use and it works fine but it requires the value to exist as a field for the tuple.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/425/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/426,https://api.github.com/repos/apache/incubator-stormcrawler/issues/426,incubator-stormcrawler,209418941,426,StatusUpdaterBolt expires tuples waiting to be acked ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-02-22T10:57:33Z,2017-02-22T15:43:51Z,There is a possibility that tuples just sit in the wait ack map i.e. they were sent to ES but for some reason never got removed. This would be a bug but to be on the safe side we should use a Guava cache instead just to check that this does not happen. The corresponding tuples would get a timeout anyway but at least we'd be able to track the issue.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/426/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/427,https://api.github.com/repos/apache/incubator-stormcrawler/issues/427,incubator-stormcrawler,209681710,427,Add basic authentication to HTTP protocol,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-02-23T07:08:30Z,2023-12-05T16:21:35Z,We could store the credentials in a file in resources and/or from the tuple metadata. The class to modify is [HttpProtocol](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/protocol/httpclient/HttpProtocol.java),"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/427/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/427,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4MTk2ODQwNQ==,incubator-stormcrawler,281968405,427,NA,isspek,6966175,isspek,,NA,2017-02-23T11:31:51Z,2017-02-23T11:31:51Z,I am working for this issue and I am trying to find proper approach.  Can we use cookies to get authentication to access  the websites which requires authentication in intranet? We might also need cookie management system. ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4MTk2ODQwNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/427,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4MTk3MDgwNw==,incubator-stormcrawler,281970807,427,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-02-23T11:44:00Z,2017-02-23T11:44:00Z,"Great! There is already an open issue for the cookies #32 but we haven't done much work on it yet. Unlike the credentials which could be stored in a file in /resources, the cookies would be persisted like any other metadata and converted back into the objects required by the HTTP client library on the fly. That library has its own implementation of cookie storage but it would be best not to use it I think as we have no guarantee that the same JVM instance will still be alive when the next URL comes round e.g. the worker could have died. Dealing with the cookies purely as test in metadata is also more flexible as they could be passed as seeds metadata.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4MTk3MDgwNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/427,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NjE2Nzc4NQ==,incubator-stormcrawler,286167785,427,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-13T16:47:27Z,2017-03-13T16:47:27Z,@isspek any updates on this? Anything I can help you with? ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NjE2Nzc4NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/427,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NjMyMzc2Mg==,incubator-stormcrawler,286323762,427,NA,isspek,6966175,isspek,,NA,2017-03-14T05:09:35Z,2017-03-14T05:09:35Z,"@jnioche  I couldn't find a proper solution for the website which requires form based authentication. So I really need your advices. 

I have generated cookies in configure of HttpProtocol:

```
cookieStore = new BasicCookieStore();
builder.setDefaultCookieStore(cookieStore);
getAuthorization(Parameters.get(""domain.user""), Parameters.get(""domain.password""));
```

And the getAuthorization function is used to generate cookies by using form based authentication. Currently, I couldn't find a solution for getting the parameters of the forms automatically:

```
private void getAuthorization(String username, String password) {
		AbstractFormBasedAuthentication hba = FormBasedAuthenticationFactory.getAuthenticator();
		hba.authenticate(username, password);
		List<Cookie> cookies = hba.getCookies();
		for (Cookie cookie : cookies) {
			cookieStore.addCookie(cookie);
		}
	}
```
The problem is that it is not generalized approach and the urls must be check whether is required authorization or not before processing. In my opinion the basic credentials and the type of authentication should be given in spout bolt, so we can initialize cookies and stores them in metadata.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NjMyMzc2Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/427,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NjQwMDg1Ng==,incubator-stormcrawler,286400856,427,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-14T12:02:29Z,2017-03-14T12:02:29Z,"This issue is about basic authentication as described in [https://en.wikipedia.org/wiki/Basic_access_authentication]. There is ongoing work on cookies #32, maybe have a look at the exchanges there.

> the basic credentials and the type of authentication should be given in spout bolt, so we can initialize cookies and stores them in metadata.

if you know the cookies in advance then you will be able to pass them in the seed metadata, the outlinks will get whichever cookies are returned by the server and so on.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NjQwMDg1Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/427,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NjQ2MTkxMQ==,incubator-stormcrawler,286461911,427,NA,isspek,6966175,isspek,,NA,2017-03-14T15:41:12Z,2017-03-14T15:41:12Z,"@jnioche btw the form of the website I crawl also contains parameter such as actionflag=... in addition to username and password. Therefore, the solution mentioned in [#432](https://github.com/DigitalPebble/storm-crawler/pull/432) didn't work. So I wrote a class (FormBasedAuthenticationFactory) similar to this one (http://www.mkyong.com/java/apache-httpclient-examples/.) It works but again it is hard coded not generic since  I couldn't get the parameters of the form programmatically. I will implement an approach to give credentials to the seed. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NjQ2MTkxMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/427,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NjQ4MzAyNg==,incubator-stormcrawler,286483026,427,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-14T16:43:55Z,2017-03-14T16:43:55Z,Note to self\: http://www.httpwatch.com/httpgallery/authentication/ contains some live examples we could use to test the authentication,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NjQ4MzAyNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/427,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NjQ4NzYzNA==,incubator-stormcrawler,286487634,427,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-14T16:57:27Z,2017-03-14T16:57:27Z,"@isspek assuming we have the cookie mechanism in place, one way of doing would be to add support for POST requests. This would be triggered by some arbitrary key/value in the metadata, usually for the seeds. you'd then get the cookies you need for the outlinks. This assumes, however, that the page you'll be sending the form to contains the oulinks needed for the crawl.

http://www.baeldung.com/httpclient-post-http-request contains some code illustrating how to do that.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NjQ4NzYzNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/427,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5tvXVN,incubator-stormcrawler,1841132877,427,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-12-05T16:21:35Z,2023-12-05T16:21:35Z,Both the OKHTTP and the Apache HTTPClient support basic authentication,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5tvXVN/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/428,https://api.github.com/repos/apache/incubator-stormcrawler/issues/428,incubator-stormcrawler,209816499,428,Remove mvn exec plugin from archetype pom,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-02-23T16:41:37Z,2017-03-21T16:33:08Z,"as mentioned in the readme the way to launch storm is to have it on the classpath
or see if we can solve #324 ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/428/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/428,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4ODEzNzIzOQ==,incubator-stormcrawler,288137239,428,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-21T16:33:07Z,2017-03-21T16:33:07Z,#324 should be solved. We can leave the mvn exec plugin where it is.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4ODEzNzIzOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/429,https://api.github.com/repos/apache/incubator-stormcrawler/issues/429,incubator-stormcrawler,211036506,429,Aggregation Spouts to use shard request cache ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-03-01T10:18:20Z,2017-04-19T15:11:34Z,"See https://www.elastic.co/guide/en/elasticsearch/reference/2.4/shard-request-cache.html

This would make the aggregations faster but depends on the value of the refresh interval. We'd need to change the logic around the nextFetchDate query so that we reuse an existing value unless it does not return any results. This alone would also make the search faster as we'd query a diminishing set of documents.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/429/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/429,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5MDQxNDEyMg==,incubator-stormcrawler,290414122,429,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-30T13:41:58Z,2017-03-30T13:41:58Z,"Note: cache is disabled by default in ES 2.x but enabled in 5.x

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5MDQxNDEyMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/429,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NTMwNDQzMw==,incubator-stormcrawler,295304433,429,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-04-19T15:11:29Z,2017-04-19T15:11:29Z,The logic is now to reset the nextFetchDate only when the number of buckets is 0. We'll refine the mechanism in #452 ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NTMwNDQzMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/430,https://api.github.com/repos/apache/incubator-stormcrawler/issues/430,incubator-stormcrawler,211739995,430,upgrade version of httpclient,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-03-03T16:42:45Z,2017-03-07T11:34:18Z,4.5.3 is the latest stable release,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/430/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/433,https://api.github.com/repos/apache/incubator-stormcrawler/issues/433,incubator-stormcrawler,213788393,433,ES : provide basic mapping for doc index,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-03-13T14:43:43Z,2017-03-13T16:46:06Z,The ESInitscript does not create a mapping for the doc index.  We should provide a basic one with e.g. _source and _all disabled etc...  ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/433/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/433,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NjEzNjU1Nw==,incubator-stormcrawler,286136557,433,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-13T15:10:21Z,2017-03-13T15:10:21Z,"This would also prevent fields from being indexed both as text and keywords, see [https://www.elastic.co/blog/strings-are-dead-long-live-strings]","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NjEzNjU1Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/434,https://api.github.com/repos/apache/incubator-stormcrawler/issues/434,incubator-stormcrawler,214057143,434,Improve metrics for status updater cache,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-03-14T12:31:04Z,2017-03-14T12:32:31Z,"Knowing the number of evictions, hits and misses would be good and Guava provides these stats easily.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/434/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/435,https://api.github.com/repos/apache/incubator-stormcrawler/issues/435,incubator-stormcrawler,214320214,435,File Protocol,isspek,6966175,isspek,,CLOSED,2017-03-15T08:47:26Z,2017-03-21T10:33:13Z,I have adopted File protocol implementation in Apache Nutch to Storm Crawler. See the implementations in (https://gist.github.com/isspek/32e9d762666593b4781ef3a0155dd74b) It works but needs revision. I need your suggestions. Some functions are exactly same as the class in Apache Nutch. ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/435/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/435,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NjY4MDE1Ng==,incubator-stormcrawler,286680156,435,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-15T09:01:42Z,2017-03-15T09:01:42Z,"Looks good, thanks! please open a Pull Request, it will make it easier to review your code. One change you could do before that would be to add the license headers at the top of your files. Also please use [parameterized messages](https://www.slf4j.org/faq.html#logging_performance) for the logs and StringBuilder instead of StringBuffer +and avoid manual concatenations as in `x.append(""<title>Index of "" + path + ""</title></head>\n"");)`.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NjY4MDE1Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/437,https://api.github.com/repos/apache/incubator-stormcrawler/issues/437,incubator-stormcrawler,214650385,437,Upgrade to Storm 1.0.3,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-03-16T09:58:12Z,2018-04-06T15:17:46Z,"Getting the following exception - which is surprising given that we specify the version of httpclient and storm should either use a shaded version or not at all

```
2017-03-16 10:47:48.583 o.a.s.d.executor Thread-14-fetcher-executor[3 3] [ERROR] 
java.lang.NoSuchMethodError: org.apache.http.impl.client.HttpClientBuilder.setConnectionManagerShared(Z)Lorg/apache/http/impl/client/HttpClientBuilder;
	at com.digitalpebble.stormcrawler.protocol.httpclient.HttpProtocol.configure(HttpProtocol.java:94) ~[stormjar.jar:?]
	at com.digitalpebble.stormcrawler.protocol.ProtocolFactory.<init>(ProtocolFactory.java:71) ~[stormjar.jar:?]
	at com.digitalpebble.stormcrawler.bolt.FetcherBolt.prepare(FetcherBolt.java:685) ~[stormjar.jar:?]
```","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/437/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/437,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4ODEwODM3NA==,incubator-stormcrawler,288108374,437,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-21T15:07:28Z,2017-03-21T15:07:28Z,"The issue above seems to occur only when Flux is added as a dependency. 

flux-core 1.0.3 contains a copy of the http client classes, whereas 1.0.2 did not","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4ODEwODM3NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/437,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM3OTI4NTg5OQ==,incubator-stormcrawler,379285899,437,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-04-06T15:17:46Z,2018-04-06T15:17:46Z,See JIRA https://issues.apache.org/jira/browse/STORM-2428,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM3OTI4NTg5OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/438,https://api.github.com/repos/apache/incubator-stormcrawler/issues/438,incubator-stormcrawler,214734993,438,Improve charset detection,lukb,5494764,Lukasz B.,lukasz@mintrock.com,CLOSED,2017-03-16T15:04:15Z,2017-08-30T08:29:58Z,"Charset detection works fine in most cases, but looking at the cases when it fails makes me think how it can be improved.

I found this page useful for a general guidance:
https://www.w3.org/International/questions/qa-html-encoding-declarations

In short, here's the detection sequence based on the above resource:

1) Look for BOM (""byte-order mark"", hex: EF BB BF) at the beginning of the content. If present, assume UTF-8. 
2) If BOM is not found in (1), look for charset declaration in HTTP Content-Type Header.
3) If declared charset not found in (2), take a look at meta tags (two cases to consider: <meta charset... and <meta content...)

If charset is not found after those 3 checks what's probably sensible is to entirely depend on a text-based charset detection.

Here's the charset detection bit I found in storm-crawler in JSoupParserBolt:

```
private String getContentCharset(byte[] content, Metadata metadata) {
        String charset = null;

        // check if the server specified a charset
        String specifiedContentType = metadata
                .getFirstValue(HttpHeaders.CONTENT_TYPE);
        try {
            if (specifiedContentType != null) {
                ContentType parsedContentType = ContentType
                        .parse(specifiedContentType);
                charset = parsedContentType.getCharset().name();
                if (maxLengthCharsetDetection == 0) {
                    return charset;
                }
            }
        } catch (Exception e) {
            charset = null;
        }

        // filter HTML tags
        charsetDetector.enableInputFilter(true);
        // give it a hint
        charsetDetector.setDeclaredEncoding(charset);
        // trim the content of the text for the detection
        byte[] subContent = content;
        if (maxLengthCharsetDetection != -1
                && content.length > maxLengthCharsetDetection) {
            subContent = Arrays.copyOfRange(content, 0,
                    maxLengthCharsetDetection);
        }
        charsetDetector.setText(subContent);
        try {
            CharsetMatch charsetMatch = charsetDetector.detect();
            if (charsetMatch != null) {
                charset = charsetMatch.getName();
            }
        } catch (Exception e) {
            // ignore and leave the charset as-is
        }
        return charset;
    }
```

CharsetDetector and CharsetMatch come from ICU4J http://site.icu-project.org/

From my understanding the code above looks for charset declared in Content-Type Header and if found uses it as a hint in further detection via CharsetDetector (as long as the maxLengthCharsetDetection is not set to 0). 

What's worth pointing out here is that CharsetDetector.detect() will take precedence over the declared charset in the HTTP Header if present. 
Also, I couldn't find any sign of parsing meta tags in order to determine charset declaration (let me know if it's there somewhere). 

So how can charset detection be improved? Take a hint from meta tags like for example here:
https://github.com/apache/tika/blob/9130bbc1fa6d69419b2ad294917260d6b1cced08/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlEncodingDetector.java

But I wonder, is it such a common case to find the declared charset to be different from the actual content encoding and that is why the current charset detection implementation relies on the dynamic detection via CharsetDetector to have a final say?

Looking at source code of CharsetDetector reveals that in fact detect() method returns only the first matching charset of all charsets that are a possible match (the array is suppose to be ordered by highest probability descending). CharsetDetector.detectAll() returns all the matching charsets. 

I have seen CharsetDetector.detect() wrongly returning ISO-8859-1 despite hinted ISO-8859-2 via         charsetDetector.setDeclaredEncoding() which came from HTTP header value (I wish I had an actual example at hand), so I'm not too sure how reliable it is.

What do you think about changing the charset detection implementation to resort to CharsetDetector only if HTTP/HTML-level charset declaration was not found? To factor in one more aspect: skipping CharsetDetector.detect() in some cases would yield performance benefits.

After all, I think it comes down to a question who is wrong more often on average: hinted CharsetDetector.detect() or HTTP/HTML-level charset declaration found in the crawled websites.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/438/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/438,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NzM2MzY1NQ==,incubator-stormcrawler,287363655,438,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-17T14:09:56Z,2017-03-17T14:09:56Z,"Thanks @lukb 

> What do you think about changing the charset detection implementation to resort to CharsetDetector only if HTTP/HTML-level charset declaration was not found? To factor in one more aspect: skipping CharsetDetector.detect() in some cases would yield performance benefits.

We could make it configurable at least e.g. `charset.detection.override` with a value of `true` would correspond to the current behaviour whereas `false` would do what you described. 

> After all, I think it comes down to a question who is wrong more often on average: hinted CharsetDetector.detect() or HTTP/HTML-level charset declaration found in the crawled websites.

Exactly, I thought there had been work on this based on CommonCrawl but I can't find any trace of it. @sebastian-nagel do you know anything related to this?

We could also log the cases where there is a discrepancy between the detection and what the headers contained. This would give us concrete examples for debugging.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NzM2MzY1NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/438,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NzYzNjc2Mg==,incubator-stormcrawler,287636762,438,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2017-03-19T18:32:30Z,2017-03-19T18:32:30Z,"The [fix](/iipc/webarchive-commons/commit/ed33bae09360ebf57e751e28b3eae2183b62237e) was simply to use [StandardCharsetDetector](/iipc/webarchive-commons/blob/master/src/main/java/org/archive/format/text/charset/StandardCharsetDetector.java) which is based on a trivial heuristic: take the charset found first in the hierarchy of (1) HTTP header, (2) HTML meta data or (3) guessed by org.mozilla.juniversalchardet. I checked one CC WARC file for errors of this approach: it works quite well, looks like for languages where encoding is crucial the web masters know what they do. Most errors affected English texts containing apostrophes, copy right marks and occasional Spanish words.

Adding a charset from HTML meta may help, also `detect.charset.maxlength: 2048` may be too small (cf. [NUTCH-2042](https://issues.apache.org/jira/browse/NUTCH-2042)/[TIKA-357](https://issues.apache.org/jira/browse/TIKA-357)) to get textual content from the HTML body for the detector.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NzYzNjc2Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/438,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMxNjk2Mzk1OA==,incubator-stormcrawler,316963958,438,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-07-21T10:14:41Z,2017-07-21T10:14:41Z,"Example of failed identification

http://www.kidstaff.com.ua/tema-11530898.html => http header and html agree on windows-1251 but identifier returns ""ISO-8859-8-I"" which throws an UnsupportedCharsetException.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMxNjk2Mzk1OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/438,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMxNjk3NDU3MA==,incubator-stormcrawler,316974570,438,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-07-21T11:11:17Z,2017-07-21T11:11:17Z,"Note: the [DataUtil class in JSoup ](https://github.com/jhy/jsoup/blob/master/src/main/java/org/jsoup/helper/DataUtil.java#L93) uses the BOM info and if not found looks into the metatags, however if a value is passed by the user (as we do with the content type coming from the detector, the latter is used de facto).","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMxNjk3NDU3MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/438,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMyNDI5NDY1MA==,incubator-stormcrawler,324294650,438,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-08-23T10:57:48Z,2017-08-23T10:57:48Z,"@lukb I have implemented as slightly different logic in a new branch `charset`, following Ken's suggestion in https://github.com/crawler-commons/crawler-commons/issues/171
Comments welcome as usual!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMyNDI5NDY1MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/438,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMyNDI5NzYxMw==,incubator-stormcrawler,324297613,438,NA,lukb,5494764,Lukasz B.,lukasz@mintrock.com,NA,2017-08-23T11:12:01Z,2017-08-23T11:12:01Z,"Looks good. 

Any reason why BOM is not the first condition to check? 

From: https://www.w3.org/International/questions/qa-html-encoding-declarations

> If you have a UTF-8 byte-order mark (BOM) at the start of your file then recent browser versions other than Internet Explorer 10 or 11 will use that to determine that the encoding of your page is UTF-8. It has a higher precedence than any other declaration, including the HTTP header.
> 
> You could skip the meta encoding declaration if you have a BOM, but we recommend that you keep it, since it helps people looking at the source code to ascertain what the encoding of the page is.

Checking BOM and skipping the rest could be a performance boost as well.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMyNDI5NzYxMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/438,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMyNDI5OTYzMA==,incubator-stormcrawler,324299630,438,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-08-23T11:22:31Z,2017-08-23T11:22:31Z,@kkrugler any reasons not to trust the BOM before anything else?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMyNDI5OTYzMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/438,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMyNTY5ODYwOA==,incubator-stormcrawler,325698608,438,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-08-29T15:20:59Z,2017-08-29T15:20:59Z,@lukb I decided to use BOM first as per your suggestion and will merge shortly unless someone disagrees. ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMyNTY5ODYwOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/438,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMyNTY5OTg3OA==,incubator-stormcrawler,325699878,438,NA,lukb,5494764,Lukasz B.,lukasz@mintrock.com,NA,2017-08-29T15:25:01Z,2017-08-29T15:25:01Z,"That sounds good, Julien.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMyNTY5OTg3OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/439,https://api.github.com/repos/apache/incubator-stormcrawler/issues/439,incubator-stormcrawler,214989372,439,Spouts generate one metric per call to ES   ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-03-17T12:27:06Z,2017-03-17T12:28:18Z,"instead of just aggregating the total. This way we can see the number of calls and the individual times as well as compute averages, min, max etc... from Kibana / Grafana.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/439/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/440,https://api.github.com/repos/apache/incubator-stormcrawler/issues/440,incubator-stormcrawler,215103188,440,exited loop !  continuosly ,MyraBaba,17505439,,,CLOSED,2017-03-17T19:39:29Z,2017-03-20T15:59:33Z,"Hi,

We used  storm crawler for testing in January and that time we used through creating uber jar .  Flux . not configured than.

last day we updated storm crawler and its changed  to  to flux and couldnt create uberjar with old way.

So we used flux . and injected urls..

Starting to crawl...

But it is always exiting from loop in a few minutes. Didnt know what..

here the last log:

`
63501 [FetcherThread] INFO  c.d.s.b.FetcherBolt - [Fetcher #3] Fetched http://www.yenicaggazetesi.com.tr/sinema-haberleri-58hk.htm with status 200 in msec 622
63505 [Thread-30-parse-executor[5 5]] INFO  c.d.s.b.JSoupParserBolt - Parsing : starting http://www.yenicaggazetesi.com.tr/sinema-haberleri-58hk.htm
63509 [Thread-30-parse-executor[5 5]] INFO  c.d.s.b.JSoupParserBolt - Parsed http://www.yenicaggazetesi.com.tr/sinema-haberleri-58hk.htm in 3 msec
63650 [FetcherThread] WARN  c.d.s.p.h.HttpProtocol - HTTP content trimmed to 65536
63650 [FetcherThread] INFO  c.d.s.b.FetcherBolt - [Fetcher #3] Fetched http://www.motosiklet.net/forum/motosiklet-modelleri/?pp=20&daysprune=-1&prefixid=39_Kuba_Yuan_Motosiklet with status 200 in msec 324
63655 [Thread-30-parse-executor[5 5]] INFO  c.d.s.b.JSoupParserBolt - Parsing : starting http://www.motosiklet.net/forum/motosiklet-modelleri/?pp=20&daysprune=-1&prefixid=39_Kuba_Yuan_Motosiklet
63660 [Thread-30-parse-executor[5 5]] INFO  c.d.s.b.JSoupParserBolt - Parsed http://www.motosiklet.net/forum/motosiklet-modelleri/?pp=20&daysprune=-1&prefixid=39_Kuba_Yuan_Motosiklet in 4 msec
63669 [main] INFO  o.a.s.l.ThriftAccessLogger - Request ID: 1 access from:  principal:  operation: killTopology
63681 [main] INFO  o.a.s.d.nimbus - Delaying event :remove for 300 secs for crawler-1-1489779049
63692 [main] INFO  o.a.s.d.nimbus - Adding topo to history log: crawler-1-1489779049
63697 [main] INFO  o.a.s.d.nimbus - Shutting down master
63699 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
63699 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x15addc043490003
63700 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x15addc043490003 closed
63700 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down
63700 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
63700 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /0:0:0:0:0:0:0:1:54079 which had sessionid 0x15addc043490003
63700 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x15addc043490004
63701 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x15addc043490004 closed
63701 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down
63701 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /0:0:0:0:0:0:0:1:54080 which had sessionid 0x15addc043490004
63701 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
63701 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x15addc043490000
63702 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x15addc043490000 closed
63702 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down
63702 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:54077 which had sessionid 0x15addc043490000
63702 [main] INFO  o.a.s.zookeeper - closing zookeeper connection of leader elector.
63702 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
63702 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x15addc043490001
63703 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x15addc043490001 closed
63703 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down
63703 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:54078 which had sessionid 0x15addc043490001
63703 [main] INFO  o.a.s.d.nimbus - Shut down master
63703 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
63703 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x15addc043490006
63703 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x15addc043490006 closed
63703 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down
63704 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:54082 which had sessionid 0x15addc043490006
63704 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
63704 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x15addc043490008
63704 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x15addc043490008 closed
63704 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down
63704 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:54084 which had sessionid 0x15addc043490008
63705 [main] INFO  o.a.s.d.supervisor - Shutting down supervisor 65050983-1686-4239-9c57-b66ea773bb1e
63706 [Thread-7] INFO  o.a.s.event - Event manager interrupted
63706 [Thread-8] INFO  o.a.s.event - Event manager interrupted
63706 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
63706 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x15addc04349000a
63707 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x15addc04349000a closed
63707 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down
63707 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:54086 which had sessionid 0x15addc04349000a
63711 [main] INFO  o.a.s.d.supervisor - Shutting down 3d22da9e-e57a-4d44-9bb9-eb910686258d:50615cfd-191a-4432-8580-a5fcade0034f
63711 [main] INFO  o.a.s.config - GET worker-user 50615cfd-191a-4432-8580-a5fcade0034f
63713 [main] INFO  o.a.s.process-simulator - Killing process e285c014-a7d5-4cfe-977b-8bdc5e9478d5
63713 [main] INFO  o.a.s.d.worker - Shutting down worker crawler-1-1489779049 3d22da9e-e57a-4d44-9bb9-eb910686258d 1027
63713 [main] INFO  o.a.s.d.worker - Terminating messaging context
63713 [main] INFO  o.a.s.d.worker - Shutting down executors
63714 [main] INFO  o.a.s.d.executor - Shutting down executor spout:[8 8]
63715 [Thread-14-spout-executor[8 8]] INFO  o.a.s.util - Async loop interrupted!
63715 [Thread-13-disruptor-executor[8 8]-send-queue] INFO  o.a.s.util - Async loop interrupted!
63752 [main] INFO  o.a.s.d.executor - Shut down executor spout:[8 8]
63753 [main] INFO  o.a.s.d.executor - Shutting down executor __metricscom.digitalpebble.stormcrawler.elasticsearch.metrics.MetricsConsumer:[2 2]
63753 [Thread-16-__metricscom.digitalpebble.stormcrawler.elasticsearch.metrics.MetricsConsumer-executor[2 2]] INFO  o.a.s.util - Async loop interrupted!
63753 [Thread-15-disruptor-executor[2 2]-send-queue] INFO  o.a.s.util - Async loop interrupted!
63771 [main] INFO  o.a.s.d.executor - Shut down executor __metricscom.digitalpebble.stormcrawler.elasticsearch.metrics.MetricsConsumer:[2 2]
63771 [main] INFO  o.a.s.d.executor - Shutting down executor sitemap:[7 7]
63771 [Thread-18-sitemap-executor[7 7]] INFO  o.a.s.util - Async loop interrupted!
63771 [Thread-17-disruptor-executor[7 7]-send-queue] INFO  o.a.s.util - Async loop interrupted!
63772 [main] INFO  o.a.s.d.executor - Shut down executor sitemap:[7 7]
63772 [main] INFO  o.a.s.d.executor - Shutting down executor fetcher:[3 3]
63772 [Thread-20-fetcher-executor[3 3]] INFO  o.a.s.util - Async loop interrupted!
63772 [Thread-19-disruptor-executor[3 3]-send-queue] INFO  o.a.s.util - Async loop interrupted!
63773 [main] INFO  o.a.s.d.executor - Shut down executor fetcher:[3 3]
63773 [main] INFO  o.a.s.d.executor - Shutting down executor __acker:[1 1]
63773 [Thread-22-__acker-executor[1 1]] INFO  o.a.s.util - Async loop interrupted!
63773 [Thread-21-disruptor-executor[1 1]-send-queue] INFO  o.a.s.util - Async loop interrupted!
63774 [main] INFO  o.a.s.d.executor - Shut down executor __acker:[1 1]
63774 [main] INFO  o.a.s.d.executor - Shutting down executor partitioner:[6 6]
63774 [Thread-24-partitioner-executor[6 6]] INFO  o.a.s.util - Async loop interrupted!
63774 [Thread-23-disruptor-executor[6 6]-send-queue] INFO  o.a.s.util - Async loop interrupted!
63775 [main] INFO  o.a.s.d.executor - Shut down executor partitioner:[6 6]
63775 [main] INFO  o.a.s.d.executor - Shutting down executor status:[9 9]
63775 [Thread-26-status-executor[9 9]] INFO  o.a.s.util - Async loop interrupted!
63775 [Thread-25-disruptor-executor[9 9]-send-queue] INFO  o.a.s.util - Async loop interrupted!
63792 [FetcherThread] INFO  c.d.s.b.FetcherBolt - [Fetcher #3] Fetched http://www.yeniasya.com.tr/dunya/bm-de-israil-baskisi-istifasi_426691 with status 200 in msec 5277
63807 [elasticsearch[Chrome][listener][T#2]] WARN  c.d.s.e.p.StatusUpdaterBolt - Could not find unacked tuple for 124583fdd7b4381ce05520cfb834ace3112ff384a87550e599db05413e0e9362
63807 [elasticsearch[Chrome][listener][T#2]] WARN  c.d.s.e.p.StatusUpdaterBolt - Could not find unacked tuple for 174540b1ff7f7bf70bef56c57cf29e100d6f8847e4b5d648608848303436c2db
63807 [elasticsearch[Chrome][listener][T#2]] INFO  c.d.s.e.p.StatusUpdaterBolt - Bulk response 211, waitAck 0, acked 211
63810 [FetcherThread] WARN  c.d.s.p.h.HttpProtocol - HTTP content trimmed to 65536
63810 [FetcherThread] INFO  c.d.s.b.FetcherBolt - [Fetcher #3] Fetched http://www.hurriyet.com.tr with status 200 in msec 330
63817 [main] INFO  o.a.s.d.executor - Shut down executor status:[9 9]
63818 [main] INFO  o.a.s.d.executor - Shutting down executor __system:[-1 -1]
63818 [Thread-28-__system-executor[-1 -1]] INFO  o.a.s.util - Async loop interrupted!
63818 [Thread-27-disruptor-executor[-1 -1]-send-queue] INFO  o.a.s.util - Async loop interrupted!
63819 [main] INFO  o.a.s.d.executor - Shut down executor __system:[-1 -1]
63819 [main] INFO  o.a.s.d.executor - Shutting down executor parse:[5 5]
63819 [Thread-30-parse-executor[5 5]] INFO  o.a.s.util - Async loop interrupted!
63819 [Thread-29-disruptor-executor[5 5]-send-queue] INFO  o.a.s.util - Async loop interrupted!
63820 [main] INFO  o.a.s.d.executor - Shut down executor parse:[5 5]
63820 [main] INFO  o.a.s.d.executor - Shutting down executor index:[4 4]
63820 [Thread-32-index-executor[4 4]] INFO  o.a.s.util - Async loop interrupted!
63820 [Thread-31-disruptor-executor[4 4]-send-queue] INFO  o.a.s.util - Async loop interrupted!
63841 [main] INFO  o.a.s.d.executor - Shut down executor index:[4 4]
63841 [main] INFO  o.a.s.d.worker - Shut down executors
63841 [main] INFO  o.a.s.d.worker - Shutting down transfer thread
63841 [Thread-33-disruptor-worker-transfer-queue] INFO  o.a.s.util - Async loop interrupted!
63842 [main] INFO  o.a.s.d.worker - Shut down transfer thread
63842 [main] INFO  o.a.s.d.worker - Shut down backpressure thread
63843 [main] INFO  o.a.s.d.worker - Shutting down default resources
63843 [main] INFO  o.a.s.d.worker - Shut down default resources
63843 [main] INFO  o.a.s.d.worker - Trigger any worker shutdown hooks
63848 [main] INFO  o.a.s.d.worker - Disconnecting from storm cluster state context
63848 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
63848 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x15addc043490011
63849 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x15addc043490011 closed
63849 [Thread-10-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down
63850 [main] INFO  o.a.s.d.worker - Shut down worker crawler-1-1489779049 3d22da9e-e57a-4d44-9bb9-eb910686258d 1027
63850 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:54097 which had sessionid 0x15addc043490011
63865 [main] INFO  o.a.s.config - REMOVE worker-user 50615cfd-191a-4432-8580-a5fcade0034f
63866 [main] INFO  o.a.s.d.supervisor - Shut down 3d22da9e-e57a-4d44-9bb9-eb910686258d:50615cfd-191a-4432-8580-a5fcade0034f
63866 [main] INFO  o.a.s.d.supervisor - Shutting down supervisor 3d22da9e-e57a-4d44-9bb9-eb910686258d
63867 [Thread-9] INFO  o.a.s.event - Event manager interrupted
63867 [Thread-10] INFO  o.a.s.event - Event manager interrupted
63867 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
63868 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x15addc04349000c
63869 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x15addc04349000c closed
63869 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down
63869 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:54088 which had sessionid 0x15addc04349000c
63869 [main] INFO  o.a.s.testing - Shutting down in process zookeeper
63870 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - NIOServerCnxn factory exited run method
63872 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - shutting down
63872 [main] INFO  o.a.s.s.o.a.z.s.SessionTrackerImpl - Shutting down
63872 [main] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Shutting down
63872 [main] INFO  o.a.s.s.o.a.z.s.SyncRequestProcessor - Shutting down
63872 [ProcessThread(sid:0 cport:-1):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - PrepRequestProcessor exited loop!
63872 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.SyncRequestProcessor - SyncRequestProcessor exited!
63872 [main] INFO  o.a.s.s.o.a.z.s.FinalRequestProcessor - shutdown of request processor complete
63872 [main] INFO  o.a.s.testing - Done shutting down in process zookeeper
63872 [main] INFO  o.a.s.testing - Deleting temporary path /var/folders/ly/fkgkdh_959g_p_m85pvtnnjw0000gn/T//3fc6734c-9fce-4b0a-b533-5484cc04b45d
63877 [main] INFO  o.a.s.testing - Deleting temporary path /var/folders/ly/fkgkdh_959g_p_m85pvtnnjw0000gn/T//c0a2c454-3249-48dd-853a-183e05ca4736
63878 [main] INFO  o.a.s.testing - Deleting temporary path /var/folders/ly/fkgkdh_959g_p_m85pvtnnjw0000gn/T//2fe8476d-0fb3-47ef-a9da-dc8dcb48a079
63880 [main] INFO  o.a.s.testing - Deleting temporary path /var/folders/ly/fkgkdh_959g_p_m85pvtnnjw0000gn/T//54df0f86-cfce-4a5b-b73b-6a6bcfed3570
64035 [FetcherThread] WARN  c.d.s.p.h.HttpProtocol - HTTP content trimmed to 65536
64035 [FetcherThread] INFO  c.d.s.b.FetcherBolt - [Fetcher #3] Fetched http://www.kibrisgazetesi.com/ekonomi/seyrusefer-kiyagi-luks-araclara-yarayacak/14657 with status 200 in msec 4604
64175 [FetcherThread] WARN  c.d.s.p.h.HttpProtocol - HTTP content trimmed to 65536
64175 [FetcherThread] INFO  c.d.s.b.FetcherBolt - [Fetcher #3] Fetched http://www.haberx.com/arsiv(20,a,2016-06-07,193).aspx with status 200 in msec 6642
64183 [FetcherThread] ERROR c.d.s.b.FetcherBolt - Exception while fetching http://www.cnnturk.com/ajanda/tahsin-yarali-kurtuldu-cesur-ve-guzel-19-yeni-bolum-fragmani-son-bolumun-ardindan-yayinlanacak
org.apache.http.NoHttpResponseException: The target server failed to respond
	at org.apache.http.impl.conn.DefaultHttpResponseParser.parseHead(DefaultHttpResponseParser.java:143) ~[haberCrawl-1.0-SNAPSHOT.jar:?]
	at org.apache.http.impl.conn.DefaultHttpResponseParser.parseHead(DefaultHttpResponseParser.java:57) ~[haberCrawl-1.0-SNAPSHOT.jar:?]
	at org.apache.http.impl.io.AbstractMessageParser.parse(AbstractMessageParser.java:261) ~[haberCrawl-1.0-SNAPSHOT.jar:?]
	at org.apache.http.impl.DefaultBHttpClientConnection.receiveResponseHeader(DefaultBHttpClientConnection.java:165) ~[haberCrawl-1.0-SNAPSHOT.jar:?]
	at org.apache.http.impl.conn.CPoolProxy.receiveResponseHeader(CPoolProxy.java:167) ~[haberCrawl-1.0-SNAPSHOT.jar:?]
	at org.apache.http.protocol.HttpRequestExecutor.doReceiveResponse(HttpRequestExecutor.java:272) ~[haberCrawl-1.0-SNAPSHOT.jar:?]
	at org.apache.http.protocol.HttpRequestExecutor.execute(HttpRequestExecutor.java:124) ~[haberCrawl-1.0-SNAPSHOT.jar:?]
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:271) ~[haberCrawl-1.0-SNAPSHOT.jar:?]
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:184) ~[haberCrawl-1.0-SNAPSHOT.jar:?]
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:184) ~[haberCrawl-1.0-SNAPSHOT.jar:?]
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:71) ~[haberCrawl-1.0-SNAPSHOT.jar:?]
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:220) ~[haberCrawl-1.0-SNAPSHOT.jar:?]
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:164) ~[haberCrawl-1.0-SNAPSHOT.jar:?]
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:139) ~[haberCrawl-1.0-SNAPSHOT.jar:?]
	at com.digitalpebble.stormcrawler.protocol.httpclient.HttpProtocol.getProtocolOutput(HttpProtocol.java:148) ~[haberCrawl-1.0-SNAPSHOT.jar:?]
	at com.digitalpebble.stormcrawler.bolt.FetcherBolt$FetcherThread.run(FetcherBolt.java:493) [haberCrawl-1.0-SNAPSHOT.jar:?]
64299 [FetcherThread] WARN  c.d.s.p.h.HttpProtocol - HTTP content trimmed to 65536
64299 [FetcherThread] INFO  c.d.s.b.FetcherBolt - [Fetcher #3] Fetched http://webtv.radikal.com.tr/spor/ with status 200 in msec 2376
64351 [FetcherThread] INFO  c.d.s.b.FetcherBolt - [Fetcher #3] Fetched http://www.objektifhaber.com/ataturk-havalimaninda-patlama-ve-silah-sesleri-1688-foto/ with status 200 in msec 1066
64512 [FetcherThread] INFO  c.d.s.b.FetcherBolt - [Fetcher #3] Fetched http://www.pressturk.com/firma/kategori/dogalgaz/49/ with status 200 in msec 108
64640 [FetcherThread] INFO  c.d.s.b.FetcherBolt - [Fetcher #3] Fetched http://www.internethaber.com/isimsizler-1-bolum-fragmani-video-galerisi-1762077.htm with status 200 in msec 1324
64678 [FetcherThread] INFO  c.d.s.b.FetcherBolt - [Fetcher #3] Fetched http://www.yenicaggazetesi.com.tr/bitliste-bes-minare-42028yy.htm with status 200 in msec 171
64756 [FetcherThread] WARN  c.d.s.p.h.HttpProtocol - HTTP content trimmed to 65536
64756 [FetcherThread] INFO  c.d.s.b.FetcherBolt - [Fetcher #3] Fetched http://www.cumhuriyet.com.tr/arama/metrob%C3%BCs with status 200 in msec 777
64843 [FetcherThread] WARN  c.d.s.p.h.HttpProtocol - HTTP content trimmed to 65536
64843 [FetcherThread] INFO  c.d.s.b.FetcherBolt - [Fetcher #3] Fetched http://www.hurriyet.com.tr/itu-mizahfest-ile-guldurecek-40379118 with status 200 in msec 27
64940 [FetcherThread] WARN  c.d.s.p.h.HttpProtocol - HTTP content trimmed to 65536
64940 [FetcherThread] INFO  c.d.s.b.FetcherBolt - [Fetcher #3] Fetched http://www.motosiklet.net/forum/motosiklet-modelleri/?pp=20&daysprune=-1&prefixid=131_ktm_motorsiklet with status 200 in msec 290
64948 [FetcherThread] WARN  c.d.s.p.h.HttpProtocol - HTTP content trimmed to 65536
64948 [FetcherThread] INFO  c.d.s.b.FetcherBolt - [Fetcher #3] Fetched http://www.yeniasya.com.tr/etiket/ba%C5%9F%C3%B6rt%C3%BCs%C3%BC with status 200 in msec 152
65504 [SessionTracker] INFO  o.a.s.s.o.a.z.s.SessionTrackerImpl - SessionTrackerImpl exited loop!
alpullu:haberCrawl alpullu$ 

`","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/440/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/440,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NzcwNjQzNQ==,incubator-stormcrawler,287706435,440,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-20T09:10:08Z,2017-03-20T09:10:08Z,"> last day we updated storm crawler and its changed to to flux and couldnt create uberjar with old way.

The java topology is still in the archetype and you should be able to use it in exactly the same way as before.

I presume you are running it in local mode. Which version of Storm are you on?

> 63669 [main] INFO o.a.s.l.ThriftAccessLogger - Request ID: 1 access from: principal: operation: killTopology

Looks like a Storm-related issue, would be worth checking whether you have the same problem when running the Java topology. If not the problem could be related to Flux.

Anything relevant in the Nimbus log file?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NzcwNjQzNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/440,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NzczNDM5Nw==,incubator-stormcrawler,287734397,440,NA,MyraBaba,17505439,,,NA,2017-03-20T11:29:24Z,2017-03-20T11:29:24Z,"With same setup I can run old way (  storm jar classfile -conf xxxx. -local ) without any problem. 

But when I try flux after few minutes its happenign and killingTopology.

Storm is 1.0.2

Nimbus file shows no error. Clean and smooth

Best.



> On 20 Mar 2017, at 12:10, Julien Nioche <notifications@github.com> wrote:
> 
> last day we updated storm crawler and its changed to to flux and couldnt create uberjar with old way.
> 
> The java topology is still in the archetype and you should be able to use it in exactly the same way as before.
> 
> I presume you are running it in local mode. Which version of Storm are you on?
> 
> 63669 [main] INFO o.a.s.l.ThriftAccessLogger - Request ID: 1 access from: principal: operation: killTopology
> 
> Looks like a Storm-related issue, would be worth checking whether you have the same problem when running the Java topology. If not the problem could be related to Flux.
> 
> Anything relevant in the Nimbus log file?
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub <https://github.com/DigitalPebble/storm-crawler/issues/440#issuecomment-287706435>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AQscn0tHBNUeUZvGk7FjV9_Rvfh6_0hCks5rnkJxgaJpZM4MhBLk>.
> 

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NzczNDM5Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/440,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4Nzc1ODcwNA==,incubator-stormcrawler,287758704,440,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-20T13:29:17Z,2017-03-20T13:29:17Z,"[http://user.storm.apache.narkive.com/lA9pc40i/flux]

> By default, flux will run local mode topologies for 60 seconds.

try setting a ridiculously large value with -s or use in remote mode, which will give you the benefits of the storm UI, proper log files etc...

Will add a note in the README generated by the archetype. 

Thanks for reporting this!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4Nzc1ODcwNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/440,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NzgwNTgwOQ==,incubator-stormcrawler,287805809,440,NA,MyraBaba,17505439,,,NA,2017-03-20T15:59:33Z,2017-03-20T15:59:33Z,":))))

Thanks


> On 20 Mar 2017, at 16:29, Julien Nioche <notifications@github.com> wrote:
> 
> [http://user.storm.apache.narkive.com/lA9pc40i/flux]
> 
> By default, flux will run local mode topologies for 60 seconds.
> 
> try setting a ridiculously large value with -s or use in remote mode, which will give you the benefits of the storm UI, proper log files etc...
> 
> Will add a note in the README generated by the archetype.
> 
> Thanks for reporting this!
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub <https://github.com/DigitalPebble/storm-crawler/issues/440#issuecomment-287758704>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AQscn9fOhCdusQT64KTmwVJLdS000MvIks5rnn8vgaJpZM4MhBLk>.
> 

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4NzgwNTgwOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/441,https://api.github.com/repos/apache/incubator-stormcrawler/issues/441,incubator-stormcrawler,215655368,441,Submit storm topology in local ,isspek,6966175,isspek,,CLOSED,2017-03-21T08:01:51Z,2017-03-21T19:09:43Z,"I created a package  containing my custom storm topology for my web-app project. It runs in local mode without any problem.  However when  I call this method `ConfigurableTopology.start(new CrawlTopology(), args);` as local mode in the package, from the rest controller based on spring framework, I receive the following errors: 

```
152504 [Thread-9] ERROR o.a.s.event - Error when processing event
java.io.FileNotFoundException: Source '...\wtpwebapps\project-name\WEB-INF\lib\cdm-4.5.5.jar!\resources' does not exist
    at org.apache.storm.shade.org.apache.commons.io.FileUtils.checkFileRequirements(FileUtils.java:1405) ~[storm-core-1.0.2.jar:1.0.2]
    at org.apache.storm.shade.org.apache.commons.io.FileUtils.copyDirectory(FileUtils.java:1368) ~[storm-core-1.0.2.jar:1.0.2]
    at org.apache.storm.shade.org.apache.commons.io.FileUtils.copyDirectory(FileUtils.java:1268) ~[storm-core-1.0.2.jar:1.0.2]
    at org.apache.storm.shade.org.apache.commons.io.FileUtils.copyDirectory(FileUtils.java:1237) ~[storm-core-1.0.2.jar:1.0.2]
    at org.apache.storm.daemon.supervisor$fn__9436.invoke(supervisor.clj:1178) ~[storm-core-1.0.2.jar:1.0.2]
    at clojure.lang.MultiFn.invoke(MultiFn.java:243) ~[clojure-1.7.0.jar:?]
    at org.apache.storm.daemon.supervisor$mk_synchronize_supervisor$this__9163$fn__9181.invoke(supervisor.clj:579) ~[storm-core-1.0.2.jar:1.0.2]
    at org.apache.storm.daemon.supervisor$mk_synchronize_supervisor$this__9163.invoke(supervisor.clj:578) ~[storm-core-1.0.2.jar:1.0.2]
    at org.apache.storm.event$event_manager$fn__8735.invoke(event.clj:40) [storm-core-1.0.2.jar:1.0.2]
    at clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]
    at java.lang.Thread.run(Thread.java:745) [?:1.8.0_91]
152504 [Thread-11] ERROR o.a.s.event - Error when processing event
java.io.FileNotFoundException: Source '...\project-name\WEB-INF\lib\cdm-4.5.5.jar!\resources' does not exist
    at org.apache.storm.shade.org.apache.commons.io.FileUtils.checkFileRequirements(FileUtils.java:1405) ~[storm-core-1.0.2.jar:1.0.2]
    at org.apache.storm.shade.org.apache.commons.io.FileUtils.copyDirectory(FileUtils.java:1368) ~[storm-core-1.0.2.jar:1.0.2]
    at org.apache.storm.shade.org.apache.commons.io.FileUtils.copyDirectory(FileUtils.java:1268) ~[storm-core-1.0.2.jar:1.0.2]
    at org.apache.storm.shade.org.apache.commons.io.FileUtils.copyDirectory(FileUtils.java:1237) ~[storm-core-1.0.2.jar:1.0.2]
    at org.apache.storm.daemon.supervisor$fn__9436.invoke(supervisor.clj:1178) ~[storm-core-1.0.2.jar:1.0.2]
    at clojure.lang.MultiFn.invoke(MultiFn.java:243) ~[clojure-1.7.0.jar:?]
    at org.apache.storm.daemon.supervisor$mk_synchronize_supervisor$this__9163$fn__9181.invoke(supervisor.clj:579) ~[storm-core-1.0.2.jar:1.0.2]
    at org.apache.storm.daemon.supervisor$mk_synchronize_supervisor$this__9163.invoke(supervisor.clj:578) ~[storm-core-1.0.2.jar:1.0.2]
    at org.apache.storm.event$event_manager$fn__8735.invoke(event.clj:40) [storm-core-1.0.2.jar:1.0.2]
    at clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]
    at java.lang.Thread.run(Thread.java:745) [?:1.8.0_91]
152508 [Thread-11] ERROR o.a.s.util - Halting process: (""Error when processing an event"")
java.lang.RuntimeException: (""Error when processing an event"")
    at org.apache.storm.util$exit_process_BANG_.doInvoke(util.clj:341) [storm-core-1.0.2.jar:1.0.2]
    at clojure.lang.RestFn.invoke(RestFn.java:423) [clojure-1.7.0.jar:?]
    at org.apache.storm.event$event_manager$fn__8735.invoke(event.clj:48) [storm-core-1.0.2.jar:1.0.2]
    at clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]
    at java.lang.Thread.run(Thread.java:745) [?:1.8.0_91]
152508 [Thread-9] ERROR o.a.s.util - Halting process: (""Error when processing an event"")
java.lang.RuntimeException: (""Error when processing an event"")
    at org.apache.storm.util$exit_process_BANG_.doInvoke(util.clj:341) [storm-core-1.0.2.jar:1.0.2]
    at clojure.lang.RestFn.invoke(RestFn.java:423) [clojure-1.7.0.jar:?]
    at org.apache.storm.event$event_manager$fn__8735.invoke(event.clj:48) [storm-core-1.0.2.jar:1.0.2]
    at clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]
    at java.lang.Thread.run(Thread.java:745) [?:1.8.0_91]
2017-03-20 15:47:21,335 FATAL Unable to register shutdown hook because JVM is shutting down.
154735 [Thread-10] INFO  o.a.s.d.supervisor - Removing code for storm id crawl-1-1490010427
```

I just want to use storm crawler in fat jar package, not to install it in neither my local system nor server. I am not sure this issue is related to storm or storm crawler. I apreciate the any ideas for resolving this issue. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/441/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/441,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4ODAzOTMzNw==,incubator-stormcrawler,288039337,441,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-21T10:40:35Z,2017-03-21T10:40:35Z,"See #324, this is a Storm-related issue. I opened a JIRA https://issues.apache.org/jira/browse/STORM-2055, it could be related to https://issues.apache.org/jira/browse/STORM-2324, which in theory has been fixed by Storm 1.0.3
I opened #437 for upgrading to 1.0.3 but got into problems with it.  Since you are running in local mode, you probably won't have the same problem. Could you try changing the versions of Storm to 1.0.3 and see if it fixes it?  ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4ODAzOTMzNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/441,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4ODA5NDk2Nw==,incubator-stormcrawler,288094967,441,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-21T14:27:15Z,2017-03-21T14:27:15Z,"Investigated a bit, you can run it in local mode without getting the error above by upgrading the storm dependency to 1.0.3.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4ODA5NDk2Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/441,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4ODE0MDIwMg==,incubator-stormcrawler,288140202,441,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-21T16:42:12Z,2017-03-21T16:42:12Z,@isspek I have upgraded the version of Storm to 1.0.3 in the master branch. Could you please recompile it and use it in your project? Please let me know if it fixes the issue. Thanks,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4ODE0MDIwMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/441,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4ODE0NzU0OA==,incubator-stormcrawler,288147548,441,NA,isspek,6966175,isspek,,NA,2017-03-21T17:04:18Z,2017-03-21T17:04:18Z,"@jnioche Sorry I couldn't reply because I am away from that computer. When I upgraded to Storm 1.0.3, I didn't get this error, but I received new exception related to windows. I searched the internet and the problem seems related to the version of Windows (that computer is XP), and Eclipse.  To be sure,  I am trying to simulate the problem with machine installed Windows 10.  I will update this comment tomorrow with new exception message and the solution if I come up.

**UPDATE:**

I tried with the machine windows 10 and received the same exception. I guess the storm is not working properly without installation if I submit crawler from rest-api. The new exception is:

```
java.nio.file.FileSystemException: C:\Users\PC1\AppData\Local\Temp\f5c0a7b1-eb39-40ec-8e8d-fa11ee5bb62a\workers\eb5b8bf6-6a2e-4c04-8498-3ef80eb269eb\artifacts

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86) ~[?:1.8.0_121]
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97) ~[?:1.8.0_121]
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102) ~[?:1.8.0_121]
	at sun.nio.fs.WindowsFileSystemProvider.createSymbolicLink(WindowsFileSystemProvider.java:585) ~[?:1.8.0_121]
	at java.nio.file.Files.createSymbolicLink(Files.java:1043) ~[?:1.8.0_121]
	at org.apache.storm.daemon.supervisor.AdvancedFSOps.createSymlink(AdvancedFSOps.java:354) ~[storm-core-1.0.3.jar:1.0.3]
	at org.apache.storm.daemon.supervisor.Container.createArtifactsLink(Container.java:383) ~[storm-core-1.0.3.jar:1.0.3]
	at org.apache.storm.daemon.supervisor.Container.setup(Container.java:321) ~[storm-core-1.0.3.jar:1.0.3]
	at org.apache.storm.daemon.supervisor.LocalContainerLauncher.launchContainer(LocalContainerLauncher.java:44) ~[storm-core-1.0.3.jar:1.0.3]
	at org.apache.storm.daemon.supervisor.Slot.handleWaitingForBlobLocalization(Slot.java:387) ~[storm-core-1.0.3.jar:1.0.3]
	at org.apache.storm.daemon.supervisor.Slot.stateMachineStep(Slot.java:275) ~[storm-core-1.0.3.jar:1.0.3]
	at org.apache.storm.daemon.supervisor.Slot.run(Slot.java:741) [storm-core-1.0.3.jar:1.0.3]
29143 [SLOT_1024] ERROR o.a.s.u.Utils - Halting process: Error when processing an event
java.lang.RuntimeException: Halting process: Error when processing an event
	at org.apache.storm.utils.Utils.exitProcess(Utils.java:1749) [storm-core-1.0.3.jar:1.0.3]
	at org.apache.storm.daemon.supervisor.Slot.run(Slot.java:774) [storm-core-1.0.3.jar:1.0.3]
2017-03-21 19:02:00,594 FATAL Unable to register shutdown hook because JVM is shutting down.
```

I guess I had better use storm that I have installed in a server. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4ODE0NzU0OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/442,https://api.github.com/repos/apache/incubator-stormcrawler/issues/442,incubator-stormcrawler,215845133,442,ES Status Updater never hits cache,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-03-21T19:00:10Z,2017-03-21T19:00:30Z,"The culprit is that we cache using the ID and not the URL 
`super.ack(x, id);`


","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/442/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/443,https://api.github.com/repos/apache/incubator-stormcrawler/issues/443,incubator-stormcrawler,216736758,443,Investigate OKHTTP to replace Apache HTTPClient,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-03-24T10:36:02Z,2017-07-07T10:16:39Z,"[OKHTTP](http://square.github.io/okhttp/) seems to be more robust on a small set of problematic URLs I tested (including #405) and at first glance, its API is more logical and easier to understand.  

It would also make it easier to store the http request verbatim (see #317) for generating WARCs.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/443/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/443,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwMTQ0ODI1Ng==,incubator-stormcrawler,301448256,443,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-05-15T11:26:25Z,2017-05-15T11:26:25Z,"OKHTTP does not have the same issue as httpclient for large content, see #463. We can read and trim very large content without getting stuck when closing it.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwMTQ0ODI1Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/444,https://api.github.com/repos/apache/incubator-stormcrawler/issues/444,incubator-stormcrawler,217207721,444,Utility class to export URL and metadata from ES index to file,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-03-27T10:53:05Z,2017-03-27T12:50:45Z,This would provide a very basic mechanism for backups as well as a simple way to load alternative storage backends.   ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/444/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/444,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4OTQ0MzY5OQ==,incubator-stormcrawler,289443699,444,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-03-27T12:50:45Z,2017-03-27T12:50:45Z,"Used with e.g. 

```
mvn exec:java -Dexec.mainClass=""com.digitalpebble.stormcrawler.elasticsearch.util.URLExtractor"" -Dexec.args=""es-conf.yaml urls status""
```","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI4OTQ0MzY5OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/445,https://api.github.com/repos/apache/incubator-stormcrawler/issues/445,incubator-stormcrawler,217808712,445,Per URL Xpath ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-03-29T08:58:52Z,2018-06-13T12:18:47Z,"See http://stackoverflow.com/questions/43081051/broad-crawling-different-xpaths-scrapy

Similar to #399 where we set a max depth per URL but this time we'd have a xpath expression like in the [XpathFilter](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/parse/filter/XPathFilter.java)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/445/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/445,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NjkxNzI2MA==,incubator-stormcrawler,396917260,445,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-06-13T12:18:46Z,2018-06-13T12:18:46Z,Better to go along the lines of #578 - setting things through the seeds is just messy. I'd rather have a JSON based file that could be reloaded in ES thanks to #569 ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NjkxNzI2MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/448,https://api.github.com/repos/apache/incubator-stormcrawler/issues/448,incubator-stormcrawler,217856007,448,Fetature Request- Support recursive crawling in the CrawlTopology,foromer4,10501096,Omer Schleifer,foromer4@gmail.com,CLOSED,2017-03-29T12:14:16Z,2017-08-02T09:05:01Z,"To support  recursive crawling ,it is suggested to modify the `CrawlTopology `used by the archtype so that it uses the `MemoryUpdaterBolt`.
Also, need to pass metadata to streams as a field.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/448/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/448,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5MTEzODA3Mw==,incubator-stormcrawler,291138073,448,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-04-03T13:11:02Z,2017-04-03T13:11:02Z,"Hi @foromer4 

> Also, need to pass metadata to streams as a field.

should be the case already

do you want to submit a PR for this?

Thanks!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5MTEzODA3Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/448,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5MTgyMzgwMQ==,incubator-stormcrawler,291823801,448,NA,foromer4,10501096,Omer Schleifer,foromer4@gmail.com,NA,2017-04-05T10:45:37Z,2017-04-05T10:45:37Z,"Sure ,I will take it. 

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5MTgyMzgwMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/448,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMxOTYxNDA3OA==,incubator-stormcrawler,319614078,448,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-08-02T09:05:01Z,2017-08-02T09:05:01Z,Closing as there has been no progress on it and it is a trivial task ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMxOTYxNDA3OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/450,https://api.github.com/repos/apache/incubator-stormcrawler/issues/450,incubator-stormcrawler,218859671,450,Upgrade to Storm 1.1.0,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-04-03T08:16:42Z,2017-04-27T13:34:49Z,"Storm 1.1.0 has been released and contains the fix I contributed to upgrade the logging dependencies, which is needed to run ES 5.

Upgrading to Storm 1.1.0 should be straightforward, except for the WARC module as the classes if leverages have undergone substantial changes in Storm.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/450/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/452,https://api.github.com/repos/apache/incubator-stormcrawler/issues/452,incubator-stormcrawler,218930892,452,Optimise nextFetchDate to speed up queries to Elasticsearch ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-04-03T13:20:41Z,2017-04-27T13:36:32Z,"The queries in the spouts take longer as the status index gets larger. We use sampling with the aggregation spouts but could also optimise the speed by querying on a nextFetchDate value which would be old enough to minimise the amount of docs on which the aggregations run, while retrieving as many docs as possible.

The same approach could also be used for the collapsing spout.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/452/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/452,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NTI5ODUzNQ==,incubator-stormcrawler,295298535,452,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-04-19T14:55:15Z,2017-04-19T14:55:15Z,The CollapsingSpout currently resets the Date to now if the number of buckets returned is 0. We could set a minimum number of buckets or a distance to the largest nextFetchDate returned when the sorting is on.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NTI5ODUzNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/453,https://api.github.com/repos/apache/incubator-stormcrawler/issues/453,incubator-stormcrawler,220418249,453,Issue while connecting to elasticsearch,iRajashekharC,17562178,Rajashekhar,rajshekhar.charantimath@gmail.com,CLOSED,2017-04-08T18:32:17Z,2017-04-09T14:24:18Z,"What kind of issue is this?

 - [x] Question. 
Hello,

I have been following video blog on  Storm Crawler.

I am trying to create a web crawler referring the WIKI<https://github.com/DigitalPebble/storm-crawler/tree/master/external/elasticsearch > and video <https://www.youtube.com/watch?v=xMCuWpPh-4A&feature=youtu.be> , but I am getting:

**java.lang.IllegalStateException: Received message from unsupported version: [2.0.0] minimal compatible version is: [5.0.0]**

I am using following:
Elasticsearch : 5.3.0 version
Storm: 1.0.3 version.

Please help me with what versions are recommended and used by you.

Appreciate your help.


Thanks!
Raj","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/453/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/453,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5Mjc0NzA3Mw==,incubator-stormcrawler,292747073,453,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-04-08T21:31:13Z,2017-04-08T21:31:13Z,"Please use StackOverflow in the future for asking questions such as these.
The video is based on the archetype 1.4 which uses ES 2.x but we've upgraded to ES5 since. Clone the repo, build with `mvn clean install` and recreate a new project with the archetype again but this time specifying 1.5-SNAPSHOT. This should get you the right dependencies for ES5.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5Mjc0NzA3Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/453,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5Mjc4ODkzMw==,incubator-stormcrawler,292788933,453,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-04-09T14:24:08Z,2017-04-09T14:24:08Z,"Thanks @raaz1234 for opening http://stackoverflow.com/questions/43307698/issue-while-connecting-to-elasticsearch

Closing this issue for now, assuming that the problem is sorted.  ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5Mjc4ODkzMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/455,https://api.github.com/repos/apache/incubator-stormcrawler/issues/455,incubator-stormcrawler,222750161,455,java.util.zip.ZipException: Not in GZIP format thrown on redirs with httpclient,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-04-19T14:06:23Z,2017-04-19T14:07:13Z,"An issue with the underlying http library which can be avoided by not pulling the content when we already know that it is a redirection. The fetchers will ignore the content anyway.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/455/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/456,https://api.github.com/repos/apache/incubator-stormcrawler/issues/456,incubator-stormcrawler,222829053,456,Twitter HERON upgrade label:wish,MyraBaba,17505439,,,CLOSED,2017-04-19T18:29:49Z,2017-04-20T09:12:12Z,"Hi,

We loved Twitter Heron simplicity , UI and performance. 

Do you have a plan to upgrade Twitter Heron or a way to support code base for Heron ?

Best

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/456/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/456,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NTY0NTMwMg==,incubator-stormcrawler,295645302,456,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-04-20T09:11:59Z,2017-04-20T09:11:59Z,"Hi @MyraBaba 

We'll see how Apache Storm and Heron evolve but at the moment this is definitely not planned.
I haven't tried Heron very much but it did not strike me as being simpler than Storm, quite the opposite. As for performance, is this something you observed yourself or have you just read about it? IIRC the comparisons I saw were based on older versions of Storm and anyway for web crawling, the bottlenecks are the politeness and the speed of the backends for recursive crawls, not much to do with Storm itself.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NTY0NTMwMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/458,https://api.github.com/repos/apache/incubator-stormcrawler/issues/458,incubator-stormcrawler,223611576,458,NoClassDefFoundError : Version: 1.5-snapshot ,saikatmohajan,3003914,SAIKAT MOHAJAN,,CLOSED,2017-04-23T04:23:03Z,2017-09-26T10:12:30Z,"**java.lang.NoClassDefFoundError: Could not initialize class org.elasticsearch.common.network.NetworkService
	at org.elasticsearch.client.transport.TransportClient.newPluginService(TransportClient.java:98) ~[stormjar.jar:?]**
	
I am getting this error when using storm crawler version 1.5- snapshot which uses elasticsearch 5.3.0. I ran the following command to inject the seed file to elasticsearch and getting the error:
**storm jar myjar-2.0-SNAPSHOT.jar com.digitalpebble.stormcrawler.elasticsearch.ESSeedInjector / seeds.txt -conf es-conf.yaml**

My code was working with storm crawler 1.4, but I needed to use elastic search 5.3.0. So, I am trying to build my code with 1.5-snapshot. myjar-2.0-SNAPSHOT.jar contains all the dependencies including org.elasticsearch dependencies. But, for some reason storm isn't picking up the elasticsearch library.  

Thanks
Saikat","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/458/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/458,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NjQ4NzYzOA==,incubator-stormcrawler,296487638,458,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-04-23T20:49:50Z,2017-04-23T20:49:50Z,"Hi, did you upgrade the log4j and slf4j dependencies (see STORM-2326) in your Storm installation? This won't be necessary in the next release of Apache Storm.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NjQ4NzYzOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/458,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NjUxMzEzOQ==,incubator-stormcrawler,296513139,458,NA,saikatmohajan,3003914,SAIKAT MOHAJAN,,NA,2017-04-24T02:53:08Z,2017-04-24T02:53:08Z,"Thank you @jnioche for your quick response. I upgraded the log4j libraries in my storm installation. But , still having the issue. I upagraded log4j-api, log4j-core, log4j-slf4j-impl from 2.1 to 2.8 and sl4j-api from 1.7.7 to 1.7.21 in my storm installation i.e. in /usr/hdp/2.5.0.0-1245/storm/lib folder in all nodes in the cluster. also restarted the cluster, but the issues remains to be the same. Is there anything else that I am missing. Thank you again for your help.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NjUxMzEzOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/458,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NjU2NjE0NA==,incubator-stormcrawler,296566144,458,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-04-24T08:02:13Z,2017-04-24T08:02:13Z,Do you have a longer stack trace? ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NjU2NjE0NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/458,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NjU4NjYzNg==,incubator-stormcrawler,296586636,458,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-04-24T09:04:10Z,2017-04-24T09:04:10Z,"Also  with ES5 we have to specify

```
	<manifestEntries>
									    <Change></Change>
									    <Build-Date></Build-Date>
									</manifestEntries>
```
for maven shade. See 
https://github.com/DigitalPebble/stormcrawlerfight/blob/es5.3/pom.xml#L66","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NjU4NjYzNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/458,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NjY1MDQxNw==,incubator-stormcrawler,296650417,458,NA,saikatmohajan,3003914,SAIKAT MOHAJAN,,NA,2017-04-24T12:35:33Z,2017-04-24T12:35:33Z,"Looks like the issue is related to manifest. However, I have the manifestEntries in my pom. here is my pom and the detail stack trace. and also I see that the latest jars are being picked up.
**pom.xml**
<properties>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
    <storm.core.version>1.0.2</storm.core.version>
    <storm.crawler.version>1.5-SNAPSHOT</storm.crawler.version>
    <flux.core.version>1.0.2</flux.core.version>
    <phantomjs.driver.version>1.3.0</phantomjs.driver.version>
    <xsoup.version>0.3.1</xsoup.version>
    <crawler-commons.version>0.7</crawler-commons.version>
    <elasticsearch.version>5.3.0</elasticsearch.version>
	</properties>

	<build>
		<plugins>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-compiler-plugin</artifactId>
				<version>3.2</version>
				<configuration>
					<source>1.8</source>
					<target>1.8</target>
				</configuration>
			</plugin>
			<plugin>
				<groupId>org.codehaus.mojo</groupId>
				<artifactId>exec-maven-plugin</artifactId>
				<version>1.3.2</version>
				<executions>
					<execution>
						<goals>
							<goal>exec</goal>
						</goals>
					</execution>
				</executions>
				<configuration>
					<executable>java</executable>
					<includeProjectDependencies>true</includeProjectDependencies>
					<includePluginDependencies>false</includePluginDependencies>
					<classpathScope>compile</classpathScope>
				</configuration>
			</plugin>
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-shade-plugin</artifactId>
        <version>1.3.3</version>
        <executions>
          <execution>
            <phase>package</phase>
            <goals>
              <goal>shade</goal>
            </goals>
            <configuration>
              <createDependencyReducedPom>false</createDependencyReducedPom>
              <transformers>
                <transformer implementation=""org.apache.maven.plugins.shade.resource.ServicesResourceTransformer"" />
                <transformer implementation=""org.apache.maven.plugins.shade.resource.ManifestResourceTransformer"">
                  <mainClass>org.apache.storm.flux.Flux</mainClass>
                  <manifestEntries>
                    <Change></Change>
                    <Build-Date></Build-Date>
                  </manifestEntries>
                </transformer>
              </transformers>
              <!-- The filters below are necessary if you want to include the Tika
                module -->
              <filters>
                <filter>
                  <artifact>*:*</artifact>
                  <excludes>
                    <exclude>META-INF/*.SF</exclude>
                    <exclude>META-INF/*.DSA</exclude>
                    <exclude>META-INF/*.RSA</exclude>
                  </excludes>
                </filter>
              </filters>
            </configuration>
          </execution>
        </executions>
      </plugin>

		</plugins>
	</build>

	<dependencies>
		<dependency>
			<groupId>org.apache.storm</groupId>
			<artifactId>storm-core</artifactId>
			<version>1.0.2</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.storm</groupId>
			<artifactId>flux-core</artifactId>
			<version>1.0.2</version>
		</dependency>
    <dependency>
      <groupId>com.github.crawler-commons</groupId>
      <artifactId>crawler-commons</artifactId>
      <version>${crawler-commons.version}</version>
    </dependency>
		<dependency>
			<groupId>com.digitalpebble.stormcrawler</groupId>
			<artifactId>storm-crawler-core</artifactId>
			<version>${storm.crawler.version}</version>
		</dependency>
    <dependency>
      <groupId>com.digitalpebble.stormcrawler</groupId>
      <artifactId>storm-crawler-elasticsearch</artifactId>
      <version>${storm.crawler.version}</version>
    </dependency>
   
    <dependency>
      <groupId>us.codecraft</groupId>
      <artifactId>xsoup</artifactId>
      <version>${xsoup.version}</version>
    </dependency>
    <dependency>
      <groupId>com.machinepublishers</groupId>
      <artifactId>jbrowserdriver</artifactId>
      <version>0.17.8-SNAPSHOT</version>
    </dependency>
  </dependencies>

**Error Log:** 
java.lang.NoClassDefFoundError: Could not initialize class org.elasticsearch.common.network.NetworkService
	at org.elasticsearch.client.transport.TransportClient.newPluginService(TransportClient.java:98) ~[stormjar.jar:?]
	at org.elasticsearch.client.transport.TransportClient.buildTemplate(TransportClient.java:126) ~[stormjar.jar:?]
	at org.elasticsearch.client.transport.TransportClient.<init>(TransportClient.java:268) ~[stormjar.jar:?]
	at org.elasticsearch.transport.client.PreBuiltTransportClient.<init>(PreBuiltTransportClient.java:125) ~[stormjar.jar:?]
	at org.elasticsearch.transport.client.PreBuiltTransportClient.<init>(PreBuiltTransportClient.java:111) ~[stormjar.jar:?]
	at com.digitalpebble.stormcrawler.elasticsearch.ElasticSearchConnection.getClient(ElasticSearchConnection.java:86) ~[stormjar.jar:?]
	at com.digitalpebble.stormcrawler.elasticsearch.ElasticSearchConnection.getConnection(ElasticSearchConnection.java:148) ~[stormjar.jar:?]
	at com.digitalpebble.stormcrawler.elasticsearch.persistence.StatusUpdaterBolt.prepare(StatusUpdaterBolt.java:141) ~[stormjar.jar:?]
	at org.apache.storm.daemon.executor$fn__6571$fn__6584.invoke(executor.clj:798) ~[storm-core-1.0.1.2.5.0.0-1245.jar:1.0.1.2.5.0.0-1245]
	at org.apache.storm.util$async_loop$fn__554.invoke(util.clj:482) [storm-core-1.0.1.2.5.0.0-1245.jar:1.0.1.2.5.0.0-1245]
	at clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_60]
2017-04-24 08:23:42.554 o.a.s.d.executor [ERROR] 
java.lang.NoClassDefFoundError: Could not initialize class org.elasticsearch.common.network.NetworkService
	at org.elasticsearch.client.transport.TransportClient.newPluginService(TransportClient.java:98) ~[stormjar.jar:?]
	at org.elasticsearch.client.transport.TransportClient.buildTemplate(TransportClient.java:126) ~[stormjar.jar:?]
	at org.elasticsearch.client.transport.TransportClient.<init>(TransportClient.java:268) ~[stormjar.jar:?]
	at org.elasticsearch.transport.client.PreBuiltTransportClient.<init>(PreBuiltTransportClient.java:125) ~[stormjar.jar:?]
	at org.elasticsearch.transport.client.PreBuiltTransportClient.<init>(PreBuiltTransportClient.java:111) ~[stormjar.jar:?]
	at com.digitalpebble.stormcrawler.elasticsearch.ElasticSearchConnection.getClient(ElasticSearchConnection.java:86) ~[stormjar.jar:?]
	at com.digitalpebble.stormcrawler.elasticsearch.ElasticSearchConnection.getConnection(ElasticSearchConnection.java:148) ~[stormjar.jar:?]
	at com.digitalpebble.stormcrawler.elasticsearch.persistence.StatusUpdaterBolt.prepare(StatusUpdaterBolt.java:141) ~[stormjar.jar:?]
	at org.apache.storm.daemon.executor$fn__6571$fn__6584.invoke(executor.clj:798) ~[storm-core-1.0.1.2.5.0.0-1245.jar:1.0.1.2.5.0.0-1245]
	at org.apache.storm.util$async_loop$fn__554.invoke(util.clj:482) [storm-core-1.0.1.2.5.0.0-1245.jar:1.0.1.2.5.0.0-1245]
	at clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_60]
2017-04-24 08:23:42.543 o.a.s.util [ERROR] Async loop died!
java.lang.ExceptionInInitializerError: null
	at org.elasticsearch.common.logging.DeprecationLogger.<clinit>(DeprecationLogger.java:138) ~[stormjar.jar:?]
	at org.elasticsearch.common.xcontent.support.AbstractXContentParser.<init>(AbstractXContentParser.java:57) ~[stormjar.jar:?]
	at org.elasticsearch.common.xcontent.json.JsonXContentParser.<init>(JsonXContentParser.java:44) ~[stormjar.jar:?]
	at org.elasticsearch.common.xcontent.json.JsonXContent.createParser(JsonXContent.java:103) ~[stormjar.jar:?]
	at org.elasticsearch.common.settings.Setting.parseableStringToList(Setting.java:832) ~[stormjar.jar:?]
	at org.elasticsearch.common.settings.Setting.lambda$listSetting$27(Setting.java:786) ~[stormjar.jar:?]
	at org.elasticsearch.common.settings.Setting.listSetting(Setting.java:791) ~[stormjar.jar:?]
	at org.elasticsearch.common.settings.Setting.listSetting(Setting.java:786) ~[stormjar.jar:?]
	at org.elasticsearch.common.network.NetworkService.<clinit>(NetworkService.java:50) ~[stormjar.jar:?]
	at org.elasticsearch.client.transport.TransportClient.newPluginService(TransportClient.java:98) ~[stormjar.jar:?]
	at org.elasticsearch.client.transport.TransportClient.buildTemplate(TransportClient.java:126) ~[stormjar.jar:?]
	at org.elasticsearch.client.transport.TransportClient.<init>(TransportClient.java:268) ~[stormjar.jar:?]
	at org.elasticsearch.transport.client.PreBuiltTransportClient.<init>(PreBuiltTransportClient.java:125) ~[stormjar.jar:?]
	at org.elasticsearch.transport.client.PreBuiltTransportClient.<init>(PreBuiltTransportClient.java:111) ~[stormjar.jar:?]
	at com.digitalpebble.stormcrawler.elasticsearch.ElasticSearchConnection.getClient(ElasticSearchConnection.java:86) ~[stormjar.jar:?]
	at com.digitalpebble.stormcrawler.elasticsearch.ElasticSearchConnection.getConnection(ElasticSearchConnection.java:148) ~[stormjar.jar:?]
	at com.digitalpebble.stormcrawler.elasticsearch.ElasticSearchConnection.getConnection(ElasticSearchConnection.java:130) ~[stormjar.jar:?]
	at com.digitalpebble.stormcrawler.elasticsearch.metrics.MetricsConsumer.prepare(MetricsConsumer.java:93) ~[stormjar.jar:?]
	at org.apache.storm.metric.MetricsConsumerBolt.prepare(MetricsConsumerBolt.java:75) ~[storm-core-1.0.1.2.5.0.0-1245.jar:1.0.1.2.5.0.0-1245]
	at org.apache.storm.daemon.executor$fn__6571$fn__6584.invoke(executor.clj:798) ~[storm-core-1.0.1.2.5.0.0-1245.jar:1.0.1.2.5.0.0-1245]
	at org.apache.storm.util$async_loop$fn__554.invoke(util.clj:482) [storm-core-1.0.1.2.5.0.0-1245.jar:1.0.1.2.5.0.0-1245]
	at clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_60]
Caused by: java.lang.NullPointerException
	at org.elasticsearch.Build.<clinit>(Build.java:49) ~[stormjar.jar:?]
	... 23 more
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NjY1MDQxNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/458,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NjgxMTA5Mw==,incubator-stormcrawler,296811093,458,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-04-24T20:22:47Z,2017-04-24T20:22:47Z,"https://github.com/elastic/elasticsearch/blob/5.3/core/src/main/java/org/elasticsearch/Build.java#L49
wondering what the [stormjar.jar:?] could correspond to? something added by hdp? could you try on a standalone Storm distribution?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NjgxMTA5Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/458,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NzcxNTI4Mg==,incubator-stormcrawler,297715282,458,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-04-27T13:37:05Z,2017-04-27T13:37:05Z,@saikatmohajan any luck?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NzcxNTI4Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/458,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NzcxNjI4Mw==,incubator-stormcrawler,297716283,458,NA,saikatmohajan,3003914,SAIKAT MOHAJAN,,NA,2017-04-27T13:41:02Z,2017-04-27T13:41:02Z,"Hey Julien, 
                  I haven't tried running on stand alone server yet. Will try soon and keep you posted. and also trying to figure out why it's picking up an storm jar without the version information in it. 
Thank you.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5NzcxNjI4Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/458,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwMTQ0MjIzOQ==,incubator-stormcrawler,301442239,458,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-05-15T10:54:16Z,2017-05-15T10:54:16Z,Closing for now. ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwMTQ0MjIzOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/458,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMzMjE1MjU0MA==,incubator-stormcrawler,332152540,458,NA,ericxu131,340417,Eric Xu,,NA,2017-09-26T10:12:30Z,2017-09-26T10:12:30Z,@saikatmohajan Try to upgrade lucene version. I fixed this error when i changed lucene version from 6.5.1 to 6.6.1.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMzMjE1MjU0MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/460,https://api.github.com/repos/apache/incubator-stormcrawler/issues/460,incubator-stormcrawler,224837631,460,Indicate whether RobotsRules come from cache or have been fetched,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-04-27T16:14:31Z,2017-04-27T16:30:15Z,Needed for #343 but also to generate useful metrics about the rate at which robot rules are fetched,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/460/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/461,https://api.github.com/repos/apache/incubator-stormcrawler/issues/461,incubator-stormcrawler,225594969,461,Installing Storm crawler on Cygwin,cadelina,4171538,Jade CADELINA,cadelina@gmail.com,CLOSED,2017-05-02T05:37:11Z,2017-05-02T08:12:39Z,"Is it possible to run Storm-crawler using Cygwin?

I've got Elasticsearch and Kibana installed on Windows 2012 but I can't get Storm-crawler to run under Windows. 

What I've done is install Cygwin but I cannot execute Storm within Cygwin.

Any ideas?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/461/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/461,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5ODU0NjAzNA==,incubator-stormcrawler,298546034,461,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-05-02T08:12:39Z,2017-05-02T08:12:39Z,"Hi @cadelina 

http://ptgoetz.github.io/blog/2013/12/18/running-apache-storm-on-windows/ explains the steps to follow

Alternatively you could run SC without Storm and via Maven with 

`mvn clean compile exec:java -Dexec.mainClass=org.apache.storm.flux.Flux -Dexec.args=""--local crawler.flux --sleep 60000""`

For questions, please use StackOverflow, thanks!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDI5ODU0NjAzNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/462,https://api.github.com/repos/apache/incubator-stormcrawler/issues/462,incubator-stormcrawler,226512433,462,Memory issues when ByteArrayBuffer gets instantiated with a large value despite maxLength being set ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-05-05T09:00:28Z,2017-05-05T09:06:20Z,"Am getting a heapdump where a single ByteArrayBuffer takes 1,111,950,000 bytes, despite the max content having been set to 52,428,800

https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/protocol/httpclient/HttpProtocol.java#L261

We should instantiate the ByteArrayBuffer with the max length instead of the one returned by the server","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/462/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/463,https://api.github.com/repos/apache/incubator-stormcrawler/issues/463,incubator-stormcrawler,227044907,463,HTTP Protocol reads the whole content when calling close() on the stream,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-05-08T13:24:56Z,2017-07-06T10:47:18Z,"In case of very large content, we end up pulling the whole thing even though we want to trim it. This can, in turn, lead to timeouts. 

Here are some very large URLs to test on 
___
http://get.gamexp.ru/BGO_160224/BGO_20160224-2.bin
http://get.gamexp.ru/BGO_160224/BGO_20160224-4.bin
http://get.gamexp.ru/BGO_160224/BGO_20160224-6.bin
http://get.gamexp.ru/BGO_160224/BGO_20160224-3.bin
http://get.gamexp.ru/BGO_160224/BGO_20160224-1.bin
http://get.gamexp.ru/BGO_160224/BGO_20160224-5.bin
___

what's worse, CloseableHTTTPClient calls `EntityUtils.consume(entity);` so it looks like we are trying to close it twice anyway.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/463/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/463,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwNDg3ODc0Mg==,incubator-stormcrawler,304878742,463,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-05-30T13:31:16Z,2017-05-30T13:31:16Z,"OKHTTP can handle that, not HTTP client. Won't fix","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwNDg3ODc0Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/463,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMxMzM2MjQzOQ==,incubator-stormcrawler,313362439,463,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-07-06T10:47:18Z,2017-07-06T10:47:18Z,See https://issues.apache.org/jira/browse/HTTPCLIENT-1861,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMxMzM2MjQzOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/464,https://api.github.com/repos/apache/incubator-stormcrawler/issues/464,incubator-stormcrawler,229758327,464,FetcherBolt to dump URLs being fetched to log,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-05-18T18:05:50Z,2017-05-18T18:07:10Z,"The existing mechanism dumps the content of the queues but not the URLs being fetched, which would be useful e.g. a URL takes forever....","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/464/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/465,https://api.github.com/repos/apache/incubator-stormcrawler/issues/465,incubator-stormcrawler,230215146,465,[Elasticsearch] index with parent child relationship,faustro,28839310,Faustin Roman,,CLOSED,2017-05-21T11:44:53Z,2017-05-25T09:20:40Z,"Wish: index documents with parent_child schema:
https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-parent-field.html

I tried to implement this using 1.5-SNAPSHOT.
I created the index with the required mappings for parent_child.

Here is my modified IndexerBolt.java:

            IndexRequestBuilder request = connection.getClient()
                    .prepareIndex(indexName, docType).setSource(builder)
                    .setId(sha256hex)
                    .setParent(""1"")
                    .setRouting(""1"");

.setRouting works and documents get indexed
If I add .setParent, documents are not indexed.

Can storm send to ES parent and routing parameters?

Might be also useful to have a file option, e.g. es.indexer.routing, es.indexer.parent","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/465/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/465,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwMzA3NjMzNg==,incubator-stormcrawler,303076336,465,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-05-22T11:41:38Z,2017-05-22T11:41:38Z,"Do the Elasticsearch logs contain any information as to why the documents do not get indexed?

In your snippet above, ""1"" is probably not a valid document ID, it should be the sha256hex of the parent URL.

> Can storm send to ES parent and routing parameters?

You probably mean StormCrawler and not Storm but more likely to be a problem with ES itself.

From [https://www.elastic.co/guide/en/elasticsearch/guide/current/indexing-parent-child.html] 

> However, if a parent ID is specified, it is used as the routing value instead of the _id. In other words, both the parent and the child use the same routing value—the _id of the parent—and so they are both stored on the same shard.

If you can do it with curl then there is no reason why you shouldn't be able to do it with SC.




","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwMzA3NjMzNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/465,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwMzMzODA1OQ==,incubator-stormcrawler,303338059,465,NA,faustro,28839310,Faustin Roman,,NA,2017-05-23T09:08:32Z,2017-05-23T09:08:32Z,"ES has nothing in the log, is like the query is not even sent to the ES (if I enable .setParent)

“1” in the snippet is just an example and works with setId or setRouting.
Adding .setParent creates an issue.
Could you please confirm you can replicate it?
How can I log what is sent from SC to ES? (in local mode)

Thanks for the quick reply!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwMzMzODA1OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/465,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwMzk2MjY2Ng==,incubator-stormcrawler,303962666,465,NA,faustro,28839310,Faustin Roman,,NA,2017-05-25T09:13:45Z,2017-05-25T09:13:45Z,"I had an error in the ES mapping definition for ""_parent"" that let to strange results: index created but documents not created, hence no logs...Now is working!

StormCrawler rocks!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwMzk2MjY2Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/465,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwMzk2NDA4Mw==,incubator-stormcrawler,303964083,465,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-05-25T09:20:40Z,2017-05-25T09:20:40Z,"> StormCrawler rocks!

Thanks, glad you like it! Feel free to tell the world about it ;-)","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwMzk2NDA4Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/466,https://api.github.com/repos/apache/incubator-stormcrawler/issues/466,incubator-stormcrawler,230350643,466,JSoup parser to handle text/plain,jnioche,218319,Julien Nioche,julien@digitalpebble.com,OPEN,2017-05-22T10:24:00Z,2017-05-22T10:24:00Z,"There is no parsing involved so we might as well do it.

2017-05-22 11:16:54.269 c.d.s.b.JSoupParserBolt Thread-10-parse-executor[7 7] [ERROR] Exception content-type text/plain for http://www.murfreesboropost.com/candidates-for-state-house-district-34-cms-23820
2017-05-22 11:16:55.921 c.d.s.b.JSoupParserBolt Thread-42-parse-executor[5 5] [ERROR] Exception content-type text/plain for http://www.murfreesboropost.com/candidates-for-state-house-district-62-cms-23821
2017-05-22 11:16:57.049 c.d.s.b.JSoupParserBolt Thread-4-parse-executor[8 8] [ERROR] Exception content-type text/plain for http://www.murfreesboropost.com/rutherford-county-sheriff-candidates-cms-23826

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/466/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/467,https://api.github.com/repos/apache/incubator-stormcrawler/issues/467,incubator-stormcrawler,230378517,467,FetcherBolt to check if tuple beyond timeout before fetching,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-05-22T12:23:31Z,2017-06-01T17:30:36Z,"When URLs get stuck in the fetch queues because we are busy being polite or fetching another URL from the same queue, they eventually get fetched even though they were already timed-out by Storm. The spouts would then release them (possibly after a delay) and they get selected for fetching again. As a result, they can appear in the queues several times.

One option would be to check whether the same URL already is in the queue and if so, simply ack or fail the tuple but checking the content of the queues could be costly.

Another option would be to add a timestamp in the metadata when the FetcherBolt enqueues the tuple and check just before fetching whether it has gone past the timeout and has already been failed.

The SimpleFetcherBolt could use a similar approach but since the queue is external to it, the timestamp would need to be added further up the topology chain e.g. by the spout.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/467/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/467,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwNDMyNTQxNA==,incubator-stormcrawler,304325414,467,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-05-26T16:19:55Z,2017-05-26T16:19:55Z,"The FetcherBolt could also have a config to indicate a max number of elements in a given queue, if a URL is added to a queue which is already full, we'll fail the corresponding tuple. It will be tried later for sure but at least it won't sit in the queue for ages.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwNDMyNTQxNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/467,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwNTU2NDA4MA==,incubator-stormcrawler,305564080,467,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-06-01T17:30:36Z,2017-06-01T17:30:36Z,#470 is good enough for now. Not sure many people use SimpleFetcherBolt and it would need a more complex solution.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwNTU2NDA4MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/468,https://api.github.com/repos/apache/incubator-stormcrawler/issues/468,incubator-stormcrawler,230409284,468,HTTP protocol - deal with slow streams,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-05-22T14:13:37Z,2017-05-30T13:32:15Z,Some URLs return endless streams which generate data at a very slow rate. The max length is not very useful for those as it takes too long before we get to the threshold. We should have a config at the protocol level instead to set a completion timeout.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/468/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/468,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwNDg3OTAzOQ==,incubator-stormcrawler,304879039,468,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-05-30T13:32:15Z,2017-05-30T13:32:15Z,"Won't fix with stupid httpclient. Done in OKHTTP, closing","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwNDg3OTAzOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/469,https://api.github.com/repos/apache/incubator-stormcrawler/issues/469,incubator-stormcrawler,230651350,469,Override sitemapsAutoDiscovery settings per URL,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-05-23T09:54:33Z,2017-05-23T09:55:28Z,Could set  `sitemap.discovery=[true|false]` in the seeds to override the global settings.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/469/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/470,https://api.github.com/repos/apache/incubator-stormcrawler/issues/470,incubator-stormcrawler,232260470,470,FetcherBolt to limit max size of internal queues,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-05-30T13:52:53Z,2017-06-01T11:23:31Z,"See #467 

if `fetcher.max.queue.size` is > 0 and the queue for a given tuple is already at that limit, we will fail the tuple. It will get replayed later on but at least it won't sit in the queue (and be failed anyway).
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/470/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/471,https://api.github.com/repos/apache/incubator-stormcrawler/issues/471,incubator-stormcrawler,232847302,471,Can't get sitemaps from robots.txt,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-06-01T11:22:07Z,2017-06-01T11:58:33Z,"Bug introduced by #460, basically the wrapper class does not delegate the call to getSitemaps

Might be sufficient to trigger a 1.5.1 release","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/471/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/472,https://api.github.com/repos/apache/incubator-stormcrawler/issues/472,incubator-stormcrawler,233145168,472,Enhancement: Access to JSoup Document from ParseFilters,owenrh,2006075,Owen Rees-Hayward,,CLOSED,2017-06-02T10:44:12Z,2017-10-06T12:10:32Z,"For pages with malformed HTML there are scenarios where the XPathFilter, etc, are unable to parse some links present in a page. However, I've found that JSoup is able to parse links from the content.

Consequently, it would be really helpful to be able to access the JSoup Document created by the JSoupParser bolt in the parse filters themselves, or have the ability to create JSoup specific filters. I guess the former would require an API change, but the latter would split the emitting of links across the codebase unnecessarily.

As a work around, I've updated our custom JSoupParserBolt to attach the JSoup document onto ThreadLocal - but this is obviously a big old hack : o","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/472/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/472,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwNTc1NTYxMA==,incubator-stormcrawler,305755610,472,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-06-02T10:57:15Z,2017-06-02T10:57:15Z,"if you can access the data from the JSoup Document there it should be possible to get that across to the DOM representation in [JSoupDOMBuilder](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/parse/JSoupDOMBuilder.java), shouldn't it?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwNTc1NTYxMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/472,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwNTc2MjY3MQ==,incubator-stormcrawler,305762671,472,NA,owenrh,2006075,Owen Rees-Hayward,,NA,2017-06-02T11:37:49Z,2017-06-02T11:37:49Z,"@jnioche I'm not familiar with JSoupDomBuilder, but I guess you're saying that a modification to that would mean the links could make their way into the DocumentFragment passed into the parse filters. 

So then the XPathFilter would find the now well-formed links?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwNTc2MjY3MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/472,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwNTc2MjgzOQ==,incubator-stormcrawler,305762839,472,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-06-02T11:38:42Z,2017-06-02T11:38:42Z,Exactly. ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwNTc2MjgzOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/472,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwNTc3MDIxMQ==,incubator-stormcrawler,305770211,472,NA,owenrh,2006075,Owen Rees-Hayward,,NA,2017-06-02T12:18:47Z,2017-06-02T12:18:47Z,"Cool, when I've got a mo I'll have a look at it and see if I can patch it somehow.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMwNTc3MDIxMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/472,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMzNDczNzExOQ==,incubator-stormcrawler,334737119,472,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-10-06T12:10:32Z,2017-10-06T12:10:32Z,"Can't reproduce, closing for now","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMzNDczNzExOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/473,https://api.github.com/repos/apache/incubator-stormcrawler/issues/473,incubator-stormcrawler,233154673,473,Upgrade to Tika 1.15,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-06-02T11:28:41Z,2017-06-02T11:29:11Z,Self explanatory,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/473/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/474,https://api.github.com/repos/apache/incubator-stormcrawler/issues/474,incubator-stormcrawler,234780487,474,Upgrade to Crawler-Commons 0.8,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-06-09T10:03:41Z,2017-06-09T10:05:39Z,This will remove the sub dependency we had on an older version of httpclient but also faster; leaner and more robust SAX-based sitemap parsing.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/474/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/476,https://api.github.com/repos/apache/incubator-stormcrawler/issues/476,incubator-stormcrawler,234798670,476,Add option to send only N bytes of text to indexers,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-06-09T11:26:40Z,2018-03-05T11:28:35Z,"IIRC this is done in Nutch and could be useful to improve the perfs of the indexing. Based on the assumption that the whole text of a document is not necessary for search, we could trim it to the first N chars.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/476/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/477,https://api.github.com/repos/apache/incubator-stormcrawler/issues/477,incubator-stormcrawler,235519134,477,discoveryDate and lastProcessedDate do not specify the timezone,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-06-13T11:15:08Z,2017-06-13T11:57:08Z,which means we need to know which zone is used implicitly by the servers,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/477/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/478,https://api.github.com/repos/apache/incubator-stormcrawler/issues/478,incubator-stormcrawler,235555211,478,Elasticsearch spouts don't load newly added seeds,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-06-13T13:32:10Z,2017-06-14T09:53:24Z,"Since version 1.5, the spouts try to optimise the query on nextFetchDate by reusing it unless no documents are found. This works fine for cases where all the seeds are injected at the same time, but not when new seeds are added while the crawl is already under way. 

We should add a new config indicating that we want to always use NOW as a nextFetchDate or better a max amount of time since the previous value of nextFetchDate so that we'd update it e.g. every few minutes.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/478/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/479,https://api.github.com/repos/apache/incubator-stormcrawler/issues/479,incubator-stormcrawler,238827212,479,Exclude content of <style> element from text representation,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-06-27T12:00:49Z,2017-08-02T09:03:45Z,"https://www.w3schools.com/tags/tag_style.asp
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/479/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/479,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMxNjM5MDk1Mw==,incubator-stormcrawler,316390953,479,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-07-19T13:40:45Z,2017-07-19T13:40:45Z,can't reproduce the issue,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMxNjM5MDk1Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/480,https://api.github.com/repos/apache/incubator-stormcrawler/issues/480,incubator-stormcrawler,238840639,480,ContentFilter to leave trace of the pattern that matched (if any),jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-06-27T12:52:54Z,2017-06-27T12:53:41Z,This can be useful for debugging and also to prevent a less reliable mechanism to match if we already found something good with Xpath e.g. BoilerPipe,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/480/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/481,https://api.github.com/repos/apache/incubator-stormcrawler/issues/481,incubator-stormcrawler,238856532,481,languageId: configurable minimalConfidence,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-06-27T13:46:11Z,2017-08-30T09:24:10Z,"The default is very high (0.999) which means that we get no language code if it is below. We might want to be able to set to a lower value, we'll get the best candidate anyway. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/481/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/481,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMyNTkzMDQ1Nw==,incubator-stormcrawler,325930457,481,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-08-30T09:05:55Z,2017-08-30T09:05:55Z,"or at least get all the languages with their probabilities and decide which ones have the highest values
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMyNTkzMDQ1Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/483,https://api.github.com/repos/apache/incubator-stormcrawler/issues/483,incubator-stormcrawler,240612313,483,Add scope to parsefilters,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-07-05T10:51:15Z,2023-12-05T16:15:53Z,"ParseFilters can be called from various parser implementations: sitemap, feeds, jsoup, tika.
it could be useful to add an optional _scope_ in their definition so that we'd avoid loading / executing them for a particular bolt.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/483/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/485,https://api.github.com/repos/apache/incubator-stormcrawler/issues/485,incubator-stormcrawler,242018145,485,Configure HTTP protocol to use HEAD method only,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-07-11T11:41:45Z,2017-07-11T12:02:31Z,"This can be done on a per URL basis for cases where we only want to know the HTTP headers returned by the server without getting the actual content e.g. is this URL redirected and of so where to?

This can be done on a per URL basis by giving a tuple an arbitrary key/value such as `http.method.head`","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/485/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/485,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMxNDQyMjEzNg==,incubator-stormcrawler,314422136,485,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-07-11T12:02:31Z,2017-07-11T12:02:31Z,Add this to #486 ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMxNDQyMjEzNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/486,https://api.github.com/repos/apache/incubator-stormcrawler/issues/486,incubator-stormcrawler,242023108,486,describe capabilities of various protocol implementations,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-07-11T12:02:13Z,2017-07-11T14:05:35Z,"We have the following http protocol implementations: 
- httpclient
- okhttp
- selenium

we need a description of what each one does or not.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/486/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/486,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMxNDQ1NDU1NA==,incubator-stormcrawler,314454554,486,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-07-11T14:05:35Z,2017-07-11T14:05:35Z,See https://github.com/DigitalPebble/storm-crawler/wiki/Protocols,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMxNDQ1NDU1NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/489,https://api.github.com/repos/apache/incubator-stormcrawler/issues/489,incubator-stormcrawler,247743850,489,Add config to shard based on instance number instead of field,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-08-03T15:22:39Z,2024-05-03T11:32:34Z,"This way all the documents sent by a particular bolt instance would go to the same shard, instead of the request being split and sent to separate nodes then the result aggregated by the coordinating node.

This means that we'd need to have one instance per shard, just like with the spouts and use [URLStreamGrouping](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/util/URLStreamGrouping.java).

The internal cache would still be used as a given URL would be consistently sent to the same bolt instance.

Ideally, we would be able to detect an ideal mapping where local nodes are used if possible.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/489/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/489,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58veyD,incubator-stormcrawler,2092821635,489,NA,rzo1,13417392,Richard Zowalla,,NA,2024-05-03T11:32:34Z,2024-05-03T11:32:34Z,We dropped ES as we joined the ASF incubator. Closing.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58veyD/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/490,https://api.github.com/repos/apache/incubator-stormcrawler/issues/490,incubator-stormcrawler,250875340,490,Usage of DateFormat is not thread-safe,tendres1980,16487396,,,CLOSED,2017-08-17T09:02:29Z,2017-08-21T09:11:24Z,"The usage of DateFormat in several classes is not thread-safe. Either use the new Java 8 date/time API or make them thread-safe.

e.g. for Java 8 replace
`protected SimpleDateFormat httpDateFormat = new SimpleDateFormat(
            ""EEE, dd MMM yyyy HH:mm:ss zzz"", Locale.US);`

with:
`protected DateTimeFormatter httpDateFormat = java.time.format.DateTimeFormatter.RFC_1123_DATE_TIME;`

then format the current time via:
`ZonedDateTime date = ZonedDateTime.now(ZoneId.systemDefault());
String now = httpDateFormat.format(date);`

For Java <8:
`private static final ThreadLocal<DateFormat> DATEFORMAT = new ThreadLocal<DateFormat>() {
        protected DateFormat initialValue() {
            return new SimpleDateFormat(""EEE, dd MMM yyyy HH:mm:ss zzz"", Locale.US);
        }
    };`","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/490/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/490,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMyMzY5MDE5OA==,incubator-stormcrawler,323690198,490,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-08-21T09:11:24Z,2017-08-21T09:11:24Z,"Same as for the other issue, please reopen it if you want me to look at it.
I can see only 2 uses of DateFormat - one in the ES metrics consumers and one in AbstractStatusUpdaterBolt, where it does not matter as we know that the execute method is not accessed by more than one thread at a time. Any other uses I've missed?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMyMzY5MDE5OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/491,https://api.github.com/repos/apache/incubator-stormcrawler/issues/491,incubator-stormcrawler,250924833,491,Add timezone to date-format used in AbstractStatusUpdaterBolt,tendres1980,16487396,,,CLOSED,2017-08-17T12:19:39Z,2017-09-01T14:36:30Z,"The date-format used in the AbstractStatusUpdaterBolt does not specify a timezone. The format is used for the metadata 'discoveryDate' and 'lastProcessedDate'. When trying to store these dates for example in an elastic index, this leads to problems since the default timezone for elastic is UTC. When these dates are stored in elastic (using a date-format) for a different timezone, the dates are no longer correct. 

For example I am running the storm-crawler on a machine with CEST timezone, getting a date like '2017-08-17T14:16:00'. When looking at the date in elastic through kibana it shows as 'August 17th 2017, 16:16:00.000' which is the original date interpreted as UTC.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/491/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/491,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMyMzY4Nzg5OQ==,incubator-stormcrawler,323687899,491,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-08-21T09:01:52Z,2017-08-21T09:01:52Z,Hi @tendres1980. Thanks for opening this issue. any reason why you closed it? I see you created #492 so I presume this is still valid. If so please reopen it - it should be closed only when the problem is solved or invalid. Thanks! ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMyMzY4Nzg5OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/491,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMyNjU5NzM1MA==,incubator-stormcrawler,326597350,491,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-09-01T14:36:30Z,2017-09-01T14:36:30Z,"Actually not related to #492 and probably closed as fixed in master branch in 80098788f4733f9f416135f81e8aabff1a648602
duplicates #477","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMyNjU5NzM1MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/493,https://api.github.com/repos/apache/incubator-stormcrawler/issues/493,incubator-stormcrawler,251952611,493,Upgrade to ES 5.6.1,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-08-22T13:14:11Z,2017-10-10T13:46:06Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/493/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/493,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMyNDA1MDIwNA==,incubator-stormcrawler,324050204,493,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-08-22T14:48:52Z,2017-08-22T14:48:52Z,"Getting 
```
8861 [Thread-26-status-executor[22 22]] ERROR o.a.s.d.executor - 
java.lang.RuntimeException: java.lang.IllegalStateException: availableProcessors is already set to [8], rejecting [8]
	at com.digitalpebble.stormcrawler.elasticsearch.persistence.StatusUpdaterBolt.prepare(StatusUpdaterBolt.java:145) ~[storm-crawler-fight-2.0-SNAPSHOT.jar:?]
	at org.apache.storm.daemon.executor$fn__5044$fn__5057.invoke(executor.clj:791) ~[storm-core-1.1.0.jar:1.1.0]
	at org.apache.storm.util$async_loop$fn__557.invoke(util.clj:482) [storm-core-1.1.0.jar:1.1.0]
	at clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_144]
Caused by: java.lang.IllegalStateException: availableProcessors is already set to [8], rejecting [8]
	at io.netty.util.NettyRuntime$AvailableProcessorsHolder.setAvailableProcessors(NettyRuntime.java:51) ~[storm-crawler-fight-2.0-SNAPSHOT.jar:?]
	at io.netty.util.NettyRuntime.setAvailableProcessors(NettyRuntime.java:87) ~[storm-crawler-fight-2.0-SNAPSHOT.jar:?]
	at org.elasticsearch.transport.netty4.Netty4Utils.setAvailableProcessors(Netty4Utils.java:82) ~[storm-crawler-fight-2.0-SNAPSHOT.jar:?]
	at org.elasticsearch.transport.netty4.Netty4Transport.<init>(Netty4Transport.java:138) ~[storm-crawler-fight-2.0-SNAPSHOT.jar:?]
	at org.elasticsearch.transport.Netty4Plugin.lambda$getTransports$0(Netty4Plugin.java:93) ~[storm-crawler-fight-2.0-SNAPSHOT.jar:?]
	at org.elasticsearch.client.transport.TransportClient.buildTemplate(TransportClient.java:174) ~[storm-crawler-fight-2.0-SNAPSHOT.jar:?]
	at org.elasticsearch.client.transport.TransportClient.<init>(TransportClient.java:265) ~[storm-crawler-fight-2.0-SNAPSHOT.jar:?]
	at org.elasticsearch.transport.client.PreBuiltTransportClient.<init>(PreBuiltTransportClient.java:130) ~[storm-crawler-fight-2.0-SNAPSHOT.jar:?]
	at org.elasticsearch.transport.client.PreBuiltTransportClient.<init>(PreBuiltTransportClient.java:116) ~[storm-crawler-fight-2.0-SNAPSHOT.jar:?]
	at com.digitalpebble.stormcrawler.elasticsearch.ElasticSearchConnection.getClient(ElasticSearchConnection.java:86) ~[storm-crawler-fight-2.0-SNAPSHOT.jar:?]
	at com.digitalpebble.stormcrawler.elasticsearch.ElasticSearchConnection.getConnection(ElasticSearchConnection.java:148) ~[storm-crawler-fight-2.0-SNAPSHOT.jar:?]
	at com.digitalpebble.stormcrawler.elasticsearch.persistence.StatusUpdaterBolt.prepare(StatusUpdaterBolt.java:141) ~[storm-crawler-fight-2.0-SNAPSHOT.jar:?]
	... 4 more
```
See https://discuss.elastic.co/t/elasticsearch-5-4-1-availableprocessors-is-already-set/88036/4
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMyNDA1MDIwNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/493,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMzMDgzMTMzMg==,incubator-stormcrawler,330831332,493,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-09-20T12:06:59Z,2017-09-20T12:06:59Z,"The exception above is due to the fact that the status updater bolt creates on instance of the ES client for each bolt instead of sharing them across the JVM as we do e.g. for the spouts by having a static instance.

However, we would still have multiple clients as we'd be sending to the metrics, status and doc index separately.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMzMDgzMTMzMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/493,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMzNTQ3NzQzMw==,incubator-stormcrawler,335477433,493,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-10-10T13:46:06Z,2017-10-10T13:46:06Z,Done in #500 ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMzNTQ3NzQzMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/494,https://api.github.com/repos/apache/incubator-stormcrawler/issues/494,incubator-stormcrawler,252024748,494,Status dashboard fails to visualize Top-Hosts,wolverline,460865,G Mohr,odwolfe@yahoo.com,CLOSED,2017-08-22T16:59:42Z,2017-09-01T13:51:11Z,"I followed the import process and the Kibana Json file looks like:

Line: 9
`""panelsJSON"": ""[{\""col\"":1,\""id\"":\""status-count\"",\""row\"":1,\""size_x\"":4,\""size_y\"":5,\""type\"":\""visualization\""},{\""id\"":\""Top-Hosts\"",\""type\"":\""visualization\"",\""size_x\"":4,\""size_y\"":5,\""col\"":5,\""row\"":1}]"",`

The screen shot:
![kibana_status](https://user-images.githubusercontent.com/460865/29577477-91576bca-8739-11e7-8f9b-ebaffc3c05c3.png)

Is this a bug or something I missed out some settings?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/494/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/494,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMyNDI0OTg2OQ==,incubator-stormcrawler,324249869,494,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-08-23T07:49:40Z,2017-08-23T07:49:40Z,"Did you change the following [config](https://github.com/DigitalPebble/storm-crawler/blob/master/external/elasticsearch/es-conf.yaml#L27)?

  _es.status.routing.fieldname: ""metadata.hostname""_

Did you load the dashboard schema before injecting the documents? If so, Kibana does not know that there is a field `metadata.hostname`. Could you try to refresh the field list in Management -> Index? 

One option would be to have a generic field name e.g. `key` regardless of what we use for sharding (host/domain/ip) and define it in the ES mapping script.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMyNDI0OTg2OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/494,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMyNjU4NTQyNA==,incubator-stormcrawler,326585424,494,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-09-01T13:51:11Z,2017-09-01T13:51:11Z,Can't reproduce. Please reopen with more info if still relevant,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMyNjU4NTQyNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/496,https://api.github.com/repos/apache/incubator-stormcrawler/issues/496,incubator-stormcrawler,254662444,496,Use ISO representation of time for modifiedtime in adaptivescheduler,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-09-01T14:43:01Z,2017-09-01T14:43:41Z,"See #492
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/496/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/498,https://api.github.com/repos/apache/incubator-stormcrawler/issues/498,incubator-stormcrawler,258831710,498,*ParserBolts should use outlinks from parsefilters ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-09-19T14:00:53Z,2017-09-19T14:15:10Z,"As done by [JSoupParserBolt](https://github.com/DigitalPebble/storm-crawler/blob/e394917f65e22b8e4512279cee603e75cdb2ca31/core/src/main/java/com/digitalpebble/stormcrawler/bolt/JSoupParserBolt.java#L329) and not the original array so that if any parsefilters modify the outlinks the modified version will be used.

Affects FeedParserBolt and SitemapParserBolt","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/498/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/499,https://api.github.com/repos/apache/incubator-stormcrawler/issues/499,incubator-stormcrawler,258871888,499,HTTP clients should handle http.accept.language and http.accept,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-09-19T15:50:49Z,2017-10-19T12:56:32Z,"We have those in the default config but they are not used in the protocol implementations.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/499/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/499,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMzMDU4NDQ4NQ==,incubator-stormcrawler,330584485,499,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-09-19T15:52:08Z,2017-09-19T15:52:08Z,Needs implementing for okhttp,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMzMDU4NDQ4NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/502,https://api.github.com/repos/apache/incubator-stormcrawler/issues/502,incubator-stormcrawler,263404295,502,ES Spout : define filter query via config,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-10-06T10:38:55Z,2017-10-17T12:12:29Z,This would be useful for crawling only a subset of the status index.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/502/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/504,https://api.github.com/repos/apache/incubator-stormcrawler/issues/504,incubator-stormcrawler,263486162,504,Capture stats about hosts on status stream post fetching ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,OPEN,2017-10-06T15:32:13Z,2019-05-22T11:33:11Z,"This could be used to notify external components of host-related information such as:
- robots delay settings
- fetch times
- [HTTP 429 codes](https://httpstatuses.com/429)

This would be used by the FetcherBolt, for instance, to implement throttling at the spout level and users would not have to modify the Fetcher code for doing so.

@owenrh 



","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/504/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/504,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2ODAzNzQ1Mg==,incubator-stormcrawler,368037452,504,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-02-23T15:16:49Z,2018-02-23T15:16:49Z,"The fetch times are stored in the metadata - the same could be done with the robots delay. Instead of having yet another stream, we could have a custom bolt intercepting the URLs from the FetcherBolt on the status stream and doing whatever it wants based on the content of the metadata. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2ODAzNzQ1Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/504,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5NDc0NTczOQ==,incubator-stormcrawler,494745739,504,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-05-22T10:26:39Z,2019-05-22T10:26:39Z,Having a windowing bolt for that purpose would make it easier to aggregate counts per minute,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5NDc0NTczOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/504,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5NDc2NDU2Nw==,incubator-stormcrawler,494764567,504,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-05-22T11:33:11Z,2019-05-22T11:33:11Z,"Could also rely on the state framework provided by Storm to send to a pluggable storage e.g. Redis

https://storm.apache.org/releases/1.2.2/Windowing.html
https://storm.apache.org/releases/1.2.2/State-checkpointing.html","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5NDc2NDU2Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/505,https://api.github.com/repos/apache/incubator-stormcrawler/issues/505,incubator-stormcrawler,264861625,505,RemoteDriverProtocol needs multiple instances,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-10-12T08:52:56Z,2017-10-19T14:14:45Z,"This is not an issue when using the SimpleFetcherBolt as each instance has its own ProtocolFactory, however, with the FetcherBolt which has a shared ProtocolFactory for all the fetching threads, we have only one instance of RemoteDriverProtocol running at a time. 

This is not a problem for the other protocol implementations as their underlying libs can handle multithreaded access but that won't work with RemoteWebDriver. One option would be to give fetching threads their own instance of ProtocolFactory but that would not be a good idea as this would mean one map and config instances per thread + have as many open connections as we have threads.

A better approach would be to either:
- (minimal approach) add a parameter so that we create N instances for each selenium.address
- replace the LinkedBlockingQueue from the SeleniumProtocol abstract class and replace it with a Threadpool or something similar so that we could close old connections etc... 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/505/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/505,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMzNzkyMTQyMQ==,incubator-stormcrawler,337921421,505,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-10-19T14:14:45Z,2017-10-19T14:14:45Z,Implemented the minimal approach. Use `selenium.instances.num:` in conf,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMzNzkyMTQyMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/506,https://api.github.com/repos/apache/incubator-stormcrawler/issues/506,incubator-stormcrawler,266094508,506,okhttp : store request and response headers verbatim in metadata,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-10-17T11:49:26Z,2017-10-19T10:32:26Z,"this is similar to #317 but for the implementation based on okhttp
see https://github.com/DigitalPebble/storm-crawler/wiki/Protocols
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/506/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/507,https://api.github.com/repos/apache/incubator-stormcrawler/issues/507,incubator-stormcrawler,266430044,507,okhttp protocol does not store headers in metadata,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-10-18T09:51:26Z,2017-10-19T10:32:43Z,"and it returns the input metadata instead of providing a new instance - the fetcherbolts merge the intial metadata and the one in the protocolresponse
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/507/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/509,https://api.github.com/repos/apache/incubator-stormcrawler/issues/509,incubator-stormcrawler,266441079,509,Generate WARC request records,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-10-18T10:26:51Z,2019-03-23T21:58:11Z,"#508 allows to get the verbatim representation of the request, the WARCRecordFormatClass could therefore generate WARC request records","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/509/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/509,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMzNzU0MjkxMw==,incubator-stormcrawler,337542913,509,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-10-18T10:27:13Z,2017-10-18T10:27:13Z,@sebastian-nagel this would be relevant for the news-crawl,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMzNzU0MjkxMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/510,https://api.github.com/repos/apache/incubator-stormcrawler/issues/510,incubator-stormcrawler,266784516,510,Upgrade WARC module to latest Storm-HDFS version ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-10-19T09:53:19Z,2017-12-15T09:25:43Z,"The module for HDFS in Storm has changed and we're still based on an older version. Would be good to keep in sync.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/510/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/510,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM1MTk1NjUxOQ==,incubator-stormcrawler,351956519,510,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-12-15T09:25:39Z,2017-12-15T09:25:39Z,Fixed in #520 ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM1MTk1NjUxOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/512,https://api.github.com/repos/apache/incubator-stormcrawler/issues/512,incubator-stormcrawler,268524467,512,Update a tutorial video on the quickstart page,illia-v,17710133,Illia Volochii,illia.volochii@gmail.com,CLOSED,2017-10-25T19:43:54Z,2017-10-27T09:57:17Z,"Looks like a tutorial video on http://stormcrawler.net/getting-started/ can be updated to https://www.youtube.com/watch?v=KTerugU12TY which can save some time for newcomers.

Thanks!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/512/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/512,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMzOTkyODU5OA==,incubator-stormcrawler,339928598,512,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-10-27T09:57:17Z,2017-10-27T09:57:17Z,"Done, thanks for the suggestion","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDMzOTkyODU5OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/513,https://api.github.com/repos/apache/incubator-stormcrawler/issues/513,incubator-stormcrawler,269060880,513,Upgrade to crawler-commons 0.9,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-10-27T10:30:01Z,2017-10-31T11:03:48Z,"
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/513/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/514,https://api.github.com/repos/apache/incubator-stormcrawler/issues/514,incubator-stormcrawler,271856360,514,Selenium protocol follows redirections,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-11-07T14:45:06Z,2017-11-07T14:46:57Z,"It should behave like the other protocols instead and return an empty content with the corresponding 3xx code
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/514/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/515,https://api.github.com/repos/apache/incubator-stormcrawler/issues/515,incubator-stormcrawler,272582843,515,SitemapParserBolt should force mime-type based on the clue,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-11-09T14:27:36Z,2017-11-09T14:29:11Z,"http://www.soliant.com/feeds/jobs-sitemap/ 
returns the following http header
`Content-Type: text/html; charset=utf-8`
as a result the underlying sitemap parser can't handle it properly.

What we can do is to do the detection based on the clue regardless of whether the doc has been declared as being a sitemap and if it matches, force the mime-type to 'application/xml' as the clue indicates a XML doc for sure.

For this particular URL, not setting the mime-type at all does not work either as the content does not have the required xml element `<?xml version=""1.0"" encoding=""UTF-8""?>` which Tika uses to guess the mimetype. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/515/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/516,https://api.github.com/repos/apache/incubator-stormcrawler/issues/516,incubator-stormcrawler,276562089,516,Upgrade to Elasticsearch 6.0,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-11-24T09:41:07Z,2017-11-28T10:36:14Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/516/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/518,https://api.github.com/repos/apache/incubator-stormcrawler/issues/518,incubator-stormcrawler,282037088,518,upgrade to Tika 1.17,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-12-14T09:40:54Z,2017-12-14T14:50:25Z,http://www.apache.org/dist/tika/CHANGES-1.17.txt,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/518/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/519,https://api.github.com/repos/apache/incubator-stormcrawler/issues/519,incubator-stormcrawler,282037292,519,Upgrade to ES 6.1.0,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2017-12-14T09:41:39Z,2018-01-09T17:03:33Z,https://www.elastic.co/guide/en/elasticsearch/reference/6.1/release-notes-6.1.0.html,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/519/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/519,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM1NjI1MTI5OA==,incubator-stormcrawler,356251298,519,NA,rzo1,13417392,Richard Zowalla,,NA,2018-01-09T10:57:37Z,2018-01-09T10:57:37Z,This is done with #525 ? :),"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM1NjI1MTI5OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/521,https://api.github.com/repos/apache/incubator-stormcrawler/issues/521,incubator-stormcrawler,282108874,521,AggregationSpout fails with default value of es.status.bucket.field == _routing,sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2017-12-14T13:56:18Z,2017-12-14T14:42:13Z,"AggregationSpout fails if using the default value of `es.status.bucket.field`:
```
2017-12-13 15:33:16.524 c.d.s.e.p.AggregationSpout elasticsearch[_client_][listener][T#1] [ERROR] Exception with ES query
org.elasticsearch.transport.RemoteTransportException: [jH2OwBx][127.0.0.1:9300][indices:data/read/search]
Caused by: org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
...
Caused by: org.elasticsearch.common.io.stream.NotSerializableExceptionWrapper: : Fielddata is not supported on field [_routing] of type [_routing]
        at org.elasticsearch.ElasticsearchException.guessRootCauses(ElasticsearchException.java:618) ~[stormjar.jar:?]
```

The default value `_routing` is set in AbstractSpout:
```
    /** Field name to use for aggregating **/
    protected static final String ESStatusBucketFieldParamName = ""es.status.bucket.field"";
    ...
        partitionField = ConfUtils.getString(stormConf,
                ESStatusBucketFieldParamName, ""_routing"");
```
It's used both by AggregationSpout and CollapsingSpout.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/521/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/521,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM1MTcyODY2NA==,incubator-stormcrawler,351728664,521,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2017-12-14T14:38:38Z,2017-12-14T14:38:38Z,the example config file uses a [different value](https://github.com/DigitalPebble/storm-crawler/blob/master/external/elasticsearch/es-conf.yaml#L50)  but you are right that the default value in the code should be the same. Will fix it. Thanks ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM1MTcyODY2NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/526,https://api.github.com/repos/apache/incubator-stormcrawler/issues/526,incubator-stormcrawler,290177576,526,"StormCrawler with ES: ""Found data point value __recv-iconnection of class class java.util.HashMap""",rzo1,13417392,Richard Zowalla,,CLOSED,2018-01-20T09:03:51Z,2018-01-21T17:59:13Z,"I am using storm-crawler 1.7 with ES integration. 

While conducting some testing, I find the following ERROR in the supervisor log-files:

```
2018-01-20 09:56:38.363 c.d.s.e.m.MetricsConsumer Thread-47 [ERROR] Found data point value __recv-iconnection of class class java.util.HashMap
2018-01-20 09:56:38.363 c.d.s.e.m.MetricsConsumer Thread-47 [ERROR] Found data point value __send-iconnection of class class clojure.lang.PersistentArrayMap
2018-01-20 09:56:38.363 c.d.s.e.m.MetricsConsumer Thread-47 [ERROR] Found data point value __send-iconnection of class class clojure.lang.PersistentArrayMap
2018-01-20 09:56:38.623 c.d.s.e.m.MetricsConsumer Thread-47 [ERROR] Found data point value __recv-iconnection of class class java.util.HashMap
2018-01-20 09:56:38.624 c.d.s.e.m.MetricsConsumer Thread-47 [ERROR] Found data point value __send-iconnection of class class clojure.lang.PersistentArrayMap
```
This is also true, then using 

```
       - class: ""com.digitalpebble.stormcrawler.elasticsearch.metrics.IndexPerDayMetricsConsumer""
         parallelism.hint: 1
```
instead of `MetricsConsumer `.

I created the index definitions according to the README for 1.7.

Any ideas, what this is rtelated to ?

//EDIT: Sorry, I cannot add appropriate labels for this issue. Seems, that I do not have the permission to do this...","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/526/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/526,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM1OTIwNzAwMg==,incubator-stormcrawler,359207002,526,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-01-20T22:26:30Z,2018-01-20T22:26:30Z,"Nothing serious. Just some internal metrics generated by Storm which have nested map /arrays for values - the code that handles metrics for ES doesn't deal with those. 
We should probably change the log level to 'info' in  [MetricsConsumer](https://github.com/DigitalPebble/storm-crawler/blob/master/external/elasticsearch/src/main/java/com/digitalpebble/stormcrawler/elasticsearch/metrics/MetricsConsumer.java#L120), error sounds a bit dramatic. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM1OTIwNzAwMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/526,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM1OTI2NzEyMQ==,incubator-stormcrawler,359267121,526,NA,rzo1,13417392,Richard Zowalla,,NA,2018-01-21T17:59:13Z,2018-01-21T17:59:13Z,Thanks for your answer :) - the `ERROR` key-word was triggering this issue ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM1OTI2NzEyMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/527,https://api.github.com/repos/apache/incubator-stormcrawler/issues/527,incubator-stormcrawler,292365015,527,"Any reason for """"storm-crawler-elasticsearch"" begin a fat-jar in v1.7 in Maven Central?",rzo1,13417392,Richard Zowalla,,CLOSED,2018-01-29T11:01:49Z,2018-01-29T11:04:41Z,"Hi,

is there any reason, why the artifact ""storm-crawler-elasticsearch"" in version 1.7 is bundled and released as a **fat jar** on Maven Central? 

I would suggest, that up-coming releases contain lightweight artifacts, so we are not stick to fat-jar relases, which might be a problem in cases of re-shading artifacts.

Best,
rzo1","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/527/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/527,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2MTIxMjA0MQ==,incubator-stormcrawler,361212041,527,NA,rzo1,13417392,Richard Zowalla,,NA,2018-01-29T11:04:40Z,2018-01-29T11:04:40Z,Sorry - this was related to an outdated cache-entry in our local artifactory.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2MTIxMjA0MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/528,https://api.github.com/repos/apache/incubator-stormcrawler/issues/528,incubator-stormcrawler,295831368,528,Update to SOLR 7.2.1,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-02-09T10:57:12Z,2018-02-09T10:58:13Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/528/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/529,https://api.github.com/repos/apache/incubator-stormcrawler/issues/529,incubator-stormcrawler,295909156,529,MemorySpout to generate tuples with DISCOVERED status,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-02-09T15:30:46Z,2018-02-09T15:33:22Z,"Similar to what the FileSpout does but instead of specifying the Scheme in the constructor, we could simply have a boolean indicating whether to generate as DISCOVERED.

This is useful for injecting a limited number of seeds straight into a StatusUpdaterBolt.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/529/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/530,https://api.github.com/repos/apache/incubator-stormcrawler/issues/530,incubator-stormcrawler,295962567,530,OKHttp configure type of proxy,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-02-09T18:16:22Z,2018-02-09T18:17:09Z,"Not sure whether this can be done with HttpClient, but with OKHttp we can specify the type of the proxy between HTTP or SOCKS.

See [related question about Nutch](https://stackoverflow.com/questions/48699654/nutch-2-3-1-in-crawl-deep-web), expect that SC would be able to deal with SOCKS directly.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/530/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/531,https://api.github.com/repos/apache/incubator-stormcrawler/issues/531,incubator-stormcrawler,298241330,531,Upgrade to Storm 1.2.x,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-02-19T11:24:18Z,2018-02-21T11:44:55Z,"One of the highlights of Storm 1.2.x is the new Metrics reporting API => http://storm.apache.org/releases/1.2.0/metrics_v2.html

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/531/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/532,https://api.github.com/repos/apache/incubator-stormcrawler/issues/532,incubator-stormcrawler,298622546,532,Contribute to Wiki,hatemalimam,3439970,Hatem Alimam,me@hatemalimam.com,CLOSED,2018-02-20T14:53:01Z,2018-02-20T17:56:28Z,"Hello,

Is there anyway to contribute to the wiki, I've seed a lot of outdated info, misleading in a form, or broken links like this case.

![screen shot 2018-02-20 at 15 51 39](https://user-images.githubusercontent.com/3439970/36430663-0a56943c-1656-11e8-9a1a-43514cd9e857.png)


For example this information was very critical for me: 

http.content.limit
![screen shot 2018-02-20 at 15 48 26](https://user-images.githubusercontent.com/3439970/36430474-8bdceebc-1655-11e8-9ca4-00dc887d5706.png)

But as I have seen [here](https://github.com/DigitalPebble/storm-crawler/blob/69782186fd33b26acc0156e3f712908535c3d7af/core/src/main/java/com/digitalpebble/stormcrawler/protocol/httpclient/HttpProtocol.java#L289) it's implemented, and that particular attribute prevented the whole loading of some documents due to that limit, so some XPath filters weren't working of course.

Anyway my question is is there anyway I can contribute to the Wiki ? github doesn't allow that I guess.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/532/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/532,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2NzA2MDAwOA==,incubator-stormcrawler,367060008,532,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-02-20T17:48:24Z,2018-02-20T17:48:24Z,"Hi, your contribution to the wiki would be very welcome. Editing the WIKI is currently allowed to members of a group with write access, I've sent you an invitation to join and you should be able to make changes to the wiki once you've accepted it. Keeping the WIKI and other documentation in sync with changes in the code is always a challenge. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2NzA2MDAwOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/532,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2NzA2MjYwMw==,incubator-stormcrawler,367062603,532,NA,hatemalimam,3439970,Hatem Alimam,me@hatemalimam.com,NA,2018-02-20T17:56:28Z,2018-02-20T17:56:28Z,"Thanks, I've accepted it. I'll make sure to have some valuable contribution. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2NzA2MjYwMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/533,https://api.github.com/repos/apache/incubator-stormcrawler/issues/533,incubator-stormcrawler,298696494,533,http.content.limit inconsistent defaults,hatemalimam,3439970,Hatem Alimam,me@hatemalimam.com,CLOSED,2018-02-20T18:16:26Z,2018-02-21T10:19:34Z,"The default value for `http.content.limit` in [`crawler-default.yaml`](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/resources/crawler-default.yaml#L47) is `65536`

Whereas in the http protocols is `-1` in case it's not present in the config
https://github.com/DigitalPebble/storm-crawler/blob/69782186fd33b26acc0156e3f712908535c3d7af/core/src/main/java/com/digitalpebble/stormcrawler/protocol/httpclient/HttpProtocol.java#L99

IMHO we should have that `-1` as a default, any reason to have a limit as a default ?

In my case some of the content was not fetched due to that limit.

If it's for some reason a bad idea, then I guess the default value in the http protocols should be `65536`.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/533/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/533,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2NzI2NzE2OA==,incubator-stormcrawler,367267168,533,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-02-21T09:39:34Z,2018-02-21T09:39:34Z,"Having a limit on the size is just to keep large, generic crawls efficient against fetching continuous streams e.g. radio, tv. It could be set to a larger value to accommodate larger files like sitemaps or unlimited with -1. I suppose it would be less confusing to have the same value in the default config and in the code as someone looking at the code wouldn't know what is being used. 
A good compromise would be to have -1 in the code as well as the default config but use the limited value in [the conf generated by the archetype](https://github.com/DigitalPebble/storm-crawler/blob/master/archetype/src/main/resources/archetype-resources/crawler-conf.yaml) - that would be more visible to the users. What do you think @hatemalimam?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2NzI2NzE2OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/533,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2NzI3MTE0Mg==,incubator-stormcrawler,367271142,533,NA,hatemalimam,3439970,Hatem Alimam,me@hatemalimam.com,NA,2018-02-21T09:53:46Z,2018-02-21T09:53:46Z,"Absolutely, the idea of the generated conf by the archetype would be very clear to the user. I would go with that. I can open a pull request if you want for this tiny mod.  ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2NzI3MTE0Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/533,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2NzI3MTc4Ng==,incubator-stormcrawler,367271786,533,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-02-21T09:56:11Z,2018-02-21T09:56:11Z,yes please!,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2NzI3MTc4Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/535,https://api.github.com/repos/apache/incubator-stormcrawler/issues/535,incubator-stormcrawler,299740089,535,Track time spent in the FetcherBolt queues,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-02-23T15:02:59Z,2018-02-27T21:48:42Z,"Knowing how long a URL has spent in the queues is very useful and a good addition to knowing how long the actual fetching took. This could be used for instance to throttle the emissions of URLs from a particular backend, similar to #504.  These also reflect the robots wait directives - as well as the actual waiting time for the queue.

This should also be provided as metrics.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/535/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/536,https://api.github.com/repos/apache/incubator-stormcrawler/issues/536,incubator-stormcrawler,300716728,536,StormCrawler-ES throws FETCH-ERROR while crawling any websites from the status index,mitapixcii86,36895134,Moumita Bakshi,,CLOSED,2018-02-27T17:10:03Z,2018-03-01T09:04:41Z,"The websites from the seeds.txt is being indexed into the 'status' index, however the status of each URL changes from DISCOVERED to FETCH_ERROR. 

I have begun to think that the problem was with secured website, hence I tried non secured public website : http://www.statesman.com, it still throws error. Crawler Log:

018-02-27 17:30:09.130 c.d.s.e.p.AggregationSpout Thread-4-spout-executor[8 8] [INFO]  Populating buffer with nextFetchDate <= 2018-02-27T17:28:48+01:00
2018-02-27 17:30:09.136 c.d.s.e.p.AggregationSpout elasticsearch[_client_][listener][T#1] [INFO]  ES query returned 1 hits from 1 buckets in 4 msec with 1 already being processed
2018-02-27 17:30:10.256 c.d.s.p.RobotRulesParser FetcherThread #47 [INFO] Couldn't get robots.txt for http://www.statesman.com/ : org.apache.http.conn.ConnectTimeoutException: Connect to www.statesman.com:80 [www.statesman.com/52.85.245.21, www.statesman.com/52.85.245.31, www.statesman.com/52.85.245.137, www.statesman.com/52.85.245.167, www.statesman.com/52.85.245.85, www.statesman.com/52.85.245.10, www.statesman.com/52.85.245.55, www.statesman.com/52.85.245.53] failed: connect timed out
2018-02-27 17:30:11.134 c.d.s.e.p.AggregationSpout Thread-4-spout-executor[8 8] [INFO]  Populating buffer with nextFetchDate <= 2018-02-27T17:28:48+01:00
20

Issue: 
1) How to enable ssl connection 
2) How do we connect to secured es cluster and crawl secured public websites.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/536/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/536,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2OTAzNzkwMg==,incubator-stormcrawler,369037902,536,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-02-27T21:47:24Z,2018-02-27T21:47:24Z,"Hi @mitapixcii86 

> How to enable ssl connection

should work out of the box. I tried the URL above with a simple topology generated with the archetype and it worked fine

```
 [FetcherThread #1] INFO  c.d.s.b.FetcherBolt - [Fetcher #3] Fetched https://www.statesman.com with status 200 in msec 258
```

Please try the basic topology from the archetype i.e without ES to check if you are getting the same problem.

> How do we connect to secured es cluster 

 would you mind asking this on StackOverflow instead? 

> crawl secured public websites

what's the difference with your first question? do you mean authentication? see discussion on #427 


","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2OTAzNzkwMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/536,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2OTMwMjUxMQ==,incubator-stormcrawler,369302511,536,NA,mitapixcii86,36895134,Moumita Bakshi,,NA,2018-02-28T16:46:55Z,2018-02-28T16:46:55Z,"@jnioche Thanks for the quick response. 

I am very new to the crawling world. I would like to crawl a internal website, which prompts for a third party authentication via a popup form 
![image](https://user-images.githubusercontent.com/36895134/36800231-4c5222de-1caf-11e8-98b8-7671108931a2.png)
How do i pass the credentials?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2OTMwMjUxMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/536,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2OTM2ODM2Mw==,incubator-stormcrawler,369368363,536,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-02-28T20:15:06Z,2018-02-28T20:15:06Z,"A bit hard to workout without knowing more details but a simple approach would be to use Selenium and have a custom NavigationFilter to fill the credentials on the popup, see tutorial on http://digitalpebble.blogspot.co.uk/2017/04/crawl-dynamic-content-with-selenium-and.html
There could be other ways of doing it e.g. set a cookie but that depends on the specificities of the authentication mechanism.
Closing the issue for now. Please reopen if you find a bug but for questions please use Stackoverflow instead
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2OTM2ODM2Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/536,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2OTUyNDA4MQ==,incubator-stormcrawler,369524081,536,NA,mitapixcii86,36895134,Moumita Bakshi,,NA,2018-03-01T09:04:41Z,2018-03-01T09:04:41Z,Thanks @jnioche ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2OTUyNDA4MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/537,https://api.github.com/repos/apache/incubator-stormcrawler/issues/537,incubator-stormcrawler,301340287,537,Increase detect.charset.maxlength default value,hatemalimam,3439970,Hatem Alimam,me@hatemalimam.com,CLOSED,2018-03-01T09:51:33Z,2018-03-05T11:28:02Z,"I had a case where the main seed was goal.com/ar, it's an arabic website with a charset of `UTF-8`, after some debugging I found out that the class responsible for detecting the charset is [CharsetIdentification](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/util/CharsetIdentification.java), the detected charset  for that seed was wrong, it has to be `UTF-8`, instead the returned value is `ISO-8859-1`.

Basically the server is not providing a `content-type` header (`httpCharset`) nor the `htmlCharset` is being retrieved (due the shortness of the default `detect.charset.maxlength` value) , so that `hintCharset` is always `null`.

What I found out in many cases (not only in that particular seed), regarding RTL websites that `2048` of a maxlength is too few,
in my case increasing that to `10000` for example fixed the issue.

Here's an example:
URL:
http://www.goal.com/ar/%D8%A3%D8%AE%D8%A8%D8%A7%D8%B1/1

Expected result:
أخبار كرة القدم، صفحة 1 من 780 | Goal.com

Actual result with 2048 of a maxlength:
Ø£Ø®Ø¨Ø§Ø± ÙØ±Ø© Ø§ÙÙØ¯ÙØ ØµÙØ­Ø© 1 ÙÙ 780 \| Goal.com


Any particular reason why the default value is `2048` ?

https://github.com/DigitalPebble/storm-crawler/blob/2493ae73292f7d7883eb1c45a7533d808630f030/core/src/main/resources/crawler-default.yaml#L99
 

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/537/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/537,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2OTY0OTYwNQ==,incubator-stormcrawler,369649605,537,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-03-01T16:32:37Z,2018-03-01T16:32:37Z,"See #391 for why we needed to limit it. As pointed out in [#438](https://github.com/DigitalPebble/storm-crawler/issues/438#issuecomment-287636762), 2048 could indeed be too low.
Maybe the [inputFilter](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/util/CharsetIdentification.java#L111) lets scripts through which influences the detection. Maybe this could be improved as well. 

We could also add a configuration so that the value set in the HTML is used if it is valid and there is nothing from the HTTP headers and the value is valid. 

Of course we could simply go for a larger value like the one you suggested. Do you want to open a PR for this? Thanks
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2OTY0OTYwNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/537,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2OTY2MDAwMg==,incubator-stormcrawler,369660002,537,NA,kkrugler,66217,Ken Krugler,ken@transpac.com,NA,2018-03-01T17:03:52Z,2018-03-01T17:03:52Z,"Actually I see two or three potential separate issues here...

1. http://goal.com/ar returns a 301 (permanent redirect), and the response headers have `Content-Type: text/html; charset=iso-8859-1`. I assume that this charset info is ignored, but seems curious that it matches the incorrect charset being reported.
1. http://www.goal.com/ar (the redirect) returns in the http response headers `Content-Type: text/html; charset=UTF-8`. So I would assume that should be used, unless the HTML has something that overrides it.
1. The reason the `<meta charset=""utf-8"" />` HTML element isn't found in the first 2K of text is because there's a large `<script>` element right before it. This illustrates the fundamental issue around trying to read an arbitrary amount of text to find HTML elements; you can always insert enough other text to push what you're looking for out of the buffer. I think the only viable solution is to add a ""smart"" HTML element processor, which incrementally reads until it hits the `</head>` tag (or some other element that can never appear in the head block, or some really big limit).
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2OTY2MDAwMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/537,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2OTY2NTM0OQ==,incubator-stormcrawler,369665349,537,NA,hatemalimam,3439970,Hatem Alimam,me@hatemalimam.com,NA,2018-03-01T17:24:29Z,2018-03-01T17:24:29Z,"@kkrugler Interesting.
Apart from the fact that a ""smart"" HTML processor is indeed a nice idea, but for time-being increasing that 2K seems to me a necessity.

@jnioche 

> We could also add a configuration so that the value set in the HTML is used if it is valid and there is nothing from the HTTP headers and the value is valid.

You mean like skipping the guessing part, right before [`hintCharset`](https://github.com/DigitalPebble/storm-crawler/blob/e394917f65e22b8e4512279cee603e75cdb2ca31/core/src/main/java/com/digitalpebble/stormcrawler/util/CharsetIdentification.java#L59) ?
we could define a new config, for example:  `detect.force.html.charset`

In that case we skip the [`getCharsetFromText`](https://github.com/DigitalPebble/storm-crawler/blob/e394917f65e22b8e4512279cee603e75cdb2ca31/core/src/main/java/com/digitalpebble/stormcrawler/util/CharsetIdentification.java#L67) part and return `htmlCharset` if that is set to `true` ?

Could be an idea.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2OTY2NTM0OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/537,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2OTY2NjAwNg==,incubator-stormcrawler,369666006,537,NA,hatemalimam,3439970,Hatem Alimam,me@hatemalimam.com,NA,2018-03-01T17:26:30Z,2018-03-01T17:26:30Z,For now I'll open a PR to increase the default value to 10K.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM2OTY2NjAwNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/537,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM3MDA3MDM4Ng==,incubator-stormcrawler,370070386,537,NA,kkrugler,66217,Ken Krugler,ken@transpac.com,NA,2018-03-02T22:24:56Z,2018-03-02T22:24:56Z,"@hatemalimam - the main issue with increasing the size to 10K is that you'll still hit badly-formatted HTML that has the meta element after 10K of text.

One interesting reference - see https://developer.mozilla.org/en-US/docs/Web/HTML/Element/meta for their notes on charset detection. They state that the `<meta>` element must come within the first 1K of text. And that the `Content-Type` header and any BOM overrides what's in the `<meta>` element.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM3MDA3MDM4Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/537,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM3MDM5MDg3NA==,incubator-stormcrawler,370390874,537,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-03-05T11:28:02Z,2018-03-05T11:28:02Z,"Closing this one for now, we can continue the discussion on the best approach to use in a separate issue or better at crawler-commons https://github.com/crawler-commons/crawler-commons/issues/171","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM3MDM5MDg3NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/540,https://api.github.com/repos/apache/incubator-stormcrawler/issues/540,incubator-stormcrawler,302284669,540,ES IndexerBolt track number of batch sent,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-03-05T12:39:59Z,2018-11-09T11:51:45Z,"we should also check that the batched have succeeded before acking the tuples.

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/540/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/540,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzNzMzNjQyMw==,incubator-stormcrawler,437336423,540,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-11-09T11:45:32Z,2018-11-09T11:45:32Z,"> we should also check that the batched have succeeded before acking the tuples.

see #647
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzNzMzNjQyMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/540,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzNzMzNjYxNA==,incubator-stormcrawler,437336614,540,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-11-09T11:46:40Z,2018-11-09T11:46:40Z,as well as the average number of docs indexed per sec,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzNzMzNjYxNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/541,https://api.github.com/repos/apache/incubator-stormcrawler/issues/541,incubator-stormcrawler,302358275,541,FeedParserBolt: metadata added by parse filters not passed forward in topology,sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2018-03-05T16:05:01Z,2018-03-06T10:13:23Z,FeedParserBolt does not pass the metadata add by parse filters forward in the topology. AdaptiveFetchSchedule does not recognize anymore whether a feed has change by signature comparison ([cc/news-crawl#19](/commoncrawl/news-crawl/issues/19)). [f344f4b](/DigitalPebble/storm-crawler/commit/f344f4b5806a24d8f2e1116054ba0abce6a365e8#diff-f44921216e56b5182698d433c5d4ee70R137) has changed the way metadata is passed to the parsefilters in FeedParserBolt and SiteMapParserBolt while tika and jsoup parsers still work on the Metadata object directly (set by `parseData.setMetadata(metadata)`),"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/541/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/541,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM3MDcyNjY3MA==,incubator-stormcrawler,370726670,541,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-03-06T09:56:40Z,2018-03-06T09:56:40Z,"thanks @sebastian-nagel. the shortcut `parse.put(url, metadata)` creates a new instance of metadata under the bonnet and copies the values from the original metadata which indeed causes a problem aswe use and return the latter further down the code. Will fix this now.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM3MDcyNjY3MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/541,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM3MDczMTg5NA==,incubator-stormcrawler,370731894,541,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2018-03-06T10:13:23Z,2018-03-06T10:13:23Z,"Thanks, @jnioche!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM3MDczMTg5NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/544,https://api.github.com/repos/apache/incubator-stormcrawler/issues/544,incubator-stormcrawler,304706738,544,Schema for status index needs date type for nextFetchDate,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-03-13T10:28:46Z,2018-03-13T10:30:32Z,"see discussion on [DigitalPebble group](https://groups.google.com/d/msg/digitalpebble/rP5ikOva6lg/C1aVoNvRBQAJ)

Not sure why this does not work anymore but it makes sense to declare the nextFetchDate type explicitely. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/544/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/545,https://api.github.com/repos/apache/incubator-stormcrawler/issues/545,incubator-stormcrawler,304711823,545,SOLR indexer: use field type text for content field,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-03-13T10:43:39Z,2018-03-13T10:44:50Z,"Otherwise you end up with no tokenisation and messages like

`org.apache.solr.client.solrj.impl.HttpSolrClient$RemoteSolrException: Error from server at http://localhost:8983/solr/docs: Exception writing document id xxxxx to the index; possible analysis error: Document contains at least one immense term in field=""content"" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: '[67, 108, 105, 99, 107, 32, 72, 69, 82, 69, 32, 116, 111, 32, 99, 104, 101, 99, 107, 32, 111, 117, 116, 32, 116, 104, 101, 32, 66, 69]...', original message: bytes can be at most 32766 in length; got 34731. Perhaps the document has an indexed string field (solr.StrField) which is too large`","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/545/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/546,https://api.github.com/repos/apache/incubator-stormcrawler/issues/546,incubator-stormcrawler,304768768,546,Upgrade to OKHttp 3.10.0,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-03-13T13:40:45Z,2018-03-21T11:18:17Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/546/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/547,https://api.github.com/repos/apache/incubator-stormcrawler/issues/547,incubator-stormcrawler,304839579,547,URLStreamGrouping returns the taskIDs and not their index,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-03-13T16:29:15Z,2018-03-13T16:50:53Z,"
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/547/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/548,https://api.github.com/repos/apache/incubator-stormcrawler/issues/548,incubator-stormcrawler,305271451,548,Can't connect to ElasticSearch,emanodame,13068396,,,CLOSED,2018-03-14T18:09:02Z,2018-03-14T19:48:19Z,"I think there is a bug with the latest release. I have written SO post about it here.
https://stackoverflow.com/questions/49281244/stormcrawler-cannot-connect-to-elasticsearch","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/548/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/550,https://api.github.com/repos/apache/incubator-stormcrawler/issues/550,incubator-stormcrawler,307941488,550,MetricsConsumer handle recursive values,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-03-23T08:35:29Z,2018-03-28T16:51:23Z,"#526 changed the log level of messages such as the one below to WARN

```
2018-03-23 08:19:42.449 c.d.s.e.m.MetricsConsumer Thread-300 [WARN] Found data point value __recv-iconnection of class java.util.HashMap
```
These messages simply indicate that the value received by a MetricsConsumer is recursive. This seems to confuse some users. We should fix this and get the MetricsConsumers to handle recursive values.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/550/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/551,https://api.github.com/repos/apache/incubator-stormcrawler/issues/551,incubator-stormcrawler,307962958,551,Add FeedParser to archetype topology?,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-03-23T09:51:59Z,2018-05-22T10:07:36Z,"The topology in the archetype uses the SitemapParser, why not add the FeedParser as well? ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/551/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/551,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5MDkzNTY5NQ==,incubator-stormcrawler,390935695,551,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-05-22T10:03:58Z,2018-05-22T10:03:58Z,"One side effect of not doing it is that feeds end up being indexed, which is not really useful. Removing the parser for cases where we want to index the feeds, is trivial.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5MDkzNTY5NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/552,https://api.github.com/repos/apache/incubator-stormcrawler/issues/552,incubator-stormcrawler,308930835,552,Update to JSoup 1.11.2,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-03-27T11:34:20Z,2018-03-27T11:39:16Z,1.11.2 and the previous versions contain multiple bugfixes and performance improvements,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/552/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/553,https://api.github.com/repos/apache/incubator-stormcrawler/issues/553,incubator-stormcrawler,308942456,553,Optimisation: faster extraction of META tags,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-03-27T12:12:29Z,2018-03-27T12:36:26Z,"The utility classes **RefreshTag** and **RobotsTags** both use XPATH to retrieve META tags. They currently do so by looking for //META which is inefficient as it searches everywhere in the document. These 2 methods can take up to 18% of the processing time for JSoupParserBolt and 16% of the overall CPU.

Instead, we can use a more constraining XPATH which will look only into /HTML/HEAD or /HTML/BODY, the latter is not the recommended variant but can be found in the wild. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/553/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/553,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM3NjUwODU5NA==,incubator-stormcrawler,376508594,553,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-03-27T12:36:00Z,2018-03-27T12:36:00Z,Profiling after the change doesn't show a significant impact on _RobotsTags.extractMetaTags_ but _RefreshTag_ takes only 1/2 the time it used to. This represents 14% of the processing time for JSoupParserBolt and 11% of the overall CPU.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM3NjUwODU5NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/555,https://api.github.com/repos/apache/incubator-stormcrawler/issues/555,incubator-stormcrawler,309439828,555,ArrayIndexOutOfBoundsException in CollectionMetric.getValueAndReset(),jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-03-28T16:27:00Z,2018-03-28T17:03:18Z,"```
Caused by: java.lang.ArrayIndexOutOfBoundsException: 9
	at java.util.LinkedList.toArray(LinkedList.java:1053) ~[?:1.8.0_161]
	at java.util.LinkedList.addAll(LinkedList.java:408) ~[?:1.8.0_161]
	at java.util.LinkedList.addAll(LinkedList.java:387) ~[?:1.8.0_161]
	at java.util.LinkedList.<init>(LinkedList.java:119) ~[?:1.8.0_161]
	at com.digitalpebble.stormcrawler.util.CollectionMetric.getValueAndReset(CollectionMetric.java:35) ~[stormjar.jar:?]
	at org.apache.storm.daemon.executor$metrics_tick$fn__4899.invoke(executor.clj:345) ~[storm-core-1.2.1.jar:1.2.1]
	at clojure.core$map$fn__4553.invoke(core.clj:2622) ~[clojure-1.7.0.jar:?]
```

https://github.com/DigitalPebble/storm-crawler/blob/ce9134612bbfbf500adba6a89477b2597181d241/core/src/main/java/com/digitalpebble/stormcrawler/util/CollectionMetric.java#L35

The metric object is used by https://github.com/DigitalPebble/storm-crawler/blob/f6d51debfd2a5897015c388ee931b21570ea1f52/external/elasticsearch/src/main/java/com/digitalpebble/stormcrawler/elasticsearch/persistence/AbstractSpout.java#L146

My guess is that the spout instance is trying to add the list while it is being copied. We could simply add synchronized blocks to prevent concurrent access to the list.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/555/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/556,https://api.github.com/repos/apache/incubator-stormcrawler/issues/556,incubator-stormcrawler,310709849,556,icu4j 61.1 + rometools 1.9.0,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-04-03T06:28:54Z,2018-04-03T06:30:06Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/556/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/557,https://api.github.com/repos/apache/incubator-stormcrawler/issues/557,incubator-stormcrawler,311151869,557,Configurable Robots caches,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-04-04T09:27:34Z,2018-04-05T11:36:31Z,"This is currently hard-coded

https://github.com/DigitalPebble/storm-crawler/blob/3fc7d23ad0fc50033ecfc1c035cddd1543c21b6c/core/src/main/java/com/digitalpebble/stormcrawler/protocol/RobotRulesParser.java#L51

We should allow this to be done via config, like we do for the status updater bolt cache with `status.updater.cache.spec` ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/557/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/558,https://api.github.com/repos/apache/incubator-stormcrawler/issues/558,incubator-stormcrawler,311995582,558,Upgrade HTTPClient to 4.5.5,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-04-06T14:23:37Z,2018-04-06T14:41:16Z,"
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/558/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/559,https://api.github.com/repos/apache/incubator-stormcrawler/issues/559,incubator-stormcrawler,312027791,559,archetype to use flux-core 1.2.1,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-04-06T15:52:23Z,2018-04-09T13:23:28Z,"see issue #437 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/559/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/560,https://api.github.com/repos/apache/incubator-stormcrawler/issues/560,incubator-stormcrawler,312035021,560,WARCBolt to handle incorrect URIs gracefully,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-04-06T16:14:59Z,2018-04-07T06:50:50Z,"```
Caused by: java.lang.RuntimeException: Invalid URI http://tech.ifeng.com/listpage/tech-1152-1412-/1/spelist.shtml""
	at com.digitalpebble.stormcrawler.warc.WARCRecordFormat.format(WARCRecordFormat.java:181) ~[stormjar.jar:?]
```
at the moment we escalate an exception, instead, we should just log an error and move on","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/560/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/561,https://api.github.com/repos/apache/incubator-stormcrawler/issues/561,incubator-stormcrawler,313242250,561,WARCRecordFormat use ByteBuffer instead of ByteArrayOutputStream,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-04-11T09:26:17Z,2018-04-11T09:27:13Z,"ByteArrayOutputStream creates intermediates copies of the array as it expands its capacity as well as a final array copy to get the byte array. Since we know in advance the length of the byte[] we can use ByteBuffer to improve the performance.

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/561/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/562,https://api.github.com/repos/apache/incubator-stormcrawler/issues/562,incubator-stormcrawler,313326977,562,JSOUPParserBolt: lazy DOM conversion ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-04-11T13:35:40Z,2018-04-16T08:54:53Z,"JSoupParserBolt currently converts the jsoup Doc into DOM even if no parsefilters are set up or if none of them require the DOM. 

The DOM is also used by JSoupParser to extract the redirection URL and the robots metatags, but we could use the select methods on the jsoup doc as an alternative: this might be faster than Xpath as well. See #553 ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/562/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/564,https://api.github.com/repos/apache/incubator-stormcrawler/issues/564,incubator-stormcrawler,315410441,564,Purge internal queues of tuples which have already reached time out ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-04-18T09:54:49Z,2018-05-02T08:47:08Z,"URLs can sit in the internal queues of the FetcherBolt longer than the value set in _topology.message.timeout.secs_. This happens for instance when there aren't enough fetching threads or if the server corresponding to the queue is slow. By the time the URL gets fetched, its tuple will have been failed by Storm. Even with ES, where _es.status.ttl.purgatory_ allows a delay until an acked or failed URL is allowed through the topology, we can have the same URL reentering the queues later on. We could deduplicate the URLs in the queues but it is probably better and simpler to simply purge them if they have gone over the timeout. The following URLs will also to have less time to wait.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/564/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/564,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM4MjQzMjU2MA==,incubator-stormcrawler,382432560,564,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2018-04-18T15:42:15Z,2018-04-18T15:42:15Z,"+1

_es.status.ttl.purgatory_ must be set close to `fetcher.max.crawl.delay * fetcher.max.queue.size` to reliably avoid duplicate fetches for sites which request slow crawling. That's usually a large time span (eg. 20 min.), sounds good if this can be set to a lower value.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM4MjQzMjU2MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/565,https://api.github.com/repos/apache/incubator-stormcrawler/issues/565,incubator-stormcrawler,319506897,565,Investigate Java 11 HTTP client,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-05-02T11:01:17Z,2023-12-05T16:17:27Z,"http://www.baeldung.com/java-9-http-client

In incubation but could be an interesting alternative to 1/3 party libs","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/565/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/566,https://api.github.com/repos/apache/incubator-stormcrawler/issues/566,incubator-stormcrawler,319843431,566,Upgrade to Tika 1.18,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-05-03T09:17:02Z,2018-05-03T09:17:51Z,also declare the dependency on Tika core explicitly as it will be removed from the next version of crawler-commons,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/566/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/567,https://api.github.com/repos/apache/incubator-stormcrawler/issues/567,incubator-stormcrawler,320532249,567,wish: WARCHdfsBolt with CDX index,dportabella,976546,David Portabella,david.portabella@gmail.com,OPEN,2018-05-05T18:45:46Z,2019-09-23T14:27:34Z,"StormCrawler allows to filter web pages and archive them into WARC archives, as follows:
```
WARCHdfsBolt warcbolt = (WARCHdfsBolt) new WARCHdfsBolt().withFileNameFormat(fileNameFormat);

TopologyBuilder builder = new TopologyBuilder();

builder.setBolt(""warc"", warcbolt, numWorkers)
  .localOrShuffleGrouping(""parse"", WarcStreamName)
  .localOrShuffleGrouping(""tika"",  WarcStreamName);
```
Would it be possible to create a [CDX index](https://iipc.github.io/warc-specifications/specifications/cdx-format/cdx-2015/) (or JCDX index) for the WARC archives at the same time?

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/567/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/567,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM4NzMyOTAyNA==,incubator-stormcrawler,387329024,567,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2018-05-08T08:39:49Z,2018-05-08T08:39:49Z,"Should be possible:
- cf. [WarcCdxWriter](https://github.com/commoncrawl/nutch/blob/cc/src/java/org/commoncrawl/warc/WarcCdxWriter.java) for Nutch
- should ev. exclude most of the dependencies of [webarchive-commons](https://mvnrepository.com/artifact/org.netpreserve.commons/webarchive-commons) which is required to get the SURT key","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM4NzMyOTAyNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/567,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM4NzM1OTg3OA==,incubator-stormcrawler,387359878,567,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-05-08T10:34:04Z,2018-05-08T10:34:04Z,"Doable indeed. 

@dportabella the warc bolt is usually connected to the fetcher, not the parsers

`        builder.setBolt(""warc"", warcbolt).localOrShuffleGrouping(""fetch"");
`","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM4NzM1OTg3OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/567,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUzNDEyMzcwOA==,incubator-stormcrawler,534123708,567,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2019-09-23T14:27:34Z,2019-09-23T14:27:34Z,"Alternatively, the WARC bolt could add WARC file name, record offset and length to the metadata. An indexer (CDX or anything else) then could store it directly which obsoletes the need to index the CDX files in a separate step.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUzNDEyMzcwOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/568,https://api.github.com/repos/apache/incubator-stormcrawler/issues/568,incubator-stormcrawler,321096360,568,Migrate Storm-Crawler to Apache Flink,IvanBiv,7404103,Ivan Bukharin,,CLOSED,2018-05-08T08:48:10Z,2020-09-23T11:00:40Z,"@jnioche did you think about migrate this SDK to Apache Flink platform? I see Flink more better than Storm.
@jnioche what do you think?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/568/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/568,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM4NzM1ODQ5Mg==,incubator-stormcrawler,387358492,568,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-05-08T10:28:47Z,2018-05-08T10:28:47Z,"I haven't, to be honest

I see that my friend @kkrugler recently gave a talk on the subject so it's definitely worth exploring

https://sf-2018.flink-forward.org/kb_sessions/building-a-scalable-focused-web-crawler-with-flink/

@IvanBiv what would the benefits be? why not go for Apache Beam which is more generic?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM4NzM1ODQ5Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/568,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM4NzM5MjMxMA==,incubator-stormcrawler,387392310,568,NA,IvanBiv,7404103,Ivan Bukharin,,NA,2018-05-08T12:54:18Z,2018-05-08T12:54:18Z,"@jnioche thanks for link.

Flink better than Storm for me:
1) easy deploy on Docker cluster (Kubernetes). I could not run Storm cluster on Docker Swarm, the searching about this for Kubernetes showed that there is no good solution here either.
2) community

Yep, Apache Beam can be better as middleware between user processing topology and processing work platform.

Julien, you have a lot of work in the form of StormCrawler, it is worth considering the prospects, I mean processing platform.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM4NzM5MjMxMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/568,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM4ODMwODY0Mw==,incubator-stormcrawler,388308643,568,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-05-11T09:13:44Z,2018-05-11T09:13:44Z,"Thanks @IvanBiv 

I don't really see deployment on Docker as a reason to move away from Storm, as for the community, there's nothing wrong with Apache Storm one - certainly not the largest, that's true - but the project is alive and doing well.

> Julien, you have a lot of work in the form of StormCrawler, it is worth considering the prospects, I mean processing platform

Sure, but it is also because I invested loads of time in Storm that I won't dump it without very good reasons. There are loads of competing frameworks for stream processing and new ones emerging all the time but as things stand I am happy with Storm. That does not mean that I am not open minded and will never consider anything else though, it's just that I'd need more compelling arguments. 

I'd be curious to hear what @kkrugler thinks.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM4ODMwODY0Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/568,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM4ODMyMTMwNA==,incubator-stormcrawler,388321304,568,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2018-05-11T10:07:35Z,2018-05-11T10:07:35Z,"> I could not run Storm cluster on Docker Swarm, the searching about this for Kubernetes showed that there is no good solution here either.

Really? There are solutions maintained both by [Storm](https://hub.docker.com/_/storm/) and [Kubernetes](/kubernetes/examples/tree/master/staging/storm) teams/projects. Wouldn't the time better invested in improving these than porting a crawler? Esp., given that there is already [flink-crawler](/ScaleUnlimited/flink-crawler).","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM4ODMyMTMwNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/568,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM4ODMyNzgyMQ==,incubator-stormcrawler,388327821,568,NA,jorgelbg,1291846,Jorge Luis Betancourt,github@jorgelbg.me,NA,2018-05-11T10:37:48Z,2018-05-11T10:37:48Z,"I agree with @sebastian-nagel and @jnioche, at the moment there is no good (enough) reason to rewrite everything in Apache Flink. A lot of effort has been put already into creating/maintaining storm-crawler.

Even more, difficulty to deploy this project in a specific environment is not worth the investment of a full rewrite into a different streaming framework IMHO.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM4ODMyNzgyMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/568,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5MDAwMDUxNw==,incubator-stormcrawler,390000517,568,NA,kkrugler,66217,Ken Krugler,ken@transpac.com,NA,2018-05-17T20:29:06Z,2018-05-17T20:29:06Z,"I've been following this discussion, and thought I'd chime in with a few thoughts:

1. Most of the work in developing a continuous crawler lies outside of the actual streaming environment. Though being able to leverage bits from the [crawler-commons](https://github.com/crawler-commons/crawler-commons) project reduces that burden. But bottom line is that much of the heavy lifting is separate from the exact details of how various functions run in the streaming environment.
1. I started on [flink-crawler](https://github.com/ScaleUnlimited/flink-crawler) not because I thought that the storm-crawler project was unsuccessful, but because I wanted to explore using Flink as a platform for a continuous crawler (especially given its support for iterations), and as a test for whether it was possible to create a very simple (no other infrastructure) crawler that still was scalable and efficient.
1. I haven't tried either Storm or Flink with Docker (or Kubernetes), so I can't speak about the level of effort or quality of integration.
1. I've been dealing with the issue of ""platform aging"" in the [bixo](https://github.com/bixo/bixo) crawler project, as (a) it's become clear that continuous crawling has many advantages over batch, especially for focused crawls, and (b) the Cascading/Map-reduce platform is quickly becoming less interesting. So that's the other reason why doing something with flink-crawler was interesting.
1. Net-net, I don't think there's a compelling reason to port storm-crawler to a different streaming environment at this point (but see below).

To be honest, I do worry a bit about Storm, as I've watched the community of streaming users transition to Spark, Samza, Flink, Heron, Kafka streams and other options over time. One metric I use is tracking activity on the user mailing list for a project - here's that graph for Storm, from the Apache mail archives:

![screen shot 2018-05-17 at 12 56 22 pm](https://user-images.githubusercontent.com/66217/40201658-8d8892bc-59d4-11e8-833d-887a6bcb171c.png)

and the same result from Flink:

![screen shot 2018-05-17 at 1 19 30 pm](https://user-images.githubusercontent.com/66217/40201799-fe53e906-59d4-11e8-8f30-a7a0d482e68e.png)

and also for Spark:

![screen shot 2018-05-17 at 1 17 23 pm](https://user-images.githubusercontent.com/66217/40201711-ba4f1870-59d4-11e8-81eb-f4af5ece2fda.png)

All projects go through a maturity phase where the level of user activity drops off, so I don't think Storm is dead, but I do think in a year it could be time to revisit this discussion.

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5MDAwMDUxNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/568,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ0Mjc1MTUwNw==,incubator-stormcrawler,442751507,568,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-11-29T08:43:08Z,2018-11-29T08:43:08Z,"See Sematext trends on Flink,Storm,Samza (excluded Spark because a lot of it would not be about its streaming capabilities)

https://sematext.com/opensee/report/project/trend?q=Flink,Storm,Samza","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ0Mjc1MTUwNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/568,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY5NzI5MDkzNQ==,incubator-stormcrawler,697290935,568,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-09-23T11:00:40Z,2020-09-23T11:00:40Z,"not actionable, closing for now. Feel free to reopen if relevant","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY5NzI5MDkzNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/569,https://api.github.com/repos/apache/incubator-stormcrawler/issues/569,incubator-stormcrawler,321518193,569,"Wrappers for storing resources (filters, normalisers, etc...) on Elasticsearch",jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-05-09T10:35:49Z,2018-06-06T13:00:56Z,"We store the resource files for the filters and normalisers alongside the code and into the uberjar, which works fine, but Elasticsearch users could store them into a specific index where they could be updated without having to rebuild the jar and restart the topology.

One option would be to have the content of the file in a stored text field but this means that you would not be able to push the file directly onto ES. Another approach is to use JSON documents for the resources,  in which case users could send the resource files directly into the index.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/569/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/569,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5MjA0NTk2NQ==,incubator-stormcrawler,392045965,569,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-05-25T12:41:30Z,2018-05-25T12:41:30Z,This could be extended to the parsefilter and urlfilter definitions themselves which are in JSON.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5MjA0NTk2NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/569,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5MzEwMjk4Ng==,incubator-stormcrawler,393102986,569,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-05-30T09:57:07Z,2018-05-30T09:57:07Z,See #577 for introduction of JSONResource interface. ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5MzEwMjk4Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/570,https://api.github.com/repos/apache/incubator-stormcrawler/issues/570,incubator-stormcrawler,324323243,570,Add option to LanguageID to skip if metadata already set,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-05-18T08:49:22Z,2018-05-22T10:16:52Z,"We can assume that if a web page explicitly sets the language code, there is no point trying to guess it. However for document types where the metadata does not contain such codes, we might want to proceed with the identification.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/570/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/571,https://api.github.com/repos/apache/incubator-stormcrawler/issues/571,incubator-stormcrawler,324366772,571,Add ParseFilter to convert single valued Metadata to multi-valued ones  ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-05-18T11:04:32Z,2018-05-18T11:34:55Z,"Useful e.g. keywords meta tags which we want to index as multiple non-analysed fields instead of a single analysed one.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/571/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/572,https://api.github.com/repos/apache/incubator-stormcrawler/issues/572,incubator-stormcrawler,325230068,572,ES Indexer and Deletion Bolts to get index name from constructor,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-05-22T10:20:03Z,2018-05-22T10:23:20Z,"Instead of getting it from configuration. This would be useful for instance when indexing to multiple indices e.g. based on language. The existing behaviour would remain the default.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/572/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/573,https://api.github.com/repos/apache/incubator-stormcrawler/issues/573,incubator-stormcrawler,325288652,573,Caching of redirected robots.txt may overwrite correct robots.txt rules,sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2018-05-22T13:15:14Z,2018-05-23T13:02:49Z,"Redirected robots.txt rules should be only cached for the target host if the URL path is `/robots.txt` otherwise the redirect may overwrite the correct robots rules, see [NUTCH-2581](https://issues.apache.org/jira/browse/NUTCH-2581).
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/573/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/573,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5MTExNTYzOA==,incubator-stormcrawler,391115638,573,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-05-22T19:40:18Z,2018-05-22T19:40:18Z,"In the example you gave in NUTCH-2581, the target URL ends in /robots.txt  so I'm not sure I understand the problem.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5MTExNTYzOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/573,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5MTE0NDg4NQ==,incubator-stormcrawler,391144885,573,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2018-05-22T21:21:25Z,2018-05-22T21:21:25Z,"It must be exactly `/robots.txt`, not `/wyomingtheband/robots.txt` or anything else. The problem is that the [current logic](/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/protocol/HttpRobotRulesParser.java#L167) assumes that the content returned for https://www.facebook.com/wyomingtheband/robots.txt is equivalent to that of https://www.facebook.com/robots.txt which is definitely not the case. Regarding the example: this redirect and [many more](http://index.commoncrawl.org/CC-MAIN-2018-17-index?url=facebook.com&matchType=domain&output=json&filter=~url:.*/robots\.txt) mask the correct robots.txt and cause that even frequently the host www.facebook.com is considered to be allowed for crawling. Of course, there is some random what is fetched and cached first.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5MTE0NDg4NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/573,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5MTMzMjM4Mg==,incubator-stormcrawler,391332382,573,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-05-23T12:42:57Z,2018-05-23T12:42:57Z,"Ok, got it, thanks Sebastian. Will fix it right now. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5MTMzMjM4Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/573,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5MTMzODM5OA==,incubator-stormcrawler,391338398,573,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2018-05-23T13:02:49Z,2018-05-23T13:02:49Z,"Thanks, @jnioche!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5MTMzODM5OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/574,https://api.github.com/repos/apache/incubator-stormcrawler/issues/574,incubator-stormcrawler,326424874,574,Allow for the setting of Status enum from the config file.,danielamaya,6454251,Daniel,,CLOSED,2018-05-25T08:18:26Z,2018-06-06T13:09:49Z,"It would be nice to be able to configure the Status enum from the config file. This would allow the user to define what status codes are considered FETCH, FETCH_ERRORS, etc. Something along the lines of the example below.

```
http.status.code.FETCH_ERROR:
- 750
- 790
```","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/574/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/574,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5MTk4Nzk2MA==,incubator-stormcrawler,391987960,574,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-05-25T08:55:27Z,2018-05-25T08:55:27Z,"Thanks @danielamaya. For that specific example, the [fromHTTPCode method](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/persistence/Status.java#L33) returns FETCH_ERROR for any value which is not a SUCCESS or REDIRECTION. Adding the config as suggested would not change the behaviour at all.
Can you give me an example of a case where the codes for FETCHED (300 / 204) or REDIR (3xx) should be different from what we currently handle? 
We could set these mappings in the default configuration and let users override them if necessary. The fromHTTPCode method is called from [only a few places](https://github.com/DigitalPebble/storm-crawler/search?q=fromHTTPCode&unscoped_q=fromHTTPCode) and the change would not be huge but I'd like to make sure that there are good reasons for doing it first.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5MTk4Nzk2MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/574,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5MjE2MTgyNg==,incubator-stormcrawler,392161826,574,NA,danielamaya,6454251,Daniel,,NA,2018-05-25T19:47:39Z,2018-05-25T19:47:39Z,"Actually, my only example would be for FETCH_ERROR. The logic for everything else is fine for me.  Reading the documentation for statusStream, I see the following:

> The difference between FETCH_ERROR and ERROR is that the former is possibly transient whereas the latter is terminal.

I understand that 404 could indicate a server under stress, meaning a 404 could potentially be considered a transient error. However, in my case a 404 is terminal, whereas a 606 is a custom code used by the server meaning I've been rate limited. Looking at the logic of the [Status enum](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/persistence/Status.java) it seems that anything above a 400 will be considered a FETCH_ERROR, meaning a 404 would be considered a FETCH_ERROR. I'd like to be able to configure what is considered terminal (i.e., don't attempt to fetch again), and what codes are actually considered FETCH_ERROR (i.e., retry after time specified by fetchInterval.fetch.error). I don't want to continue trying to fetch 404 pages, but I would like to retry on 606 status.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5MjE2MTgyNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/574,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5MjUyNjM1Mw==,incubator-stormcrawler,392526353,574,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-05-28T13:24:58Z,2018-05-28T13:24:58Z,"Thanks for the explanation @danielamaya. One simpler solution would be to write your own Scheduler.  It could extend the [DefaultScheduler](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/persistence/DefaultScheduler.java#L111) and as the http code should be saved in the metadata under _fetch.statusCode_, you could force the Status based on your own logic. What do you think?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5MjUyNjM1Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/574,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NTA2MjQ1OQ==,incubator-stormcrawler,395062459,574,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-06-06T13:09:48Z,2018-06-06T13:09:48Z,"Closing for now @danielamaya, feel free to comment on the solution I suggested","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NTA2MjQ1OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/577,https://api.github.com/repos/apache/incubator-stormcrawler/issues/577,incubator-stormcrawler,327656818,577,ParseFilter to tag a document based on pattern matching on its URL,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-05-30T09:52:26Z,2018-05-31T09:32:29Z,"Similar to the concept of collections in the [GSA](https://www.google.com/support/enterprise/static/gsa/docs/admin/74/admin_console_help/crawl_collections.html), we can have a ParseFilter to add to the document metadata based on patterns matching its URL. 

The resources can be defined in JSON like so

```
{
	""collections"": [{
			""name"": ""stormcrawler"",
			""includePatterns"": [""http://stormcrawler.net/.+""]
		},
		{
			""name"": ""crawler"",
			""includePatterns"": ["".+crawler.+"", "".+nutch.+""],
			""excludePatterns"": ["".+baby.+"", "".+spider.+""]
		}
	]
}
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/577/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/577,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5MzQ3MzEyMQ==,incubator-stormcrawler,393473121,577,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-05-31T09:32:29Z,2018-05-31T09:32:29Z,The format used is different from what the [GSA supports](https://support.google.com/gsa/answer/6329145?hl=en). Ours is pure regex and it is possible to convert the GSA ones pretty easily.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5MzQ3MzEyMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/578,https://api.github.com/repos/apache/incubator-stormcrawler/issues/578,incubator-stormcrawler,329863373,578,New URL filter implementation based on JSON file and organised per hostname or domain,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-06-06T13:17:14Z,2018-06-11T10:24:50Z,"One benefit is that we won't need to go through all the patterns and can just check the ones for a particular domain which could be quicker. Being based on a JSON file, means that thanks to #569 and we'll even be able to refresh the resources from ES without restarting the topology.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/578/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/578,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NTA4MzkwMQ==,incubator-stormcrawler,395083901,578,NA,noerw,7880552,Norwin,,NA,2018-06-06T14:14:40Z,2018-06-06T14:14:40Z,"Even more flexibility would be given, if the filters were organized by arbitrary keys, that would be matched to metadata key/values.
This would for example allow the use case where sets of (seed) URLs are grouped by an external ID (eg `metadata.crawlId`), which maps to specific crawl settings / filters for that group.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NTA4MzkwMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/578,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NTEwOTQ3Ng==,incubator-stormcrawler,395109476,578,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-06-06T15:25:05Z,2018-06-06T15:25:05Z,"That's a good suggestion. I'll think about a nice way to configure per host/domain/arbitrary metadata in the same config file but if you have any suggestion, that would be welcome.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NTEwOTQ3Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/578,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NTIxMzA2NQ==,incubator-stormcrawler,395213065,578,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2018-06-06T21:03:23Z,2018-06-06T21:03:23Z,"Maybe the [urlfilter-fast](https://github.com/commoncrawl/nutch/blob/cc-fast-url-filter/src/plugin/urlfilter-fast/src/java/org/apache/nutch/urlfilter/fast/FastURLFilter.java) plugin in CC's fork of Nutch could be a source of inspiration. Matching regular expressions only on path (and query) is also faster than matching on the longer URL string. Currently, urlfilter-fast uses a HashMap to hold rules per host/domain. That scales well up to 100,000s of hosts/domains given that most of them share the simple {{DenyPath .*}} - I'm trying to replace the hash by a trie and hope to be able to blacklist few millions of domains using only about 100-200 MB of Java heap memory.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NTIxMzA2NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/578,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NTU0NTkwMg==,incubator-stormcrawler,395545902,578,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-06-07T19:59:08Z,2018-06-07T19:59:08Z,"@noerw I've put an initial version in [a separate branch](https://github.com/DigitalPebble/storm-crawler/tree/578), please have a look and let me know what you think of it","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NTU0NTkwMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/578,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NTY4MTEwMw==,incubator-stormcrawler,395681103,578,NA,noerw,7880552,Norwin,,NA,2018-06-08T07:57:39Z,2018-06-08T07:57:39Z,"Amazing, thank you! This looks great, two remarks though:
- When generating the required JSON, it would be easier to have the scope type, key and value in separate JSON fields instead of having to build strings. But thats just preference I guess.
    ```json
    [
           {
    		""scope"": ""GLOBAL"",
			""patterns"": [""DenyPathQuery \\.jpg""]
		},
		{
			""scope"": ""DOMAIN"",
			""value"": ""stormcrawler.net"",
			""patterns"": [""DenyPath .+""]
		},
		{
			""scope"": ""METADATA"",
			""value"": ""bar"",
			""key"": ""foo"",
			""patterns"": [""DenyPath .+""]
           }
    ]
    ```
- To implement a whitelist, a directive `AllowPath` could easily be added to `checkScope()`, right?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NTY4MTEwMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/578,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NTY4ODUyMA==,incubator-stormcrawler,395688520,578,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-06-08T08:26:11Z,2018-06-08T08:26:11Z,"> it would be easier to have the scope type, key and value in separate JSON fields instead of having to build strings

I considered it but thought it was simpler like that. The value (whatever it is) is part of the scope and easier to build and understand.

> To implement a whitelist, a directive AllowPath could easily be added to checkScope(), right?

Could do. I'll have a look at that.

Thanks for your feedback","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NTY4ODUyMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/578,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NTcxMjA1OA==,incubator-stormcrawler,395712058,578,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-06-08T09:53:36Z,2018-06-08T09:53:36Z,@noerw see #581 ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NTcxMjA1OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/578,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NjE5NjQ3OA==,incubator-stormcrawler,396196478,578,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-06-11T10:24:50Z,2018-06-11T10:24:50Z,Merged,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NjE5NjQ3OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/579,https://api.github.com/repos/apache/incubator-stormcrawler/issues/579,incubator-stormcrawler,329891303,579,Remove synchronization used in storm crawler in single threaded bolts,nitindahiya,11920415,,,CLOSED,2018-06-06T14:24:53Z,2018-06-06T15:20:25Z,"Why are synchronized blocks used in several places, for eg. StatusUpdaterBolt(es)
  ```
        // need to synchronize: otherwise it might get added to the cache
        // without having been sent to ES
          synchronized (waitAck) {
            // check that the same URL is not being sent to ES
            List<Tuple> alreadySent = waitAck.getIfPresent(sha256hex);
            if (alreadySent != null) {
                // if this object is discovered - adding another version of it
                // won't make any difference
                LOG.debug(
                        ""Already being sent to ES {} with status {} and ID {}"",
                        url, status, sha256hex);
                if (status.equals(Status.DISCOVERED)) {
                    // done to prevent concurrency issues
                    // the ack method could have been called
                    // after the entries from waitack were
                    // purged which can lead to entries being added straight to
                    // waitack even if nothing was sent to ES
                    metadata.setValue(""es.status.skipped.sending"", ""true"");
                    return;
                }
            }
        }
```

Aren't storm spouts thread safe by default ?
Thanks!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/579/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/579,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NTEwNzgxNA==,incubator-stormcrawler,395107814,579,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-06-06T15:20:25Z,2018-06-06T15:20:25Z,"The ES client is non blocking and can use more than one thread so it must be able to operate in parallel with the main execution thread. Trust me, they are there for a reason ;-)","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NTEwNzgxNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/580,https://api.github.com/repos/apache/incubator-stormcrawler/issues/580,incubator-stormcrawler,330365706,580,Upgrade to Crawler-Commons 0.10,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-06-07T17:24:54Z,2018-06-08T10:15:08Z,"Better sitemap processing and no Tika dependency
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/580/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/582,https://api.github.com/repos/apache/incubator-stormcrawler/issues/582,incubator-stormcrawler,331128847,582,SimpleFetcherBolt to send URLs back to its own queue if time to wait above threshold,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-06-11T10:19:35Z,2018-06-11T10:22:47Z,"The SimpleFetcherBolt is less complex than the standard FetcherBolt as it does not have to hold internal fetch queues but instead has many instances (threads managed by Storm). However, its performance is usually worse as it enforces the politeness by sleeping the necessary amount of time, which in effect, prevents it from processing URLs from other servers.

What we can do is to send any tuple for which the wait time is above a certain threshold back to the queue of the bolt if it is above a certain threshold. This would have the advantage of moving quicker to a URL from a different server, but a possible drawback is that a URL could get a timeout if it gets sent to the back of the queue too often.

By default, the threshold would be set to -1, meaning that the existing behaviour would be preserved and all delays would be slept. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/582/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/583,https://api.github.com/repos/apache/incubator-stormcrawler/issues/583,incubator-stormcrawler,331131333,583,Upgrade to Storm 1.2.2,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-06-11T10:27:22Z,2018-06-11T10:31:38Z,"https://www.apache.org/dist/storm/apache-storm-1.2.2/RELEASE_NOTES.html

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/583/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/584,https://api.github.com/repos/apache/incubator-stormcrawler/issues/584,incubator-stormcrawler,331612625,584,ES IndexerBolt set pipeline via config,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-06-12T14:28:07Z,2018-06-13T12:11:01Z,"See discussion on [SO](https://stackoverflow.com/questions/50817021/archiving-old-websites-with-stormcrawler-and-elasticsearch)

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/584/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/585,https://api.github.com/repos/apache/incubator-stormcrawler/issues/585,incubator-stormcrawler,331967938,585,Move to metrics v2,jnioche,218319,Julien Nioche,julien@digitalpebble.com,OPEN,2018-06-13T12:14:02Z,2019-08-09T09:54:41Z,"The methods of the initial version of the metrics are marked as deprecated, we should port the code to use the new mechanism
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/585/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/585,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyMDA1MTI1OA==,incubator-stormcrawler,420051258,585,NA,jcruzmartini,6817516,Juan Cruz Martini,,NA,2018-09-10T20:34:04Z,2018-09-10T20:34:04Z,"@jnioche are you working in this one? probably I can help on this, I am doing some modifications on my code and I am updating my custom metrics.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyMDA1MTI1OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/585,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyMDA2ODM4Mw==,incubator-stormcrawler,420068383,585,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-09-10T21:32:07Z,2018-09-10T21:32:07Z,"Hi Juan,

I am not yet working on it. Would be fab to get your help on this. Thanks
in advance!

On Mon, 10 Sep 2018 at 21:34, Juan Cruz Martini <notifications@github.com>
wrote:

> @jnioche <https://github.com/jnioche> are you working in this one?
> probably I can help on this, I am doing some modifications on my code and I
> am updating my custom metrics.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/DigitalPebble/storm-crawler/issues/585#issuecomment-420051258>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AANUz1P6uSXXqDDwRHpElhS4r4Irl68Hks5uZsy8gaJpZM4UmFE3>
> .
>


-- 



* Open Source Solutions for Text Engineering   http://www.digitalpebble.com
<http://www.digitalpebble.com>*
*http://digitalpebble.blogspot.com <http://digitalpebble.blogspot.com/>*
@digitalpebble <https://twitter.com/digitalpebble>
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyMDA2ODM4Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/585,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzOTA2NDI5OQ==,incubator-stormcrawler,439064299,585,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-11-15T14:45:49Z,2018-11-15T14:45:49Z,@jcruzmartini any progress on that?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzOTA2NDI5OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/585,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUxOTg1OTAzMw==,incubator-stormcrawler,519859033,585,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-08-09T09:54:41Z,2019-08-09T09:54:41Z,"This needs implementations for the MetricsConsumers, ideally, these could be offered as separate projects so that people could use and contribute to them even if they don't use StormCrawler. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUxOTg1OTAzMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/586,https://api.github.com/repos/apache/incubator-stormcrawler/issues/586,incubator-stormcrawler,331970112,586,New XPATH implementation based on JSON file and organised per hostname or domain,jnioche,218319,Julien Nioche,julien@digitalpebble.com,OPEN,2018-06-13T12:20:39Z,2019-02-11T10:03:16Z,"Replaces #445 and similar to #578 but for a ParseFilter that can load XPATH patterns per hostname or domain.

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/586/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/587,https://api.github.com/repos/apache/incubator-stormcrawler/issues/587,incubator-stormcrawler,332297930,587,Upgrade ES to 6.3.0,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-06-14T08:20:33Z,2018-06-14T08:24:50Z,"
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/587/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/588,https://api.github.com/repos/apache/incubator-stormcrawler/issues/588,incubator-stormcrawler,332339453,588,ES Wrapper for URLFilters implementing JSONResource,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-06-14T10:16:30Z,2018-07-02T13:42:57Z,"Similar to https://github.com/DigitalPebble/storm-crawler/blob/master/external/elasticsearch/src/main/java/com/digitalpebble/stormcrawler/elasticsearch/parse/filter/JSONResourceWrapper.java but for URLFilters.

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/588/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/588,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NzI0NTU0MA==,incubator-stormcrawler,397245540,588,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-06-14T10:16:59Z,2018-06-14T10:16:59Z,Could also move JSONResource out of ParseFilter as it is used by URLfilters as well,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDM5NzI0NTU0MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/588,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQwMTgwODI4Nw==,incubator-stormcrawler,401808287,588,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-07-02T13:42:50Z,2018-07-02T13:42:50Z,can be used with com.digitalpebble.stormcrawler.filtering.regex.FastURLFilter,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQwMTgwODI4Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/590,https://api.github.com/repos/apache/incubator-stormcrawler/issues/590,incubator-stormcrawler,338850608,590,ES change value of es.status.reset.fetchdate.after,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-07-06T08:29:28Z,2018-07-06T08:29:50Z,"By default it is set to -1, which means that the same nextFetchDate will be reused as long as it returns results. If a single site has loads of URLs scheduled at the same time, e.g. coming from a sitemap, only URLs from that site will be fetched. 

Will change to 120 secs by default, can always be changed by the users.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/590/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/591,https://api.github.com/repos/apache/incubator-stormcrawler/issues/591,incubator-stormcrawler,339991534,591,wish: Expose some fields on StatusUpdaterBolt to allow custom naming strategy implementation,jcruzmartini,6817516,Juan Cruz Martini,,CLOSED,2018-07-10T20:18:17Z,2018-07-13T15:13:26Z,"Hi @jnioche , we are working with ES integration of the crawler and for some reasons we want to extend the functionality of **StatusUpdaterBolt** , basically we want to apply our custom naming strategy for handling many status indexes and content indexes names in parallel. Names will depend on same information stored previously in metadata. eg. `status_${some_property_name}`.
The existing code fits perfect to our needs, so we want to extend existing class and only override behavior that you have on `store` method.

Our main issue basically consist in the limited scope of all variables in **StatusUpdaterBolt** that we need to interact in `store` method of our child class that will be extending **StatusUpdaterBolt**.

Having those vars as protected or having getters for those will allow to extend this class and allow custom implementations in a future.

Obviously, we can implement our whole custom implementation extending AbstractStatusUpdaterBolt, but just want to check if you want to avoid overriding of this class for any special reason.

Thanks for your time in advance.






 ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/591/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/591,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQwMzk1Njg4NA==,incubator-stormcrawler,403956884,591,NA,xytian315,4520812,Kristy Tian,xytian315@gmail.com,NA,2018-07-10T20:34:41Z,2018-07-10T20:34:41Z,"+1
same as the fields defined here https://github.com/DigitalPebble/storm-crawler/blob/master/external/elasticsearch/src/main/java/com/digitalpebble/stormcrawler/elasticsearch/bolt/IndexerBolt.java#L63
https://github.com/DigitalPebble/storm-crawler/blob/master/external/elasticsearch/src/main/java/com/digitalpebble/stormcrawler/elasticsearch/metrics/StatusMetricsBolt.java#L59
It would be nice if it defined as ""protected"". ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQwMzk1Njg4NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/591,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQwNDExNTg2MQ==,incubator-stormcrawler,404115861,591,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-07-11T10:04:51Z,2018-07-11T10:04:51Z,"Hi
@jcruzmartini I suppose your only modification to the logic in store() would be to use a custom index name based on the value of a metadatum. Instead of copying the whole method and have access to the fields, what about adding a method _getIndexName(Metadata m)_ in the super class which would return the value set in the config. Your subclass would simply need to override that method and could use _super.getIndexName(m)_.

What do you think? I can see a benefit of doing this for cases where we want to keep a separate index per language for instance.

I am not against setting the fields to protected but I am not convinced that it is necessary for all of them. Also, I wouldn't want the subclass to be able to change the values and would prefer getters.

@xytian315 would the solution above work for you as well?

Would either of you like to submit a PR?

Thanks
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQwNDExNTg2MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/591,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQwNDE4MzUzNg==,incubator-stormcrawler,404183536,591,NA,jcruzmartini,6817516,Juan Cruz Martini,,NA,2018-07-11T14:10:14Z,2018-07-11T14:10:14Z,"Thanks @jnioche for your quick response, your proposal sounds great. I am gonna be creating a pull request for including those changes. I am thinking that probably we will need to do same in AbstractSpout class for getting custom indexName when executing ES query in AggregationSpout.
I am gonna talk with @xytian315  in order to coordinate modifications required for both changes.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQwNDE4MzUzNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/591,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQwNDE4NDg4NA==,incubator-stormcrawler,404184884,591,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-07-11T14:14:19Z,2018-07-11T14:14:19Z,"Except that it can't be based on Metadata values in the spouts. I'd create a constructor for the AbstractSpout where you can specify a non-default index name, similar to what I did for the [IndexerBolt](https://github.com/DigitalPebble/storm-crawler/blob/master/external/elasticsearch/src/main/java/com/digitalpebble/stormcrawler/elasticsearch/bolt/IndexerBolt.java#L80)","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQwNDE4NDg4NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/591,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQwNDg2MzE5Mw==,incubator-stormcrawler,404863193,591,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-07-13T15:13:25Z,2018-07-13T15:13:25Z,See #592 ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQwNDg2MzE5Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/595,https://api.github.com/repos/apache/incubator-stormcrawler/issues/595,incubator-stormcrawler,346949556,595,NPE in elasticsearch CollapsingSpout,noerw,7880552,Norwin,,CLOSED,2018-08-02T10:19:09Z,2018-08-03T20:43:29Z,"`com.digitalpebble.stormcrawler.elasticsearch.persistence.CollapsingSpout` throws a NPE due to `lastDate` being `null`:

https://github.com/DigitalPebble/storm-crawler/blob/1.10/external/elasticsearch/src/main/java/com/digitalpebble/stormcrawler/elasticsearch/persistence/CollapsingSpout.java#L187

To reproduce, just configure an empty or nonexistent status index.

v1.9 is also affected. `AggregationSpout` might be affected as well. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/595/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/595,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxMDI0ODg5MA==,incubator-stormcrawler,410248890,595,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-08-03T13:12:27Z,2018-08-03T13:12:27Z,"It happens with an empty status index. If the index does not exist at all we get 

`org.elasticsearch.ElasticsearchStatusException: Elasticsearch exception [type=index_not_found_exception, reason=no such index]`

which is normal and expected. The init script must be called prior to running the topology.

The issue happens with the CollapsingSpout only, not with the AggregationSpout. I'll push a fix as soon as github is working again. Can't pull or push at the moment.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxMDI0ODg5MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/595,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxMDI1Nzc4MA==,incubator-stormcrawler,410257780,595,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-08-03T13:41:37Z,2018-08-03T13:41:37Z,"thanks for reporting it @noerw 
please give the master branch a try ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxMDI1Nzc4MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/595,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxMDI2MDU1Mw==,incubator-stormcrawler,410260553,595,NA,noerw,7880552,Norwin,,NA,2018-08-03T13:51:55Z,2018-08-03T13:51:55Z,"Thanks for the fix!
I used a wildcard for the status index `crawlstatus-*`, and in that case there is no `index_not_found_exception` when there is no match, but a valid response with no hits (ES 6.2).","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxMDI2MDU1Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/595,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxMDMzODM4Ng==,incubator-stormcrawler,410338386,595,NA,jcruzmartini,6817516,Juan Cruz Martini,,NA,2018-08-03T18:28:02Z,2018-08-03T18:28:02Z,"Hi @jnioche , we have been dealing with something similar on these days in our project, is same scenario because we are using also `status*` as @noerw is using, when we do not have any status index created yet, we are getting an exception on StatusMetricBolt.

`87152 [Thread-62-status_metrics-executor[24 24]] INFO  c.d.s.e.m.StatusMetricsBolt - Multiquery returned in 279 msec
87164 [Thread-62-status_metrics-executor[24 24]] ERROR o.a.s.util - Async loop died!
java.lang.RuntimeException: java.lang.NullPointerException
    at org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:522) ~[storm-core-1.2.2.jar:1.2.2]
    at org.apache.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:487) ~[storm-core-1.2.2.jar:1.2.2]
    at org.apache.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:74) ~[storm-core-1.2.2.jar:1.2.2]
    at org.apache.storm.daemon.executor$fn__10795$fn__10808$fn__10861.invoke(executor.clj:861) ~[storm-core-1.2.2.jar:1.2.2]
    at org.apache.storm.util$async_loop$fn__553.invoke(util.clj:484) [storm-core-1.2.2.jar:1.2.2]
    at clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]
    at java.lang.Thread.run(Thread.java:748) [?:1.8.0_171]
Caused by: java.lang.NullPointerException
    at com.digitalpebble.stormcrawler.elasticsearch.metrics.StatusMetricsBolt.execute(StatusMetricsBolt.java:145) ~[stormcrawler-1.1.0.jar:?]
    at org.apache.storm.daemon.executor$fn__10795$tuple_action_fn__10797.invoke(executor.clj:739) ~[storm-core-1.2.2.jar:1.2.2]
    at org.apache.storm.daemon.executor$mk_task_receiver$fn__10716.invoke(executor.clj:471) ~[storm-core-1.2.2.jar:1.2.2]
    at org.apache.storm.disruptor$clojure_handler$reify__10135.onEvent(disruptor.clj:41) ~[storm-core-1.2.2.jar:1.2.2]
    at org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:509) ~[storm-core-1.2.2.jar:1.2.2]
    ... 6 more`

if you want and you think that this will add some value to the project, I can create a PR for fixing that NPE that is being thrown when there is not any index created yet.

Just a comment to add more information to @noerw scenario, we are getting a NPE also in AggregationSpout when using `status*`, but spout is not crashing so is more or less like a warning

`11018 [I/O dispatcher 2] ERROR c.d.s.e.p.AggregationSpout - Exception with ES query
java.io.IOException: Unable to parse response body for Response{requestLine=POST /status*/status/_search?typed_keys=true&ignore_unavailable=false&expand_wildcards=open&allow_no_indices=true&preference=_shards%3A6&search_type=query_then_fetch&batched_reduce_size=512 HTTP/1.1, host=http://localhost:9200, response=HTTP/1.1 200 OK}
 at org.elasticsearch.client.RestHighLevelClient$1.onSuccess(RestHighLevelClient.java:582) [stormcrawler-1.1.0.jar:?]
 at org.elasticsearch.client.RestClient$FailureTrackingResponseListener.onSuccess(RestClient.java:621) [stormcrawler-1.1.0.jar:?]
 at org.elasticsearch.client.RestClient$1.completed(RestClient.java:375) [stormcrawler-1.1.0.jar:?]
 at org.elasticsearch.client.RestClient$1.completed(RestClient.java:366) [stormcrawler-1.1.0.jar:?]
 at org.apache.http.concurrent.BasicFuture.completed(BasicFuture.java:123) [stormcrawler-1.1.0.jar:?]
 at org.apache.http.impl.nio.client.DefaultClientExchangeHandlerImpl.responseCompleted(DefaultClientExchangeHandlerImpl.java:177) [stormcrawler-1.1.0.jar:?]
 at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.processResponse(HttpAsyncRequestExecutor.java:436) [stormcrawler-1.1.0.jar:?]
 at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.inputReady(HttpAsyncRequestExecutor.java:326) [stormcrawler-1.1.0.jar:?]
 at org.apache.http.impl.nio.DefaultNHttpClientConnection.consumeInput(DefaultNHttpClientConnection.java:265) [stormcrawler-1.1.0.jar:?]
 at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:81) [stormcrawler-1.1.0.jar:?]
 at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:39) [stormcrawler-1.1.0.jar:?]
 at org.apache.http.impl.nio.reactor.AbstractIODispatch.inputReady(AbstractIODispatch.java:114) [stormcrawler-1.1.0.jar:?]
 at org.apache.http.impl.nio.reactor.BaseIOReactor.readable(BaseIOReactor.java:162) [stormcrawler-1.1.0.jar:?]
 at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvent(AbstractIOReactor.java:337) [stormcrawler-1.1.0.jar:?]
 at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvents(AbstractIOReactor.java:315) [stormcrawler-1.1.0.jar:?]
 at org.apache.http.impl.nio.reactor.AbstractIOReactor.execute(AbstractIOReactor.java:276) [stormcrawler-1.1.0.jar:?]
 at org.apache.http.impl.nio.reactor.BaseIOReactor.execute(BaseIOReactor.java:104) [stormcrawler-1.1.0.jar:?]
 at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor$Worker.run(AbstractMultiworkerIOReactor.java:588) [stormcrawler-1.1.0.jar:?]
 at java.lang.Thread.run(Thread.java:745) [?:1.8.0_25]
Caused by: java.lang.NullPointerException`
Thanks in advance","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxMDMzODM4Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/595,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxMDM2NzcyNg==,incubator-stormcrawler,410367726,595,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-08-03T20:28:45Z,2018-08-03T20:28:45Z,"Hi @jcruzmartini 
StatusMetricBolt -> yes please a PR would be welcome. I'll try to reproduce the problem
AggregationSpout-> do you have the source of the NullPointerException further down in the logs? Could you please open a separate issue for it?
Thanks","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxMDM2NzcyNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/595,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxMDM3MTEwMA==,incubator-stormcrawler,410371100,595,NA,jcruzmartini,6817516,Juan Cruz Martini,,NA,2018-08-03T20:43:29Z,2018-08-03T20:43:29Z,sure! thanks @jnioche ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxMDM3MTEwMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/596,https://api.github.com/repos/apache/incubator-stormcrawler/issues/596,incubator-stormcrawler,347452143,596,WARCHdfsBolt writes zero byte files,keyboardsamurai,67417,Antonio Agudo,,CLOSED,2018-08-03T16:01:16Z,2018-09-07T10:14:59Z,"As discussed [in a stackoverflow thread](https://stackoverflow.com/questions/51654160/getting-a-topology-on-stormcrawler-to-properly-write-warc-files/51670822#51670822), I tried to create a storm-crawler-archetype 1.10 based project that emits warc files. Unfortunately though, these warc files always appear empty and contain 0 bytes. 

[I created a repo](https://github.com/keyboardsamurai/storm-test-warc) where the setup is shown. Also I tried to amend the suggestions that @jnioche gave me (Adding a FileTimeSizeRotationPolicy set to rotate every 10 seconds and 10 Kbytes and setting a new CountSyncPolicy(1)) to no avail.

The command I use to run this example is `mvn clean package && storm jar target/test-1.0-SNAPSHOT.jar test.CrawlTopology -conf ./crawler-conf.yaml -local`

**Sidenote:**
I also downgraded the test repo case from above to SC 1.8 and Storm 1.2.1 respectively [in this branch right here](https://github.com/keyboardsamurai/storm-test-warc/tree/0_8_VERSION), but couldn't get that to write a proper WARC file either when using time based rotation - these files were 4 Kilobytes in size but appeared to be invalid gzip files with some binary content. 

However, when either lowering the filesize threshold to an excessive value like 4 kbyte or using the MemoryStatusUpdater for recursion, valid single page archives started to appear. It seems that flushing behavior might still be somewhat random.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/596/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/596,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxODM1MzM4NA==,incubator-stormcrawler,418353384,596,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-09-04T12:46:08Z,2018-09-04T12:46:08Z,"Hi @keyboardsamurai to get the sync working you need to configure HDFS like so

```
        warcbolt.withConfigKey(""warc"");
        Map<String, Object> hdfsConf = new HashMap<>();
        hdfsConf.put(""fs.file.impl"", ""org.apache.hadoop.fs.RawLocalFileSystem"");
        getConf().put(""warc"", hdfsConf);
```

This uses the RawLocalFileSystem, which unlike the checksum one used by default does a proper sync of the content to the file. 

This seems to work with SC 1.8. The latest version of SC is broken and does not generate a proper gzip.

> However, when either lowering the filesize threshold to an excessive value like 4 kbyte or using the MemoryStatusUpdater for recursion, valid single page archives started to appear. 

This worked because the rotation had time to work as new URLs were coming through and / or the size was low enough.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxODM1MzM4NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/596,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxOTM3MDgyOA==,incubator-stormcrawler,419370828,596,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-09-07T08:52:53Z,2018-09-07T08:52:53Z,@sebastian-nagel have you tried the WARC module since the changes you made in https://github.com/DigitalPebble/storm-crawler/commit/0afe3ede45f9474d5684257735c3ceb93336f53a#diff-5332acd41a61ec17dd64f203a6132c33 ?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxOTM3MDgyOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/596,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxOTM5MzExMA==,incubator-stormcrawler,419393110,596,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-09-07T10:14:59Z,2018-09-07T10:14:59Z,"Have found the cause of the problem and fixed it. This had to do with the compression of the entries. We should now get a valid gzip regardless of whether triggered by a sync or a rotation.

Thanks @keyboardsamurai for reporting it. Please give the fix a try if you can.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxOTM5MzExMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/597,https://api.github.com/repos/apache/incubator-stormcrawler/issues/597,incubator-stormcrawler,347555079,597,NPE in AggregationSpout when there is not any status index created,jcruzmartini,6817516,Juan Cruz Martini,,CLOSED,2018-08-03T22:38:36Z,2018-08-15T07:52:19Z,"When we are running crawler topology and there is not any index status created yet in ES, AggregationSpout is throwing a NPE.
We are using as index name in configuration file `status*` in order to get all indexes that match with that criteria.
The exception that we are getting is

```
17027 [I/O dispatcher 5] ERROR c.d.s.e.p.AggregationSpout - Exception with ES query
java.io.IOException: Unable to parse response body for Response{requestLine=POST /status*/status/_search?typed_keys=true&ignore_unavailable=false&expand_wildcards=open&allow_no_indices=true&preference=_shards%3A0&search_type=query_then_fetch&batched_reduce_size=512 HTTP/1.1, host=http://localhost:9200, response=HTTP/1.1 200 OK}
	at org.elasticsearch.client.RestHighLevelClient$1.onSuccess(RestHighLevelClient.java:582) [stormcrawler-1.1.0.jar:?]
	at org.elasticsearch.client.RestClient$FailureTrackingResponseListener.onSuccess(RestClient.java:621) [stormcrawler-1.1.0.jar:?]
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:375) [stormcrawler-1.1.0.jar:?]
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:366) [stormcrawler-1.1.0.jar:?]
	at org.apache.http.concurrent.BasicFuture.completed(BasicFuture.java:123) [stormcrawler-1.1.0.jar:?]
	at org.apache.http.impl.nio.client.DefaultClientExchangeHandlerImpl.responseCompleted(DefaultClientExchangeHandlerImpl.java:177) [stormcrawler-1.1.0.jar:?]
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.processResponse(HttpAsyncRequestExecutor.java:436) [stormcrawler-1.1.0.jar:?]
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.inputReady(HttpAsyncRequestExecutor.java:326) [stormcrawler-1.1.0.jar:?]
	at org.apache.http.impl.nio.DefaultNHttpClientConnection.consumeInput(DefaultNHttpClientConnection.java:265) [stormcrawler-1.1.0.jar:?]
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:81) [stormcrawler-1.1.0.jar:?]
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:39) [stormcrawler-1.1.0.jar:?]
	at org.apache.http.impl.nio.reactor.AbstractIODispatch.inputReady(AbstractIODispatch.java:114) [stormcrawler-1.1.0.jar:?]
	at org.apache.http.impl.nio.reactor.BaseIOReactor.readable(BaseIOReactor.java:162) [stormcrawler-1.1.0.jar:?]
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvent(AbstractIOReactor.java:337) [stormcrawler-1.1.0.jar:?]
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvents(AbstractIOReactor.java:315) [stormcrawler-1.1.0.jar:?]
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.execute(AbstractIOReactor.java:276) [stormcrawler-1.1.0.jar:?]
	at org.apache.http.impl.nio.reactor.BaseIOReactor.execute(BaseIOReactor.java:104) [stormcrawler-1.1.0.jar:?]
	at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor$Worker.run(AbstractMultiworkerIOReactor.java:588) [stormcrawler-1.1.0.jar:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_25]
Caused by: java.lang.NullPointerException
	at com.digitalpebble.stormcrawler.elasticsearch.persistence.AggregationSpout.onResponse(AggregationSpout.java:191) ~[stormcrawler-1.1.0.jar:?]
	at com.digitalpebble.stormcrawler.elasticsearch.persistence.AggregationSpout.onResponse(AggregationSpout.java:71) [stormcrawler-1.1.0.jar:?]
	at org.elasticsearch.client.RestHighLevelClient$1.onSuccess(RestHighLevelClient.java:580) [stormcrawler-1.1.0.jar:?]
	... 18 more
17028 [I/O dispatcher 1] ERROR c.d.s.e.p.AggregationSpout - Exception with ES query
java.io.IOException: Unable to parse response body for Response{requestLine=POST /status*/status/_search?typed_keys=true&ignore_unavailable=false&expand_wildcards=open&allow_no_indices=true&preference=_shards%3A2&search_type=query_then_fetch&batched_reduce_size=512 HTTP/1.1, host=http://localhost:9200, response=HTTP/1.1 200 OK}
	at org.elasticsearch.client.RestHighLevelClient$1.onSuccess(RestHighLevelClient.java:582) [stormcrawler-1.1.0.jar:?]
	at org.elasticsearch.client.RestClient$FailureTrackingResponseListener.onSuccess(RestClient.java:621) [stormcrawler-1.1.0.jar:?]
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:375) [stormcrawler-1.1.0.jar:?]
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:366) [stormcrawler-1.1.0.jar:?]
	at org.apache.http.concurrent.BasicFuture.completed(BasicFuture.java:123) [stormcrawler-1.1.0.jar:?]
	at org.apache.http.impl.nio.client.DefaultClientExchangeHandlerImpl.responseCompleted(DefaultClientExchangeHandlerImpl.java:177) [stormcrawler-1.1.0.jar:?]
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.processResponse(HttpAsyncRequestExecutor.java:436) [stormcrawler-1.1.0.jar:?]
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.inputReady(HttpAsyncRequestExecutor.java:326) [stormcrawler-1.1.0.jar:?]
	at org.apache.http.impl.nio.DefaultNHttpClientConnection.consumeInput(DefaultNHttpClientConnection.java:265) [stormcrawler-1.1.0.jar:?]
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:81) [stormcrawler-1.1.0.jar:?]
	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:39) [stormcrawler-1.1.0.jar:?]
	at org.apache.http.impl.nio.reactor.AbstractIODispatch.inputReady(AbstractIODispatch.java:114) [stormcrawler-1.1.0.jar:?]
	at org.apache.http.impl.nio.reactor.BaseIOReactor.readable(BaseIOReactor.java:162) [stormcrawler-1.1.0.jar:?]
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvent(AbstractIOReactor.java:337) [stormcrawler-1.1.0.jar:?]
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvents(AbstractIOReactor.java:315) [stormcrawler-1.1.0.jar:?]
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.execute(AbstractIOReactor.java:276) [stormcrawler-1.1.0.jar:?]
	at org.apache.http.impl.nio.reactor.BaseIOReactor.execute(BaseIOReactor.java:104) [stormcrawler-1.1.0.jar:?]
	at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor$Worker.run(AbstractMultiworkerIOReactor.java:588) [stormcrawler-1.1.0.jar:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_25]
Caused by: java.lang.NullPointerException
	at com.digitalpebble.stormcrawler.elasticsearch.persistence.AggregationSpout.onResponse(AggregationSpout.java:191) ~[stormcrawler-1.1.0.jar:?]
	at com.digitalpebble.stormcrawler.elasticsearch.persistence.AggregationSpout.onResponse(AggregationSpout.java:71) [stormcrawler-1.1.0.jar:?]
	at org.elasticsearch.client.RestHighLevelClient$1.onSuccess(RestHighLevelClient.java:580) [stormcrawler-1.1.0.jar:?]
	... 18 more

```

I think that the fix for this issue should be done in onResponse checking that results.getAggregations() is not null.

` Aggregations aggregs = response.getAggregations();`

Thanks in advance @jnioche  and let me know if that works for you I can create a PR for this too","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/597/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/597,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxMjE4MjQ3OQ==,incubator-stormcrawler,412182479,597,NA,jcruzmartini,6817516,Juan Cruz Martini,,NA,2018-08-10T19:29:19Z,2018-08-10T19:29:19Z,"We added a workaround for this issue in our code, basically what we did is extend AggregationSpout and overrride onResponse method.

```
  @Override
    public void onResponse(SearchResponse response) {

        Aggregations aggregs = response.getAggregations();
		if (aggregs == null) {
			isInESQuery.set(false);
			return;
		}
		super.onResponse(response);
    }
```

this solved the issue,  response.getAggregations() is null when there is no any index","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxMjE4MjQ3OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/597,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxMzEyMTgzOA==,incubator-stormcrawler,413121838,597,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-08-15T07:52:19Z,2018-08-15T07:52:19Z,"Fixed, thanks. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxMzEyMTgzOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/600,https://api.github.com/repos/apache/incubator-stormcrawler/issues/600,incubator-stormcrawler,351309503,600,"wish: possibility to store ""HTTP status code"" in the ES status index? ",xytian315,4520812,Kristy Tian,xytian315@gmail.com,CLOSED,2018-08-16T18:01:09Z,2018-08-17T07:55:00Z,"Sometimes we want to know more than just ""FETCHED, REDIRECTION, FETCHED_ERROR"". 
https://github.com/DigitalPebble/storm-crawler/blob/a2e47204cb2fd7c089cac7764d803a6013b867a9/core/src/main/java/com/digitalpebble/stormcrawler/persistence/Status.java

especially it seemed all 4XX and 5XX belongs to FETCHED_ERROR. Do you guys have plans to store specific ""HTTP status code"" in the ES status index? 

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/600/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/600,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxMzYzNTQxNA==,incubator-stormcrawler,413635414,600,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2018-08-16T18:08:44Z,2018-08-16T18:08:44Z,"Isn't this already possible by adding `fetch.statusCode` to the list of persisted metadata (file `crawler-conf.yaml`):
```
metadata.persist:
- fetch.statusCode

```","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxMzYzNTQxNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/601,https://api.github.com/repos/apache/incubator-stormcrawler/issues/601,incubator-stormcrawler,354178494,601,what are the dependencies of storm crawler and where can i find the bundled jar files of those dependencies ?,saiprashanth24,42546847,,,CLOSED,2018-08-27T04:47:22Z,2018-09-11T15:15:45Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/601/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/601,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxNjE0Mjg5Mw==,incubator-stormcrawler,416142893,601,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-08-27T07:41:35Z,2018-08-27T07:41:35Z,Wrong place to ask questions and no effort to find the solution. ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxNjE0Mjg5Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/602,https://api.github.com/repos/apache/incubator-stormcrawler/issues/602,incubator-stormcrawler,354208902,602,i am getting exception when i run the crawltopology class ..the exception is shown below:  please help me solve it .,saiprashanth24,42546847,,,CLOSED,2018-08-27T07:23:57Z,2018-08-27T07:42:10Z,"What kind of issue is this?

 - [x] Question. This issue tracker is not the best place for questions. If you want to ask how to do
       something, or to understand why something isn't working the way you expect it to, use StackOverflow
       instead with the label 'stormcrawler': https://stackoverflow.com/questions/tagged/stormcrawler 

 - [ ] Bug report. If you’ve found a bug, please include a test if you can, it makes it a lot easier to fix things. Use the label 'bug' on the issue.
 
 - [ ] Feature request. Please use the label 'wish' on the issue.

Thanks!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/602/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/602,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxNjEzOTA5Mg==,incubator-stormcrawler,416139092,602,NA,saiprashanth24,42546847,,,NA,2018-08-27T07:25:24Z,2018-08-27T07:25:24Z,"![screenshot from 2018-08-27 12-54-58](https://user-images.githubusercontent.com/42546847/44646405-708be500-a9f8-11e8-94f7-2021ae53696f.png)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxNjEzOTA5Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/603,https://api.github.com/repos/apache/incubator-stormcrawler/issues/603,incubator-stormcrawler,354672368,603,how to extend the scheduler class ?,saiprashanth24,42546847,,,CLOSED,2018-08-28T10:41:03Z,2018-08-31T16:57:28Z,"What kind of issue is this?

 - [x] Question. This issue tracker is not the best place for questions. If you want to ask how to do
       something, or to understand why something isn't working the way you expect it to, use StackOverflow
       instead with the label 'stormcrawler': https://stackoverflow.com/questions/tagged/stormcrawler 

 - [ ] Bug report. If you’ve found a bug, please include a test if you can, it makes it a lot easier to fix things. Use the label 'bug' on the issue.
 
 - [ ] Feature request. Please use the label 'wish' on the issue.

Thanks!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/603/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/603,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxNzcyNzY5OQ==,incubator-stormcrawler,417727699,603,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-08-31T16:57:28Z,2018-08-31T16:57:28Z,"@saiprashanth24 which part of 

> This issue tracker is not the best place for questions. If you want to ask how to do
something, or to understand why something isn't working the way you expect it to, use StackOverflow
instead with the label 'stormcrawler': https://stackoverflow.com/questions/tagged/stormcrawler

wasn't clear?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxNzcyNzY5OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/604,https://api.github.com/repos/apache/incubator-stormcrawler/issues/604,incubator-stormcrawler,355983496,604,A simple HttpClient.execute slower than JSoup.connect,Serimert90,16742552,Mert Serimer,mertserimer@gmail.com,CLOSED,2018-08-31T13:36:03Z,2018-09-03T10:09:21Z,"*****************************Apache HttpCore 4.4.10**********************

CloseableHttpClient client = HttpClientBuilder.create()
                        .setUserAgent(""Mozilla/5.0 (Windows NT 6.1; WOW64; rv:45.0) Gecko/20100101 Firefox/45.0"")
                        .setConnectionTimeToLive(1,TimeUnit.MINUTES)
                        .setMaxConnPerRoute(1000)
                        .setMaxConnTotal(1000)
                        .disableAutomaticRetries()
                        .build();
                HttpClientContext context = HttpClientContext.create();
                HttpGet request = new HttpGet(""URL"");

                // add request header
                request.addHeader(""User-Agent"", ""Mozilla/5.0 (Windows NT 6.1; WOW64; rv:45.0) Gecko/20100101 Firefox/45.0"");
                HttpResponse response2 = client.execute(request,context);*/


*******************************JSOUP********************************

                Connection.Response response = Jsoup.connect(""URL"")
                        .userAgent(""Mozilla/5.0 (Windows NT 6.1; WOW64; rv:45.0) Gecko/20100101 Firefox/45.0"")
                        .header(""Accept-Encoding"", ""gzip, deflate"")
                        .execute();

                cookies = response.cookies();

When trying with apache, it gives _org.apache.http.NoHttpResponseException: The target server failed to respond_ when automatic tries enabled .  but in the some _xth_ try it gives me the result in 1 seconds maybe. With  Jsoup it is very fast and instant.

What am i doing wrong?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/604/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/604,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxNzcyNzExMA==,incubator-stormcrawler,417727110,604,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-08-31T16:55:41Z,2018-08-31T16:55:41Z,"Hi @Serimert90, why don't you ask this to the Http Core mailing list or on StackOverflow? You'd get a more accurate answer.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQxNzcyNzExMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/605,https://api.github.com/repos/apache/incubator-stormcrawler/issues/605,incubator-stormcrawler,361631855,605,Use ForkParser in Tika to specify timeout for parsing,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-09-19T08:18:41Z,2018-09-25T19:46:43Z,at the moment there is no limitation on the parsing time ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/605/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/605,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNDQ3Njk2OA==,incubator-stormcrawler,424476968,605,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-09-25T19:46:43Z,2018-09-25T19:46:43Z,"well, not really what the ForkParser is about. Would be good to have a timeout but this can be done with a monitoring thread.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNDQ3Njk2OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/606,https://api.github.com/repos/apache/incubator-stormcrawler/issues/606,incubator-stormcrawler,361634171,606,Upgrade to Tika 1.19,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-09-19T08:25:15Z,2018-09-19T08:41:36Z,"
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/606/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/607,https://api.github.com/repos/apache/incubator-stormcrawler/issues/607,incubator-stormcrawler,361636534,607,Upgrade to ES 6.4.1,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-09-19T08:31:50Z,2018-09-19T08:41:36Z,https://www.elastic.co/guide/en/elasticsearch/reference/6.4/release-notes-6.4.0.html,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/607/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/608,https://api.github.com/repos/apache/incubator-stormcrawler/issues/608,incubator-stormcrawler,362616805,608,SQL IndexerBolt,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-09-21T13:29:11Z,2018-11-30T16:09:16Z,Would be good to be able to index documents into a SQL table,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/608/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/609,https://api.github.com/repos/apache/incubator-stormcrawler/issues/609,incubator-stormcrawler,362617968,609,SQLSpout group by hostname and get top N results,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-09-21T13:32:22Z,2018-10-03T11:12:37Z,"Similar to what is done in ES with aggregations. At the moment we rely on shard numbers only but this does not guarantee a good mix of URL sources.

See https://stackoverflow.com/questions/2129693/using-limit-within-group-by-to-get-n-results-per-group
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/609/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/609,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyMzk4Mjk1MQ==,incubator-stormcrawler,423982951,609,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-09-24T13:55:11Z,2018-09-24T13:55:11Z,"Uses Window functions

https://mariadb.com/kb/en/library/window-functions-overview/
http://www.mysqltutorial.org/mysql-window-functions/mysql-rank-function/

These are supported in recent versions of MariaDB or MySQL 

The sharding mechanism can still be used. A new parameter _mysql.max.urls.per.bucket_ has been introduced.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyMzk4Mjk1MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/610,https://api.github.com/repos/apache/incubator-stormcrawler/issues/610,incubator-stormcrawler,363148209,610,Batch PreparedStatements in SQL status updater bolt,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-09-24T13:32:55Z,2018-10-03T11:12:10Z,"Each document is currently updated in an individual call to SQL, which can be a bottleneck. It would be more efficient to batch the preparedstatements.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/610/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/610,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNDMxOTQ3NA==,incubator-stormcrawler,424319474,610,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-09-25T12:17:57Z,2018-09-25T12:17:57Z,@cruftex ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNDMxOTQ3NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/610,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNDQ4NTY3Mw==,incubator-stormcrawler,424485673,610,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-09-25T20:15:29Z,2018-09-25T20:15:29Z,see also https://mariadb.com/kb/en/library/option-batchmultisend-description/,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNDQ4NTY3Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/610,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNDYyMjQwNw==,incubator-stormcrawler,424622407,610,NA,cruftex,2668191,Jens Wilke,github@cruftex.net,NA,2018-09-26T07:59:19Z,2018-09-26T07:59:19Z,http://java-persistence-performance.blogspot.com/2013/05/batch-writing-and-dynamic-vs.html,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNDYyMjQwNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/610,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNDY0OTAwMw==,incubator-stormcrawler,424649003,610,NA,cruftex,2668191,Jens Wilke,github@cruftex.net,NA,2018-09-26T09:29:08Z,2018-09-26T09:29:08Z,"Hi Julien,

unfortunately there are no automated tests for the SQL persistence component. That would make working on code improvements so much easier.

In our applications we use the H2 database engine with in memory mode for the tests and PostgreSQL in production. That works pretty fine. For the tests there is no need to setup a database then, which means it can run on every CI server.

Another thing: There are some MySQL specific functions used. I am not 100% sure, but it seems everything needed is pretty basic, so it should be possible to make everything database agnostic and just use plain SQL.

So I'd recommend to get rid of MySQL specifics and have some tests first. What do you think?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNDY0OTAwMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/610,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNDY0OTUzOQ==,incubator-stormcrawler,424649539,610,NA,cruftex,2668191,Jens Wilke,github@cruftex.net,NA,2018-09-26T09:30:58Z,2018-09-26T09:30:58Z,Another thing: Some SQL databases have JSON support. It would be a good idea to change the metadata serialization format to JSON.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNDY0OTUzOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/610,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNDY1MjgxNQ==,incubator-stormcrawler,424652815,610,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-09-26T09:42:00Z,2018-09-26T09:42:00Z,"Hi Jens, thanks for your comments. I like the idea of having tests + be database neutral.
Am working on a first version of the batching, will send a PR shortly. Would be great if you could review it, we can then refine it further.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNDY1MjgxNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/611,https://api.github.com/repos/apache/incubator-stormcrawler/issues/611,incubator-stormcrawler,363948506,611,Detect changes / Update timestamp in the meta data,cruftex,2668191,Jens Wilke,github@cruftex.net,CLOSED,2018-09-26T10:01:23Z,2023-12-05T16:15:35Z,"If the crawl runs frequently to detect changes of a website, it is most likely that the content is actually not changed. This leads to a lot of redundant operations. Idea:

Detect whether there is a change in the extracted content (not the fetched content), e.g. by storing a hash in the meta data.

Only update index, if a change is detected. Index updates are quite expensive.

Store a content hash and an update timestamp in the status metadata.

Further enhancements: Store the last n timestamps of a content update and maybe adjust the fetch frequency accordingly.

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/611/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/611,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNDY1OTE2NQ==,incubator-stormcrawler,424659165,611,NA,cruftex,2668191,Jens Wilke,github@cruftex.net,NA,2018-09-26T10:03:47Z,2018-09-26T10:03:47Z,"I started to hack in this kind of functionality in the ES status updater and indexer. But that is not the 'right' place for it. Probably it needs to go into the parser, or, there needs to be another step after the parsing, which decides whether the content is send to the indexer or not.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNDY1OTE2NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/611,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNDY2MDc5MA==,incubator-stormcrawler,424660790,611,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-09-26T10:09:47Z,2018-09-26T10:09:47Z,"Have you looked at https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/persistence/AdaptiveScheduler.java
?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNDY2MDc5MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/611,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNDY2NDA1Ng==,incubator-stormcrawler,424664056,611,NA,cruftex,2668191,Jens Wilke,github@cruftex.net,NA,2018-09-26T10:21:57Z,2018-09-26T10:21:57Z,"Probably yes, it's some time ago.

The scheduler is changing the fetch interval. That is one aspect of it.

It uses `MD5SignatureParseFilter`. But the signature makes more sense on the parsed data, not the fetched data, especially if the parsing is expensive and only extracts a few bits from the page.

Also I ran into issues with updating the status after the first fetch.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNDY2NDA1Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/611,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNDY2ODg5NA==,incubator-stormcrawler,424668894,611,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-09-26T10:39:48Z,2018-09-26T10:39:48Z,Isn't that a case of having a different ParseFilter implementation e.g. _MetadataSignatureParseFilter_ which would generate the same keys in the md as MD5SignatureParseFilter but not based on the text? The logic if the AdaptiveScheduler would remain the same,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNDY2ODg5NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/611,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNjIxNTI4Mg==,incubator-stormcrawler,426215282,611,NA,cruftex,2668191,Jens Wilke,github@cruftex.net,NA,2018-10-02T09:50:18Z,2018-10-02T09:50:18Z,"Hi Julien, I think the actual feature request is not satisfied:

- Have an update timestamp, when a change in the parsed data is detected
- Only send parsed data to the index updater, if a change was detected

Reopen or should I put the different aspects to it in more distinctive issues?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNjIxNTI4Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/611,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNjIxNTczOQ==,incubator-stormcrawler,426215739,611,NA,cruftex,2668191,Jens Wilke,github@cruftex.net,NA,2018-10-02T09:51:54Z,2018-10-02T09:51:54Z,Its totally okay if you don't want to address this right now. But maybe its good to keep the issue open for somebody else to chime in.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNjIxNTczOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/611,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNjIxNjA3Ng==,incubator-stormcrawler,426216076,611,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-10-02T09:53:10Z,2018-10-02T09:53:10Z,could split it into 2 different things: the metadata based signature generation on one hand and the partial updates on the other. Let's focus on the first in this issue. ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNjIxNjA3Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/611,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNDQ2NjIzMA==,incubator-stormcrawler,704466230,611,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2020-10-06T18:28:04Z,2020-10-06T18:28:04Z,"> Have an update timestamp, when a change in the parsed data is detected

AdaptiveScheduler writes the change date detected by signature comparison to the metadata field `last-modified`. If `protocol.md.prefix` is not empty, no other component is writing into this field, so the field holds the update timestamp (or the time of the first fetch).","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNDQ2NjIzMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/611,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5tvUTo,incubator-stormcrawler,1841120488,611,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-12-05T16:15:34Z,2023-12-05T16:15:34Z,"No activity, closing down","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5tvUTo/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/612,https://api.github.com/repos/apache/incubator-stormcrawler/issues/612,incubator-stormcrawler,363965647,612,SQL MetricsConsumer,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-09-26T10:42:34Z,2018-09-26T16:30:07Z,"Just to make the SQL module more or less complete, we could add a MetricsConsumer. Grafana can query SQL DBs","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/612/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/612,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNDc4MzExMg==,incubator-stormcrawler,424783112,612,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-09-26T16:30:07Z,2018-09-26T16:30:07Z,"Haven't tried it with Grafana yet, comments welcome!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNDc4MzExMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/614,https://api.github.com/repos/apache/incubator-stormcrawler/issues/614,incubator-stormcrawler,363973949,614,SQL Spout - reuse Date,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-09-26T11:06:04Z,2018-10-04T10:27:18Z,"We currently use NOW as a value for the nextFetchDateQuery we should instead reuse the previous date used so that the search space remains as small as possible and also to give the backend a chance to cache the results. This value could be also set to the largest one retrieved by the previous results and / or reset after a while.

This is what is done in the ES module.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/614/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/615,https://api.github.com/repos/apache/incubator-stormcrawler/issues/615,incubator-stormcrawler,363994845,615,OKHTTP protocol trust all SSL certificates,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-09-26T12:04:51Z,2018-09-26T12:25:03Z,"This would prevent the issue below
```
 javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target
javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target
at sun.security.ssl.Alerts.getSSLException(Alerts.java:192)
```","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/615/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/615,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNDY5MjE2OA==,incubator-stormcrawler,424692168,615,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-09-26T12:11:24Z,2018-09-26T12:11:24Z,@sebastian-nagel feel free to port to the Nutch implementation if find it useful. I saw that a similar thing was recently added for the other protocol there,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNDY5MjE2OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/615,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNDY5NTY5Mw==,incubator-stormcrawler,424695693,615,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2018-09-26T12:25:03Z,2018-09-26T12:25:03Z,"Thanks, that was already my plan after Markus provided the patch for protocol-http.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNDY5NTY5Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/616,https://api.github.com/repos/apache/incubator-stormcrawler/issues/616,incubator-stormcrawler,364409281,616,Custom intervals in Scheduler can't contain dots ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-09-27T10:33:50Z,2018-09-27T10:36:53Z,"_fetchInterval.FETCHED.testKey.key2=someValue_

currently doesn't work as the regexp parses the status as _FETCHED.testKey_","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/616/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/617,https://api.github.com/repos/apache/incubator-stormcrawler/issues/617,incubator-stormcrawler,365106434,617,Abstract functionalities of spout implementations,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-09-29T07:23:51Z,2018-10-04T10:27:44Z,"Spouts for SOLR, ES or SQL all have in common that they get URLs from a query, which often will return results already being processed. These spouts keep track of the URLs being processed and in the case of ES, apply a delay after acking to make sure that changes have a chance of being applied to the index before removing the URL from the cache.

This behaviour should go in an abstract class to simplify the code.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/617/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/619,https://api.github.com/repos/apache/incubator-stormcrawler/issues/619,incubator-stormcrawler,365425353,619,Harmonise param names for SQL,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-10-01T11:50:14Z,2018-10-02T10:44:00Z,"Most config keys are prefixed with ""mysql."" instead we should use ""sql"" and make the code as implementation neutral as possible.
Would be good to make the configuration of the connection entirely via the conf file and not hardcoded","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/619/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/619,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNjIyMTEzNQ==,incubator-stormcrawler,426221135,619,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-10-02T10:12:29Z,2018-10-02T10:12:29Z,This is a first step towards making the SQL module 'implementation neutral' where possible.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNjIyMTEzNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/619,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNjIyODg2OQ==,incubator-stormcrawler,426228869,619,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-10-02T10:44:00Z,2018-10-02T10:44:00Z,"The configuration of the connection is now done like this

```
  sql.connection:
   url: ""jdbc:mysql://localhost:3306/crawl""
   user: ""myuser""
   password: ""mypassword""
   rewriteBatchedStatements: ""true""
   useBatchMultiSend: ""true""
```
and is implementation neutral. You can pass key / values specific to the SQL backend used.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNjIyODg2OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/620,https://api.github.com/repos/apache/incubator-stormcrawler/issues/620,incubator-stormcrawler,365642892,620,Add support for shards in SOLR,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-10-01T21:05:42Z,2024-11-10T10:00:59Z,"Just like it's done in ES, we could route the documents in the statusupdaterbolt based on the host / name or IP and in the spouts check that the number of instances is equal to the # of shards and filter the queries per shard accordingly.

At the moment, we can have only one instance of a spout.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/620/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/620,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5FQkaL,incubator-stormcrawler,1161971339,620,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-06-21T16:16:49Z,2022-06-21T16:16:49Z,https://solr.apache.org/guide/solr/latest/deployment-guide/solrcloud-shards-indexing.html#document-routing,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5FQkaL/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/620,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6CO7e9,incubator-stormcrawler,2184951741,620,NA,mvolikas,115570991,Markos Volikas,,NA,2024-06-23T11:29:11Z,2024-06-23T11:29:11Z,This one is really interesting. Will it be up to the user to correctly create the status core with the same number of shards as the `parallelism: ***` used in the crawler.flux?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6CO7e9/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/620,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6CYH84,incubator-stormcrawler,2187362104,620,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-06-24T20:37:39Z,2024-06-24T20:37:39Z,"> This one is really interesting. Will it be up to the user to correctly create the status core with the same number of shards as the `parallelism: ***` used in the crawler.flux?

yes. we should set it to a reasonable default value (10?) but then it is up to the user to manage it","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6CYH84/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/620,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6GRY39,incubator-stormcrawler,2252705277,620,NA,mvolikas,115570991,Markos Volikas,,NA,2024-07-26T12:54:14Z,2024-07-26T12:54:14Z,@jnioche can we merge branch [851](https://github.com/apache/incubator-stormcrawler/tree/851) into main at this point? This way we can update / add tests along with the new functionality.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6GRY39/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/620,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6GSf5D,incubator-stormcrawler,2252996163,620,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-07-26T15:24:51Z,2024-07-26T15:24:51Z,"Hasn't that been done in https://github.com/apache/incubator-stormcrawler/pull/1240? Is there more in that branch that hasn't been merged? If so, would you mind creating a PR from that branch? Thanks!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6GSf5D/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/620,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6HJ-iS,incubator-stormcrawler,2267539602,620,NA,mvolikas,115570991,Markos Volikas,,NA,2024-08-04T13:15:14Z,2024-08-04T13:15:14Z,"> Hasn't that been done in #1240? Is there more in that branch that hasn't been merged? If so, would you mind creating a PR from that branch? Thanks!

The changes from #1240 were merged into branch apache:851 but not into main. Should I open an additional PR from apache:851 to main? ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6HJ-iS/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/620,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6Jy2we,incubator-stormcrawler,2311810078,620,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-08-27T07:50:41Z,2024-08-27T07:50:41Z,"Hi @mvolikas - sorry about the delayed response, I have just returned from holidays 

>  Should I open an additional PR from apache:851 to main?

yes please, that would be great
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6Jy2we/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/621,https://api.github.com/repos/apache/incubator-stormcrawler/issues/621,incubator-stormcrawler,365819594,621,asynchronous queries and updates in SOLR?,jnioche,218319,Julien Nioche,julien@digitalpebble.com,OPEN,2018-10-02T09:45:25Z,2025-01-27T12:16:01Z,Maybe https://github.com/inoio/solrs would be useful?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/621/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/621,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5FQnrn,incubator-stormcrawler,1161984743,621,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-06-21T16:30:10Z,2022-06-21T16:30:10Z,"see https://solr.apache.org/guide/solr/latest/deployment-guide/solrj.html

[ConcurrentUpdateHttp2SolrClient](https://solr.apache.org/docs/9_0_0/solrj/org/apache/solr/client/solrj/impl/ConcurrentUpdateHttp2SolrClient.html) - just like ConcurrentUpdateSolrClient but using Http2SolrClient instead. This class is experimental therefore its API’s might change or be removed in minor versions of SolrJ.

Not sure whether CloudSolrClient is asynchronous

[CloudSolrClient] (https://solr.apache.org/docs/9_0_0/solrj/org/apache/solr/client/solrj/impl/CloudSolrClient.html) - geared towards communicating with SolrCloud deployments. Uses already-recorded ZooKeeper state to discover and route requests to healthy Solr nodes.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5FQnrn/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/621,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6YtKEZ,incubator-stormcrawler,2561974553,621,NA,mvolikas,115570991,Markos Volikas,,NA,2024-12-25T18:45:13Z,2024-12-25T18:45:13Z,"My understanding is the following:

- [ConcurrentUpdateHttp2SolrClient](https://solr.apache.org/docs/9_7_0/solrj/org/apache/solr/client/solrj/impl/ConcurrentUpdateHttp2SolrClient.html) is not experimental in version 9.7.0 and seems promising for the `StatusUpdater` and `Inderer` bolts where it can batch updates without changing the way we submit documents.

- Regarding querying in the spouts we could use the [requestAsync](https://solr.apache.org/docs/9_7_0/solrj/org/apache/solr/client/solrj/impl/Http2SolrClient.html#requestAsync(org.apache.solr.client.solrj.SolrRequest,java.lang.String)) of the `Http2SolrClient` with futures.

- I'm not sure about the benefits of the [CloudSolrClient](https://solr.apache.org/docs/9_7_0/solrj/org/apache/solr/client/solrj/impl/CloudSolrClient.html), to be honest. The API seems to be synchronous from the caller's perspective. Additionally, since we currently have a single node (with multiple shards for the status collection) we will not use any of the automatic routing (e.g. load balancing requests across nodes) and failover (e.g. a node goes down) features.

Any thoughts?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6YtKEZ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/621,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6blZQz,incubator-stormcrawler,2610271283,621,NA,mvolikas,115570991,Markos Volikas,,NA,2025-01-23T16:15:58Z,2025-01-23T16:15:58Z,"@jnioche and @rzo1 I am planning to implement this using [ConcurrentUpdateHttp2SolrClient](https://solr.apache.org/docs/9_7_0/solrj/org/apache/solr/client/solrj/impl/ConcurrentUpdateHttp2SolrClient.html) and [requestAsync](https://solr.apache.org/docs/9_7_0/solrj/org/apache/solr/client/solrj/impl/Http2SolrClient.html#requestAsync(org.apache.solr.client.solrj.SolrRequest,java.lang.String)). Does this sound reasonable? Do you have any comments?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6blZQz/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/621,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6b5GM-,incubator-stormcrawler,2615436094,621,NA,rzo1,13417392,Richard Zowalla,,NA,2025-01-27T10:57:24Z,2025-01-27T10:57:24Z,@mvolikas I am not a SOLR user but sounds good to me.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6b5GM-/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/621,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6b5u9p,incubator-stormcrawler,2615603049,621,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2025-01-27T12:16:00Z,2025-01-27T12:16:00Z,"Same, go for what you think is best

On Mon, 27 Jan 2025, 10:57 Richard Zowalla, ***@***.***>
wrote:

> @mvolikas <https://github.com/mvolikas> I am not a SOLR user but sounds
> good to me.
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/apache/incubator-stormcrawler/issues/621#issuecomment-2615436094>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AABVJT37LLPPNPGT23UBJU32MYGKXAVCNFSM6AAAAABUGHYTDKVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDMMJVGQZTMMBZGQ>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6b5u9p/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/622,https://api.github.com/repos/apache/incubator-stormcrawler/issues/622,incubator-stormcrawler,365820234,622,SOLR spout - reuse nextFetchDate?,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-10-02T09:47:11Z,2018-10-03T11:40:27Z,"Similar to #614 but for SOLR. Instead of filtering on docs with a nextFetchDate <= NOW, either reuse the previous date if it it returned any docs.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/622/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/622,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNjYwNTQ5NA==,incubator-stormcrawler,426605494,622,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-10-03T11:40:27Z,2018-10-03T11:40:27Z,Also fixes a bug as we were running the paging while setting a new date everytime.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNjYwNTQ5NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/623,https://api.github.com/repos/apache/incubator-stormcrawler/issues/623,incubator-stormcrawler,365845341,623,"SOLRSpout log queries, time and number of results",jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-10-02T11:00:13Z,2018-10-02T11:01:35Z,"This will help to reproduce the queries externally, spot any issues with the processing times etc...
Also a new metric _spout_query_time_msec_ will be used by all the implementations of AbstractQueryingSpout. It will replace _ES_query_time_msec_ which was used by ES so far.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/623/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/624,https://api.github.com/repos/apache/incubator-stormcrawler/issues/624,incubator-stormcrawler,365943942,624,upgrade to SOLR 7.5,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-10-02T15:07:07Z,2018-10-04T06:04:43Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/624/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/625,https://api.github.com/repos/apache/incubator-stormcrawler/issues/625,incubator-stormcrawler,366493780,625,SOLR StatusUpdater Exception writing document id ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-10-03T19:34:04Z,2018-10-05T11:20:01Z,"org.apache.solr.client.solrj.impl.HttpSolrClient$RemoteSolrException: Error from server at http://localhost:8983/solr/status: Exception writing document id https://tv.sohu.com/v/dXMvMzEyODEzNDk4LzEwNjc3ODE0OS5zaHRtbA==.html to the index; possible analysis error.
ks!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/625/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/625,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNzMzMTc2NA==,incubator-stormcrawler,427331764,625,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-10-05T11:20:01Z,2018-10-05T11:20:01Z,Can't reproduce the issue,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyNzMzMTc2NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/626,https://api.github.com/repos/apache/incubator-stormcrawler/issues/626,incubator-stormcrawler,366501686,626,SOLR Status Updater - configure byDomain or byIP,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-10-03T19:54:52Z,2024-11-10T10:01:00Z,"only by host is currently implemented 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/626/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/626,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5_9brs,incubator-stormcrawler,2146810604,626,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-06-04T07:30:23Z,2024-06-04T07:30:23Z,"@mvolikas is that of interest to you?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5_9brs/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/626,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6AiDCa,incubator-stormcrawler,2156408986,626,NA,mvolikas,115570991,Markos Volikas,,NA,2024-06-09T09:18:46Z,2024-06-09T09:18:46Z,I want to give it a try! I'm not 100% sure about the extra functionality we are aiming for though. Is this related to #620? I guess we could start by adding the partition key in the metadata like we do in OpenSearch?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6AiDCa/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/626,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6Ai1-g,incubator-stormcrawler,2156617632,626,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-06-09T13:58:15Z,2024-06-09T13:58:15Z,"It is exactly that. What this is about it to have the field name to use for the key (and whether it should be in the metadata) configurable, just like in [OpenSearch](https://github.com/apache/incubator-stormcrawler/blob/main/external/opensearch/src/main/java/org/apache/stormcrawler/opensearch/persistence/StatusUpdaterBolt.java#L154) and also add the logic of host/domain/IP .  The logic of how to query based on the shards will be added to the spouts later on in #620 ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6Ai1-g/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/627,https://api.github.com/repos/apache/incubator-stormcrawler/issues/627,incubator-stormcrawler,366631396,627,SOLR StatusUpdater use short status name,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-10-04T05:48:42Z,2018-10-04T05:51:32Z,"We currently index com.digitalpebble.stormcrawler.persistence.Status:DISCOVERED which is unecessarily long and harder to use in queries
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/627/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/628,https://api.github.com/repos/apache/incubator-stormcrawler/issues/628,incubator-stormcrawler,366685787,628,Move reset.fetchdate.after to AbstractQueryingSpout,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-10-04T08:54:12Z,2018-10-04T10:27:18Z,"This was only in ES so far and the other backend can benefit from it especially SOLR which reuses the nextFetchDate #622 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/628/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/629,https://api.github.com/repos/apache/incubator-stormcrawler/issues/629,incubator-stormcrawler,366819120,629,Per-Request HttpProtocol Configuration,ndtreviv,1530653,Nathan Trevivian,,CLOSED,2018-10-04T14:30:59Z,2018-10-11T12:49:58Z,"We've noticed that when trying to fetch images from some specific image hosting sites, they always respond with a 302 (Redirection) unless the `Accept` header is either empty or specifically the mime-type of the image.

I know that the `Accept` header used by HttpProtocol is configurable, but it's a one-time configuration used on all requests.

There are a couple of ways to potentially spin this:

1. Make `getProtocolOutput` apply a set of config values based on a set of rules or similar. 
2. Enable HttpProtocol to be extended so that we can tailor to our hearts delight (at the moment `CONNECTION_MANAGER`, `builder` and `requestConfig` are all `private`)

Is there another way to achieve this?

(PS: I can't apply any labels to this, but it's a Feature Request, unless the problem can be resolved another way)","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/629/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/630,https://api.github.com/repos/apache/incubator-stormcrawler/issues/630,incubator-stormcrawler,367161674,630,Improve MimeType detection for interpreted server-side languages,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-10-05T11:00:23Z,2018-10-05T11:02:27Z,"e.g. http://www.oeeee.com/api/channel.php?s=/index/index/channel/bhouse
has a HTTP header of _text/HTML_ but the detection in Tika returns _text/x-php_ based on the content.
Tika 1.19 contains https://github.com/apache/tika/pull/236 which should fix such issues but we need to give it the full URL as a clue and not just the filename.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/630/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/631,https://api.github.com/repos/apache/incubator-stormcrawler/issues/631,incubator-stormcrawler,368163598,631,AbstractHttpProtocol uses StringTabScheme to parse input into URL and Metadata,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-10-09T11:27:18Z,2018-10-09T11:28:52Z,"The  main method is used to test the output of protocol implementations. It currently treats each input as being the URL, instead we should rely on StringTabScheme to parse input into URL and Metadata instead of passing an empty Metadata object.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/631/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/632,https://api.github.com/repos/apache/incubator-stormcrawler/issues/632,incubator-stormcrawler,368166012,632,Support for cookies in okhttp implementation ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-10-09T11:34:29Z,2018-10-09T11:35:40Z,"To be in line with what the httpclient protocol does w.r.t cookies i.e if the config contains ` http.use.cookies: true` and the metadata contains one or more entries for the key `set-cookie`, then we check that the cookie applies and add it to the request header.
This usually means adding 
```  
metadata.transfer:
   - set-cookie
```
to the conf.

I might refine the mechanism for both implementations later on.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/632/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/633,https://api.github.com/repos/apache/incubator-stormcrawler/issues/633,incubator-stormcrawler,368857230,633,Elasticsearch java.net.UknownHostException: http,tony-boxed,15108709,,,CLOSED,2018-10-10T21:13:08Z,2018-10-11T16:20:19Z,"I'm using everything out of the box - the latest Stormcrawler with the latest elasticsearch stuff on github and the latest Elasticsearch (though I'm currently trying an older version of ES but getting the same issue).

Every time, when running:

`storm jar target/synopdoc-1.0.jar  org.apache.storm.flux.Flux --local es-crawler.flux --sleep 86400000`

I fail on this:

`29161 [Thread-20-__metricscom.digitalpebble.stormcrawler.elasticsearch.metrics.MetricsConsumer-executor[2 2]] ERROR c.d.s.e.m.MetricsConsumer - Can't connect to ElasticSearch
java.lang.RuntimeException: java.net.UnknownHostException: http`

I have no idea how to fix this and there's essentially no information on google. Like I said, everything is out of the box; I have not made any changes to any settings files or whatever.

The ES_IndexInit.sh script executes successfully and creates the two indices so clearly 9200 is connectable and up.

Any help at all is greatly appreciated.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/633/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/633,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyODg4ODQwNQ==,incubator-stormcrawler,428888405,633,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-10-11T09:34:33Z,2018-10-11T09:34:33Z,"Hi @tony-boxed,
 I can't reproduce the issue. I have build SC from the master branch with mvn clean install then generated a new project with 
`mvn archetype:generate -DarchetypeGroupId=com.digitalpebble.stormcrawler -DarchetypeArtifactId=storm-crawler-archetype -DarchetypeVersion=1.11-SNAPSHOT`
I then copied the es-crawler.flux and es-conf.yaml from the ES module 
`cp /data/storm-crawler/external/elasticsearch/es-*.* .`
Added 
```
		<dependency>
			<groupId>com.digitalpebble.stormcrawler</groupId>
			<artifactId>storm-crawler-elasticsearch</artifactId>
			<version>1.11-SNAPSHOT</version>
		</dependency>
``` 
to the pom then 
`mvn clean package`
Finally
 `storm jar target/test-1.0-SNAPSHOT.jar  org.apache.storm.flux.Flux --local es-crawler.flux --sleep 86400000`
It does not fetch anything as I haven't injected any URLs but it doesn't produce the error above.

Maybe check the content of the es-conf file, in particular   
`es.status.addresses: ""http://localhost:9200""`

You can find tutorials on[Youtube]( https://www.youtube.com/channel/UCUuzkdeQV-XEPUq53bH_b5A?view_as=subscriber)


","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyODg4ODQwNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/633,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyODk5ODg0NA==,incubator-stormcrawler,428998844,633,NA,tony-boxed,15108709,,,NA,2018-10-11T15:26:15Z,2018-10-11T15:26:15Z,"When I attempt to execute your archetype command I get this:

`The desired archetype does not exist (com.digitalpebble.stormcrawler:storm-crawler-archetype:1.11-SNAPSHOT)`","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyODk5ODg0NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/633,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyOTAwMjgwNw==,incubator-stormcrawler,429002807,633,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-10-11T15:36:33Z,2018-10-11T15:36:33Z,"Did you clone the SC repo and build with 'mvn clean install'? You can use the archetype from 1.10, won't make much difference as long as you point to the 1.11-SNAPSHOT dependency for the ES module in the pom of the project.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyOTAwMjgwNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/633,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyOTAxNzQyMQ==,incubator-stormcrawler,429017421,633,NA,tony-boxed,15108709,,,NA,2018-10-11T16:12:11Z,2018-10-11T16:12:11Z,"OK I used 1.10 and it appears to be fixed after following your steps. Thank you very much, I will now attempt to inject urls and perform a real crawl.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyOTAxNzQyMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/633,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyOTAyMDQ4OQ==,incubator-stormcrawler,429020489,633,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-10-11T16:20:19Z,2018-10-11T16:20:19Z,"Glad it's sorted. Closing for now, you can use StackOverflow if you have any questions. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQyOTAyMDQ4OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/635,https://api.github.com/repos/apache/incubator-stormcrawler/issues/635,incubator-stormcrawler,369769614,635,CollapsingSpout replace paging with Search After,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-10-13T05:33:35Z,2018-10-18T09:55:58Z,"https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-search-after.html


","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/635/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/635,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzMDk0ODg0Mw==,incubator-stormcrawler,430948843,635,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-10-18T09:55:37Z,2018-10-18T09:55:37Z,"collapse cannot be used in conjunction with scroll, rescore or search after.

:-(","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzMDk0ODg0Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/636,https://api.github.com/repos/apache/incubator-stormcrawler/issues/636,incubator-stormcrawler,371068063,636,FetcherBolts original metadata overwrites metadata returned by protocol,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-10-17T13:14:08Z,2018-10-17T13:24:47Z,"This has an impact e.g. for cookies as any new value returned by the server is ignored if the original metadata already had a value.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/636/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/636,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzMDYyNjcyNQ==,incubator-stormcrawler,430626725,636,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-10-17T13:24:46Z,2018-10-17T13:24:46Z,We now copy the K/V from the original metadata into a new MD instance then copy the K/V from the protocol output. ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzMDYyNjcyNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/637,https://api.github.com/repos/apache/incubator-stormcrawler/issues/637,incubator-stormcrawler,372037469,637,Where does Stormcrawler store the actual parsed contents of each HTML page fetched?,tony-boxed,15108709,,,CLOSED,2018-10-19T16:55:05Z,2018-10-21T01:25:39Z,"I have a feeling I'm misunderstanding something. I assumed Stormcrawler worked similar to Nutch and that it would store the parsed contents of each fetched page directly in elasticsearch as it crawls. However, all I see is the status index which contains a few tidbits about each page but not the actual page contents. It says FETCHED.

Are the pages actually fetched and stored somewhere else? Or is a separate command/crawl required to follow through with the fetching of every crawled page?

Thanks.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/637/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/637,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzMTQ1MDg0Mw==,incubator-stormcrawler,431450843,637,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-10-19T18:11:09Z,2018-10-19T18:11:09Z,"Hi

I have a feeling I'm misunderstanding something. I assumed Stormcrawler
> worked similar to Nutch and that it would store the parsed contents of each
> fetched page directly in elasticsearch as it crawls.
>
It does. That's whar the 'index' index is for, see
https://github.com/DigitalPebble/storm-crawler/blob/master/external/elasticsearch/ES_IndexInit.sh#L113

> However, all I see is the status index which contains a few tidbits about
> each page but not the actual page contents. It says FETCHED.
>
The status index is the equivalent of the crawldb in Nutch

> Are the pages actually fetched and stored somewhere else? Or is a separate
> command/crawl required to follow through with the fetching of every crawled
> page?
>

I pointed you to the videos tutorials before did you have a look at them? =>
https://www.youtube.com/channel/UCUuzkdeQV-XEPUq53bH_b5A?view_as=subscriber

> Thanks.
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/DigitalPebble/storm-crawler/issues/637>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AANUz0-o-nEw7_iuJkzoqD6MbMAetUwMks5umgP4gaJpZM4XxA1f>
> .
>


-- 



* Open Source Solutions for Text Engineering   http://www.digitalpebble.com
<http://www.digitalpebble.com>*
*http://digitalpebble.blogspot.com <http://digitalpebble.blogspot.com/>*
@digitalpebble <https://twitter.com/digitalpebble>
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzMTQ1MDg0Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/637,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzMTQ5Nzg3NQ==,incubator-stormcrawler,431497875,637,NA,tony-boxed,15108709,,,NA,2018-10-19T21:02:01Z,2018-10-19T21:02:01Z,"Yes, I watched your entire tutorial. It was very good and well-explained. But I watched it in pieces of the course of a week or so so I may have skipped over something crucial by accident.

I see the following in my index index:

> {
""took"": 14,
""timed_out"": false,
""_shards"": {
""total"": 5,
""successful"": 5,
""skipped"": 0,
""failed"": 0
},
""hits"": {
""total"": 9247,
""max_score"": 1,
""hits"": [
{
""_index"": ""index"",
""_type"": ""doc"",
""_id"": ""0df4cbdae566397d299fd7716a9aa6992410b763536c20a8973b5920f8192815"",
""_score"": 1
},

Where can I find the actual parsed contents that each _id is linked to?

I appreciate your quick and thorough responses greatly.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzMTQ5Nzg3NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/637,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzMTU1NDY4Ng==,incubator-stormcrawler,431554686,637,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-10-20T06:42:39Z,2018-10-20T06:42:39Z,See ES_IndexInit. You need to modify the schema if necessary so that the content is stored or the _source field enabled. The settings by default try to optimize space.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzMTU1NDY4Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/637,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzMTYzMDc4Nw==,incubator-stormcrawler,431630787,637,NA,tony-boxed,15108709,,,NA,2018-10-21T01:25:39Z,2018-10-21T01:25:39Z,"Ah ok, understood. I will give this a try. Thank you.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzMTYzMDc4Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/638,https://api.github.com/repos/apache/incubator-stormcrawler/issues/638,incubator-stormcrawler,372621866,638,ParserFilter to exclude script and style tags from text extracted by StormCrawler.,anveshv18,35245968,Anvesh,,CLOSED,2018-10-22T17:40:19Z,2019-01-02T11:00:58Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/638/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/638,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ0ODY4MzA3MA==,incubator-stormcrawler,448683070,638,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-12-19T17:42:58Z,2018-12-19T17:42:58Z,Similar to #146 ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ0ODY4MzA3MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/639,https://api.github.com/repos/apache/incubator-stormcrawler/issues/639,incubator-stormcrawler,372673812,639,Does Stormcrawler follow secondary JavaScript page content loads?,tony-boxed,15108709,,,CLOSED,2018-10-22T19:56:22Z,2018-10-22T20:21:57Z,"From looking at my scraped results for webmd.com, it seems it may not and I guess it's way too much to expect that it would since that would be very complicated. But I figured I'd ask anyway to double check.

So, if I have a page that uses JavaScript to load its body after the initial page load, does Stormcrawler have any method by which it will wait for this secondary content to load and then scrape the page?

I imagine no crawler does this except very very high level and complicated crawlers like what Google or  Bing might use - or maybe even they don't since it would require browser-level intelligence and complexity. The thought of how you'd even implement a behavior of this stature is anxiety-producing.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/639/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/639,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzMTk2Nzc4OQ==,incubator-stormcrawler,431967789,639,NA,kkrugler,66217,Ken Krugler,ken@transpac.com,NA,2018-10-22T20:17:05Z,2018-10-22T20:17:05Z,"Hi @tony-boxed - as @jnioche noted on your previous issue, **please** ask questions on [Stack Overflow](https://stackoverflow.com/questions/tagged/stormcrawler), versus opening up issues on GitHub, thanks.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzMTk2Nzc4OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/639,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzMTk2OTcyMA==,incubator-stormcrawler,431969720,639,NA,tony-boxed,15108709,,,NA,2018-10-22T20:21:57Z,2018-10-22T20:21:57Z,Whoops - thanks!,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzMTk2OTcyMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/640,https://api.github.com/repos/apache/incubator-stormcrawler/issues/640,incubator-stormcrawler,372946783,640,Update Jackson and Wiremock dependencies,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-10-23T11:19:11Z,2018-11-22T10:16:05Z,"Got a notification of a security issue with the version of jackson-databind that we were using. Even though this does not affect SC as the json files are used locally only, it is still good to update the deps.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/640/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/641,https://api.github.com/repos/apache/incubator-stormcrawler/issues/641,incubator-stormcrawler,373497526,641,Post JSON data with OKHTTP protocol via metadata,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-10-24T13:58:04Z,2018-10-24T14:06:35Z,"Useful for dealing with JSON endpoints without Selenium. if the metadata for a URL contains a particular key e.g. _http.post.json_, we will POST the value associated with this key to the URL.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/641/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/642,https://api.github.com/repos/apache/incubator-stormcrawler/issues/642,incubator-stormcrawler,374403933,642,Selenium RemoteDriverProtocol triggered by K/V in metadata,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-10-26T14:15:55Z,2018-10-26T14:16:50Z,"Alternative implementation of RemoteDriverProtocol which delegates the calls  to a different implementation if the URL does not have a value for the  protocol.use.selenium in its metadata. Allows to use Selenium for some of the URLs only.

Needs _selenium.delegated.protocol_ to have a protocol class for value e.g. ""com.digitalpebble.stormcrawler.protocol.httpclient.HttpProtocol""","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/642/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/643,https://api.github.com/repos/apache/incubator-stormcrawler/issues/643,incubator-stormcrawler,374406093,643,SeleniumProtocol NavigationFilters not reached in case of a redirection,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-10-26T14:21:01Z,2018-10-26T14:21:25Z,"Instead we should apply the filters and treat the doc as a redirection if none of them has been triggered.  
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/643/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/644,https://api.github.com/repos/apache/incubator-stormcrawler/issues/644,incubator-stormcrawler,376552223,644,[bug] : StackOverFlow Exception when http.content.limit is high,jcruzmartini,6817516,Juan Cruz Martini,,CLOSED,2018-11-01T20:13:36Z,2018-11-17T09:50:02Z,"When crawling using high values in **http.content.limit** configuration property, we are getting this exception:

`java.lang.StackOverflowError at org.jsoup.helper.StringUtil.stringBuilder(StringUtil.java:235) at org.jsoup.helper.StringUtil.normaliseWhitespace(StringUtil.java:143) at org.jsoup.nodes.TextNode.normaliseWhitespace(TextNode.java:135) at org.jsoup.nodes.TextNode.text(TextNode.java:46) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:142) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(JSoupDOMBuilder.java:136) at com.digitalpebble.stormcrawler.parse.JSoupDOMBuilder.createDOM(`

We tried `http.content.limit` in -1 and 10MB and we are getting same issue, also if we set in 65k (default value) exception disappear.

Issue is reproducible using these urls 
 - dbctan.blogspot.com/2006/12  
 - polloxniner.blogspot.com




","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/644/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/644,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzNTM0MTY0OA==,incubator-stormcrawler,435341648,644,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-11-02T10:52:44Z,2018-11-02T10:52:44Z,"thanks @jcruzmartini, this is not a bug as such, it's just that when fetching the whole documents (209 and 350Kb) the conversion from the JSoup document to DocumentFragments involves a lot of recursion and crashes the stack limit. 
I managed to parse the 2 urls you gave by setting _-Xss10M_ as VM arguments.

One alternative would be to avoid the conversion to DocumentFragment altogether and simply send a Document object, both extend _org.w3c.dom.Document_ so I could change the method signature in ParseFilter to use that instead.

Not sure what the advantages of using a DocumentFragment are but if the conversion is costly then maybe there isn't much point in doing it.

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzNTM0MTY0OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/644,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzNTM4MTc2MQ==,incubator-stormcrawler,435381761,644,NA,jcruzmartini,6817516,Juan Cruz Martini,,NA,2018-11-02T13:34:34Z,2018-11-02T13:34:34Z,"@jnioche many thanks for the support, this information is really useful , I will try to set a higher Xss value in my VM , will let you know how it goes. Probably 10M is too much, having in mind that we have too many threads running at same time... ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzNTM4MTc2MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/644,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzODYxNzA5MA==,incubator-stormcrawler,438617090,644,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-11-14T10:38:28Z,2018-11-14T10:38:28Z,"@jcruzmartini I've opened a PR which should fix this, see #653 
Would you mind giving it a try? ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzODYxNzA5MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/645,https://api.github.com/repos/apache/incubator-stormcrawler/issues/645,incubator-stormcrawler,377427407,645,Limit crawl to URLs found in sitemaps,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-11-05T14:36:39Z,2018-11-07T10:56:16Z,"We can already use the metadata filter to remove outlinks found in pages with metadata isSitemap=false. These are the URLs listed in the sitemaps. isSitemap=true indicates that a page is a sitemap file.
The problem we have until now is that if the sitemaps are found through discovery, whichever seed URL has been used to discover the sitemaps will have its oulinks added and their outlinks will be added too if they are not listed in the sitemaps etc...
What we could do would be to add _isSitemap=false_ if sitemaps have been found though discovery for a particular URL. This way that URL could be processed furhter but not its outlinks.

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/645/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/646,https://api.github.com/repos/apache/incubator-stormcrawler/issues/646,incubator-stormcrawler,378713381,646,ES aggregationspout use non scoring queries?,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-11-08T12:38:08Z,2018-11-21T11:34:27Z,"https://www.elastic.co/guide/en/elasticsearch/guide/2.x/_filtering_queries.html
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/646/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/646,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ0MDYzMjUxMw==,incubator-stormcrawler,440632513,646,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-11-21T11:34:27Z,2018-11-21T11:34:27Z,Surprisingly these make the requests slower. Closing for now,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ0MDYzMjUxMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/647,https://api.github.com/repos/apache/incubator-stormcrawler/issues/647,incubator-stormcrawler,379130684,647,ES IndexerBolt : check success of batches before acking tuples,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-11-09T11:45:09Z,2019-03-18T10:35:45Z,"
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/647/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/648,https://api.github.com/repos/apache/incubator-stormcrawler/issues/648,incubator-stormcrawler,379159853,648,spout.reset.fetchdate.after based on time when query was set to NOW,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-11-09T13:22:28Z,2018-11-09T17:09:33Z,"and not the actual date used for the query. This way we will be able to use it at the same time as _es.status.recentDate_
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/648/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/649,https://api.github.com/repos/apache/incubator-stormcrawler/issues/649,incubator-stormcrawler,379246638,649,Rename index index into docs?,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-11-09T17:09:21Z,2018-11-13T13:35:15Z,"Index is a rubbish name for an index. We have status and metrics. What about docs?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/649/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/649,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzNzQzNTE4Mg==,incubator-stormcrawler,437435182,649,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2018-11-09T17:33:35Z,2018-11-09T17:33:35Z,"Or ""content""?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzNzQzNTE4Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/650,https://api.github.com/repos/apache/incubator-stormcrawler/issues/650,incubator-stormcrawler,380185169,650,ES investigate aggregations with terms partitioning,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-11-13T11:39:49Z,2018-11-19T22:08:48Z,"https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-terms-aggregation.html#_filtering_values_with_partitions

Suggested by @markharwood in https://discuss.elastic.co/t/performance-aggregations-vs-collapsing/156295/5","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/650/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/650,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzODcxNzI5MQ==,incubator-stormcrawler,438717291,650,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-11-14T16:06:30Z,2018-11-14T16:06:30Z,"Could try that instead of sharding per host, each spout would be in charge of a separate partition.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQzODcxNzI5MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/650,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ0MDA1OTQ3Nw==,incubator-stormcrawler,440059477,650,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-11-19T22:08:48Z,2018-11-19T22:08:48Z,Tried with the  spout instance number and the total number of instances and the perfs are atrocious. ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ0MDA1OTQ3Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/651,https://api.github.com/repos/apache/incubator-stormcrawler/issues/651,incubator-stormcrawler,380227933,651,ES StatusMetricsBolt generate metrics for total number of docs,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-11-13T13:33:45Z,2018-11-13T17:17:50Z,"
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/651/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/654,https://api.github.com/repos/apache/incubator-stormcrawler/issues/654,incubator-stormcrawler,381153932,654,"Scheduling -> round to the closest second, minute or hour",jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-11-15T13:09:53Z,2018-11-17T14:36:11Z,"Having millisecond precision on the nextFetchDate is not very useful. Being able to round down to the closest second, minute or hour would reduce the sparsity of the data and could speed up the search.

See discussion on https://discuss.elastic.co/t/performance-aggregations-vs-collapsing/156295/30


","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/654/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/657,https://api.github.com/repos/apache/incubator-stormcrawler/issues/657,incubator-stormcrawler,381603927,657,Staggered scheduling of sitemap URLs  ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-11-16T13:40:33Z,2018-11-17T14:34:22Z,"Sitemaps can slow down the status updates significantly as they contain loads of URLs which need adding to the storage. When a main sitemap index points to many sitemap URLs, these get fetched around the same time and all the URLs they contain get also added at about the same time. 

Instead, a sitemap index file could schedule the fetching of the sitemaps it contains over a period of time. The processing of these files would be mixed with 'normal' urls, for which we might not necessarily follow outlinks, thus putting less strain on the status updater.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/657/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/658,https://api.github.com/repos/apache/incubator-stormcrawler/issues/658,incubator-stormcrawler,381692288,658,MemorySpout blocked on URL to be fetch in distant future,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-11-16T17:27:14Z,2018-11-20T12:53:56Z,"Despite what the Javadoc says, we check the URL first then the nextFetchDate. This can lead to a situation where the next URL to be returned is actually one don't need to do for a while.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/658/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/658,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ0MDI2MzIyNg==,incubator-stormcrawler,440263226,658,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-11-20T12:53:56Z,2018-11-20T12:53:56Z,can't reproduce,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ0MDI2MzIyNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/660,https://api.github.com/repos/apache/incubator-stormcrawler/issues/660,incubator-stormcrawler,381848455,660,redirected sitemaps don't have isSitemap=true,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-11-17T10:02:32Z,2018-11-17T10:06:02Z,"if a document is detected as being a sitemap and can be parsed correctly by the sitemap parser then we should set  isSitemap=true
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/660/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/661,https://api.github.com/repos/apache/incubator-stormcrawler/issues/661,incubator-stormcrawler,382413366,661,Elasticsearch 6.5.0,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-11-19T22:09:45Z,2018-11-22T10:14:38Z,"
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/661/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/662,https://api.github.com/repos/apache/incubator-stormcrawler/issues/662,incubator-stormcrawler,382415979,662,FetcherBolt -> don't add discovered sitemaps if the robots rules does not allow them,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-11-19T22:17:41Z,2018-11-20T13:04:35Z,"
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/662/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/663,https://api.github.com/repos/apache/incubator-stormcrawler/issues/663,incubator-stormcrawler,382662758,663,JSOUP update to 1.11.3,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-11-20T13:27:20Z,2018-11-20T13:28:07Z,"
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/663/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/664,https://api.github.com/repos/apache/incubator-stormcrawler/issues/664,incubator-stormcrawler,385693963,664,FileSpout to use StringTabScheme by default,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-11-29T11:37:33Z,2018-11-30T12:12:15Z,"in most cases, we end up using StringTabScheme so having it by default would make things simpler, yet it is also useful to be able to specify a different implementation","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/664/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/665,https://api.github.com/repos/apache/incubator-stormcrawler/issues/665,incubator-stormcrawler,385759146,665,SQL NPE when using SQLSpout,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-11-29T14:22:02Z,2018-11-30T08:39:59Z,"```
java.lang.NullPointerException at com.digitalpebble.stormcrawler.sql.SQLSpout.populateBuffer(SQLSpout.java:114)
```
due to #648 and _lastTimeResetToNOW_ not being set.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/665/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/666,https://api.github.com/repos/apache/incubator-stormcrawler/issues/666,incubator-stormcrawler,386088157,666,DOM generated by JSOUP parser doesn't match XPATH expressions,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-11-30T08:37:55Z,2018-11-30T09:20:58Z,"This is a bug caused by the changes introduced in #653 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/666/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/666,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ0MzEzNTUxMA==,incubator-stormcrawler,443135510,666,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-11-30T08:55:46Z,2018-11-30T08:55:46Z,"Namespaces, as usual :-( 

The main difference with the previous class is in https://github.com/DigitalPebble/storm-crawler/blob/1.11/core/src/main/java/com/digitalpebble/stormcrawler/parse/JSoupDOMBuilder.java#L110

Will fix and test now","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ0MzEzNTUxMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/667,https://api.github.com/repos/apache/incubator-stormcrawler/issues/667,incubator-stormcrawler,386090156,667,Upgrade ElasticSearch to 6.5.2,rzo1,13417392,Richard Zowalla,,CLOSED,2018-11-30T08:44:19Z,2018-12-14T09:23:04Z,"Upgrade StormCrawler ES version to 6.5.1

Latest ES release 6.5.1 contains several bug fixes targerting ES 6.5.0 related to ""aggregation"", see https://www.elastic.co/guide/en/elasticsearch/reference/current/release-notes-6.5.1.html","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/667/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/667,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ0MzEzMzI0NA==,incubator-stormcrawler,443133244,667,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-11-30T08:46:31Z,2018-11-30T08:46:31Z,Do these bugs affect the server side only or the client code that we are using? ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ0MzEzMzI0NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/667,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ0MzEzMzk2NA==,incubator-stormcrawler,443133964,667,NA,rzo1,13417392,Richard Zowalla,,NA,2018-11-30T08:49:24Z,2018-11-30T08:49:24Z,"As far as I can see from the linked PR / Issue Trackerr, the aggregation bugs affect the server side only. So this upgrade is not of very high priority. 

I just stumpled across the new version (while preparing a talk) and thought it would be worth to open an issue in order to not forget this in the next release :)","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ0MzEzMzk2NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/668,https://api.github.com/repos/apache/incubator-stormcrawler/issues/668,incubator-stormcrawler,386141420,668,Archetype sets StormCrawler version in a property,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-11-30T11:05:05Z,2018-11-30T11:13:29Z,saves having to repeat the version for all the modules in a project + simplify the documentation,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/668/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/669,https://api.github.com/repos/apache/incubator-stormcrawler/issues/669,incubator-stormcrawler,386290101,669,Implement horizontal depth limit (qty of outlinks discovered by page),jcruzmartini,6817516,Juan Cruz Martini,,CLOSED,2018-11-30T17:57:02Z,2019-01-03T18:17:07Z,"We have been having troubles crawling huge sites, so in order to limit the qty of pages that we are gonna be crawling in each site, would be awesome if we can implement an horizontal depth limit, that means that crawler wont discovery more than N outlinks per page. Where N is configurable 

_I am working on this now, will create a PR in the afternoon with some unit tests to cover this scenario if you do not have objections._

Thanks
Juan
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/669/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/669,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ0NDAwODA0NQ==,incubator-stormcrawler,444008045,669,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2018-12-04T08:07:52Z,2018-12-04T08:07:52Z,#670 ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ0NDAwODA0NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/671,https://api.github.com/repos/apache/incubator-stormcrawler/issues/671,incubator-stormcrawler,387913131,671,Indexer bolts to use value from metadata as docID,jnioche,218319,Julien Nioche,julien@digitalpebble.com,OPEN,2018-12-05T19:37:52Z,2018-12-05T19:37:52Z,"The default value would still be the URL or canonical tag but if a value is found for a predefined key, its value would be used. This would help with deduplication as a ParseFIlter could generate a hash from the content and use it for _id. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/671/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/673,https://api.github.com/repos/apache/incubator-stormcrawler/issues/673,incubator-stormcrawler,391032380,673,Date format used for HTTP if-modified-since requests must follow RFC 7231,sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2018-12-14T09:32:01Z,2018-12-14T12:22:06Z,"The value of the `If-Modified-Since` header must follow the date format defined in [RFC 7231](https://tools.ietf.org/html/rfc7231#section-7.1.1.1) (e.g., ""Thu, 22 Dec 2017 07:51:19 UTC"", see also [RFC 2616](https://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html#sec3.3.1)). Other formats are likely to be not supported by HTTP server. I've checked my local Apache:
- using the correct date format the server responds with 304 not modified:
```
% wget --header='If-Modified-Since: Thu, 22 Dec 2017 07:51:19 UTC' -v -d -O/dev/null http://localhost/
...
---request begin---
GET / HTTP/1.1
User-Agent: Wget/1.19.4 (linux-gnu)
Accept: */*
Accept-Encoding: identity
Host: localhost
Connection: Keep-Alive
If-Modified-Since: Thu, 22 Dec 2017 07:51:19 UTC

---request end---
HTTP request sent, awaiting response... 
---response begin---
HTTP/1.1 304 Not Modified
Date: Fri, 14 Dec 2018 09:13:12 GMT
Server: Apache/2.4.29 (Ubuntu)
Connection: Keep-Alive
Keep-Alive: timeout=5, max=100
ETag: ""2aa6-55af5dcdd19ea""

---response end---
304 Not Modified
```
- while the date format used in StormCrawler 
```
% wget --header='If-Modified-Since: 2017-12-22T07:51:19.000Z' -v -d -O/dev/null http://localhost/
...
---request begin---
GET / HTTP/1.1
User-Agent: Wget/1.19.4 (linux-gnu)
Accept: */*
Accept-Encoding: identity
Host: localhost
Connection: Keep-Alive
If-Modified-Since: 2017-12-22T07:51:19.000Z

---request end---
HTTP request sent, awaiting response... 
---response begin---
HTTP/1.1 200 OK
Date: Fri, 14 Dec 2018 09:14:03 GMT
Server: Apache/2.4.29 (Ubuntu)
Last-Modified: Sat, 07 Oct 2017 14:35:02 GMT
ETag: ""2aa6-55af5dcdd19ea""
Accept-Ranges: bytes
Content-Length: 10918
Vary: Accept-Encoding
Keep-Alive: timeout=5, max=100
Connection: Keep-Alive
Content-Type: text/html

---response end---
200 OK
```

#496 changed the date format of the last-modified time string persisted in metadata to be compliant with the date formats supported by Elasticsearch. It's good to have a single standard format used for all dates. But the protocols should reformat dates. I'll open a PR to fix this.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/673/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/673,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ0NzI3NDExMA==,incubator-stormcrawler,447274110,673,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2018-12-14T09:54:11Z,2018-12-14T09:54:11Z,"Some additional evidence to estimate whether web servers support other date formats:
- the Common Crawl news crawler uses the AdaptiveFetchSchedule to adjust the re-fetch schedule to the actual change frequency of news feeds and sitemaps
- the last-modified time is tracked to avoid the unnecessary fetch and processing of news feeds and sitemaps
- here the frequency of HTTP status codes of news feeds and sitemaps from Oct 2017 (before #496 has been deployed. 
```
58124   59.625%  200
20535   21.065%  304
 8747    8.973%  301
 3323    3.409%  302
 2309    2.369%  404
```
20% of the feeds and sitemaps have the status ""304 not modified"".
- the frequencies from Dec 2018 (#496 deployed since Dec 2017):
```
391697   72.687%  200
 87196   16.181%  301
 23564    4.373%  404
 17053    3.165%  304
 11682    2.168%  302
```
Only 17,000 or 3% now have status ""304"". A closer look showed that 7000 of them still have a RFC-conform date because they haven't been modified since 2017.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ0NzI3NDExMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/675,https://api.github.com/repos/apache/incubator-stormcrawler/issues/675,incubator-stormcrawler,392690177,675,ES DeletionBolt expects Metadata from tuples,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-12-19T16:51:47Z,2018-12-19T16:55:37Z,"Bug introduced in 1d4fc415efc2648c2425ba8af43b48192b15b86c

The [AbstractStatusUpdaterBolt](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/persistence/AbstractStatusUpdaterBolt.java#L249) sends only the URL.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/675/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/676,https://api.github.com/repos/apache/incubator-stormcrawler/issues/676,incubator-stormcrawler,394598757,676,Upgrade to Tika 1.20,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2018-12-28T10:03:33Z,2019-01-02T10:58:30Z,"https://dist.apache.org/repos/dist/release/tika/CHANGES-1.20.txt
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/676/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/677,https://api.github.com/repos/apache/incubator-stormcrawler/issues/677,incubator-stormcrawler,395176345,677,Core Spouts  should use status stream if withDiscoveredStatus is set to true,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-01-02T08:24:24Z,2019-01-06T07:33:54Z,"The FileSpout can be used for injecting new seeds, in which case it is connected to the status updater bolt directly. All the other components which connect to a status updater bolt (i.e. extensions of StatusEmitterBolt) do use the _status_ stream to do so.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/677/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/677,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ1MTIyODY0MA==,incubator-stormcrawler,451228640,677,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-01-03T18:11:22Z,2019-01-03T18:11:22Z,Note: this is a breaking change - topology class and Flux files will need to be updated.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ1MTIyODY0MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/682,https://api.github.com/repos/apache/incubator-stormcrawler/issues/682,incubator-stormcrawler,410262190,682,Upgrade ES to 6.6.0,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-02-14T11:48:42Z,2019-02-14T11:50:14Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/682/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/683,https://api.github.com/repos/apache/incubator-stormcrawler/issues/683,incubator-stormcrawler,410982295,683,Asynchronous spouts (i.e ES) can send queries after max delay since previous one ended ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-02-15T23:03:18Z,2019-03-01T09:36:54Z,"At the moment both synchronous and asynchronous spout implementations wait for the buffer to be empty before emitting a query. Since queries on a large index can take some time, this usually means that the spout waits idly and that the number of tuples in flight progressively goes down.

We already have a minimal delay for emitting a query after one has been sent so as to not swamp the backend when queries are fast. We could have a max delay since the previous request has been received and processed and if elapsed, force the query to be re-emitted even if the buffer is not empty.  
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/683/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/683,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ2NDYzODI2OQ==,incubator-stormcrawler,464638269,683,NA,mstrewe,15155589,Maik Piel,,NA,2019-02-18T08:41:56Z,2019-02-18T08:41:56Z,"It would be a good idea to query in advance to avoid idle times. 
2 Questions i have:

1. What ist does the `in_buffer` really do?
2. Would it make sence to check the size of the `InProcessMap` map and allow query in advance when it has fewer urls then x percent of `maxBucketNum * maxURLsPerBucket`? (e.g. x = 10)","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ2NDYzODI2OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/683,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ2NDcwMjY2MA==,incubator-stormcrawler,464702660,683,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-02-18T11:49:03Z,2019-02-18T11:49:03Z,"thanks for your comments @mstrewe 

> * What ist does the `in_buffer` really do?

Merely an optimisation. it gives us a way of checking that a URL is not already in the buffer when processing the results from ES. We could rely on _buffer.contains()_ but being a LinkedList it is likely to be inefficient whereas the HashSet will be fast.

> * Would it make sence to check the size of the `InProcessMap` map and allow query in advance when it has fewer urls then x percent of `maxBucketNum * maxURLsPerBucket`?

I considered doing something like that but the InProcessMap also contains URLs that have been processed succesfully and acked - not just the ones that are currently processing. Moreover, some crawls where most buckets have been exhausted and only a few buckets are left would probably trigger a query as soon as the previous one has finished. We could explore a variant of this idea later on.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ2NDcwMjY2MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/684,https://api.github.com/repos/apache/incubator-stormcrawler/issues/684,incubator-stormcrawler,411451091,684,StatusUpdaterBolt to use provided domain name for routing,sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2019-02-18T12:24:08Z,2019-03-13T13:23:47Z,"StatusUpdaterBolt if configured with routing `byDomain` should use the routing key from metadata (if provided in the field defined by `es.status.routing.fieldname`). Updates of the public suffix list (included in the crawler-commons dependency) may change the domain name and routing key, and may cause duplicate status records in the index and needless refetches of the same URL (cf. commoncrawl/news-crawl#28).

The simplest solution is just to use the provided routing key (similar as it's done for routing `byIP`). This would require only changes in URLPartitioner. Alternatively, StatusUpdaterBolt could check whether the routing key has changed and then send a deletion request using the original routing key and update the status document with the new routing key.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/684/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/684,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ2NTUxNTcxOQ==,incubator-stormcrawler,465515719,684,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-02-20T10:25:12Z,2019-02-20T10:25:12Z,"thanks @sebastian-nagel, get the problem, will think about the best way to implement it ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ2NTUxNTcxOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/684,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ2NzA1MDI1Mw==,incubator-stormcrawler,467050253,684,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-02-25T15:17:51Z,2019-02-25T15:17:51Z,"@sebastian-nagel have put a fix in branch 684, see commit above

you'll need to add _es.routing.value_ to the _metadata.persist_ configuration, even though that particular metadata doesn't actually get stored as it is the only way of passing it to the statusupdaterbolt.

Let me know what you think ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ2NzA1MDI1Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/684,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ2NzUwMzk1Ng==,incubator-stormcrawler,467503956,684,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2019-02-26T16:16:36Z,2019-02-26T16:16:36Z,"Thanks, I'll test it during the next days. To pick the `_routing` value from ES is of course the most reliable solution, maybe better than using `metadata.hostname` (see `es.status.bucket.field` resp. `es.status.routing.fieldname`).","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ2NzUwMzk1Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/684,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ2ODAzMzE5Mg==,incubator-stormcrawler,468033192,684,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-02-27T21:14:22Z,2019-02-27T21:14:22Z,"Am not super happy with this solutiion. It prevents URLS from being refetched forever but means that URLs discovered for the same domain might end up on a different shard. We'd need to extend it to the other backends as well as they might suffer from the same issue. We could add deletion of the old entries but the code would be more complex for an issue which will affect a tiny portion of the users i.e. those who have a long-running crawl + have updated the dependency on crawler-commons either via a new storm-crawler or directly + use domain for sharding.

I also don't like the special case for _es.routing.value_.

Instead, we could have an external mechanism for reindexing an entire status index. I'll also add a comment in the release note so that people force a version of the domain list or crawler-commons if they upgrade. 

what do you think @sebastian-nagel ?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ2ODAzMzE5Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/684,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ2ODI5ODU5NA==,incubator-stormcrawler,468298594,684,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-02-28T14:45:24Z,2019-02-28T14:45:24Z,"The reindexing could be done as a topology with the StatusUpdaterBolt, similar to what we do when injecting except that the content would come from a bespoke Spout which would simply read all the content from a shard with a [Search Scroll](https://www.elastic.co/guide/en/elasticsearch/client/java-rest/7.0/java-rest-high-search-scroll.html). We'd just need a new spout implementation for this.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ2ODI5ODU5NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/684,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ2ODMwMDk0Mw==,incubator-stormcrawler,468300943,684,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2019-02-28T14:51:26Z,2019-02-28T14:51:26Z,"No question, looks like there is no smart and simple solution. From the maintenance perspective:
- not upgrading the public suffix list isn't really an option, there are too many additions over the years
- a ""self-repairing"" status updater (delete and add with new routing key) would be nice
- but a tool to do the fix-up once after a software upgrade is ok (if it's fast enough)

Given that it's possible to quickly get a list of domain names (as routing keys or `metadata.hostname`):
- get the domain name for the routing key in strict/validating mode, and if it differs from the original value or is now null (for new public suffixes, e.g. `kiev.ua`):
- get the full list of items and submit a delete and update

I'm ok with documenting the potential problem and for the long term adding some tool to do the fix-up.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ2ODMwMDk0Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/684,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ2ODMwMjE1Mg==,incubator-stormcrawler,468302152,684,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2019-02-28T14:54:18Z,2019-02-28T14:54:18Z,"About ""full reindexing"": it would still require to send also a deletion. Right?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ2ODMwMjE1Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/684,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ2ODMwMzQxMQ==,incubator-stormcrawler,468303411,684,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-02-28T14:57:24Z,2019-02-28T14:57:24Z,"the way I see it, it would copy to a new index. Aliasing could be used to preserve a generic name e.g. status if needed.
Reindexing could also be useful e.g. for changing the sharding logic or the number of shards etc...","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ2ODMwMzQxMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/684,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ2ODMwNjkyNA==,incubator-stormcrawler,468306924,684,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-02-28T15:06:24Z,2019-02-28T15:06:24Z,"At the moment the configuration of the status bolt and the spouts is based on the same names e.g. _es.status.index.name_; we could add a constructor to StatusUpdaterBolt so that it can use a different value for _ESBoltType_, this way the spouts and the status updater could operate on different indices. The default behaviour would remain the same.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ2ODMwNjkyNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/685,https://api.github.com/repos/apache/incubator-stormcrawler/issues/685,incubator-stormcrawler,414170053,685,Track how long a spout has been without any URLs in its buffer,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-02-25T15:46:09Z,2019-02-25T15:47:18Z,This is essentially to measure the difference pre and after #683 when the ES asynchronous spouts won't wait for the buffer to be empty to refill it.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/685/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/687,https://api.github.com/repos/apache/incubator-stormcrawler/issues/687,incubator-stormcrawler,415682323,687,StatusUpdaterBolt to load config from non-default param names,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-02-28T15:31:56Z,2019-02-28T15:34:55Z,"See discussion on #684 
TLDR; can be useful for distinguishing the config of the spouts from the one used for the StatusUpdaterBolt
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/687/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/688,https://api.github.com/repos/apache/incubator-stormcrawler/issues/688,incubator-stormcrawler,416021532,688,Add a ScrollSpout to read all the documents from a shard,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-03-01T09:48:34Z,2019-03-13T13:23:10Z,"See discussion on #684 

This would be useful for reindexing an entire index e..g when the list of domains has changed or a larger number of shards is needed. These spouts would then be connected to a StatusUpdaterBolt in a simple topology

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/688/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/688,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ2ODczNjYzMw==,incubator-stormcrawler,468736633,688,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-03-01T17:05:01Z,2019-03-01T17:05:01Z,"The logic of the StatusUpdaterBolt might need changing as well. Even if the spout sends all the info as-is, the status updater bolt might make changes to it e.g. increment the counter for number of failures. Either we split the existing behavior into 2 separate bolts or we have a brand new simplified bolt .","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ2ODczNjYzMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/689,https://api.github.com/repos/apache/incubator-stormcrawler/issues/689,incubator-stormcrawler,417783088,689,change ack mechanism for StatusUpdaterBolts,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-03-06T12:39:03Z,2019-03-19T18:09:44Z,"At the moment the ack mechanism in AbstractStatusUpdaterBolt is both complex and error prone. 

The execute method calls _store(url, status, metadata, nextFetch)_ then _ack(tuple, url)_, with the latter being possibly overridden by subclasses. The motivation behind it was to make sure that all the implementations would call _ack(tuple, url)_. 

For asynchronous updater bolts like ES, the ack method is overridden for keeping track of which tuples need acking. The implementation from the super class is used later on for acking once we got confirmation that the backend has received it.

The trouble with this is that in some situations the slight gap between store() and ack() for a given tuple is enough for another thread to creep in and run whichever code deals with the results from the backend. 
One symptom is messages like:

```
2019-03-06 12:04:12.590 c.d.s.e.p.StatusUpdaterBolt Thread-26-status-executor[13 13] [DEBUG] Sent to ES buffer https://SOMEURL with ID 6a3997116fb7368c1206f6431a18d71b15eb0067364febb6e46d68510d55187a
2019-03-06 12:04:12.634 c.d.s.e.p.StatusUpdaterBolt I/O dispatcher 9 [WARN] Could not find unacked tuple for 6a3997116fb7368c1206f6431a18d71b15eb0067364febb6e46d68510d55187a
2019-03-06 12:04:12.636 c.d.s.e.p.StatusUpdaterBolt Thread-26-status-executor[13 13] [DEBUG] Added to waitAck https://SOMEURL with ID 6a3997116fb7368c1206f6431a18d71b15eb0067364febb6e46d68510d55187a total 1
2019-03-06 12:04:12.853 c.d.s.e.p.StatusUpdaterBolt I/O dispatcher 9 [DEBUG] Still in wait ack after bulk response [675] => 6a3997116fb7368c1206f6431a18d71b15eb0067364febb6e46d68510d55187a
...
```

To prevent this and simplify the code, I propose to change the store method to 

**__store(url, status, metadata, nextFetch, tuple)_**

and make the ack method final in the abstract class.

This way, classes like the ES StatusUpdaterBolt could have more control on the tuples waiting to be acked. The main implication is that all the updater bolts implementations will need to be modified to call the ack method explicitely. Since there aren't so many of them, this should not be a big problem.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/689/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/692,https://api.github.com/repos/apache/incubator-stormcrawler/issues/692,incubator-stormcrawler,420936697,692,upgrade okhttp to 3.14.0,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-03-14T10:24:06Z,2019-03-25T07:39:24Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/692/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/692,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ3MzgzOTk1NA==,incubator-stormcrawler,473839954,692,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-03-18T09:48:29Z,2019-03-18T09:48:29Z,"from 3.11 - see https://github.com/square/okhttp/blob/master/CHANGELOG.md

in particular 

> OkHttp now offers full-operation timeouts. This sets a limit on how long the entire call may take and covers resolving DNS, connecting, writing the request body, server processing, and reading the full response body. If a call requires redirects or retries all must complete within one timeout period.
> 
> Use OkHttpClient.Builder.callTimeout() to specify the default duration and Call.timeout() to specify the timeout of an individual call.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ3MzgzOTk1NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/692,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ3MzkwNjkwMA==,incubator-stormcrawler,473906900,692,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2019-03-18T13:21:19Z,2019-03-18T13:21:19Z,"Yes, this feature might be useful. Although the savings are small as the `http.content.limit` still requires to request data in a loop in smaller blocks. #691 tracks the reason for trimmed content (content or time limit, or other exceptions): with a global callTimeout() it would require that all exceptions thrown by okhttp are analyzed to distinguish between timeouts and other exceptions.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ3MzkwNjkwMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/692,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ3MzkwOTkwOQ==,incubator-stormcrawler,473909909,692,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-03-18T13:29:30Z,2019-03-18T13:29:30Z,good point for not using it. Still worth upgrading for all the other bugfixe it contains,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ3MzkwOTkwOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/693,https://api.github.com/repos/apache/incubator-stormcrawler/issues/693,incubator-stormcrawler,422118053,693,Upgrade to crawler-commons 1.0,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-03-18T09:36:40Z,2019-03-23T15:43:16Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/693/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/696,https://api.github.com/repos/apache/incubator-stormcrawler/issues/696,incubator-stormcrawler,424411037,696,can't display v2 metrics,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-03-22T21:44:18Z,2019-03-23T13:43:24Z,"Probably missing something obvious but the v2 metrics used for instance in the spouts e.g. beingProcessed, in buffers, in purgatory can;t be displayed with Grafana","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/696/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/697,https://api.github.com/repos/apache/incubator-stormcrawler/issues/697,incubator-stormcrawler,424411039,697,can't display v2 metrics,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-03-22T21:44:18Z,2019-03-23T13:43:05Z,"Probably missing something obvious but the v2 metrics used for instance in the spouts e.g. beingProcessed, in buffers, in purgatory can;t be displayed with Grafana","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/697/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/698,https://api.github.com/repos/apache/incubator-stormcrawler/issues/698,incubator-stormcrawler,424411061,698,can't display v2 metrics,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-03-22T21:44:25Z,2019-03-25T10:03:32Z,"Probably missing something obvious but the v2 metrics used for instance in the spouts e.g. beingProcessed, in buffers, in purgatory can;t be displayed with Grafana","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/698/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/698,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ3NTg3NDExOA==,incubator-stormcrawler,475874118,698,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-03-23T14:25:34Z,2019-03-23T14:25:34Z,@jcruzmartini  any idea?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ3NTg3NDExOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/698,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ3NjEyMjY3Ng==,incubator-stormcrawler,476122676,698,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-03-25T09:46:47Z,2019-03-25T09:46:47Z,"Should have looked at http://storm.apache.org/releases/1.2.2/metrics_v2.html

The way the reporters are listed in the conf is quite different + need a new implementation of the consumers. Will revert for now and possibly convert everything later on.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ3NjEyMjY3Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/699,https://api.github.com/repos/apache/incubator-stormcrawler/issues/699,incubator-stormcrawler,426098473,699,ES 6.70,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-03-27T17:42:12Z,2019-03-28T09:55:12Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/699/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/700,https://api.github.com/repos/apache/incubator-stormcrawler/issues/700,incubator-stormcrawler,426099891,700,Robots URL filter to get instructions from cache only,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-03-27T17:44:58Z,2019-03-28T09:55:11Z,"The filter currently has an option to retrieve the robots file if the target and source belong to the same hostname. Not doing so on an open crawl can have negative impact on the performance. 
A better alternative would be to be able to limit the retrieval of the robots to the internal cache, regardless of the hostnames. This would have better coverage than same hostname only while guaranteeing no negative impact on the perfs.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/700/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/701,https://api.github.com/repos/apache/incubator-stormcrawler/issues/701,incubator-stormcrawler,428653087,701,Upgrade to SOLR 8.6.0,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-04-03T09:12:28Z,2020-10-23T12:15:45Z,"org.apache.solr:solr-solrj ............................ 7.5.0 -> 8.0.0

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/701/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/701,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1MDI4NjE0OQ==,incubator-stormcrawler,550286149,701,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-11-06T12:23:23Z,2019-11-06T12:23:23Z,http://mail-archives.us.apache.org/mod_mbox/www-announce/201911.mbox/%3CCAHPRk5EO-XTnwpZVZjU=DPO%2BxOwaTnjzoJC%2B5O5ES5KLNC5e8w@mail.gmail.com%3E,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1MDI4NjE0OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/701,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU4Njg0ODY3Nw==,incubator-stormcrawler,586848677,701,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-02-17T07:13:13Z,2020-02-17T07:13:13Z,https://lucene.apache.org/solr/guide/8_4/solr-upgrade-notes.html,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU4Njg0ODY3Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/701,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxNTMwNTY1Nw==,incubator-stormcrawler,715305657,701,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-10-23T12:15:40Z,2020-10-23T12:15:40Z,Fixed in #839 ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxNTMwNTY1Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/702,https://api.github.com/repos/apache/incubator-stormcrawler/issues/702,incubator-stormcrawler,428655763,702,Core dependencies upgrades,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-04-03T09:17:16Z,2019-04-03T09:59:17Z,"guava -> 27.0.1 to 27.1
icu4j -> 61.1 to 64.1
httpclient -> 4.5.5 to 4.5.8
snakeyaml -> 1.16 to 1.24
wiremock -> 2.19.0 to 2.22.0
rometools -> 1.9.0 to 1.12.0","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/702/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/702,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ3OTQyMjc3Ng==,incubator-stormcrawler,479422776,702,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-04-03T09:58:31Z,2019-04-03T09:58:31Z,"Note: the following command is useful for finding updates
'mvn versions:display-dependency-updates'
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ3OTQyMjc3Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/703,https://api.github.com/repos/apache/incubator-stormcrawler/issues/703,incubator-stormcrawler,430858724,703,"Allow indexing under canonical URL if in the same domain, not just host",jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-04-09T09:20:47Z,2019-04-09T18:40:43Z,"https://github.com/DigitalPebble/storm-crawler/blob/dfe4ec54b766f7a69a424dbb2b96a5384a88921f/core/src/main/java/com/digitalpebble/stormcrawler/indexing/AbstractIndexerBolt.java#L210
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/703/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/704,https://api.github.com/repos/apache/incubator-stormcrawler/issues/704,incubator-stormcrawler,432036974,704,URLs ending with a space are fetched over and over again,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-04-11T13:54:10Z,2019-04-11T14:50:09Z,"The reason for this is that the FetcherBolt normalises the URL without the space and that modified version is updated into the persistence backend (e.g Elasticsearch), the original one with the space at the end is unmodified and keeps being fetched.

We should make sure that the fetcherbolts keeps the original URL even if it is incorrect. We should also make sure that the URL normalisers remove these spaces in the first place.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/704/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/705,https://api.github.com/repos/apache/incubator-stormcrawler/issues/705,incubator-stormcrawler,432101513,705,URLs with content that breaks ES get refetched over and over again,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-04-11T15:57:14Z,2019-04-11T16:04:21Z,"Came across a URL which had a ridiculously long keyword value, not separated by commas and ES threw the following failure:
 _{""index"":""content"",""type"":""doc"",""id"":""7f1b8dc352af11b2dcbaac654cb385519af505587069d42012f9c15dd74a9716"",""cause"":{""type"":""exception"",""reason"":""Elasticsearch exception [type=illegal_argument_exception, reason=Document contains at least one immense term in field=\""keywords\"" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: '[114, 111, 112, 101, 32, 98, 111, 110, 100, 97, 103, 101, 32, 98, 111, 110, 100, 97, 103, 101, 32, 114, 111, 112, 101, 32, 98, 111, 110, 100]...', original message: bytes can be at most 32766 in length; got 61973]"",""caused_by"":{""type"":""exception"",""reason"":""Elasticsearch exception [type=max_bytes_length_exceeded_exception, reason=bytes can be at most 32766 in length; got 61973]""}},""status"":400}_

Failures like these simply have their tuple failed and are refetched soon afterwards. We should make sure that a 400 code in ES changes the status of the tuple to ERROR.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/705/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/706,https://api.github.com/repos/apache/incubator-stormcrawler/issues/706,incubator-stormcrawler,432487313,706,URLs without valid host name (and routing) stay DISCOVERED forever,sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2019-04-12T10:02:41Z,2019-04-15T14:23:04Z,"From time to time I have to clean up URLs which fail to fetch and stay DISCOVERED forever. These URLs (eg., `http:/feeds/xml/latest.xml`) are valid in terms of bot java.net.URL and java.net.URI but lack a valid host name (empty for URL, null for URI).

My first thought was that #704 also addresses this issue but that isn't the case. The main difference: from the logs there is no evidence that any of these URLs without host name are tried to be fetched. The only log messages come from the
- feed parser (when checking robots.txt before #700):
```
2019-04-09 06:19:37.927 c.d.s.p.RobotRulesParser Thread-24-feed-executor[4 7] [INFO] Couldn't get robots.txt for http:/feeds/xml/latest.xml : java.net.UnknownHostException: robots.txt: Name or service not known
2019-04-09 06:19:37.928 c.d.s.b.FeedParserBolt Thread-24-feed-executor[4 7] [INFO] Feed parser done http://sportdog.gr/feeds/xml/latest.xml
```
- and StatusUpdaterBolt with debug logging:
```
2019-04-12 09:25:46.379 c.d.s.e.p.StatusUpdaterBolt Thread-16-status-executor[24 24] [DEBUG] Added to waitAck http:/feeds/xml/latest.xml with ID d9b44c50cbf08dc553acaab40fb8d9e58614e655c0738d19f2a481104d405ca2 total 1
2019-04-12 09:25:46.379 c.d.s.e.p.StatusUpdaterBolt Thread-16-status-executor[24 24] [DEBUG] Sending to ES buffer http:/feeds/xml/latest.xml with ID d9b44c50cbf08dc553acaab40fb8d9e58614e655c0738d19f2a481104d405ca2
2019-04-12 09:25:46.379 c.d.s.p.AdaptiveScheduler Thread-16-status-executor[24 24] [DEBUG] Scheduling status: DISCOVERED, metadata: discoveryDate: 2019-04-12T09:25:46.379Z
```

The invalid URL stems from an [Atom feed](http://sportdog.gr/feeds/xml/latest.xml):
```xml
    <entry>
        <title>Η Κωνσταντίνα Σπυροπούλου μας δείχνει τα κάλλη της με σέξι μπικίνι - Πρέπει να δεις αυτή τη φωτό!</title>
        <link rel=""alternate"" type=""text/html"" href=""//#rurl_blhttp://newpost.gr/lifestyle/5caf3cec90e42f7a56d7db7a/i-konstantina-spyropoyloy-mas-deihnei-ta-kalli-tis-me-sexi-mpikini""/>
        <published>2019-04-11T17:09:00+00:00</published>
```

The mentioned URL is stored in the status index without a routing key (`metadata.hostname`):
```json
    ""hits"" : [
      {
        ""_index"" : ""status"",
        ""_type"" : ""status"",
        ""_id"" : ""d9b44c50cbf08dc553acaab40fb8d9e58614e655c0738d19f2a481104d405ca2"",
        ""_score"" : 0.2876821,
        ""_source"" : {
          ""url"" : ""http:/feeds/xml/latest.xml"",
          ""status"" : ""DISCOVERED"",
          ""metadata"" : {
            ""url%2Epath"" : [
              ""http://sportdog.gr/feeds/xml/latest.xml""
            ],
            ""depth"" : [
              ""1""
            ]
          },
          ""nextFetchDate"" : ""2019-04-12T09:25:46.000Z""
        }
      }
    ]
```

One solution would be to filter these URLs away - if hostname is empty and protocol http/https - file URLs are allowed without host.

Alternatively, if the empty host or domain name should be allowed as routing key to make these items fail. Also (I haven't checked it): isn't the empty routing mandatory in a crawl which mixes http:// and file:// URLs?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/706/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/706,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4MjYxNzM5MQ==,incubator-stormcrawler,482617391,706,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-04-12T15:27:53Z,2019-04-12T15:27:53Z,"These URLs should be filtered indeed.

Not sure why this URL doesn't have its status updated. I tried with a simple topology from the archetype and the fetcher sends it to the statusupdaterbolt as a fetch error

_http:/feeds/xml/latest.xml	FETCH_ERROR	Fri Apr 12 17:41:18 BST 2019_

the statusupdaterbolt gets an empty partition key and does not do the sharding explicitely but the latter should be based on the _id which is generated from the URL so regardless of which shard this URL gets sent to, the behaviour should be consistent.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4MjYxNzM5MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/706,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4MjgxMzYzMg==,incubator-stormcrawler,482813632,706,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2019-04-13T14:26:17Z,2019-04-13T14:26:17Z,"I have:
```
# (es-conf.yaml)
  es.status.routing: true
  es.status.routing.fieldname: ""metadata.hostname""
# (crawler-conf.yaml)
  partition.url.mode: ""byDomain""
```","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4MjgxMzYzMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/706,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4MjkyNzIzMg==,incubator-stormcrawler,482927232,706,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-04-14T07:34:57Z,2019-04-14T07:34:57Z,"Got it, this URL never gets fetched because the spouts group them by a field it does not have. The way in which it is sharded is irrelevant. I've just tested using an empty string for the sharding and as value for _metadata.hostname_ and it works fine: the URLs gets fetched and its status updated accordingly. Will commit a fix soon, thanks @sebastian-nagel 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4MjkyNzIzMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/706,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4MzI0NzgwNg==,incubator-stormcrawler,483247806,706,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-04-15T13:19:17Z,2019-04-15T13:19:17Z,@sebastian-nagel don't you use the HostURLFilter? It should have prevented the URL from being added,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4MzI0NzgwNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/706,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4MzI1NzE1MQ==,incubator-stormcrawler,483257151,706,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2019-04-15T13:43:59Z,2019-04-15T13:43:59Z,"The cross-domain filter has been disabled and later HostURLFilter has been entirely removed from the config. There can be cross-domain links from feeds, esp. sites ""hosting"" their feed on `feedburner.com`.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4MzI1NzE1MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/706,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4MzI2NjY2Nw==,incubator-stormcrawler,483266667,706,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-04-15T14:08:28Z,2019-04-15T14:08:28Z,makes sense. we could add a check for a valid hostname in the basic URL filter or normaliser,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4MzI2NjY2Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/707,https://api.github.com/repos/apache/incubator-stormcrawler/issues/707,incubator-stormcrawler,433787844,707,ParseFilter to normalise the mime-type of documents into simple values,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-04-16T13:43:22Z,2019-04-17T08:53:38Z,"e.g. pdf, doc, html, image etc...

Could be within the Tika module, useful for building a search engine.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/707/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/707,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4Mzk5NzU0MA==,incubator-stormcrawler,483997540,707,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-04-17T08:53:38Z,2019-04-17T08:53:38Z,Put it in core alongside the other parse filters as it relies on JSoup and not so much on Tika,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4Mzk5NzU0MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/708,https://api.github.com/repos/apache/incubator-stormcrawler/issues/708,incubator-stormcrawler,436157044,708,Upgrade to Elasticsearch 7.0.x,rzo1,13417392,Richard Zowalla,,CLOSED,2019-04-23T12:20:15Z,2019-05-09T09:56:06Z,"Upgrade Elasticsearch to 7.0.x (7.0.0 atm) (includes adjustments for Kibana 7.0.x) as well.

Breaking changes can be found here: 

https://www.elastic.co/guide/en/elasticsearch/reference/current/breaking-changes-7.0.html

Upgrade guideance:

https://www.elastic.co/guide/en/elasticsearch/reference/current/setup-upgrade.html

As far as I can see, we will have to deal with some deprecated stuff in `DeletionBolt` and `StatusMetricsBolt`. 

In addition, `docType` is in the process of being removed in the near future (see JavaDoc of `DeleteRequest`)

In addition `DEFAULT_MAX_RETRY_TIMEOUT_MILLIS` used in `ElasticSearchConnection` seems to be removed as well (see https://www.elastic.co/guide/en/elasticsearch/reference/current/breaking-changes-7.0.html#breaking_70_restclient_changes for details) without an replacement.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/708/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/708,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4NTc4NTExNw==,incubator-stormcrawler,485785117,708,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-04-23T12:38:53Z,2019-04-23T12:38:53Z,"hi! do you know we already have a branch for it?
https://github.com/DigitalPebble/storm-crawler/tree/es-7

Feedback welcome as usual","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4NTc4NTExNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/708,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4NTc4OTQ1OA==,incubator-stormcrawler,485789458,708,NA,rzo1,13417392,Richard Zowalla,,NA,2019-04-23T12:51:52Z,2019-04-23T12:51:52Z,"Hey @jnioche 

wuhu - thanks for the response. I did not checked this branch as I did not found an related issue.

I will give it a try!

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4NTc4OTQ1OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/708,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4ODU3NTc0Ng==,incubator-stormcrawler,488575746,708,NA,rzo1,13417392,Richard Zowalla,,NA,2019-05-02T07:25:10Z,2019-05-02T07:25:10Z,I did some testing - no issues yet. Will continue to build our depending artifacts against the es-7 branch (merged with the latest master changes),"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4ODU3NTc0Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/708,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4OTMyOTU1Mg==,incubator-stormcrawler,489329552,708,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-05-04T14:00:07Z,2019-05-04T14:00:07Z,"Will be in the 1.14 release then
https://twitter.com/stormcrawlerapi/status/1124259162039422977
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4OTMyOTU1Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/709,https://api.github.com/repos/apache/incubator-stormcrawler/issues/709,incubator-stormcrawler,436808554,709,Robot rules should check the cache in case of a redirection,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-04-24T17:03:24Z,2019-04-25T07:11:44Z,"We should check the cache before fetching the redirection and cache the result for the key. What currently happens is that we always refetch the redirection, even when it is already in the cache.
Performance aside, this means that the rules were never marked as coming from the cache.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/709/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/710,https://api.github.com/repos/apache/incubator-stormcrawler/issues/710,incubator-stormcrawler,436811188,710,Fix the logic around sitemap = false,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-04-24T17:10:19Z,2019-04-26T12:43:21Z,"#645 was a good idea in theory but needs fixing. The idea was to prevent pages from having their outlinks followed unless they had been flagged as being a sitemap (or not), basically, we have sitemaps, let's stick to what they contain.

For a given URL, this was done in the fetchers by setting isSitemap=false when sitemap files were found from the robots.txt, only if the robots was freshly fetched and not coming from the cache. 

The outlinks are then filtered thanks to 

>  {
>       ""class"": ""com.digitalpebble.stormcrawler.filtering.metadata.MetadataFilter"",
>       ""name"": ""MetadataFilter"",
>       ""params"": {
>         ""isSitemap"": ""false"",
>         ""isFeed"": ""false""
>       }
>     }

**isSitemap**

- set to true when finding the URL in the robots.txt or detecting them in the sitemap parser

- set to false when finding the sitemap parser finds a terminal leaf i.e. definitely not a sub sitemap **or** by the fetcher, see logic above.

This works OK in most cases, nothing's affected if the MetadataFilter is not set apart from the following case: if a sitemap is redirected, the isSitemap key is lost - the idea being that we are not sure the target really is a sitemap and not a HTML page so it is not transferred automatically. When the redirected URLs is about to be fetched, and as we know there are sitemaps for that site, it gets _isSitemap=false_ which prevents the detection of the sitemap to be applied. The sitemap parsing is skipped and the documents ends up being passed to the other parsers. 

The detection is triggered by the config  _sitemap.sniffContent: true_ but is done anyway to fix incorrect mime types.

Here is a cleaner approach:
- we can use a different key to mark that there are sitemaps for a site instead of relying on _isSitemap=false_, e.g. _foundSitemap=true_ and let the SitemapParser flag the URL as _isSitemap=false_ if it is really the case. 
- remove _sitemap.sniffContent: true_ altogether there is no performance gain in not using it as we compute it anyway and it won't give false positives. Having it systematically also means that we can process redirected sitemaps successfully
- add _foundSitemap_ regardless of whether the robots came from the cache or not for more consistency 
 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/710/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/710,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4Njk4MTQ0Mw==,incubator-stormcrawler,486981443,710,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-04-26T08:53:47Z,2019-04-26T08:53:47Z,the sitemap parser will mark the docs as isSitemap=false but that won't be used to filter the outlinks. Instead we'll need a better version of the metadata filter which can combine metadata i.e. filter if a doc has both _foundSitemap=true_ and _isSitemap=false_,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4Njk4MTQ0Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/711,https://api.github.com/repos/apache/incubator-stormcrawler/issues/711,incubator-stormcrawler,437569724,711,MetadataFilter to filter based on multiple key values,jnioche,218319,Julien Nioche,julien@digitalpebble.com,OPEN,2019-04-26T08:57:44Z,2019-04-26T08:57:52Z,"see #710 to filter docs if _isSitemap=false_ and _foundSitemap=true_
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/711/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/712,https://api.github.com/repos/apache/incubator-stormcrawler/issues/712,incubator-stormcrawler,438672036,712,Set mimetype whitelist for Tika Parser,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-04-30T09:05:43Z,2019-04-30T15:02:47Z,"Using the Tika parser on an open crawl can cause some memory and performance issues as it will try to parse anything that comes its way. This could be very large archives or multimedia files where the URL does not give any clue to its content and therefore the URL filters are unable to filter them out. Tika then takes ages parsing them, so the incoming tuples back up in the internal queues until eventually the JVM runs out of memory. This is also the case with PDF documents which have been trimmed by the Fetcher.
One solution would be to add a configurable mime-type blacklist for the Tika parser so that such tuples get discarded and the corresponding URLs given an ERROR status. We can also treat trimmed documents in the same way.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/712/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/712,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4Nzk4ODE4Mg==,incubator-stormcrawler,487988182,712,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-04-30T15:02:47Z,2019-04-30T15:02:47Z,"You can configure the whitelist as so:

```
    parser.mimetype.whitelist:
     - application/.+word.*
     - application/.+excel.*
     - application/.+powerpoint.*
     - application/.*pdf.*
```","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4Nzk4ODE4Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/713,https://api.github.com/repos/apache/incubator-stormcrawler/issues/713,incubator-stormcrawler,438674240,713,Review Robots' caching logic,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-04-30T09:11:41Z,2019-05-07T13:50:52Z,"@sebastian-nagel's comment on #709 (96eff4c)

> Wouldn't this mean that the rules read from /robots.txt of the redirection host are always taken, no matter what the path of redirect target is? One example:
> 
> https://host-a.example.org/robots.txt redirects to https://static.example.org/host-a/robots.txt
> keyredir of the redirect target is https:static.example.org:443
> but under this key the rules from https://static.example.org/robots.txt are hold
> The logic should be the other way around: only if the path of the redirect target equals /robots.txt, the rules can be taken from the cache using the key of the redirect target.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/713/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/713,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4OTA0MTU4NQ==,incubator-stormcrawler,489041585,713,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2019-05-03T10:00:27Z,2019-05-03T10:00:27Z,Is this in progress? Otherwise I would try to get it fixed.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4OTA0MTU4NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/713,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4OTA1MDAyOQ==,incubator-stormcrawler,489050029,713,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-05-03T10:22:50Z,2019-05-03T10:22:50Z,"Am not working on it, would be great if you could have a go. Thanks","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ4OTA1MDAyOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/714,https://api.github.com/repos/apache/incubator-stormcrawler/issues/714,incubator-stormcrawler,439207214,714,MetricsConsumer to include topology ID in metrics,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-05-01T15:33:36Z,2019-05-07T10:56:31Z,"This way we can distinguish between topologies in Grafana / Kibana
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/714/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/715,https://api.github.com/repos/apache/incubator-stormcrawler/issues/715,incubator-stormcrawler,439951805,715,ESSeedInjector: no URLs injected because URL filter does not subscribe to status stream,sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2019-05-03T09:00:22Z,2019-05-03T10:24:44Z,"With #677 the FileSpout emits tuples to the ""status"" stream if called with param `withDiscoveredStatus`. However, the URL filter bolt does not subscribe to the ""status"" stream which causes that all injected URLs are lost. I'll open a PR soon.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/715/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/719,https://api.github.com/repos/apache/incubator-stormcrawler/issues/719,incubator-stormcrawler,442602917,719,Reduce logging of exceptions in FetcherBolt,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-05-10T08:36:51Z,2019-05-10T08:37:34Z,"The FetcherBolt treats most exceptions occurring during fetching with a debug level of ERROR and dumps the stack trace which makes the logs difficult to read and unnecessarily verbose. Most of these exceptions are a normal part of crawling and should not be considered as errors.

I will commit a change which will change the level to INFO and generate a stack only if the level is set to DEBUG.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/719/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/720,https://api.github.com/repos/apache/incubator-stormcrawler/issues/720,incubator-stormcrawler,442690362,720,NPE in WARCHdfsBolt on cleanup(),sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2019-05-10T12:18:38Z,2019-05-10T16:18:23Z,"When a (local) topology is killed and no tuples have been passed to the WARCHdfsBolt, the cleanup() will raise a NPE:
```
68227 [Thread-91-warc-executor[36 36]] INFO  o.a.s.util - Async loop interrupted!
68227 [Thread-89-disruptor-executor[36 36]-send-queue] INFO  o.a.s.util - Async loop interrupted!
68227 [SLOT_1024] INFO  c.d.s.w.GzipHdfsBolt - Cleanup called on bolt
68227 [SLOT_1024] ERROR o.a.s.d.s.Slot - Error when processing event
java.lang.NullPointerException: null
        at com.digitalpebble.stormcrawler.warc.GzipHdfsBolt.cleanup(GzipHdfsBolt.java:187) ~[storm-crawler-fight-2.0-SNAPSHOT.jar:?]
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_181]
        ...
        at org.apache.storm.ProcessSimulator.killProcess(ProcessSimulator.java:67) ~[storm-core-1.2.2.jar:1.2.2]
        at org.apache.storm.daemon.supervisor.LocalContainer.kill(LocalContainer.java:69) ~[storm-core-1.2.2.jar:1.2.2]
        ...
```

Of course, it's a minor issue (the topology is shut down anyway) but should either check always initialize the output stream or check whether it is initialized.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/720/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/720,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5MTI5MjI0Mw==,incubator-stormcrawler,491292243,720,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2019-05-10T13:39:40Z,2019-05-10T13:39:40Z,"Clarification: happens in local mode also with a successfully written WARC file.
Maybe related: check why (local mode?) a checksum filesystem was chosen despite the configuration:
```
# grep -A1 warc crawler-conf.yaml 
  warc:
    fs.file.impl: ""org.apache.hadoop.fs.RawLocalFileSystem""

# ls -a /tmp/warc/
.crawl-20190510132330-01-00000.warc.gz.crc
crawl-20190510132330-01-00000.warc.gz
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5MTI5MjI0Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/720,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5MTMyMDU3Mw==,incubator-stormcrawler,491320573,720,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-05-10T15:01:33Z,2019-05-10T15:01:33Z,"Did you specify the config key for the bolt?
```
      - name: ""withConfigKey""
        args:
          - ""warc""
```","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5MTMyMDU3Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/720,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5MTMyMjI5NA==,incubator-stormcrawler,491322294,720,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-05-10T15:06:21Z,2019-05-10T15:06:21Z,re-error in cleanup() : we could simply check that this.out is not null,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5MTMyMjI5NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/720,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5MTMzMjExNg==,incubator-stormcrawler,491332116,720,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2019-05-10T15:35:07Z,2019-05-10T15:35:07Z,"Actually, the cleanup method is called twice from different threads when running in local mode. One does not have the output stream initialized, cf. log output with the null-check applied:
```
67419 [SLOT_1024] INFO  o.a.s.d.worker - Shutting down executors
67419 [SLOT_1024] INFO  o.a.s.d.executor - Shutting down executor warc:[41 41]
67422 [Thread-19-warc-executor[41 41]] INFO  o.a.s.util - Async loop interrupted!
67427 [Thread-18-disruptor-executor[41 41]-send-queue] INFO  o.a.s.util - Async loop interrupted!
67430 [SLOT_1024] INFO  c.d.s.w.GzipHdfsBolt - Cleanup called on bolt
67430 [SLOT_1024] WARN  c.d.s.w.GzipHdfsBolt - Nothing to cleanup: output stream not initialized
67431 [SLOT_1024] INFO  o.a.s.d.executor - Shut down executor warc:[41 41]
...
72837 [SLOT_1027] INFO  o.a.s.d.executor - Shutting down executor warc:[42 42]
72838 [Thread-329-warc-executor[42 42]] INFO  o.a.s.util - Async loop interrupted!
72840 [Thread-328-disruptor-executor[42 42]-send-queue] INFO  o.a.s.util - Async loop interrupted!
72841 [SLOT_1027] INFO  c.d.s.w.GzipHdfsBolt - Cleanup called on bolt
72846 [SLOT_1027] INFO  o.a.s.d.executor - Shut down executor warc:[42 42]
```","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5MTMzMjExNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/720,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5MTM0NjUyNw==,incubator-stormcrawler,491346527,720,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-05-10T16:18:23Z,2019-05-10T16:18:23Z,"Merged, thanks @sebastian-nagel ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5MTM0NjUyNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/721,https://api.github.com/repos/apache/incubator-stormcrawler/issues/721,incubator-stormcrawler,442737562,721,withRequestRecords can cause ConcurrentModificationException on the metadata,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-05-10T14:06:20Z,2019-05-12T07:34:22Z,"When running a web archiving topology with 2 workers running on a single machine and with the WARC bolt connected straight to the FetcherBolt with the rest of the topology (parsing, updating) connected to the FetcherBolt as well, I am getting a  ConcurrentModificationException on the Metadata.

This is strange as I was expecting the tuples to be serialized between bolts but this would indicate that the instance is shared between bolts. The [WARCRequestRecordFormat](https://github.com/DigitalPebble/storm-crawler/blob/48c34777fd9708e20c1c27f68832e150a67e4d68/external/warc/src/main/java/com/digitalpebble/stormcrawler/warc/WARCRequestRecordFormat.java#L68) writes to the metadata after it has been emitted by one of other bolts, which causes the exception.

This does not happen when _withRequestRecords_ is not used.  WARCRecordFormat relies on the key ""_request.warc_record_id_"" in the metadata to link the request with the response.

As a solution, we could make a copy of the tuple in MultipleRecordFormat so that WARCRequestRecordFormat can write to the metadata and WARCRecordFormat can read from it without affecting the other bolts.


","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/721/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/721,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5MTMxMzI0MA==,incubator-stormcrawler,491313240,721,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-05-10T14:41:03Z,2019-05-10T14:41:03Z,"@sebastian-nagel this is probably a bug in Storm and I can't work out a clean solution to this problem. Would it be OK to temporarily comment out 

 ```       metadata.addValue(""_request.warc_record_id_"", mainID); ```

until the root of the problem is found? This way we could release 1.14
 ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5MTMxMzI0MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/721,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5MTM0NzQ1MQ==,incubator-stormcrawler,491347451,721,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2019-05-10T16:21:23Z,2019-05-10T16:21:23Z,"Luckily, the [WARC-Concurrent-To](http://iipc.github.io/warc-specifications/specifications/warc-format/warc-1.1/#warc-concurrent-to) is not mandatory, so this may be an option.

From the [1.2.2 storm docs](http://storm.apache.org/releases/1.2.2/Troubleshooting.html):

> Everything you emit into the output collector must be immutable. What's happening is that your bolt is modifying the object while it is being serialized to be sent over the network.

I've tried to reproduce the issue but without success so far.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5MTM0NzQ1MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/721,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5MTU3MjU1MA==,incubator-stormcrawler,491572550,721,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-05-12T07:33:35Z,2019-05-12T07:33:35Z,I've reproduced the issue on another server and it doesn't happen when commenting the line above. Will commit shortly.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5MTU3MjU1MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/723,https://api.github.com/repos/apache/incubator-stormcrawler/issues/723,incubator-stormcrawler,444456356,723,StatusMetricsBolt returns a max of 10K results per status,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-05-15T14:00:34Z,2019-09-19T08:15:20Z,"Since the move to ES 7, the counts are limited to 10K.

After removing the limitation,am getting the following times for the queries

```
MultiQuery returned in 1842 msec
MultiQuery returned in 1537 msec
MultiQuery returned in 1053 msec
MultiQuery returned in 1140 msec
MultiQuery returned in 1116 msec
MultiQuery returned in 1439 msec
MultiQuery returned in 2348 msec
MultiQuery returned in 2037 msec
MultiQuery returned in 1556 msec
MultiQuery returned in 1640 msec
MultiQuery returned in 1619 msec
MultiQuery returned in 5011 msec
```

Would be worth having a look at the [CountAPI](https://www.elastic.co/guide/en/elasticsearch/client/java-rest/current/java-rest-high-count.html) for doing it, might be more efficient.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/723/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/723,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5MzM4ODEzMw==,incubator-stormcrawler,493388133,723,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-05-17T09:28:08Z,2019-05-17T09:28:08Z,"implemented it using the count API, can't be slower than running a standard query anyway. Can't track how long these queries take unfortunately","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5MzM4ODEzMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/724,https://api.github.com/repos/apache/incubator-stormcrawler/issues/724,incubator-stormcrawler,444991519,724,MetricsConsumer takes an optional date format ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-05-16T14:33:32Z,2019-05-16T14:36:14Z,"We don't need 3 classes to implement two flavours of time formatted index names when the MetricsConsumer can be configured with an optional argument like

```
    topology.metrics.consumer.register:
         - class: ""com.digitalpebble.stormcrawler.elasticsearch.metrics.MetricsConsumer""
           parallelism.hint: 1
           argument: ""yyyy-MM-dd""
```

which is more flexible and economical","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/724/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/725,https://api.github.com/repos/apache/incubator-stormcrawler/issues/725,incubator-stormcrawler,445397303,725,ES spouts use nextFetchDate RangeQuery as a filter,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-05-17T11:30:06Z,2019-05-17T11:34:41Z,"There is no reason why it should be treated as the main query, it is merely a filter which has no influence on the scoring. We sort the results explicitly anyway. Using it as a filter would have a beneficial impact on the performance via caching, no scoring computation etc...
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/725/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/726,https://api.github.com/repos/apache/incubator-stormcrawler/issues/726,incubator-stormcrawler,445954511,726,Upgrade to Tika 1.22,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-05-20T07:07:17Z,2019-08-05T06:21:36Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/726/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/726,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUwODAxNTMwNg==,incubator-stormcrawler,508015306,726,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-07-03T09:24:11Z,2019-07-03T09:24:11Z,should be released soon,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUwODAxNTMwNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/727,https://api.github.com/repos/apache/incubator-stormcrawler/issues/727,incubator-stormcrawler,446128726,727,ScrollSpout to quit logging when finished,sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2019-05-20T13:49:07Z,2019-05-21T14:10:13Z,"The ScrollSpouts continue logging
```
2019-05-16 07:05:53.646 c.d.s.e.p.ScrollSpout I/O dispatcher 8 [INFO] [spout #3]  ES query returned 0 hits in 1 msec
2019-05-16 07:05:53.646 c.d.s.e.p.ScrollSpout I/O dispatcher 7 [INFO] [spout #5]  ES query returned 0 hits in 1 msec
2019-05-16 07:05:53.646 c.d.s.e.p.ScrollSpout I/O dispatcher 1 [INFO] [spout #4]  ES query returned 0 hits in 1 msec
2019-05-16 07:05:53.646 c.d.s.e.p.ScrollSpout I/O dispatcher 1 [INFO] [spout #7]  ES query returned 0 hits in 1 msec
2019-05-16 07:05:53.647 c.d.s.e.p.ScrollSpout I/O dispatcher 1 [INFO] [spout #3]  ES query returned 0 hits in 1 msec
2019-05-16 07:05:53.647 c.d.s.e.p.ScrollSpout I/O dispatcher 1 [INFO] [spout #4]  ES query returned 0 hits in 1 msec
2019-05-16 07:05:53.647 c.d.s.e.p.ScrollSpout I/O dispatcher 7 [INFO] [spout #7]  ES query returned 0 hits in 1 msec
2019-05-16 07:05:53.647 c.d.s.e.p.ScrollSpout I/O dispatcher 8 [INFO] [spout #5]  ES query returned 0 hits in 1 msec
```
after they have finished. It would be nice if they could quit, at least, they should log less. 4,000 lines per second for 10 spouts will cause the ""real"" log messages rotated away quickly, so that it becomes impossible to analyze errors during reindexing (#688).

[ScrollSpout line 90](https://github.com/DigitalPebble/storm-crawler/pull/690/commits/f1d89a2beacb8d520c1cc0f28de86c4c4e2a9bb5#diff-db5cbda8294effc5eb9e9a691fffe57dR90) assumes that the scroll ID is set to null if the scroll response is exhausted. But according to the [ES documentation](https://www.elastic.co/guide/en/elasticsearch/client/java-api/7.0/java-search-scrolling.html), ""zero hits mark the end of the scroll and the while loop.""","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/727/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/727,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5NDA0NTc3Mg==,incubator-stormcrawler,494045772,727,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-05-20T15:52:38Z,2019-05-20T15:52:38Z,"Hi Sebastian, should be fixed. Would be fab if you could give it a try","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5NDA0NTc3Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/727,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5NDQwNzkwNA==,incubator-stormcrawler,494407904,727,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2019-05-21T14:10:13Z,2019-05-21T14:10:13Z,"Thanks, @jnioche. It's tested: the spouts quit logging but keep running.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5NDQwNzkwNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/728,https://api.github.com/repos/apache/incubator-stormcrawler/issues/728,incubator-stormcrawler,446471768,728,Use regular expressions for list of metadata to persist and transfer,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-05-21T07:59:50Z,2023-11-13T09:33:27Z,"This would allow defining generic patterns e.g. _xxx_s_ or _yyy_p_ so that any matching key gets store or persisted without having to list them in the config explicitly. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/728/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/728,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5rwGQ_,incubator-stormcrawler,1807770687,728,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-11-13T09:33:27Z,2023-11-13T09:33:27Z,Overlaps with #728 which is probably sufficient as an approach,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5rwGQ_/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/729,https://api.github.com/repos/apache/incubator-stormcrawler/issues/729,incubator-stormcrawler,447046218,729,b,pgg-are-my-initials,11097343,Pedro García Guillamón,pgarcia@sensingtools.com,CLOSED,2019-05-22T10:05:50Z,2019-05-22T10:06:19Z,"What kind of issue is this?

 - [ ] Question. This issue tracker is not the best place for questions. If you want to ask how to do
       something, or to understand why something isn't working the way you expect it to, use StackOverflow
       instead with the label 'stormcrawler': https://stackoverflow.com/questions/tagged/stormcrawler 

 - [ ] Bug report. If you’ve found a bug, please include a test if you can, it makes it a lot easier to fix things. Use the label 'bug' on the issue.
 
 - [ ] Feature request. Please use the label 'wish' on the issue.

Thanks!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/729/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/730,https://api.github.com/repos/apache/incubator-stormcrawler/issues/730,incubator-stormcrawler,447057288,730,ESSeedInjector topology does not index seeds into Elasticsearch 7.0.1,pgg-are-my-initials,11097343,Pedro García Guillamón,pgarcia@sensingtools.com,CLOSED,2019-05-22T10:30:22Z,2019-05-23T09:45:59Z,"**The used environment:**
- Default ES cluster with Kibana deployed on docker swarm. Both in 7.0.1 version
- Step by step creation of the topology based on your [guide](https://github.com/DigitalPebble/storm-crawler/tree/master/external/elasticsearch).
_I ran the ES_IndexInit.sh and it gone well_ 

**The error:**
- In JAR side:

> 7183 [Thread-22-__metricscom.digitalpebble.stormcrawler.elasticsearch.metrics.MetricsConsumer-executor[2 2]] INFO  o.a.s.d.executor - Prepared bolt __metricscom.digitalpebble.stormcrawler.elasticsearch.metrics.MetricsConsumer:(2)
12261 [I/O dispatcher 2] WARN  o.e.c.RestClient - request [POST http://localhost:9200/_bulk?timeout=1m] returned 1 warnings: [299 Elasticsearch-7.0.1-e4efcb5 ""[types removal] Specifying types in bulk requests is deprecated.""]
12343 [I/O dispatcher 2] ERROR c.d.s.e.p.StatusUpdaterBolt - update ID 9005907c6abf5883088107da21dd92f62273c2d8ee584099ac335a9da723d28d, failure: {""index"":""status"",""type"":""status"",""id"":""9005907c6abf5883088107da21dd92f62273c2d8ee584099ac335a9da723d28d"",""cause"":{""type"":""exception"",""reason"":""Elasticsearch exception [type=illegal_argument_exception, reason=Rejecting mapping update to [status] as the final mapping would have more than 1 type: [_doc, status]]""},""status"":400}
12348 [I/O dispatcher 2] INFO  c.d.s.e.p.StatusUpdaterBolt - Bulk response [1] : items 1, waitAck 0, acked 0, failed 1

- In ES side:

> {""type"": ""server"", ""timestamp"": ""2019-05-22T10:23:44,500+0000"", ""level"": ""DEBUG"", ""component"": ""o.e.a.b.TransportShardBulkAction"", ""cluster.name"": ""docker-cluster"", ""node.name"": ""es01"", ""cluster.uuid"": ""doc0CjGtQnOQTBJeGavYyQ"", ""node.id"": ""xP1kHvj1QNClECd6LMAUeQ"",  ""message"": ""[status][0] failed to execute bulk item (create) index {[status][status][9005907c6abf5883088107da21dd92f62273c2d8ee584099ac335a9da723d28d], source[{\""url\"":\""http://www.theguardian.com/newssitemap.xml\"",\""status\"":\""DISCOVERED\"",\""metadata\"":{\""isSitemap\"":[\""true\""],\""hostname\"":\""www.theguardian.com\""},\""nextFetchDate\"":\""2019-05-22T10:23:39.000Z\""}]}"" , 
{""type"": ""server"", ""timestamp"": ""2019-05-22T10:22:52,378+0000"", ""level"": ""DEBUG"", ""component"": ""o.e.a.b.TransportShardBulkAction"", ""cluster.name"": ""docker-cluster"", ""node.name"": ""es01"", ""cluster.uuid"": ""doc0CjGtQnOQTBJeGavYyQ"", ""node.id"": ""xP1kHvj1QNClECd6LMAUeQ"",  ""message"": ""[metrics][0] failed to execute bulk item (index) index {[metrics][datapoint][9WMQ32oBD9QyCgkUqeDN], source[{\""srcComponentId\"":\""enqueue\"",\""srcTaskId\"":3,\""srcWorkerHost\"":\""rocco\"",\""srcWorkerPort\"":1027,\""name\"":\""waitAck\"",\""value\"":0.0,\""timestamp\"":\""2019-05-22T10:22:47.720Z\""}]}"" , ,
""at java.lang.Thread.run(Thread.java:835) [?:?]""] },
""stacktrace"": [""java.lang.IllegalArgumentException: Rejecting mapping update to [status] as the final mapping would have more than 1 type: [_doc, status]"",,
""at org.elasticsearch.index.mapper.MapperService.internalMerge(MapperService.java:449) ~[elasticsearch-7.0.1.jar:7.0.1]"",,


","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/730/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/730,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5NDc3NzkzOQ==,incubator-stormcrawler,494777939,730,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-05-22T12:18:17Z,2019-05-22T12:18:17Z,which version of StormCrawler are you using? You need 1.14 in order to use ES7,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5NDc3NzkzOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/730,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5NDc4NTg3OQ==,incubator-stormcrawler,494785879,730,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2019-05-22T12:43:16Z,2019-05-22T12:43:16Z,"```
Rejecting mapping update to [status] as the final mapping would have more than 1 type: [_doc, status]""
```
looks like there is a mixture of StormCrawler 1.14 (doc type ""_doc"") and 1.13 or below (doc type ""status""): @aswencio22222, has the the index been upgraded from an older version?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5NDc4NTg3OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/730,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5NTE0NzY0NQ==,incubator-stormcrawler,495147645,730,NA,pgg-are-my-initials,11097343,Pedro García Guillamón,pgarcia@sensingtools.com,NA,2019-05-23T09:45:48Z,2019-05-23T09:45:48Z,"Ok was a version problem as you pointed. Thanks to both, keep it up!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDQ5NTE0NzY0NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/731,https://api.github.com/repos/apache/incubator-stormcrawler/issues/731,incubator-stormcrawler,447163566,731,Add boolean indicating whether URL has been found in a redirection,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-05-22T14:15:51Z,2019-06-17T08:02:12Z,"This would allow filtering for a particular domain, instead of preventing all redirections.
Later on, this could also be taken into account to distinguish the depth from the number of redirs.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/731/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/731,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUwMjU3NzIzNA==,incubator-stormcrawler,502577234,731,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-06-17T08:02:11Z,2019-06-17T08:02:11Z,"not needed, we have a key / value in the source metadata indicating that it came from a redir.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUwMjU3NzIzNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/733,https://api.github.com/repos/apache/incubator-stormcrawler/issues/733,incubator-stormcrawler,453112064,733,LangId normalises and returns value found via extraction ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-06-06T15:56:32Z,2019-06-06T15:59:37Z,The current behavior is to skip the detection if a value is found in the metadata. What is needed is to return the value under the same key name as if it had been extracted and normalise the values e.g. if it contains a country code.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/733/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/734,https://api.github.com/repos/apache/incubator-stormcrawler/issues/734,incubator-stormcrawler,458753205,734,Use sniffer for ES connections,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-06-20T16:22:08Z,2019-07-03T09:19:35Z,"According to the [ES doc](https://www.elastic.co/guide/en/elasticsearch/client/java-rest/current/_node_selector.html)

> The client sends each request to one of the configured nodes in round-robin fashion.

which makes sense, otherwise in a multinode cluster, the same node would end up doing all the coordination.

One thing that is currently missing is the ability to discover all the nodes in the cluster using the 
[Sniffer](https://www.elastic.co/guide/en/elasticsearch/client/java-rest/current/_usage.html). This could simplify things for cases where the cluster is large or its nodes change often.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/734/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/735,https://api.github.com/repos/apache/incubator-stormcrawler/issues/735,incubator-stormcrawler,460872255,735,[Bug] RemoteDriverProtocol does not set user agent correctly,GerbenKD,1324876,Gerben de Vries,,CLOSED,2019-06-26T09:51:58Z,2019-06-26T19:56:28Z,"The RemoteDriverProtocol class scans for the `$useragent` String here (in RemoteDriverProtocol):

                Entry<String, Object> entry = iter.next();
                Object val = entry.getValue();
                // substitute variable $useragent for the real value
                if (val instanceof String
                        && ""$useragent"".equalsIgnoreCase(val.toString())) {
                    val = userAgentString;
                }
                capabilities.setCapability(entry.getKey(), entry.getValue());

However, the changed value is never actually used, instead the orginal value in the entry is used.
Related, I'm not sure this is the right way to set the user-agent for Chrome.

cheers and thanks,

Gerben
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/735/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/735,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUwNjAyMTk5OQ==,incubator-stormcrawler,506021999,735,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-06-26T19:56:28Z,2019-06-26T19:56:28Z,"thanks @GerbenKD, should now be fixed

feel free to open a PR if you find that Chrome requires a different mechanism","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUwNjAyMTk5OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/737,https://api.github.com/repos/apache/incubator-stormcrawler/issues/737,incubator-stormcrawler,463640920,737,Upgrade to ES 7.2.0,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-07-03T09:21:08Z,2019-07-03T09:22:19Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/737/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/738,https://api.github.com/repos/apache/incubator-stormcrawler/issues/738,incubator-stormcrawler,463731806,738,FetcherBolt doesn't recover when entering maxNumberURLsInQueues,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-07-03T12:44:42Z,2019-07-03T12:45:51Z,maxNumberURLsInQueues is a way of blocking the reads from the Storm input queue when reaching a number of URLs in the FetcherBolt. There is currently a bug as we never recheck the condition and exit the loop.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/738/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/739,https://api.github.com/repos/apache/incubator-stormcrawler/issues/739,incubator-stormcrawler,465689205,739,shade Elasticsearch dependencies?,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-07-09T10:02:18Z,2019-07-23T12:59:28Z,"I have a situation where a custom IndexerBolt has been created for ES and talks to cluster which is likely to be on ES6 for a while, while the status and metrics can already be on ES7. Am wondering whether it would make sense to shade the ES deps so that the standard spouts and bolts can be on 7 whereas any bespoke component could use the version it wants.  ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/739/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/739,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUwOTU4MjAzNg==,incubator-stormcrawler,509582036,739,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-07-09T10:12:09Z,2019-07-09T10:12:09Z,https://maven.apache.org/plugins/maven-shade-plugin/examples/class-relocation.html,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUwOTU4MjAzNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/739,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUxNDE5ODg4MQ==,incubator-stormcrawler,514198881,739,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-07-23T12:59:27Z,2019-07-23T12:59:27Z,closing for now,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUxNDE5ODg4MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/740,https://api.github.com/repos/apache/incubator-stormcrawler/issues/740,incubator-stormcrawler,469661213,740,improvements to URLFilterBolt ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-07-18T09:21:37Z,2019-07-18T09:36:16Z,"It could be instanciated with param to be applied to DISCOVERED status only and take a custom config file for the filters, different from the one defined for the rest of the topology","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/740/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/741,https://api.github.com/repos/apache/incubator-stormcrawler/issues/741,incubator-stormcrawler,476673510,741,Upgrade to JSOUP 1.12.1,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-08-05T06:09:14Z,2020-07-02T12:25:16Z,https://jsoup.org/news/release-1.12.1,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/741/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/741,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUxODEwMzM2MA==,incubator-stormcrawler,518103360,741,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-08-05T06:28:52Z,2019-08-05T06:28:52Z,"```
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.2:compile (default-compile) on project storm-crawler-core: Compilation failure
[ERROR] /data/storm-crawler/core/src/main/java/com/digitalpebble/stormcrawler/parse/TextExtractor.java:[23,24] cannot find symbol
[ERROR]   symbol:   class StringUtil
[ERROR]   location: package org.jsoup.helper
[ERROR] 
[ERROR] -> [Help 1]
```","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUxODEwMzM2MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/741,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1Mjk3NDkxMA==,incubator-stormcrawler,652974910,741,NA,rem7i,10940287,,,NA,2020-07-02T12:25:16Z,2020-07-02T12:25:16Z,"I have the same problem and couldn't find any solution, even though I downgraded to version 1.8.13","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1Mjk3NDkxMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/742,https://api.github.com/repos/apache/incubator-stormcrawler/issues/742,incubator-stormcrawler,478430375,742,Upgrade to ES 7.3.0,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-08-08T12:08:11Z,2019-08-08T12:13:18Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/742/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/743,https://api.github.com/repos/apache/incubator-stormcrawler/issues/743,incubator-stormcrawler,478437843,743,Upgrade to Storm 1.2.3,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-08-08T12:23:49Z,2019-08-08T12:24:50Z,http://storm.apache.org/2019/07/18/storm123-released.html,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/743/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/744,https://api.github.com/repos/apache/incubator-stormcrawler/issues/744,incubator-stormcrawler,478899447,744,Improve types used for numeric values for metrics mappings,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-08-09T09:47:49Z,2019-08-09T09:52:04Z,"Even though the metrics are small documents and a crawl does not generate very many, there is no reason to use long when short or integer can do. For instance, **srcTaskId** is unlikely to have a value greater than 32,767 and therefore a _short_ is sufficient. Same for **srcWorkerPort**, which can use an _integer_.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/744/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/745,https://api.github.com/repos/apache/incubator-stormcrawler/issues/745,incubator-stormcrawler,481038511,745,Fetcher bolts generate metrics for HTTP status,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-08-15T07:58:07Z,2019-08-15T08:16:05Z,This will allow spotting whether the crawl is being too aggressive given the bandwith or other issues.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/745/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/746,https://api.github.com/repos/apache/incubator-stormcrawler/issues/746,incubator-stormcrawler,481043461,746,FetcherBolt skips tuples which have spent too much time in queues ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-08-15T08:13:42Z,2019-08-15T08:16:05Z,Slow servers tend to produce queues of increasing length with the risk of the spout generating the same URLs more than once after a while. A new config `fetcher.timeout.queue` will ack URLs from the queues after N seconds; the value should correspond to the topology timeout.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/746/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/747,https://api.github.com/repos/apache/incubator-stormcrawler/issues/747,incubator-stormcrawler,488613172,747,CharsetIdentification crashes on binary content,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-09-03T13:40:43Z,2019-09-03T13:58:52Z,Processing `http://www.estrongs.com/eshelp/en/ES_File_Explorer_User_Manual3.0.htm` makes the CharsetIdentification throw an exception which escalates and terminates the worker. We should catch the exception instead and return null for the charset. The parser will then fail to parse the document and generate an ERROR status.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/747/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/748,https://api.github.com/repos/apache/incubator-stormcrawler/issues/748,incubator-stormcrawler,490752769,748,Fetch the website but does not discover anything.,AliAzG,12786596,Ali Aminzadeh Gohari,ali.azgohari@gmail.com,CLOSED,2019-09-08T13:13:06Z,2019-09-09T06:01:48Z,"Hi.
I am trying to crawl the following websites:
`[""https://www.modiseh.com/"", ""https://www.digistyle.com"", ""https://snapp.ir/"", ""https://www.tabnak.ir/"", ""https://www.digikala.com""]`
StromCrawler fetch these websites but does not discover anything!
This is my output in **Solr**:
`{
  ""responseHeader"":{
    ""status"":0,
    ""QTime"":0},
  ""response"":{""numFound"":5,""start"":0,""docs"":[
      {
        ""url"":""https://snapp.ir/"",
        ""host"":""snapp.ir"",
        ""status"":""FETCHED"",
        ""metadata.isSitemap"":[""false""],
        ""nextFetchDate"":""2019-09-09T13:01:09Z""},
      {
        ""url"":""https://www.digistyle.com"",
        ""host"":""www.digistyle.com"",
        ""status"":""FETCHED"",
        ""metadata.isSitemap"":[""false""],
        ""nextFetchDate"":""2019-09-09T13:01:10Z""},
      {
        ""url"":""https://www.tabnak.ir/"",
        ""host"":""www.tabnak.ir"",
        ""status"":""FETCHED"",
        ""metadata.isSitemap"":[""false""],
        ""nextFetchDate"":""2019-09-09T13:01:13Z""},
      {
        ""url"":""https://www.digikala.com"",
        ""host"":""www.digikala.com"",
        ""status"":""FETCHED"",
        ""metadata.isSitemap"":[""false""],
        ""nextFetchDate"":""2019-09-09T13:01:14Z""},
      {
        ""url"":""https://www.modiseh.com/"",
        ""host"":""www.modiseh.com"",
        ""status"":""FETCHED"",
        ""metadata.isSitemap"":[""false""],
        ""nextFetchDate"":""2019-09-09T13:01:14Z""}]
  }}
`
And this is my `crawler-conf.yaml`:
` metadata.persist:
   - _redirTo
   - error.cause
   - error.source
   - isSitemap
   - isFeed

  http.agent.name: ""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36""
  http.agent.version: ""537.36""
  http.agent.description: ""Free open-source web browser developed by Google. Chromium is the name of the open source project behind Google Chrome, released under the BSD license.""
  http.agent.url: ""http://www.google.com/chrome""
  http.agent.email: ""google@someorganization.com""
  http.content.limit: -1`
Where is the problem?
Thanks!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/748/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/749,https://api.github.com/repos/apache/incubator-stormcrawler/issues/749,incubator-stormcrawler,491106730,749,Enable extension parsing for SitemapParser ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-09-09T13:46:54Z,2020-07-17T09:16:53Z,"https://github.com/crawler-commons/crawler-commons/pull/218/ introduced support for sitemap extensions. 
These are not active by default and should be made configurable. The extension data found (if any) would be added to the outlink metadata and could therefore be used by a ParseFilter.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/749/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/749,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMDk5NDgyNQ==,incubator-stormcrawler,630994825,749,NA,evanhalley,897306,Evan Halley,,NA,2020-05-19T18:18:33Z,2020-05-19T18:18:33Z,"I'm curious about the implementation for this one.  It looks the sitemap extension attributes are regular java objects (instead of a Map<String,String> for example).  This means we would essentially need a helper class that can convert an extension attributes class from POJO to Strings that we could then store in the metadata object attached to the Outlink.  You could then access them by the keys as specified in the Sitemap XML.  

For example, using the key **video:duration** to get the video duraiton out of the metadata object.

Would an implementation like this be a solution for this issue?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMDk5NDgyNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/749,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMTI3ODAzNg==,incubator-stormcrawler,631278036,749,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2020-05-20T07:00:53Z,2020-05-20T07:00:53Z,"Hi @evanhalley, yes and some of the attributes are itself complex objects, eg. ""video:price"".

Maybe it's better to split the implementation into two parts:
1. add `asMap()` methods to the attribute objects in [crawler-commons](https://github.com/crawler-commons/crawler-commons/). That seems better maintainable than implementing it in storm-crawler. There are already `toString()` methods for the attributes. The `asMap()` method should return a Map<String, String[]> because some attributes are multi-valued, eg. video:price which can be specified using multiple currencies.
2. in storm-crawler: add the code to enable the sitemap extensions by a configuration property and to add the attributes to the metadata. Maybe it's worth to discuss the following points:
   - enable all extensions or make it configurable which extensions
   - (optionally) prefix the metadata keys - `sitemap.video:price`, cf. #776 

What's your opinion?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMTI3ODAzNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/749,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMTMwNTMzNQ==,incubator-stormcrawler,631305335,749,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-05-20T07:55:52Z,2020-05-20T07:55:52Z,"thanks @evanhalley and @sebastian-nagel 

I had a first prototype to deal with images only and looked like that 

```
  Map<Extension, ExtensionMetadata[]> attributes = smurl.getAttributes();
                if (attributes != null) {
                    // handle image only for now
                    ExtensionMetadata[] emds = attributes.getOrDefault(Extension.IMAGE,
                            new ExtensionMetadata[] {});
                    for (ExtensionMetadata emd : emds) {
                        ImageAttributes e = (ImageAttributes) emd;
                        String val = e.getCaption();
                        if (val != null) {
                            customKeyVal.add(Extension.IMAGE.name()+"".caption"");
                            customKeyVal.add(val);
                        }
                        val = e.getGeoLocation();
                        if (val != null) {
                            customKeyVal.add(Extension.IMAGE.name()+"".geolocation"");
                            customKeyVal.add(val);
                        }
                        val = e.getTitle();
                        if (val != null) {
                            customKeyVal.add(Extension.IMAGE.name()+"".title"");
                            customKeyVal.add(val);
                        }
                        URL u = e.getLicense();
                        if (u != null) {
                            customKeyVal.add(Extension.IMAGE.name()+"".license"");
                            customKeyVal.add(u.toExternalForm());
                        }
                        u = e.getLoc();
                        if (u != null) {
                            customKeyVal.add(Extension.IMAGE.name()+"".loc"");
                            customKeyVal.add(u.toExternalForm());
                        }
                    }
                }
```
and a config element to declare that we wanted the images extensions. The plan was to extend to the other types in a similar way, however, as suggested by @sebastian-nagel, having a way of getting the Map from crawler-commons would be a lot nicer and would require less code in StormCrawler. 

+1 to using a prefix as well.


","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMTMwNTMzNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/749,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMTYxNDM0Ng==,incubator-stormcrawler,631614346,749,NA,evanhalley,897306,Evan Halley,,NA,2020-05-20T17:23:48Z,2020-05-20T17:23:48Z,"1) I like splitting it into two pieces, one piece in crawler-commons and the other in storm crawler. More manageable and can be beneficial to others who have a crawler-commons dependency. 

2) I like the granular configurability and should be painless to implement (vs. an on/off for all extensions), especially if there is CPU overhead in doing extension parsing.

And +1 for using the prefix as well.

I'll submit an issue to crawler-commons and starting working on that piece.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMTYxNDM0Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/749,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMjA2MTI4NQ==,incubator-stormcrawler,632061285,749,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-05-21T12:34:50Z,2020-05-21T12:34:50Z,"that would be great, thanks @evanhalley ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzMjA2MTI4NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/749,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY0OTQ0MzQ0OA==,incubator-stormcrawler,649443448,749,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-06-25T10:05:20Z,2020-06-25T10:05:20Z,"Hi @evanhalley, crawler-commons 1.1 should be released soon but there is a [release candidate](https://groups.google.com/d/msg/crawler-commons/d-voPj5GRLc/R0ulQJOjBAAJ) for it - just in case you fancy working on this issue ;-)

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY0OTQ0MzQ0OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/749,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY0OTU5MDcxNQ==,incubator-stormcrawler,649590715,749,NA,evanhalley,897306,Evan Halley,,NA,2020-06-25T14:37:39Z,2020-06-25T14:37:39Z,"@jnioche sounds great, I'll continue by work on implementing this enhancement ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY0OTU5MDcxNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/749,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1MTI1MzY4OQ==,incubator-stormcrawler,651253689,749,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-06-29T17:20:01Z,2020-06-29T17:20:01Z,Depends on #807 ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1MTI1MzY4OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/750,https://api.github.com/repos/apache/incubator-stormcrawler/issues/750,incubator-stormcrawler,494409531,750,"Index pages with content=""noindex,follow"" meta tag",AliAzG,12786596,Ali Aminzadeh Gohari,ali.azgohari@gmail.com,CLOSED,2019-09-17T05:32:05Z,2020-07-16T09:44:40Z,"Some pages with `<meta name=""robots"" content=""noindex,follow""/> ` tag, can not get indexed in _docs_ in SOLR.
Need to add some configs to skip these kinds of tags.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/750/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/750,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1OTMwMTM0NA==,incubator-stormcrawler,659301344,750,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-07-16T09:44:40Z,2020-07-16T09:44:40Z,"There can be legitimate reasons to ignore robots directives from html meta tags or http headers. Have added the functionality to do so in 7077243b

The following elements are now in the default configuration

```
  # ignore directives from robots.txt files?
  http.robots.file.skip: false
  
  # ignore robots directives from the http headers?
  http.robots.headers.skip: false
  
  # ignore robots directives from the html meta?
  http.robots.meta.skip: false
```
There is a breaking change as the previous config name for the robots files was `http.skip.robots`, which I changed to `http.robots.file.skip`","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1OTMwMTM0NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/751,https://api.github.com/repos/apache/incubator-stormcrawler/issues/751,incubator-stormcrawler,494523883,751,OKHttp configure authentication for proxies,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-09-17T09:58:55Z,2019-10-18T10:13:54Z,"we can currently select the host and port of the proxy to use, but not a username nor password","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/751/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/751,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU0MzY1MTU2MA==,incubator-stormcrawler,543651560,751,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-10-18T10:11:17Z,2019-10-18T10:11:17Z,"httpclient already supports it since 898043836769b43867aae689

just need to add it to okhttp","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU0MzY1MTU2MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/753,https://api.github.com/repos/apache/incubator-stormcrawler/issues/753,incubator-stormcrawler,495128486,753,ES spouts control how long the search is allowed to take with timeout,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-09-18T10:14:17Z,2019-09-18T10:27:00Z,"This should be optional and configurable. Getting results in a timely fashion is important for the spouts, even if it means getting incomplete results.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/753/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/754,https://api.github.com/repos/apache/incubator-stormcrawler/issues/754,incubator-stormcrawler,496288520,754,Make URLBuffer configurable + AbstractURLBuffer uses URLPartitioner  ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-09-20T11:01:25Z,2019-09-20T11:03:05Z,This way the URLBuffer can create queues per domain or IP and not just hostname. Otherwise using SimpleURLBuffer while using domain as a key for sharding / grouping doesn't work for the HybridSpout -> we send queries on a configurable field name but the values correspond to the host anyway. ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/754/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/755,https://api.github.com/repos/apache/incubator-stormcrawler/issues/755,incubator-stormcrawler,497132403,755,Implement WARC spout,sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2019-09-23T14:27:05Z,2020-06-25T10:01:18Z,"A ""WARC spout"" could read records from WARC files and emit tuples <URL, content, metadata> into the topology, similar as done by FetcherBolt. This would allow
- to reproducibely test and benchmark the topology (parser, indexer and status update bolts) with the same ""frozen"" data
- to use parts of a crawl topology to process historic data from WARC files using the same parsers and indexers
- to easily rewrite or (re)index WARC files, cf. #567 ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/755/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/755,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUzNDE5MDk4Ng==,incubator-stormcrawler,534190986,755,NA,kkrugler,66217,Ken Krugler,ken@transpac.com,NA,2019-09-23T17:02:40Z,2019-09-23T17:02:40Z,"Just FYI, there's a Common Crawl fetcher that's part of the flink-crawler project, which we used extensively during testing as a way of having a large-scale, reproducible crawl. See https://github.com/ScaleUnlimited/flink-crawler/tree/master/src/main/java/com/scaleunlimited/flinkcrawler/fetcher/commoncrawl","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUzNDE5MDk4Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/755,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUzNTUwNjQ2NA==,incubator-stormcrawler,535506464,755,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2019-09-26T13:39:54Z,2019-09-26T13:39:54Z,"Thanks, @kkrugler: a fetcher which gets the content from WARC files via a CDX index would be a further step. For now, my idea was simpler: just consume a list of WARC files and emit all records into the topology. It's just a ""replay"" of an already recorded crawl.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUzNTUwNjQ2NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/756,https://api.github.com/repos/apache/incubator-stormcrawler/issues/756,incubator-stormcrawler,498925292,756,okhttp protocol: trimmed content because of content limit not reliably marked,sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2019-09-26T14:32:30Z,2019-09-26T15:58:55Z,"(see [NUTCH-2729](https://issues.apache.org/jira/browse/NUTCH-2729) and commoncrawl/nutch#10 for the same issue in Nutch)

The marking of trimmed content (by content limit) is not reliable and reproducibly fails for compressed or chunked content, or when there is no `Content-Length` header: in this case marking as `http.trimmed: true` in metadata checks whether the internal buffer of okhttp holds more data than requested. For a reliable detection we need to request one byte more than the configured `http.content.limit`. Esp. for compressed content the internal buffer of okhttp tends to hold exactly the number of requested bytes.

One example, fetching a 9 MB sitemap with `http.content.limit: 1048576` and `http.store.headers: true`:
```
> java -cp ... com.digitalpebble.stormcrawler.protocol.okhttp.HttpProtocol ... http://localhost/sitemap.xml
http://localhost/sitemap.xml
date: Thu, 26 Sep 2019 14:03:25 GMT
server: Apache/2.4.29 (Ubuntu)
transfer-encoding: chunked
vary: Accept-Encoding
last-modified: Mon, 19 Mar 2018 07:05:39 GMT
keep-alive: timeout=5, max=100
_request.headers_: GET /sitemap.xml 
...
Accept-Encoding: gzip


...
_response.ip_: 127.0.0.1
_response.headers_: HTTP/1.1 200 OK
...
Vary: Accept-Encoding
Content-Encoding: gzip
Keep-Alive: timeout=5, max=100
Connection: Keep-Alive
Transfer-Encoding: chunked
Content-Type: application/xml



status code: 200
content length: 1048576
fetched in : 157 msec
```

The content has exactly the size of the limit but not trimming/truncation marked.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/756/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/756,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUzNTU3MTI3NA==,incubator-stormcrawler,535571274,756,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-09-26T15:58:55Z,2019-09-26T15:58:55Z,thanks @sebastian-nagel ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUzNTU3MTI3NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/758,https://api.github.com/repos/apache/incubator-stormcrawler/issues/758,incubator-stormcrawler,499496809,758,langID parse filter gets stuck,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-09-27T15:01:47Z,2019-09-27T15:03:28Z,"On URLs such as 

https://about.gitlab.com/handbook/marketing/product-marketing/demo/ct-files/gke-setup.html

which contains a ridiculously long token (1.2M chars), the langID filter gets stuck when trying to use regular expression to filter the content.

The solution is to limit the amount of text to be used BEFORE sending to the langID library.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/758/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/759,https://api.github.com/repos/apache/incubator-stormcrawler/issues/759,incubator-stormcrawler,501005464,759,Kibana status dashboard import fails,jdpedrie,89034,John Pedrie,john@pedrie.com,CLOSED,2019-10-01T16:22:06Z,2019-10-10T10:47:51Z,"Following the [instructions](https://github.com/DigitalPebble/storm-crawler/blob/master/external/elasticsearch/README.md#kibana) for importing dashboards, I receive an error when importing the `Top-Hosts` visualization from `status.json`:

> Could not locate that index-pattern-field (id: metadata.hostname)

When inspecting data in the index, `metadata.hostname` does appear as expected.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/759/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/759,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUzNzM1MTAwOQ==,incubator-stormcrawler,537351009,759,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-10-02T06:09:24Z,2019-10-02T06:09:24Z,"thanks @jdpedrie, I have updated the instructions in the README. Will try to reproduce the steps later and see if I am getting the same problem","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUzNzM1MTAwOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/759,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUzNzUzOTU4OA==,incubator-stormcrawler,537539588,759,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-10-02T15:11:20Z,2019-10-02T15:11:20Z,Did you load the dashboards before running the crawl? or was the crawl topology already started?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUzNzUzOTU4OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/759,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUzNzU0MzIwMA==,incubator-stormcrawler,537543200,759,NA,jdpedrie,89034,John Pedrie,john@pedrie.com,NA,2019-10-02T15:19:36Z,2019-10-02T15:19:36Z,The crawl was already begun.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUzNzU0MzIwMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/759,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUzODExMjAxNg==,incubator-stormcrawler,538112016,759,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-10-03T20:20:50Z,2019-10-03T20:20:50Z,"Weird, could you please reload the index pattern, check that _metadata.hostname_ is listed and re-import the dashboard?

I am tempted to add a field explicitly in the mapping ('_key_'?) and refer to it in the visualization instead of relying on something that can vary from one configuration to the next. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUzODExMjAxNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/759,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUzODEyMjQxMA==,incubator-stormcrawler,538122410,759,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-10-03T20:49:08Z,2019-10-03T20:49:08Z,"#761 should prevent this in the future. For your existing crawl, reloading the index pattern should do the trick. Let me know how it goes.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDUzODEyMjQxMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/759,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU0MDUxMzAxNg==,incubator-stormcrawler,540513016,759,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-10-10T10:47:51Z,2019-10-10T10:47:51Z,"Closing for now, #761 seems to be working. Please reopen if necessary","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU0MDUxMzAxNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/761,https://api.github.com/repos/apache/incubator-stormcrawler/issues/761,incubator-stormcrawler,502289336,761,ES specify field used for grouping the URLs explicitly in mapping,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-10-03T20:46:48Z,2019-10-03T20:48:10Z,"The default value was '_metadata.hostname_' and wasn't in the mapping for status but created when the documents get indexed. This was also misleading when the URL was based on domain or IP + caused issued when trying to load the Kibana dashboard before starting the crawl.

Instead, we'll have a default value 'key' which will be specified in the mapping. Any existing crawl can still specify the previous field name of course.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/761/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/762,https://api.github.com/repos/apache/incubator-stormcrawler/issues/762,incubator-stormcrawler,502709619,762,Use search after for pagination in HybridSpout,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-10-04T15:42:47Z,2019-10-11T12:27:13Z,"When retrieving URLs for a particular host with a term query, we could use [search after](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-body.html#request-body-search-search-after) to avoid retrieving URLs we already know. 

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/762/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/765,https://api.github.com/repos/apache/incubator-stormcrawler/issues/765,incubator-stormcrawler,513961315,765,Filter queries in ES can be defined as lists,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-10-29T14:30:30Z,2019-10-29T15:01:46Z,"instead of being aggregated into a single entry

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/765/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/765,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU0NzQ2NTE3NA==,incubator-stormcrawler,547465174,765,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-10-29T15:01:45Z,2019-10-29T15:01:45Z,implemented in 7a56550913dbcb1d7e73d29afab23b3fd60a6961,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU0NzQ2NTE3NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/766,https://api.github.com/repos/apache/incubator-stormcrawler/issues/766,incubator-stormcrawler,513983552,766,es.status.bucket.sort.field can be take a list of values,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-10-29T14:58:05Z,2019-10-29T15:00:53Z,"the hybrid spout needs _url_ to be used as another sort field, instead of hardcoding we can add it via the config
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/766/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/768,https://api.github.com/repos/apache/incubator-stormcrawler/issues/768,incubator-stormcrawler,522263281,768,Crawl-delay handling: allow `fetcher.max.crawl.delay` exceed 300 sec.,sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2019-11-13T14:36:37Z,2019-12-06T09:27:21Z,"Content from sites with a max. crawl delay larger than 300 seconds is ignored as this is the internal default max. delay of [crawler-commons' robots.txt parser](/crawler-commons/crawler-commons/blob/c9c0ac6eda91b13d534e69f6da3fd15065414fb0/src/main/java/crawlercommons/robots/SimpleRobotRulesParser.java#L78). See [NUTCH-2754](https://issues.apache.org/jira/browse/NUTCH-2754) and /crawler-commons/crawler-commons#276.

Because StormCrawler allows to fine-tune the behavior, in case the robots.txt crawl-delay exceeds the `fetcher.max.crawl.delay` (see `fetcher.max.crawl.delay.force` and #549), we might just disable the crawler-commons-internal handling of the crawl delay by passing Long.MAX_VALUE to the constructor of SimpleRobotRulesParser.

Reproducible
- by setting `fetcher.max.crawl.delay: 600` (10 min.)
- the following robots.txt on localhost:
  ```
  User-agent: *
  Allow: /
  Crawl-Delay: 301
  ```
- running
  ```
  % java -cp ... com.digitalpebble.stormcrawler.protocol.okhttp.HttpProtocol -c ... http://localhost/
  http://localhost/
  robots allowed: false
  ...
  ```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/768/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/769,https://api.github.com/repos/apache/incubator-stormcrawler/issues/769,incubator-stormcrawler,523351952,769,java.lang.ClassCastException: clojure.lang.PersistentVector cannot be cast to java.lang.String at com.digitalpebble.stormcrawler.util.ConfUtils.getString,billiamchoi,48000438,billiamchoi,,CLOSED,2019-11-15T09:20:32Z,2019-11-16T07:56:26Z,"

I follow tutorial on http://stormcrawler.net/getting-started/ by watching youtube.

After I type fallowing line on my command line

I got error on my spout

storm jar target/tutorial-1.0-SNAPSHOT.jar  org.apache.storm.flux.Flux --remote es-crawler.flux

![스크린샷 2019-11-15 오후 6 08 20](https://user-images.githubusercontent.com/48000438/68931146-4710d200-07d3-11ea-9881-a5b9164d426d.png)

the error log is like this :

java.lang.ClassCastException: clojure.lang.PersistentVector cannot be cast to java.lang.String at com.digitalpebble.stormcrawler.util.ConfUtils.getString(ConfUtils.java:74) at com.digitalpebble.stormcrawler.elasticsearch.persistence.AbstractSpout.open(AbstractSpout.java:183) at com.digitalpebble.stormcrawler.elasticsearch.persistence.AggregationSpout.open(AggregationSpout.java:96) at org.apache.storm.daemon.executor$fn__10112$fn__10127.invoke(executor.clj:609) at org.apache.storm.util$async_loop$fn__624.invoke(util.clj:482) at clojure.lang.AFn.run(AFn.java:22) at java.lang.Thread.run(Thread.java:748)

Can you guys please give me a hint or solution to this error log?

I use

elasticsearch version 7.4.2 
kibana version 7.4.2
storm version 1.2.3
and my computer is mac
 ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/769/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/769,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1NDM5MjY5MQ==,incubator-stormcrawler,554392691,769,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-11-15T15:01:39Z,2019-11-15T15:01:39Z,"Hi @billiamchoi,

In the future, could you please ask questions like these on StackOverflow with the tag 'stormcrawler'? you'd get a larger audience.

This [video](https://www.youtube.com/watch?v=KTerugU12TY) has been done more than 2 years and some of it is probably outdated. The version of SC used in the video (1.5) won't be compatible with ES 7.x anyway.

Looks like you are passing a list in the config where the code expects a String. Would you mind sharing your ES configuration file?

The error message you posted is a bit puzzling as [line 183 does not call Confutils](https://github.com/DigitalPebble/storm-crawler/blob/1.5/external/elasticsearch/src/main/java/com/digitalpebble/stormcrawler/elasticsearch/persistence/AbstractSpout.java#L183)  version 1.5 of SC.

Could you please check the version of SC in the pom file?

Thanks!

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1NDM5MjY5MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/769,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1NDUwNjY0Mg==,incubator-stormcrawler,554506642,769,NA,billiamchoi,48000438,billiamchoi,,NA,2019-11-15T19:59:42Z,2019-11-15T19:59:42Z,"in my es-conf.yaml

```
# configuration for Elasticsearch resources
  
config:
  # ES indexer bolt
  # adresses can be specified as a full URL
  # if not we assume that the protocol is http and the port 9200
  es.indexer.addresses: ""localhost""
  es.indexer.index.name: ""content""
  # es.indexer.pipeline: ""_PIPELINE_""
  es.indexer.create: false
  es.indexer.bulkActions: 100
  es.indexer.flushInterval: ""2s""
  es.indexer.concurrentRequests: 1
  es.indexer.settings:
    cluster.name: ""elasticsearch""
  
  # ES metricsConsumer
  es.metrics.addresses: ""http://localhost:9200""
  es.metrics.index.name: ""metrics""
  es.metrics.settings:
    cluster.name: ""elasticsearch""
  
  # ES spout and persistence bolt
  es.status.addresses: ""http://localhost:9200""
  es.status.index.name: ""status""
  #es.status.user: ""USERNAME""
  #es.status.password: ""PASSWORD""
  # the routing is done on the value of 'partition.url.mode'
  es.status.routing: true
  # stores the value used for grouping the URLs as a separate field
  # needed by the spout implementations
  # also used for routing if the value above is set to true 
  es.status.routing.fieldname: ""key""
  es.status.bulkActions: 500
  es.status.flushInterval: ""5s""
  es.status.concurrentRequests: 1
  es.status.settings:
    cluster.name: ""elasticsearch""
  
  ################
  # spout config #
  ################
  
  # positive or negative filters parsable by the Lucene Query Parser
  # es.status.filterQuery: 
  #  - ""-(key:stormcrawler.net)""
  #  - ""-(key:digitalpebble.com)""

  # time in secs for which the URLs will be considered for fetching after a ack of fail
  spout.ttl.purgatory: 30
  
  # Min time (in msecs) to allow between 2 successive queries to ES
  spout.min.delay.queries: 2000

  # Delay since previous query date (in secs) after which the nextFetchDate value will be reset to the current time
  # Setting this to -1 or a large value means that the ES will cache the results but also that less and less results
  # might be returned.
  spout.reset.fetchdate.after: 120

  es.status.max.buckets: 50
  es.status.max.urls.per.bucket: 2
  # field to group the URLs into buckets
  es.status.bucket.field: ""key""
  # fields to sort the URLs within a bucket
  es.status.bucket.sort.field: 
   - ""nextFetchDate""
   - ""url""
  # field to sort the buckets
  es.status.global.sort.field: ""nextFetchDate""

  # CollapsingSpout : limits the deep paging by resetting the start offset for the ES query 
  es.status.max.start.offset: 500
  
  # AggregationSpout : sampling improves the performance on large crawls
  es.status.sample: false

  # max allowed duration of a query in sec 
  es.status.query.timeout: -1

  # AggregationSpout (expert): adds this value in mins to the latest date returned in the results and
  # use it as nextFetchDate
  es.status.recentDate.increase: -1
  es.status.recentDate.min.gap: -1

  topology.metrics.consumer.register:
       - class: ""com.digitalpebble.stormcrawler.elasticsearch.metrics.MetricsConsumer""
         parallelism.hint: 1
         #whitelist:
         #  - ""fetcher_counter""
         #  - ""fetcher_average.bytes_fetched""
         #blacklist:
         #  - ""__receive.*""

```
and my storm cralwer version is 1.4 

should I use lower version of ES? 

And sorry about putting this kind of question in github issue.

It was my first question. 

In future I will use StackOverflow","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1NDUwNjY0Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/769,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1NDUyMDY5NQ==,incubator-stormcrawler,554520695,769,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-11-15T20:42:15Z,2019-11-15T20:42:15Z,"> And sorry about putting this kind of question in github issue.
> 
> It was my first question.
> 
> In future I will use StackOverflow

No problem at all!

I think the problem comes from the fact that you are using the config for the current version of SC but SC 1.4. In particular, _  es.status.bucket.sort.field_ wasn't multivalued until recently. 

Either use the [version of the conf](https://github.com/DigitalPebble/storm-crawler/blob/1.4/external/elasticsearch/es-conf.yaml) that is compatible with your version of SC, or better, use the latest SC. Please note that the  conf on the master branch does not match the latest release, again, get it from [tag 1.15](https://github.com/DigitalPebble/storm-crawler/blob/1.15/external/elasticsearch/es-conf.yaml). 

Let me know how it goes.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1NDUyMDY5NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/769,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1NDYxMjE1OQ==,incubator-stormcrawler,554612159,769,NA,billiamchoi,48000438,billiamchoi,,NA,2019-11-16T07:12:16Z,2019-11-16T07:12:16Z,"Thanks, @jnioche 
I solve the problem by restart storm crawler based project version 1.15
I git cloned master branch of storm cralwer which I think It is version 1.14
you gave me ilnk of tag 1.15 version of storm crawler and I changed es-conf.yaml
It works fine thanks to you

I have extra question..

Top K100 2016.txt file works very well as seeds.txt

but I want to crawl website for a instance..

https://www.kaggle.com/
https://www.data.gov/

I noticed that Injector works fine and 
elasticsearch said that it is  status: 'discovered'
but I don't get any of status:fetched by those kind of websites
Is there difference between topk2016 sites and two websites that I mentioned?

Anyway It was really kind of you to reply on my issue

Sincerely, billiamchoi
 

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1NDYxMjE1OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/769,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1NDYxNDYzNg==,incubator-stormcrawler,554614636,769,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-11-16T07:56:26Z,2019-11-16T07:56:26Z,I can't see anything obviously wrong with these 2 sites. Please ask on StackOverflow if you can't solve the problem.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU1NDYxNDYzNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/770,https://api.github.com/repos/apache/incubator-stormcrawler/issues/770,incubator-stormcrawler,531831782,770,ES upgraded to 7.5.0,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-12-03T09:07:56Z,2019-12-09T13:07:34Z,https://www.elastic.co/guide/en/elasticsearch/reference/current/release-notes-7.5.0.html,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/770/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/771,https://api.github.com/repos/apache/incubator-stormcrawler/issues/771,incubator-stormcrawler,532072873,771,Tika 1.23,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-12-03T15:38:14Z,2019-12-30T08:30:50Z,"https://dist.apache.org/repos/dist/dev/tika/CHANGES-1.23.txt
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/771/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/773,https://api.github.com/repos/apache/incubator-stormcrawler/issues/773,incubator-stormcrawler,533984860,773,Archetype for SC+Elasticsearch,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-12-06T13:32:11Z,2020-01-16T10:39:45Z,"Most people use StormCrawler with Elasticsearch as a backend. Providing a basic Maven archetype for it could greatly simplify the initial setup and reduce risks of version conflicts like we had in #759 .

 ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/773/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/776,https://api.github.com/repos/apache/incubator-stormcrawler/issues/776,incubator-stormcrawler,537565050,776,Prefix protocol metadata to avoid that internal metadata fields are accidentally overwritten,sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2019-12-13T13:59:31Z,2020-05-05T13:10:06Z,"HTTP protocol implementations add all HTTP response header fields to the response metadata. The FetcherBolt merges the response metadata into the metadata which is passed forward in the topology as part of the tuples <url, content, metadata>. Existing key-value(s) pairs (persisted in the status index) are overwritten and later eventually stored in the status index (if listed in ""metadata.persist"") or even transferred to outlinks (""metadata.transfer"").

This allows to easily use the response header values for requests, e.g. cookies or ""ETag"".

However, webadmins are free to send any header back. This may cause unwanted collisions with metadata keys used by crawler-internal classes. E.g. if the server responds with non-standard headers ""HostName"" or ""Depth"". Or even standard headers such as ""Last-modified"" which require to follow a specific format for internal use.

To avoid collisions: Why not prefix protocol metadata: `protocol.content-type` or `http.content-type`? This would also make it clear which component sets the metadata - similar to the prefixes `fetch.` and `parse.` already used. The draw-back would be that users are required to update the configuration.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/776/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/776,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU2NTk5MDE3OQ==,incubator-stormcrawler,565990179,776,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-12-16T10:01:36Z,2019-12-16T10:01:36Z,"Good summary of the existing behaviour and interesting point, thanks. Not sure how frequent this issue would arise but certainly worth considering, although as you pointed out there would be a cost in updating the configs and code. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU2NTk5MDE3OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/776,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU2NjA0OTQ4Ng==,incubator-stormcrawler,566049486,776,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2019-12-16T12:56:19Z,2019-12-16T12:56:19Z,">  Not sure how frequent this issue would arise

Not very often for non-standard headers, but it happens. I've counted HTTP header names for a random selection of 250 WARC files and got about 14,000 unique lowercased header names, among them:
- 220 x `hostname` - luckily without effect because `metadata.hostname` (old configuration, now field `key` outside metadata and safe) is always set from the URL (to address #684 by reindexing was the correct decision)
- 5 x `ip`, e.g. https://dnews.dn.ua/news/735755 :
```
HTTP/1.1 200 OK
Server: nginx
...
ip: 107.23.218.4
```
If URLs are partitioned ""byIP"", the `ip` header field would overwrite the persisted IP eventually causing duplicates in the status index, same URL in various partitions.

So, it's probably more a matter of time and size of the crawl until a collision happens. It's also a minor security issue. The prefix would then also mark all prefixed metadata names as unsafe, same as for `parse.keywords` - you cannot trust the value unless you crawl your own content.

> a cost in updating the configs and code.

For the code: At a first glance, there aren't so many changes: the protocol implementations and few more places.
For the user config: A configurable prefix if empty would allow to delay any changes. That's important if you want to keep your status index and cannot reindex immediately.

An alternative solution would be to force users to explicitly configure the HTTP header names put into the response metadata:
```yaml
  # lists the (HTTP) protocol response headers put into
  # response metadata as pairs <key, value(s)>
  # Header names are lowercased. Metadata persisted under the
  # same name is overwritten by the response metadata.
  metadata.protocol.response:
   - etag
   - set-cookie
```","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU2NjA0OTQ4Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/776,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU2ODE5NzczNQ==,incubator-stormcrawler,568197735,776,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-12-21T17:27:35Z,2019-12-21T17:27:35Z,"hi @sebastian-nagel 

> An alternative solution would be to force users to explicitly configure the HTTP header names put into the response metadata:

Probably easier to use the prefix instead, there's already enough config everywhere ;-)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU2ODE5NzczNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/776,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNDAzMjU2Mg==,incubator-stormcrawler,624032562,776,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-05-05T12:43:12Z,2020-05-05T12:43:12Z,"@sebastian-nagel just came across such a case

> curl -i ""https://cdn.prod.www.spiegel.de/images/d1f3784e-24cd-41fa-b6be-f85a19f9cea1_w920_r1.77_fpx45.33_fpy50.jpg""
> HTTP/2 200 
> date: Tue, 05 May 2020 12:40:42 GMT
> content-type: image/jpeg
> content-length: 94287
> cache-control: public, max-age=604800, s-maxage=604800
> etag: ""0c3fe0e90ffa24814db2517fac84b6a1""
> expires: Tue, 12 May 2020 06:45:30 GMT
> last-modified: Tue, 05 May 2020 06:44:53 GMT
> server: Footprint Distributor V6.1.1162
> alt-svc: clear
> x-cache: MISS
> x-cache-grace: 300.000
> x-ttl: 1800.000
> source: default
> age: 21345
> accept-ranges: byte

annoyingly I had a **source** metadata already in use and it got overridden :-)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNDAzMjU2Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/776,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNDA0NTMwMA==,incubator-stormcrawler,624045300,776,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2020-05-05T13:10:06Z,2020-05-05T13:10:06Z,"Resembles me about one statement in this [discussion](https://groups.google.com/d/msg/common-crawl/YFCUCy6drm8/3rEPZ9P8AwAJ): ""the maxim that web-scale data will provide an example breaking every single one of your shortcuts.""","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYyNDA0NTMwMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/777,https://api.github.com/repos/apache/incubator-stormcrawler/issues/777,incubator-stormcrawler,537565187,777,status index / Adaptive scheduler: get rid of last-modified dates in non-ISO date format,sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2019-12-13T13:59:50Z,2020-07-08T15:36:51Z,"There are still quite a few ""last-modified"" dates not in ISO date format, e.g.:
``` json
""_source"" : {
  ""url"" : ""https://zz.te.ua/feed/"",
  ""status"" : ""FETCHED"",
  ""metadata"" : {
    ""last-modified"" : [
      ""Thu, 12 Dec 2019 20:00:57 GMT""
    ],
    ""signature"" : [
      ""9fde2d107d3339060a178fa8a59a55da""
    ],
    ""fetchInterval"" : [
      ""432""
    ],
    ""isFeed"" : [
      ""true""
    ],
    ""fetch%2EstatusCode"" : [
      ""200""
    ],
    ""signatureChangeDate"" : [
      ""2019-12-12T21:44:57.948Z""
    ],
    ""hostname"" : ""zz.te.ua""
  },
  ""nextFetchDate"" : ""2019-12-13T13:02:41.000Z""
}
```

Protocol implementations expect the last-modified time to be in ISO format (see #673) - if the ISO format is not followed, they do not send the ""If-not-modified-since"" header.

With #496 the adaptive scheduler uses the ISO date-time format to store the last-modified time.
However, the adaptive scheduler only sets the last-modified time when the comparison of the current and the previous signature indicates a content change. It never sets the last-modified time
1. for the initial fetch of a page (no signatures to compare) or
2. if the pages has not changed (HTTP 304 or same signature)
3. if another scheduler is used

In these situations, if the server sends a ""Last-modified"" header with the response, this value overwrites the existing one. There two issues with the value from the ""Last-modified"" header:
- the date format
- we cannot trust the date:
  - it could be a time in the future or even implausible far in the past
  - or just off few hours because of time zone issues or just the clock going wrong

""If-modified-since"" requests should always use the date of the last fetch (if successful).

To overcome the issue:
1. use a different metadata field than ""last-modified"" for either AdaptiveScheduler or to hold the response metadata (see #776)
2. let AdaptiveScheduler set ""last-modified"" for initial fetches (or first successful fetch after a fetch error or redirect status)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/777/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/777,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU2NTQ1NDMzNg==,incubator-stormcrawler,565454336,777,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2019-12-13T14:10:42Z,2019-12-13T14:10:42Z,"Alternative solution without changes of metadata field names:
-  AdaptiveScheduler
   - sets ""signatureChangeDate"" also at the initial fetch
   - always overwrites ""last-modified"" with ""signatureChangeDate"" so that the ""last-modified"" field holds a well-formatted date or is empty after non-successful fetches
- both ""last-modified"" and ""signatureChangeDate"" are required to be persisted (both containing the same value)","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU2NTQ1NDMzNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/777,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU2OTg4MTE4NQ==,incubator-stormcrawler,569881185,777,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2019-12-31T07:31:45Z,2019-12-31T07:31:45Z,"hi @sebastian-nagel 
sorry for the late reply

could we simply ignore _last-modified_ altogether and rely on _signatureChangeDate_ only? in that case the 2nd option w/o change of metadata would be preferable and whatever is set by the servers for  _last-modified_ becomes irrelevant.

how would this affect the default behaviour when not using the AdaptiveScheduler?




","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU2OTg4MTE4NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/777,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU3MjA4OTQxMQ==,incubator-stormcrawler,572089411,777,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2020-01-08T14:40:32Z,2020-01-08T14:40:32Z,"1. we would also need to set _signatureChangeDate_ for successful fetches (HTTP 200 Ok)
   - (using AdaptiveScheduler) for the initial fetch
   - (without AdaptiveScheduler) for all successful fetches: could be done in DefaultScheduler
2. the change affects all HTTP protocol implementations: read the value sent in the ""If-Modified-Since"" header from _signatureChangeDate_ instead of _last-modified_ - But what about #776? Dependent on the decision there, we could continue to use _last-modified_ and set it appropriately in both schedulers.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU3MjA4OTQxMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/777,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU3MjUyOTc1OA==,incubator-stormcrawler,572529758,777,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-01-09T11:56:47Z,2020-01-09T11:56:47Z,I am inclined to postponed this after the next release. This and #776 are not trivial and I'd rather have time to think it through without blocking the release. What do you think @sebastian-nagel ?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU3MjUyOTc1OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/777,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU3Mjk1ODU2OQ==,incubator-stormcrawler,572958569,777,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2020-01-10T09:56:41Z,2020-01-10T09:56:41Z,Ok to carefully think about a good solution.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDU3Mjk1ODU2OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/778,https://api.github.com/repos/apache/incubator-stormcrawler/issues/778,incubator-stormcrawler,543339169,778,ES merge seed injection into crawl topology,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2019-12-29T08:43:08Z,2019-12-29T09:33:11Z,"The seed injection step is often confusing for beginners and in 99% of cases the topology will run on a single machine, often in local mode. Adding the file spout to the crawl topology will greatly simplify things. More advanced users will tweak the file to their needs anyway. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/778/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/780,https://api.github.com/repos/apache/incubator-stormcrawler/issues/780,incubator-stormcrawler,545684617,780,Kibana- change format of templates to ndjson,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2020-01-06T11:40:58Z,2020-01-06T11:46:58Z,the old json format is not supported anymore,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/780/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/782,https://api.github.com/repos/apache/incubator-stormcrawler/issues/782,incubator-stormcrawler,548129447,782,"HybridSpout get key for results when prefixed by ""metadata.""",jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2020-01-10T15:05:33Z,2020-01-10T15:14:02Z,ES stores the content of _metadata_ in a submap and a getting a key like 'metadata.hostname' won't retrieve anything.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/782/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/783,https://api.github.com/repos/apache/incubator-stormcrawler/issues/783,incubator-stormcrawler,548159449,783,AggregationSpout to store sortValues for the last result of each bucket,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2020-01-10T16:02:01Z,2020-01-10T16:02:45Z,so that the HybridSpout can use them and avoid getting URLs that the aggregation already got. ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/783/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/784,https://api.github.com/repos/apache/incubator-stormcrawler/issues/784,incubator-stormcrawler,548181026,784,support retry-after in FetcherBolt,jnioche,218319,Julien Nioche,julien@digitalpebble.com,OPEN,2020-01-10T16:44:47Z,2020-07-17T09:17:47Z,"https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Retry-After

if a site is asking for a delay, we should enforce it in the internal queues of the FetcherBolt.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/784/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/784,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1ODc5MjAzNQ==,incubator-stormcrawler,658792035,784,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-07-15T14:11:28Z,2020-07-15T14:11:28Z,"Could use the snippet below

```
// has a retry after? 503 (Service Unavailable) or 429 (Too Many Requests) 
                	// but also a permanent redir (301)
                    String retry_after = mergedMD.getFirstValue(""Retry-After"");
                    if (retry_after != null){
                    	// in seconds?
                    	if (retry_after.matches(""[0-9]+"")) {
                    		int rety_after_secs = Integer.parseInt(retry_after);
                    	}
                    	else {
                    		// expressed as a date
                    		// or a delay in secs
                    		SimpleDateFormat format = new SimpleDateFormat(""EEE, dd MMM yyyy HH:mm:ss zzz"");
                    		try {
                    			Date d = format.parse(retry_after);
                    			// pass the date
                    			d.toInstant().toString();
                    		}
                    		catch (ParseException pe) {
                    			LOG.debug(""Incorrect date found for retry-after: {} - {}"",retry_after, url);
                    		}
                    	}
                    }
```","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1ODc5MjAzNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/785,https://api.github.com/repos/apache/incubator-stormcrawler/issues/785,incubator-stormcrawler,548419654,785,Import Kibana dashboards using the API,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2020-01-11T11:40:57Z,2020-01-11T11:42:44Z,with a script to make it even easier. Should be simpler than doing it manually through the UI.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/785/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/786,https://api.github.com/repos/apache/incubator-stormcrawler/issues/786,incubator-stormcrawler,549652407,786,include Kibana script and resources in ES archetype ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2020-01-14T15:44:33Z,2020-01-14T15:46:10Z,"so that users do not have to download SC at all
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/786/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/787,https://api.github.com/repos/apache/incubator-stormcrawler/issues/787,incubator-stormcrawler,566188098,787,Allow ES to connect over a proxy,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2020-02-17T10:05:50Z,2020-02-17T11:27:14Z,"https://www.elastic.co/guide/en/elasticsearch/client/java-rest/current/java-rest-low-usage-initialization.html
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/787/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/788,https://api.github.com/repos/apache/incubator-stormcrawler/issues/788,incubator-stormcrawler,568242461,788,use regular expressions for custom number of threads per queue ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2020-02-20T11:44:05Z,2020-02-20T12:15:49Z,"Being able to define a custom number of threads for a given fetch queue is useful, however it would be even better to define them with regular expressions. This way, instead of having to list all the hostname variants for a given domain **and** still queue by hostname, we could capture them all with a regexp, making the conf file more concise and also covering yet unseen variants.

This would work for domains as well as IP addresses, if those were used in _fetcher.queue.mode_.

note: will be based on a map so the order of the matches is not guaranteed","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/788/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/791,https://api.github.com/repos/apache/incubator-stormcrawler/issues/791,incubator-stormcrawler,572186683,791,Remove deprecated methods and fields,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2020-02-27T16:11:02Z,2020-03-20T09:26:03Z,"I was hoping to release 2.0 but [STORM-3582](https://issues.apache.org/jira/projects/STORM/issues/STORM-3582?filter=allopenissues) is a massive blocker. I don't see much activity or interest in the Storm dev community, so I won't wait for the next major release to cleanup deprecated stuff. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/791/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/792,https://api.github.com/repos/apache/incubator-stormcrawler/issues/792,incubator-stormcrawler,574722021,792,Basic authentication for OKHTTP protocol,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2020-03-03T14:50:15Z,2020-03-03T14:50:45Z,"Similar to #589 

Single credentials used for all sites crawled 
_http.basicauth.user
http.basicauth.password_

Will add per-site or per-url, regexp-base mechanism for both protocol implementations separately.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/792/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/794,https://api.github.com/repos/apache/incubator-stormcrawler/issues/794,incubator-stormcrawler,578519789,794,Utility to debug / test parsefilters,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2020-03-10T11:41:39Z,2020-03-10T11:43:11Z,"Similar to what we have for testing the output of protocols, but for checking **parse filters**, e.g. given a configuration file, loads the parse filters and apply them on a URL passed as argument. 

Could run / debug within Eclipse but also on the command line e.g.

`mvn exec:java -Dexec.mainClass=""com.digitalpebble.stormcrawler.parse.ParseFilters"" -Dexec.args=""-c crawler-conf.yaml http://stormcrawler.net/""`

or to debug

`/usr/share/maven/bin/mvnDebug Dexec.mainClass=""com.digitalpebble.stormcrawler.parse.ParseFilters"" -Dexec.args=""-c crawler-conf.yaml http://stormcrawler.net/""`
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/794/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/795,https://api.github.com/repos/apache/incubator-stormcrawler/issues/795,incubator-stormcrawler,599737967,795,Running under apache storm v 2.10,ravi-b-m,28898841,Ravi M,,CLOSED,2020-04-14T17:30:17Z,2020-04-14T19:22:28Z,"I have installed the latest version of storm 2.1.0 and trying to run my topology under local mode in the local storm cluster.. I get the following exception
```
17:14:21.987 [main] INFO  o.a.s.m.StormMetricsRegistry - Started statistics report plugin...
Exception in thread ""main"" java.lang.NoSuchMethodError: org.apache.storm.LocalCluster.submitTopology(Ljava/lang/String;Ljava/util/Map;Lorg/apache/storm/generated/StormTopology;)V
	at com.digitalpebble.stormcrawler.ConfigurableTopology.submit(ConfigurableTopology.java:76)
	at abbvie.ir.pikm.CrawlTopology.run(CrawlTopology.java:119)
	at com.digitalpebble.stormcrawler.ConfigurableTopology.start(ConfigurableTopology.java:50)
	at abbvie.ir.pikm.CrawlTopology.main(CrawlTopology.java:46)
```

Is the latest version of storm supported ??
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/795/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/795,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMzU4NDk4Mg==,incubator-stormcrawler,613584982,795,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2020-04-14T17:47:15Z,2020-04-14T17:47:15Z,"There is a [development branch to run storm-crawler on Storm 2.x](https://github.com/DigitalPebble/storm-crawler/tree/2.x). However, be aware of [STORM-3582](https://issues.apache.org/jira/projects/STORM/issues/STORM-3582).","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYxMzU4NDk4Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/796,https://api.github.com/repos/apache/incubator-stormcrawler/issues/796,incubator-stormcrawler,601304960,796,parsefilters.config.file and urlfilters.config.file location,ravi-b-m,28898841,Ravi M,,CLOSED,2020-04-16T18:15:47Z,2020-04-17T12:36:09Z,"Based on this
[JSONResource.java](https://github.com/DigitalPebble/storm-crawler/blob/14ed86dbeb39e9af550f24a2914a9f32ba869463/core/src/main/java/com/digitalpebble/stormcrawler/JSONResource.java#L51)

I cannot externalize my `parsefilters.json` and `urlfilters.json`, do I need to embed them in my uber jar ?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/796/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/796,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYxNTIyMDE1MQ==,incubator-stormcrawler,615220151,796,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-04-17T12:36:09Z,2020-04-17T12:36:09Z,"yes. simply put them in src/main/resources

BTW please ask questions like these on Stackoverflow with the tag Stormcrawler.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYxNTIyMDE1MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/797,https://api.github.com/repos/apache/incubator-stormcrawler/issues/797,incubator-stormcrawler,605644251,797,Tika 1.24.1,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2020-04-23T15:43:41Z,2020-06-03T14:30:17Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/797/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/800,https://api.github.com/repos/apache/incubator-stormcrawler/issues/800,incubator-stormcrawler,626597348,800,Elasticsearch IndexerBolt not being acked correctly causing failures in spout,matiascrespof,52938071,Matias Crespo,,CLOSED,2020-05-28T15:19:52Z,2020-05-29T13:33:21Z,"We found with @jcruzmartini that elasticsearch Indexer is bolt acking before emit tuples in afterBulk method is causing ack failures in spout after timeout set in topology.

Proposed solution is change order of emit / ack in **com.digitalpebble.stormcrawler.elasticsearch.bolt.IndexerBolt** :

```
if (!failed) {
                    acked++;
                    _collector.emit(StatusStreamName, t, new Values(u,
                            metadata, Status.FETCHED));
                    _collector.ack(t);
                } else {
...
...
```
After migrate from 1.13 to 1.16 we noticed bad performance in our crawler, and also a lot of failures in the spout, after add IndexerBolt class in our project with that modification it started working correctly with great performance

@jnioche  we can create a pull request with a simple change in that class if you want

Thanks!
Matias","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/800/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/800,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNTQyODI1Mg==,incubator-stormcrawler,635428252,800,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-05-28T15:41:32Z,2020-05-28T15:41:32Z,"Hi Matias

Thanks and yes please open a PR.

That would mean that they get failed because they were treated as non acked
in time. Do you know if they actually make it to the statusupdater bolt at
all? This probably happens on a fraction of the tuples.
I suppose this would affect the performance  as the spouts would not
release more URLs tp process.

thanks again!

On Thu, 28 May 2020 at 16:20, Matias Crespo <notifications@github.com>
wrote:

> We found with @jcruzmartini <https://github.com/jcruzmartini> that
> elasticsearch Indexer is bolt acking before emit tuples in afterBulk method
> is causing ack failures in spout after timeout set in topology.
>
> Proposed solution is change order of emit / ack in
> *com.digitalpebble.stormcrawler.elasticsearch.bolt.IndexerBolt* :
>
> if (!failed) {
>                     acked++;
>                     _collector.emit(StatusStreamName, t, new Values(u,
>                             metadata, Status.FETCHED));
>                     _collector.ack(t);
>                 } else {
> ...
> ...
>
> After migrate from 1.13 to 1.16 we noticed bad performance in our crawler,
> and also a lot of failures in the spout, after add IndexerBolt class in our
> project with that modification it started working correctly with great
> performance
>
> @jnioche <https://github.com/jnioche> we can create a pull request with a
> simple change in that class if you want
>
> Thanks!
> Matias
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/DigitalPebble/storm-crawler/issues/800>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AABVJT7R7THPG3622XDOXQ3RTZ6KRANCNFSM4NNF3DWA>
> .
>


-- 



* Open Source Solutions for Text Engineering   http://www.digitalpebble.com
<http://www.digitalpebble.com>*
*http://digitalpebble.blogspot.com <http://digitalpebble.blogspot.com/>*
@digitalpebble <https://twitter.com/digitalpebble>
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNTQyODI1Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/800,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNTQ3MDUwOQ==,incubator-stormcrawler,635470509,800,NA,matiascrespof,52938071,Matias Crespo,,NA,2020-05-28T16:57:59Z,2020-05-28T16:57:59Z,"Hi @jnioche , thanks for your quick reply!

Exactly, they were treated as non acked and is only a fraction of the tuples. the tuples are failing after topology reach time out set in **topology.message.timeout.secs**.
They actually make it to the statusupdater , but at some point it stops since it reach the **topology.max.spout.pending**, so the topology gets stuck.

We are going to create a PR today. 

Thanks for your help!

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNTQ3MDUwOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/800,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNTU1NzYyMw==,incubator-stormcrawler,635557623,800,NA,jcruzmartini,6817516,Juan Cruz Martini,,NA,2020-05-28T19:45:19Z,2020-05-28T19:45:19Z,"thanks for your quick reply @jnioche I think this issue is affecting all the users that are using stormcrawler with ES, it's surprising for me why this was not reported before. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNTU1NzYyMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/800,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNTg1MDAyMw==,incubator-stormcrawler,635850023,800,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-05-29T08:39:21Z,2020-05-29T08:39:21Z,"changed the title a bit as it is not about the anchoring as such

@jcruzmartini it wasn't an easy one to spot, but you and @matiascrespof have great detective skills ;-)

Thanks again for reporting it and submitting a PR. I'll go through all the acks to see if this happens anywhere else","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNTg1MDAyMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/800,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNTk3NDkwMg==,incubator-stormcrawler,635974902,800,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-05-29T13:33:19Z,2020-05-29T13:33:19Z,Fixed by #801 ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDYzNTk3NDkwMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/802,https://api.github.com/repos/apache/incubator-stormcrawler/issues/802,incubator-stormcrawler,638674449,802,Archetype generate an absolute path for seed file,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2020-06-15T09:04:25Z,2020-09-17T12:36:47Z,"
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/802/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/802,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1NjIyMjE1Nw==,incubator-stormcrawler,656222157,802,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-07-09T16:19:01Z,2020-07-09T16:19:01Z,https://stackoverflow.com/questions/62819286/get-an-absolute-path-in-a-resource-generated-by-a-maven-archetype,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1NjIyMjE1Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/802,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1OTMwMTcxMw==,incubator-stormcrawler,659301713,802,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-07-16T09:45:27Z,2020-07-16T09:45:27Z,no luck with getting a solution for this. Will untag from 1.17,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1OTMwMTcxMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/802,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY5NDIwMTQwMg==,incubator-stormcrawler,694201402,802,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-09-17T12:36:39Z,2020-09-17T12:36:39Z,Looks like an impossible thing to do with Maven. Closing,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY5NDIwMTQwMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/806,https://api.github.com/repos/apache/incubator-stormcrawler/issues/806,incubator-stormcrawler,645653301,806,Detect changes to the seed files and reload them in the spout,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2020-06-25T15:24:57Z,2020-07-15T12:17:07Z,so that you don't need to restart the topology if you add a URL to the files ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/806/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/806,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1ODczMzQwNw==,incubator-stormcrawler,658733407,806,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-07-15T12:17:07Z,2020-07-15T12:17:07Z,"nah, just turn the topology off and back on ;-)","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1ODczMzQwNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/807,https://api.github.com/repos/apache/incubator-stormcrawler/issues/807,incubator-stormcrawler,647540348,807,Upgrade to CrawlerCommons 1.1,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2020-06-29T17:19:17Z,2020-06-29T17:25:03Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/807/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/808,https://api.github.com/repos/apache/incubator-stormcrawler/issues/808,incubator-stormcrawler,647547922,808,various dependency upgrades,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2020-06-29T17:32:32Z,2020-07-09T09:37:06Z,"`mvn versions:display-dependency-updates | grep ""\->"" | sort | uniq`

[INFO]   com.amazonaws:aws-java-sdk-cloudsearch ........... 1.10.77 -> 1.11.812
[INFO]   com.amazonaws:aws-java-sdk-s3 .................... 1.10.77 -> 1.11.812
[INFO]   com.fasterxml.jackson.core:jackson-databind ....... 2.9.10.5 -> 2.11.1
[INFO]   com.github.tomakehurst:wiremock ..................... 2.19.0 -> 2.26.3
[INFO]   com.github.tomakehurst:wiremock ..................... 2.22.0 -> 2.26.3
[INFO]   com.google.guava:guava .......................... 27.1-jre -> 29.0-jre
[INFO]   com.ibm.icu:icu4j ....................................... 64.1 -> 67.1
[INFO]   com.rometools:rome .................................. 1.12.0 -> 1.14.1
[INFO]   com.squareup.okhttp3:okhttp .......................... 3.14.2 -> 4.7.2
[INFO]   junit:junit ............................................. 4.11 -> 4.13
[INFO]   org.apache.httpcomponents:httpclient ................. 4.5.8 -> 4.5.12
[INFO]   org.apache.solr:solr-solrj ............................ 7.5.0 -> 8.5.1
[INFO]   org.jsoup:jsoup ..................................... 1.12.1 -> 1.13.1
[INFO]   org.mockito:mockito-all ......................... 1.10.8 -> 2.0.2-beta
[INFO]   org.seleniumhq.selenium:selenium-support ...... 3.4.0 -> 4.0.0-alpha-6
[INFO]   org.yaml:snakeyaml ...................................... 1.24 -> 1.26

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/808/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/808,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1MzExNjE2NA==,incubator-stormcrawler,653116164,808,NA,matiascrespof,52938071,Matias Crespo,,NA,2020-07-02T16:49:27Z,2020-07-02T16:49:27Z,"Hello @jnioche, about dependency **com.squareup.okhttp3:okhttp** , for version 3.14.2, we noticed after some time certain urls getting stuck in Fetcher Bolt (configuring debugfiletrigger file in our project, we noticed urls from certain domains never fetched) 
We downgraded dependency to previous version of crawler 1.13 in our pom file (okhttp dependency 3.11.0) and issue was gone, same result upgrading to 4.7.2, same described in this task.

We didn't investigate in detail the cause since the issue is gone and everything seems to work ok, we just wanted to give you a heads up that for crawler version 1.16 there is a potential issue with that library.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1MzExNjE2NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/808,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1MzQxMDc4Ng==,incubator-stormcrawler,653410786,808,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-07-03T08:00:57Z,2020-07-03T08:00:57Z,"thanks @matiascrespof, this is very useful. If these URLs get stuck then they certainly time out and get failed in the spout, in which case it should be easy to find out what they are. I might upgrade to 4.7.2 and see if I can reproduce the problem. Thanks again","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1MzQxMDc4Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/808,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1MzQxNjQ4NA==,incubator-stormcrawler,653416484,808,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-07-03T08:13:38Z,2020-07-03T08:13:38Z,"note to self mockito 2 has been in beta for 5 years, probably best to stick to the latest 1 version -> 1.10.19","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1MzQxNjQ4NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/808,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1MzU4Mzc0Mg==,incubator-stormcrawler,653583742,808,NA,matiascrespof,52938071,Matias Crespo,,NA,2020-07-03T14:53:27Z,2020-07-03T14:53:27Z,"> thanks @matiascrespof, this is very useful. If these URLs get stuck then they certainly time out and get failed in the spout, in which case it should be easy to find out what they are. I might upgrade to 4.7.2 and see if I can reproduce the problem. Thanks again

Sorry, I meant when we upgraded to 4.7.2, the issue is gone, we only experimented the issue with 3.14.2.

True, the urls get failed in the spout but still the queue (FetchItemQueue) doesn't clean up the url, since we think the thread gets stuck when perform call to protocol (method getProtocolOutput,  OkHttpClient client, from com.digitalpebble.stormcrawler.protocol.okhttp.HttpProtocol )

We were not able to reproduce it locally, since it happens when crawler is running  after a while..

I hope it helps @jnioche !
Thanks","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1MzU4Mzc0Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/808,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1Mzc2NDkyMA==,incubator-stormcrawler,653764920,808,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-07-04T13:14:20Z,2020-07-04T13:14:20Z,"ok, thanks @matiascrespof, will definitely update to 4.7.2 then. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1Mzc2NDkyMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/808,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1NjAyMzUyMA==,incubator-stormcrawler,656023520,808,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-07-09T09:37:06Z,2020-07-09T09:37:06Z,the solr upgrade is already covered in #701 ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1NjAyMzUyMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/809,https://api.github.com/repos/apache/incubator-stormcrawler/issues/809,incubator-stormcrawler,648155798,809,AggregationSpout error due SimpleDateFormat not thread safe ,jcruzmartini,6817516,Juan Cruz Martini,,CLOSED,2020-06-30T13:03:30Z,2020-07-02T15:06:16Z,"sometimes when the crawl is finishing and we only have few URLs pending, the `nextTuple()` in the aggregation spout is being called steadily (totally expected). If you have the property `es.status.concurrentRequests` in a number greater than 1 and your property `spout.min.delay.queries` is too low, you may get this error

```
java.io.IOException: Unable to parse response body for Response{requestLine=POST /status*/_search?typed_keys=true&ignore_unavailable=false&expand_wildcards=open&allow_no_indices=true&preference=_shards%3A8&ignore_throttled=true&search_type=query_then_fetch&batched_reduce_size=512&ccs_minimize_roundtrips=true HTTP/1.1, host=https://elasticsearch-coordinating:9200, response=HTTP/1.1 200 OK}
	at org.elasticsearch.client.RestHighLevelClient$1.onSuccess(RestHighLevelClient.java:1665) [stormjar.jar:?]
	at org.elasticsearch.client.RestClient$FailureTrackingResponseListener.onSuccess(RestClient.java:590) [stormjar.jar:?]
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:333) [stormjar.jar:?]
	at org.elasticsearch.client.RestClient$1.completed(RestClient.java:327) [stormjar.jar:?]
	at org.apache.http.concurrent.BasicFuture.completed(BasicFuture.java:122) [stormjar.jar:?]
	at org.apache.http.impl.nio.client.DefaultClientExchangeHandlerImpl.responseCompleted(DefaultClientExchangeHandlerImpl.java:181) [stormjar.jar:?]
	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.processResponse(HttpAsyncRequestExecutor.java:448) [stormjar.jar:?]
 	at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.inputReady(HttpAsyncRequestExecutor.java:338) [stormjar.jar:?]
 	at org.apache.http.impl.nio.DefaultNHttpClientConnection.consumeInput(DefaultNHttpClientConnection.java:265) [stormjar.jar:?]
 	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:81) [stormjar.jar:?]
 	at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:39) [stormjar.jar:?]
 	at org.apache.http.impl.nio.reactor.AbstractIODispatch.inputReady(AbstractIODispatch.java:121) [stormjar.jar:?]
 	at org.apache.http.impl.nio.reactor.BaseIOReactor.readable(BaseIOReactor.java:162) [stormjar.jar:?]
 	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvent(AbstractIOReactor.java:337) [stormjar.jar:?]
 	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvents(AbstractIOReactor.java:315) [stormjar.jar:?]
 	at org.apache.http.impl.nio.reactor.AbstractIOReactor.execute(AbstractIOReactor.java:276) [stormjar.jar:?]
 	at org.apache.http.impl.nio.reactor.BaseIOReactor.execute(BaseIOReactor.java:104) [stormjar.jar:?]
 	at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor$Worker.run(AbstractMultiworkerIOReactor.java:591) [stormjar.jar:?]
 	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_252]
 Caused by: java.lang.NumberFormatException: For input string: """"
 	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65) ~[?:1.8.0_252]
 	at java.lang.Long.parseLong(Long.java:601) ~[?:1.8.0_252]
 	at java.lang.Long.parseLong(Long.java:631) ~[?:1.8.0_252]
 	at java.text.DigitList.getLong(DigitList.java:195) ~[?:1.8.0_252]
 	at java.text.DecimalFormat.parse(DecimalFormat.java:2084) ~[?:1.8.0_252]
 	at java.text.SimpleDateFormat.subParse(SimpleDateFormat.java:1869) ~[?:1.8.0_252]
 	at java.text.SimpleDateFormat.parse(SimpleDateFormat.java:1514) ~[?:1.8.0_252]
 	at java.text.DateFormat.parse(DateFormat.java:364) ~[?:1.8.0_252]
 	at com.digitalpebble.stormcrawler.elasticsearch.persistence.AggregationSpout.onResponse(AggregationSpout.java:258) ~[stormjar.jar:?]
 	at com.digitalpebble.stormcrawler.elasticsearch.persistence.AggregationSpout.onResponse(AggregationSpout.java:71)
```

After some reserch we realized that this error is happening because 2 responses are trying to use the SDF at same time. We tried reducing the`es.status.concurrentRequests` to 1 and  increase `spout.min.delay.queries` and the error has gone.
If you want we can include a fix for this, we have 2 options:
1. syncronize the use of the SDF
```
                    	synchronized (formatter) {
                    		mostRecentDateFound = formatter.parse(strDate);
			}
``` 
2. use DateTimeFormatter(thread safe) instead of SDF

**Extra information** 
- we have 10 spouts
- 1 spout per shard","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/809/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/809,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1MTc3ODkyNQ==,incubator-stormcrawler,651778925,809,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-06-30T13:07:53Z,2020-06-30T13:07:53Z,"Good catch, thanks! I'd go for _DateTimeFormatter_ - it's the modern way of doing it ;-)
Do you think you could provide a PR for it? ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1MTc3ODkyNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/809,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1MTc4MDM3OA==,incubator-stormcrawler,651780378,809,NA,jcruzmartini,6817516,Juan Cruz Martini,,NA,2020-06-30T13:10:32Z,2020-06-30T13:10:32Z,@jnioche sure we will add a new PR soon. thanks for your quick response ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY1MTc4MDM3OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/811,https://api.github.com/repos/apache/incubator-stormcrawler/issues/811,incubator-stormcrawler,650500645,811,rename external into modules,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2020-07-03T10:20:50Z,2023-12-05T16:14:07Z,"and put core in there as well. The **core** vs **external** is not a useful distinction to have: everything is a module
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/811/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/813,https://api.github.com/repos/apache/incubator-stormcrawler/issues/813,incubator-stormcrawler,653963812,813,_fetch.exception_ key should be removed from metadata if subsequent fetches are succesfull,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2020-07-09T10:49:02Z,2020-07-09T10:53:28Z,"similar to #415 

or put another way it should always be removed just before fetching 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/813/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/814,https://api.github.com/repos/apache/incubator-stormcrawler/issues/814,incubator-stormcrawler,654116840,814,SimpleFetcherBolt maxThrottleSleepMSec not deactivated,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2020-07-09T14:42:42Z,2020-07-09T15:36:50Z,"if the value of _fetcher.max.throttle.sleep_ is -1, the functionality should be inactive and the tuples should not be sent back via the throttle stream
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/814/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/816,https://api.github.com/repos/apache/incubator-stormcrawler/issues/816,incubator-stormcrawler,674280546,816,FileSpout doesn't replay failed tuples?,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2020-08-06T12:37:24Z,2020-09-17T12:56:45Z,"Need to check that this is the case but if the tuples don't get written successfully via the status updater, they simply get forgotten and not replayed. this is unlikely to happen but we should add them back to the buffer in case of a fail and dump an explicit message in the logs ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/816/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/817,https://api.github.com/repos/apache/incubator-stormcrawler/issues/817,incubator-stormcrawler,676284622,817,Storm Crawler 2.0 -conf arguments no longer work,jdpedrie,89034,John Pedrie,john@pedrie.com,CLOSED,2020-08-10T17:05:41Z,2020-08-10T18:14:30Z,"In Storm Crawler 1.x, we were able to provide additional configuration files via the `-conf` argument when starting a topology. In Storm Crawler 2.0, this no longer works.

```sh
$ /path/to/storm/bin/storm jar app.jar \
	com.foo.bar.topology.MyTopology \
	-conf /path/to/config.yaml
```

In Storm Crawler 1.16, inspecting the value of `args` in [`ConfigurableTopology.start`](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/ConfigurableTopology.java#L43) shows the following:

```
args:
	0: ""-conf""
	1: ""/path/to/config.yaml""
```

In Storm Crawler 2.0, the same command shows the value of `args` as:

```
args:
	0: ""/path/to/config.yaml""
```

Since `ConfigurableTopology.parse` disambiguates args based on the `-conf` prefix, this apparent upstream change in Storm has caused custom configuration files to no longer work.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/817/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/817,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3MTUwMzk3OA==,incubator-stormcrawler,671503978,817,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2020-08-10T18:04:46Z,2020-08-10T18:04:46Z,See d77b80a and the updated README. Does adding `--` solve your problem?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3MTUwMzk3OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/817,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3MTUwODgzNQ==,incubator-stormcrawler,671508835,817,NA,jdpedrie,89034,John Pedrie,john@pedrie.com,NA,2020-08-10T18:14:23Z,2020-08-10T18:14:23Z,That did the trick. Thanks for the quick reply!,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY3MTUwODgzNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/818,https://api.github.com/repos/apache/incubator-stormcrawler/issues/818,incubator-stormcrawler,693054871,818,Can't skip text or url fields in indexing,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2020-09-04T11:11:11Z,2020-09-04T11:24:51Z,"Sometimes we don't want to index any text at all, just values from the metadata. This is not possible at the moment with some indexing bolts.

The default configuration has 

  _indexer.text.fieldname: ""content""_

the ES indexer checks that the field name is not set to null, which can never happen. Setting it to an empty value has no effect either.

The indexer implementations should check that the value is neither _null_ nor _empty_  which would allow to skip the indexing of the text. 
The same applies to the url field.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/818/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/819,https://api.github.com/repos/apache/incubator-stormcrawler/issues/819,incubator-stormcrawler,695251367,819,Simplify indexer config when the metadata key is the same as the field  ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2020-09-07T16:15:25Z,2020-09-08T09:19:46Z,"We often get tautological configurations for the indexing e.g. 
_author=author_
when we want to generate a field named 'author' from the metadata key of the same name. 
We should be able to simply state
_author_ without a right hand side for cases like these","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/819/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/820,https://api.github.com/repos/apache/incubator-stormcrawler/issues/820,incubator-stormcrawler,706159013,820,HTTP date formatter to follow RFC 7231,sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2020-09-22T07:54:17Z,2020-09-23T10:59:21Z,"The date sent by HTTP protocol implementations in the If-modified-since request header field should follow [sec. 7.1.1.1 of RFC 7231](https://tools.ietf.org/html/rfc7231#section-7.1.1.1). In detail, the [RFC 1123 formatter](https://docs.oracle.com/javase/8/docs/api/java/time/format/DateTimeFormatter.html#RFC_1123_DATE_TIME) used in [HttpHeaders#formatDate](https://github.com/DigitalPebble/storm-crawler/blob/54bb5934918ff0f8919d58372405cfb14d63ad93/core/src/main/java/com/digitalpebble/stormcrawler/protocol/HttpHeaders.java#L86) does not use obligatorily use two digits for the day of month:
```
Sunday, December 1, 2019, 01:16:13 GMT
```
should be
```
Sunday, December 01, 2019, 01:16:13 GMT
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/820/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/821,https://api.github.com/repos/apache/incubator-stormcrawler/issues/821,incubator-stormcrawler,706174295,821,HttpHeaders#formatDate fails to parse date and returns always an empty string,sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2020-09-22T08:19:45Z,2020-09-23T10:59:19Z,"The method [HttpHeaders#formatDate](https://github.com/DigitalPebble/storm-crawler/blob/54bb5934918ff0f8919d58372405cfb14d63ad93/core/src/main/java/com/digitalpebble/stormcrawler/protocol/HttpHeaders.java#L86) fails to parse the ISO date holding the last-modified time with the exception
```
java.time.format.DateTimeParseException: Text '2020-09-22T08:00:00.000Z' could not be parsed: Unable to obtain ZonedDateTime from TemporalAccesso
r: {InstantSeconds=1600761600, NanoOfSecond=0, MicroOfSecond=0, MilliOfSecond=0},ISO of type java.time.format.Parsed
        at java.time.format.DateTimeFormatter.createError(DateTimeFormatter.java:1920)
        at java.time.format.DateTimeFormatter.parse(DateTimeFormatter.java:1855)
        at com.digitalpebble.stormcrawler.protocol.HttpHeaders.formatHttpDate(HttpHeaders.java:88)
        ...
```
which is caught and an empty string is returned. As a consequence the HTTP protocols will send the ""If-modified-since"" HTTP header with an empty date. So, Last-modified handling is broken due to this bug. See also: #673 and #674 which introduced this bug. A unit test to verify #820 uncovered it.

The exception is caused because the [ISO_INSTANT DateTimeFormatter](https://docs.oracle.com/javase/8/docs/api/java/time/format/DateTimeFormatter.html#ISO_INSTANT) requires that a timezone (UTC) is provided.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/821/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/821,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY5NjU5MjA5OQ==,incubator-stormcrawler,696592099,821,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2020-09-22T08:51:00Z,2020-09-22T08:51:00Z,"Verified that the ""If-modified-since"" header is **not** properly sent using the main method of HTTP protocols and the option `http.store.headers: true`:
```
java -cp ... com.digitalpebble.stormcrawler.protocol.okhttp.HttpProtocol -c ./conf/crawler-conf-test.yaml $'http://localhost/\tlast-modified=2019-11-01T20:00:00.000Z'
_request.headers_: GET / HTTP/1.1
User-Agent: ...
Accept: ...
Accept-Language: ...
If-Modified-Since: 
...

status code: 200
...
```","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY5NjU5MjA5OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/824,https://api.github.com/repos/apache/incubator-stormcrawler/issues/824,incubator-stormcrawler,708196369,824,StatusUpdaterBolt should use timeField() to index nextFetchDate?,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2020-09-24T13:57:36Z,2020-11-26T13:44:11Z,"or use a good old Map<String, Object> instead","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/824/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/824,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY5ODM2MjY3Ng==,incubator-stormcrawler,698362676,824,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-09-24T13:58:52Z,2020-09-24T13:58:52Z,https://www.elastic.co/guide/en/elasticsearch/client/java-rest/7.6/java-rest-high-document-index.html,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDY5ODM2MjY3Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/825,https://api.github.com/repos/apache/incubator-stormcrawler/issues/825,incubator-stormcrawler,712632527,825,WARCSpout/FileSpout: ClassCastException if message ID of failed tuples is not of type byte[],sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2020-10-01T08:45:18Z,2020-10-06T18:46:19Z,"When a tuple emitted by WARCSpout fails downstream, the method `fail(Object msgId)` inherited from FileSpout throws a ClassCastException:
```
2020-09-30 12:50:16.983 o.a.s.util Thread-16-spout-executor[5 5] [ERROR] Async loop died!
java.lang.RuntimeException: java.lang.ClassCastException: java.lang.String cannot be cast to [B
        at org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:522) ~[storm-core-1.2.3.jar:1.2.3]
        ...
Caused by: java.lang.ClassCastException: java.lang.String cannot be cast to [B
        at com.digitalpebble.stormcrawler.spout.FileSpout.fail(FileSpout.java:257) ~[stormjar.jar:?]
        ...
        ... 7 more
2020-09-30 12:50:17.113 o.a.s.util Thread-16-spout-executor[5 5] [ERROR] Halting process: (""Worker died"")
```

Also FileSpout itself (not an extending class) may run into this issue, in case `withDiscoveredStatus` is true which makes FileSpout to use the URL string as message ID.

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/825/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/827,https://api.github.com/repos/apache/incubator-stormcrawler/issues/827,incubator-stormcrawler,714643687,827,HTTP protocol implementation: allow to configure which protocol version(s) to use,sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2020-10-05T08:43:06Z,2020-10-06T15:11:23Z,"It should be possible to configure which HTTP protocol versions (HTTP/1.1, HTTP/2, etc.) are used by a protocol implementation:
- WARC readers may fail on yet unknown HTTP protocol versions (see [discussion ""Is there an option to use HTTP/1.0 or 1.1 for the Warc File""](https://groups.google.com/g/digitalpebble/c/VgoLRAnQDV0/m/bUrod9jxAAAJ), commoncrawl/news-crawl#42)
- but could be also useful for debugging and testing","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/827/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/827,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNDMzODU2Mg==,incubator-stormcrawler,704338562,827,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-10-06T15:11:21Z,2020-10-06T15:11:21Z,fixed in #829 ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNDMzODU2Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/828,https://api.github.com/repos/apache/incubator-stormcrawler/issues/828,incubator-stormcrawler,714644175,828,[WARC] Backward compatible storage of HTTP/2 headers,sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2020-10-05T08:43:48Z,2022-12-13T17:01:04Z,"Enable WARCHdfsBolt resp. WarcRecordFormat to write failure-proof files when using HTTP/2 - do not use ""HTTP/2"" in the status line as this may crash some WARC parsers. See iipc/warc-specifications#15 and iipc/warc-specifications#42 which proposes a field `WARC-Protocol`. Needs clarification how to store HTTP/2 requests and responses, meanwhile HTTP/2 can be disabled by #827.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/828/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/828,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5QaS0H,incubator-stormcrawler,1349070087,828,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-12-13T17:01:04Z,2022-12-13T17:01:04Z,Fixed in #1010 ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5QaS0H/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/830,https://api.github.com/repos/apache/incubator-stormcrawler/issues/830,incubator-stormcrawler,714699669,830,Images are not displayed with url that contains utf-8 special symbols,MindaugasArsulis,45561906,,,CLOSED,2020-10-05T10:01:46Z,2020-11-03T10:06:01Z,"I made a warc file with storm-crawler and in this website - https://lietuva.lt/ - images are represented as:

div class=""fold"" style=""background-image: url('https://lietuva.lt/wp-content/uploads/2019/07/VMG-Alfas-Ivanauskas-šaltibarščiai.jpg')""

when I open my crawled warc file with pywb I get:

div class=""fold"" style=""background-image: url('http://localhost:8080/my-web-archive/20201002045755/https://lietuva.lt/wp-content/uploads/2019/07/VMG-Alfas-Ivanauskas-%C3%85%C2%A1altibar%C3%85%C2%A1%C3%84%C2%8Diai.jpg')""

it seems that image url is being converted to utf-8 several times.
When I open same warc file with Webrecorder.io I get correct encoding:

div class=""fold"" style=""background-image: url('https://lietuva.lt/wp-content/uploads/2019/07/VMG-Alfas-Ivanauskas-šaltibarščiai.jpg')""

and image is displayed.

So I guess I should change these url links in warc html to encoded ones. How should I do that?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/830/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/830,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMzU0MTkxOQ==,incubator-stormcrawler,703541919,830,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2020-10-05T10:22:45Z,2020-10-05T10:22:45Z,"The page content is written literally to the WARC files, the HTML (or any other payload, binary or not) is not modified. The playback software [rewrites](https://pywb.readthedocs.io/en/latest/manual/rewriter.html) the HTML so that links and page dependencies (images, CSS) are loaded from the archives and not from their original location.

Could you verify whether URLs in the WARC are recorded properly in the WARC files. Just grep for the mentioned snippet:
```
gzip -dc xyz.warc.gz | grep -F ""url('https://lietuva.lt/wp-content/uploads/2019/07/VMG""
```

> change these url links in warc html to encoded ones

Just to confirm: this is not possible. It's rather an issue of the playback software.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMzU0MTkxOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/830,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMzYyMTQ0Nw==,incubator-stormcrawler,703621447,830,NA,MindaugasArsulis,45561906,,,NA,2020-10-05T13:10:38Z,2020-10-05T13:10:38Z,"Thank you for your answer.

When you said it is not possible to change url to encoded ones, I have started to look at pywb. And strangely, when I run pywb thru the console, I can't see those pictures, but if I run it with intellij, pictures are shown. I have no idea why. But it works one way and it doesn't work the other","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwMzYyMTQ0Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/830,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNDE1MjYxMQ==,incubator-stormcrawler,704152611,830,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2020-10-06T09:37:36Z,2020-10-06T09:37:36Z,"Tried it using the Docker ""webrecorder/pywb"" and looks like the URL is encoded correct in the browser: `background-image: url('http://localhost:8080/default/20201006090923oe_/https://lietuva.lt/wp-content/uploads/2019/07/VMG-Alfas-Ivanauskas-%C5%A1altibar%C5%A1%C4%8Diai.jpg');`

Just curious: did you manage that stormcrawler includes all page dependencies to be included in the WARC files? That's not trivial, esp. for URLs are in style attributes.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNDE1MjYxMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/830,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNDE3MDE2MA==,incubator-stormcrawler,704170160,830,NA,MindaugasArsulis,45561906,,,NA,2020-10-06T10:10:58Z,2020-10-06T10:10:58Z,"> Just curious: did you manage that stormcrawler includes all page dependencies to be included in the WARC files?

Yes, I have managed that. I need to make warc files with as close to orginal website style as possible. 

I have noticed that when I open warc, browser console tells me, that it can't seem to find woff files. And I can't find them in page source. Maybe you know where to look for them?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNDE3MDE2MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/830,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNDE5MjY4OA==,incubator-stormcrawler,704192688,830,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2020-10-06T11:00:04Z,2020-10-06T11:00:04Z,"> Yes, I have managed that.

If this is no secret magic, would be great if you could share how to achieve this, eg. on the [warc module README](/DigitalPebble/storm-crawler/blob/master/external/warc/README.md)

> woff files

Web fonts are usually requested via `@font-face` constructs in the CSS, eg. in the [style.css](https://lietuva.lt/wp-content/themes/lietuva/assets/style.css?ver=20191002)","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNDE5MjY4OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/830,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNTU3NzYwMA==,incubator-stormcrawler,705577600,830,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-10-08T13:43:13Z,2020-10-08T13:43:13Z,"great discussion and fab to see our WARC module being used
@MindaugasArsulis I'd be interested in hearing about the context of your work. Could you drop me a line at julien@digitalpebble.com? Thanks","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNTU3NzYwMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/830,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxNTM3MjExMw==,incubator-stormcrawler,715372113,830,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-10-23T14:19:51Z,2020-10-23T14:19:51Z,Can this be closed?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxNTM3MjExMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/832,https://api.github.com/repos/apache/incubator-stormcrawler/issues/832,incubator-stormcrawler,716257217,832,Elasticsearch IndexerBolt: tuples with canonical URL may not get acked,sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2020-10-07T07:00:10Z,2020-10-23T14:18:24Z,"This issue was seen in a topology fed by WARCSpout. The failure of unacked tuples triggered #825. The failure was reproducible: if the topology was run again with the same input an mostly overlapping (but not identical) set of URLs were logged as failed. In addition, the failed URLs are missing in the status index.

A closer analysis showed that pages with canonical URL were involved. One example:
```
2020-10-06 19:41:44.202 c.d.s.w.WARCSpout Thread-4-spout-executor[8 8] [INFO] Fetched https://www.obozrevatel.com/ukr/dnipro/city/u-dnipri-ta-oblasti-ogolosili-shtormove-poperedzhennya.htm with status 200
2020-10-06 19:41:44.351 c.d.s.w.WARCSpout Thread-4-spout-executor[8 8] [INFO] Fetched https://www.obozrevatel.com/ukr/dnipro/city/u-dnipri-ta-oblasti-ogolosili-shtormove-poperedzhennya/amp.htm with status 200
2020-10-06 19:41:45.608 c.d.s.b.JSoupParserBolt Thread-14-parse-executor[6 6] [INFO] Parsing : starting https://www.obozrevatel.com/ukr/dnipro/city/u-dnipri-ta-oblasti-ogolosili-shtormove-poperedzhennya.htm
2020-10-06 19:41:45.636 c.d.s.b.JSoupParserBolt Thread-14-parse-executor[6 6] [INFO] Parsed https://www.obozrevatel.com/ukr/dnipro/city/u-dnipri-ta-oblasti-ogolosili-shtormove-poperedzhennya.htm in 23 msec
2020-10-06 19:41:45.674 c.d.s.b.JSoupParserBolt Thread-14-parse-executor[6 6] [INFO] Total for https://www.obozrevatel.com/ukr/dnipro/city/u-dnipri-ta-oblasti-ogolosili-shtormove-poperedzhennya.htm - 61 msec
2020-10-06 19:41:45.675 c.d.s.e.b.IndexerBolt Thread-10-index-executor[3 3] [INFO] Indexing https://www.obozrevatel.com/ukr/dnipro/city/u-dnipri-ta-oblasti-ogolosili-shtormove-poperedzhennya.htm as https://www.obozrevatel.com/ukr/dnipro/city/u-dnipri-ta-oblasti-ogolosili-shtormove-poperedzhennya.htm
2020-10-06 19:41:46.191 c.d.s.b.JSoupParserBolt Thread-14-parse-executor[6 6] [INFO] Parsing : starting https://www.obozrevatel.com/ukr/dnipro/city/u-dnipri-ta-oblasti-ogolosili-shtormove-poperedzhennya/amp.htm
2020-10-06 19:41:46.202 c.d.s.b.JSoupParserBolt Thread-14-parse-executor[6 6] [INFO] Parsed https://www.obozrevatel.com/ukr/dnipro/city/u-dnipri-ta-oblasti-ogolosili-shtormove-poperedzhennya/amp.htm in 7 msec
2020-10-06 19:41:46.212 c.d.s.b.JSoupParserBolt Thread-14-parse-executor[6 6] [INFO] Total for https://www.obozrevatel.com/ukr/dnipro/city/u-dnipri-ta-oblasti-ogolosili-shtormove-poperedzhennya/amp.htm - 17 msec
2020-10-06 19:41:46.215 c.d.s.e.b.IndexerBolt Thread-10-index-executor[3 3] [INFO] Indexing https://www.obozrevatel.com/ukr/dnipro/city/u-dnipri-ta-oblasti-ogolosili-shtormove-poperedzhennya/amp.htm as https://www.obozrevatel.com/ukr/dnipro/city/u-dnipri-ta-oblasti-ogolosili-shtormove-poperedzhennya.htm
2020-10-06 19:41:46.754 c.d.s.e.b.IndexerBolt I/O dispatcher 12 [WARN] Could not find unacked tuple for 50571c0ffec7d295bb754b4847bdf2edace07885895ca09e5d459eeddd03c6f7
2020-10-06 19:51:40.108 c.d.s.e.b.IndexerBolt I/O dispatcher 12 [INFO] Bulk response [246] : items 100, waitAck 42, acked 99, failed 0
2020-10-06 19:51:43.985 c.d.s.w.WARCSpout Thread-4-spout-executor[8 8] [ERROR] Failed - unable to replay WARC record of: https://www.obozrevatel.com/ukr/dnipro/city/u-dnipri-ta-oblasti-ogolosili-shtormove-poperedzhennya.htm
```

Reduced to be more readable:
```
19:41:44.202 [INFO] Fetched A with status 200
19:41:44.351 [INFO] Fetched B with status 200
19:41:45.608 [INFO] Parsing : starting A
19:41:45.636 [INFO] Parsed A in 23 msec
19:41:45.674 [INFO] Total for A - 61 msec
19:41:45.675 [INFO] Indexing A as A
19:41:46.191 [INFO] Parsing : starting B
19:41:46.202 [INFO] Parsed B in 7 msec
19:41:46.212 [INFO] Total for B - 17 msec
19:41:46.215 [INFO] Indexing B as A
19:41:46.754 [WARN] Could not find unacked tuple for sha256sum(A)
19:51:40.108 [INFO] Bulk response [246] : items 100, waitAck 42, acked 99, failed 0
19:51:43.985 [ERROR] Failed - unable to replay WARC record of: A
```
Note: there is no prior `Bulk response` log message, so this means both pages/URLs have been processed in the first bulk. The hash is verified as sha256 hash of A by:
```
$> echo -n 'https://www.obozrevatel.com/ukr/dnipro/city/u-dnipri-ta-oblasti-ogolosili-shtormove-poperedzhennya.htm' \
    | sha256sum 
50571c0ffec7d295bb754b4847bdf2edace07885895ca09e5d459eeddd03c6f7  -
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/832/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/832,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNDc1MDU2MQ==,incubator-stormcrawler,704750561,832,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2020-10-07T07:28:35Z,2020-10-07T07:28:35Z,"The docID (based on the canonical URL) is also used as key in the `waitAck` cache. Tuples with same docID are overwritten in the cache. Solutions?
- make waitAck `Cache<String, List<Tuple>>`
- check beforehand whether docID is in cache: if yes, do not index, just report to status stream","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNDc1MDU2MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/832,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNDc1MjUzOQ==,incubator-stormcrawler,704752539,832,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2020-10-07T07:32:25Z,2020-10-07T07:32:25Z,"Btw., docID is calculated twice (second time as `sha256hex`).","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNDc1MjUzOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/832,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNDgxMjg0MQ==,incubator-stormcrawler,704812841,832,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-10-07T09:28:16Z,2020-10-07T09:28:16Z,"thanks Sebastian, I'll have a look","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNDgxMjg0MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/832,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNDk3NjQ0Ng==,incubator-stormcrawler,704976446,832,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-10-07T14:30:45Z,2020-10-07T14:30:45Z,"> The docID (based on the canonical URL) is also used as key in the `waitAck` cache. Tuples with same docID are overwritten in the cache. Solutions?
> 
> * make waitAck `Cache<String, List<Tuple>>`
> * check beforehand whether docID is in cache: if yes, do not index, just report to status stream

This is the approach used in the StatusUpdaterBolt

https://github.com/DigitalPebble/storm-crawler/blob/master/external/elasticsearch/src/main/java/com/digitalpebble/stormcrawler/elasticsearch/persistence/StatusUpdaterBolt.java#L238","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNDk3NjQ0Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/832,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNTM5NDA0MA==,incubator-stormcrawler,705394040,832,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2020-10-08T07:45:14Z,2020-10-08T07:45:14Z,"Ok. Interestingly, using a topology with a WARCSpout there are also many log messages about unacked tuples from StatusUpdaterBolt. Is there a good explanation for these? When processing one BulkItemResponse StatusUpdaterBolt acks all tuples of one docID. Shouldn't it ack only a single tuple? Is there a way to connect one tuple and a BulkItemResponse?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNTM5NDA0MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/832,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNjUwMjkzNg==,incubator-stormcrawler,706502936,832,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-10-10T07:19:20Z,2020-10-10T07:19:20Z,"Will reply about the StatusUpdaterBolt later 
Have opened #834, which will be a good opportunity to reproduce the problem you observed @sebastian-nagel  ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNjUwMjkzNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/832,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNzgxNzU1Nw==,incubator-stormcrawler,707817557,832,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-10-13T15:23:53Z,2020-10-13T15:23:53Z,"to put this issue into context: the worst thing that can happen is that the second URL (whichever it is) will eventually fail with a timeout but should get replayed by the spout and will eventually make it to the _status_ and _content_ indices. Of course, if the spout can't replay the inputs, you'd lose it. But then a similar content for the same URL would have been indexed anyway","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcwNzgxNzU1Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/834,https://api.github.com/repos/apache/incubator-stormcrawler/issues/834,incubator-stormcrawler,718554798,834,Add JUnit tests for ES module,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2020-10-10T07:17:33Z,2020-10-23T14:19:07Z,"Using the official Docker images for ES and [](https://www.testcontainers.org/modules/elasticsearch/) to launch the containers from JUnit.
This will help reproduce issues with the ES module and check that new changes do not introduce regressions. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/834/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/834,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxNTM3MTY4Ng==,incubator-stormcrawler,715371686,834,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-10-23T14:19:07Z,2020-10-23T14:19:07Z,Fixed in #836 ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDcxNTM3MTY4Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/837,https://api.github.com/repos/apache/incubator-stormcrawler/issues/837,incubator-stormcrawler,725762618,837,investigate using Top metrics aggregations instead of top hit,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2020-10-20T16:34:38Z,2021-01-23T07:02:12Z,https://www.elastic.co/guide/en/elasticsearch/reference/7.9/search-aggregations-metrics-top-metrics.html,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/837/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/837,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMzEyNDA4Mg==,incubator-stormcrawler,733124082,837,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2020-11-24T17:24:46Z,2020-11-24T17:24:46Z,"`The sort field in the metric request functions exactly the same as the sort field in the search request except: * It can’t be used on binary, flattened, ip, keyword, or text fields. * It only supports a single sort value so which document wins ties is not specified.`

given that we typically sort on the nextFetchDate + URL, this is not likely to be a good fit","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDczMzEyNDA4Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/838,https://api.github.com/repos/apache/incubator-stormcrawler/issues/838,incubator-stormcrawler,728078338,838,logQueuesContent won't be called if no new tuples are getting in,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2020-10-23T09:50:48Z,2020-11-10T16:42:04Z,"we could use a tick tuple every so often to make sure that the mechanism is triggered, regardless of whether new tuples are coming in","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/838/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/840,https://api.github.com/repos/apache/incubator-stormcrawler/issues/840,incubator-stormcrawler,735186868,840,Upgrade to Apache Storm 2.2.0,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2020-11-03T10:07:56Z,2020-11-10T16:30:21Z,https://storm.apache.org/2020/06/30/storm220-released.html,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/840/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/841,https://api.github.com/repos/apache/incubator-stormcrawler/issues/841,incubator-stormcrawler,749817028,841,quick testing of regex-normalizer rules,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2020-11-24T15:36:20Z,2020-11-24T15:38:14Z,"using the _main_ method, just to check that a pattern behaves as expected; similar to what we do with the protocols","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/841/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/842,https://api.github.com/repos/apache/incubator-stormcrawler/issues/842,incubator-stormcrawler,754232966,842,Tika 1.25,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2020-12-01T09:43:38Z,2020-12-03T13:18:25Z,"https://downloads.apache.org/tika/CHANGES-1.25.txt
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/842/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/844,https://api.github.com/repos/apache/incubator-stormcrawler/issues/844,incubator-stormcrawler,774736300,844,"Exception in thread ""main"" java.lang.ClassNotFoundException: org.apache.storm.flux.Flux",,,,,CLOSED,2020-12-25T13:56:26Z,2020-12-25T14:03:37Z,"Running Storm Crawler Elasticsearch Archetype version 2.0, with JDK 11 and Apache Storm 2.1, yields the following error:

Exception in thread ""main"" java.lang.ClassNotFoundException: org.apache.storm.flux.Flux
	at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)
	at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:315)
	at org.apache.storm.LocalCluster.lambda$main$1(LocalCluster.java:395)
	at org.apache.storm.LocalCluster.withLocalModeOverride(LocalCluster.java:347)
	at org.apache.storm.LocalCluster.main(LocalCluster.java:392)","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/844/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/844,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc1MTI1MzgyNw==,incubator-stormcrawler,751253827,844,NA,,,,,NA,2020-12-25T14:03:35Z,2020-12-25T14:03:35Z,Solved: I ran mvn package clean instead of mvn clean package. There was no target folder.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc1MTI1MzgyNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/845,https://api.github.com/repos/apache/incubator-stormcrawler/issues/845,incubator-stormcrawler,786011901,845,Archetypes use okttp protocol,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2021-01-14T13:59:53Z,2021-01-14T14:01:40Z,"The okhttp implementation is more robust than the httpclient based one, for instance it is able to properly trim the content from a connection whereas the latter will keep fetching despite having gone beyond the threshold. They have similar capabilities overall. We'll leave the httpclient one as default so as to not induce unwanted changes in existing crawl. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/845/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/846,https://api.github.com/repos/apache/incubator-stormcrawler/issues/846,incubator-stormcrawler,786018192,846,Set user-agent as a one liner,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2021-01-14T14:08:19Z,2021-01-14T14:15:49Z,"The user agent is currently built from multiple config elements

  **http.agent.name**: ""Anonymous Coward""
  **http.agent.version**: ""1.0""
  **http.agent.description**: ""built with StormCrawler Elasticsearch Archetype ${StormCrawlerVersion}""
  **http.agent.url**: ""http://someorganization.com/""
  **http.agent.email**: ""someone@someorganization.com""

and turned into a string which gets sent to the servers.

It would be good to have a config  **http.agent**  which, if set, would contain the string to use and would override the other elements if present. This would just make it a bit more straightforward to use a custom signature.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/846/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/847,https://api.github.com/repos/apache/incubator-stormcrawler/issues/847,incubator-stormcrawler,789221179,847,Add JSoup specific parse filters,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2021-01-19T17:36:57Z,2021-04-25T08:45:30Z,"The existing ParseFilters can operate on DOM objects and use XPath. These are called by the JSOUp Parser, the Tika one and the RSS and sitemap parsers. They don't need to use Xpath but sometimes do.

When the document comes from JSOUP and at least one filters requires XPath, this means generating a copy of the JSOUP document into a DOM structure then running the XPath expressions. This requires CPU and memory. 

We could have a set of parse filters specific to the JSOUP bolt (but would not be used in other bolts) for cases when a light extraction is needed and can be done straight onto the JSOUP document - this way no need to convert and the JSOUP selectors could be faster than XPATH and are definitely nicer to use.

Of course these would not be called by the Tika bolt but then I doubt anyone uses the latter to deal with HTML docs anyway.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/847/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/848,https://api.github.com/repos/apache/incubator-stormcrawler/issues/848,incubator-stormcrawler,789223265,848,Add option to completely skip text extraction,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2021-01-19T17:38:59Z,2021-01-20T16:15:38Z,"Sometimes, well, you simply don't want the text. Why bother to extract it then?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/848/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/849,https://api.github.com/repos/apache/incubator-stormcrawler/issues/849,incubator-stormcrawler,789234842,849,Provide option for a faster charset detection strategy,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2021-01-19T17:55:48Z,2021-01-20T17:44:48Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/849/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/849,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc2Mzc2MzkzMA==,incubator-stormcrawler,763763930,849,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-01-20T16:29:25Z,2021-01-20T16:29:25Z,"With the current logic, the extraction from the HTML or guessing from text are expensive. 

What we probably want instead is to provide an alternative strategy so that any tag found in the HTML is used if it is found and only rely on the (costly) guesswork if nothing has been found that way.

We could also try to make the extraction from HTML faster - at the moment we parse the doc with Jsoup for up to _detect.charset.maxlength_ chars, which is not cheap. A simple regular expression for the standard charset meta tag would probably detect most cases successfully relatively fast, we'd keep the parsing with JSOUP as a backup.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc2Mzc2MzkzMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/849,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc2MzgxODQ3NA==,incubator-stormcrawler,763818474,849,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-01-20T17:43:34Z,2021-01-20T17:43:34Z,"A quick experiment showed that the default approach 2.3s for 5s spent in the parser bolt (with no parseFilters); 2.1 s of which is the text detection whereas the faster approach takes only 0.63secs for the same 5 secs spent by the parser. So roughly it is 4x as fast.

of course if you have many or expensive parsefilters the effect will not be as noticeable ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc2MzgxODQ3NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/849,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc2MzgxOTA5OQ==,incubator-stormcrawler,763819099,849,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-01-20T17:44:48Z,2021-01-20T17:44:48Z,"Either way, the optimisation for the tag extraction will make things faster compared to previous versions.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc2MzgxOTA5OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/850,https://api.github.com/repos/apache/incubator-stormcrawler/issues/850,incubator-stormcrawler,791877399,850,WARCSpout doesn't handle http.content.limit -1 correctly,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2021-01-22T10:13:36Z,2021-01-28T09:40:09Z,"-1 is the value it takes by default if not set in the config and it means that the content should not be trimmed, just like the Fetcher Bolts do, however it doesn't handle it correctly and tries to trim to a negative value.
A temporary workaround is to configure it with a large value

`  http.content.limit: 99999999`","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/850/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/850,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc2NzAyMTg1MA==,incubator-stormcrawler,767021850,850,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-01-25T18:29:58Z,2021-01-25T18:29:58Z,@sebastian-nagel do you want to have a look at this one or shall I?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc2NzAyMTg1MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/850,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc2NzQ3NTk5NQ==,incubator-stormcrawler,767475995,850,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2021-01-26T11:16:15Z,2021-01-26T11:16:15Z,"Ok, I'll have a look.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc2NzQ3NTk5NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/851,https://api.github.com/repos/apache/incubator-stormcrawler/issues/851,incubator-stormcrawler,792459324,851,SOLR - add tests using Docker image,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2021-01-23T07:06:18Z,2024-06-04T07:43:29Z,"Similar to what we have for ES, the tests could spin a Docker container for SOLR and check that documents are indexed as it should be.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/851/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/851,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Zk9yd,incubator-stormcrawler,1502862493,851,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-04-11T07:57:12Z,2023-04-11T07:57:12Z,"See https://www.testcontainers.org/modules/solr/

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Zk9yd/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/851,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5bR5oG,incubator-stormcrawler,1531419142,851,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-05-02T12:47:52Z,2023-05-02T12:47:52Z,"Initial code in https://github.com/DigitalPebble/storm-crawler/tree/851
Work in progress","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5bR5oG/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/851,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5-x5__,incubator-stormcrawler,2127011839,851,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-05-23T12:42:02Z,2024-05-23T12:42:02Z,"@mvolikas since you use this module, any chance you would be able to have a look at this one? Or any of the other [issues for SOLR](https://github.com/apache/incubator-stormcrawler/issues?q=is%3Aissue+is%3Aopen+label%3ASOLR)?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5-x5__/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/851,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5-yDKl,incubator-stormcrawler,2127049381,851,NA,mvolikas,115570991,Markos Volikas,,NA,2024-05-23T13:00:49Z,2024-05-23T13:00:49Z,"Sure, thx! I was actually having a look earlier today :)","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5-yDKl/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/851,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5-z28k,incubator-stormcrawler,2127523620,851,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-05-23T16:06:25Z,2024-05-23T16:06:25Z,"> Sure, thx! I was actually having a look earlier today :)

That would be fantastic!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5-z28k/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/851,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5_Fg_y,incubator-stormcrawler,2132152306,851,NA,mvolikas,115570991,Markos Volikas,,NA,2024-05-26T09:32:05Z,2024-05-26T09:32:05Z,"Hi there!
I have opened a PR to branch 851. I fixed the StatusBoltTest and added a very simple IndexerBoltTest (just checks if the tuple is acked). Note that I used a slightly different approach: Now the solr/cores/ configuration files are used for the tests, and the cores are created explicitly. For the Indexer, I could also add a query to Solr that checks that the document is actually in the core. What do you think?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5_Fg_y/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/851,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5_9hHL,incubator-stormcrawler,2146832843,851,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-06-04T07:43:23Z,2024-06-04T07:43:23Z,Fixed by #1240 ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5_9hHL/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/852,https://api.github.com/repos/apache/incubator-stormcrawler/issues/852,incubator-stormcrawler,794217241,852,ES Spout to connect to local shards when available,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2021-01-26T13:07:39Z,2021-10-20T08:56:20Z,"ES nodes are sometimes hosted on the same nodes as the Storm workers. When this is the case, it would be good if the spout instances could connect to the shards available locally.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/852/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/852,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc42YX55,incubator-stormcrawler,912359033,852,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-09-03T08:27:04Z,2021-09-03T08:27:04Z,"an alternative would be to have spouts retrieve results not per shard, but per ES node, which would then make it easier to connect locally","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc42YX55/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/852,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc42YZaY,incubator-stormcrawler,912365208,852,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-09-03T08:36:53Z,2021-09-03T08:36:53Z,"could find the nodes hosting the shards via https://www.elastic.co/guide/en/elasticsearch/reference/current/search-shards.html
one downside is that if a node is down and the shards served by another one, things might get a bit problematic","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc42YZaY/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/852,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc42YaNA,incubator-stormcrawler,912368448,852,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-09-03T08:42:03Z,2021-09-03T08:42:03Z,https://www.elastic.co/guide/en/elasticsearch/reference/current/search-search.html#search-preference,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc42YaNA/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/852,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc42Ya50,incubator-stormcrawler,912371316,852,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-09-03T08:46:50Z,2021-09-03T08:46:50Z,"A simple improvement to the existing mechanism would be to specify a preference for the local version of a shard e.g.
`_shards:2|_local`

this should be harmless and could speed things up a bit if the shard assigned to the spout happens to also be available locally","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc42Ya50/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/854,https://api.github.com/repos/apache/incubator-stormcrawler/issues/854,incubator-stormcrawler,795173850,854,Protocol implementations: Integer.MAX_VALUE not save as max. content size ,sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2021-01-27T14:56:50Z,2021-10-20T10:11:26Z,"The protocol implementations (httpclient, okhttp, file) use Integer.MAX_VALUE for the maximum size of allowed content. While int_max is the limit of the array index, the max. allocatable array size is few bytes smaller and depends on the JVM, see [do-java-arrays-have-a-maximum-size](https://stackoverflow.com/questions/3038392/do-java-arrays-have-a-maximum-size). Maybe use [fastutil's Arrays.MAX_ARRAY_SIZE](http://fastutil.di.unimi.it/docs/it/unimi/dsi/fastutil/Arrays.html#MAX_ARRAY_SIZE) which is Integer.MAX_VALUE - 8 ?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/854/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/854,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc2ODM1MjI2Mg==,incubator-stormcrawler,768352262,854,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-01-27T15:12:25Z,2021-01-27T15:12:25Z,"Well, everything will probably explode if we get to anything that big ;-) 
Let's use  _Integer.MAX_VALUE - 8_  but without introducing a dependency on fastutils.
Thanks!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc2ODM1MjI2Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/855,https://api.github.com/repos/apache/incubator-stormcrawler/issues/855,incubator-stormcrawler,800260959,855,Dependency updates,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2021-02-03T11:58:25Z,2021-02-04T15:10:34Z,"`mvn versions:display-dependency-updates`

```
[INFO]   org.seleniumhq.selenium:selenium-remote-driver ...
[INFO]                                           4.0.0-alpha-6 -> 4.0.0-alpha-7
[INFO]   org.seleniumhq.selenium:selenium-support ...
[INFO]                                           4.0.0-alpha-6 -> 4.0.0-alpha-7
[INFO]   org.elasticsearch.client:elasticsearch-rest-high-level-client ...
[INFO]                                                          7.5.0 -> 7.10.2
[INFO]   com.amazonaws:aws-java-sdk-cloudsearch .......... 1.11.819 -> 1.11.947
[INFO]   com.amazonaws:aws-java-sdk-s3 ................... 1.11.819 -> 1.11.947
[INFO]   com.fasterxml.jackson.core:jackson-databind ......... 2.11.1 -> 2.12.1
[INFO]   com.github.tomakehurst:wiremock ..................... 2.19.0 -> 2.27.2
[INFO]   com.github.tomakehurst:wiremock ..................... 2.26.3 -> 2.27.2
[INFO]   com.google.guava:guava .......................... 29.0-jre -> 30.1-jre
[INFO]   com.ibm.icu:icu4j ....................................... 67.1 -> 68.2
[INFO]   com.rometools:rome .................................. 1.14.1 -> 1.15.0
[INFO]   com.squareup.okhttp3:okhttp ................... 4.7.2 -> 5.0.0-alpha.2
[INFO]   junit:junit ........................................... 4.13 -> 4.13.1
[INFO]   org.apache.httpcomponents:httpclient ................ 4.5.12 -> 4.5.13
[INFO]   org.apache.solr:solr-solrj ............................ 8.6.3 -> 8.8.0
[INFO]   org.apache.storm:storm-core ........................... 1.2.3 -> 2.2.0
[INFO]   org.apache.storm:storm-hdfs ........................... 1.2.3 -> 2.2.0
[INFO]   org.apache.tika:tika-core ........................ 1.25 -> 2.0.0-ALPHA
[INFO]   org.apache.tika:tika-parsers ..................... 1.25 -> 2.0.0-ALPHA
[INFO]   org.mockito:mockito-all ........................ 1.10.19 -> 2.0.2-beta
[INFO]   org.mockito:mockito-all ......................... 1.10.8 -> 2.0.2-beta
[INFO]   org.netpreserve:jwarc ............................... 0.13.0 -> 0.13.1
[INFO]   org.testcontainers:elasticsearch .................... 1.14.3 -> 1.15.1
[INFO]   org.yaml:snakeyaml ...................................... 1.26 -> 1.27
[INFO]   xerces:xercesImpl ................................... 2.12.0 -> 2.12.1
```","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/855/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/856,https://api.github.com/repos/apache/incubator-stormcrawler/issues/856,incubator-stormcrawler,803650309,856,"Exception in thread ""main"" java.lang.NoSuchMethodError: 'java.lang.Integer org.apache.storm.utils.Utils.getInt(java.lang.Object)'",AaronNGray,85523,Aaron Gray,aaronngray@gmail.com,CLOSED,2021-02-08T15:08:28Z,2021-02-08T16:10:45Z,"What kind of issue is this?

 - [ ] Question. This issue tracker is not the best place for questions. If you want to ask how to do
       something, or to understand why something isn't working the way you expect it to, use StackOverflow
       instead with the label 'stormcrawler': https://stackoverflow.com/questions/tagged/stormcrawler 

 - [x ] Bug report. If you’ve found a bug, please include a test if you can, it makes it a lot easier to fix things. Use the label 'bug' on the issue.
 
 - [ ] Feature request. Please use the label 'wish' on the issue.

I am getting the following :-
```
storm jar target/storm-crawler-elasticsearch-1.0-SNAPSHOT.jar global.climateemergency.ESCrawlTopology -conf crawler-conf.yaml -conf es-conf.yaml -local . seeds.txt
Running: java -client -Ddaemon.name= -Dstorm.options=onf,onf -Dstorm.home=/mnt/c/Users/aaron/Development/apache-storm-2.2.0 -Dstorm.log.dir=/mnt/c/Users/aaron/Development/apache-storm-2.2.0/logs -Djava.library.path=/usr/local/lib:/opt/local/lib:/usr/lib:/usr/lib64 -Dstorm.conf.file= -cp /mnt/c/Users/aaron/Development/apache-storm-2.2.0/*:/mnt/c/Users/aaron/Development/apache-storm-2.2.0/lib-worker/*:/mnt/c/Users/aaron/Development/apache-storm-2.2.0/extlib/*:target/storm-crawler-elasticsearch-1.0-SNAPSHOT.jar:/mnt/c/Users/aaron/Development/apache-storm-2.2.0/conf:/mnt/c/Users/aaron/Development/apache-storm-2.2.0/bin: -Dstorm.jar=target/storm-crawler-elasticsearch-1.0-SNAPSHOT.jar -Dstorm.dependency.jars= -Dstorm.dependency.artifacts={} global.climateemergency.ESCrawlTopology crawler-conf.yaml es-conf.yaml -local . seeds.txt
Exception in thread ""main"" java.lang.NoSuchMethodError: 'java.lang.Integer org.apache.storm.utils.Utils.getInt(java.lang.Object)'
        at com.digitalpebble.stormcrawler.util.ConfUtils.getInt(ConfUtils.java:46)
        at global.climateemergency.ESCrawlTopology.run(ESCrawlTopology.java:55)
        at com.digitalpebble.stormcrawler.ConfigurableTopology.start(ConfigurableTopology.java:50)
        at global.climateemergency.ESCrawlTopology.main(ESCrawlTopology.java:48)
```
I am on Ubuntu on Windows WSL, I will try on my Linux Debian system ....
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/856/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/856,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTIzMjkxMQ==,incubator-stormcrawler,775232911,856,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2021-02-08T15:34:04Z,2021-02-08T15:34:04Z,"Hi @AaronNGray, the main branch of StormCrawler is based on Storm 1.2.3 - there is a branch for Storm 2.x but afaik it's still recommended to use Storm 1.2.3.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTIzMjkxMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/856,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTIzNzkyOA==,incubator-stormcrawler,775237928,856,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-02-08T15:41:11Z,2021-02-08T15:41:11Z,"hi @AaronNGray, Seb is right: you are using a topology based on SC 1 on a Storm 2 cluster. You can either use a Storm 1 cluster instead or use the SC 2 branch. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTIzNzkyOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/856,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTIzOTYyNg==,incubator-stormcrawler,775239626,856,NA,AaronNGray,85523,Aaron Gray,aaronngray@gmail.com,NA,2021-02-08T15:43:32Z,2021-02-08T15:43:32Z,Ah I have been using Maven generated code and following your documentation and the generated documentation. AFAICT I think something needs updating somewhere !,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTIzOTYyNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/856,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTI0MTk5MQ==,incubator-stormcrawler,775241991,856,NA,AaronNGray,85523,Aaron Gray,aaronngray@gmail.com,NA,2021-02-08T15:46:39Z,2021-02-08T15:46:39Z,"Is StormCrawler 2.x on Maven ?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTI0MTk5MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/856,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTI1Njk1Ng==,incubator-stormcrawler,775256956,856,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-02-08T16:10:45Z,2021-02-08T16:10:45Z,"https://mvnrepository.com/artifact/com.digitalpebble.stormcrawler/storm-crawler-core/2.0
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTI1Njk1Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/857,https://api.github.com/repos/apache/incubator-stormcrawler/issues/857,incubator-stormcrawler,803735118,857,Java topology doesn't read configurations with Storm 2,AaronNGray,85523,Aaron Gray,aaronngray@gmail.com,CLOSED,2021-02-08T16:44:30Z,2021-03-08T14:02:54Z," - [x ] Bug report. If you’ve found a bug, please include a test if you can, it makes it a lot easier to fix things. Use the label 'bug' on the issue.

I am getting the following :-
```
16:33:27.858 [Thread-35-spout-executor[12, 12]] ERROR c.d.s.e.p.AbstractSpout - Can't connect to ElasticSearch
java.lang.IllegalArgumentException: hosts must not be null nor empty
        at org.elasticsearch.client.RestClient.builder(RestClient.java:173) ~[stormcrawler-1.0-SNAPSHOT.jar:?]
        at com.digitalpebble.stormcrawler.elasticsearch.ElasticSearchConnection.getClient(ElasticSearchConnection.java:117) ~[stormcrawler-1.0-SNAPSHOT.jar:?]
```
ElasticSearch is up and running. I cannot find a 'hosts:' parameter anywhere and 'es-conf.yaml' parameters are set to localhost, or http://locahost:9200
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/857/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/857,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTI5ODU3NQ==,incubator-stormcrawler,775298575,857,NA,AaronNGray,85523,Aaron Gray,aaronngray@gmail.com,NA,2021-02-08T17:10:46Z,2021-02-08T17:10:46Z,"It works fine using Flex.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTI5ODU3NQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/857,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTI5ODcxNw==,incubator-stormcrawler,775298717,857,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-02-08T17:10:56Z,2021-02-08T17:10:56Z,"how did you generate the topology? are you on SC2? what is the content of es-conf.yaml?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTI5ODcxNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/857,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTMwMTAwMQ==,incubator-stormcrawler,775301001,857,NA,AaronNGray,85523,Aaron Gray,aaronngray@gmail.com,NA,2021-02-08T17:14:28Z,2021-02-08T17:14:28Z,"```
mvn archetype:generate -DarchetypeGroupId=com.digitalpebble.stormcrawler -DarchetypeArtifactId=storm-crawler-elasticsearch-archetype -DarchetypeVersion=2.0
```
>how did you generate the topology?
./ES_IndexInit.sh

es-conf.yaml
```
# configuration for Elasticsearch resources

config:
  # ES indexer bolt
  # adresses can be specified as a full URL
  # if not we assume that the protocol is http and the port 9200
  es.indexer.addresses: ""localhost""
  es.indexer.index.name: ""content""
  # es.indexer.pipeline: ""_PIPELINE_""
  es.indexer.create: false
  es.indexer.bulkActions: 100
  es.indexer.flushInterval: ""2s""
  es.indexer.concurrentRequests: 1

  # ES metricsConsumer
  es.metrics.addresses: ""http://localhost:9200""
  es.metrics.index.name: ""metrics""

  # ES spout and persistence bolt
  es.status.addresses: ""http://localhost:9200""
  es.status.index.name: ""status""
  #es.status.user: ""USERNAME""
  #es.status.password: ""PASSWORD""
  # the routing is done on the value of 'partition.url.mode'
  es.status.routing: true
  # stores the value used for grouping the URLs as a separate field
  # needed by the spout implementations
  # also used for routing if the value above is set to true
  es.status.routing.fieldname: ""key""
  es.status.bulkActions: 500
  es.status.flushInterval: ""5s""
  es.status.concurrentRequests: 1

    # spout config #

  # positive or negative filters parsable by the Lucene Query Parser
  # es.status.filterQuery:
  #  - ""-(key:stormcrawler.net)""
  #  - ""-(key:digitalpebble.com)""

  # time in secs for which the URLs will be considered for fetching after a ack of fail
  spout.ttl.purgatory: 30

  # Min time (in msecs) to allow between 2 successive queries to ES
  spout.min.delay.queries: 2000

  # Delay since previous query date (in secs) after which the nextFetchDate value will be reset to the current time
  # Setting this to -1 or a large value means that the ES will cache the results but also that less and less results
  # might be returned.
  spout.reset.fetchdate.after: 120

  es.status.max.buckets: 50
  es.status.max.urls.per.bucket: 2
  # field to group the URLs into buckets
  es.status.bucket.field: ""key""
  # fields to sort the URLs within a bucket
  es.status.bucket.sort.field:
   - ""nextFetchDate""
   - ""url""
  # field to sort the buckets
  es.status.global.sort.field: ""nextFetchDate""

  # CollapsingSpout : limits the deep paging by resetting the start offset for the ES query
  es.status.max.start.offset: 500

  # AggregationSpout : sampling improves the performance on large crawls
  es.status.sample: false

  # max allowed duration of a query in sec
  es.status.query.timeout: -1

  # AggregationSpout (expert): adds this value in mins to the latest date returned in the results and
  # use it as nextFetchDate
  es.status.recentDate.increase: -1
  es.status.recentDate.min.gap: -1

  topology.metrics.consumer.register:
       - class: ""com.digitalpebble.stormcrawler.elasticsearch.metrics.MetricsConsumer""
         parallelism.hint: 1
         #whitelist:
         #  - ""fetcher_counter""
         #  - ""fetcher_average.bytes_fetched""
         #blacklist:
         #  - ""__receive.*""
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTMwMTAwMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/857,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTMwOTcxOQ==,incubator-stormcrawler,775309719,857,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-02-08T17:25:02Z,2021-02-08T17:25:02Z,"Fab, thanks.
let me have a look. Judging by the content, the es-conf is the same as the one generated by the archetype","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTMwOTcxOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/857,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTMxMDIwMA==,incubator-stormcrawler,775310200,857,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-02-08T17:25:38Z,2021-02-08T17:25:38Z,Running locally or remotely?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTMxMDIwMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/857,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTMxMjI1Mw==,incubator-stormcrawler,775312253,857,NA,AaronNGray,85523,Aaron Gray,aaronngray@gmail.com,NA,2021-02-08T17:28:33Z,2021-02-08T17:28:33Z,"locally under Ubuntu on WSL2
```
storm local target/stormcrawler-1.0-SNAPSHOT.jar global.climateemergency.ESCrawlTopology -conf crawler-conf.yaml -conf es-conf.yaml . seeds.txt
```

It still seems to refer to `[stormcrawler-1.0-SNAPSHOT.jar`

```
17:25:53.681 [Thread-37-indexer-executor[8, 8]] ERROR c.d.s.e.b.IndexerBolt - Can't connect to ElasticSearch
java.lang.IllegalArgumentException: hosts must not be null nor empty
        at org.elasticsearch.client.RestClient.builder(RestClient.java:173) ~[stormcrawler-1.0-SNAPSHOT.jar:?]
        at com.digitalpebble.stormcrawler.elasticsearch.ElasticSearchConnection.getClient(ElasticSearchConnection.java:117) ~[stormcrawler-1.0-SNAPSHOT.jar:?]
        at com.digitalpebble.stormcrawler.elasticsearch.ElasticSearchConnection.getConnection(ElasticSearchConnection.java:241) ~[stormcrawler-1.0-SNAPSHOT.jar:?]
        at com.digitalpebble.stormcrawler.elasticsearch.bolt.IndexerBolt.prepare(IndexerBolt.java:117) [stormcrawler-1.0-SNAPSHOT.jar:?]
        at org.apache.storm.executor.bolt.BoltExecutor.init(BoltExecutor.java:147) [storm-client-2.2.0.jar:2.2.0]
        at org.apache.storm.executor.bolt.BoltExecutor.call(BoltExecutor.java:157) [storm-client-2.2.0.jar:2.2.0]
        at org.apache.storm.executor.bolt.BoltExecutor.call(BoltExecutor.java:59) [storm-client-2.2.0.jar:2.2.0]
        at org.apache.storm.utils.Utils$1.run(Utils.java:389) [storm-client-2.2.0.jar:2.2.0]
        at java.lang.Thread.run(Thread.java:834) [?:?]
```","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTMxMjI1Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/857,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTMxNjMzOQ==,incubator-stormcrawler,775316339,857,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-02-08T17:35:02Z,2021-02-08T17:35:02Z,"> It still seems to refer to [stormcrawler-1.0-SNAPSHOT.jar

that's just the name of the uberjar built with `mvn clean package` and you'd have the same problem when running with Flux","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTMxNjMzOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/857,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTMxODQ5OA==,incubator-stormcrawler,775318498,857,NA,AaronNGray,85523,Aaron Gray,aaronngray@gmail.com,NA,2021-02-08T17:38:35Z,2021-02-08T17:38:35Z,"I will restart and move to a linux server tomorrow. But it would good to know what is causing this. 

`ElasticSearchConnection.java:117` looks pretty simple though and I dont know how it would fail.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTMxODQ5OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/857,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTMyMDUwNQ==,incubator-stormcrawler,775320505,857,NA,AaronNGray,85523,Aaron Gray,aaronngray@gmail.com,NA,2021-02-08T17:41:49Z,2021-02-08T17:41:49Z,"On an asside I would like to move Zookeeper, Storm, and ElasticSearch to being services rather than just servers.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTMyMDUwNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/857,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTM0MTczNg==,incubator-stormcrawler,775341736,857,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-02-08T18:14:43Z,2021-02-08T18:14:43Z,"I can reproduce the problem - for some reason when running the Java topology, the '-conf' args are removed and the ConfigurableTopology only gets [crawler-conf.yaml, es-conf.yaml, ., seeds.txt] 
I will update the title of this issue accordingly and see if it can be fixed in the next release, in the meantime, please use Flux.
note; we had a discussion not long ago about removing the Java topology classes altogether as they are not as easily updatable and user friendly as their Flux counterpart.
thanks for reporting this @AaronNGray ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTM0MTczNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/857,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTM1NDA3Ng==,incubator-stormcrawler,775354076,857,NA,AaronNGray,85523,Aaron Gray,aaronngray@gmail.com,NA,2021-02-08T18:34:12Z,2021-02-08T18:34:12Z,@jnioche I need to use programmatic Topologies for my usecase(s) as I am planning on running multiple crawler and search engine instances.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTM1NDA3Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/857,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTM1NzQ0NA==,incubator-stormcrawler,775357444,857,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-02-08T18:40:05Z,2021-02-08T18:40:05Z,"to add to my previous comment: anything starting with '-c' gets removed by Storm 2. great.

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTM1NzQ0NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/857,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTM1ODc2NA==,incubator-stormcrawler,775358764,857,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-02-08T18:42:25Z,2021-02-08T18:42:25Z,"


> hows that happening ? Is it a bug in storm ?

or a feature? don't know

as Sebastian pointed out, support for Storm 2 is still experimental. you might be better off using Storm 1","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTM1ODc2NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/857,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTM1ODkwNw==,incubator-stormcrawler,775358907,857,NA,AaronNGray,85523,Aaron Gray,aaronngray@gmail.com,NA,2021-02-08T18:42:41Z,2021-02-08T18:42:41Z,Okay I will use Flex for now. But in the medium term I am going to be creating a seedable crawler/search engine,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTM1ODkwNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/857,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTM2MDMxNA==,incubator-stormcrawler,775360314,857,NA,AaronNGray,85523,Aaron Gray,aaronngray@gmail.com,NA,2021-02-08T18:45:14Z,2021-02-08T18:45:14Z,So Storm Crawler 2.x will work with Storm 1.2.3. Okay I will do that. And also use docker for Storm and Zookeeper :),"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTM2MDMxNA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/857,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTM2MTM3MQ==,incubator-stormcrawler,775361371,857,NA,AaronNGray,85523,Aaron Gray,aaronngray@gmail.com,NA,2021-02-08T18:47:04Z,2021-02-08T18:47:04Z,Thanks for the support !,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTM2MTM3MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/857,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTQwMjk1OA==,incubator-stormcrawler,775402958,857,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-02-08T19:55:35Z,2021-02-08T19:55:35Z,"> So Storm Crawler 2.x will work with Storm 1.2.3. Okay I will do that. And also use docker for Storm and Zookeeper :)

nope, as I mentioned earlier, Storm Crawler 2.x will **not** work with Storm 1.2.3, you need to use the main branch of SC (1.x) and Apache Storm 1.2.3","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTQwMjk1OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/857,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTQwNTI2NA==,incubator-stormcrawler,775405264,857,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-02-08T19:57:45Z,2021-02-08T19:57:45Z,">  And also use docker for Storm and Zookeeper :)

good idea
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTQwNTI2NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/857,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTc0NTU2Mw==,incubator-stormcrawler,775745563,857,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-02-09T07:56:33Z,2021-02-09T07:56:33Z,"https://issues.apache.org/jira/browse/STORM-3742

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc3NTc0NTU2Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/857,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc5MTkxNzg4Mg==,incubator-stormcrawler,791917882,857,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-03-06T11:21:14Z,2021-03-06T11:21:14Z,@AaronNGray the trick is to insert '--' after ESCrawlTopology (see issue above). Will modify the READMEs for the 2.x branch.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc5MTkxNzg4Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/857,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc5MjcyMzIwMw==,incubator-stormcrawler,792723203,857,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2021-03-08T12:27:43Z,2021-03-08T12:27:43Z,"> insert '--' after ESCrawlTopology

See #774.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc5MjcyMzIwMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/857,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc5Mjc3NjE1Nw==,incubator-stormcrawler,792776157,857,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-03-08T14:02:54Z,2021-03-08T14:02:54Z,"ahh, thanks @sebastian-nagel, need to fix my previous commit, we already had it for the basic archetype. I really have the memory  of a goldfish","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc5Mjc3NjE1Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/858,https://api.github.com/repos/apache/incubator-stormcrawler/issues/858,incubator-stormcrawler,818628857,858,Archetypes generate topologies with Tika parsing ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2021-03-01T08:45:54Z,2021-03-01T09:34:06Z,"https://twitter.com/digitalpebble/status/1364133893700530178

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/858/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/859,https://api.github.com/repos/apache/incubator-stormcrawler/issues/859,incubator-stormcrawler,818675389,859,Add Deletion bolt to Flux version of the Elasticsearch topo from the archetype ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2021-03-01T09:33:53Z,2021-03-01T09:48:13Z,"Quite a long title. Put simply the Java version of the topology has the Deletion bolt whereas the Flux one doesn't
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/859/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/860,https://api.github.com/repos/apache/incubator-stormcrawler/issues/860,incubator-stormcrawler,818690823,860,Add MimeTypeNormalization parse filter to topologies generated from archetypes,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2021-03-01T09:52:21Z,2021-03-01T10:33:59Z,"The **MimeTypeNormalization** converts the mime-type values (returned by the servers or guessed based on the content) as human-readable values such as pdf, html or image and stores them in the metadata. This can be used during indexing to generate a field used for filtering search results.

Now that we added parsing with Tika through #858, it would be nice to add this parse filter to the topologies. The generated field is useful for a typical search engine system.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/860/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/861,https://api.github.com/repos/apache/incubator-stormcrawler/issues/861,incubator-stormcrawler,819960484,861,Do not generate a nextFetchDate at all if the scheduling is set to NEVER,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2021-03-02T12:12:58Z,2021-03-29T10:08:06Z,"Setting a date in a far distant future is a way of preventing URLs to be ever returned, however, the same result would be achieved by not setting a fetch date at all. The benefit of the latter would be a gain in storage space and possibly faster queries (to be tested).
An URL can always be updated with a nextFetchDate later on if necessary.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/861/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/861,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc5MTM1MDkxMw==,incubator-stormcrawler,791350913,861,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-03-05T11:08:40Z,2021-03-05T11:08:40Z,"The scheduler interface could return an _Optional<Date>_ or an integer for a timestamp, with a value of -1 in case a URL doesn't need refetching. Relying on  _DefaultScheduler.NEVER_ to determine whether a _nextFetchDate_ should not be written is not ideal; there is no guarantee that the DefaultScheduler is used. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc5MTM1MDkxMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/862,https://api.github.com/repos/apache/incubator-stormcrawler/issues/862,incubator-stormcrawler,822653745,862,in domain depth and out domain depth,zhongwei2014,9468822,,,CLOSED,2021-03-05T01:29:14Z,2021-03-11T07:12:57Z,"
 
 Can we have a separate depth configuration for in domain and out of domain. For example, I would like to crawl the outside url if it is a direct outlink from this domain, but I don't want to crawl the whole site of the other domain, can I set the in_domain depth to 100, and outside domain depth to 0?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/862/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/862,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc5MTI5NTQ1MA==,incubator-stormcrawler,791295450,862,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2021-03-05T09:33:08Z,2021-03-05T09:33:08Z,"I do not fully understand your use case
- with depth = 0 the filter ""MaxDepthFilter"" would not follow any outlinks
- depth = 1 would mean you allow one outlink, but would you also accept links to the external domain from deep pages on your source domain? Or only from the seed / home page?

The [filter method](/DigitalPebble/storm-crawler/blob/2d4ed3d28a943198c85dead2715e102593f09cad/core/src/main/java/com/digitalpebble/stormcrawler/filtering/depth/MaxDepthFilter.java#L55) gets both source and target URL as arguments, so it can be modified to fit your use case. E.g., in case of a link to an external domain increment the depth by 100. Max depth is set to 100 and for internal links it is incremented as usual by 1.

A final note: the filter ""HostURLFilter"" provides an option `ignoreOutsideDomain`, if true links to external domains are not followed at all.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc5MTI5NTQ1MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/862,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc5MTMxODU1Ng==,incubator-stormcrawler,791318556,862,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-03-05T10:09:56Z,2021-03-05T10:09:56Z,"that's a great question @zhongwei2014, thanks! There are probably several ways to do that.

You could for instance write a custom ParseFilter first so that outlinks outside the original domain get a key / value in their metadata when the source page is parsed, then write a custom URL Filter so that any outlinks found later on for a page with that key in its metadata get removed. You will need to add that key to   _metadata.persist_ in your config.

Does that make sense?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc5MTMxODU1Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/862,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc5MTMyMTA1OQ==,incubator-stormcrawler,791321059,862,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-03-05T10:14:17Z,2021-03-05T10:14:17Z,"the problem with the solution above is that it won't work for redirections, only for outlinks. I'll have a think and come back later with a different suggestion.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc5MTMyMTA1OQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/862,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc5MjYzNTgzNw==,incubator-stormcrawler,792635837,862,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-03-08T09:58:41Z,2021-03-08T09:58:41Z,"@zhongwei2014 the best way to do it would be to extend the default implementation of [MetadataTransfer](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/util/MetadataTransfer.java) and in  _getMetaForOutlink()_ increment the depth by whichever value is beyond your threshold if the source and target belong to different domains. this would work for outlinks as well as redirections.
The transfer is pluggable and you can set the implementation to use via _metadata.transfer.class_ in the config.
Let us know if it worked for you
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc5MjYzNTgzNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/862,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc5Mjk3MDM2Nw==,incubator-stormcrawler,792970367,862,NA,zhongwei2014,9468822,,,NA,2021-03-08T18:23:03Z,2021-03-08T18:23:03Z,"Thanks. I was thinking about extending a filter (depth or host) class, but this might be a better place. I will let you know.
Thanks. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc5Mjk3MDM2Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/862,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc5NjUxODQ0MA==,incubator-stormcrawler,796518440,862,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-03-11T07:12:56Z,2021-03-11T07:12:56Z,"Closing for now, please reopen if the solution I suggested didn't work @zhongwei2014 ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDc5NjUxODQ0MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/863,https://api.github.com/repos/apache/incubator-stormcrawler/issues/863,incubator-stormcrawler,823626399,863,Upgrade to Storm 2.2.0 in archetypes,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2021-03-06T11:30:28Z,2021-03-08T09:46:24Z,"
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/863/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/864,https://api.github.com/repos/apache/incubator-stormcrawler/issues/864,incubator-stormcrawler,833386346,864,[Patch] Update the Wiki to include more configuration information and some hierarchy,psa-neutronian,80069036,,,CLOSED,2021-03-17T04:20:53Z,2021-03-19T14:38:37Z,"I've gone through the components in core and updated the documentation to include every call to ConfUtils. I've also added a bit of structure (folders and a custom sidebar) to make it a little easier to find things.

Here's the commits: https://github.com/psa/storm-crawler-wiki/commits/config-updates
Here's what they look like: https://github.com/psa/storm-crawler-wiki/wiki

Unfortunately, wiki's don't have the ability to do pull requests so the merge needs to be done as a clone + rsync or similar. 

I plan on doing the external modules next, feedback appreciated.

This work paid for by https://neutronian.com/","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/864/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/864,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgwMDc4NzExNw==,incubator-stormcrawler,800787117,864,NA,psa-neutronian,80069036,,,NA,2021-03-17T04:35:58Z,2021-03-17T04:35:58Z,"To make pull requests on the wiki easier, could a separate repository be created that automatically synchronizes to the wiki, similar to what's being doing in https://github.com/devonfw/devon4j/blob/develop/.travis.yml? ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgwMDc4NzExNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/864,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgwMDk0MzI5NA==,incubator-stormcrawler,800943294,864,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-03-17T09:44:20Z,2021-03-17T09:44:20Z,"Thanks a lot @psa-neutronian, I will have a look at your changes and the mechanism to sync the WIKI.
Alternatively, I could also give you write access to the WIKI.
Is StormCrawler used by Neutronian? ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgwMDk0MzI5NA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/864,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgwMTU2ODgwNw==,incubator-stormcrawler,801568807,864,NA,psa-neutronian,80069036,,,NA,2021-03-18T02:28:34Z,2021-03-18T02:28:34Z,"If you're happy with giving me wiki write access, I'm happy to do updates. Any review process?

Neutronian is considering using it and doing due diligence before diving in.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgwMTU2ODgwNw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/864,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgwMjAwMjg5Mw==,incubator-stormcrawler,802002893,864,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-03-18T15:05:31Z,2021-03-18T15:05:31Z,"Have temporarily given you rights access. Given that it is not possible to PR the WIKI, I'll just review your changes afterwards.
Great to hear about Neutronian's interest; I'd be interested in feedback after the due diligence.
Thanks!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgwMjAwMjg5Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/864,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgwMjg0MzQ4OA==,incubator-stormcrawler,802843488,864,NA,psa-neutronian,80069036,,,NA,2021-03-19T13:44:28Z,2021-03-19T13:44:28Z,"Changes pushed.

As mentioned earlier, I'm working on more changes for the external modules and I'll open another ticket for those.

If you want me to make changes for this update, please re-open and I'll do so.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgwMjg0MzQ4OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/864,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgwMjg4MDkwMQ==,incubator-stormcrawler,802880901,864,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-03-19T14:38:37Z,2021-03-19T14:38:37Z,"Looks good, thanks Paul","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgwMjg4MDkwMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/865,https://api.github.com/repos/apache/incubator-stormcrawler/issues/865,incubator-stormcrawler,836078671,865,Add URLFrontier module,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2021-03-19T14:47:16Z,2021-03-29T10:42:21Z,Merge branch for [url-frontier](https://github.com/crawler-commons/url-frontier) as soon as the client library is available from Maven Central.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/865/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/867,https://api.github.com/repos/apache/incubator-stormcrawler/issues/867,incubator-stormcrawler,842186960,867,Send host info on a specific stream ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,OPEN,2021-03-26T17:57:31Z,2023-09-04T11:08:22Z,"Could be used to notify that a status HTTP 429 has been caught (see ##784 on that topic) or that the robots.txt specified a delay.
A bespoke bolt could then notify a URL Frontier via [setDelay](https://github.com/crawler-commons/url-frontier/blob/master/API/urlfrontier.proto#L55) or [blockQueueUntil](https://github.com/crawler-commons/url-frontier/blob/master/API/urlfrontier.proto#L45)

see #504 for a related discussion
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/867/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/869,https://api.github.com/repos/apache/incubator-stormcrawler/issues/869,incubator-stormcrawler,846184530,869,Upgrade to Tika 1.26,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2021-03-31T08:32:00Z,2021-04-09T07:19:29Z,https://downloads.apache.org/tika/CHANGES-1.26.txt,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/869/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/870,https://api.github.com/repos/apache/incubator-stormcrawler/issues/870,incubator-stormcrawler,849740404,870,getCharsetFromMeta StringIndexOutOfBoundsException: String index out of range: -9999,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2021-04-03T21:11:06Z,2021-04-09T07:09:47Z,"19633413 [Thread-24-parse-executor[7 7]] INFO  c.d.s.b.JSoupParserBolt - Parsing : starting https://indicator.natwest.com:443/
19633417 [Thread-24-parse-executor[7 7]] ERROR o.a.s.util - Async loop died!
java.lang.RuntimeException: java.lang.StringIndexOutOfBoundsException: String index out of range: -9999
	at org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:522) ~[storm-core-1.2.3.jar:1.2.3]
	at org.apache.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:487) ~[storm-core-1.2.3.jar:1.2.3]
	at org.apache.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:74) ~[storm-core-1.2.3.jar:1.2.3]
	at org.apache.storm.daemon.executor$fn__10180$fn__10193$fn__10246.invoke(executor.clj:861) ~[storm-core-1.2.3.jar:1.2.3]
	at org.apache.storm.util$async_loop$fn__624.invoke(util.clj:484) [storm-core-1.2.3.jar:1.2.3]
	at clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_282]
Caused by: java.lang.StringIndexOutOfBoundsException: String index out of range: -9999
	at java.lang.String.substring(String.java:1967) ~[?:1.8.0_282]
	at com.digitalpebble.stormcrawler.util.CharsetIdentification.getCharsetFromMeta(CharsetIdentification.java:189) ~[crawlurlfrontier-1.0-SNAPSHOT.jar:?]
	at com.digitalpebble.stormcrawler.util.CharsetIdentification.getCharsetFast(CharsetIdentification.java:56) ~[crawlurlfrontier-1.0-SNAPSHOT.jar:?]
	at com.digitalpebble.stormcrawler.bolt.JSoupParserBolt.execute(JSoupParserBolt.java:227) ~[crawlurlfrontier-1.0-SNAPSHOT.jar:?]
	at org.apache.storm.daemon.executor$fn__10180$tuple_action_fn__10182.invoke(executor.clj:739) ~[storm-core-1.2.3.jar:1.2.3]
	at org.apache.storm.daemon.executor$mk_task_receiver$fn__10101.invoke(executor.clj:468) ~[storm-core-1.2.3.jar:1.2.3]
	at org.apache.storm.disruptor$clojure_handler$reify__9612.onEvent(disruptor.clj:41) ~[storm-core-1.2.3.jar:1.2.3]
	at org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:509) ~[storm-core-1.2.3.jar:1.2.3]
	... 6 more
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/870/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/870,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgxMjkzNTY4Mw==,incubator-stormcrawler,812935683,870,NA,kkrugler,66217,Ken Krugler,ken@transpac.com,NA,2021-04-03T22:41:32Z,2021-04-03T22:41:32Z,"If the subsequent `""` isn't found (so `end == -1`), then `substring()` shouldn't be called here:

``` java
        // fast search for e.g. <meta charset=""utf-8"">
        // might not get it 100% but should be frequent enough
        // and faster than parsing
        int start = html.indexOf(""<meta charset=\"""");
        if (start != -1) {
            int end = html.indexOf('""', start + 15);
            return validateCharset(html.substring(start + 15, end));
        }
```

But I don't see how either index to `substring()` could be -9999.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgxMjkzNTY4Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/870,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgxNjQ2Mjg1Mw==,incubator-stormcrawler,816462853,870,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-04-09T07:04:37Z,2021-04-09T07:04:37Z,"@kkrugler, you are right. 

we take up to 10K characters to find the charset and on that particular URL, the charset info is at the very end but is cut before it finishes

    _<meta charset=""u_
    
The exception message thrown by _substring()_ is confusing indeed.

Will fix shortly 

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgxNjQ2Mjg1Mw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/875,https://api.github.com/repos/apache/incubator-stormcrawler/issues/875,incubator-stormcrawler,863927694,875,need a more reliable detection of whether a document has been already parsed by Jsoup,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2021-04-21T14:03:00Z,2021-04-25T09:04:18Z,"Now that the archetypes provide Tika as well as JSoup, we come across cases where a HTML document is parsed by Jsoup but has no text (e.g frameset). See also for instance http://johnnycashstore.com/

The problem comes from the fact that he redirection bolt looks at the presence of text to determine whether a URL has already been parsed. Instead, we should inject a K/V in the metadata and use that instead","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/875/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/876,https://api.github.com/repos/apache/incubator-stormcrawler/issues/876,incubator-stormcrawler,864962935,876,URL Frontier status updater pushing messages too quickly,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2021-04-22T13:38:05Z,2021-04-22T14:58:34Z,"Seeing 

```
java.lang.RuntimeException: io.grpc.netty.shaded.io.netty.util.internal.OutOfDirectMemoryError: failed to allocate 2097152 byte(s) of direct memory (used: 1908408599, max: 1908932608)
	at org.apache.storm.utils.Utils$1.run(Utils.java:409) ~[storm-client-2.2.0.jar:2.2.0]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_282]
Caused by: io.grpc.netty.shaded.io.netty.util.internal.OutOfDirectMemoryError: failed to allocate 2097152 byte(s) of direct memory (used: 1908408599, max: 1908932608)
	at io.grpc.netty.shaded.io.netty.util.internal.PlatformDependent.incrementMemoryCounter(PlatformDependent.java:754) ~[stormjar.jar:?]
	at io.grpc.netty.shaded.io.netty.util.internal.PlatformDependent.allocateDirectNoCleaner(PlatformDependent.java:709) ~[stormjar.jar:?]
	at io.grpc.netty.shaded.io.netty.buffer.PoolArena$DirectArena.allocateDirect(PoolArena.java:755) ~[stormjar.jar:?]
	at io.grpc.netty.shaded.io.netty.buffer.PoolArena$DirectArena.newChunk(PoolArena.java:731) ~[stormjar.jar:?]
	at io.grpc.netty.shaded.io.netty.buffer.PoolArena.allocateNormal(PoolArena.java:247) ~[stormjar.jar:?]
	at io.grpc.netty.shaded.io.netty.buffer.PoolArena.allocate(PoolArena.java:215) ~[stormjar.jar:?]
	at io.grpc.netty.shaded.io.netty.buffer.PoolArena.allocate(PoolArena.java:147) ~[stormjar.jar:?]
	at io.grpc.netty.shaded.io.netty.buffer.PooledByteBufAllocator.newDirectBuffer(PooledByteBufAllocator.java:356) ~[stormjar.jar:?]
	at io.grpc.netty.shaded.io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:187) ~[stormjar.jar:?]
	at io.grpc.netty.shaded.io.netty.buffer.AbstractByteBufAllocator.buffer(AbstractByteBufAllocator.java:123) ~[stormjar.jar:?]
	at io.grpc.netty.shaded.io.grpc.netty.NettyWritableBufferAllocator.allocate(NettyWritableBufferAllocator.java:51) ~[stormjar.jar:?]
	at io.grpc.internal.MessageFramer.writeKnownLengthUncompressed(MessageFramer.java:227) ~[stormjar.jar:?]
	at io.grpc.internal.MessageFramer.writeUncompressed(MessageFramer.java:168) ~[stormjar.jar:?]
	at io.grpc.internal.MessageFramer.writePayload(MessageFramer.java:141) ~[stormjar.jar:?]
	at io.grpc.internal.AbstractStream.writeMessage(AbstractStream.java:65) ~[stormjar.jar:?]
	at io.grpc.internal.ForwardingClientStream.writeMessage(ForwardingClientStream.java:37) ~[stormjar.jar:?]
	at io.grpc.internal.DelayedStream.writeMessage(DelayedStream.java:252) ~[stormjar.jar:?]
	at io.grpc.internal.ClientCallImpl.sendMessageInternal(ClientCallImpl.java:580) ~[stormjar.jar:?]
	at io.grpc.internal.ClientCallImpl.sendMessage(ClientCallImpl.java:564) ~[stormjar.jar:?]
	at io.grpc.internal.DelayedClientCall.sendMessage(DelayedClientCall.java:317) ~[stormjar.jar:?]
	at io.grpc.stub.ClientCalls$CallToStreamObserverAdapter.onNext(ClientCalls.java:364) ~[stormjar.jar:?]
	at com.digitalpebble.stormcrawler.urlfrontier.StatusUpdaterBolt.store(StatusUpdaterBolt.java:164) ~[stormjar.jar:?]
	at com.digitalpebble.stormcrawler.persistence.AbstractStatusUpdaterBolt.execute(AbstractStatusUpdaterBolt.java:250) ~[stormjar.jar:?]
	at org.apache.storm.executor.bolt.BoltExecutor.tupleActionFn(BoltExecutor.java:236) ~[storm-client-2.2.0.jar:2.2.0]
	at org.apache.storm.executor.Executor.accept(Executor.java:283) ~[storm-client-2.2.0.jar:2.2.0]
	at org.apache.storm.utils.JCQueue.consumeImpl(JCQueue.java:131) ~[storm-client-2.2.0.jar:2.2.0]
	at org.apache.storm.utils.JCQueue.consume(JCQueue.java:111) ~[storm-client-2.2.0.jar:2.2.0]
	at org.apache.storm.executor.bolt.BoltExecutor$1.call(BoltExecutor.java:172) ~[storm-client-2.2.0.jar:2.2.0]
	at org.apache.storm.executor.bolt.BoltExecutor$1.call(BoltExecutor.java:159) ~[storm-client-2.2.0.jar:2.2.0]
	at org.apache.storm.utils.Utils$1.run(Utils.java:394) ~[storm-client-2.2.0.jar:2.2.0]
```

which according to  https://github.com/grpc/grpc-java/issues/2247 could be an indication that some throttling is needed.

Will try adding a max outgoing message config to see if it fixes it.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/876/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/878,https://api.github.com/repos/apache/incubator-stormcrawler/issues/878,incubator-stormcrawler,866959753,878,Track time spent in DNS resolution by OKHTTP protocol,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2021-04-25T09:16:47Z,2021-04-27T10:50:37Z,"This can be done very neatly with [Events](https://square.github.io/okhttp/events/)

The protocol instances can't report metrics directly but could add key values to the metadata; the Fetcher could look for those and send them to the metrics. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/878/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/879,https://api.github.com/repos/apache/incubator-stormcrawler/issues/879,incubator-stormcrawler,867494698,879,Spout to stream incoming results instead of using a blocking call,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2021-04-26T09:38:38Z,2021-04-26T10:42:42Z,"_GetURLs_ in URLFrontier streams the results. The spout should leverage that instead of using blocking calls.
The service processes eligible queues one by one, by streaming the results we would start crawling for the first results returned while the backend still works on the other queues.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/879/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/880,https://api.github.com/repos/apache/incubator-stormcrawler/issues/880,incubator-stormcrawler,867713255,880,2.x Jackson version conflict when running in local mode?,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2021-04-26T13:36:09Z,2021-10-06T11:05:30Z,"
Does not happen in remote mode, only when running in local

```
14:32:01.031 [Thread-49-tika-executor[24, 24]] ERROR o.a.s.u.Utils - Async loop died!
java.lang.VerifyError: Stack map does not match the one at exception handler 77
Exception Details:
  Location:
    com/fasterxml/jackson/databind/deser/std/StdDeserializer._parseDate(Lcom/fasterxml/jackson/core/JsonParser;Lcom/fasterxml/jackson/databind/DeserializationContext;)Ljava/util/Date; @77: astore
  Reason:
    Type 'com/fasterxml/jackson/core/JsonParseException' (current frame, stack[0]) is not assignable to 'com/fasterxml/jackson/core/exc/StreamReadException' (stack map, stack[0])
  Current Frame:
    bci: @69
    flags: { }
    locals: { 'com/fasterxml/jackson/databind/deser/std/StdDeserializer', 'com/fasterxml/jackson/core/JsonParser', 'com/fasterxml/jackson/databind/DeserializationContext' }
    stack: { 'com/fasterxml/jackson/core/JsonParseException' }
  Stackmap Frame:
    bci: @77
    flags: { }
    locals: { 'com/fasterxml/jackson/databind/deser/std/StdDeserializer', 'com/fasterxml/jackson/core/JsonParser', 'com/fasterxml/jackson/databind/DeserializationContext' }
    stack: { 'com/fasterxml/jackson/core/exc/StreamReadException' }
  Bytecode:
    0x0000000: 2bb6 0035 aa00 0000 0000 0081 0000 0003
    0x0000010: 0000 000b 0000 007a 0000 0081 0000 0081
    0x0000020: 0000 0034 0000 0041 0000 0081 0000 0081
    0x0000030: 0000 0081 0000 0071 2a2b b600 11b6 0012
    0x0000040: 2cb6 006b b02b b600 4742 a700 223a 052c
    0x0000050: 2ab4 0002 2bb6 006e 126f 03bd 0004 b600
    0x0000060: 70c0 002d 3a06 1906 b600 4c42 bb00 7159
    0x0000070: 21b7 0072 b02a 2cb6 0073 c000 71b0 2a2b
    0x0000080: 2cb6 0074 b02c 2ab4 0002 2bb6 0025 c000
    0x0000090: 71b0                                   
  Exception Handler Table:
    bci [69, 74] => handler: 77
    bci [69, 74] => handler: 77
  Stackmap Table:
    same_frame(@56)
    same_frame(@69)
    same_locals_1_stack_item_frame(@77,Object[#359])
    append_frame(@108,Long)
    chop_frame(@117,1)
    same_frame(@126)
    same_frame(@133)

	at com.fasterxml.jackson.databind.deser.BasicDeserializerFactory.createTreeDeserializer(BasicDeserializerFactory.java:1513) ~[crawl2-1.0-SNAPSHOT.jar:?]
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createDeserializer2(DeserializerCache.java:409) ~[crawl2-1.0-SNAPSHOT.jar:?]
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createDeserializer(DeserializerCache.java:349) ~[crawl2-1.0-SNAPSHOT.jar:?]
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:264) ~[crawl2-1.0-SNAPSHOT.jar:?]
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCacheValueDeserializer(DeserializerCache.java:244) ~[crawl2-1.0-SNAPSHOT.jar:?]
	at com.fasterxml.jackson.databind.deser.DeserializerCache.findValueDeserializer(DeserializerCache.java:142) ~[crawl2-1.0-SNAPSHOT.jar:?]
	at com.fasterxml.jackson.databind.DeserializationContext.findRootValueDeserializer(DeserializationContext.java:476) ~[crawl2-1.0-SNAPSHOT.jar:?]
	at com.fasterxml.jackson.databind.ObjectMapper._findRootDeserializer(ObjectMapper.java:4389) ~[crawl2-1.0-SNAPSHOT.jar:?]
	at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4198) ~[crawl2-1.0-SNAPSHOT.jar:?]
	at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3242) ~[crawl2-1.0-SNAPSHOT.jar:?]
	at com.digitalpebble.stormcrawler.filtering.URLFilters.loadJSONResources(URLFilters.java:99) ~[crawl2-1.0-SNAPSHOT.jar:?]
	at com.digitalpebble.stormcrawler.JSONResource.loadJSONResources(JSONResource.java:52) ~[crawl2-1.0-SNAPSHOT.jar:?]
	at com.digitalpebble.stormcrawler.filtering.URLFilters.<init>(URLFilters.java:89) ~[crawl2-1.0-SNAPSHOT.jar:?]
	at com.digitalpebble.stormcrawler.filtering.URLFilters.fromConf(URLFilters.java:68) ~[crawl2-1.0-SNAPSHOT.jar:?]
	at com.digitalpebble.stormcrawler.tika.ParserBolt.prepare(ParserBolt.java:109) ~[crawl2-1.0-SNAPSHOT.jar:?]
	at org.apache.storm.executor.bolt.BoltExecutor.init(BoltExecutor.java:147) ~[storm-client-2.2.0.jar:2.2.0]
	at org.apache.storm.executor.bolt.BoltExecutor.call(BoltExecutor.java:157) ~[storm-client-2.2.0.jar:2.2.0]
	at org.apache.storm.executor.bolt.BoltExecutor.call(BoltExecutor.java:59) ~[storm-client-2.2.0.jar:2.2.0]
	at org.apache.storm.utils.Utils$1.run(Utils.java:389) [storm-client-2.2.0.jar:2.2.0]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_282]
14:32:01.031 [Thread-48-filter-executor[6, 6]] ERROR o.a.s.u.Utils - Async loop died!
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/880/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/880,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgyNzQ3Njg2Mg==,incubator-stormcrawler,827476862,880,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-04-27T09:52:54Z,2021-04-27T09:52:54Z,"One of the differences between remote and local in Storm 2 resides in the classpath

**REMOTE**
`/usr/share/apache-storm-2.2.0/*:/usr/share/apache-storm-2.2.0/lib-worker/*:/usr/share/apache-storm-2.2.0/extlib/*:target/crawl2-1.0-SNAPSHOT.jar:/usr/share/apache-storm-2.2.0/conf:/usr/share/apache-storm-2.2.0/bin:`

**LOCAL**
`/usr/share/apache-storm-2.2.0/*:/usr/share/apache-storm-2.2.0/lib/*:/usr/share/apache-storm-2.2.0/extlib/*:target/crawl2-1.0-SNAPSHOT.jar:/usr/share/apache-storm-2.2.0/conf:/usr/share/apache-storm-2.2.0/bin:`

_lib-worker_ is used in remote and doesn't contain much whereas _lib_ contains Jackson 2.9.8 which conflicts with 2.11.1 specified by our core module.

One option would be to downgrade to the same version as Storm - but we'll get all manners of alerts about it being unsafe.
Apparently, the next version of Storm will use [2.10](https://github.com/apache/storm/pull/3382/files).

We could use a different library in the core module altogether, but some of our other modules (ES, Tika) declare a dependency on it as well.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgyNzQ3Njg2Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/880,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgyNzUwMDg3Mg==,incubator-stormcrawler,827500872,880,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-04-27T10:33:17Z,2021-04-27T10:33:17Z,"
Adding 

```
	<dependencyManagement>
		<dependencies>
			<dependency>
				<groupId>com.fasterxml.jackson.core</groupId>
				<artifactId>jackson-databind</artifactId>
				<version>2.9.8</version>
			</dependency>
		</dependencies>
	</dependencyManagement>
```	
to the pom.xml of the topology made it work fine in local mode. Might add it commented out to the pom generated by the archetypes.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgyNzUwMDg3Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/880,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc43yf9T,incubator-stormcrawler,935984979,880,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-10-06T11:05:30Z,2021-10-06T11:05:30Z,Fixed by #911 ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc43yf9T/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/882,https://api.github.com/repos/apache/incubator-stormcrawler/issues/882,incubator-stormcrawler,871055442,882,Default setting for 'selenium.pageLoadTimeout' leads to 'InvalidArgumentException' when using Selenium protocol,piehld,19936765,Dennis Piehl,dennis.piehl@rcsb.org,CLOSED,2021-04-29T14:07:09Z,2023-09-29T09:07:17Z,"When trying to run Stormcrawler with the selenium protocol connected to chrome driver, the default setting for `selenium.pageLoadTimeout` of `-1` leads to the following exception: 
~~~
java.lang.RuntimeException: org.openqa.selenium.InvalidArgumentException: invalid argument: value must be a non-negative integer
~~~

**Versions:** 
- Ubuntu 18.04
- Stormcrawler 1.17
- Storm 1.2.3
- Selenium 4.0.0-alpha 6
- Chromedriver 90.0.4430.24

**Configurations**
### crawler-conf.yaml
~~~
config: 
  topology.workers: 3
  topology.message.timeout.secs: 3000
  topology.max.spout.pending: 100
  topology.debug: true

  fetcher.threads.number: 100
  
  # override the JVM parameters for the workers
  topology.worker.childopts: ""-Xmx2g -Djava.net.preferIPv4Stack=true""

  # mandatory when using Flux
  topology.kryo.register:
    - com.digitalpebble.stormcrawler.Metadata

  # lists the metadata to persist to storage
  # these are not transfered to the outlinks
  metadata.persist:
   - _redirTo
   - error.cause
   - error.source
   - isSitemap
   - isFeed

  http.agent.name: ""My crawler""
  http.agent.version: ""1.0""
  http.agent.description: """"
  http.agent.url: """"
  http.agent.email: """"

  # The maximum number of bytes for returned HTTP response bodies.
  # The fetched page will be trimmed to 65KB in this case
  # Set -1 to disable the limit.
  http.content.limit: -1 # default 65536

  parsefilters.config.file: ""parsefilters.json""
  urlfilters.config.file: ""urlfilters.json""

  # revisit a page daily (value in minutes)
  # set it to -1 to never refetch a page
  fetchInterval.default: 1440

  # revisit a page with a fetch error after 2 hours (value in minutes)
  # set it to -1 to never refetch a page
  fetchInterval.fetch.error: 120

  # never revisit a page with an error (or set a value in minutes)
  fetchInterval.error: -1

  # configuration for the classes extending AbstractIndexerBolt
  # indexer.md.filter: ""someKey=aValue""
  indexer.url.fieldname: ""url""
  indexer.text.fieldname: ""content""
  indexer.canonical.name: ""canonical""
  indexer.md.mapping:
  - parse.title=title
  - parse.keywords=keywords
  - parse.description=description
  - domain=domain

  # Metrics consumers:
  topology.metrics.consumer.register:
     - class: ""org.apache.storm.metric.LoggingMetricsConsumer""
       parallelism.hint: 1

  http.protocol.implementation: ""com.digitalpebble.stormcrawler.protocol.selenium.RemoteDriverProtocol""
  https.protocol.implementation: ""com.digitalpebble.stormcrawler.protocol.selenium.RemoteDriverProtocol""
  selenium.addresses: ""http://localhost:9515""
  selenium.setScriptTimeout: 10000
  # selenium.pageLoadTimeout: 10000   # <-- IF NOT ASSIGNED EXPLICITLY, THE DEFAULT VALUE RESULTS IN EXCEPTION
  selenium.implicitlyWait: 1000
  selenium.capabilities:
    goog:chromeOptions:
      args: 
      - ""--nosandbox""
      - ""--disable-dev-shm-usage""
      - ""--headless""
      - ""--disable-gpu""
~~~

### es-conf.yaml
~~~
config:
  # ES indexer bolt
  es.indexer.addresses: ""localhost""
  es.indexer.index.name: ""content""
  # es.indexer.pipeline: ""_PIPELINE_""
  es.indexer.create: false
  es.indexer.bulkActions: 100
  es.indexer.flushInterval: ""2s""
  es.indexer.concurrentRequests: 1
  
  # ES metricsConsumer
  es.metrics.addresses: ""http://localhost:9200""
  es.metrics.index.name: ""metrics""
  
  # ES spout and persistence bolt
  es.status.addresses: ""http://localhost:9200""
  es.status.index.name: ""status""
  es.status.routing: true
  es.status.routing.fieldname: ""key""
  es.status.bulkActions: 500
  es.status.flushInterval: ""5s""
  es.status.concurrentRequests: 1
  
    # spout config #
    
  # time in secs for which the URLs will be considered for fetching after a ack of fail
  spout.ttl.purgatory: 30
  
  # Min time (in msecs) to allow between 2 successive queries to ES
  spout.min.delay.queries: 2000

  # Delay since previous query date (in secs) after which the nextFetchDate value will be reset to the current time
  spout.reset.fetchdate.after: 120

  es.status.max.buckets: 50
  es.status.max.urls.per.bucket: 2
  # field to group the URLs into buckets
  es.status.bucket.field: ""key""
  # fields to sort the URLs within a bucket
  es.status.bucket.sort.field: 
   - ""nextFetchDate""
   - ""url""
  # field to sort the buckets
  es.status.global.sort.field: ""nextFetchDate""

  # CollapsingSpout : limits the deep paging by resetting the start offset for the ES query 
  es.status.max.start.offset: 500
  
  # AggregationSpout : sampling improves the performance on large crawls
  es.status.sample: false

  # max allowed duration of a query in sec 
  es.status.query.timeout: -1

  # AggregationSpout (expert): adds this value in mins to the latest date returned in the results and
  # use it as nextFetchDate
  es.status.recentDate.increase: -1
  es.status.recentDate.min.gap: -1

  topology.metrics.consumer.register:
       - class: ""com.digitalpebble.stormcrawler.elasticsearch.metrics.MetricsConsumer""
         parallelism.hint: 1
~~~

### es-crawler.flux
~~~
name: ""crawler""

includes:
    - resource: true
      file: ""/crawler-default.yaml""
      override: false

    - resource: false
      file: ""crawler-conf.yaml""
      override: true

    - resource: false
      file: ""es-conf.yaml""
      override: true

spouts:
  - id: ""spout""
    className: ""com.digitalpebble.stormcrawler.elasticsearch.persistence.AggregationSpout""
    parallelism: 10

  - id: ""filespout""
    className: ""com.digitalpebble.stormcrawler.spout.FileSpout""
    parallelism: 1
    constructorArgs:
      - "".""
      - ""seeds.txt""
      - true

bolts:
  - id: ""filter""
    className: ""com.digitalpebble.stormcrawler.bolt.URLFilterBolt""
    parallelism: 3
  - id: ""partitioner""
    className: ""com.digitalpebble.stormcrawler.bolt.URLPartitionerBolt""
    parallelism: 3
  - id: ""fetcher""
    className: ""com.digitalpebble.stormcrawler.bolt.FetcherBolt""
    parallelism: 3
  - id: ""sitemap""
    className: ""com.digitalpebble.stormcrawler.bolt.SiteMapParserBolt""
    parallelism: 3
  - id: ""parse""
    className: ""com.digitalpebble.stormcrawler.bolt.JSoupParserBolt""
    parallelism: 12
  - id: ""index""
    className: ""com.digitalpebble.stormcrawler.elasticsearch.bolt.IndexerBolt""
    parallelism: 3
  - id: ""status""
    className: ""com.digitalpebble.stormcrawler.elasticsearch.persistence.StatusUpdaterBolt""
    parallelism: 3
  - id: ""status_metrics""
    className: ""com.digitalpebble.stormcrawler.elasticsearch.metrics.StatusMetricsBolt""
    parallelism: 3

streams:
  - from: ""spout""
    to: ""partitioner""
    grouping:
      type: SHUFFLE
      
  - from: ""spout""
    to: ""status_metrics""
    grouping:
      type: SHUFFLE     

  - from: ""partitioner""
    to: ""fetcher""
    grouping:
      type: FIELDS
      args: [""key""]

  - from: ""fetcher""
    to: ""sitemap""
    grouping:
      type: LOCAL_OR_SHUFFLE

  - from: ""sitemap""
    to: ""parse""
    grouping:
      type: LOCAL_OR_SHUFFLE

  - from: ""parse""
    to: ""index""
    grouping:
      type: LOCAL_OR_SHUFFLE

  - from: ""fetcher""
    to: ""status""
    grouping:
      type: FIELDS
      args: [""url""]
      streamId: ""status""

  - from: ""sitemap""
    to: ""status""
    grouping:
      type: FIELDS
      args: [""url""]
      streamId: ""status""

  - from: ""parse""
    to: ""status""
    grouping:
      type: FIELDS
      args: [""url""]
      streamId: ""status""

  - from: ""index""
    to: ""status""
    grouping:
      type: FIELDS
      args: [""url""]
      streamId: ""status""

  - from: ""filespout""
    to: ""filter""
    grouping:
      type: FIELDS
      args: [""url""]
      streamId: ""status""

  - from: ""filter""
    to: ""status""
    grouping:
      streamId: ""status""
      type: CUSTOM
      customClass:
        className: ""com.digitalpebble.stormcrawler.util.URLStreamGrouping""
        constructorArgs:
          - ""byDomain""
~~~

### parsefilters.json
~~~
{
  ""com.digitalpebble.stormcrawler.parse.ParseFilters"": [
    {
      ""class"": ""com.digitalpebble.stormcrawler.parse.filter.XPathFilter"",
      ""name"": ""XPathFilter"",
      ""params"": {
        ""canonical"": ""//*[@rel=\""canonical\""]/@href"",
        ""parse.description"": [
            ""//*[@name=\""description\""]/@content"",
            ""//*[@name=\""Description\""]/@content""
         ],
        ""parse.title"": [
            ""//TITLE"",
            ""//META[@name=\""title\""]/@content""
         ],
         ""parse.keywords"": ""//META[@name=\""keywords\""]/@content""
      }
    },
    {
      ""class"": ""com.digitalpebble.stormcrawler.parse.filter.LinkParseFilter"",
      ""name"": ""LinkParseFilter"",
      ""params"": {
         ""pattern"": ""//FRAME/@src""
       }
    },
    {
      ""class"": ""com.digitalpebble.stormcrawler.parse.filter.DomainParseFilter"",
      ""name"": ""DomainParseFilter"",
      ""params"": {
        ""key"": ""domain"",
        ""byHost"": false
       }
    },
    {
      ""class"": ""com.digitalpebble.stormcrawler.parse.filter.CommaSeparatedToMultivaluedMetadata"",
      ""name"": ""CommaSeparatedToMultivaluedMetadata"",
      ""params"": {
        ""keys"": [""parse.keywords""]
       }
    }
  ]
}
~~~

### pom.xml
~~~
<?xml version=""1.0"" encoding=""UTF-8""?>
<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">

	<modelVersion>4.0.0</modelVersion>
	<groupId>org.rcsb.crawler</groupId>
	<artifactId>stormcrawler</artifactId>
	<version>1.0-SNAPSHOT</version>
	<packaging>jar</packaging>

	<name>stormcrawler</name>

	<properties>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
		<stormcrawler.version>1.17</stormcrawler.version>
	</properties>

	<build>
		<plugins>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-compiler-plugin</artifactId>
				<version>3.2</version>
				<configuration>
					<source>1.8</source>
					<target>1.8</target>
				</configuration>
			</plugin>
			<plugin>
				<groupId>org.codehaus.mojo</groupId>
				<artifactId>exec-maven-plugin</artifactId>
				<version>1.3.2</version>
				<executions>
					<execution>
						<goals>
							<goal>exec</goal>
						</goals>
					</execution>
				</executions>
				<configuration>
					<executable>java</executable>
					<includeProjectDependencies>true</includeProjectDependencies>
					<includePluginDependencies>false</includePluginDependencies>
					<classpathScope>compile</classpathScope>
				</configuration>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-shade-plugin</artifactId>
				<version>1.3.3</version>
				<executions>
					<execution>
						<phase>package</phase>
						<goals>
							<goal>shade</goal>
						</goals>
						<configuration>
							<createDependencyReducedPom>false</createDependencyReducedPom>
							<transformers>
								<transformer
									implementation=""org.apache.maven.plugins.shade.resource.ServicesResourceTransformer"" />
								<transformer
									implementation=""org.apache.maven.plugins.shade.resource.ManifestResourceTransformer"">
									<mainClass>org.apache.storm.flux.Flux</mainClass>
									<manifestEntries>
										<Change></Change>
										<Build-Date></Build-Date>
									</manifestEntries>
								</transformer>
							</transformers>
							<!-- The filters below are necessary if you want to include the Tika
								module -->
							<filters>
								<filter>
									<artifact>*:*</artifact>
									<excludes>
										<exclude>META-INF/*.SF</exclude>
										<exclude>META-INF/*.DSA</exclude>
										<exclude>META-INF/*.RSA</exclude>
									</excludes>
								</filter>
								<filter>
									<!-- https://issues.apache.org/jira/browse/STORM-2428 -->
									<artifact>org.apache.storm:flux-core</artifact>
									<excludes>
										<exclude>org/apache/commons/**</exclude>
										<exclude>org/apache/http/**</exclude>
										<exclude>org/yaml/**</exclude>
									</excludes>
								</filter>
							</filters>
						</configuration>
					</execution>
				</executions>
			</plugin>
		</plugins>
	</build>

	<dependencies>
		<dependency>
			<groupId>com.digitalpebble.stormcrawler</groupId>
			<artifactId>storm-crawler-core</artifactId>
			<version>${stormcrawler.version}</version>
		</dependency>
		<dependency>
			<groupId>com.digitalpebble.stormcrawler</groupId>
			<artifactId>storm-crawler-elasticsearch</artifactId>
			<version>${stormcrawler.version}</version>
		</dependency>
		<dependency>
			<groupId>org.apache.storm</groupId>
			<artifactId>storm-core</artifactId>
			<version>1.2.3</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.storm</groupId>
			<artifactId>flux-core</artifactId>
			<version>1.2.3</version>
		</dependency>
	</dependencies>
</project>
~~~

### Steps to reproduce:
1. Rebuild maven package using above configurations: `mvn clean install; mvn clean package`
2. Start chromedriver in background: `chromedriver --headless`
3. Start topology in local mode: `storm jar target/stormcrawler-1.0-SNAPSHOT.jar  org.apache.storm.flux.Flux --local es-crawler.flux --sleep 60000`

**Traceback error:**
~~~
14829 [Thread-44-fetcher-executor[5 5]] ERROR o.a.s.util - Async loop died!
java.lang.RuntimeException: org.openqa.selenium.InvalidArgumentException: invalid argument: value must be a non-negative integer
  (Session info: headless chrome=90.0.4430.93)
Build info: version: '4.0.0-alpha-6', revision: '5f43a29cfc'
System info: host: 'stormcrawler-dev', ip: '127.0.0.1', os.name: 'Linux', os.arch: 'amd64', os.version: '4.15.0-142-generic', java.version: '1.8.0_282'
Driver info: org.openqa.selenium.remote.RemoteWebDriver
Capabilities {acceptInsecureCerts: false, browserName: chrome, browserVersion: 90.0.4430.93, chrome: {chromedriverVersion: 90.0.4430.24 (4c6d850f087da..., userDataDir: /tmp/.com.google.Chrome.Auy1IS}, goog:chromeOptions: {debuggerAddress: localhost:39999}, javascriptEnabled: true, networkConnectionEnabled: false, pageLoadStrategy: normal, platform: LINUX, platformName: LINUX, proxy: Proxy(), setWindowRect: true, strictFileInteractability: false, timeouts: {implicit: 0, pageLoad: 300000, script: 30000}, unhandledPromptBehavior: dismiss and notify, webauthn:extension:largeBlob: true, webauthn:virtualAuthenticators: true}
Session ID: c6d92cca0f0be276c0f0c477d41e9945
	at com.digitalpebble.stormcrawler.protocol.selenium.RemoteDriverProtocol.configure(RemoteDriverProtocol.java:101) ~[stormcrawler-1.0-SNAPSHOT.jar:?]
	at com.digitalpebble.stormcrawler.protocol.ProtocolFactory.<init>(ProtocolFactory.java:69) ~[stormcrawler-1.0-SNAPSHOT.jar:?]
	at com.digitalpebble.stormcrawler.bolt.FetcherBolt.prepare(FetcherBolt.java:818) ~[stormcrawler-1.0-SNAPSHOT.jar:?]
	at org.apache.storm.daemon.executor$fn__10180$fn__10193.invoke(executor.clj:803) ~[storm-core-1.2.3.jar:1.2.3]
	at org.apache.storm.util$async_loop$fn__624.invoke(util.clj:482) [storm-core-1.2.3.jar:1.2.3]
	at clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_282]
Caused by: org.openqa.selenium.InvalidArgumentException: invalid argument: value must be a non-negative integer
  (Session info: headless chrome=90.0.4430.93)
Build info: version: '4.0.0-alpha-6', revision: '5f43a29cfc'
System info: host: 'stormcrawler-dev', ip: '127.0.0.1', os.name: 'Linux', os.arch: 'amd64', os.version: '4.15.0-142-generic', java.version: '1.8.0_282'
Driver info: org.openqa.selenium.remote.RemoteWebDriver
Capabilities {acceptInsecureCerts: false, browserName: chrome, browserVersion: 90.0.4430.93, chrome: {chromedriverVersion: 90.0.4430.24 (4c6d850f087da..., userDataDir: /tmp/.com.google.Chrome.Auy1IS}, goog:chromeOptions: {debuggerAddress: localhost:39999}, javascriptEnabled: true, networkConnectionEnabled: false, pageLoadStrategy: normal, platform: LINUX, platformName: LINUX, proxy: Proxy(), setWindowRect: true, strictFileInteractability: false, timeouts: {implicit: 0, pageLoad: 300000, script: 30000}, unhandledPromptBehavior: dismiss and notify, webauthn:extension:largeBlob: true, webauthn:virtualAuthenticators: true}
Session ID: c6d92cca0f0be276c0f0c477d41e9945
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_282]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_282]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_282]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_282]
	at org.openqa.selenium.remote.codec.w3c.W3CHttpResponseCodec.createException(W3CHttpResponseCodec.java:196) ~[stormcrawler-1.0-SNAPSHOT.jar:?]
	at org.openqa.selenium.remote.codec.w3c.W3CHttpResponseCodec.decode(W3CHttpResponseCodec.java:129) ~[stormcrawler-1.0-SNAPSHOT.jar:?]
	at org.openqa.selenium.remote.codec.w3c.W3CHttpResponseCodec.decode(W3CHttpResponseCodec.java:53) ~[stormcrawler-1.0-SNAPSHOT.jar:?]
	at org.openqa.selenium.remote.HttpCommandExecutor.execute(HttpCommandExecutor.java:160) ~[stormcrawler-1.0-SNAPSHOT.jar:?]
	at org.openqa.selenium.remote.RemoteWebDriver.execute(RemoteWebDriver.java:582) ~[stormcrawler-1.0-SNAPSHOT.jar:?]
	at org.openqa.selenium.remote.RemoteWebDriver$RemoteWebDriverOptions$RemoteTimeouts.pageLoadTimeout(RemoteWebDriver.java:860) ~[stormcrawler-1.0-SNAPSHOT.jar:?]
	at com.digitalpebble.stormcrawler.protocol.selenium.RemoteDriverProtocol.configure(RemoteDriverProtocol.java:93) ~[stormcrawler-1.0-SNAPSHOT.jar:?]
	... 6 more
14829 [Thread-84-fetcher-executor[6 6]] ERROR o.a.s.util - Async loop died!
java.lang.RuntimeException: org.openqa.selenium.InvalidArgumentException: invalid argument: value must be a non-negative integer
  (Session info: headless chrome=90.0.4430.93)
Build info: version: '4.0.0-alpha-6', revision: '5f43a29cfc'
System info: host: 'stormcrawler-dev', ip: '127.0.0.1', os.name: 'Linux', os.arch: 'amd64', os.version: '4.15.0-142-generic', java.version: '1.8.0_282'
Driver info: org.openqa.selenium.remote.RemoteWebDriver
Capabilities {acceptInsecureCerts: false, browserName: chrome, browserVersion: 90.0.4430.93, chrome: {chromedriverVersion: 90.0.4430.24 (4c6d850f087da..., userDataDir: /tmp/.com.google.Chrome.1ItD3n}, goog:chromeOptions: {debuggerAddress: localhost:36933}, javascriptEnabled: true, networkConnectionEnabled: false, pageLoadStrategy: normal, platform: LINUX, platformName: LINUX, proxy: Proxy(), setWindowRect: true, strictFileInteractability: false, timeouts: {implicit: 0, pageLoad: 300000, script: 30000}, unhandledPromptBehavior: dismiss and notify, webauthn:extension:largeBlob: true, webauthn:virtualAuthenticators: true}
Session ID: 1a58286d80d1f25b4f12993ad7fd0f07
	at com.digitalpebble.stormcrawler.protocol.selenium.RemoteDriverProtocol.configure(RemoteDriverProtocol.java:101) ~[stormcrawler-1.0-SNAPSHOT.jar:?]
	at com.digitalpebble.stormcrawler.protocol.ProtocolFactory.<init>(ProtocolFactory.java:69) ~[stormcrawler-1.0-SNAPSHOT.jar:?]
	at com.digitalpebble.stormcrawler.bolt.FetcherBolt.prepare(FetcherBolt.java:818) ~[stormcrawler-1.0-SNAPSHOT.jar:?]
	at org.apache.storm.daemon.executor$fn__10180$fn__10193.invoke(executor.clj:803) ~[storm-core-1.2.3.jar:1.2.3]
	at org.apache.storm.util$async_loop$fn__624.invoke(util.clj:482) [storm-core-1.2.3.jar:1.2.3]
	at clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_282]
Caused by: org.openqa.selenium.InvalidArgumentException: invalid argument: value must be a non-negative integer
  (Session info: headless chrome=90.0.4430.93)
~~~

### Temporary solution:
Explicitly set the `selenium.pageLoadTimeout` setting to > 0 in crawler-conf.yaml.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/882/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/882,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgzMTEwMDA1MQ==,incubator-stormcrawler,831100051,882,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-05-03T08:11:42Z,2021-05-03T08:11:42Z,"The other timeouts have a default value of 0. According to https://www.oreilly.com/library/view/mastering-selenium-webdriver/9781788299671/b2019b48-d321-41bd-b72b-a32d6cf187ab.xhtml, the default value for pageLoadTimeout is 0 and means infinite.
@piehld what do you think about setting the default value to 0 for it?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgzMTEwMDA1MQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/882,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgzMTM0NTYzMA==,incubator-stormcrawler,831345630,882,NA,piehld,19936765,Dennis Piehl,dennis.piehl@rcsb.org,NA,2021-05-03T15:36:38Z,2021-05-03T15:36:38Z,"@jnioche, Yes I just confirmed that setting it to 0 worked, so perhaps that's a better default than -1 (which is also specified here: https://github.com/DigitalPebble/storm-crawler/wiki/Configuration#protocol). 

One strange observation I'll add though is that this does NOT appear to be an issue when using PhantomJS--it only becomes a problem when I use Chromedriver. I'm not exactly sure why this is the case though, but from the source you link you it sounds like such differences may occur between drivers:

> The exact mechanisms used can differ from driver to driver, and it is constantly under review to try to make it as accurate and as stable as possible. However, modern websites are a moving target, so the current revision of code in Selenium may not work for the site you are testing.
> 
> Patrick, Leigh Collin, Mark. Mastering Selenium WebDriver 3. 0 : Boost the Performance and Reliability of Your Automated Checks by Mastering Selenium WebDriver, 2nd Edition, Packt Publishing, Limited, 2018. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/rutgers-ebooks/detail.action?docID=5446029.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgzMTM0NTYzMA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/882,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgzMTM4NDY2Ng==,incubator-stormcrawler,831384666,882,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-05-03T16:41:15Z,2021-05-03T16:41:15Z,Fixed thanks @piehld ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDgzMTM4NDY2Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/883,https://api.github.com/repos/apache/incubator-stormcrawler/issues/883,incubator-stormcrawler,877306905,883,Add contributions policy,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2021-05-06T09:42:16Z,2021-05-06T09:49:12Z,"Would be good to have that. A Developer Certificate of Origin (DCO) is probably the best way to go, given the size of the project.
See https://download.fsfe.org/NGI0/V2/FSFE%20-%204%20-%20Free%20Software%20Contribution%20Policy.pdf

Could also install https://probot.github.io/apps/dco/ so that any PR checks for signed-off commits
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/883/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/884,https://api.github.com/repos/apache/incubator-stormcrawler/issues/884,incubator-stormcrawler,877420384,884,Check if synchronization in StatusEmitterbolt is still needed,rzo1,13417392,Richard Zowalla,,CLOSED,2021-05-06T11:58:56Z,2021-08-11T16:28:25Z,"As discussed in https://github.com/DigitalPebble/storm-crawler/commit/21206129bc49df5763411ab44aeed144aa8485eb#commitcomment-50463375 , the `StatusEmitterBolt` contains a workaround for https://issues.apache.org/jira/projects/STORM/issues/STORM-3582

It seems, that the underlying issue in STORM was fixed with https://issues.apache.org/jira/browse/STORM-3620 and was included in Storm 2.2.0.

We should therefore check / investigate, if the workaround in Stormcrawler can be removed.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/884/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/885,https://api.github.com/repos/apache/incubator-stormcrawler/issues/885,incubator-stormcrawler,917306432,885,HybridSpout cannot use arbitrary metadata field as PartitionField,GerbenKD,1324876,Gerben de Vries,,CLOSED,2021-06-10T12:47:43Z,2021-06-22T12:09:55Z,"When using the HybridSpout I get cannot cast ArrayList to String exceptions when using a field from metadata as the key.

The error is in the following line:

https://github.com/DigitalPebble/storm-crawler/blob/eb735b4f704e86ccdf004ca4dee107f331fad2a4/external/elasticsearch/src/main/java/com/digitalpebble/stormcrawler/elasticsearch/persistence/HybridSpout.java#L178

Since metadata field values are always lists, this error seems to make sense.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/885/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/885,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg1OTM4OTM3OA==,incubator-stormcrawler,859389378,885,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-06-11T08:35:10Z,2021-06-11T08:35:10Z,"Fields can be multivalued but unless I am mistaken, if a single value is present then a String is returned. Any reason why you'd have more than one value for that field? ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg1OTM4OTM3OA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/885,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2MDU0ODMyNg==,incubator-stormcrawler,860548326,885,NA,GerbenKD,1324876,Gerben de Vries,,NA,2021-06-14T09:41:39Z,2021-06-14T09:41:39Z,"Hi Julien. I posted an issue too soon, likely this is because of how we serialize the Metadata to elasticsearch. I see this is different in your implementation of the StatusUpdaterBolt. My apologies.

cheers,

Gerben","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2MDU0ODMyNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/885,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2MDU1NzYxNg==,incubator-stormcrawler,860557616,885,NA,GerbenKD,1324876,Gerben de Vries,,NA,2021-06-14T09:56:14Z,2021-06-14T09:56:14Z,"Hmm actually, also when using the SDK StatusUpdaterBolt I see single values as arrays in ES.

cheers,

Gerben","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2MDU1NzYxNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/885,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2MDU3MDIxNQ==,incubator-stormcrawler,860570215,885,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-06-14T10:15:56Z,2021-06-14T10:15:56Z,"ok thanks, will have a look","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2MDU3MDIxNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/885,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTExNTk1Ng==,incubator-stormcrawler,865115956,885,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-06-21T15:14:17Z,2021-06-21T15:14:17Z,"I've just added a test to try to reproduce the problem and it's not happening. I really don't think single values are returned by ES as lists.
@GerbenKD could you please double check and try to reproduce the problem? Thanks","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTExNTk1Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/885,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTYzNDA0Mg==,incubator-stormcrawler,865634042,885,NA,GerbenKD,1324876,Gerben de Vries,,NA,2021-06-22T06:25:28Z,2021-06-22T06:25:28Z,"Hi Julien,

Attached a screenshot of the debugger for the HybridSpout. You see that the hostname field is an ArrayList of size 1. In ES this is also stored as a List with a single element. Could this be an ES difference? We are using 7.5.2.

![hybridspout](https://user-images.githubusercontent.com/1324876/122874154-f2302880-d332-11eb-91ed-986863f6ed61.png)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTYzNDA0Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/885,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTc2OTI4MA==,incubator-stormcrawler,865769280,885,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-06-22T08:58:43Z,2021-06-22T08:58:43Z,"Tested with 7.5.2, no difference. It would have been too big a change for a minor release. 
What's your mapping for the status index? How did you create it?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTc2OTI4MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/885,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTgwNTMyOA==,incubator-stormcrawler,865805328,885,NA,GerbenKD,1324876,Gerben de Vries,,NA,2021-06-22T09:22:13Z,2021-06-22T09:22:13Z,"Status index is created by the SDK. I wonder whether the issue is this line though:

https://github.com/DigitalPebble/storm-crawler/blob/0f327d347514ae7fe1fb0ce16693d90765d4dea6/external/elasticsearch/src/main/java/com/digitalpebble/stormcrawler/elasticsearch/persistence/StatusUpdaterBolt.java#L218

Only for `metadata.key` a non-array value is added to the metadata builder object. All other metadata values are `String[]`. I tried to use another metadata value in `HybridSpout` (as in the other issue I created). Hence I get the exception.

Gerben","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTgwNTMyOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/885,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTg0MDMzOA==,incubator-stormcrawler,865840338,885,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-06-22T09:53:32Z,2021-06-22T09:53:32Z,"Managed to reproduce it in the test, thanks. Can you please try the fix in ea6d3fb?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTg0MDMzOA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/885,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTkwMjIzMw==,incubator-stormcrawler,865902233,885,NA,GerbenKD,1324876,Gerben de Vries,,NA,2021-06-22T11:27:07Z,2021-06-22T11:27:07Z,"Works! Thanks!

Gerben","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTkwMjIzMw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/885,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTkyODgwNQ==,incubator-stormcrawler,865928805,885,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-06-22T12:09:55Z,2021-06-22T12:09:55Z,great. thanks for reporting it @GerbenKD ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTkyODgwNQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/886,https://api.github.com/repos/apache/incubator-stormcrawler/issues/886,incubator-stormcrawler,920347617,886,URLFilters show logging as if ParseFilters,GerbenKD,1324876,Gerben de Vries,,CLOSED,2021-06-14T12:08:57Z,2021-06-15T08:31:05Z,"I'm not sure whether the following line is intentional. 

https://github.com/DigitalPebble/storm-crawler/blob/eb735b4f704e86ccdf004ca4dee107f331fad2a4/core/src/main/java/com/digitalpebble/stormcrawler/util/Configurable.java#L33

When debugging my URLFilters it was confusing that they were logging as ParseFilters because of the line above.

cheers,

Gerben","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/886/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/886,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2MDY0Nzc2Ng==,incubator-stormcrawler,860647766,886,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-06-14T12:33:26Z,2021-06-14T12:33:26Z,"Good catch. Overlooked that when I refactored the code. Not sure if there is a way of getting the actual class implementing the interface. Alternatively could rewrite into 
_LoggerFactory.getLogger(Configurable.class);_","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2MDY0Nzc2Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/886,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2MDY0OTM2Ng==,incubator-stormcrawler,860649366,886,NA,GerbenKD,1324876,Gerben de Vries,,NA,2021-06-14T12:36:01Z,2021-06-14T12:36:01Z,"I've never seen that with the actual implementing class. For me it would make most sense to log from Configurable.class. 

Gerben","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2MDY0OTM2Ng==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/887,https://api.github.com/repos/apache/incubator-stormcrawler/issues/887,incubator-stormcrawler,926096620,887,HybridSpout PartitionField can only be field used in URLPartitioner,GerbenKD,1324876,Gerben de Vries,,CLOSED,2021-06-21T11:02:09Z,2021-06-21T15:07:04Z,"The parameter `partitionField` in the `HybridSpout` can only be the same field as the one used in the `URLPartitioner`.

The `emptyQueue()` method in the `HybridSpout` filters on the `queueName` machting the `partitionField`:
https://github.com/DigitalPebble/storm-crawler/blob/3af65c5950fbfcb46aff05e57d56e29e38e00299/external/elasticsearch/src/main/java/com/digitalpebble/stormcrawler/elasticsearch/persistence/HybridSpout.java#L107

However, the `queuename` is created in `AbstractURLBuffer` with the key from the `URLPartitioner`. So, the `partitionField` cannot be anything else than the `URLPartitioner` allows. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/887/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/887,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTAzMTU2MA==,incubator-stormcrawler,865031560,887,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-06-21T13:25:26Z,2021-06-21T13:25:26Z,"We could modify AggregationSpout so that it uses the value found in the field corresponding to _partitionField_  and use that to send to the URLBuffer; so that would be a guarantee that the value are definitely the same.

However in practice, URLPartitioner should be configured in the same way for the StatusUpdaterBolt and the spouts, so the values within_partitionField_ should be the same, shouldn't they?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTAzMTU2MA==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/887,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTEwMDEwMg==,incubator-stormcrawler,865100102,887,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-06-21T14:56:17Z,2021-06-21T14:56:17Z,@GerbenKD could it be an issue due to the fact that you are not using the standard StatusUpdaterBolt and hence don't use URLPartitioner to generate the values that are used for partitioning?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTEwMDEwMg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/887,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTExMDMxNg==,incubator-stormcrawler,865110316,887,NA,GerbenKD,1324876,Gerben de Vries,,NA,2021-06-21T15:07:04Z,2021-06-21T15:07:04Z,"Hi Julien. Yes, you are right, that is exactly the issue. Sorry for the confusion.
It seems that I was confused as to what the setting `es.status.bucket.field` does. It tells where to store the key, not which field to use as a key. And this fieldname can be anything that isn't used. Closing the issue. 

Thanks,

Gerben","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTExMDMxNg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/888,https://api.github.com/repos/apache/incubator-stormcrawler/issues/888,incubator-stormcrawler,926123402,888,Fields in URLMetadata inner class not accessible outside package,GerbenKD,1324876,Gerben de Vries,,CLOSED,2021-06-21T11:33:29Z,2023-12-05T16:24:18Z,"The fields of the `URLMetadata` inner class in `AbstractURLBuffer` are not accesible outside the package, which means no extensions can be made outside the package that want to implement a new `next()` method.

https://github.com/DigitalPebble/storm-crawler/blob/3af65c5950fbfcb46aff05e57d56e29e38e00299/core/src/main/java/com/digitalpebble/stormcrawler/persistence/urlbuffer/AbstractURLBuffer.java#L123","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/888/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/888,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTAzNTAxOQ==,incubator-stormcrawler,865035019,888,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-06-21T13:30:24Z,2021-06-21T13:30:24Z,"I suppose the fields could be _protected_ too. Feel free to open a PR for this, thanks!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg2NTAzNTAxOQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/888,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5tvYw_,incubator-stormcrawler,1841138751,888,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-12-05T16:24:18Z,2023-12-05T16:24:18Z,No activity closing,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5tvYw_/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/892,https://api.github.com/repos/apache/incubator-stormcrawler/issues/892,incubator-stormcrawler,944414505,892,Bug: StackOverFlow issue in CharsetIdentification ,vitos73,31733697,Vitaly Maslyaninov,,CLOSED,2021-07-14T13:11:40Z,2022-01-10T12:21:12Z,"If a website has erroneous content we've got a crash of crawler with a java.lang.StackOverflowError in com.digitalpebble.stormcrawler.util.CharsetIdentification.getCharsetFromMeta(CharsetIdentification.java:192)

Example site: http://gurpreetkaur.co.in/
Example content (exact)
```
<!DOCTYPE html>
--
  | <!--[if IE 7]><html class=""ie ie7 ltie8 ltie9"" lang=""en-US""><![endif]-->
  | <!--[if IE 8]><html class=""ie ie8 ltie9"" lang=""en-US""><![endif]-->
  | <!--[if !(IE 7) \| !(IE 8)  ]><!-->
  | <html lang=""en-US"">
  | <!--<![endif]-->
  |  
  | <head>
  | <meta charset=""UTF-8
```
Problem with comparison in line 191 CharsetIdentification.java:
was: 
```
            if (end == -1) {
                return getCharsetFromMeta(buffer, maxlength + 10);
            }
```
should be:
```
             if (end == -1 && ((maxlength +10) < buffer.length)) {
                return getCharsetFromMeta(buffer, maxlength + 10);
            } 
```
We've to ensure that were chars left before EOF. 








","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/892/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/892,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg3OTkzNDQ3Nw==,incubator-stormcrawler,879934477,892,NA,vitos73,31733697,Vitaly Maslyaninov,,NA,2021-07-14T14:20:05Z,2021-07-14T14:20:05Z,"full solution of fast detection via tag looks like:
 ```
int start = html.indexOf(""<meta charset=\"""");
        if (start != -1) {
            int end = html.indexOf('""', start + 15);
            // https://github.com/DigitalPebble/storm-crawler/issues/870
            // try on a slightly larger section of text if it is trimmed
            if (end == -1 && ((maxlength +10) < buffer.length)) {
                return getCharsetFromMeta(buffer, maxlength + 10);
            }
            if (end == -1) {
                // there is open tag meta but not closed = we have broken content!
                return null;
            }
            return validateCharset(html.substring(start + 15, end));
        }
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg3OTkzNDQ3Nw==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/892,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg4MDUxMTY3Mg==,incubator-stormcrawler,880511672,892,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-07-15T08:40:38Z,2021-07-15T08:40:38Z,thanks @vitos73. Do you want to / can you contribute a PR to fix it?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg4MDUxMTY3Mg==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/892,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg4MDU3NjQzMQ==,incubator-stormcrawler,880576431,892,NA,vitos73,31733697,Vitaly Maslyaninov,,NA,2021-07-15T10:17:30Z,2021-07-15T10:17:30Z,"@jnioche 
Done: #895 
Thank you!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/MDEyOklzc3VlQ29tbWVudDg4MDU3NjQzMQ==/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/903,https://api.github.com/repos/apache/incubator-stormcrawler/issues/903,incubator-stormcrawler,963972202,903,Replace Guava caches with Caffeine ones,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2021-08-09T13:02:20Z,2021-08-12T13:14:17Z,"Caffeine library is a rewrite of Guava’s cache that uses a Guava-inspired API that returns CompletableFutures, allowing asynchronous automatic loading of entries into a cache. The library was written by Ben Manes who is the author of ConcurrentLinkedHashMap on which Guava cache is based.

Caffeine has better performance than Guava but its API is very similar. There are bugs in Guava which have not been fixed.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/903/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/907,https://api.github.com/repos/apache/incubator-stormcrawler/issues/907,incubator-stormcrawler,991924588,907,AggregationSpout does not release IsInQuery boolean sometimes,GerbenKD,1324876,Gerben de Vries,,CLOSED,2021-09-09T08:04:43Z,2022-06-06T10:45:11Z,"First remark: I haven't identified the cause of this issue, but I think it could still be good for others to be aware of it, therefore I'm opening this issue.

Sometimes my `AggregationSpout` gets stuck doing nothing because the `isInQuery` boolean is never reset to `false`. I suppose this can happen when somehow the `onSuccess()` and `onFailure()` methods are not called. Currently I'm considering adding in functionality to reset the `isInQuery` boolean after a certain amount of time.

Maybe others have encountered this issue as well and have a nicer solution, that would be great to know. 
I will update this ticket in case I find out more.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/907/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/907,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc4-j-GB,incubator-stormcrawler,1049616769,907,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-02-24T08:40:30Z,2022-02-24T08:40:30Z,Hi @GerbenKD did you find more on this?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc4-j-GB/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/907,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc4-kgPo,incubator-stormcrawler,1049756648,907,NA,GerbenKD,1324876,Gerben de Vries,,NA,2022-02-24T11:20:18Z,2022-02-24T11:20:18Z,"Hi @jnioche, no I didn't find out anything more, other than that it does indeed happen. I therefore did as I suggested and I reset the `isInQuery` boolean after a certain timeout has passed. That works :) but it would be better of course to get to the root cause.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc4-kgPo/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/907,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc4-khCV,incubator-stormcrawler,1049759893,907,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-02-24T11:23:51Z,2022-02-24T11:23:51Z,Thanks. I have added a bunch of logs to see if I can trace the source of the problem. Am seeing something that looks a bit like it in a customer's crawl.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc4-khCV/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/907,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5D6tV6,incubator-stormcrawler,1139463546,907,NA,thijswesterveld,6349270,,,NA,2022-05-27T09:52:11Z,2022-05-27T09:52:11Z,"Hi @jnioche, 

We may have found the root cause of this. The issue seems to be with the `onFailure()` methods in Hybridspout and AggregationSpout.  The `onFailure()` method in `AggregationSpout` calls `markQueryReceivedNow()`, but the one in `HybridSpout` doesn't . 

We are using a variant of  `Hybridspout`. Failures are always handled by the `onFailure()` method in that child class, even though the query or response that is causing the failure is from the parent `AggregationSpout` class. 

`onResponse()` decides between parent/child handling by [checking the response properties](https://github.com/DigitalPebble/storm-crawler/blob/795b966e91461b0f4546d4634e45e11d71cf2978/external/elasticsearch/src/main/java/com/digitalpebble/stormcrawler/elasticsearch/persistence/HybridSpout.java#L142-L149). Ideally, we'd do something similar in `onFailure()`, but I don't think we have the information there to make that decision. 

In our variants of the Hybridspout we have solved it by removing the `onFailure()` override our variant of  `HybridSpout` to make sure we always release isInQuery. This of course introduces the reverse issue of releasing too quickly if the failure comes from a single queue .
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5D6tV6/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/907,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5D9dRe,incubator-stormcrawler,1140184158,907,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-05-28T06:19:38Z,2022-05-28T06:19:38Z,"thanks @thijswesterveld, I will have a look when I come back from holiday","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5D9dRe/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/907,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5EYpok,incubator-stormcrawler,1147312676,907,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-06-06T10:45:11Z,2022-06-06T10:45:11Z,"hi @thijswesterveld, I have just pushed a commit which should solve the problem. We will now use a separate listener to handle the results for specific queues and will let the super class deal with _onFailure_(), which I think is a lot cleaner. 
Would be great if you could give it a try. Feel free to reopen this issue if necessary.
Thanks again for your reporting it in the first place and the detective work to get to the bottom of the problem. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5EYpok/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/909,https://api.github.com/repos/apache/incubator-stormcrawler/issues/909,incubator-stormcrawler,998613180,909,Issue with ConcurrentModificationException for Metadata in StatusMetricsBolt,juli-alvarez,11411638,Julian Alvarez,,CLOSED,2021-09-16T20:30:13Z,2021-09-17T20:25:16Z,"We have been using stormcrawler with elasticsearch under huge load using parallelism across multiple workers for some time without any issues. After we upgraded the version from 1.18 to 2.1 (storm 1.2.3 to 2.2.0 as well) we started getting ConcurrentModificationException from kryo for Metadata class.

```
2021-09-14 17:13:48.797 o.a.s.e.e.ReportError Thread-20-spout-executor[59, 59] [ERROR] Error
java.lang.RuntimeException: com.esotericsoftware.kryo.KryoException: java.util.ConcurrentModificationException
Serialization trace:
md (com.digitalpebble.stormcrawler.Metadata)
	at org.apache.storm.utils.Utils$1.run(Utils.java:409) ~[storm-client-2.2.0.jar:2.2.0]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_292]
Caused by: com.esotericsoftware.kryo.KryoException: java.util.ConcurrentModificationException
Serialization trace:
md (com.digitalpebble.stormcrawler.Metadata)
	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:101) ~[kryo-3.0.3.jar:?]
	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:518) ~[kryo-3.0.3.jar:?]
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628) ~[kryo-3.0.3.jar:?]
	at com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:100) ~[kryo-3.0.3.jar:?]
	at com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:40) ~[kryo-3.0.3.jar:?]
	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:534) ~[kryo-3.0.3.jar:?]
	at org.apache.storm.serialization.KryoValuesSerializer.serializeInto(KryoValuesSerializer.java:38) ~[storm-client-2.2.0.jar:2.2.0]
	at org.apache.storm.serialization.KryoTupleSerializer.serialize(KryoTupleSerializer.java:40) ~[storm-client-2.2.0.jar:2.2.0]
	at org.apache.storm.daemon.worker.WorkerTransfer.tryTransferRemote(WorkerTransfer.java:116) ~[storm-client-2.2.0.jar:2.2.0]
	at org.apache.storm.daemon.worker.WorkerState.tryTransferRemote(WorkerState.java:524) ~[storm-client-2.2.0.jar:2.2.0]
	at org.apache.storm.executor.ExecutorTransfer.tryTransfer(ExecutorTransfer.java:68) ~[storm-client-2.2.0.jar:2.2.0]
	at org.apache.storm.executor.spout.SpoutOutputCollectorImpl.sendSpoutMsg(SpoutOutputCollectorImpl.java:140) ~[storm-client-2.2.0.jar:2.2.0]
	at org.apache.storm.executor.spout.SpoutOutputCollectorImpl.emit(SpoutOutputCollectorImpl.java:70) ~[storm-client-2.2.0.jar:2.2.0]
	at org.apache.storm.spout.SpoutOutputCollector.emit(SpoutOutputCollector.java:56) ~[storm-client-2.2.0.jar:2.2.0]
	at com.digitalpebble.stormcrawler.persistence.AbstractQueryingSpout.nextTuple(AbstractQueryingSpout.java:197) ~[stormjar.jar:?]
	at org.apache.storm.executor.spout.SpoutExecutor$2.call(SpoutExecutor.java:193) ~[storm-client-2.2.0.jar:2.2.0]
	at org.apache.storm.executor.spout.SpoutExecutor$2.call(SpoutExecutor.java:160) ~[storm-client-2.2.0.jar:2.2.0]
	at org.apache.storm.utils.Utils$1.run(Utils.java:394) ~[storm-client-2.2.0.jar:2.2.0]
	... 1 more
```

We did some research and found that the root cause of the issue was that the Metadata object was being mutated after it was emitted. Also we were able to identify that the issue disappeared whenever we removed the status_metrics bolt from the topology. That made sense because the metadata emitted by the spout was modified later in the default stream and was also emitted to the status metrics bolt.

We propose a solution that is connecting the status metrics bolt to the __system using the __tick stream. That's because the mentioned bolt only uses the tick tuple to perform kind of a cron job. This way we avoid passing the real tuple that is not used at all with the metadata that was causing the issue.

es-crawler.flux
```
  - from: ""__system""
    to: ""status_metrics""
    grouping:
      type: SHUFFLE
      streamId: ""__tick""
```

BTW, I'm working with @matiascrespof and @jcruzmartini.

Thanks!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/909/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/909,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc427sHc,incubator-stormcrawler,921616860,909,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-09-17T08:38:59Z,2021-09-17T08:38:59Z,"thanks @juli-alvarez 
This makes a lot of sense and would be a far better way of doing. I assume you tried the solution above and it worked. Would you like to submit a PR to change the *.flux file? 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc427sHc/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/909,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc428ZqT,incubator-stormcrawler,921803411,909,NA,juli-alvarez,11411638,Julian Alvarez,,NA,2021-09-17T13:36:50Z,2021-09-17T13:36:50Z,"Hi @jnioche! Glad you like the approach.
Yes, we have the crawler running for the past 24hs and everything is working as expected, no exception, no workers dying and grafana dashboards looking good as well.
Sure, I will create the PR with the changes in the flux file.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc428ZqT/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/909,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc428Z87,incubator-stormcrawler,921804603,909,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-09-17T13:38:38Z,2021-09-17T13:38:38Z,Not that I don't want to do it myself: I really want you to take full credit for it ;-),"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc428Z87/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/909,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc429KTy,incubator-stormcrawler,922002674,909,NA,juli-alvarez,11411638,Julian Alvarez,,NA,2021-09-17T18:38:01Z,2021-09-17T18:38:01Z,@jnioche Done! Thanks Julien 🥇 ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc429KTy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/909,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc429YiW,incubator-stormcrawler,922060950,909,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-09-17T20:25:09Z,2021-09-17T20:25:09Z,Fixed in #910,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc429YiW/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/911,https://api.github.com/repos/apache/incubator-stormcrawler/issues/911,incubator-stormcrawler,1018037962,911,Update Storm to 2.3.0,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2021-10-06T10:50:43Z,2021-10-06T11:04:06Z,https://storm.apache.org/2021/09/27/storm230-released.html,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/911/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/913,https://api.github.com/repos/apache/incubator-stormcrawler/issues/913,incubator-stormcrawler,1023678985,913,Use GH Actions to set up Maven CI,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2021-10-12T10:58:53Z,2021-10-12T11:16:14Z,"I hadn't noticed but there have been changes to travis-ci and recent changes have not been checked for a while.
Would be nice to use GH Actions instead.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/913/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/914,https://api.github.com/repos/apache/incubator-stormcrawler/issues/914,incubator-stormcrawler,1026806457,914,Dependencies upgrades,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2021-10-14T20:47:00Z,2021-10-15T11:02:16Z,"```
[INFO]   org.seleniumhq.selenium:selenium-remote-driver ...
[INFO]                                                   4.0.0-alpha-7 -> 4.0.0
[INFO]   org.elasticsearch.client:elasticsearch-rest-client-sniffer ...
[INFO]                                                    7.5.0 -> 8.0.0-alpha2
[INFO]   org.elasticsearch.client:elasticsearch-rest-high-level-client ...
[INFO]                                                    7.5.0 -> 8.0.0-alpha2
[INFO]   com.amazonaws:aws-java-sdk-cloudsearch ........... 1.11.948 -> 1.12.88
[INFO]   com.amazonaws:aws-java-sdk-s3 .................... 1.11.948 -> 1.12.88
[INFO]   com.fasterxml.jackson.core:jackson-databind ......... 2.11.1 -> 2.13.0
[INFO]   com.github.ben-manes.caffeine:caffeine ................ 2.9.2 -> 3.0.4
[INFO]   com.github.crawler-commons:crawler-commons ................ 1.1 -> 1.2
[INFO]   com.github.crawler-commons:urlfrontier-API ................ 0.3 -> 0.4
[INFO]   com.ibm.icu:icu4j ....................................... 68.2 -> 69.1
[INFO]   com.rometools:rome .................................. 1.15.0 -> 1.16.0
[INFO]   com.squareup.okhttp3:okhttp ................... 4.9.1 -> 5.0.0-alpha.2
[INFO]   junit:junit ......................................... 4.13.1 -> 4.13.2
[INFO]   org.apache.solr:solr-solrj ........................... 8.8.0 -> 8.10.0
[INFO]   org.apache.tika:tika-core .............................. 1.26 -> 2.1.0
[INFO]   org.apache.tika:tika-parsers ........................... 1.26 -> 2.1.0
[INFO]   org.jsoup:jsoup ..................................... 1.14.2 -> 1.14.3
[INFO]   org.mockito:mockito-core .............................. 3.6.0 -> 4.0.0
[INFO]   org.mockito:mockito-core .............................. 3.7.7 -> 4.0.0
[INFO]   org.netpreserve:jwarc ............................... 0.13.1 -> 0.16.5
[INFO]   org.seleniumhq.selenium:selenium-support ...... 4.0.0-alpha-7 -> 4.0.0
[INFO]   org.testcontainers:elasticsearch .................... 1.15.1 -> 1.16.0
[INFO]   org.yaml:snakeyaml ...................................... 1.27 -> 1.29
```

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/914/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/914,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc44R3EU,incubator-stormcrawler,944206100,914,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-10-15T10:57:09Z,2021-10-15T10:57:09Z,"Caffeine 3.x requires Java 11 - we're not quite there yet
Mockito 4 + Jackson not compatible as is
OKHttp + ES are alpha

Everything else compiles and passes the tests","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc44R3EU/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/915,https://api.github.com/repos/apache/incubator-stormcrawler/issues/915,incubator-stormcrawler,1027536145,915,Performance degradation using version 2.1.0,jcruzmartini,6817516,Juan Cruz Martini,,CLOSED,2021-10-15T15:05:48Z,2021-10-22T13:19:25Z,"### Performance degradation using version 2.1.0
We have been experiencing performance degradation when using the new version of stormcrawler.
We are pretty sure that the issue is being caused by this workaround

```
    /** Workaround for https://issues.apache.org/jira/projects/STORM/issues/STORM-3582?filter=allopenissues **/
    protected synchronized void emit(String streamId, Tuple anchor, List<Object> tuple) {
        collector.emit(streamId, anchor, tuple);
    }
```
it's worth mentioning that we are using stormcrawler intensively with a high number of threads (300) so having now this method synchronized is adding extra delays and affecting the performance.
Here you can see an example of how it is performing SC 2.1 vs 1.18...

![image](https://user-images.githubusercontent.com/6817516/137509179-6c71c093-a841-4b20-9c1c-21ebb4ea3670.png)

left side SC 2.1, then we stopped the crawler and we re-started using SC 1.18.
We tried removing the `synchronized` in the emit method, metrics started to look better but we got this kind of issue, related to this apache storm issue : https://issues.apache.org/jira/browse/STORM-3620

```
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] 2021-10-15 13:51:32.752 o.a.s.u.Utils Thread-16-fetcher-executor[10, 10] [ERROR] Async loop died!
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] com.esotericsoftware.kryo.KryoException: java.util.ConcurrentModificationException
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] Serialization trace:
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] md (com.digitalpebble.stormcrawler.Metadata)
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] 	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:101) ~[kryo-3.0.3.jar:?]
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] 	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:518) ~[kryo-3.0.3.jar:?]
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] 	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628) ~[kryo-3.0.3.jar:?]
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] 	at com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:100) ~[kryo-3.0.3.jar:?]
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] 	at com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:40) ~[kryo-3.0.3.jar:?]
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] 	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:534) ~[kryo-3.0.3.jar:?]
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] 	at org.apache.storm.serialization.KryoValuesSerializer.serializeInto(KryoValuesSerializer.java:38) ~[storm-client-2.2.0.jar:2.2.0]
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] 	at org.apache.storm.serialization.KryoTupleSerializer.serialize(KryoTupleSerializer.java:40) ~[storm-client-2.2.0.jar:2.2.0]
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] 	at org.apache.storm.daemon.worker.WorkerTransfer.tryTransferRemote(WorkerTransfer.java:116) ~[storm-client-2.2.0.jar:2.2.0]
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] 	at org.apache.storm.daemon.worker.WorkerState.tryTransferRemote(WorkerState.java:524) ~[storm-client-2.2.0.jar:2.2.0]
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] 	at org.apache.storm.executor.ExecutorTransfer.tryTransfer(ExecutorTransfer.java:68) ~[storm-client-2.2.0.jar:2.2.0]
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] 	at org.apache.storm.executor.bolt.BoltExecutor$1.tryFlushPendingEmits(BoltExecutor.java:200) ~[storm-client-2.2.0.jar:2.2.0]
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] 	at org.apache.storm.executor.bolt.BoltExecutor$1.call(BoltExecutor.java:166) ~[storm-client-2.2.0.jar:2.2.0]
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] 	at org.apache.storm.executor.bolt.BoltExecutor$1.call(BoltExecutor.java:159) ~[storm-client-2.2.0.jar:2.2.0]
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] 	at org.apache.storm.utils.Utils$1.run(Utils.java:394) [storm-client-2.2.0.jar:2.2.0]
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] 	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_292]
./worker.log:2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] Caused by: java.util.ConcurrentModificationException
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] 	at java.util.HashMap$HashIterator.nextNode(HashMap.java:1445) ~[?:1.8.0_292]
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] 	at java.util.HashMap$EntryIterator.next(HashMap.java:1479) ~[?:1.8.0_292]
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] 	at java.util.HashMap$EntryIterator.next(HashMap.java:1477) ~[?:1.8.0_292]
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] 	at com.esotericsoftware.kryo.serializers.MapSerializer.write(MapSerializer.java:99) ~[kryo-3.0.3.jar:?]
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] 	at com.esotericsoftware.kryo.serializers.MapSerializer.write(MapSerializer.java:39) ~[kryo-3.0.3.jar:?]
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] 	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:552) ~[kryo-3.0.3.jar:?]
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] 	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80) ~[kryo-3.0.3.jar:?]
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] 	... 15 more
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] 2021-10-15 13:51:32.756 o.a.s.e.e.ReportError Thread-16-fetcher-executor[10, 10] [ERROR] Error
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] java.lang.RuntimeException: com.esotericsoftware.kryo.KryoException: java.util.ConcurrentModificationException
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] Serialization trace:
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] md (com.digitalpebble.stormcrawler.Metadata)
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] 	at org.apache.storm.utils.Utils$1.run(Utils.java:409) ~[storm-client-2.2.0.jar:2.2.0]
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] 	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_292]
./worker.log:2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] Caused by: com.esotericsoftware.kryo.KryoException: java.util.ConcurrentModificationException
./worker.log-2021-10-15 13:51:32.756 STDERR Thread-2 [INFO] Serialization trace:
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] md (com.digitalpebble.stormcrawler.Metadata)
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:101) ~[kryo-3.0.3.jar:?]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:518) ~[kryo-3.0.3.jar:?]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628) ~[kryo-3.0.3.jar:?]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:100) ~[kryo-3.0.3.jar:?]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:40) ~[kryo-3.0.3.jar:?]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:534) ~[kryo-3.0.3.jar:?]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at org.apache.storm.serialization.KryoValuesSerializer.serializeInto(KryoValuesSerializer.java:38) ~[storm-client-2.2.0.jar:2.2.0]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at org.apache.storm.serialization.KryoTupleSerializer.serialize(KryoTupleSerializer.java:40) ~[storm-client-2.2.0.jar:2.2.0]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at org.apache.storm.daemon.worker.WorkerTransfer.tryTransferRemote(WorkerTransfer.java:116) ~[storm-client-2.2.0.jar:2.2.0]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at org.apache.storm.daemon.worker.WorkerState.tryTransferRemote(WorkerState.java:524) ~[storm-client-2.2.0.jar:2.2.0]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at org.apache.storm.executor.ExecutorTransfer.tryTransfer(ExecutorTransfer.java:68) ~[storm-client-2.2.0.jar:2.2.0]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at org.apache.storm.executor.bolt.BoltExecutor$1.tryFlushPendingEmits(BoltExecutor.java:200) ~[storm-client-2.2.0.jar:2.2.0]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at org.apache.storm.executor.bolt.BoltExecutor$1.call(BoltExecutor.java:166) ~[storm-client-2.2.0.jar:2.2.0]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at org.apache.storm.executor.bolt.BoltExecutor$1.call(BoltExecutor.java:159) ~[storm-client-2.2.0.jar:2.2.0]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at org.apache.storm.utils.Utils$1.run(Utils.java:394) ~[storm-client-2.2.0.jar:2.2.0]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	... 1 more
./worker.log:2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] Caused by: java.util.ConcurrentModificationException
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at java.util.HashMap$HashIterator.nextNode(HashMap.java:1445) ~[?:1.8.0_292]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at java.util.HashMap$EntryIterator.next(HashMap.java:1479) ~[?:1.8.0_292]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at java.util.HashMap$EntryIterator.next(HashMap.java:1477) ~[?:1.8.0_292]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at com.esotericsoftware.kryo.serializers.MapSerializer.write(MapSerializer.java:99) ~[kryo-3.0.3.jar:?]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at com.esotericsoftware.kryo.serializers.MapSerializer.write(MapSerializer.java:39) ~[kryo-3.0.3.jar:?]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:552) ~[kryo-3.0.3.jar:?]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80) ~[kryo-3.0.3.jar:?]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:518) ~[kryo-3.0.3.jar:?]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628) ~[kryo-3.0.3.jar:?]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:100) ~[kryo-3.0.3.jar:?]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:40) ~[kryo-3.0.3.jar:?]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:534) ~[kryo-3.0.3.jar:?]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at org.apache.storm.serialization.KryoValuesSerializer.serializeInto(KryoValuesSerializer.java:38) ~[storm-client-2.2.0.jar:2.2.0]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at org.apache.storm.serialization.KryoTupleSerializer.serialize(KryoTupleSerializer.java:40) ~[storm-client-2.2.0.jar:2.2.0]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at org.apache.storm.daemon.worker.WorkerTransfer.tryTransferRemote(WorkerTransfer.java:116) ~[storm-client-2.2.0.jar:2.2.0]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at org.apache.storm.daemon.worker.WorkerState.tryTransferRemote(WorkerState.java:524) ~[storm-client-2.2.0.jar:2.2.0]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at org.apache.storm.executor.ExecutorTransfer.tryTransfer(ExecutorTransfer.java:68) ~[storm-client-2.2.0.jar:2.2.0]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at org.apache.storm.executor.bolt.BoltExecutor$1.tryFlushPendingEmits(BoltExecutor.java:200) ~[storm-client-2.2.0.jar:2.2.0]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at org.apache.storm.executor.bolt.BoltExecutor$1.call(BoltExecutor.java:166) ~[storm-client-2.2.0.jar:2.2.0]
./worker.log-2021-10-15 13:51:32.757 STDERR Thread-2 [INFO] 	at org.apache.storm.executor.bolt.BoltExecutor$1.call(BoltExecutor.java:159) ~[storm-client-2.2.0.jar:2.2.0]
```

@jnioche we are working on a workaround to see if we can resolve this last issue with the serialization, we will keep you posted.


What kind of issue is this?

 - [ ] Question. This issue tracker is not the best place for questions. If you want to ask how to do
       something, or to understand why something isn't working the way you expect it to, use StackOverflow
       instead with the label 'stormcrawler': https://stackoverflow.com/questions/tagged/stormcrawler 

 - [x] Bug report. If you’ve found a bug, please include a test if you can, it makes it a lot easier to fix things. Use the label 'bug' on the issue.
 
 - [ ] Feature request. Please use the label 'wish' on the issue.

Thanks!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/915/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/915,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc44Sgkh,incubator-stormcrawler,944376097,915,NA,jcruzmartini,6817516,Juan Cruz Martini,,NA,2021-10-15T15:06:05Z,2021-10-15T15:06:05Z,cc @juli-alvarez @matiascrespof ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc44Sgkh/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/915,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc44Sh9o,incubator-stormcrawler,944381800,915,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-10-15T15:13:13Z,2021-10-15T15:13:13Z,"The sync has been removed in #904, this will be part of the next release. 
Which version of Storm is your cluster on? This should have been fixed in 2.2.0. I recently upgraded the dependency to 2.3.0","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc44Sh9o/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/915,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc44SnFV,incubator-stormcrawler,944402773,915,NA,jcruzmartini,6817516,Juan Cruz Martini,,NA,2021-10-15T15:41:56Z,2021-10-15T15:41:56Z,"we are using 
```
		<storm.version>2.2.0</storm.version>
		<storm.crawler.version>2.1</storm.crawler.version>
```
so should be fixed, but we will try overriding storm client dependency with  		
<storm-client.version>2.3.0</storm-client.version>

Another important thing to note is that we are using 
`fetcher.threads.per.queue: ` greater than 1, that is the default value.

thanks @jnioche 

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc44SnFV/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/915,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc44S9Pt,incubator-stormcrawler,944493549,915,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-10-15T18:02:14Z,2021-10-15T18:02:14Z,"So your storm cluster is on 2.2.0?

Sent from my mobile,  please excuse any typos

On Fri, 15 Oct 2021, 16:42 Juan Cruz Martini, ***@***.***>
wrote:

> we are using
>
> 		<storm.version>2.2.0</storm.version>
> 		<storm.crawler.version>2.1</storm.crawler.version>
>
> so should be fixed, but we will try overriding storm client dependency with
> <storm-client.version>2.3.0</storm-client.version>
>
> thanks @jnioche <https://github.com/jnioche>
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/DigitalPebble/storm-crawler/issues/915#issuecomment-944402773>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AABVJT6NYILOMD4WL6X7HU3UHBDU5ANCNFSM5GCFQPFA>
> .
> Triage notifications on the go with GitHub Mobile for iOS
> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>
> or Android
> <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.
>
>
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc44S9Pt/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/915,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc44TBTb,incubator-stormcrawler,944510171,915,NA,jcruzmartini,6817516,Juan Cruz Martini,,NA,2021-10-15T18:29:26Z,2021-10-15T18:29:26Z,"@jnioche yes our cluster is in 2.2.0. @juli-alvarez was able to do a workaround when using `fetcher.threads.per.queue: 5`, basically he is doing this.


```
    private class FetcherThread extends Thread {

        @Override
        public void run() {
            while (true) {
             
             //before emitting we are creating a new instance of the metadata
             final Metadata immutableMd = new Metadata();
             immutableMd.putAll(metadata);
              collector.emit(com.digitalpebble.stormcrawler.Constants.StatusStreamName,
                      fit.t,
                      new Values(fit.url, immutableMd, Status.ERROR));
            }
        }

```
we are doing this before every `collector.emit `that appears inside `run()` method. We know is not a nice hotfix, but at least is unblocking us for now.
I think the easiest way to reproduce it is by using high numbers in `fetcher.threads.per.queue:`

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc44TBTb/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/915,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc44eNsN,incubator-stormcrawler,947444493,915,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-10-20T08:29:33Z,2021-10-20T08:29:33Z,Hi @jcruzmartini any updates on this? I tried setting _fetcher.threads.per.queue_ to 5 in one of my crawl but haven't been able  to reproduce the issue.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc44eNsN/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/915,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc44fLaJ,incubator-stormcrawler,947697289,915,NA,jcruzmartini,6817516,Juan Cruz Martini,,NA,2021-10-20T14:01:01Z,2021-10-20T14:01:01Z,"Hi @jnioche we are still getting this exception, let me try to reproduce it using the SC without any custom change in order to guarantee that this is not something in our end","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc44fLaJ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/915,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc44mYLu,incubator-stormcrawler,949584622,915,NA,jcruzmartini,6817516,Juan Cruz Martini,,NA,2021-10-22T12:27:25Z,2021-10-22T12:27:25Z,"@jnioche closing this issue we were not able to reproduce the issue using the master branch with apache storm 2.3.0.
thanks for your help","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc44mYLu/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/915,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc44miGe,incubator-stormcrawler,949625246,915,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-10-22T13:19:16Z,2021-10-22T13:19:16Z,@jcruzmartini glad it's fixed. Thanks for checking,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc44miGe/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/921,https://api.github.com/repos/apache/incubator-stormcrawler/issues/921,incubator-stormcrawler,1044488078,921,http.content.limit has effect on robots.txt,wowasa,28445631,Wolfgang Walter SAUER,info@wowasa.com,CLOSED,2021-11-04T08:53:09Z,2021-11-09T09:06:00Z,"Since we need only some header information in our project we set »http.content.limit: 0« and we just realized that this setting concerns also the robots.txt, so that f.e. a crawl-delay set there isn't respected anymore. 

If it's not a bug, it might be reasonable to point out the effect of the setting on the processing of robots.txt
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/921/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/921,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc45QWVg,incubator-stormcrawler,960587104,921,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2021-11-04T09:28:06Z,2021-11-04T09:28:06Z,"Thanks, good point. It'd consider it as a bug because the [robots.txt RFC draft](https://datatracker.ietf.org/doc/html/draft-rep-wg-topic-00#section-2.5) specifies that at least 500 kiB are fetched.

Sending a HEAD request (#485) might work around the problem ([only implemented in httpclient](https://github.com/DigitalPebble/storm-crawler/wiki/Protocols#feature-grid)).","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc45QWVg/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/921,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc45YAxP,incubator-stormcrawler,962595919,921,NA,wowasa,28445631,Wolfgang Walter SAUER,info@wowasa.com,NA,2021-11-07T11:47:09Z,2021-11-07T11:47:09Z,"thank you, Sebastian: our link checking application is sending a head request anyway in the first attempt, since we just need some header info. Only in case of non-ok status response it's sending a get request in a second attempt. But since we're checking millions of links without any need for content I would prefer »http.content.limit: 0«. 
Hence I would fix the issue with an own instance of CloseableHttpClient with default settings to read the robots.txt. Or do you have a different approach?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc45YAxP/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/921,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc45ZtxU,incubator-stormcrawler,963042388,921,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2021-11-08T11:07:23Z,2021-11-08T11:07:23Z,"I'd suggest to pass a page-specific ""http.content.limit"" from HttpRobotRulesParser to the protocol via metadata. I'll open a PR. The fix should be independent of the used protocol implementation (okhttp, httpclient) and it should still use all other protocol features (proxy, connection pool, etc.)","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc45ZtxU/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/924,https://api.github.com/repos/apache/incubator-stormcrawler/issues/924,incubator-stormcrawler,1048443187,924,Need to register Status class with Kryo,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2021-11-09T10:34:19Z,2021-11-18T12:23:58Z,"Wasn't necessary until now but maybe due to a change of version since switching to Storm 2.3.0. In deployed mode at least, we need to register the Status class. This is usually done in the configuration files.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/924/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/924,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc45_AmY,incubator-stormcrawler,972818840,924,NA,jcruzmartini,6817516,Juan Cruz Martini,,NA,2021-11-18T12:23:57Z,2021-11-18T12:23:57Z,"we faced this issue when testing 2.2 with storm 2.3.0 , but we were not sure if it was something on our side ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc45_AmY/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/925,https://api.github.com/repos/apache/incubator-stormcrawler/issues/925,incubator-stormcrawler,1055094647,925,JSoupParserBolt cannot configure more than one JSoupFilters per worker,Mikwiss,7784455,Mikwiss,mikwiss00@gmail.com,CLOSED,2021-11-16T16:43:03Z,2021-11-17T10:16:55Z,"Hi all !

I'm playing with the apache storm parallelism. With the following configuration, I encounter an issue : 

Conf yaml :
```
config:
    topology.workers: 1
```

Flux file :
```
-  id: ""parser""
   className: ""com.digitalpebble.stormcrawler.bolt.JSoupParserBolt""
   parallelism: 2
```

In this case, only the first JSoupParserBolt instantiated has a not empty list of JSoupFilters. With some investigation, I found a variable should be not static : 

`    public static String configFile = ""jsoup.filters.config.file""; `

With the keyword static, all the bolt on the same worker share the variable. After the first instantiation, the JouspFilters looses the key config value _jsoup.filters.config.file_. 

JsoupFilters line 93 : 
```
public JSoupFilters(Map stormConf, String configFile) throws IOException {
		this.configFile = configFile;
}
```

I'll run some test and I'll make a pull request !","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/925/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/926,https://api.github.com/repos/apache/incubator-stormcrawler/issues/926,incubator-stormcrawler,1055111110,926,Kyro Class is not registered: com.digitalpebble.stormcrawler.persistence.Status,fackse,78822845,,,CLOSED,2021-11-16T17:00:00Z,2021-11-17T12:00:26Z,"In version 1.17 the following error message appears in the Storm UI: 
` java.lang.RuntimeException:  java.lang.IllegalArgumentException: Class is not registered:  com.digitalpebble.stormcrawler.persistence.Status Note: To register this class use: kryo.register(com.digitalpe....`
The following components output this error:
1. memoryspout
2. fetch

We are using storm-crawler/external/elasticsearch/


Maybe this is related to #924. Attached is the used pom.xml (Githib doesn't like xml files, so I had to change the extension to .txt)

Let me know if you need more information.

Thanks and kind regards
Norman
[pom.txt](https://github.com/DigitalPebble/storm-crawler/files/7548315/pom.txt)

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/926/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/926,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc455P_R,incubator-stormcrawler,971309009,926,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-11-17T07:27:51Z,2021-11-17T07:27:51Z,"thanks @fackse, I think this is a duplicate of #924
not sure why we are seeing these exceptions only now but I will fix it shortly
please note that the 1.x branch is not active, the fix will be in main branch. You will have to move to Storm2 in order to benefit from it","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc455P_R/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/926,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc456BuX,incubator-stormcrawler,971512727,926,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-11-17T12:00:26Z,2021-11-17T12:00:26Z,"Have fixed #924
@fackse the fix does not need you to use 2.x, it should be a matter of adding 

```
  topology.kryo.register:
    - com.digitalpebble.stormcrawler.Metadata
    - com.digitalpebble.stormcrawler.persistence.Status

```

to the configuration of your topology.
Please let us know if that doesn't fix it
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc456BuX/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/928,https://api.github.com/repos/apache/incubator-stormcrawler/issues/928,incubator-stormcrawler,1056249484,928,Follow refresh redirects,juli-alvarez,11411638,Julian Alvarez,,CLOSED,2021-11-17T15:14:38Z,2021-11-19T15:28:05Z,"Hi @jnioche! 
Currently we are using a custom protocol when fetching that does follow redirections. So far so good until we found a case where the redirection is being done by meta refresh tag in the parsing phase. This lead to unexpected and inconsistent results, like having two documents created in the ES index, the original seed with status REDIRECTION and status.code 200 and the redirected url with status FETCHED.
I want to propose a simple change in JSoupParserBolt that adds the followRefreshRedirects flag (defaulting to true) in order to be able to skip this behavior and just get the original seed with status FETCHED and status.code 200 in our example.
Please let me know what do you think and if you consider it will be helpful for others with this use case I will create the PR.
Thanks!

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/928/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/928,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc45-4EP,incubator-stormcrawler,972783887,928,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-11-18T11:34:01Z,2021-11-18T11:34:01Z,"hi @juli-alvarez, thanks for asking.

Can't you get the same result by setting _redirections.allowed: false_ in the config?
If your protocol follows redirections (which is often the case if you use Selenium or Playwright) then they will be handled there and only there?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc45-4EP/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/928,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc45_Sh7,incubator-stormcrawler,972892283,928,NA,juli-alvarez,11411638,Julian Alvarez,,NA,2021-11-18T14:01:57Z,2021-11-18T14:01:57Z,"Hi @jnioche, thanks for the quick response!
Exactly. For those seeds we crawl using follow redirections we just delegate this task to the ok http client in the fetcher bolt. We would expect to see that seed not marked as REDIRECTION but instead as FETCHED or ERROR. So, it's ok for us to use the redirections.allowed setting but it should include the whole redirection block.
`
        // redirection?
        try {
            String redirection = null;

            Element redirElement = jsoupDoc
                    .selectFirst(""meta[http-equiv~=(?i)refresh][content]"");
            if (redirElement != null) {
                redirection = RefreshTag.extractRefreshURL(redirElement
                        .attr(""content""));
            }

            if (StringUtils.isNotBlank(redirection)) {
                // stores the URL it redirects to
                // used for debugging mainly - do not resolve the target
                // URL
                LOG.info(""Found redir in {} to {}"", url, redirection);
                metadata.setValue(""_redirTo"", redirection);

                if (allowRedirs() && StringUtils.isNotBlank(redirection)) {
                    emitOutlink(tuple, new URL(url), redirection, metadata);
                }

                // Mark URL as redirected
                collector
                        .emit(com.digitalpebble.stormcrawler.Constants.StatusStreamName,
                                tuple, new Values(url, metadata,
                                        Status.REDIRECTION));
                collector.ack(tuple);
                eventCounter.scope(""tuple_success"").incr();
                return;
            }
        } catch (MalformedURLException e) {
            LOG.error(""MalformedURLException on {}"", url);
        }
`
Currently is just preventing the redirection to be emitted as DISCOVERED and the line with the emit as REDIRECTION is giving us problems.
What do you think?
Thanks!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc45_Sh7/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/928,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc46DLCe,incubator-stormcrawler,973910174,928,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-11-19T09:39:40Z,2021-11-19T09:39:40Z,"thanks, @juli-alvarez, I see what you mean. It would be better to have a separate configuration for this (_jsoup.ignore.meta.redirections_ with a default value of false?) as it is not quite the same as _redirections.allowed_.
This would cover the whole block. Any chance you could contribute a PR for this?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc46DLCe/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/928,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc46EJgf,incubator-stormcrawler,974166047,928,NA,juli-alvarez,11411638,Julian Alvarez,,NA,2021-11-19T15:25:13Z,2021-11-19T15:25:13Z,"Hi @jnioche! Totally agree with you.
PR created: https://github.com/DigitalPebble/storm-crawler/pull/930
Thanks!!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc46EJgf/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/929,https://api.github.com/repos/apache/incubator-stormcrawler/issues/929,incubator-stormcrawler,1058407835,929,[Elasticsearch] Fielddata is disabled on text fields by default.,fackse,78822845,,,CLOSED,2021-11-19T11:04:55Z,2021-11-19T14:13:54Z,"In version 2.1 there seems to be a bug in the ES_IndexInit.sh. Unfortunately I'm not quite fit about Elasticsearch, however the AggregationSpout gives an error message:

> 2021-11-19 10:57:50.715 c.d.s.e.p.AggregationSpout I/O dispatcher 5 [ERROR]  Exception with ES query
> org.elasticsearch.ElasticsearchStatusException: Elasticsearch exception [type=search_phase_execution_exception, reason=all shards failed]
>         at org.elasticsearch.rest.BytesRestResponse.errorFromXContent(BytesRestResponse.java:177) ~[stormjar.jar:?]
>         at org.elasticsearch.client.RestHighLevelClient.parseEntity(RestHighLevelClient.java:1793) ~[stormjar.jar:?]
>         at org.elasticsearch.client.RestHighLevelClient.parseResponseException(RestHighLevelClient.java:1770) ~[stormjar.jar:?]
>         at org.elasticsearch.client.RestHighLevelClient$1.onFailure(RestHighLevelClient.java:1686) [stormjar.jar:?]
>         at org.elasticsearch.client.RestClient$FailureTrackingResponseListener.onDefinitiveFailure(RestClient.java:598) [stormjar.jar:?]
>         at org.elasticsearch.client.RestClient$1.completed(RestClient.java:343) [stormjar.jar:?]
>         at org.elasticsearch.client.RestClient$1.completed(RestClient.java:327) [stormjar.jar:?]
>         at org.apache.http.concurrent.BasicFuture.completed(BasicFuture.java:122) [stormjar.jar:?]
>         at org.apache.http.impl.nio.client.DefaultClientExchangeHandlerImpl.responseCompleted(DefaultClientExchangeHandlerImpl.java:181) [stormjar.jar:?]
>         at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.processResponse(HttpAsyncRequestExecutor.java:448) [stormjar.jar:?]
>         at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.inputReady(HttpAsyncRequestExecutor.java:338) [stormjar.jar:?]
>         at org.apache.http.impl.nio.DefaultNHttpClientConnection.consumeInput(DefaultNHttpClientConnection.java:265) [stormjar.jar:?]
>         at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:81) [stormjar.jar:?]
>         at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:39) [stormjar.jar:?]
>         at org.apache.http.impl.nio.reactor.AbstractIODispatch.inputReady(AbstractIODispatch.java:114) [stormjar.jar:?]
>         at org.apache.http.impl.nio.reactor.BaseIOReactor.readable(BaseIOReactor.java:162) [stormjar.jar:?]
>         at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvent(AbstractIOReactor.java:337) [stormjar.jar:?]
>         at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvents(AbstractIOReactor.java:315) [stormjar.jar:?]
>         at org.apache.http.impl.nio.reactor.AbstractIOReactor.execute(AbstractIOReactor.java:276) [stormjar.jar:?]
>         at org.apache.http.impl.nio.reactor.BaseIOReactor.execute(BaseIOReactor.java:104) [stormjar.jar:?]
>         at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor$Worker.run(AbstractMultiworkerIOReactor.java:591) [stormjar.jar:?]
>         at java.lang.Thread.run(Thread.java:748) [?:1.8.0_222]
>         Suppressed: org.elasticsearch.client.ResponseException: method [POST], host [http://elasticsearch:9200], URI [/status/_search?typed_keys=true&ignore_unavailable=false&expand_wildcards=open&allow_no_indices=true&ignore_throttled=true&search_type=query_then_fetch&batched_reduce_size=512&ccs_minimize_roundtrips=true], status line [HTTP/1.1 400 Bad Request]
> {""error"":{""root_cause"":[{""type"":""illegal_argument_exception"",""reason"":""Text fields are not optimised for operations that require per-document field data like aggregations and sorting, so these operations are disabled by default. Please use a keyword field instead. Alternatively, set fielddata=true on [key] in order to load field data by uninverting the inverted index. Note that this can use significant memory.""}],""type"":""search_phase_execution_exception"",""reason"":""all shards failed"",""phase"":""query"",""grouped"":true,""failed_shards"":[{""shard"":0,""index"":""status"",""node"":""7x7XAkS4S7m2Xbtz2E-BXQ"",""reason"":{""type"":""illegal_argument_exception"",""reason"":""Text fields are not optimised for operations that require per-document field data like aggregations and sorting, so these operations are disabled by default. Please use a keyword field instead. Alternatively, set fielddata=true on [key] in order to load field data by uninverting the inverted index. Note that this can use significant memory.""}}],""caused_by"":{""type"":""illegal_argument_exception"",""reason"":""Text fields are not optimised for operations that require per-document field data like aggregations and sorting, so these operations are disabled by default. Please use a keyword field instead. Alternatively, set fielddata=true on [key] in order to load field data by uninverting the inverted index. Note that this can use significant memory."",""caused_by"":{""type"":""illegal_argument_exception"",""reason"":""Text fields are not optimised for operations that require per-document field data like aggregations and sorting, so these operations are disabled by default. Please use a keyword field instead. Alternatively, set fielddata=true on [key] in order to load field data by uninverting the inverted index. Note that this can use significant memory.""}}},""status"":400}
>                 at org.elasticsearch.client.RestClient.convertResponse(RestClient.java:283) ~[stormjar.jar:?]
>                 at org.elasticsearch.client.RestClient.access$1700(RestClient.java:97) ~[stormjar.jar:?]
>                 at org.elasticsearch.client.RestClient$1.completed(RestClient.java:331) [stormjar.jar:?]
>                 at org.elasticsearch.client.RestClient$1.completed(RestClient.java:327) [stormjar.jar:?]
>                 at org.apache.http.concurrent.BasicFuture.completed(BasicFuture.java:122) [stormjar.jar:?]
>                 at org.apache.http.impl.nio.client.DefaultClientExchangeHandlerImpl.responseCompleted(DefaultClientExchangeHandlerImpl.java:181) [stormjar.jar:?]
>                 at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.processResponse(HttpAsyncRequestExecutor.java:448) [stormjar.jar:?]
>                 at org.apache.http.nio.protocol.HttpAsyncRequestExecutor.inputReady(HttpAsyncRequestExecutor.java:338) [stormjar.jar:?]
>                 at org.apache.http.impl.nio.DefaultNHttpClientConnection.consumeInput(DefaultNHttpClientConnection.java:265) [stormjar.jar:?]
>                 at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:81) [stormjar.jar:?]
>                 at org.apache.http.impl.nio.client.InternalIODispatch.onInputReady(InternalIODispatch.java:39) [stormjar.jar:?]
>                 at org.apache.http.impl.nio.reactor.AbstractIODispatch.inputReady(AbstractIODispatch.java:114) [stormjar.jar:?]
>                 at org.apache.http.impl.nio.reactor.BaseIOReactor.readable(BaseIOReactor.java:162) [stormjar.jar:?]
>                 at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvent(AbstractIOReactor.java:337) [stormjar.jar:?]
>                 at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvents(AbstractIOReactor.java:315) [stormjar.jar:?]
>                 at org.apache.http.impl.nio.reactor.AbstractIOReactor.execute(AbstractIOReactor.java:276) [stormjar.jar:?]
>                 at org.apache.http.impl.nio.reactor.BaseIOReactor.execute(BaseIOReactor.java:104) [stormjar.jar:?]
>                 at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor$Worker.run(AbstractMultiworkerIOReactor.java:591) [stormjar.jar:?]
>                 at java.lang.Thread.run(Thread.java:748) [?:1.8.0_222]
> Caused by: org.elasticsearch.ElasticsearchException: Elasticsearch exception [type=illegal_argument_exception, reason=Text fields are not optimised for operations that require per-document field data like aggregations and sorting, so these operations are disabled by default. Please use a keyword field instead. Alternatively, set fielddata=true on [key] in order to load field data by uninverting the inverted index. Note that this can use significant memory.]
>         at org.elasticsearch.ElasticsearchException.innerFromXContent(ElasticsearchException.java:496) ~[stormjar.jar:?]
>         at org.elasticsearch.ElasticsearchException.fromXContent(ElasticsearchException.java:407) ~[stormjar.jar:?]
>         at org.elasticsearch.ElasticsearchException.innerFromXContent(ElasticsearchException.java:437) ~[stormjar.jar:?]
>         at org.elasticsearch.ElasticsearchException.failureFromXContent(ElasticsearchException.java:603) ~[stormjar.jar:?]
>         at org.elasticsearch.rest.BytesRestResponse.errorFromXContent(BytesRestResponse.java:169) ~[stormjar.jar:?]
>         ... 21 more
> Caused by: org.elasticsearch.ElasticsearchException: Elasticsearch exception [type=illegal_argument_exception, reason=Text fields are not optimised for operations that require per-document field data like aggregations and sorting, so these operations are disabled by default. Please use a keyword field instead. Alternatively, set fielddata=true on [key] in order to load field data by uninverting the inverted index. Note that this can use significant memory.]
>         at org.elasticsearch.ElasticsearchException.innerFromXContent(ElasticsearchException.java:496) ~[stormjar.jar:?]
>         at org.elasticsearch.ElasticsearchException.fromXContent(ElasticsearchException.java:407) ~[stormjar.jar:?]
>         at org.elasticsearch.ElasticsearchException.innerFromXContent(ElasticsearchException.java:437) ~[stormjar.jar:?]
>         at org.elasticsearch.ElasticsearchException.fromXContent(ElasticsearchException.java:407) ~[stormjar.jar:?]
>         at org.elasticsearch.ElasticsearchException.innerFromXContent(ElasticsearchException.java:437) ~[stormjar.jar:?]
>         at org.elasticsearch.ElasticsearchException.failureFromXContent(ElasticsearchException.java:603) ~[stormjar.jar:?]
>         at org.elasticsearch.rest.BytesRestResponse.errorFromXContent(BytesRestResponse.java:169) ~[stormjar.jar:?]
>         ... 21 more

However, in the DevOps console of Kibana the query works. Currently I have worked around the problem by creating the status index as follows:
```
PUT status
{
	""settings"": {
		""index"": {
			""number_of_shards"": 10,
			""number_of_replicas"": 1,
			""refresh_interval"": ""5s""
		}
	},
	""mappings"": {
			""dynamic_templates"": [{
				""metadata"": {
					""path_match"": ""metadata.*"",
					""match_mapping_type"": ""string"",
					""mapping"": {
						""type"": ""keyword"",
						""fielddata"": true
					}
				}
			}],
			""_source"": {
				""enabled"": true
			},
			""properties"": {
				""key"": {
					""type"": ""keyword"",
					""index"": true
					
				},
				""nextFetchDate"": {
					""type"": ""date"",
					""format"": ""date_optional_time""
				},
				""status"": {
					""type"": ""keyword""
				},
				""url"": {
					""type"": ""keyword""
				}
			}
	}
}

```
A warning is showed:

> #! dynamic template [metadata] has invalid content [{""path_match"":""metadata.*"",""match_mapping_type"":""string"",""mapping"":{""fielddata"":true,""type"":""keyword""}}], attempted to validate it with the following match_mapping_type: [string], caused by [unknown parameter [fielddata] on mapper [__dynamic__metadata] of type [keyword]]
> {
>   ""acknowledged"" : true,
>   ""shards_acknowledged"" : true,
>   ""index"" : ""status""
> }
> 

but it works anyway.
PS: Unfortunately I can not set labels","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/929/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/929,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc46DfaD,incubator-stormcrawler,973993603,929,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-11-19T11:30:54Z,2021-11-19T11:30:54Z,"thanks @fackse I will try to reproduce the problem
which version of ES are you on?
_key_ is [already marked as a keyword](https://github.com/DigitalPebble/storm-crawler/blob/master/external/elasticsearch/archetype/src/main/resources/archetype-resources/ES_IndexInit.sh#L37) so I am not sure why you are getting this

re:labels - I think only admins can set them for some reason
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc46DfaD/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/929,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc46DgQE,incubator-stormcrawler,973997060,929,NA,fackse,78822845,,,NA,2021-11-19T11:36:40Z,2021-11-19T11:36:40Z,"Hi @jnioche,
I'm using 7.14.2. Sorry, but I'm not an expert and so I just ""hacked around"" until it worked.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc46DgQE/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/929,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc46DiRC,incubator-stormcrawler,974005314,929,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-11-19T11:50:55Z,2021-11-19T11:50:55Z,"> I'm using 7.14.2. Sorry, but I'm not an expert and so I just ""hacked around"" until it worked.
Don't apologise! Hacking around is what I do for a living ;-)

I have tried with 7.15.2 with a topology generated from the 2.2-SNAPSHOT archetype and did not get the error. Same with the 2.1 archetype.

Where did you get the _ES_indexInit.sh_ file from? It could be that it dates from a while back before _key_ was used as the default field name.
 


 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc46DiRC/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/929,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc46D7T6,incubator-stormcrawler,974107898,929,NA,fackse,78822845,,,NA,2021-11-19T14:13:54Z,2021-11-19T14:13:54Z,"Thanks for the kind reply :-)
I got the ES_indexInit.sh from the generated archetype (2.1). But then I assume that the error comes from somewhere else. I run the whole thing as a Docker Swarm, possibly the cause is in the Elasticsearch image. Anyway, if the error occurs again, I'll take a closer look.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc46D7T6/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/933,https://api.github.com/repos/apache/incubator-stormcrawler/issues/933,incubator-stormcrawler,1060011181,933,Remove selenium.instances.num,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2021-11-22T11:06:02Z,2021-11-22T11:11:58Z,"This had been added in #505 but is superseded by #932
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/933/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/935,https://api.github.com/repos/apache/incubator-stormcrawler/issues/935,incubator-stormcrawler,1078890600,935,Log4J vulnerability - CVE-2021-44228,jcruzmartini,6817516,Juan Cruz Martini,,CLOSED,2021-12-13T19:18:20Z,2022-01-10T12:21:29Z,"What kind of issue is this?

 - [] Question. This issue tracker is not the best place for questions. If you want to ask how to do
       something, or to understand why something isn't working the way you expect it to, use StackOverflow
       instead with the label 'stormcrawler': https://stackoverflow.com/questions/tagged/stormcrawler 

 - [ ] Bug report. If you’ve found a bug, please include a test if you can, it makes it a lot easier to fix things. Use the label 'bug' on the issue.
 
 - [x] Feature request. Please use the label 'wish' on the issue.

Thanks!

Adding this issue, in order to let you know that the stormcrawler project is being affected by the vulnerability documented here
https://nvd.nist.gov/vuln/detail/CVE-2021-44228 related with log4j.

![image](https://user-images.githubusercontent.com/6817516/145873900-d76e0beb-1fa1-4cb8-9b7a-b582c0e55c24.png)

```
 ✘ jmartini@cacute-xps  ~/workspace/storm-crawler-fork   master  mvn dependency:tree | grep log4j
[INFO] |  +- org.apache.logging.log4j:log4j-api:jar:2.11.2:provided
[INFO] |  +- org.apache.logging.log4j:log4j-core:jar:2.11.2:provided

```
we can create a PR for fixing this on our end , overriding the dependencies that are coming from apache storm dependency ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/935/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/935,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc47LQqq,incubator-stormcrawler,992807594,935,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-12-13T19:39:00Z,2021-12-13T19:39:00Z,"That would be great, thank you

Sent from my mobile,  please excuse any typos

On Mon, 13 Dec 2021, 19:18 Juan Cruz Martini, ***@***.***>
wrote:

> What kind of issue is this?
>
>    -
>
>    [] Question. This issue tracker is not the best place for questions.
>    If you want to ask how to do
>    something, or to understand why something isn't working the way you
>    expect it to, use StackOverflow
>    instead with the label 'stormcrawler':
>    https://stackoverflow.com/questions/tagged/stormcrawler
>    -
>
>    Bug report. If you’ve found a bug, please include a test if you can,
>    it makes it a lot easier to fix things. Use the label 'bug' on the issue.
>    -
>
>    Feature request. Please use the label 'wish' on the issue.
>
> Thanks!
>
> Adding this issue, in order to let you know that the stormcrawler project
> is being affected by the vulnerability documented here
> https://nvd.nist.gov/vuln/detail/CVE-2021-44228 related with log4j.
>
> [image: image]
> <https://user-images.githubusercontent.com/6817516/145873900-d76e0beb-1fa1-4cb8-9b7a-b582c0e55c24.png>
>
>  ✘ ***@***.***  ~/workspace/storm-crawler-fork   master  mvn dependency:tree | grep log4j
>
> [INFO] |  +- org.apache.logging.log4j:log4j-api:jar:2.11.2:provided
>
> [INFO] |  +- org.apache.logging.log4j:log4j-core:jar:2.11.2:provided
>
>
>
>
> we can create a PR for fixing this on our end , overriding the
> dependencies that are coming from apache storm dependency
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/DigitalPebble/storm-crawler/issues/935>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AABVJT7KGBMVHQ4X5RGK3DLUQZBIPANCNFSM5J66CBIQ>
> .
> Triage notifications on the go with GitHub Mobile for iOS
> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>
> or Android
> <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.
>
>
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc47LQqq/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/935,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc47LZqc,incubator-stormcrawler,992844444,935,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2021-12-13T20:08:30Z,2021-12-13T20:08:30Z,"> overriding the dependencies that are coming from apache storm dependency

Instead of overrding with a fixed version, what about enforcing 2.15.0 as the minimum version? See https://gist.github.com/gunnarmorling/8026d004776313ebfc65674202134e6d and apache/tika@859b57b","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc47LZqc/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/935,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc47Lrt5,incubator-stormcrawler,992918393,935,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-12-13T21:17:20Z,2021-12-13T21:17:20Z,I expect the main issue would be that a publicly accessible Storm UI (as well as its other services) could have the same vulnerability without us being able to do anything about it. Or wouldn't that be the case at all?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc47Lrt5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/935,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc47L2XQ,incubator-stormcrawler,992962000,935,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2021-12-13T22:19:06Z,2021-12-13T22:19:06Z,"See [STORM-3808](https://issues.apache.org/jira/browse/STORM-3808). For a StormCrawler instance running on Storm removing the JndiLookup.class from the log4j-core jar shipped with Storm is highly recommended as Storm's jar are in front of the classpath. Could be even done without stopping the process, see https://github.com/corretto/hotpatch-for-apache-log4j2","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc47L2XQ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/935,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc47NXOC,incubator-stormcrawler,993358722,935,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2021-12-14T09:46:41Z,2021-12-14T09:46:41Z,[Log4j 2.16.0 released](https://lists.apache.org/thread/d6v4r6nosxysyq9rvnr779336yf0woz4),"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc47NXOC/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/935,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc47b4iR,incubator-stormcrawler,997165201,935,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2021-12-18T07:50:57Z,2021-12-18T07:50:57Z,"If I understand correctly, running the enforcer will break our build until the issue is solved in Storm. In which case, we might want to override as suggested by @jcruzmartini so that we are not blocked. Is that correct?
We probably need to add a similar mechanism to the poms provided by the archetypes.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc47b4iR/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/935,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc47h2ya,incubator-stormcrawler,998730906,935,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2021-12-21T12:15:52Z,2021-12-21T12:15:52Z,"Yes, the log4j dependency needs to be overridden. Nevertheless, the enforcer plugin makes sure that this is done in all modules. Later on, with the next version of Storm, we can remove the log4j dependency.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc47h2ya/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/938,https://api.github.com/repos/apache/incubator-stormcrawler/issues/938,incubator-stormcrawler,1100463171,938,Investigate the PointInTime API in Elaticsearch,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-01-12T15:18:09Z,2022-11-25T14:21:28Z,"https://www.elastic.co/guide/en/elasticsearch/reference/current/point-in-time-api.html

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/938/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/938,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5PIJgh,incubator-stormcrawler,1327536161,938,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-11-25T14:21:27Z,2022-11-25T14:21:27Z,Probably meant to use that within the Spouts but not sure now whether it would be really useful. The filter on the _nextFetchDate_ is cached so the result would be the same. Closing for now.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5PIJgh/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/940,https://api.github.com/repos/apache/incubator-stormcrawler/issues/940,incubator-stormcrawler,1115087890,940,Upgrade ES client to 7.15.2,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-01-26T14:34:36Z,2022-01-26T14:44:33Z,"org.elasticsearch/elasticsearch : 7.5.0 
is reported to have critical vulnerabilities. Time for an upgrade.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/940/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/941,https://api.github.com/repos/apache/incubator-stormcrawler/issues/941,incubator-stormcrawler,1115096070,941,ES client to use compression (configurable) ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-01-26T14:42:14Z,2022-01-26T14:44:52Z,"The Rest high level client can send compressed requests and decompress responses from ES.
See https://github.com/elastic/elasticsearch/pull/55413

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/941/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/944,https://api.github.com/repos/apache/incubator-stormcrawler/issues/944,incubator-stormcrawler,1124135729,944,Convert LinkParseFilter into a JSoupFilter,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-02-04T12:12:18Z,2022-02-04T14:53:23Z,"The conversion from the JSoup document to a DOM structure typically takes 30% of the processing time in JSoupParserBolt. This conversion is only needed if one ore more of the configured ParseFilters needs a DOM structure. This is the case for the LinkParseFilter.
If the same functionality was available as a JSoupFilter, we could potentially save quite a bit of CPU.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/944/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/945,https://api.github.com/repos/apache/incubator-stormcrawler/issues/945,incubator-stormcrawler,1128575971,945,Newer Elasticsearch Version deprecate the REST High Level Client in favour of the Java API Client,rzo1,13417392,Richard Zowalla,,CLOSED,2022-02-09T13:57:05Z,2024-05-03T11:31:42Z,"The High Level Rest Client is deprecated in favor of the [Elasticsearch Java API Client](https://www.elastic.co/guide/en/elasticsearch/client/java-api-client/current/introduction.html)

This will affect SC, if we want to upgrade Elasticsearch from 7.5.2 to 7.17.0

We should investigate whether the current High Level REST client can be easily replaced by the new Java API client.

A migration guide is available [here](https://www.elastic.co/guide/en/elasticsearch/client/java-api-client/current/migrate-hlrc.html)","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/945/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/945,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc49nmIj,incubator-stormcrawler,1033789987,945,NA,rzo1,13417392,Richard Zowalla,,NA,2022-02-09T13:59:35Z,2022-02-09T13:59:35Z,"@jnioche would have labeld it accordingly, but I do not have  the permissions.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc49nmIj/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/945,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc49ny02,incubator-stormcrawler,1033841974,945,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-02-09T14:50:35Z,2022-02-09T14:50:35Z,Elasticsearch 8.0 is approaching. We could either port the whole module to 8 and replace the client at the same time or maybe have a new module _elasticsearch-8_ and keep the existing one with HLRC for a bit? We could clean things up a bit at the same time e.g. remove the CollapsingSpout,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc49ny02/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/945,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc49n00Y,incubator-stormcrawler,1033850136,945,NA,rzo1,13417392,Richard Zowalla,,NA,2022-02-09T14:58:30Z,2022-02-09T14:58:30Z,"> The Elasticsearch Java client is forward compatible; meaning that the client supports communicating with greater or equal minor versions of Elasticsearch. Elasticsearch language clients are only backwards compatible with default distributions and without guarantees made. 

I like the `elasticsearch-8` approach as users might have deployed older elasticsearch versions and the HLRC replacement might have an impact, so perhaps we can still update to `7.17.0` (and live with the deprecation warning) and later come up with a `elasticsearch-8` module. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc49n00Y/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/945,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc49n1D7,incubator-stormcrawler,1033851131,945,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-02-09T14:59:24Z,2022-02-09T14:59:24Z,"> > The Elasticsearch Java client is forward compatible; meaning that the client supports communicating with greater or equal minor versions of Elasticsearch. Elasticsearch language clients are only backwards compatible with default distributions and without guarantees made.
> 
> I like the `elasticsearch-8` approach as users might have deployed older elasticsearch versions and the HLRC replacement might have an impact, so perhaps we can still update to `7.17.0` (and live with the deprecation warning) and later come up with a `elasticsearch-8` module.

I know quite a few users for whom this would be the case","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc49n1D7/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/945,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc49wD2t,incubator-stormcrawler,1036008877,945,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-02-11T09:17:43Z,2022-02-11T09:17:43Z,"Elasticsearch 8 is out! 
https://www.elastic.co/blog/whats-new-elastic-8-0-0
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc49wD2t/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/945,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc49w0FA,incubator-stormcrawler,1036206400,945,NA,rzo1,13417392,Richard Zowalla,,NA,2022-02-11T13:19:43Z,2022-02-11T13:19:43Z,https://www.elastic.co/guide/en/elasticsearch/reference/8.0/migrating-8.0.html,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc49w0FA/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/945,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5CPGes,incubator-stormcrawler,1111254956,945,NA,ngramp,104520902,Graham Perry,,NA,2022-04-27T17:09:17Z,2022-04-27T17:09:17Z,"> Elasticsearch 8 is out! https://www.elastic.co/blog/whats-new-elastic-8-0-0

This related to that? The ES_IndexInit.sh script fails in multiple places. Can't delete metrics* or content* wildcard references, can't use metric* index patterns as a legacy template as it's used by Elastic Agent as per:
https://www.elastic.co/guide/en/elasticsearch/reference/current/index-templates.html
Can disable the builtin templates using stack.templates.enabled, but seems like it would break other features. Seems it needs to be composable, _index_template.

Also, since security is the default now, all the protocols should be changed to https as standard and method to deal with cacerts for the connections implemented (does not even seem to respect systemwide certs).","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5CPGes/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/945,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5CSnfc,incubator-stormcrawler,1112176604,945,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-04-28T13:02:56Z,2022-04-28T13:02:56Z,"thanks @devlperry 
we could have an alternative version of the script in the current module to fix the issues you mentioned when running ES8
any chance you could contribute a PR for this?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5CSnfc/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/945,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5a86uH,incubator-stormcrawler,1525918599,945,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-04-27T15:38:06Z,2023-04-27T15:38:06Z,"Note to self: BulkIngester is what BulkProcessor used to be

https://www.elastic.co/guide/en/elasticsearch/client/java-api-client/current/indexing-bulk.html","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5a86uH/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/945,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58veiC,incubator-stormcrawler,2092820610,945,NA,rzo1,13417392,Richard Zowalla,,NA,2024-05-03T11:31:42Z,2024-05-03T11:31:42Z,"We dropped ES, so closing this issue is ok now.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58veiC/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/950,https://api.github.com/repos/apache/incubator-stormcrawler/issues/950,incubator-stormcrawler,1129972261,950,Bump Elasticsearch HLRC to 7.17.0,rzo1,13417392,Richard Zowalla,,CLOSED,2022-02-10T12:25:21Z,2022-02-10T12:57:23Z,"Bump [elasticsearch-rest-high-level-client](https://github.com/elastic/elasticsearch) from 7.5.2 to 7.17.0.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/elastic/elasticsearch/releases"">elasticsearch-rest-high-level-client's releases</a>.</em></p>
<blockquote>
<h2>Elasticsearch 7.17.0</h2>
<p>Downloads: <a href=""https://elastic.co/downloads/elasticsearch"">https://elastic.co/downloads/elasticsearch</a>
Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/reference/7.17/release-notes-7.17.0.html"">https://www.elastic.co/guide/en/elasticsearch/reference/7.17/release-notes-7.17.0.html</a></p>
<h2>Elasticsearch 7.16.3</h2>
<p>Downloads: <a href=""https://elastic.co/downloads/elasticsearch"">https://elastic.co/downloads/elasticsearch</a>
Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/reference/7.16/release-notes-7.16.3.html"">https://www.elastic.co/guide/en/elasticsearch/reference/7.16/release-notes-7.16.3.html</a></p>
<h2>Elasticsearch 7.16.2</h2>
<p>Downloads: <a href=""https://elastic.co/downloads/elasticsearch"">https://elastic.co/downloads/elasticsearch</a>
Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/reference/7.16/release-notes-7.16.2.html"">https://www.elastic.co/guide/en/elasticsearch/reference/7.16/release-notes-7.16.2.html</a></p>
<h2>Elasticsearch 7.16.1</h2>
<p>Downloads: <a href=""https://elastic.co/downloads/elasticsearch"">https://elastic.co/downloads/elasticsearch</a>
Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/reference/7.16/release-notes-7.16.1.html"">https://www.elastic.co/guide/en/elasticsearch/reference/7.16/release-notes-7.16.1.html</a></p>
<h2>Elasticsearch 7.16.0</h2>
<p>Downloads: <a href=""https://elastic.co/downloads/elasticsearch"">https://elastic.co/downloads/elasticsearch</a>
Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/reference/7.16/release-notes-7.16.0.html"">https://www.elastic.co/guide/en/elasticsearch/reference/7.16/release-notes-7.16.0.html</a></p>
<h2>Elasticsearch 7.15.2</h2>
<p>Downloads: <a href=""https://elastic.co/downloads/elasticsearch"">https://elastic.co/downloads/elasticsearch</a>
Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/reference/7.15/release-notes-7.15.2.html"">https://www.elastic.co/guide/en/elasticsearch/reference/7.15/release-notes-7.15.2.html</a></p>
<h2>Elasticsearch 7.15.1</h2>
<p>Downloads: <a href=""https://elastic.co/downloads/elasticsearch"">https://elastic.co/downloads/elasticsearch</a>
Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/reference/7.15/release-notes-7.15.1.html"">https://www.elastic.co/guide/en/elasticsearch/reference/7.15/release-notes-7.15.1.html</a></p>
<h2>Elasticsearch 7.15.0</h2>
<p>Downloads: <a href=""https://elastic.co/downloads/elasticsearch"">https://elastic.co/downloads/elasticsearch</a>
Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/reference/7.15/release-notes-7.15.0.html"">https://www.elastic.co/guide/en/elasticsearch/reference/7.15/release-notes-7.15.0.html</a></p>
<h2>Elasticsearch 7.14.2</h2>
<p>Downloads: <a href=""https://elastic.co/downloads/elasticsearch"">https://elastic.co/downloads/elasticsearch</a>
Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/reference/7.14/release-notes-7.14.2.html"">https://www.elastic.co/guide/en/elasticsearch/reference/7.14/release-notes-7.14.2.html</a></p>
<h2>Elasticsearch 7.14.1</h2>
<p>Downloads: <a href=""https://elastic.co/downloads/elasticsearch"">https://elastic.co/downloads/elasticsearch</a>
Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/reference/7.14/release-notes-7.14.1.html"">https://www.elastic.co/guide/en/elasticsearch/reference/7.14/release-notes-7.14.1.html</a></p>
<h2>Elasticsearch 7.14.0</h2>
<p>Downloads: <a href=""https://elastic.co/downloads/elasticsearch"">https://elastic.co/downloads/elasticsearch</a>
Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/reference/7.14/release-notes-7.14.0.html"">https://www.elastic.co/guide/en/elasticsearch/reference/7.14/release-notes-7.14.0.html</a></p>
<h2>Elasticsearch 7.13.4</h2>
<p>Downloads: <a href=""https://elastic.co/downloads/elasticsearch"">https://elastic.co/downloads/elasticsearch</a>
Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/reference/7.13/release-notes-7.13.4.html"">https://www.elastic.co/guide/en/elasticsearch/reference/7.13/release-notes-7.13.4.html</a></p>
<h2>Elasticsearch 7.13.3</h2>
<p>Downloads: <a href=""https://elastic.co/downloads/elasticsearch"">https://elastic.co/downloads/elasticsearch</a></p>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/950/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/952,https://api.github.com/repos/apache/incubator-stormcrawler/issues/952,incubator-stormcrawler,1130026943,952,Upgrade Caffeine to 2.9.3,rzo1,13417392,Richard Zowalla,,CLOSED,2022-02-10T12:56:19Z,2022-02-10T12:59:02Z,https://github.com/ben-manes/caffeine/releases/tag/v2.9.3,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/952/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/954,https://api.github.com/repos/apache/incubator-stormcrawler/issues/954,incubator-stormcrawler,1146102929,954,Issue with the order of emit and emitOutlink for redirections in FetcherBolt,juli-alvarez,11411638,Julian Alvarez,,CLOSED,2022-02-21T18:15:16Z,2022-02-24T14:00:24Z,"What kind of issue is this?

 - [ ] Question. This issue tracker is not the best place for questions. If you want to ask how to do
       something, or to understand why something isn't working the way you expect it to, use StackOverflow
       instead with the label 'stormcrawler': https://stackoverflow.com/questions/tagged/stormcrawler 

 - [X] Bug report. If you’ve found a bug, please include a test if you can, it makes it a lot easier to fix things. Use the label 'bug' on the issue.
 
 - [ ] Feature request. Please use the label 'wish' on the issue.

Thanks!

Hi @jnioche. 
I've found an issue in the fetcher bolt . When a redirection takes place, the outlink (that belongs to the page in the redirTo) is being processed after the update to redirection status of the current url is emitted to the status updater bolt. For those cases where the fetcher and the status updater bolts are in the same worker, the metadata instance is the same which is causing unexpected behavior, like metadata keys being lost, when we are creating the metadata for the child based on the parent's in the metadata transfer class.
The issue is easily fixed by changing the order in the fetcher bolt to parse the outlink first and then emit the update of the parent url, the same way it's handled for redirections in the jsoup bolt.
If you want I can create a PR for it.
Thanks.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/954/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/954,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc4-clLf,incubator-stormcrawler,1047679711,954,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-02-22T11:04:02Z,2022-02-22T11:04:02Z,"hi @juli-alvarez, thanks for reporting this. This is definitely a bug which might affect quite a few users.
We should copy the metadata anyway so that any alterations in a tuple would not affect the other, regardless of order. We could change the order as you suggested to be consistent with the way it is done in the parser. 
A PR would be greatly appreciated!
Thanks again ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc4-clLf/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/954,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc4-g58k,incubator-stormcrawler,1048813348,954,NA,juli-alvarez,11411638,Julian Alvarez,,NA,2022-02-23T14:03:21Z,2022-02-23T14:03:21Z,"Hi @jnioche. What do you think about copying parent's metadata inside the emitOutlink method? This way we cover fetcher, simple fetcher and jsoup parser bolts. Also, I've seen in the fetcher bolts the emitOutlink is also called for sitemaps, so we cover that as well.. The only downside I see is if anyone overrides the method and removes the copy then the issue will appear again.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc4-g58k/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/954,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc4-hgpn,incubator-stormcrawler,1048971879,954,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-02-23T16:32:31Z,2022-02-23T16:32:31Z,"Judging by the code in [StatusEmitterBolt](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/bolt/StatusEmitterBolt.java#L103), the metadata for the outlink is created by the [MetadataTransfer](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/util/MetadataTransfer.java#L160). It is a brand new one and should not be the one from the original URL.
So the problem you describe should not happen really. Do you have a unit test to reproduce it?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc4-hgpn/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/954,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc4-iCg5,incubator-stormcrawler,1049110585,954,NA,juli-alvarez,11411638,Julian Alvarez,,NA,2022-02-23T19:00:51Z,2022-02-23T19:00:51Z,"Hi @jnioche . Yes, that's true, but the issue only arises in the fetcher where the parent url is being emitted before the outlink is processed. In my case, when the fetcher and the status bolts were in the same worker, the instance used in the metadata transfer to create the outlink's metadata was the same. So, if parent's metadata was modified in the status bolt it caused weird issues when creating the outlink in the fetcher, like keys missing randomly. That's why changing the order fixed the issue. Probably copying the parent's metadata is redundant if the order is changed because as you said, outlink metadata is a new instance.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc4-iCg5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/954,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc4-j9rJ,incubator-stormcrawler,1049615049,954,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-02-24T08:38:10Z,2022-02-24T08:38:10Z,ok let's change the order in the FetcherBolt. Can you send a PR with a comment in the code referencing this issue so that if anyone looks at it in the future they can be aware that the order matters. Thanks!,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc4-j9rJ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/956,https://api.github.com/repos/apache/incubator-stormcrawler/issues/956,incubator-stormcrawler,1158625745,956,Spout does not reconnect to URLFrontier if an exception occurs,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-03-03T16:29:19Z,2022-03-03T16:30:37Z,"To reproduce, start a topo reading from a Frontier without the Frontier having started. The _isInQuery_ field is not reset to false, which is why the spout doesn't try to populate the buffer.

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/956/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/957,https://api.github.com/repos/apache/incubator-stormcrawler/issues/957,incubator-stormcrawler,1166654519,957,Investigate doc-value-only fields ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-03-11T17:04:10Z,2024-05-03T11:32:19Z,"https://www.elastic.co/blog/whats-new-elasticsearch-kibana-cloud-8-1-0)](https://www.elastic.co/blog/whats-new-elasticsearch-kibana-cloud-8-1-0

For the _status_ index, only the _key_ and _nextFetchDate_ are frequently queried. Anything else (URL, metadata, status) is mostly used in kibana (unless there is filtering on the source).

Most fields in the _metrics_ would benefit from it.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/957/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/957,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58vetd,incubator-stormcrawler,2092821341,957,NA,rzo1,13417392,Richard Zowalla,,NA,2024-05-03T11:32:19Z,2024-05-03T11:32:19Z,We dropped ES as we joined the ASF incubator. Closing.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58vetd/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/958,https://api.github.com/repos/apache/incubator-stormcrawler/issues/958,incubator-stormcrawler,1168461683,958,Enable _source for  content index in ES archetype,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-03-14T14:27:56Z,2022-03-21T11:45:41Z,"With 
```
""_source"": {
  ""enabled"": true
}
```
The _content_ index takes less space on disk but it is not possible to show its content in Kibana. 
The archetypes are meant to be starting point, people can always make the ES schema more restrictive as they get more familiar with it.

Being able to see things with Kibana would help beginner understand what's happening under the bonnet.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/958/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/959,https://api.github.com/repos/apache/incubator-stormcrawler/issues/959,incubator-stormcrawler,1180828541,959,"Setting ""maxDepth"": 0 in urlfilter.json prevents ES seed injection",orliac,36704287,,,CLOSED,2022-03-25T13:58:37Z,2022-03-28T10:05:58Z,"With StormCrawler 2.3-SNAPSHOT, setting ""maxDepth"": 0 in the urlfilters.json prevents the seed injection into the ES index.

Expected behavior would be that the seeds would be injected and crawled with no redirection.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/959/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/959,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5AZmqb,incubator-stormcrawler,1080453787,959,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-03-28T10:05:57Z,2022-03-28T10:05:57Z,"thanks @orliac, should now be fixed. I simply removed the special rule for max depth 0","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5AZmqb/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/960,https://api.github.com/repos/apache/incubator-stormcrawler/issues/960,incubator-stormcrawler,1183078363,960,Upgrade to Storm 2.4.0,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-03-28T08:28:06Z,2022-03-28T17:27:43Z,"https://storm.apache.org/2022/03/25/storm240-released.html
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/960/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/962,https://api.github.com/repos/apache/incubator-stormcrawler/issues/962,incubator-stormcrawler,1194893658,962,Allow compatibility.mode for rest client to connect to ES8+,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-04-06T17:16:26Z,2022-04-06T17:50:10Z,"The new Java client will be used at some point, when it can do batch operations. see #945
In the meantime, we need the existing REST based client to be usable with an ES8+ cluster. Luckily there is a config that makes it possible.


","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/962/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/963,https://api.github.com/repos/apache/incubator-stormcrawler/issues/963,incubator-stormcrawler,1223095291,963,JSoupParserBolt - toOutlinks method as protected,juli-alvarez,11411638,Julian Alvarez,,CLOSED,2022-05-02T16:35:27Z,2022-05-03T14:04:44Z,"What kind of issue is this?

 - [ ] Question. This issue tracker is not the best place for questions. If you want to ask how to do
       something, or to understand why something isn't working the way you expect it to, use StackOverflow
       instead with the label 'stormcrawler': https://stackoverflow.com/questions/tagged/stormcrawler 

 - [ ] Bug report. If you’ve found a bug, please include a test if you can, it makes it a lot easier to fix things. Use the label 'bug' on the issue.
 
 - [X] Feature request. Please use the label 'wish' on the issue.

Thanks!

Hi @jnioche!
Is it possible to make toOutlinks method in JSoupParserBolt protected? We're allowing to customize the number of outlinks processed using a max in the metadata and we'd need to override that method in order to create create a new map with this limit and pass it to the parent's toOutlinks.
Thanks!

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/963/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/963,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Cgk0V,incubator-stormcrawler,1115835669,963,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-05-03T08:04:50Z,2022-05-03T08:04:50Z,"sure, done!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Cgk0V/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/963,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5ChvEC,incubator-stormcrawler,1116139778,963,NA,juli-alvarez,11411638,Julian Alvarez,,NA,2022-05-03T14:04:43Z,2022-05-03T14:04:43Z,Thanks @jnioche !!,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5ChvEC/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/964,https://api.github.com/repos/apache/incubator-stormcrawler/issues/964,incubator-stormcrawler,1223096049,964,FetcherBolt - customize fetcher delay based on metadata property,juli-alvarez,11411638,Julian Alvarez,,CLOSED,2022-05-02T16:36:12Z,2022-06-27T12:42:59Z,"What kind of issue is this?

 - [ ] Question. This issue tracker is not the best place for questions. If you want to ask how to do
       something, or to understand why something isn't working the way you expect it to, use StackOverflow
       instead with the label 'stormcrawler': https://stackoverflow.com/questions/tagged/stormcrawler 

 - [ ] Bug report. If you’ve found a bug, please include a test if you can, it makes it a lot easier to fix things. Use the label 'bug' on the issue.
 
 - [X] Feature request. Please use the label 'wish' on the issue.

Thanks!

Hi @jnioche!
We're trying to customize the crawl delay based on a property that comes in the metadata. We're passing this value to the fetchQueues.getFetchItemQueue() and using it to create the new FetchItemQueue. In case that the item already exists we set the minCrawlDelay if the new fetcher delay is greater than the current one (we take the less aggressive).
What do you think? It's possible to get this changes into the core?
Thanks!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/964/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/964,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Cgk-Y,incubator-stormcrawler,1115836312,964,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-05-03T08:05:44Z,2022-05-03T08:05:44Z,why not? do you want to submit a PR for it?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Cgk-Y/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/964,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Chu1B,incubator-stormcrawler,1116138817,964,NA,juli-alvarez,11411638,Julian Alvarez,,NA,2022-05-03T14:03:58Z,2022-05-03T14:03:58Z,Done! https://github.com/DigitalPebble/storm-crawler/pull/967,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Chu1B/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/965,https://api.github.com/repos/apache/incubator-stormcrawler/issues/965,incubator-stormcrawler,1223905813,965,Update to Apache Tika 2.4.0,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-05-03T10:07:10Z,2022-05-05T11:45:51Z,"[CHANGE NOTES](https://www.apache.org/dist/tika/2.4.0/CHANGES-2.4.0.txt
)

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/965/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/966,https://api.github.com/repos/apache/incubator-stormcrawler/issues/966,incubator-stormcrawler,1223982225,966,Can configure multiple addresses for URLFrontier nodes,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-05-03T11:39:40Z,2022-05-03T11:40:14Z,and get the spouts or status updater to connect to one each. Introduce a new config _urlfrontier.address_; if not set use values from _urlfrontier.host_ and _urlfrontier.port_.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/966/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/968,https://api.github.com/repos/apache/incubator-stormcrawler/issues/968,incubator-stormcrawler,1236683089,968,Update jsoup from 1.14.3 to 1.15.1,rzo1,13417392,Richard Zowalla,,CLOSED,2022-05-16T06:26:27Z,2022-05-16T10:14:56Z,"Bumps [jsoup](https://github.com/jhy/jsoup) from 1.14.3 to 1.15.1.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/jhy/jsoup/releases"">jsoup's releases</a>.</em></p>
<blockquote>
<p>jsoup 1.15.1 is out now with a bunch of <a href=""https://jsoup.org/news/release-1.15.1"">improvements and bug fixes</a>.</p>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/jhy/jsoup/blob/master/CHANGES"">jsoup's changelog</a>.</em></p>
<blockquote>
<p>jsoup changelog</p>
<p>*** Release 1.15.1 [2022-May-15]</p>
<ul>
<li>
<p>Change: removed previously deprecated methods and classes (including org.jsoup.safety.Whitelist; use
org.jsoup.safety.Safelist instead).</p>
</li>
<li>
<p>Improvement: when converting jsoup Documents to W3C Documents in W3CDom, preserve HTML valid attribute names if the
input document is using the HTML syntax. (Previously, would always coerce using the more restrictive XML syntax.)
<a href=""https://github.com/jhy/jsoup/pull/1648"">jhy/jsoup#1648</a></p>
</li>
<li>
<p>Improvement: added the :containsWholeText(text) selector, to match against non-normalized Element text. That can be
useful when elements can only be distinguished by e.g. specific case, or leading whitespace, etc.
<a href=""https://github.com/jhy/jsoup/issues/1636"">jhy/jsoup#1636</a></p>
</li>
<li>
<p>Improvement: added Element#wholeOwnText() to retrieve the original (non-normalized) ownText of an Element. Also
added the :containsWholeOwnText(text) selector, to match against that. BR elements are now treated as newlines
in the wholeText methods.
<a href=""https://github.com/jhy/jsoup/issues/1636"">jhy/jsoup#1636</a></p>
</li>
<li>
<p>Improvement: added the :matchesWholeText(regex) and :matchesWholeOwnText(regex) selectors, to match against whole
(non-normalized, case sensitive) element text and own text, respectively.
<a href=""https://github.com/jhy/jsoup/issues/1636"">jhy/jsoup#1636</a></p>
</li>
<li>
<p>Improvement: when evaluating an XPath query against a context element, the complete document is now visible to the
query, vs only the context element's sub-tree. This enables support for queries outside (parent or sibling) the
element, e.g. ancestor-or-self::*.
<a href=""https://github.com/jhy/jsoup/issues/1652"">jhy/jsoup#1652</a></p>
</li>
<li>
<p>Improvement: allow a maxPaddingWidth on the indent level in OutputSettings when pretty printing. This defaults to
30 to limit the indent level for very deeply nested elements, and may be disabled by setting to -1.
<a href=""https://github.com/jhy/jsoup/pull/1655"">jhy/jsoup#1655</a></p>
</li>
<li>
<p>Improvement: when cloning a Node or an Element, the clone gets a cloned OwnerDocument containing only that clone, so
as to preserve applicable settings, such as the Pretty Print settings.
<a href=""https://github.com/jhy/jsoup/issues/763"">jhy/jsoup#763</a></p>
</li>
<li>
<p>Improvement: added a convenience method Jsoup.parse(File).
<a href=""https://github.com/jhy/jsoup/issues/1693"">jhy/jsoup#1693</a></p>
</li>
<li>
<p>Improvement: in the NodeTraversor, added default implementations for NodeVisitor.tail() and NodeFilter.tail(), so
that code using only head() methods can be written as lambdas.</p>
</li>
<li>
<p>Improvement: in NodeTraversor, added support for removing nodes via Node.remove() during NodeVisitor.head().
<a href=""https://github.com/jhy/jsoup/issues/1699"">jhy/jsoup#1699</a></p>
</li>
<li>
<p>Improvement: added Node.forEachNode(Consumer<!-- raw HTML omitted -->) and Element.forEach(Consumer&lt;Element) methods, to efficiently
traverse the DOM with a functional interface.
<a href=""https://github.com/jhy/jsoup/issues/1700"">jhy/jsoup#1700</a></p>
</li>
<li>
<p>Bugfix: boolean attribute names should be case-insensitive, but were not when the parser was configured to preserve</p>
</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/jhy/jsoup/commit/3ffbeebc0959e2ada7ed1b4595338d2f09597e85""><code>3ffbeeb</code></a> [maven-release-plugin] prepare release jsoup-1.15.1</li>
<li><a href=""https://github.com/jhy/jsoup/commit/2b4a1dacf69b0e0fde3baeebbcf7ce1228da0342""><code>2b4a1da</code></a> Changelog for <a href=""https://github.com/jhy/jsoup/issues/1763"">#1763</a></li>
<li><a href=""https://github.com/jhy/jsoup/commit/eaf5028718840d71c9a7f94f538b65b135012702""><code>eaf5028</code></a> Fix/safelist deep copy constructor (<a href=""https://github.com/jhy/jsoup/issues/1763"">#1763</a>)</li>
<li><a href=""https://github.com/jhy/jsoup/commit/72612480cfc5a8b3c6ca31097cfd908121a638da""><code>7261248</code></a> Bump maven-bundle-plugin from 5.1.5 to 5.1.6 (<a href=""https://github.com/jhy/jsoup/issues/1768"">#1768</a>)</li>
<li><a href=""https://github.com/jhy/jsoup/commit/c76cad626cdd34aaa700336f1adbb28d36e90032""><code>c76cad6</code></a> Bump gson from 2.8.9 to 2.9.0 (<a href=""https://github.com/jhy/jsoup/issues/1769"">#1769</a>)</li>
<li><a href=""https://github.com/jhy/jsoup/commit/3cc012dbaa0c5af34f41ece6aed1ff622a03e65d""><code>3cc012d</code></a> Bump maven-surefire-plugin from 3.0.0-M5 to 3.0.0-M6 (<a href=""https://github.com/jhy/jsoup/issues/1770"">#1770</a>)</li>
<li><a href=""https://github.com/jhy/jsoup/commit/f881e81d83cc413fa90a1af6579072a316df6784""><code>f881e81</code></a> Bump maven-failsafe-plugin from 3.0.0-M5 to 3.0.0-M6 (<a href=""https://github.com/jhy/jsoup/issues/1771"">#1771</a>)</li>
<li><a href=""https://github.com/jhy/jsoup/commit/e6dc745d209391ae4cec8371b9b189b36f4b8987""><code>e6dc745</code></a> Bump maven-javadoc-plugin from 3.3.1 to 3.4.0 (<a href=""https://github.com/jhy/jsoup/issues/1772"">#1772</a>)</li>
<li><a href=""https://github.com/jhy/jsoup/commit/768b6cf31d2f7bb931312f9588c440bcd946eb15""><code>768b6cf</code></a> Bump maven-compiler-plugin from 3.8.1 to 3.10.1 (<a href=""https://github.com/jhy/jsoup/issues/1732"">#1732</a>)</li>
<li><a href=""https://github.com/jhy/jsoup/commit/cb9fea2a83f131dbfb1cef3f9433596b358888cb""><code>cb9fea2</code></a> Bump japicmp-maven-plugin from 0.15.4 to 0.15.7 (<a href=""https://github.com/jhy/jsoup/issues/1729"">#1729</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/jhy/jsoup/compare/jsoup-1.14.3...jsoup-1.15.1"">compare view</a></li>
</ul>
</details>
<br />


","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/968/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/968,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5DMmdv,incubator-stormcrawler,1127376751,968,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-05-16T08:23:55Z,2022-05-16T08:23:55Z,"thanks @rzo1 
did you check that the [Xsoup](https://github.com/code4craft/xsoup) based resources in https://github.com/DigitalPebble/storm-crawler/tree/master/core/src/main/java/com/digitalpebble/stormcrawler/jsoup still work after the update?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5DMmdv/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/968,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5DMp_R,incubator-stormcrawler,1127391185,968,NA,rzo1,13417392,Richard Zowalla,,NA,2022-05-16T08:38:04Z,2022-05-16T08:38:04Z,"@jnioche I did run `JSoupFiltersTest` after the upgrade, which didn't break. In addition, I conducted an upgrade of JSoup in [Xsoup](https://github.com/code4craft/xsoup/pull/54) locally and did run their unit tests (related PR is now merged), which didn't break either. It seems, they did not depend on any removed classes / methods (no compile or runtime issues on the Xsoup site).

Therefore, I am confident, that it does not break anything but might enable new XPath-based use-cases :)


","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5DMp_R/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/968,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5DMrAj,incubator-stormcrawler,1127395363,968,NA,rzo1,13417392,Richard Zowalla,,NA,2022-05-16T08:42:21Z,2022-05-16T08:42:21Z,"We might want to add an `exclusion` block for `jsoup` in the `xsoup` declaration to avoid pulling `1.13.x` (which is contained in the latest released Xsoup version) and omit the conflict warning with 1.14.3 or (now) 1.15.1). 

Wdyt?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5DMrAj/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/968,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5DM9QK,incubator-stormcrawler,1127470090,968,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-05-16T10:00:03Z,2022-05-16T10:00:03Z,"> We might want to add an `exclusion` block for `jsoup` in the `xsoup` declaration to avoid pulling `1.13.x` (which is contained in the latest released Xsoup version) and omit the conflict warning with 1.14.3 or (now) 1.15.1).
> 
> Wdyt?

Excellent idea!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5DM9QK/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/968,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5DNA4U,incubator-stormcrawler,1127484948,968,NA,rzo1,13417392,Richard Zowalla,,NA,2022-05-16T10:14:56Z,2022-05-16T10:14:56Z,Ok - will add the exclusion later.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5DNA4U/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/969,https://api.github.com/repos/apache/incubator-stormcrawler/issues/969,incubator-stormcrawler,1237163864,969,ES look at / measure the new random sampler aggregation,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-05-16T13:29:03Z,2024-03-14T08:30:42Z,https://www.elastic.co/blog/aggregate-data-faster-with-new-the-random-sampler-aggregation,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/969/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/969,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc53BXqJ,incubator-stormcrawler,1996847753,969,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-03-14T08:30:42Z,2024-03-14T08:30:42Z,This is a feature from Elastic 8.2 which is not under open source license. ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc53BXqJ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/970,https://api.github.com/repos/apache/incubator-stormcrawler/issues/970,incubator-stormcrawler,1240215182,970,HttpProtocol doesn't consider http.content.limit in test for filesize,wowasa,28445631,Wolfgang Walter SAUER,info@wowasa.com,CLOSED,2022-05-18T16:33:39Z,2022-06-14T05:05:23Z,"In line 327 of the class is a test »entity.getContentLength() <= Constants.MAX_ARRAY_SIZE« which should, in my view, consider the configured http.content.limit. 
We're getting an exception for very large files, although we have http.content.limit=0, since we just need some information from the http header. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/970/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/970,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5DYcKW,incubator-stormcrawler,1130480278,970,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-05-18T20:01:07Z,2022-05-18T20:01:07Z,"Thanks.  Good point! Do you want to submit  a PR for it?


On Wed, 18 May 2022, 17:33 Wolfgang Walter SAUER, ***@***.***>
wrote:

> In line 327 of the class is a test »entity.getContentLength() <=
> Constants.MAX_ARRAY_SIZE« which should, in my view, consider the configured
> http.content.limit.
> We're getting an exception for very large files, although we have
> http.content.limit=0, since we just need some information from the http
> header.
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/DigitalPebble/storm-crawler/issues/970>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AABVJT7QTJEQ7NLIJP3ZJYLVKULW7ANCNFSM5WJB67VQ>
> .
> You are receiving this because you are subscribed to this thread.Message
> ID: ***@***.***>
>
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5DYcKW/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/970,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Db_Uw,incubator-stormcrawler,1131410736,970,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-05-19T08:41:19Z,2022-05-19T08:41:19Z,@wowasa do you know you can specify _http.method.head=true_ in the config? This will result in a HEAD request and you will get only the HTTP headers you are after?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Db_Uw/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/970,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5DePsE,incubator-stormcrawler,1132002052,970,NA,wowasa,28445631,Wolfgang Walter SAUER,info@wowasa.com,NA,2022-05-19T17:39:43Z,2022-05-19T17:39:43Z,"@jnioche : thank you - this is what we're doing. We're permanently checking URLs for availability in our project with a HEAD request first and a GET request next only in case the HEAD request doesn't return a status 200 or 304, with little modifications of the FetcherBolt class, since we need to know the number of redirects. 
Unfortunately we have some URLs with a timeout in HEAD request, which is strange, and a content-length on GET request, which exceeds the limit. 
Question is now if the behavior of HttpProtocol class is qualified as a bug of storm crawler - then I'm waiting for a fix - or not. In this case I'm going to fix it for our project. 

p.s. - not to be misunderstood: I could also fork it and make a suggestion for a fix then, if it is qualified as a bug","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5DePsE/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/970,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5DgocN,incubator-stormcrawler,1132627725,970,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-05-20T08:28:18Z,2022-05-20T08:28:18Z,"thanks @wowasa, yes it is a bug. There is no point in worrying about something being too big when we know we are going to trim it anyway. A PR would be much appreciated.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5DgocN/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/970,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5DgrtA,incubator-stormcrawler,1132641088,970,NA,wowasa,28445631,Wolfgang Walter SAUER,info@wowasa.com,NA,2022-05-20T08:42:14Z,2022-05-20T08:42:14Z,fine. Will do so next week,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5DgrtA/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/970,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Eh8wG,incubator-stormcrawler,1149750278,970,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-06-08T10:38:05Z,2022-06-08T10:38:05Z,@wowasa I see that you have created a branch on your fork. Could you turn that into a Pull Request so that I can merge it into our code? Thanks!,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Eh8wG/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/970,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5EkDCF,incubator-stormcrawler,1150300293,970,NA,wowasa,28445631,Wolfgang Walter SAUER,info@wowasa.com,NA,2022-06-08T19:17:06Z,2022-06-08T19:17:06Z,sorry - I had just forgotten it,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5EkDCF/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/970,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5EmE05,incubator-stormcrawler,1150831929,970,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-06-09T08:32:19Z,2022-06-09T08:32:19Z,"merged, thanks a lot!
While we are here, I gather your work is related to [Clarin ERIC](https://www.clarin.eu/). Would you mind sharing how StormCrawler is used there? Could we mention Clarin on the [Powered-By](https://github.com/DigitalPebble/storm-crawler/wiki/Powered-By) page?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5EmE05/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/970,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5EusFe,incubator-stormcrawler,1153089886,970,NA,wowasa,28445631,Wolfgang Walter SAUER,info@wowasa.com,NA,2022-06-12T07:09:38Z,2022-06-12T07:09:38Z,"For the mention I have to ask my colleague first - I'll give you a feedback asp 

We're simply using the StormCrawler for link checking in our project. Means we're collecting XML files with metada on linguistic resources and we're checking permanently response-status, -time and the number of redirects of the included links. 
This is our link ckecking project https://github.com/clarin-eric/linkchecker where I only had to change the MetricsFetcherBolt of StormCrawler slightly to send a HEAD request first, a GET request next in case of failure and to count the number of redirects. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5EusFe/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/970,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Exisr,incubator-stormcrawler,1153837867,970,NA,wowasa,28445631,Wolfgang Walter SAUER,info@wowasa.com,NA,2022-06-13T12:11:59Z,2022-06-13T12:11:59Z,got green light. You can mention it on your page and we're grateful for your work invested in Strom Crawler anyway,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Exisr/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/970,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5E05Az,incubator-stormcrawler,1154715699,970,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-06-14T05:05:23Z,2022-06-14T05:05:23Z,"thanks and thanks @wowasa 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5E05Az/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/971,https://api.github.com/repos/apache/incubator-stormcrawler/issues/971,incubator-stormcrawler,1242859490,971,Use URLFrontier API 2.1 and support crawlIDs,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-05-20T09:12:38Z,2022-05-20T09:14:44Z,"URLFrontier 2.1 provides a finer acknowledgement for _PutURLs_ where we can distinguish between URLs that have been successful, ignored or failed. For the latter, they should be retried in Storm.

Also add support for a globally set _crawlID_. It could be done per URL later on based on the metadata and have more than one per crawl but this would require changes to the way the URLs are cached in AbstractStatusUpdaterBolt.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/971/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/971,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Dgy82,incubator-stormcrawler,1132670774,971,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-05-20T09:14:44Z,2022-05-20T09:14:44Z,Fixed in 57b86fef,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Dgy82/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/973,https://api.github.com/repos/apache/incubator-stormcrawler/issues/973,incubator-stormcrawler,1266395873,973,urlfrontier spout does not log the number of URLs obtained from a call to getURLs,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-06-09T16:37:23Z,2022-06-09T16:48:45Z,"`Got 0 URLs from the frontier
`
is all we get because the log is not done in the right place.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/973/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/975,https://api.github.com/repos/apache/incubator-stormcrawler/issues/975,incubator-stormcrawler,1275682791,975,Tika 2.4.1,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-06-18T06:40:00Z,2022-06-18T06:42:37Z,"see https://github.com/apache/tika/blob/2.4.1/CHANGES.txt

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/975/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/976,https://api.github.com/repos/apache/incubator-stormcrawler/issues/976,incubator-stormcrawler,1275683437,976,Use Java 11,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-06-18T06:43:46Z,2022-06-18T06:50:52Z,[Active support for Java 8 has ended](https://endoflife.date/java). The latest versions of some of the libraries or Maven plugins that StormCrawler relies on require Java 11.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/976/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/977,https://api.github.com/repos/apache/incubator-stormcrawler/issues/977,incubator-stormcrawler,1276528941,977,Dependency and maven plugin upgrades,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-06-20T08:03:12Z,2022-06-20T08:19:26Z,"<icu4j.version>71.1</icu4j.version>
<selenium.version>4.2.2</selenium.version>
<okhttp.version>4.10.0</okhttp.version>
<caffeine.version>3.1.1</caffeine.version>
<aws.version>1.12.243</aws.version>
<jwarc.version>0.18.1</jwarc.version>
<jackson.version>2.13.3</jackson.version>

**Maven plugins**

<artifactId>git-code-format-maven-plugin</artifactId> 3.4
<artifactId>maven-compiler-plugin</artifactId> 3.10.1
<artifactId>maven-archetype-plugin</artifactId> 3.2.1","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/977/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/978,https://api.github.com/repos/apache/incubator-stormcrawler/issues/978,incubator-stormcrawler,1278690527,978,Upgrade to SOLR 9.0.0,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-06-21T16:24:39Z,2022-10-04T08:52:00Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/978/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/979,https://api.github.com/repos/apache/incubator-stormcrawler/issues/979,incubator-stormcrawler,1285446392,979,Number of StatusUpdaterBolt instances can be a multiple of the frontier nodes,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-06-27T08:35:26Z,2022-06-27T08:36:18Z,"instead of having to be exactly the same number. This should improve the throughput as the service implementation will run the operations in separate threads.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/979/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/981,https://api.github.com/repos/apache/incubator-stormcrawler/issues/981,incubator-stormcrawler,1291274382,981,[URLFrontier] URLFrontier extension not returning ID preventing Status-ACK making crawling impossible,FelixEngl,15279363,Felix Engl,,CLOSED,2022-07-01T11:16:24Z,2022-07-06T08:10:45Z,"Hello @jnioche,

we switched our URL and Status handling from a custom bolt to URL-frontier. But I recognized, that the Status-Bold is not acking any tuple. After going into the code, adding some log-events and cleaning up the async-code and improving the state-management, my unit test shows the following log:

```
12:35:05.187 [Time-limited test] INFO  c.d.s.u.StatusUpdaterBolt - Initialisation of connection to URLFrontier service on localhost:53770
12:35:05.187 [Time-limited test] INFO  c.d.s.u.StatusUpdaterBolt - Allowing up to 100000 message in flight
12:35:05.194 [Time-limited test] ERROR c.d.s.u.PartitionUtil - Unknown partition mode : null - forcing to byHost
12:35:05.194 [Time-limited test] INFO  c.d.s.u.URLPartitioner - Using partition mode : QUEUE_MODE_HOST
12:35:05.263 [Time-limited test] TRACE c.d.s.u.StatusUpdaterBolt - Added to waitAck https://www.url.net/something with ID https://www.url.net/something total 1 - sent to localhost:53770
12:35:05.751 [grpc-default-executor-1] WARN  c.d.s.u.StatusUpdaterBolt - Could not find unacked tuple for blank id ``. (Ack: )
12:35:05.752 [grpc-default-executor-1] TRACE c.d.s.u.StatusUpdaterBolt - Trace for unpacked tuple for blank id: 
12:35:10.787 [Time-limited test] INFO  c.d.s.u.ChannelManager - Shutting down channel ManagedChannelOrphanWrapper{delegate=ManagedChannelImpl{logId=1, target=localhost:53770}}
```

It looks like URL-Frontier does not provide an ID when responding to a put, this is an error that can not be fixed on the SC side. Without the ID the Status won't be able to ACK a single tuple, making crawling basically impossible.

I added the used Unit-Tests ect. in this PR: https://github.com/DigitalPebble/storm-crawler/pull/980

Best Regards

Felix","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/981/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/981,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5F8qAu,incubator-stormcrawler,1173528622,981,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-07-04T08:40:12Z,2022-07-04T08:40:12Z,"thanks @FelixEngl 
I will look at #980 but if there is a problem with URLFrontier the issue should have been opened there.
Could you clarify which version of URLFrontier you are using, how you are starting it etc... ?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5F8qAu/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/981,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5F8trx,incubator-stormcrawler,1173543665,981,NA,FelixEngl,15279363,Felix Engl,,NA,2022-07-04T08:54:51Z,2022-07-04T08:54:51Z,"Ah sorry, I really should've opened it there. I'll open one there immediately and link to this issue. (tbh. I was so happy that I found that problem after 3 days of searching, that this totally slipped my mind. ^^') 

About my Configuration:
I'm starting version 2.1 in a compose file. Uploading the URLs and connecting to the Frontier are no problem.
In the Unit-Tests of the PR I'm just starting a docker container with default parameters. I also created a Frontier-Testcontainer. That should help us to write even more tests when this one works. (Maybe I should put that URL-Frontier-Testcontainer in a separate repository, commit it to the testcontainer-repository or make a PR at the URL-Frontier repository. What do you think would be the best approach?)","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5F8trx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/981,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5F8-HB,incubator-stormcrawler,1173610945,981,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-07-04T09:56:22Z,2022-07-04T09:56:22Z,"thanks @FelixEngl 
There already is a test suite in URLFrontier. If we have a test that can reproduce the issue, it should be added there. Having a test container in the URLFrontier module could also be useful for testing that the related components in StormCrawler behave as expected. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5F8-HB/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/981,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5F9QD_,incubator-stormcrawler,1173684479,981,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-07-04T11:05:44Z,2022-07-04T11:05:44Z,"I think the underlying issue has already been fixed in URLFrontier

https://github.com/crawler-commons/url-frontier/commit/ced0150d3a516ba8c8ad94b362fb8960ab2b35d6

I will release a new version of URLFrontier shortly.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5F9QD_/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/981,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5F9eq-,incubator-stormcrawler,1173744318,981,NA,FelixEngl,15279363,Felix Engl,,NA,2022-07-04T12:09:36Z,2022-07-04T12:09:36Z,"> thanks @FelixEngl There already is a test suite in URLFrontier. If we have a test that can reproduce the issue, it should be added there. Having a test container in the URLFrontier module could also be useful for testing that the related components in StormCrawler behave as expected.

Then I'll add some more tests after https://github.com/DigitalPebble/storm-crawler/pull/980 was ACKed. I already wrote aome ideas for useful tests down.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5F9eq-/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/981,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5GFxuL,incubator-stormcrawler,1175919499,981,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-07-06T08:10:45Z,2022-07-06T08:10:45Z,Will close this issue as the underlying problem has been fixed already,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5GFxuL/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/986,https://api.github.com/repos/apache/incubator-stormcrawler/issues/986,incubator-stormcrawler,1297187419,986,Fix starvation and busy waiting of ES StatusUpdaterBolt ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-07-07T10:47:04Z,2022-07-12T08:42:24Z,See related discussion in #983 ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/986/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/986,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5GRFRE,incubator-stormcrawler,1178883140,986,NA,FelixEngl,15279363,Felix Engl,,NA,2022-07-08T11:34:16Z,2022-07-08T11:34:16Z,"Fixed it: 
- `StatusUpdaterBold`: https://github.com/DigitalPebble/storm-crawler/pull/988
- `IndexerBold` https://github.com/DigitalPebble/storm-crawler/pull/989","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5GRFRE/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/986,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5GbBLN,incubator-stormcrawler,1181487821,986,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-07-12T08:42:24Z,2022-07-12T08:42:24Z,Thanks @FelixEngl ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5GbBLN/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/987,https://api.github.com/repos/apache/incubator-stormcrawler/issues/987,incubator-stormcrawler,1297836736,987,Update xsoup from 0.3.2 to 0.3.4,rzo1,13417392,Richard Zowalla,,CLOSED,2022-07-07T17:43:37Z,2022-07-07T17:49:22Z,"- Update xsoup to 0.3.4, see https://github.com/code4craft/xsoup/compare/xsoup-0.3.2...master","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/987/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/991,https://api.github.com/repos/apache/incubator-stormcrawler/issues/991,incubator-stormcrawler,1306267952,991,ConcurrentModificationException thrown by metrics in Fetcher executor,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-07-15T16:51:02Z,2023-08-08T15:41:25Z,"```
022-07-15 09:57:16.851 o.a.s.e.e.ReportError Thread-43-fetcher-executor[15, 15] [ERROR] Error
java.lang.RuntimeException: java.lang.RuntimeException: java.util.ConcurrentModificationException
	at org.apache.storm.utils.Utils$1.run(Utils.java:411) ~[storm-client-2.4.0.jar:2.4.0]
	at java.lang.Thread.run(Thread.java:829) [?:?]
Caused by: java.lang.RuntimeException: java.util.ConcurrentModificationException
	at org.apache.storm.executor.Executor.accept(Executor.java:301) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.utils.JCQueue.consumeImpl(JCQueue.java:113) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.utils.JCQueue.consume(JCQueue.java:89) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.executor.bolt.BoltExecutor$1.call(BoltExecutor.java:154) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.executor.bolt.BoltExecutor$1.call(BoltExecutor.java:140) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.utils.Utils$1.run(Utils.java:396) ~[storm-client-2.4.0.jar:2.4.0]
	... 1 more
Caused by: java.util.ConcurrentModificationException
	at java.util.HashMap$HashIterator.nextNode(HashMap.java:1511) ~[?:?]
	at java.util.HashMap$EntryIterator.next(HashMap.java:1544) ~[?:?]
	at java.util.HashMap$EntryIterator.next(HashMap.java:1542) ~[?:?]
	at org.apache.storm.metric.api.MultiCountMetric.getValueAndReset(MultiCountMetric.java:35) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.metric.api.MultiCountMetric.getValueAndReset(MultiCountMetric.java:18) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.executor.Executor.metricsTick(Executor.java:339) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.executor.bolt.BoltExecutor.tupleActionFn(BoltExecutor.java:200) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.executor.Executor.accept(Executor.java:297) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.utils.JCQueue.consumeImpl(JCQueue.java:113) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.utils.JCQueue.consume(JCQueue.java:89) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.executor.bolt.BoltExecutor$1.call(BoltExecutor.java:154) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.executor.bolt.BoltExecutor$1.call(BoltExecutor.java:140) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.utils.Utils$1.run(Utils.java:396) ~[storm-client-2.4.0.jar:2.4.0]
	... 1 more

```","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/991/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/991,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5jfPtP,incubator-stormcrawler,1669135183,991,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-08-08T08:15:51Z,2023-08-08T08:15:51Z,See https://issues.apache.org/jira/browse/STORM-3944,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5jfPtP/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/991,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5jiAsA,incubator-stormcrawler,1669860096,991,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-08-08T15:41:24Z,2023-08-08T15:41:24Z,Will be fixed by Storm 2.6,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5jiAsA/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/992,https://api.github.com/repos/apache/incubator-stormcrawler/issues/992,incubator-stormcrawler,1306747406,992,ES IndexerBold - Fix behaviour of afterBulk,FelixEngl,15279363,Felix Engl,,CLOSED,2022-07-16T08:32:06Z,2024-05-03T11:34:24Z,"Hi @jnioche,

I was looking into https://github.com/DigitalPebble/storm-crawler/pull/989#discussion_r918581042 and reviewed the old code in order to make sure, that I get the wanted behaviour. (see https://github.com/FelixEngl/storm-crawler/blob/834347e53f79376d3a79f125a6203c91d062e04f/external/elasticsearch/src/main/java/com/digitalpebble/stormcrawler/elasticsearch/bolt/IndexerBolt.java)

Now I am wondering, shouldn't it be enough to only process the first encounter of a BulkResponseElement with a specific id and otherwise just print the required LOG-events and update the counters accordingly?

Because the old code worked like this (if I got that right):

```plain
:START afterBulk

:ITERATION 1
+ waitAck ---------------+
| ""A"" | [tuple1, tuple3] |
| ""B"" | [tuple2]         |
+------------------------+

+ bulk_response ---------------+
| 1. (id: ""A"", state: SUCCESS) |
| 2. (id: ""B"", state: SUCCESS) |
| 3. (id: ""A"", state: FAILURE) |
+------------------------------+

respone = bulk_respose.removeFirst() : (id: ""A"", state: SUCCESS)
tuples = waitAck.getIfPresent(response.id) : [tuple1, tuple3]
for(tuple in tuples){
    // process all tuples as state: SUCCESS
    ...
}
waitAck.invalidate(response.id) // Immediate removal
:ITERATION 1

:ITERATION 2
+ waitAck -------+
| ""B"" | [tuple2] |
+----------------+

+ bulk_response ---------------+
| 2. (id: ""B"", state: SUCCESS) |
| 3. (id: ""A"", state: FAILURE) |
+------------------------------+

respone = bulk_respose.removeFirst() : (id: ""B"", state: SUCCESS)
tuples = waitAck.getIfPresent(response.id) : [tuple2]
for(tuple in tuples){
    // process all tuples as state: SUCCESS
    ...
}
waitAck.invalidate(response.id) // Immediate removal
:ITERATION 2

:ITERATION 3
+ waitAck -------+
+----------------+

+ bulk_response ---------------+
| 3. (id: ""A"", state: FAILURE) |
+------------------------------+

respone = bulk_respose.removeFirst() : (id: ""A"", state: FAILURE)
tuples = waitAck.getIfPresent(response.id) : null
LOG.warn(""could not find unacked tuple for A"")
:ITERATION 3

:STOP afterBulk
```

Best Regards

Felix","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/992/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/992,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5GvzNU,incubator-stormcrawler,1186935636,992,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-07-18T08:50:56Z,2022-07-18T08:50:56Z,"Hi @FelixEngl 
I have to admit that some of your recent changes have made the code slightly more complicated than it was. Are you trying to simplify the current code?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5GvzNU/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/992,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Gvz_J,incubator-stormcrawler,1186938825,992,NA,FelixEngl,15279363,Felix Engl,,NA,2022-07-18T08:54:23Z,2022-07-18T08:54:23Z,"> Hi @FelixEngl 
> I have to admit that some of your recent changes have made the code slightly more complicated than it was. Are you trying to simplify the current code?

Yes. To be honest right now i am not happy with the design i used in the ES part.

Its working fine, but looks too ""wild"" and may become problematic to support in the future.

So right now i am working on a redesign, but first i want to make sure, that I understood the ACK logic.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Gvz_J/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/992,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Gv3bX,incubator-stormcrawler,1186952919,992,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-07-18T09:08:54Z,2022-07-18T09:08:54Z,"> Its working fine, but looks too ""wild"" and may become problematic to support in the future.

That's also what I am worried about. 

> So right now i am working on a redesign, but first i want to make sure, that I understood the ACK logic.

Your step by step description above is correct although we just iterated on the bulk_response items without removing them. 

BTW could you please add some comments to _BulkItemResponseToFailedFlag_ so that readers can understand what it does?

 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Gv3bX/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/992,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Gv51h,incubator-stormcrawler,1186962785,992,NA,FelixEngl,15279363,Felix Engl,,NA,2022-07-18T09:18:25Z,2022-07-18T09:18:25Z,"> > Its working fine, but looks too ""wild"" and may become problematic to support in the future.
> 
> That's also what I am worried about.

Yes, that also came to me when I started to fix the bug. So I decided to da a ""big rewrite"" (Like Dylan Beattie described in his song ""Big Rewrite"": https://www.youtube.com/watch?v=xCGu5Z_vaps)

> > So right now i am working on a redesign, but first i want to make sure, that I understood the ACK logic.
> 
> Your step by step description above is correct although we just iterated on the bulk_response items without removing them.
> 
> BTW could you please add some comments to _BulkItemResponseToFailedFlag_ so that readers can understand what it does?

Yes, I only added this step to emphasize the iteration. (A queue is easier to visualize than an iterator. 😄)
And I'll look into that, maybe we won't need that flag _BulkItemResponseToFailedFlag_ anymore when I redesigne the code. (I hope to get rid of some of the confusing parts, and to remove or at least streamline the streaming part.)

(But at the moment I'm quite busy so I don't think I can manage this week. 😖)","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Gv51h/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/992,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Gyfua,incubator-stormcrawler,1187642266,992,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-07-18T15:27:43Z,2022-07-18T15:27:43Z,What about reverting to the previous version and simply add the lock logic?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Gyfua/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/992,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5G2qKZ,incubator-stormcrawler,1188733593,992,NA,FelixEngl,15279363,Felix Engl,,NA,2022-07-19T08:05:53Z,2022-07-19T08:05:53Z,"> What about reverting to the previous version and simply add the lock logic?

That wont do it, because the lock would span over too much logic. So I have to rewrite the whole thing anyway.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5G2qKZ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/992,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58vfac,incubator-stormcrawler,2092824220,992,NA,rzo1,13417392,Richard Zowalla,,NA,2024-05-03T11:34:23Z,2024-05-03T11:34:23Z,ES is gone.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58vfac/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/994,https://api.github.com/repos/apache/incubator-stormcrawler/issues/994,incubator-stormcrawler,1331467227,994,Delete redirected pages,jnioche,218319,Julien Nioche,julien@digitalpebble.com,OPEN,2022-08-08T07:43:52Z,2022-08-31T13:22:41Z,"From a user

`Links that were once pages and then turn to redirects are our issue. Our content management system auto creates clean URLs. If the title of the page is changed the clean URL is changed and the old URL is redirected to the new URL. The old URL stays in our index unless manually removed. When a link is changed from FETCHED to REDIRECT it would be ideal if the index is removed.`

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/994/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/994,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5IA5M6,incubator-stormcrawler,1208193850,994,NA,circuscowboy,1919698,Scott Jordison,,NA,2022-08-08T14:19:52Z,2022-08-08T14:19:52Z,With further though of the process it seems to make sense to replicate the  FETCH_ERROR process. It tries x times to get the URL and if it remains a redirect it becomes an ERROR which would trigger the deletion bolt. With the x times  variable you would be able to control whether the feature is used by setting it to 0 or -1 to always keep it active in the status like the current state.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5IA5M6/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/995,https://api.github.com/repos/apache/incubator-stormcrawler/issues/995,incubator-stormcrawler,1337118029,995,storm ui,abls1,33981716,,,CLOSED,2022-08-12T11:57:58Z,2022-08-30T06:23:40Z,"What kind of issue is this?

 WARNING: The path /ui could not be found. Will not import it. Welcome to the Storm compiler! Root directory: /usr/lib/storm Compiler boot in 51.74 ms Type 'licenses' to show licenses for all currently used module

Thanks!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/995/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/995,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5JB6PJ,incubator-stormcrawler,1225237449,995,NA,rzo1,13417392,Richard Zowalla,,NA,2022-08-24T06:03:20Z,2022-08-24T06:03:20Z,"I don't understand your question / report. Please add some more details (versions, os, etc.).","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5JB6PJ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/995,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5JYp8k,incubator-stormcrawler,1231200036,995,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-08-30T06:23:40Z,2022-08-30T06:23:40Z,"Closing. Not enough information and the question is about Apache Storm in general, not SC specifically","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5JYp8k/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/996,https://api.github.com/repos/apache/incubator-stormcrawler/issues/996,incubator-stormcrawler,1359994498,996,Blocking fetcher thread,Mikwiss,7784455,Mikwiss,mikwiss00@gmail.com,OPEN,2022-09-02T10:18:47Z,2023-01-10T14:16:39Z,"Hi @jnioche !

Thanks again for all your work ! Now, let me expose you our fetcher thread issue. 

## Resume
Our cluster have 6 worker nodes. We are fetching more than 3 million URLs per day with our topology. It is deployed on 16 worker slots and use 16 fetchers, one by worker slot.
## OkClient.HttpProtocol
The worst issue was spotted with the OkClient.HttpProtocol. Sometime, one of the worker nodes step up to 100% CPU usage. For example, the worker 5 in this case:

![image](https://user-images.githubusercontent.com/7784455/188117872-c09ada78-7bdc-45f5-8dcf-39d0e7d95061.png)

On StromCrawler board, we can see the fetcher count increase up to 50 (our fetcher limit) :

![image](https://user-images.githubusercontent.com/7784455/188117950-9820146d-81b4-40d1-a059-fcbf30294763.png)

Worst, in another case, all the topologies are impacted : 

![image](https://user-images.githubusercontent.com/7784455/188118026-67d43208-1884-4174-a020-04552c090028.png)

All fetchers are impacted, and the topology is running slowly. The only way to fix the problem, is to kill and redeploy the topology. On kill phase, the log confirms some blocking thread:

> 2022-05-30 06:37:06.557 O.A.S.D.W.WORKER SHUTDOWNHOOK-SHUTDOWNFUNC [INFO] SHUTTING DOWN EXECUTORS
...
> 2022-05-30 06:37:07.028 O.A.S.E.EXECUTORSHUTDOWN SHUTDOWNHOOK-SHUTDOWNFUNC [INFO] SHUTTING DOWN EXECUTOR FETCHER:[30, 30]
> 2022-05-30 06:37:07.077 C.D.S.B.FETCHERBOLT THREAD-21-FETCHER-EXECUTOR[30, 30] [ERROR] INTERRUPTED EXCEPTION CAUGHT IN EXECUTE METHOD
> 2022-05-30 06:37:07.077 C.D.S.B.FETCHERBOLT THREAD-21-FETCHER-EXECUTOR[30, 30] [ERROR] INTERRUPTED EXCEPTION CAUGHT IN EXECUTE METHOD
> 2022-05-30 06:37:07.077 C.D.S.B.FETCHERBOLT THREAD-21-FETCHER-EXECUTOR[30, 30] [ERROR] INTERRUPTED EXCEPTION CAUGHT IN EXECUTE METHOD
> 2022-05-30 06:37:07.077 C.D.S.B.FETCHERBOLT THREAD-21-FETCHER-EXECUTOR[30, 30] [ERROR] INTERRUPTED EXCEPTION CAUGHT IN EXECUTE METHOD

## HttpClient.HttpProtocol
We had tried to change the protocol to fix this issue. The CPU has never reach again 100%. But periodically, some fetcher threads are not released. 

![image](https://user-images.githubusercontent.com/7784455/188118614-718c2ebd-860c-4529-b674-31b349574487.png)


After some days, those “zombie” threads increase. We are often redeploying the topology (for functional update) and obviously, a new deployment reset thread count.

For now, the issue is less critical then the OkClient one, but we are trying to understand. Do you have any ideas or similar case?

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/996/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/996,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Jojug,incubator-stormcrawler,1235368864,996,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2022-09-02T11:08:52Z,2022-09-02T11:08:52Z,"Hi @Mikwiss, for the OKHttp protocol, see #918: OkHttp's internal connection pool implementation does not scale up to 1000 or more open connections. You might want to try to tune your pool configuration. Note: the issue with connection pooling was discovered on Nutch and then ported to Stormcrawler. The best pool configuration depends on how many hosts are crawled, the distribution of URLs over hosts and the configured partitioning. Could you share more information, including which Stormcrawler and Storm versions are used? Also the Storm UI provides insight which bolts in the topology are actually the bottleneck.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Jojug/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/996,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5JpRYg,incubator-stormcrawler,1235555872,996,NA,Mikwiss,7784455,Mikwiss,mikwiss00@gmail.com,NA,2022-09-02T14:12:45Z,2022-09-02T14:12:45Z,"Hi @sebastian-nagel ! Thanks for reply ! I will check #918 in order to understand.

Each crawler we have crawls only one host. We are currently in SC 2.2 and Storm 2.3.0. We have a task in our backlog to update SC to 2.5 and Storm to 2.4.0.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5JpRYg/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/996,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5JrLTf,incubator-stormcrawler,1236055263,996,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-09-03T05:51:45Z,2022-09-03T05:51:45Z,"Thanks @Mikwiss for reporting this issue and thanks @sebastian-nagel for your comment

> Each crawler we have crawls only one host

so the 16 fetchers all deal with the same host? Did you chose that over a single Fetcher so that the tuples get distributed evenly across the Parser tasks?

What value do you have in your conf for _fetcher.threads.per.queue_ ?



","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5JrLTf/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/996,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5SGK21,incubator-stormcrawler,1377349045,996,NA,Mikwiss,7784455,Mikwiss,mikwiss00@gmail.com,NA,2023-01-10T14:16:39Z,2023-01-10T14:16:39Z,"Hi !

Sorry for the delay. To reproduce the issue we have to wait a long time. 

So, this issue occurs on only once topology (with specific target/host and 50 _fetcher.threads.per.queue_). According to our conversation with @jnioche, we decrease the `http.content.limit` to 10 000 000 (instead of -1). 
We still have the same issue :
- okhttp : 100% CPU on one worker after a few moment
- httpclient : some thread zombie

But, it's seems less violent. So we'll decrease again this parameter. We keep in touch.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5SGK21/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/998,https://api.github.com/repos/apache/incubator-stormcrawler/issues/998,incubator-stormcrawler,1395811444,998,Dependency upgrades,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-10-04T07:46:41Z,2022-11-08T13:21:48Z,"[INFO]   com.amazonaws:aws-java-sdk-cloudsearch .......... 1.12.243 -> 1.12.315
[INFO]   com.amazonaws:aws-java-sdk-s3 ................... 1.12.243 -> 1.12.315
[INFO]   org.apache.tika:tika-core ............................. 2.4.1 -> 2.5.0
[INFO]   org.apache.tika:tika-parsers-standard-package ......... 2.4.1 -> 2.5.0
[INFO]   org.mockito:mockito-core .............................. 4.6.1 -> 4.8.0
[INFO]   org.netpreserve:jwarc ............................... 0.18.1 -> 0.19.0
[INFO]   org.seleniumhq.selenium:selenium-remote-driver ........ 4.2.2 -> 4.5.0
[INFO]   org.seleniumhq.selenium:selenium-support .............. 4.2.2 -> 4.5.0
[INFO]   org.testcontainers:elasticsearch .................... 1.17.3 -> 1.17.4
[INFO]   org.testcontainers:testcontainers ................... 1.17.3 -> 1.17.4

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/998/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/998,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5N6oTE,incubator-stormcrawler,1307215044,998,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-11-08T13:21:47Z,2022-11-08T13:21:47Z,"```
		<icu4j.version>72.1</icu4j.version>
		<jackson.version>2.14.0</jackson.version>
		<log4j2.version>2.19.0</log4j2.version>
		<selenium.version>4.6.0</selenium.version>
		<testcontainer.version>1.17.5</testcontainer.version>
		<tika.version>2.6.0</tika.version>
		<urlfrontier.version>2.3</urlfrontier.version>
		<xsoup.version>0.3.6</xsoup.version>
```","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5N6oTE/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/999,https://api.github.com/repos/apache/incubator-stormcrawler/issues/999,incubator-stormcrawler,1404729612,999,JSoupParserBolt improve performance of link extraction,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-10-11T14:19:31Z,2022-10-11T14:49:46Z,"We have relied until now on JSoup's 

`link.attr(""abs:href"");`

but  it is quite slow as it normalises the source URL and builds a new URL instance for it every time. Instead we can build the URL for it once and for all and normalise only the relative part of the URL.

 

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/999/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1008,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1008,incubator-stormcrawler,1461830482,1008,Use URLFrontier in archetype,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-11-23T14:08:11Z,2022-11-25T13:53:43Z,"The current archetype relies on the MemorySpout which is not persistent and does not allow interactions with the command line.
It would be better to use URLFrontier instead, with the README explaining how to run it etc... This would also be a good illustration of what URLFrontier does. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1008/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1013,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1013,incubator-stormcrawler,1493807812,1013,Usage of FastURLFilter via ES JSONURLFilterWrapper,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-12-13T09:26:55Z,2022-12-13T16:51:29Z,"### Discussed in https://github.com/DigitalPebble/storm-crawler/discussions/1012

<div type='discussions-op-text'>

<sup>Originally posted by **sebastian-nagel** December 12, 2022</sup>
The [FastURLFilter](https://javadoc.io/doc/com.digitalpebble.stormcrawler/storm-crawler-core/latest/com/digitalpebble/stormcrawler/filtering/regex/FastURLFilter.html) configuration file contains a JSON array, not a JSON object. How can it be put into ES?

When I try to put a FastURLFilter configuration file into ES (as described in [JSONURLFilterWrapper](https://javadoc.io/doc/com.digitalpebble.stormcrawler/storm-crawler-elasticsearch/latest/com/digitalpebble/stormcrawler/elasticsearch/filtering/JSONURLFilterWrapper.html), ES responds with an error ([indicating that ES expects a JSON object](https://stackoverflow.com/questions/62778983/compressor-detection-can-only-be-called-on-some-xcontent-bytes-or-compressed-xc)):
```
curl -XPUT 'localhost:9200/config/config/fast.urlfilter.json?pretty' -H 'Content-Type: application/json' -d @fast.urlfilter.json
{
  ""error"" : {
    ""root_cause"" : [
      {
        ""type"" : ""mapper_parsing_exception"",
        ""reason"" : ""failed to parse""
      }
    ],
    ""type"" : ""mapper_parsing_exception"",
    ""reason"" : ""failed to parse"",
    ""caused_by"" : {
      ""type"" : ""not_x_content_exception"",
      ""reason"" : ""Compressor detection can only be called on some xcontent bytes or compressed xcontent bytes""
    }
  },
  ""status"" : 400
}
```</div>","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1013/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1013,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5QZVL6,incubator-stormcrawler,1348817658,1013,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-12-13T15:33:38Z,2022-12-13T15:33:38Z,"@sebastian-nagel we could change the format so that it optionally consumes a simple object with a single field, the value of which is the array.
When using with the ES wrapper, you'd need to have the field but if used directly you wouldn't necessarily need to.
What do you think?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5QZVL6/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1013,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5QZpYQ,incubator-stormcrawler,1348900368,1013,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2022-12-13T16:07:20Z,2022-12-13T16:07:20Z,"> so that it optionally consumes a simple object with a single field, the value of which is the array

Yes, makes sense. Ev., could also require a predefined field ""config"" or ""content"" or similar. This special case needs to be documented anyway, so it's maybe clearer to require a specific field name.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5QZpYQ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1013,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5QaOHH,incubator-stormcrawler,1349050823,1013,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-12-13T16:51:29Z,2022-12-13T16:51:29Z,Fixed by allowing an optional top level field. Thanks @sebastian-nagel ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5QaOHH/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1014,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1014,incubator-stormcrawler,1494520305,1014,"[WARC] WARC response records missing WARC headers ""WARC-IP-Address"" and ""WARC-Truncated"" if protocolMDprefix is not empty",sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2022-12-13T15:39:56Z,2022-12-14T10:06:19Z,"If the protocol metadata prefix (configuration property `protocolMDprefix`) is not empty WARC response records are written without the WARC headers
- ""WARC-IP-Address"" (luckily the request records include the IP address)
- ""WARC-Truncated""
- and resource records are always stored as Content-Type `application/octet-stream`

(discovered while testing #1010, will add fix to this PR)","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1014/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1016,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1016,incubator-stormcrawler,1496283320,1016,Dependency upgrades,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-12-14T10:27:07Z,2022-12-14T10:27:40Z,"+		<aws.version>1.12.364</aws.version>
+		<caffeine.version>3.1.2</caffeine.version>
+		<httpclient.version>4.5.14</httpclient.version>
+		<jackson.version>2.14.1</jackson.version>
+		<jetbrains.annotations.version>23.1.0</jetbrains.annotations.version>
+		<jwarc.version>0.20.0</jwarc.version>
+		<mockito.version>4.9.0</mockito.version>
+		<opensearch.version>2.4.1</opensearch.version>
+		<selenium.version>4.7.2</selenium.version>
+		<urlfrontier.version>2.3.1</urlfrontier.version>
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1016/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1017,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1017,incubator-stormcrawler,1496344251,1017,Add an archetype for crawling with the OpenSearch module,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-12-14T10:55:39Z,2022-12-14T11:12:44Z,Similar to the one using Elasticsearch but should save users the trouble of having to rename parameters and components if copying the ES one.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1017/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1017,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5QhobF,incubator-stormcrawler,1350993605,1017,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-12-14T11:12:44Z,2022-12-14T11:12:44Z,"With the latest version of the main branch 

```
mvn clean install
cd /tmp
mvn archetype:generate -DarchetypeGroupId=com.digitalpebble.stormcrawler -DarchetypeArtifactId=storm-crawler-opensearch-archetype -DarchetypeVersion=2.7-SNAPSHOT
```

and follow the instructions in the README in the folder created by the archetype.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5QhobF/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1018,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1018,incubator-stormcrawler,1496358069,1018,Spouts should try to define the mapping for the status index if none exists,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-12-14T11:03:03Z,2022-12-14T11:04:06Z,"We currently create it only in the _statusupdaterbolt_, if the spouts gets instantiated before, they will report that the index is missing. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1018/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1020,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1020,incubator-stormcrawler,1498277918,1020,"Handle single quotes in value of http-equiv=""refresh"" ",jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-12-15T11:41:08Z,2022-12-15T11:43:27Z,"```
curl http://actes-sud.fr/front

<!DOCTYPE html>
<html>
    <head>
        <meta charset=""UTF-8"" />
        <meta http-equiv=""refresh"" content=""0;url='http://actes-sud.fr/'"" />
        <title>Redirecting to http://actes-sud.fr/</title>
    </head>
...
```
while the standard is not to use quotes, it is not uncommon to find single quotes being used in values, resulting in an incorrect URL for the redirection.

We can also remove the utility method in RefreshTag which uses XPath as in practice we operate directly on the JSoup document, as well as precompile the evaluator and hide the extraction logic within RefreshTag. This should make things a bit faster.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1020/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1021,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1021,incubator-stormcrawler,1498297253,1021,Exclude xml-apis from xerces dependency,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2022-12-15T11:56:27Z,2022-12-15T11:58:14Z,"We use Java 11 and it contains the classes from xml-apis; by using the latter we get module conflicts in Eclipse.
There is also no point in having that sub dependency so it would be cleaner to remove it.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1021/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1022,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1022,incubator-stormcrawler,1511674997,1022,If stormcrawler above 2.5 uses Jdk 11 why the archetypes pom are not updated to 11,msghasan,32441552,Maimur Hasan,,CLOSED,2022-12-27T10:39:04Z,2023-01-09T12:56:55Z,"The pom files in the archetype should be update to java 11 version rather than jdk 8
https://github.com/DigitalPebble/storm-crawler/blob/master/external/elasticsearch/archetype/src/main/resources/archetype-resources/pom.xml","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1022/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1022,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5RaRrv,incubator-stormcrawler,1365842671,1022,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2022-12-27T11:43:41Z,2022-12-27T11:43:41Z,"good catch, thanks @msghasan. Any chance you could submit a PR to fix it for the ES archetype but also the Opensearch and the core one?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5RaRrv/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1022,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Rav2R,incubator-stormcrawler,1365966225,1022,NA,msghasan,32441552,Maimur Hasan,,NA,2022-12-27T15:02:51Z,2022-12-27T15:02:51Z,"Sure will do raise a pr request

Maimur Hasan


On Tue, Dec 27, 2022, 17:13 Julien Nioche ***@***.***> wrote:

> good catch, thanks @msghasan <https://github.com/msghasan>. Any chance
> you could submit a PR to fix it for the ES archetype but also the
> Opensearch and the core one?
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/DigitalPebble/storm-crawler/issues/1022#issuecomment-1365842671>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AHXQJUEOVZIGY6BDIP52POLWPLI7PANCNFSM6AAAAAATKKCCNQ>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Rav2R/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1022,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5RkJ-u,incubator-stormcrawler,1368432558,1022,NA,msghasan,32441552,Maimur Hasan,,NA,2023-01-01T12:26:18Z,2023-01-01T12:26:18Z,"@jnioche  Hi I forked the repository to update the archtypes but there is a code the the core pom which is checking the existing code in what it is built i.e. java class version 52 and due to that check while I try to commit it is throwing me an error stating class version not supported... have you guys compiled the full project with java 11 once and deployed back to the repository.
[core pom file](https://github.com/DigitalPebble/storm-crawler/blob/master/pom.xml)
line no 120","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5RkJ-u/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1022,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5RlUsj,incubator-stormcrawler,1368738595,1022,NA,rzo1,13417392,Richard Zowalla,,NA,2023-01-02T08:31:36Z,2023-01-02T08:31:36Z,"@msghasan I just changed the three POM files, updated `1.8` to `11` and conducted a fuil build (`clean install`) with Java 11 locally -> worked fine. Maybe you need to conduct a full build after your changes.

I noticed, that the build doesn't work with Java 17, yet (due to some module issues with incompatible maven plugins). @jnioche If we want to be able to build with Java 17, I can have a look via a separate issue. In addition, we have a dependency with a `<repository>` using `http` only, which will fail with newer Maven version (http-blocker). Might be also a thing to investigate :)

```bash
Downloading from maven-default-http-blocker: http://0.0.0.0/net/minidev/json-smart/maven-metadata.xml
[WARNING] Could not transfer metadata net.minidev:json-smart/maven-metadata.xml from/to maven-default-http-blocker (http://0.0.0.0/): transfer failed for http://0.0.0.0/net/minidev/json-smart/maven-metadata.xml
[WARNING] The POM for io.confluent:kafka-avro-serializer:jar:1.0 is missing, no dependency information available
```","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5RlUsj/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1022,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5RldgL,incubator-stormcrawler,1368774667,1022,NA,msghasan,32441552,Maimur Hasan,,NA,2023-01-02T09:27:38Z,2023-01-02T09:27:38Z,"@rzo1 For me also the built went perfectly with java 11 when running build via terminal , but while committing from github desktop it throwing an error stating that the previous class version that the project was compile was with version 52 and the current version is 55

![image](https://user-images.githubusercontent.com/32441552/210213570-ccd9282b-b9e5-4711-ba1d-aa772db57571.png)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5RldgL/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1022,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5RlueD,incubator-stormcrawler,1368844163,1022,NA,rzo1,13417392,Richard Zowalla,,NA,2023-01-02T11:03:15Z,2023-01-02T11:03:15Z,Which version of Java is set as default on your system? It looks like the Maven build is triggered as pre-commit hook and uses an (too old) version?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5RlueD/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1022,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5RlvEq,incubator-stormcrawler,1368846634,1022,NA,msghasan,32441552,Maimur Hasan,,NA,2023-01-02T11:05:29Z,2023-01-02T11:05:29Z,I have java_home set is openjdk 11 and maven 3.8.5,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5RlvEq/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1022,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5RlvLU,incubator-stormcrawler,1368847060,1022,NA,msghasan,32441552,Maimur Hasan,,NA,2023-01-02T11:05:52Z,2023-01-02T11:05:52Z,"shall I reinstall github desktop and try again
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5RlvLU/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1022,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5RlvVy,incubator-stormcrawler,1368847730,1022,NA,rzo1,13417392,Richard Zowalla,,NA,2023-01-02T11:06:29Z,2023-01-02T11:06:29Z,Does a commit via IDE work?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5RlvVy/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1022,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Rl8n3,incubator-stormcrawler,1368902135,1022,NA,msghasan,32441552,Maimur Hasan,,NA,2023-01-02T12:20:29Z,2023-01-02T12:20:29Z,"No, it doesn't.

Maimur Hasan
Ph:-9962857984

On Mon, Jan 2, 2023, 16:36 Richard Zowalla ***@***.***> wrote:

> Does a commit via IDE work?
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/DigitalPebble/storm-crawler/issues/1022#issuecomment-1368847730>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AHXQJUAIOY4MGFIVPD7H5Z3WQKZEDANCNFSM6AAAAAATKKCCNQ>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Rl8n3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1022,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Rl9q6,incubator-stormcrawler,1368906426,1022,NA,rzo1,13417392,Richard Zowalla,,NA,2023-01-02T12:27:19Z,2023-01-02T12:27:19Z,"Interesting. I am able to commit that change to my fork: https://github.com/rzo1/storm-crawler/commit/ed50c7a9e486c83a6286e7f4d70eba174c77d1f8 - no idea why it fails on your machine, though. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Rl9q6/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1022,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Rl-Fg,incubator-stormcrawler,1368908128,1022,NA,msghasan,32441552,Maimur Hasan,,NA,2023-01-02T12:30:09Z,2023-01-02T12:30:09Z,Are you using eclipse or any other ide... I am using eclipse shall i try intellij,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Rl-Fg/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1022,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5RmAD7,incubator-stormcrawler,1368916219,1022,NA,rzo1,13417392,Richard Zowalla,,NA,2023-01-02T12:44:15Z,2023-01-02T12:44:15Z,"I am using IntelliJ IDEA Community Edition on a Ubuntu 20.04 LTS machine. Don't think IDE makes a difference as the build seems to fail because of an too old runtime set for the Maven build but sure, give it a try.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5RmAD7/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1022,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Rowxj,incubator-stormcrawler,1369640035,1022,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-01-03T11:05:34Z,2023-01-03T11:05:34Z,"> I noticed, that the build doesn't work with Java 17, yet (due to some module issues with incompatible maven plugins). @jnioche If we want to be able to build with Java 17, I can have a look via a separate issue. 

Yes please. Not sure we want to move to 17 in the short term but anticipating the issues wouldn't hurt.

> In addition, we have a dependency with a <repository> using http only, which will fail with newer Maven version (http-blocker). Might be also a thing to investigate :)

Good idea. I suspect this has to do with the WARC module and probably a dependency that we can safely blacklist.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Rowxj/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1022,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5R_Z7e,incubator-stormcrawler,1375575774,1022,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-01-09T12:47:34Z,2023-01-09T12:47:34Z,Implemented in #1029 ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5R_Z7e/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1023,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1023,incubator-stormcrawler,1518838922,1023,Add support for Selenium Grid,rzo1,13417392,Richard Zowalla,,CLOSED,2023-01-04T11:50:35Z,2024-10-30T06:25:57Z,"Mainly creating this issue as a possible future request for anyone, who has some time to contribute.

Selenium nowadays supports [Selenium Grid ](https://www.selenium.dev/documentation/grid/). Selenium Grid runs in parallel on multiple machines (called Nodes) coordinated by a Hub instance.

Details can be found here: https://www.selenium.dev/documentation/grid/components/

Our current Selenium Protocol impl cannot deal with the Hub setting as we are using a `LinkedBlockingQueue` to handle multiple Selenium drivers (instances).

We should perhaps add an additional `SeleniumGridProtocol`, which can make use of Selenium Grid so we can fully leverage the grids distributed capabilities (instead using only one session of a given Selenium Grid)

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1023/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1023,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Rtzg_,incubator-stormcrawler,1370961983,1023,NA,msghasan,32441552,Maimur Hasan,,NA,2023-01-04T13:58:35Z,2023-01-04T13:58:35Z,That's very much needed shall I try it on my weekend and try to give a upgrade,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Rtzg_/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1023,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5RvN98,incubator-stormcrawler,1371332476,1023,NA,rzo1,13417392,Richard Zowalla,,NA,2023-01-04T19:29:24Z,2023-01-04T19:29:24Z,"> That's very much needed shall I try it on my weekend and try to give a upgrade

Sure. If you have some spare resources / time to work on it, feel free. A PR would be very much appreciated. 

The grid deals with the queue / sessions ids, so we would need to build some logic to handle that on our side. I wouldn't change the current Selenium impl, though to avoid breaking users (not every body uses a Selenium grid). 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5RvN98/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1023,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5mtn7-,incubator-stormcrawler,1723236094,1023,NA,dhaneshsabane,7039056,Dhanesh Sabane,,NA,2023-09-18T11:40:45Z,2023-09-18T11:40:45Z,"Referencing the detailed discussion we've had on https://github.com/DigitalPebble/storm-crawler/discussions/1092, a separate implementation for Selenium Grid makes sense.

@rzo1 , @jnioche - Shall I pick this up and raise a PR?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5mtn7-/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1023,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5muAkX,incubator-stormcrawler,1723336983,1023,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-09-18T12:46:34Z,2023-09-18T12:46:34Z,"> @rzo1 , @jnioche - Shall I pick this up and raise a PR?

This would be great, thanks
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5muAkX/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1023,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5muTDg,incubator-stormcrawler,1723412704,1023,NA,dhaneshsabane,7039056,Dhanesh Sabane,,NA,2023-09-18T13:29:27Z,2023-09-18T13:29:27Z,@jnioche - Feel free to assign this issue to me.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5muTDg/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1023,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5m45VW,incubator-stormcrawler,1726190934,1023,NA,msghasan,32441552,Maimur Hasan,,NA,2023-09-19T17:29:07Z,2023-09-19T17:29:07Z,"I have the solution but being very busy nowadays,  I thought of pushing it long back and forgot to do it...","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5m45VW/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1023,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5m5Hb_,incubator-stormcrawler,1726248703,1023,NA,msghasan,32441552,Maimur Hasan,,NA,2023-09-19T18:10:08Z,2023-09-19T18:10:08Z,"I have pushed the solution to my fork. @jnioche @rzo1 Take a look if you feel the implementation is good to have let me know I will raise the PR. If not @dhaneshsabane  can take some inspiration and ideas to further enhance from this. I am extremely sorry to delay this so much. 

https://github.com/msghasan/storm-crawler/commit/4bfdba7ad737c19508ac5649eaf1174c7a31c9b8","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5m5Hb_/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1023,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5m5IIx,incubator-stormcrawler,1726251569,1023,NA,msghasan,32441552,Maimur Hasan,,NA,2023-09-19T18:12:13Z,2023-09-19T18:12:13Z,The changes produced  in my previous message was tested  in production environment and was getting used for our purpose. ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5m5IIx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1023,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5pho7j,incubator-stormcrawler,1770426083,1023,NA,dhaneshsabane,7039056,Dhanesh Sabane,,NA,2023-10-19T09:30:22Z,2023-10-19T09:30:22Z,"@msghasan - Thank you so much for sharing the implementation. I managed to deploy your changes to my server and get the setup working. However, I did have to make a couple of changes, primarily around how capabilities were set.

Do you want to raise this as a pull request @msghasan?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5pho7j/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1023,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5phy_5,incubator-stormcrawler,1770467321,1023,NA,rzo1,13417392,Richard Zowalla,,NA,2023-10-19T09:53:24Z,2023-10-19T09:53:24Z,"So perhaps open a PR and collaborate in getting the required changes into that PR? ;-) Afterwards, we can do a review, etc.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5phy_5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1023,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5pyaDl,incubator-stormcrawler,1774821605,1023,NA,msghasan,32441552,Maimur Hasan,,NA,2023-10-23T09:49:03Z,2023-10-23T09:49:03Z,"> @msghasan - Thank you so much for sharing the implementation. I managed to deploy your changes to my server and get the setup working. However, I did have to make a couple of changes, primarily around how capabilities were set.
> 
> Do you want to raise this as a pull request @msghasan?

ok let me provide the PR this weekend or I will take out some time after work to do it","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5pyaDl/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1023,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5sYqkB,incubator-stormcrawler,1818405121,1023,NA,msghasan,32441552,Maimur Hasan,,NA,2023-11-20T07:56:41Z,2023-11-20T07:56:41Z,"@rzo1  @jnioche  Please review the below PR and let me know your thoughts on this

https://github.com/DigitalPebble/storm-crawler/pull/1123","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5sYqkB/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1023,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5sdLMh,incubator-stormcrawler,1819587361,1023,NA,msghasan,32441552,Maimur Hasan,,NA,2023-11-20T18:23:44Z,2023-11-20T18:23:44Z,[# PR Explanation](https://github.com/DigitalPebble/storm-crawler/pull/1123#issuecomment-1819585834),"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5sdLMh/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1023,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6RypYI,incubator-stormcrawler,2445973000,1023,NA,rzo1,13417392,Richard Zowalla,,NA,2024-10-30T06:25:57Z,2024-10-30T06:25:57Z,"From my POV (and as original opener of this issue), we now have playwright available, which scales easily.  So I am going to close this.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6RypYI/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1024,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1024,incubator-stormcrawler,1518894238,1024,Add support for Playwright,rzo1,13417392,Richard Zowalla,,CLOSED,2023-01-04T12:29:33Z,2024-05-21T11:57:21Z,"Mainly creating this issue as a possible future request for anyone, who has some time to contribute.

It would be neat to have Playwright protocol impl for SC.

Note, that Playwright can also connect to [Selenium Grid ](https://playwright.dev/docs/selenium-grid), which would make it a cool addition. 

Related: https://github.com/DigitalPebble/storm-crawler/issues/1023","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1024/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1024,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5RvRd_,incubator-stormcrawler,1371346815,1024,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2023-01-04T19:45:55Z,2023-01-04T19:45:55Z,"Actually, some work is already done in #899/#902","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5RvRd_/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1024,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5RvR3Q,incubator-stormcrawler,1371348432,1024,NA,rzo1,13417392,Richard Zowalla,,NA,2023-01-04T19:47:44Z,2023-01-04T19:47:44Z,Yup - saw the PRs 😎 - thanks for referencing them. Might be a good starting point.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5RvR3Q/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1024,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56muNQ,incubator-stormcrawler,2056971088,1024,NA,sam-ulrich1,40002776,Sam Ulrich,,NA,2024-04-15T14:16:23Z,2024-04-15T14:16:23Z,"The existing work may be fully operational. The problem that stalled out the work was on playwrights side and since the API has not changed it is likely a simple upgrade would fix everything.

The crawler worked but playwright would crash after a couple thousand pages","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56muNQ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1025,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1025,incubator-stormcrawler,1519052782,1025,Need Code refactoring for better code reusability in StatusUpdaterBolt,msghasan,32441552,Maimur Hasan,,CLOSED,2023-01-04T14:14:35Z,2023-01-09T09:07:47Z,"Issue 1028 solves the problem because the docId will be picked form the cache

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1025/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1025,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Rt5Ay,incubator-stormcrawler,1370984498,1025,NA,msghasan,32441552,Maimur Hasan,,NA,2023-01-04T14:16:23Z,2023-01-04T14:16:23Z,I could not add the label as wish,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Rt5Ay/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1025,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5RxAYT,incubator-stormcrawler,1371801107,1025,NA,msghasan,32441552,Maimur Hasan,,NA,2023-01-05T05:34:45Z,2023-01-05T05:34:45Z,@jnioche  Can I provide the fix and raise a PR,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5RxAYT/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1025,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5RxcZv,incubator-stormcrawler,1371915887,1025,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-01-05T08:28:13Z,2023-01-05T08:28:13Z,"Sure, this will help us understand what you want to achieve. As far as the doc ID is concerned, I'd rather we had the option to take it from the metadata, a bit like what is suggested in #671 for the IndexerBolt. This would give you the flexibility to generate the Id any way you like.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5RxcZv/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1025,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5R7gya,incubator-stormcrawler,1374555290,1025,NA,msghasan,32441552,Maimur Hasan,,NA,2023-01-07T18:05:33Z,2023-01-07T18:05:33Z,81b85a159af6a7753d60b08d3dab1ff1cf7d0be4,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5R7gya/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1025,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5R7hFY,incubator-stormcrawler,1374556504,1025,NA,msghasan,32441552,Maimur Hasan,,NA,2023-01-07T18:07:48Z,2023-01-07T18:07:48Z,"@jnioche I thought I would be able to create a new PR but my new commits went into and existing pr I have mapped the particular commit here. 
Request you guys to verify my previous PR and also would be starting to work on Selenium Grid tomorrow. Please verify and approve the changes..
Regards","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5R7hFY/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1025,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5R8NkO,incubator-stormcrawler,1374738702,1025,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-01-08T07:21:37Z,2023-01-08T07:21:37Z,"@msghasan it is not clear from the dangling commit you mentioned what you are trying to achieve and because it is not in a PR it makes it difficult to comment on specific changes.
In any case we will be addressing the doc id issue in #1028 so there is no point doing it in here.
I am not going to approve a commit which makes drastic changes to a key class without proper discussion on what it does etc...
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5R8NkO/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1025,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5R8oUP,incubator-stormcrawler,1374848271,1025,NA,msghasan,32441552,Maimur Hasan,,NA,2023-01-08T14:22:16Z,2023-01-08T14:22:16Z,@jnioche  I only refactored the store method in parts so that anybody can reuse it as per their requirement when they extend the class StatusUpdaterBolt. I did not do any changes in the existing functionality.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5R8oUP/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1025,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5R8tP6,incubator-stormcrawler,1374868474,1025,NA,msghasan,32441552,Maimur Hasan,,NA,2023-01-08T15:58:29Z,2023-01-08T15:58:29Z,"> @msghasan it is not clear from the dangling commit you mentioned what you are trying to achieve and because it is not in a PR it makes it difficult to comment on specific changes. In any case we will be addressing the doc id issue in #1028 so there is no point doing it in here. I am not going to approve a commit which makes drastic changes to a key class without proper discussion on what it does etc...

I wanted to create a PR for that but as an existing PR was opened by me for the archtype changes it got committed to that one because it was open. I have corrected the mistake and reverted the commit.. Will  raise a new PR when the existing one gets approved..","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5R8tP6/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1025,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5R8twQ,incubator-stormcrawler,1374870544,1025,NA,rzo1,13417392,Richard Zowalla,,NA,2023-01-08T16:06:22Z,2023-01-08T16:06:22Z,"Doesn't https://github.com/DigitalPebble/storm-crawler/pull/1028 solve it? If so, cool. If not, it might need more explanatio as it needs some more discussion / reasoning for changing core classes.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5R8twQ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1025,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5R9td5,incubator-stormcrawler,1375131513,1025,NA,msghasan,32441552,Maimur Hasan,,NA,2023-01-09T05:46:22Z,2023-01-09T05:46:22Z,"@jnioche @rzo1  Please ignore my previous message. I got confused by the issue no #1028. I will be deleting it and try to rephrase it again. 
I can see you guys did not understood the problem correctly maybe I was not able to express correctly , so I will be re writing the description again for you guys to understand it. I will be deleting the previous comment I made.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5R9td5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1025,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5R94jI,incubator-stormcrawler,1375176904,1025,NA,msghasan,32441552,Maimur Hasan,,NA,2023-01-09T06:55:14Z,2023-01-09T06:55:14Z,Sorry for the comments lol I made a full of myself.. Understood where I was wrong.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5R94jI/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1027,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1027,incubator-stormcrawler,1519463480,1027,Ensure SC can be build with Java 17 and Maven 3.8.x,rzo1,13417392,Richard Zowalla,,CLOSED,2023-01-04T19:21:58Z,2023-02-03T09:15:58Z,"Building SC with Java 17 targeting Java 11 does not work due to incompatible Maven Plugins.

```bash
class com.google.googlejavaformat.java.JavaInput (in unnamed module @0x751a1a56) cannot access class com.sun.tools.javac.parser.Tokens$TokenKind (in module jdk.compiler) because module jdk.compiler does not export com.sun.tools.javac.parser to unnamed module @0x751a1a56
```

Investigate, if we can easily fix it to build with Java 17.

In addition, http blocker in Maven hits for a WARC module dependency.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1027/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1032,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1032,incubator-stormcrawler,1556942635,1032,RemoteDriverProtocol Throwing exception in catch and this will lead to misbehaviour of the crawler,msghasan,32441552,Maimur Hasan,,CLOSED,2023-01-25T16:31:21Z,2023-02-28T20:44:57Z,"# WHAT 
If i have a set of 5 remote phantomjs instances running and if one of them is not working properly this line of code will throw error and my crawler will misbehave and show exceptions in log.

# HOW
If we can just handle the exception and not throw it just print an error log so that the crawler do not mismehave.


https://github.com/DigitalPebble/storm-crawler/blob/36a58b5c1b43362a755b73317150a23ba0ad0ddc/core/src/main/java/com/digitalpebble/stormcrawler/protocol/selenium/RemoteDriverProtocol.java#L79","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1032/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1032,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Tune8,incubator-stormcrawler,1404729276,1032,NA,rzo1,13417392,Richard Zowalla,,NA,2023-01-26T09:15:36Z,2023-01-26T09:15:36Z,"If the instances are not ready, it is appropriate to throw an exception IMHO. However, I see two possibilities:

- (A) Move the `try-catch` inside the loop and log the exception. 
- (B) We can add a `protected` method `onException(Throwable t)`, which can be overriden by an implementor to deal with it as needed?

wdyt @jnioche ?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Tune8/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1032,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5TxaxA,incubator-stormcrawler,1405463616,1032,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-01-26T18:59:52Z,2023-01-26T18:59:52Z,"logging the exception is fine, as long as it is at error level","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5TxaxA/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1032,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5T3sVl,incubator-stormcrawler,1407108453,1032,NA,msghasan,32441552,Maimur Hasan,,NA,2023-01-27T21:46:46Z,2023-01-27T21:46:46Z,"@jnioche Can I refactor this class method in two parts the configure method is very big.. 
can we extract line no 40 t0 59 in a method called getDesiredCapabilities which will return DesiredCapabilities object in the configure().

and line 66 to 80 inside a protected method called setupRemoteDrivers() along with the changes mentioned by @rzo1 ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5T3sVl/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1032,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5T4x-r,incubator-stormcrawler,1407393707,1032,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-01-28T12:58:50Z,2023-01-28T12:58:50Z,"@msghasan I tend to put things in methods only if they are used in more than one place and I don't find  the _configure_ here is particularly long, but if you think this adds clarity to the code then why not. 
As for the changes mentioned by @rzo1 let's just go with (A), Thanks","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5T4x-r/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1032,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5WNa61,incubator-stormcrawler,1446358709,1032,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-02-27T13:52:03Z,2023-02-27T13:52:03Z,Closing because of lack of activity. Please feel free to reopen @msghasan ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5WNa61/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1033,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1033,incubator-stormcrawler,1570841638,1033,Dependency upgrades,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-02-04T08:53:33Z,2023-02-04T08:55:03Z,"Tika 2.7.0
OpenSearch 2.5.0
JWarc 0.21.0","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1033/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1035,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1035,incubator-stormcrawler,1576355086,1035,Improvements to URL Filtering,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-02-08T15:40:53Z,2023-02-08T16:44:38Z,"In particular, avoid creating URL instances when not necessary","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1035/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1037,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1037,incubator-stormcrawler,1577669520,1037,Limit number of outlinks while filtering them,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-02-09T10:57:32Z,2023-02-09T11:17:40Z,"The JSoupParser bolt currently finds all the unique outlinks for a page, filters / normalises them then trims if _parser.emitOutlinks.max.per.page_ is not set to -1

The filtering / normalisation can be a bit CPU intensive in some cases so instead we could check that enough URLs have passed the filtering and skip the rest.

The only difference when _parser.emitOutlinks.max.per.page_ is set is that the ParseResult object - which can be accessed by the JSoupfilters and ParseFilters would also have a subset of the outlinks and not the whole set. I doubt many filters manipulate the links and if they do then keeping _parser.emitOutlinks.max.per.page_ to the default value of -1 would prevent this.

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1037/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1038,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1038,incubator-stormcrawler,1580041166,1038,Limit the amount of text to be returned by the text extraction,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-02-10T17:04:28Z,2023-02-13T13:35:30Z,"The TextExtraction can generates very long text on dodgy inputs and takes forever to do so.

This page http://robgagnon.net/GagnonCompositeRankingTopColleges2016-17.htm for instance can take 7secs just to extract the text.
This happens when ARTICLE is set for include param name, not sure why, maybe it is because the corresponding tags are never closed.

As a safeguard, we can add a new configuration element to limit the amount of text to be returned by the text extraction. When set to _10000000_ for the document above, the processing time drops to 378 msec.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1038/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1042,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1042,incubator-stormcrawler,1591890485,1042,Adapting rules for parsing robots.txt file,michaeldinzinger,39766249,Michael Dinzinger,,CLOSED,2023-02-20T13:37:25Z,2023-05-23T07:16:48Z,"Hello all,
while crawling, we ran into a politeness issue and we suppose that its cause is that there was apparently a Connection Timeout when trying to fetch the `robots.txt`. We suppose that as a consequence the other webpages for this host were crawled without any restriction, just as if there would have been a 404 on the `robots.txt`.

As far as I see, is the logic on parsing the robots.txt file implemented as follows:
```
            if (code == 200) // found rules: parse them
            {
                String ct = response.getMetadata().getFirstValue(HttpHeaders.CONTENT_TYPE);
                robotRules = parseRules(url.toString(), response.getContent(), ct, agentNames);
            } else if ((code == 403) && (!allowForbidden)) {
                robotRules = FORBID_ALL_RULES; // use forbid all
            } else if (code >= 500) {
                cacheRule = false;
                robotRules = EMPTY_RULES;
            } else robotRules = EMPTY_RULES; // use default rules
```
In HttpRobotRulesParser.java; line 168-177

More suitable would be a logic as it is described here: https://support.google.com/webmasters/answer/9679690#robots_details
To differentiate between the cases:
- 403/404/410: For the crawling of this website is no robots.txt necessary
- 429/5xx: Connection Error results in no crawling of this website

Please tell me your thoughts on this","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1042/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1042,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Vp5BV,incubator-stormcrawler,1437044821,1042,NA,rzo1,13417392,Richard Zowalla,,NA,2023-02-20T13:41:56Z,2023-02-20T13:41:56Z,"Sounds valid to apply `FORBID_ALL_RULES`, if we encounter ""too many requests"" or a http 5xx. 

However, I can also think of usecases in which you still want to apply `EMPTY_RULES` in such a case (or just stop being polite at all) ;-)

Maybe we can adjust the default here and add a configuration option to just ignore it (similar to `http.robots.403.allow`) ?

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Vp5BV/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1042,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5VyIuK,incubator-stormcrawler,1439206282,1042,NA,michaeldinzinger,39766249,Michael Dinzinger,,NA,2023-02-21T23:04:10Z,2023-02-21T23:04:10Z,"> Maybe we can adjust the default here and add a configuration option to just ignore it (similar to `http.robots.403.allow`) ?

Thank you, sounds good:)
Maybe something like `http.robots.connectionerror.skip` or `http.robots.5xx.allow` which defaults to false.
The code could then look like this
```
            robotRules = FORBID_ALL_RULES; // use default rules
            if (code == 200) // found rules: parse them
            {
                String ct = response.getMetadata().getFirstValue(HttpHeaders.CONTENT_TYPE);
                robotRules = parseRules(url.toString(), response.getContent(), ct, agentNames);
            } else if (code == 403 && allowForbidden) {
                robotRules = EMPTY_RULES; // allow all
            } else if (code >= 500) {
                cacheRule = false;
                if (allow5xx) {
                    robotRules = EMPTY_RULES; // allow all
                }
            }
```","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5VyIuK/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1042,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5V7Byq,incubator-stormcrawler,1441537194,1042,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2023-02-23T10:41:37Z,2023-02-23T10:41:37Z,"Also the recently published [RFC 9309](https://datatracker.ietf.org/doc/rfc9309/) requires to treat a failure to fetch the robots.txt with HTTP status 500-599 as ""complete disallow"" (see section [""Unreachable"" Status](https://datatracker.ietf.org/doc/html/rfc9309#name-unreachable-status)). However, if the 5xx status of the robots.txt is observed over a longer period of time, crawlers may assume that there is none (ie. EMPTY_RULES).

Nutch handles 5xx failures and after few retries to fetch the robots.txt suspends crawling content from the given site. See [NUTCH-2573](https://issues.apache.org/jira/browse/NUTCH-2573) and apache/nutch#724. Since fetch queues are implemented similarly in Nutch and StormCrawler, this mechanism could be ported to StormCrawler. Eventually, it'd be better to not just drop the URLs/tuples but to update nextFetchDate (by adding 1 hour or 1 day) to avoid that the spout is releasing the same URLs again and again into the topology.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5V7Byq/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1042,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5V7KdG,incubator-stormcrawler,1441572678,1042,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-02-23T11:09:57Z,2023-02-23T11:09:57Z,"Thanks for this discussion people!

> Eventually, it'd be better to not just drop the URLs/tuples but to update nextFetchDate (by adding 1 hour or 1 day) to avoid that the spout is releasing the same URLs again and again into the topology.

This could be done for an entire host with the mechanism suggested in #867. I have started working on it for the OpenSearch backend in [branch 990](https://github.com/DigitalPebble/storm-crawler/compare/master...990) but still early days","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5V7KdG/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1042,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5V7ZyL,incubator-stormcrawler,1441635467,1042,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2023-02-23T11:57:03Z,2023-02-23T11:57:03Z,"> the mechanism suggested in #867

Nice!

Just as a note: when running the Common Crawl crawls, temporarily suspending fetching from sites with a robots.txt 5xx HTTP status saved a lot of work responding to complaints from webmasters (sent automatically as abuse reports to AWS). This was in combination with a general slow down (exponential backoff) on HTTP 5xx, 403 Forbidden and 429 Too many requests (see NUTCH-2946).","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5V7ZyL/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1042,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5WIfZm,incubator-stormcrawler,1445066342,1042,NA,michaeldinzinger,39766249,Michael Dinzinger,,NA,2023-02-25T12:02:27Z,2023-02-25T12:02:27Z,"> Also the recently published [RFC 9309](https://datatracker.ietf.org/doc/rfc9309/) requires to treat a failure to fetch the robots.txt with HTTP status 500-599 as ""complete disallow"" (see section [""Unreachable"" Status](https://datatracker.ietf.org/doc/html/rfc9309#name-unreachable-status)). However, if the 5xx status of the robots.txt is observed over a longer period of time, crawlers may assume that there is none (ie. EMPTY_RULES).

Thank you, very interesting:)
As far as I understand, a possible modification would be to adapt the current handling of HTTP 429 and 5xx and, concretely, set FORBID_ALL_RULES as a default instead of EMPTY_RULES. This is necessary to meet the recently published RFC9309 requirements.
A long-term solution is to also add the parameters and the underlying mechanism (#867) to retry to crawl the robots.txt a few times (for the case of HTTP 503 and maybe also 429), before just being satisfied with saying ""FORBID_ALL_RULES"". In either way, a host would only be temporarily suspended from crawling, because the SC will try to crawl the robots.txt again as soon as it's not in the error_cache anymore.
And as an add-on for the long-term solution, the RFC9309 would even allow to bypass the suspension of a host due to a 5xx error on the robots.txt after getting the same server error for e.g. 30 days. But I don't see how this is easily implementable. So maybe it's better to just settle for a short-term solution for now?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5WIfZm/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1043,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1043,incubator-stormcrawler,1600134943,1043,urlfrontier.StatusUpdaterBolt fails after reconnecting the URL Frontier to the SC,michaeldinzinger,39766249,Michael Dinzinger,,CLOSED,2023-02-26T17:29:06Z,2023-04-28T07:51:01Z,"Hello all,
the following issue popped up during some experimenting with the URL Frontier and a derivate of the SC: When the URL Frontier service is killed and restarted, the serving of new URLs to the StormCrawler via the urlfrontier.Spout continues to work nicely as if the Frontier service would never have been down.
However, the StatusUpdaterBolt seems to fail all tuples that it receives (after the restart, you can see no acks, but only fails for the StatusUpdaterBolt in the Storm UI). It seems that the cancelled connection between the Crawler and the frontier cannot be resumed after the restart of the URL Frontier.
As a consequence, after the Frontier service is restarted, also the SC topology has to be killed and resubmitted, which is not very convenient. Maybe a little code fix in the StatusUpdaterBolt would solve this issue.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1043/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1043,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5bBk-C,incubator-stormcrawler,1527140226,1043,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-04-28T07:51:00Z,2023-04-28T07:51:00Z,Fixed in #1054,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5bBk-C/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1044,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1044,incubator-stormcrawler,1600142959,1044,WARCHdfsBolt forwarding WARC file path to StatusUpdaterBolt,michaeldinzinger,39766249,Michael Dinzinger,,OPEN,2023-02-26T17:57:18Z,2023-09-22T14:32:57Z,"Hello all,
as far as I understood, the WARCHdfsBolt produces a continous stream of records in WARC format. The resulting WARC files are written into e.g. an S3-compliant storage with respect to some RotationPolicy and FilenameFormat. Regarding the Storm topology, the WARCHdfsBolt is a dead-end and is not emitting any tuples.
However, we are especially interested in the information, in which file (filename) a certain web page / WARC record is written, and we would like to forward this information to the index, e.g. an OpenSearch/Elasticsearch instance.
So that we know in the end: https://stormcrawler.net/faq/ --is_stored_in--> s3://path/to/file/WARC_file_0815.warc.gz
Is this reasonable and technically possible? Probably only when the WARCHdfsBolt emits the corresponding info to the StatusUpdaterBolt and is not a dead-end anymore.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1044/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1044,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5WJ-R5,incubator-stormcrawler,1445454969,1044,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2023-02-26T20:07:42Z,2023-02-26T20:07:42Z,"Hi @michaeldinzinger, this overlaps with #567 and recently I started to explore potential ways to implement a CDX indexer:

1. the first idea was to send the a tuple with the URL, metadata, WARC file name and WARC record offsets forward in the topology. This seems more elegant because it's on the user to define which bolt consumes the WARC record location. However, looks like it's challenging to implement because the method [execute(tuple) in AbstractHdfsBolt](https://github.com/apache/storm/blob/bf29d1cc9914d4fe596b5e65532322e3dfd3e4ff/external/storm-hdfs/src/main/java/org/apache/storm/hdfs/bolt/AbstractHdfsBolt.java#L129) is final. I haven't yet explored some ""dirty"" tricks, such as holding a reference to the collector in the writer. Seems like the HdfsBolt is designed to be dead-end (however, there is nothing about that in the [storm-hdfs docs](https://storm.apache.org/releases/2.3.0/storm-hdfs.html)).
2. the alternative would be to write the CDX file along with the WARC file. This is a viable use case of the HdfsBolt, cf. apache/storm#1044.

Given that there is a more general interest, I'd continue to explore variant 1 - but I cannot promise when and whether this will be successful. Any suggestions or help are welcome!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5WJ-R5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1044,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5WjmHl,incubator-stormcrawler,1452171749,1044,NA,michaeldinzinger,39766249,Michael Dinzinger,,NA,2023-03-02T16:36:29Z,2023-03-02T16:36:29Z,"Hello @sebastian-nagel, thank you for your answer!:) Personally, I would really appreciate this, because being aware of the WARC record location is an important (but not central) aspect on our use of the StormCrawler. Therefore, I would also be willed to investigate into this issue someday. What a pity, that the HdfsBolt is constructed as dead-end..","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5WjmHl/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1044,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Wn6eB,incubator-stormcrawler,1453303681,1044,NA,michaeldinzinger,39766249,Michael Dinzinger,,NA,2023-03-03T10:26:06Z,2023-03-03T10:26:06Z,"Another thing that came up on our end regarding this issue:
Besides the before mentioned information
https://stormcrawler.net/faq/ --is_stored_in--> s3://path/to/file/WARC_file_0815.warc.gz
especially the information
s3://path/to/file/WARC_file_0815.warc.gz --was_created_on--> Timestamp.now()
would be good to have.
This is also not possible because
(1) the WARCHdfsBolt is a dead-end, and
(2) information within the StormCrawler topology is only propagated URL-wise, so to say. (that's dangerous half-knowledge from my side)
Am I right with these?

Background of this question is that we want to trigger further processing of the WARC files when the WARC file is completely written. So I'm wondering whether the crawler can provide us with the info ""Now WARC file ready"".","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5Wn6eB/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1044,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5WptpK,incubator-stormcrawler,1453775434,1044,NA,sebastian-nagel,1630582,Sebastian Nagel,,NA,2023-03-03T16:21:04Z,2023-03-03T16:21:04Z,"Could just check the filesystem for new files from time to time. This seems reasonable since WARC files usually hold several 10,000 records and, consequently, aren't finished too often.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5WptpK/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1045,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1045,incubator-stormcrawler,1602700391,1045,Bug: while submitting topology via flux to Aapache Storm,msghasan,32441552,Maimur Hasan,,CLOSED,2023-02-28T09:49:00Z,2023-03-01T05:15:38Z,"(https://github.com/DigitalPebble/storm-crawler/blob/d9ca991c514e5010805c5519971686eded4ab306/core/pom.xml#L25)
![Screenshot from 2023-02-28 15-06-08](https://user-images.githubusercontent.com/32441552/221815055-d4cd8dc2-7e09-4d4c-8ab7-38fbefbaf49a.png)

Apache storm uses snakeyaml 1.26 version and we are using 1.32 causing no such method exception.
https://github.com/apache/storm/blob/a432e99bca526886655cc1d5b2453a09b302b5ca/pom.xml#L305

I have not checked but all of a sudden topology was not getting submitted. I think through testing should be done before accepting PR.

Fix that I have used is belwo in side of dependency management
```
<dependencyManagement>
		<dependencies>
			<dependency>
				<groupId>commons-io</groupId>
				<artifactId>commons-io</artifactId>
				<version>2.11.0</version>
			</dependency>
			<dependency>
                <groupId>org.yaml</groupId>
                <artifactId>snakeyaml</artifactId>
                <version>${snakeyaml.version}</version>// this i have provided as 1.26
            </dependency>
		</dependencies>
	</dependencyManagement>
```","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1045/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1045,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5WV7q3,incubator-stormcrawler,1448590007,1045,NA,msghasan,32441552,Maimur Hasan,,NA,2023-02-28T17:34:47Z,2023-02-28T17:34:47Z,@jnioche Mark this as bug please,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5WV7q3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1045,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5WWW94,incubator-stormcrawler,1448701816,1045,NA,rzo1,13417392,Richard Zowalla,,NA,2023-02-28T18:59:18Z,2023-02-28T18:59:18Z,"The issue originates from the fact, that SC uses Maven range syntax to specifiy the version, see https://github.com/DigitalPebble/storm-crawler/blob/master/core/pom.xml#L25

This brings in snakeyaml 2.0, which removed the related constructor: https://github.com/snakeyaml/snakeyaml/commit/3e755d254aeaa902675053047fd53368a175565a#diff-a68d4fc960a9e7c7007e23eb2289cd82545302b6fd45f07bbdaba542a55df361

Consequently, as the dependency is not stable (due to range syntax) it brings in `2.0` and breaks applications. It really doesn't matter, that SC uses 1.32 and Storm 1.26 ;-)","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5WWW94/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1045,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5WXGnL,incubator-stormcrawler,1448896971,1045,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-02-28T20:52:05Z,2023-02-28T20:52:05Z,"> I think through testing should be done before accepting PR.

thanks for reporting the issue but the comment above is rather unhelpful. PRs are tested and in this particular occurrence, it passed the tests fine at the time. If you have suggestions on how to improve the CI and test suite, your input will be appreciated
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5WXGnL/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1045,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5WY4fM,incubator-stormcrawler,1449363404,1045,NA,msghasan,32441552,Maimur Hasan,,NA,2023-03-01T05:15:13Z,2023-03-01T05:15:13Z,"@jnioche  Thanks for the quick fix all of a sudden without any code changes this error started happening.. 


> , which removed

thanks for the explanation.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5WY4fM/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1049,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1049,incubator-stormcrawler,1656245395,1049,"Solr cloud results ""Collapse/Expand"" bug",syefimov,6588163,,,CLOSED,2023-04-05T20:27:23Z,2023-05-02T10:00:40Z,"[ ] Bug report
storm-crawler-solr 2.8
Class: com.digitalpebble.stormcrawler.solr.persistence.SolrSpout
Method:  populateBuffer()
Solr: Solr 8,8.2 (cloud mode)

**Issue**: Collapse and Expand Results. In results same host exists multiple times (number of shards). Solrj in this case creates invalid expandedResults object and ClassCastException  (SolrDocumentList to SolrDocument) in line 161 docs.addAll(expandedResults.get(key)); 

**Solution**: Use grouping query to fix logic and ClassCastException  bug.

```
    protected void populateBuffer() {

        SolrQuery query = new SolrQuery();

        if (lastNextFetchDate == null) {
            lastNextFetchDate = Instant.now();
            lastStartOffset = 0;
            lastTimeResetToNOW = Instant.now();
        }
        // reset the value for next fetch date if the previous one is too
        // old
        else if (resetFetchDateAfterNSecs != -1) {
            Instant changeNeededOn =
                    Instant.ofEpochMilli(
                            lastTimeResetToNOW.toEpochMilli() + (resetFetchDateAfterNSecs * 1000));
            if (Instant.now().isAfter(changeNeededOn)) {
                LOG.info(
                        ""lastDate reset based on resetFetchDateAfterNSecs {}"",
                        resetFetchDateAfterNSecs);
                lastNextFetchDate = Instant.now();
                lastStartOffset = 0;
            }
        }

        query.setQuery(""*:*"")
                .addFilterQuery(""nextFetchDate:[* TO "" + lastNextFetchDate + ""]"")
                .setStart(lastStartOffset)
                .setRows(this.maxNumResults);

        if (StringUtils.isNotBlank(diversityField) && diversityBucketSize > 0) {
        	query.set(""indent"", ""true"").set(""group"", ""true"").set(""group.field"", diversityField)
			.set(""group.limit"", diversityBucketSize).set(""group.sort"", ""nextFetchDate asc"");
        }

        LOG.debug(""QUERY => {}"", query.toString());

        try {
            long startQuery = System.currentTimeMillis();
            QueryResponse response = connection.getClient().query(query);
            long endQuery = System.currentTimeMillis();

            queryTimes.addMeasurement(endQuery - startQuery);

            SolrDocumentList docs = new SolrDocumentList();

            LOG.debug(""Response : {}"", response.toString());

            // add the main results
			if (response.getResults() != null) {
				docs.addAll(response.getResults());
			}
			int groupsTotal = 0;
            // get groups
			if (response.getGroupResponse() != null) {
				for (GroupCommand groupCommand : response.getGroupResponse().getValues()) {
					for (Group group : groupCommand.getValues()) {
						groupsTotal++;
						LOG.debug(""Group : {}"", group);
						docs.addAll(group.getResult());
					}
				}
			}

            int numhits = (response.getResults()!=null)?response.getResults().size():groupsTotal;

            // no more results?
            if (numhits == 0) {
                lastStartOffset = 0;
                lastNextFetchDate = null;
            } else {
                lastStartOffset += numhits;
            }

            String prefix = mdPrefix.concat(""."");

            int alreadyProcessed = 0;
            int docReturned = 0;
            
            for (SolrDocument doc : docs) {
                String url = (String) doc.get(""url"");

                docReturned++;

                // is already being processed - skip it!
                if (beingProcessed.containsKey(url)) {
                    alreadyProcessed++;
                    continue;
                }

                Metadata metadata = new Metadata();

                Iterator<String> keyIterators = doc.getFieldNames().iterator();
                while (keyIterators.hasNext()) {
                    String key = keyIterators.next();

                    if (key.startsWith(prefix)) {
                        Collection<Object> values = doc.getFieldValues(key);

                        key = key.substring(prefix.length());
                        Iterator<Object> valueIterator = values.iterator();
                        while (valueIterator.hasNext()) {
                            String value = (String) valueIterator.next();
                            metadata.addValue(key, value);
                        }
                    }
                }

                buffer.add(url, metadata);
            }

            LOG.info(
                    ""SOLR returned {} results from {} buckets in {} msec including {} already being processed"",
                    docReturned,
                    numhits,
                    (endQuery - startQuery),
                    alreadyProcessed);

        } catch (Exception e) {
            LOG.error(""Exception while querying Solr"", e);
        }
    }
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1049/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1049,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5ZVslA,incubator-stormcrawler,1498859840,1049,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-04-06T10:39:39Z,2023-04-06T10:39:39Z,Could you please contribute a PR instead and link it to this issue? It will make it easier to see the difference in code and comment on your suggestions. Thanks!,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5ZVslA/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1050,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1050,incubator-stormcrawler,1656288778,1050,storm-crawler-solr bug. Missing DeletionBolt bolt code.,syefimov,6588163,,,CLOSED,2023-04-05T21:00:45Z,2023-05-19T16:56:00Z,"[ ] Bug
storm-crawler-solr 2.9-shapshot
com.digitalpebble.stormcrawler.solr.persistence.StatusUpdaterBolt

StatusUpdaterBolt extends AbstractStatusUpdaterBolt. AbstractStatusUpdaterBolt has a call
```
 if (status == Status.ERROR) {
            _collector.emit(Constants.DELETION_STREAM_NAME, new Values(url, metadata));
}
```
Solution: DeletionBolt.java is attached. Update defaulr crawler.flux

```
  - id: ""deleter""
    className: ""com.digitalpebble.stormcrawler.solr.bolt.DeletionBolt""
    parallelism: 1

..

  - from: ""status""
    to: ""deleter""
    grouping:
      type: LOCAL_OR_SHUFFLE
      streamId: ""deletion""
```
[DeletionBolt.txt](https://github.com/DigitalPebble/storm-crawler/files/11163091/DeletionBolt.txt)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1050/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1050,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5ZVsRQ,incubator-stormcrawler,1498858576,1050,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-04-06T10:38:31Z,2023-04-06T10:38:31Z,"thanks @syefimov 
this is not a bug but a suggested enhancement - you are kindly offering to add a missing component.
Could you please open a pull request for it? Please include license headers as in the other files. Thanks","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5ZVsRQ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1050,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5cIgF5,incubator-stormcrawler,1545732473,1050,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-05-12T13:17:18Z,2023-05-12T13:17:18Z,"hi @syefimov, thanks again for your recent contributions. 
Any chance you could open a new PR for adding the DeletionBolt for SOLR? This would be a good addition to the project.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5cIgF5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1050,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5cIgfG,incubator-stormcrawler,1545734086,1050,NA,syefimov,6588163,,,NA,2023-05-12T13:18:30Z,2023-05-12T13:18:30Z,"Hi,
Ye I will do that.

Thank you.
________________________________
From: Julien Nioche ***@***.***>
Sent: Friday, May 12, 2023 9:17 AM
To: DigitalPebble/storm-crawler ***@***.***>
Cc: Sergey Yefimov ***@***.***>; Mention ***@***.***>
Subject: Re: [DigitalPebble/storm-crawler] storm-crawler-solr bug. Missing DeletionBolt bolt code. (Issue #1050)


hi @syefimov<https://github.com/syefimov>, thanks again for your recent contributions.
Any chance you could open a new PR for adding the DeletionBolt for SOLR? This would be a good addition to the project.

—
Reply to this email directly, view it on GitHub<https://github.com/DigitalPebble/storm-crawler/issues/1050#issuecomment-1545732473>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABSIOA7F6XTDZQOZBQVEN43XFYZ6TANCNFSM6AAAAAAWUSGEBM>.
You are receiving this because you were mentioned.Message ID: ***@***.***>
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5cIgfG/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1051,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1051,incubator-stormcrawler,1656295437,1051,nextFetchDate field in SOLR schema should be optional,syefimov,6588163,,,CLOSED,2023-04-05T21:06:17Z,2023-05-02T12:52:47Z," - [ ] Bug report.

Solr ""status"" collection 

Remove ""required"" attribute from nextFetchDate field. nextFetchDate is null in case of ""ERROR"" status inside StatusUpdaterBolt

`<field name=""nextFetchDate"" type=""pdate"" stored=""true"" indexed=""true""/>`","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1051/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1051,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5bR7FZ,incubator-stormcrawler,1531425113,1051,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-05-02T12:52:46Z,2023-05-02T12:52:46Z,"Merged, thanks @syefimov ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5bR7FZ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1058,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1058,incubator-stormcrawler,1676370859,1058,Increasing the number of redirects for Robots.txt fetching,michaeldinzinger,39766249,Michael Dinzinger,,CLOSED,2023-04-20T09:42:23Z,2023-05-22T10:02:04Z,"Hello all, as suggested in PR #1055 this issue should address the following:
The [RFC 9309](https://datatracker.ietf.org/doc/pdf/rfc9309) concerning the Robots Exclusion Protocol states that a crawler should follow at least 5 redirects. This is the corresponding section:
```
2.3.1.2. Redirects
It's possible that a server responds to a robots.txt fetch request
with a redirect, such as HTTP 301 or HTTP 302 in the case of HTTP.
The crawlers SHOULD follow at least five consecutive redirects, even
across authorities (for example, hosts in the case of HTTP).
If a robots.txt file is reached within five consecutive redirects,
the robots.txt file MUST be fetched, parsed, and its rules followed
in the context of the initial authority.
If there are more than five consecutive redirects, crawlers MAY
assume that the robots.txt file is unavailable.
```
At the moment, the StormCrawler follows only one level of redirects. The corresponding implementation is in HttpRobotRulesParser.java, beginning from line 128.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1058/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1059,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1059,incubator-stormcrawler,1690849724,1059,"BasicURLNormalizer .unmangleQueryString() returns invalid results if ""&"" symbol in a parents path ",syefimov,6588163,,,CLOSED,2023-05-01T14:04:09Z,2023-05-08T14:53:46Z,"```
    private URLFilter createNormolizeFilter() {
        ObjectNode filterParams = new ObjectNode(JsonNodeFactory.instance);
        filterParams.put(""unmangleQueryString"", Boolean.valueOf(true));
        return createFilter(filterParams);
    }

    private void testNormolizeFilter()  throws MalformedURLException {
         URLFilter urlFilter = createNormolizeFilter();
         URL url = new URL(""http://eadiv.state.wy.us/s&utax/NEWSRLSE_fy18.pdf"");
         String filterResult = urlFilter.filter(url, metadata, url.toExternalForm());
         Assert.assertEquals(""http://eadiv.state.wy.us/s&utax/NEWSRLSE_fy18.pdf"", filterResult);
   }
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1059/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1059,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5bRFmg,incubator-stormcrawler,1531206048,1059,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-05-02T10:03:00Z,2023-05-02T10:03:00Z,"Ideally the & should have been URL encoded btu we should make the normalizers as robust as possible.
@syefimov thanks for reporting it, do you want to suggest a fix for it?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5bRFmg/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1059,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5bR8tZ,incubator-stormcrawler,1531431769,1059,NA,syefimov,6588163,,,NA,2023-05-02T12:57:59Z,2023-05-02T12:57:59Z,"Yes, analyze only string after last ""/"". If it is OK I can create pull request.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5bR8tZ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1059,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5bR87b,incubator-stormcrawler,1531432667,1059,NA,rzo1,13417392,Richard Zowalla,,NA,2023-05-02T12:58:36Z,2023-05-02T12:58:36Z,Go for it :),"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5bR87b/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1060,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1060,incubator-stormcrawler,1692220092,1060,Upgrade version of TestContainers,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-05-02T11:06:13Z,2023-05-02T12:03:45Z,"to 1.18.0
Use BOM to set the version to all the modules using it, see https://www.testcontainers.org/","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1060/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1061,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1061,incubator-stormcrawler,1693143983,1061,SolrSpout IndexOutOfBoundsException in parsing group query result.,syefimov,6588163,,,CLOSED,2023-05-02T21:49:36Z,2023-05-03T12:48:55Z,"ISSUE:
com.digitalpebble.stormcrawler.solr.persistence.SolrSpout 
In case of query results for group is empty the IndexOutOfBoundsException is generated.

SOLUTION: 
To fix validate the result before parsing.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1061/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1061,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5bU60A,incubator-stormcrawler,1532210432,1061,NA,syefimov,6588163,,,NA,2023-05-02T22:01:25Z,2023-05-02T22:01:25Z,"Sorry, please discharge this issue. It is not related to the current version of SolrSpout. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5bU60A/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1063,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1063,incubator-stormcrawler,1696222290,1063,Upgrade to OpenSearch 2.7.0,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-05-04T15:13:47Z,2023-05-11T15:48:46Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1063/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1065,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1065,incubator-stormcrawler,1697351242,1065,(Re)separate injection from crawl topologies in *Search archetypes,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-05-05T10:05:34Z,2023-05-05T10:34:58Z,"The injection relies on a file on the local FS and it typically triggered as a local Storm job whereas the crawl typically runs in distributed mode. When this is the case, the file is not present in the worker nodes and this can cause an error message. Instead, we should have a separate Flux file for the injection of seeds.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1065/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1065,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5bjmKn,incubator-stormcrawler,1536058023,1065,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-05-05T10:34:23Z,2023-05-05T10:34:23Z,basically undoing #778,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5bjmKn/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1066,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1066,incubator-stormcrawler,1703158879,1066,Dependency upgrades,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-05-10T05:35:14Z,2023-05-15T15:53:41Z,"
  com.amazonaws:aws-java-sdk-cloudsearch .......... 1.12.364 -> 1.12.466
   com.amazonaws:aws-java-sdk-s3 ................... 1.12.364 -> 1.12.466
   com.fasterxml.jackson.core:jackson-annotations ...... 2.14.1 -> 2.15.0
   com.fasterxml.jackson.core:jackson-core ............. 2.14.1 -> 2.15.0
   com.fasterxml.jackson.core:jackson-databind ......... 2.14.1 -> 2.15.0
   com.github.ben-manes.caffeine:caffeine ................ 3.1.2 -> 3.1.6
   com.ibm.icu:icu4j ....................................... 72.1 -> 73.1
   com.rometools:rome ................................... 1.18.0 -> 2.1.0
   com.squareup.okhttp3:okhttp ................. 4.10.0 -> 4.11.0
   com.squareup.okhttp3:okhttp-brotli .......... 4.10.0 -> 4.11.0
   org.apache.logging.log4j:log4j-api .................. 2.19.0 -> 2.20.0
   org.apache.logging.log4j:log4j-core ................. 2.19.0 -> 2.20.0
   org.apache.logging.log4j:log4j-slf4j-impl ........... 2.19.0 -> 2.20.0
   org.apache.solr:solr-solrj ............................ 9.1.0 -> 9.2.1
   org.jetbrains:annotations ........................... 23.1.0 -> 24.0.1
   org.jsoup:jsoup ..................................... 1.15.3 -> 1.16.1
   org.mockito:mockito-core .............................. 4.9.0 -> 5.3.1
   org.seleniumhq.selenium:selenium-remote-driver ........ 4.7.2 -> 4.9.1
   org.seleniumhq.selenium:selenium-support .............. 4.7.2 -> 4.9.1
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1066/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1066,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5cRnaT,incubator-stormcrawler,1548121747,1066,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-05-15T15:53:41Z,2023-05-15T15:53:41Z,Tika 2.8.0,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5cRnaT/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1068,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1068,incubator-stormcrawler,1705577744,1068,Automatic creation of index definitions should use the bolt type,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-05-11T11:00:17Z,2023-05-11T12:44:55Z,"For the name of the template to use, instead of the index name.
It should still check for the existence of the index based on its name.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1068/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1070,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1070,incubator-stormcrawler,1705839557,1070,Add mechanism to retrieve more generic value of configuration if a specific one is not found,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-05-11T13:29:49Z,2023-05-11T15:48:15Z,"For instance, the configuration of OpenSearch or ElasticSearch can be quite repetitive if all the components hit the same instances. 
What we could do would be to have
  _opensearch.addresses: ""http://localhost:9200""_
  and use that for the status bolt if no conf for  _opensearch.indexer.addresses_ can be found. 
  
  This requires a few more methods in ConfUtils.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1070/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1072,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1072,incubator-stormcrawler,1707759878,1072,Batch requests in DeleterBolt ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-05-12T14:45:13Z,2023-05-12T14:45:56Z,"Up to now they were sent one by one, instead we should use a similar mechanism as the one from the IndexerBolt.
Have seen the deletion be at 0.9 capacity on crawls","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1072/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1075,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1075,incubator-stormcrawler,1718577889,1075,Add test coverage reports with JaCoCo,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-05-21T17:24:23Z,2023-05-22T12:23:44Z,"and export to [Coveralls](https://coveralls.io/github/DigitalPebble/storm-crawler)

We know that the test coverage is far from perfect, especially for the bolts but knowing where it can be improved would be good.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1075/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1075,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5cwkq3,incubator-stormcrawler,1556236983,1075,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-05-21T17:40:41Z,2023-05-21T17:40:41Z,The github actions should also be configured -> https://github.com/marketplace/actions/coveralls-github-action,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5cwkq3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1075,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5cwlnk,incubator-stormcrawler,1556240868,1075,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-05-21T17:54:40Z,2023-05-21T17:54:40Z,"Note to self

`mvn clean test jacoco:report coveralls:report -DrepoToken=xxxxxxx
`

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5cwlnk/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1075,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5cwl8H,incubator-stormcrawler,1556242183,1075,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-05-21T17:59:45Z,2023-05-21T17:59:45Z,"> The github actions should also be configured -> https://github.com/marketplace/actions/coveralls-github-action

@rzo1 you are the expert, any chance you could have a look at it? ;-) The matrix makes things a bit more complicated
the repo token is already stored as a secret in github","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5cwl8H/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1075,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5cy3s_,incubator-stormcrawler,1556839231,1075,NA,rzo1,13417392,Richard Zowalla,,NA,2023-05-22T09:06:15Z,2023-05-22T09:06:15Z,"@jnioche I would leave the matix build as is and just add another workflow to compute coverage for master only.

Something like

```yaml
name: Code Coverage

on:
  pull_request:
  push:
    branches:
      - master
jobs:
  build:
    name: Coveralls
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v3
        with:
          persist-credentials: false
      - name: Set up JDK 11
        uses: actions/setup-java@v3
        with:
          distribution: adopt
          java-version: 11
      - name: Build & test with Maven and coverage
        run: mvn clean test jacoco:report
      - name: Post to Coveralls
        uses: coverallsapp/github-action@v2
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          format: jacoco
```

wdyt?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5cy3s_/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1075,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5cy_pS,incubator-stormcrawler,1556871762,1075,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-05-22T09:26:28Z,2023-05-22T09:26:28Z,"good idea. Any chance you could commit that?
BTW we should add code coverage to crawler-commons as well","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5cy_pS/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1075,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5czQx6,incubator-stormcrawler,1556941946,1075,NA,rzo1,13417392,Richard Zowalla,,NA,2023-05-22T10:11:13Z,2023-05-22T10:11:13Z,looks good ;-)  - https://coveralls.io/github/DigitalPebble/storm-crawler,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5czQx6/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1075,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5czRG8,incubator-stormcrawler,1556943292,1075,NA,rzo1,13417392,Richard Zowalla,,NA,2023-05-22T10:11:49Z,2023-05-22T10:11:49Z,We might be able to remove the `coveralls` maven plugin.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5czRG8/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1075,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5cz8Jx,incubator-stormcrawler,1557119601,1075,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-05-22T12:17:13Z,2023-05-22T12:17:13Z,"> We might be able to remove the `coveralls` maven plugin.

Do you mean that it is not needed for the GH workflow? We could still run in manually with Maven but would that happen a lot in practice? I don't mind either way
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5cz8Jx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1075,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5cz-U0,incubator-stormcrawler,1557128500,1075,NA,rzo1,13417392,Richard Zowalla,,NA,2023-05-22T12:23:44Z,2023-05-22T12:23:44Z,I don't think we need it for GH action 🙃,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5cz-U0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1076,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1076,incubator-stormcrawler,1719355551,1076,Fix flaky test in AdaptiveSchedulerTest.testSchedule,rzo1,13417392,Richard Zowalla,,CLOSED,2023-05-22T10:07:33Z,2023-12-06T15:00:30Z,"```bash
AdaptiveSchedulerTest.testSchedule:101 expected:<2023-05-22T10:05:20Z> but was:<2023-05-22T10:05:19Z>
```

Seems to be a flaky test. We should investigate.-","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1076/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1076,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5jl8xd,incubator-stormcrawler,1670892637,1076,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-08-09T08:26:48Z,2023-08-09T08:26:48Z,A simple case of 2 instants being rounded to 2 different seconds. Could change the tests so that we check that they are within one second of each other instead of being equal,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5jl8xd/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1077,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1077,incubator-stormcrawler,1724254248,1077,HttpRobotRulesParser.java is not correctly formatted,michaeldinzinger,39766249,Michael Dinzinger,,CLOSED,2023-05-24T15:24:18Z,2023-05-24T15:27:46Z,"Hello, after the merge of my latest PR, the validation of the code format fails.
It results a BUILD FAILURE for `mvn clean install` of the latest SC SNAPSHOT version.
```
[ERROR] Failed to execute goal com.cosium.code:git-code-format-maven-plugin:4.2:validate-code-format (validate-code-format) on project storm-crawler-core: /<...>/storm-crawler/core/src/main/java/com/digitalpebble/stormcrawler/protocol/HttpRobotRulesParser.java is not correctly formatted ! -> [Help 1]
```
I tried to hotfix the formatting error asap to not block anyone, but unfortunately even with the automatic code formatting of my IDE using the Google Java style I couldn't get rid of the formatting mistake. I'm very thankful for any help.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1077/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1077,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5dEKNI,incubator-stormcrawler,1561371464,1077,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-05-24T15:27:46Z,2023-05-24T15:27:46Z,"`mvn git-code-format:format-code -Dgcf.globPattern=**/*`

Have applied the commit in 91ae9778

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5dEKNI/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1079,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1079,incubator-stormcrawler,1771501808,1079,Test URL filtering on the command line,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-06-23T13:51:33Z,2023-06-29T07:29:28Z,"I thought we had that already but I can't see it anywhere. The obvious place would be [URLFilters](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/filtering/URLFilters.java) and be able to point at a urlfilters.json file or by default rely look for one in the jar. Then by calling 

```
storm local target/_INSERTJARNAMEHERE_.jar com.digitalpebble.stormcrawler.filtering.URLFilters urlToFilter
```

we would be able to check the output of the filtering pipeline
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1079/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1079,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5fn_S3,incubator-stormcrawler,1604318391,1079,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-06-23T13:53:26Z,2023-06-23T13:53:26Z,a verbose mode could even show the different stages of the filtering and how they affect the URL,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5fn_S3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1082,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1082,incubator-stormcrawler,1778927882,1082,xsoup 0.3.7,rzo1,13417392,Richard Zowalla,,CLOSED,2023-06-28T13:17:24Z,2023-06-28T13:18:36Z,Upgrade to xsoup 0.3.7 (removes unnecessary transient dep towards assertj,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1082/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1083,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1083,incubator-stormcrawler,1785684159,1083,KryoException: Buffer underflow error in Apache Storm and Storm-Crawler,ahadihamide,25050521,Hamide,ahadi.hamide@gmail.com,CLOSED,2023-07-03T08:55:46Z,2023-12-05T16:10:53Z,"Question
I have been encountering a recurring issue during the deployment of a new version of my topology in Storm-Crawler, and I am seeking assistance in understanding and resolving the problem.

Error: Upon deployment, I consistently encounter the following error:

Buffer underflow.
Serialization trace:
value (org.apache.storm.metric.api.IMetricsConsumer$DataPoint)

Stack Trace:
com.esotericsoftware.kryo.io.Input in require at line 199
com.esotericsoftware.kryo.io.Input in readVarInt at line 373
com.esotericsoftware.kryo.util.DefaultClassResolver in readClass at line 127
com.esotericsoftware.kryo.Kryo in readClass at line 670
com.esotericsoftware.kryo.Kryo in readClassAndObject at line 781
com.esotericsoftware.kryo.serializers.MapSerializer in read at line 153
com.esotericsoftware.kryo.serializers.MapSerializer in read at line 39
....
com.esotericsoftware.kryo.Kryo in readObject at line 689
org.apache.storm.serialization.KryoValuesDeserializer in deserializeFrom at line 31
org.apache.storm.serialization.KryoTupleDeserializer in deserialize at line 45
This error occurs between two nodes of the storm cluster, for example nodes 3 and 8. It seems that node 3 sends a tuple to node 8 and node 8 experiences Buffer underflow and starts to reset the worker.

Despite investing several hours in troubleshooting and conducting various tests, I have been unable to determine the root cause of this issue. It is worth mentioning that I have thoroughly tested the version on my local environment and confirmed its functionality without any problems.

I kindly request your insights, suggestions, or any guidance on how to effectively diagnose and resolve this persistent deployment error.

Thank you in advance for your assistance and support.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1083/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1083,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5gfJWH,incubator-stormcrawler,1618777479,1083,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-07-03T16:00:01Z,2023-07-03T16:00:01Z,Which version of Apache Storm and StormCrawler is this running on?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5gfJWH/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1083,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5gfS9m,incubator-stormcrawler,1618816870,1083,NA,ahadihamide,25050521,Hamide,ahadi.hamide@gmail.com,NA,2023-07-03T16:17:14Z,2023-07-03T16:17:14Z,stormcrawler.version > 2.6  and storm.version > 2.4.0,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5gfS9m/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1083,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5gikCs,incubator-stormcrawler,1619673260,1083,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-07-04T07:29:43Z,2023-07-04T07:29:43Z,"This is more about Apache Storm than StormCrawler itself.

_value (org.apache.storm.metric.api.IMetricsConsumer$DataPoint)_

would point to a problem with the Metrics, I found another one a while ago see #991.

Maybe try not using the metrics at all to see whether this makes a difference. Please report this issue to Apache Storm","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5gikCs/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1083,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5givoD,incubator-stormcrawler,1619720707,1083,NA,ahadihamide,25050521,Hamide,ahadi.hamide@gmail.com,NA,2023-07-04T07:51:09Z,2023-07-04T07:51:09Z,Thank you for your response and suggestion. I will do that shortly.  I noticed that you had previously encountered a similar issue [#991](https://github.com/DigitalPebble/storm-crawler/issues/991) and had posted it on Apache Storm . Thank you for linking my issue to it and for your continued support in resolving this matter.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5givoD/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1083,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5tvRxL,incubator-stormcrawler,1841110091,1083,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-12-05T16:10:53Z,2023-12-05T16:10:53Z,Closing for now but please do reopen if you have more info or a reproducible use case. Ideally this should be reported in Apache Storm. ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5tvRxL/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1084,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1084,incubator-stormcrawler,1791754852,1084,investigate the use of_warm_up_global_ordinals,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-07-06T15:11:18Z,2024-05-03T11:32:08Z,"according to https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-search-speed.html#_warm_up_global_ordinals
this can speed up aggregation queries. We could try using them on the field used for grouping the queues","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1084/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1084,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58vepu,incubator-stormcrawler,2092821102,1084,NA,rzo1,13417392,Richard Zowalla,,NA,2024-05-03T11:32:08Z,2024-05-03T11:32:08Z,We dropped ES as we joined the ASF incubator. Closing.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58vepu/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1085,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1085,incubator-stormcrawler,1809844740,1085,Upgrade CrawlerCommons 1.4,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-07-18T12:38:41Z,2023-07-18T12:54:44Z,https://github.com/crawler-commons/crawler-commons/releases/tag/crawler-commons-1.4,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1085/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1086,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1086,incubator-stormcrawler,1810050901,1086,Utilize new SimpleRobotRulesParser API entry point,sebastian-nagel,1630582,Sebastian Nagel,,CLOSED,2023-07-18T14:27:03Z,2023-12-06T14:40:10Z,"With crawler-commons 1.4 (#1085) the robots.txt parser (SimpleRobotRulesParser) provides a new [API entry point to parse the robots.txt content](https://crawler-commons.github.io/crawler-commons/1.4/crawlercommons/robots/SimpleRobotRulesParser.html#parseContent(java.lang.String,byte%5B%5D,java.lang.String,java.util.Collection)):
- it's more efficient by accepting a collection of lower-cased, single-word user-agent product tokens, without the need to tokenize a (comma-separated) list of user-agent strings again with every robots.txt
- user-agent matching is compliant with [RFC 9309 (section 2.2.1)](https://www.rfc-editor.org/rfc/rfc9309.html#name-the-user-agent-line) only if the new API method is used

Using the new API comes with some requirements how the user-agent product tokens are passed:
- as collection with multiple alternative user-agent names as separate entries
- always *lower-cased* because the matching is done on a lower-cased user-agent line
- product tokens should comply with [RFC 9309 (section 2.2.1)](https://www.rfc-editor.org/rfc/rfc9309.html#name-the-user-agent-line)
  - e.g., the default value [Anonymous Coward](https://github.com/DigitalPebble/storm-crawler/blob/f2d29fdb7b8636163d513b81dfa185f509c14649/core/src/main/resources/crawler-default.yaml#L68C38-L68C38) does not. It would be still matched, however
  - while trailing version numbers and additional information in the user-agent line are ignored - e.g., `mybot` would match `MyBot/5.0 (http://mybot.info/)` - it does not the other way around: that is, configuring `http.agent.name` as `Mozilla/5.0 (compatible: MyBot/5.0; http://mybot.info/)` would hardly work. Btw., using the old API method there are also unwanted side effects, see crawler-commons/crawler-commons#192.

In short, some extra checks and lower-casing is required, as well as more documentation (should also add the ""expert"" properties `http.robots.agents` and `http.agent`).","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1086/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1086,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5h1qEV,incubator-stormcrawler,1641455893,1086,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-07-19T05:49:08Z,2023-07-19T05:49:08Z,[RobotRulesParser](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/protocol/RobotRulesParser.java) is where things happen,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5h1qEV/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1086,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5t2kAE,incubator-stormcrawler,1843019780,1086,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-12-06T14:40:08Z,2023-12-06T14:40:08Z,"Improved the documentation
Enforce checks of user agent tokens + lowercase them
`http.robots.agents` can be  either a list or a string containing comma separated values","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5t2kAE/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1087,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1087,incubator-stormcrawler,1825958171,1087,No Such method error due to jar conflict withing storm crawler 2.7,msghasan,32441552,Maimur Hasan,,CLOSED,2023-07-28T08:27:29Z,2023-09-18T12:46:54Z,"This issue is appearing when we are running in local mode trying to fetch the selenium driver object.

If I investigate the dependency tree I can see remote driver is using io.netty jars of 4.184.Final and in aysynch-http-client 2.12.3 they are using io.netty 4.1.60.

![Error Screen](https://github.com/DigitalPebble/storm-crawler/assets/32441552/583b6403-1204-4f24-865a-e986e7bd3b1f)

![Dependency tree](https://github.com/DigitalPebble/storm-crawler/assets/32441552/a3ad5a35-15e0-48db-8b15-61e798c5e6e5)

Even if i try to exclude the 4.1.6.0 io.netty jars the prolem is not resolved.

Can you guys provide some information on this so that I can fix this and produce a PR




","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1087/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1087,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5iqZTI,incubator-stormcrawler,1655280840,1087,NA,rzo1,13417392,Richard Zowalla,,NA,2023-07-28T08:37:31Z,2023-07-28T08:37:31Z,Looks like a classpath issue. Best way would be to urge the selenium guys to fix up their dependency tree.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5iqZTI/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1087,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5iquYm,incubator-stormcrawler,1655367206,1087,NA,msghasan,32441552,Maimur Hasan,,NA,2023-07-28T09:26:49Z,2023-07-28T09:26:49Z,Let me raise an issue with selenium and thanks ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5iquYm/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1087,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5iqv2N,incubator-stormcrawler,1655373197,1087,NA,msghasan,32441552,Maimur Hasan,,NA,2023-07-28T09:31:12Z,2023-07-28T09:31:12Z,"But One more thing I would like to add is, when I create a sample class within the storm crawler project. and run it via main method, the object is getting created and we are able to visit the url. It's only failing while running in storm crawler","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5iqv2N/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1087,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5iqwuj,incubator-stormcrawler,1655376803,1087,NA,rzo1,13417392,Richard Zowalla,,NA,2023-07-28T09:32:59Z,2023-07-28T09:32:59Z,"The JAR run by Storm is a ""shade"", ie everything is packed into a single jar. If you have overlapping transient dependencies, it is a problem. There should also be warnings regarding that in the output. Best way to fix would be to resolve the transient dependency issue in selenium, I guess.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5iqwuj/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1087,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5irwJE,incubator-stormcrawler,1655636548,1087,NA,msghasan,32441552,Maimur Hasan,,NA,2023-07-28T12:51:26Z,2023-07-28T12:51:26Z,shall I update the dependency of selenium to higher version in the pom.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5irwJE/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1087,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5irwbh,incubator-stormcrawler,1655637729,1087,NA,rzo1,13417392,Richard Zowalla,,NA,2023-07-28T12:52:27Z,2023-07-28T12:52:27Z,"If there were related changes, that would be an option, yes.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5irwbh/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1087,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5irx6j,incubator-stormcrawler,1655643811,1087,NA,msghasan,32441552,Maimur Hasan,,NA,2023-07-28T12:57:26Z,2023-07-28T12:57:26Z,"I just checked in maven the dependencies of selenium-remote-driver, even in the latest version 4.1.0 they are using the same jar aysynch-http-client 2.12.3 which uses io.netty 4.1.6.0.

Dont know it will work or not let me try","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5irx6j/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1087,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5ir5RR,incubator-stormcrawler,1655673937,1087,NA,msghasan,32441552,Maimur Hasan,,NA,2023-07-28T13:19:54Z,2023-07-28T13:19:54Z,"
> If there were related changes, that would be an option, yes.

No it did not resolve the problem. I think storm-client2.4.0 also uses io.netty 4.1.84.Final

Don't know how to resolve this problem
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5ir5RR/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1087,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5mtmSm,incubator-stormcrawler,1723229350,1087,NA,dhaneshsabane,7039056,Dhanesh Sabane,,NA,2023-09-18T11:35:41Z,2023-09-18T11:35:41Z,"@msghasan - This should solve your problem - https://github.com/DigitalPebble/storm-crawler/discussions/1092#discussioncomment-7017067

Thanks to @rzo1 ❤️ ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5mtmSm/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1089,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1089,incubator-stormcrawler,1842031831,1089,Apache Storm 2.5.0,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-08-08T20:18:42Z,2023-08-09T08:10:10Z,https://storm.apache.org/2023/08/04/storm250-released.html,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1089/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1090,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1090,incubator-stormcrawler,1871244766,1090,Tika 2.9.0,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-08-29T09:22:11Z,2023-08-29T09:31:39Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1090/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1090,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5lJ1md,incubator-stormcrawler,1697077661,1090,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-08-29T09:22:54Z,2023-08-29T09:22:54Z,https://www.apache.org/dist/tika/2.9.0/CHANGES-2.9.0.txt,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5lJ1md/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1094,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1094,incubator-stormcrawler,1900957615,1094,Dependency upgrades,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-09-18T13:34:23Z,2023-09-18T13:54:28Z,"JWARC 0.28.2
OpenSearch 2.9.0
SOLR 9.3.0","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1094/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1094,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5muggt,incubator-stormcrawler,1723467821,1094,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-09-18T13:54:28Z,2023-09-18T13:54:28Z,"Also upgraded plugin dependencies, including the ones in the archetypes","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5muggt/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1095,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1095,incubator-stormcrawler,1909016546,1095,SQL StatusUpdaterBolt bugs,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-09-22T14:27:33Z,2023-09-22T14:28:34Z,"1. the values of a preparedstatement must be filled. We currently skip the nextFetchDate if not present, instead let's put a time in a distant future
2. tuples are not acked correctly
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1095/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1096,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1096,incubator-stormcrawler,1915085050,1096,Archetypes: sitemap filtering used even though the sitemap detection is not on,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-09-27T09:28:44Z,2023-09-27T10:03:49Z,"See https://github.com/DigitalPebble/storm-crawler/blob/master/archetype/src/main/resources/archetype-resources/src/main/resources/urlfilters.json#L56

If the root page of a site is redirected and that site is known to have sitemaps, the redirection will be filtered out if the sitemap processing is not turned on. 

Either we remove the filter from the config for the archetypes or we activate the sitemap processing by default.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1096/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1097,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1097,incubator-stormcrawler,1917285315,1097,Make all protocol implementations testable on the command line,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-09-28T11:19:23Z,2023-09-28T11:20:39Z,"All the implementations extending AbstractHTTPProtocol can be easily tested on the command line as explained [in this discussion](https://github.com/DigitalPebble/storm-crawler/discussions/1092#discussioncomment-7015128)

```
storm local target/opencrawl-1.0-SNAPSHOT.jar com.digitalpebble.stormcrawler.protocol.selenium.RemoteDriverProtocol -f crawler-conf.yaml https://storm.apache.org/
```

There is no reason why the same functionality couldn't be extended to other protocol implementations such as [FileProtocol](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/protocol/file/FileProtocol.java) or the [DelegatorProtocol](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/protocol/DelegatorProtocol.java). This can be done by simply moving the logic from AbstractHTTPProtocol to the Protocol interface.

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1097/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1098,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1098,incubator-stormcrawler,1917412435,1098,Add OR operator for filter logic in DelegatorProtocol,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-09-28T12:22:43Z,2023-09-28T12:51:15Z,"The DelegatorProtocol can route the URLs to various protocol implementations based on metadata. This is particularly helpful when using with the SeleniumProtocol e.g. to make sure sitemaps are processed by another implementation (e.g. OKHTTP) to avoid rendering, which makes them unparsable. 

For the record, this is done like this

```
  # use the normal protocol for sitemaps
  protocol.delegator.config:
   - className: ""com.digitalpebble.stormcrawler.protocol.okhttp.HttpProtocol""
     filters:
       isSitemap: ""true""
   - className: ""com.digitalpebble.stormcrawler.protocol.selenium.RemoteDriverProtocol""
```
More than one filter can be defined but with the current version (<2.9), all filters **must** match in order for an implementation to be selected. 

We will add the possibility to define an OR operator, so that only one condition is required for a match. 

Now

```
  # use the normal protocol for sitemaps
  protocol.delegator.config:
   - className: ""com.digitalpebble.stormcrawler.protocol.okhttp.HttpProtocol""
     filters:
       isSitemap: ""true""
       noSelenium:
       robots.txt:
   - className: ""com.digitalpebble.stormcrawler.protocol.selenium.RemoteDriverProtocol""
```

The _okhttp_ implementation will be selected if any of the three conditions match, i.e. the URL has a key value _isSitemap: ""true""_ in its metadata, **OR** it has a key _noSelenium_ (regardless of value) **OR** it has a key _robots.txt_ (regardless of value).

The latter will be added as part of the commit to allow filtering rules to handle robots.txt (for which using Selenium is an overkill).


 



 ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1098/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1099,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1099,incubator-stormcrawler,1917485728,1099,Remove deprecated class DelegatorRemoteDriverProtocol,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-09-28T12:52:31Z,2023-09-29T09:04:54Z,The DelegatorProtocol is far more flexible ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1099/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1100,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1100,incubator-stormcrawler,1918882793,1100,Turn off tracing in Selenium driver,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-09-29T09:01:28Z,2023-09-29T09:03:57Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1100/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1101,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1101,incubator-stormcrawler,1918905696,1101,Refactor configuration of timeouts in Selenium protocol,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-09-29T09:17:47Z,2023-10-02T14:26:12Z,"The configuration of the timeouts is quite error prone.  

[The default values are set to 0
](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/resources/crawler-default.yaml#L174)
```
  selenium.implicitlyWait: 0
  selenium.pageLoadTimeout: 0
  selenium.scriptTimeout: 0
```
If not set explicitly in the configuration, the default value of 0 is used which leads to a script timeout. 

Instead we should it at -1 in the default config so that it is visible for illustration purposes and modify the code so that it is only set if the value is >=0. This would in effect mean: rely on Selenium's default unless specified otherwise, which feels a lot cleaner. It also adds an additional safety as negative values are not accepted.

We will also change the config to use a map, feels a bit cleaner conceptually

```
  # rely on selenium's default values
  # set to a value >= 0 to override
  selenium.timeouts:
    script: -1
    pageLoad: -1
    implicit: -1
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1101/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1101,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5nvwtL,incubator-stormcrawler,1740573515,1101,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-09-29T09:18:10Z,2023-09-29T09:18:10Z,"of course, this is a breaking change and it will be flagged as such in the release","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5nvwtL/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1104,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1104,incubator-stormcrawler,1927327784,1104,NimbusLeaderNotFoundException when upgrading to the latest version of storm crawler with jdk 17,batman0007,27924782,Aakanksha,,CLOSED,2023-10-05T03:51:39Z,2023-10-05T12:31:46Z,"
I'm seeing various errors while upgrading the stormcrawler version from 1.15 to 2.9, storm version 2.5.0 and java 8 to 17 simultaneously. 
First there were test failure with this exception:"" java.lang.IllegalArgumentException: Unable to canonicalize address localhost/:2000 because it's not resolvable"" when stormcarwler was at the lower version
 and on updating the version, the error was: ""The following artifacts could not be resolved: org.clojars.bipinprasad:carbonite:jar:1.6.0 (absent).""
 On adding this dependency, now this is the error: ""org.apache.storm.utils.NimbusLeaderNotFoundException: Could not find leader nimbus from seed hosts [localhost]. Did you specify a valid list of nimbus hosts for config nimbus.seeds?""
Are there compatibility issues with stormcrawler version 2.9 and jdk 17/11 or am I missing something?(java and maven paths are set and pom has all dependencies) Is anyone else seeing this issue?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1104/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1104,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5oPKQl,incubator-stormcrawler,1748804645,1104,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-10-05T12:31:46Z,2023-10-05T12:31:46Z,"Both StormCrawler and Apache Storm are both tested against JDK 11/17. Your issues seem mostly related to configuring Storm and not so much StormCrawler. Maybe best to ask questions about how to set up Storm to the Storm user list, you will get a larger audience.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5oPKQl/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1105,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1105,incubator-stormcrawler,1930520563,1105,org.apache.http.NoHttpResponseException: The target server failed to respond,visakini,108073750,,,CLOSED,2023-10-06T16:05:28Z,2024-03-06T09:15:18Z,"We are getting this exception intermittently in our application .

Http client version is 4.5.10


Will retry request will avoid this error.


Thanks!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1105/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1105,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5pFbyp,incubator-stormcrawler,1763032233,1105,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-10-14T16:22:57Z,2023-10-14T16:22:57Z,Can you elaborate a bit please? Are you suggesting to add something similar to https://gist.github.com/devrath/e86d591e0e03732f5050bc8a798c60b6 ?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5pFbyp/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1105,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5pTL9C,incubator-stormcrawler,1766637378,1105,NA,visakini,108073750,,,NA,2023-10-17T15:19:26Z,2023-10-17T15:19:26Z,"We are adding like this
  public boolean retryRequest(IOException e, int retryCount, HttpContext httpCtx) {
                if (retryCount >= 3){
                    Logger.warn(CALLER, ""Maximum tries reached, exception would be thrown to outer block"");
                    return false;
                }
                if (e instanceof org.apache.http.NoHttpResponseException){
                    Logger.warn(CALLER, ""No response from server on ""+retryCount+"" call"");
                    return true;
                }
                return false;
            }
        };
After this the request suceeds but is there any alternative solution for avoiding NoHttpResponseException.This is just a work around","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5pTL9C/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1105,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5pTMiS,incubator-stormcrawler,1766639762,1105,NA,visakini,108073750,,,NA,2023-10-17T15:20:36Z,2023-10-17T15:20:36Z,"> We are adding like this public boolean retryRequest(IOException e, int retryCount, HttpContext httpCtx) { if (retryCount >= 3){ Logger.warn(CALLER, ""Maximum tries reached, exception would be thrown to outer block""); return false; } if (e instanceof org.apache.http.NoHttpResponseException){ Logger.warn(CALLER, ""No response from server on ""+retryCount+"" call""); return true; } return false; } }; After this the request suceeds but is there any alternative solution for avoiding NoHttpResponseException.This is just a work around



> Can you elaborate a bit please? Are you suggesting to add something similar to https://gist.github.com/devrath/e86d591e0e03732f5050bc8a798c60b6 ?


We are adding like this
public boolean retryRequest(IOException e, int retryCount, HttpContext httpCtx) {
if (retryCount >= 3){
Logger.warn(CALLER, ""Maximum tries reached, exception would be thrown to outer block"");
return false;
}
if (e instanceof org.apache.http.NoHttpResponseException){
Logger.warn(CALLER, ""No response from server on ""+retryCount+"" call"");
return true;
}
return false;
}
};
After this the request suceeds but is there any alternative solution for avoiding NoHttpResponseException.This is just a work around

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5pTMiS/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1105,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5tvQ73,incubator-stormcrawler,1841106679,1105,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-12-05T16:09:11Z,2023-12-05T16:09:11Z,Could be a sign that you are using too any threads. Do you have 1 thread per queue or do you use multithreading? How many fetcher threads do you use?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5tvQ73/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1105,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc52CrjQ,incubator-stormcrawler,1980414160,1105,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-03-06T09:15:18Z,2024-03-06T09:15:18Z,No feedback. Closing for now,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc52CrjQ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1106,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1106,incubator-stormcrawler,1943381759,1106,Fetcher: optionally slow down fetching from hosts with repeated exceptions,jnioche,218319,Julien Nioche,julien@digitalpebble.com,OPEN,2023-10-14T16:28:32Z,2023-12-21T08:29:40Z,"See [NUTCH-2946](https://issues.apache.org/jira/browse/NUTCH-2946)

> The fetcher holds for every fetch queue a counter which counts the number of observed ""exceptions"" seen when fetching from the host (resp. domain or IP) bound to this queue.
> 
> As an improvement to increase the politeness of the crawler, the counter value could be used to dynamically increase the fetch delay for hosts where requests fail repeatedly with exceptions or HTTP status codes mapped to ProtocolStatus.EXCEPTION (HTTP 403 Forbidden, 429 Too many requests, 5xx server errors, etc.) Of course, this should be optional. The aim to reduce the load on such hosts already before the configured max. number of exceptions (property fetcher.max.exceptions.per.queue) is hit.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1106/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1106,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5pGeph,incubator-stormcrawler,1763306081,1106,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-10-15T07:31:34Z,2023-10-15T07:31:34Z,https://github.com/apache/nutch/pull/728,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5pGeph/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1106,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5vNrWK,incubator-stormcrawler,1865856394,1106,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-12-21T08:29:39Z,2023-12-21T08:29:39Z,"Instead of delaying, which would increase latency, trigger timeouts and fail the tuples. It would be better to assume Fetch errors for the URLs in the queue and push them straight to status.
An even better approach would be to have #867 and send data at the queue level so that URLs from it are held for a while. URLFrontier would be a good match for that.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5vNrWK/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1107,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1107,incubator-stormcrawler,1943382344,1107,Protocol-okhttp: implement IP filter,jnioche,218319,Julien Nioche,julien@digitalpebble.com,OPEN,2023-10-14T16:30:23Z,2023-10-15T07:30:21Z,"See [NUTCH-2930](https://issues.apache.org/jira/browse/NUTCH-2930)

> In order to avoid information leakage to a public search index or web archive, it should be possible to configure Nutch in a way that no content is fetched from localhost, loop-back addresses, private address spaces.
> 
> [NUTCH-2527](https://issues.apache.org/jira/browse/NUTCH-2527) adds the configuration snippets to exclude URLs pointing to private addresses.
> 
> However, filtering URLs isn't enough because a DNS entry of an arbitrary host name may point to a private IP address. Blocking must happen on the protocol level because the IP address is only know in the protocol implementation. I'll add an implementation for protocol-okhttp.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1107/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1107,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5pFjh6,incubator-stormcrawler,1763063930,1107,NA,rzo1,13417392,Richard Zowalla,,NA,2023-10-14T17:51:35Z,2023-10-14T17:51:35Z,"Sounds useful. Might also be useful to add adresses dynamically during a crawl in order to deal with abuse requests, etc.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5pFjh6/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1107,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5pGec4,incubator-stormcrawler,1763305272,1107,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-10-15T07:27:41Z,2023-10-15T07:27:41Z,NUTCH-2527 -> #543,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5pGec4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1107,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5pGemA,incubator-stormcrawler,1763305856,1107,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-10-15T07:30:21Z,2023-10-15T07:30:21Z,https://github.com/apache/nutch/pull/736/files,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5pGemA/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1108,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1108,incubator-stormcrawler,1943511429,1108,"Compatibility mode issue (ES 8, RHLC 7.17.14)",aspexi,8318368,Krzysztof Dryja (Aspexi),info@aspexi.com,CLOSED,2023-10-14T19:40:30Z,2023-12-02T11:38:37Z,"Storm Crawler: 2.10-SNAPSHOT
storm-client-version: 2.5.0
elasticsearch-rest-high-level-client: 7.17.14
elasticsearch-rest-client-sniffer: 8.8.1
ElasticSearch: 8.8.1

Compatibility mode enabled but I get this on _bulk queries:

```
java.io.IOException: Unable to parse response body for Response{requestLine=POST /_bulk?timeout=1m HTTP/1.1, host=http://localhost:9200, response=HTTP/1.1 200 OK}
Caused by: java.lang.NullPointerException
	at java.util.Objects.requireNonNull(Objects.java:221) ~[?:?]
	at org.elasticsearch.action.DocWriteResponse.<init>(DocWriteResponse.java:116)
```

Also asked the same question here https://github.com/elastic/elasticsearch/issues/84173#issuecomment-1762929183

Any ideas why regardless correct header I'm still seeing NPE?

Moreover, by monitoring network traffic I noticed that after some minutes the compatibility header disappears from _bulk requests. No idea why this happens.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1108/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1108,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5tFq-F,incubator-stormcrawler,1830203269,1108,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-11-28T16:16:25Z,2023-11-28T16:16:25Z,Hi @aspexi - did you get to the bottom of this problem?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5tFq-F/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1108,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5tgFcZ,incubator-stormcrawler,1837127449,1108,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-12-02T11:38:36Z,2023-12-02T11:38:36Z,"Closing for now, please reopen if needed","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5tgFcZ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1109,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1109,incubator-stormcrawler,1952510244,1109,User agent substitution not handled correctly,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-10-19T15:16:34Z,2023-10-19T15:20:15Z,"The mechanism for setting the user agent in the Selenium conf is not working properly. It currently expects it to be in a string but in practice it is:

1. within a list
2. that list is within a map

```
  selenium.capabilities:
    browserName: ""chrome""
    goog:chromeOptions:
       args:
         - ""--disable-dev-shm-usage""
         - ""--no-sandbox""
         - ""--user-agent=$useragent""
 ```
 
 It is never a simple value at the top level
 ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1109/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1110,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1110,incubator-stormcrawler,1952596379,1110,DelegatorProtocol to filter with regexps on URLs,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-10-19T15:56:21Z,2023-10-19T15:57:17Z,"This adds to the [recent improvements made to the DelegatorProtocol](https://github.com/DigitalPebble/storm-crawler/issues/1098).
In addition to metadata, we should be able to define regular expressions on the URLs. This will make it easier e.g. to avoid using Selenium when dealing with a suspected pdf or Word file.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1110/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1111,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1111,incubator-stormcrawler,1954398964,1111,"Fetcher, set number of threads via metadata",jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-10-20T14:21:47Z,2023-10-20T14:49:42Z,"The max number of threads to use per queue is set via configuration: 
- globally with **fetcher.threads.per.queue** 
- per queue with **fetcher.maxThreads.QUEUEID**

where _QUEUEID_ is the internal ID of the queue, typically the corresponding hostname.

It could be useful to set it through metadata so that when a queue is first created and if a given key value is found in the URL that caused it to be created, we use the value as a number of threads to use, similar to what is done for the [crawl delay](https://github.com/DigitalPebble/storm-crawler/blob/e233c854b2a4d2eb76f12d159dccad16896eeead/core/src/main/java/com/digitalpebble/stormcrawler/bolt/FetcherBolt.java#L80).","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1111/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1111,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5prA6C,incubator-stormcrawler,1772883586,1111,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-10-20T14:49:41Z,2023-10-20T14:49:41Z,You can now pass _max.threads.queue_ in URL metadata to specify a non default number of threads when a queue is created ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5prA6C/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1112,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1112,incubator-stormcrawler,1954457433,1112,Fetcher: pass custom delay for queues via metadata,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-10-20T14:53:57Z,2023-10-20T16:37:44Z,"The [existing mechanism ](https://github.com/DigitalPebble/storm-crawler/blob/e233c854b2a4d2eb76f12d159dccad16896eeead/core/src/main/java/com/digitalpebble/stormcrawler/bolt/FetcherBolt.java#L80) to set a custom delay for queues in the Fetcher actually changes the min delay - which is only used when more than 1 thread is allowed for a queue.

I will introduce a separate key name to set the _min delay_ and fix the code so that the existing key is used for the normal, non threaded access.

See #964 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1112/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1112,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5prI6C,incubator-stormcrawler,1772916354,1112,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-10-20T15:06:12Z,2023-10-20T15:06:12Z,"The custom crawl delay and min crawl delay for a queue can be specified at the URL level with the keys
- crawl.delay
- crawl.min.delay","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5prI6C/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1113,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1113,incubator-stormcrawler,1972308864,1113,Upgrade to OpenSearch 2.11,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-11-01T12:43:36Z,2023-11-01T12:44:47Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1113/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1115,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1115,incubator-stormcrawler,1972869599,1115,Improve Selenium tests,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-11-01T18:18:37Z,2023-11-01T18:19:40Z,"Check that the protocol implementation limits access to the driver when accessed concurrently. Adds metadata to trace when the protocol actually started and stopped the processing of a URL.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1115/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1116,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1116,incubator-stormcrawler,1973546173,1116,Use MockServer for Selenium tests,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-11-02T05:40:46Z,2023-11-08T13:40:57Z,This would be better than connecting to a real URL ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1116/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1118,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1118,incubator-stormcrawler,1977992293,1118,Dependency upgrades,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-11-05T22:01:19Z,2023-11-09T15:47:38Z,"https://jsoup.org/news/release-1.16.2

> jsoup 1.16.2 is out now with faster CSS selector execution via a cost-based query planner, better support for math and svg elements, and a bunch of other improvements and bug fixes.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1118/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1118,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5rh6RU,incubator-stormcrawler,1804051540,1118,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-11-09T15:30:15Z,2023-11-09T15:30:15Z,"Candidates for updates

- [x]   com.amazonaws:aws-java-sdk-cloudsearch .......... 1.12.467 -> 1.12.585
- [x]    com.amazonaws:aws-java-sdk-s3 ................... 1.12.467 -> 1.12.585
- [x]    com.github.ben-manes.caffeine:caffeine ................ 3.1.6 -> 3.1.8
- [x]    com.ibm.icu:icu4j ....................................... 73.1 -> 74.1
- [x]    commons-cli:commons-cli ............................... 1.5.0 -> 1.6.0
- [x]    com.squareup.okhttp3:okhttp ................. 4.11.0 -> 4.12.0
- [x]    com.squareup.okhttp3:okhttp-brotli .......... 4.11.0 -> 4.12.0
- [x]    org.apache.solr:solr-solrj ............................ 9.3.0 -> 9.4.0
- [x]    org.apache.tika:tika-core ............................. 2.9.0 -> 2.9.1
- [x]    org.apache.tika:tika-parsers-standard-package ......... 2.9.0 -> 2.9.1
- [x]    org.jsoup:jsoup ..................................... 1.16.1 -> 1.16.2
- [x]    org.mockito:mockito-core .............................. 5.5.0 -> 5.7.0
- [x]    org.seleniumhq.selenium:selenium-chrome-driver ...... 4.12.1 -> 4.15.0
- [x]    org.seleniumhq.selenium:selenium-remote-driver ...... 4.12.1 -> 4.15.0
- [x]    org.seleniumhq.selenium:selenium-support ............ 4.12.1 -> 4.15.0
- [x]    org.testcontainers ............................ 1.19.0 -> 1.19.1
- [x]    org.yaml:snakeyaml ........................................ 2.0 -> 2.2
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5rh6RU/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1120,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1120,incubator-stormcrawler,1994926179,1120,WARCSpout read inputs from HDFS FS,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-11-15T14:46:31Z,2023-11-17T10:58:03Z,"The WARCSpout treats the inputs to read as URLs or expected local files. Since the WARC module uses the HDFS dependencies, we could make it handle content from HDFS. This would also help read from S3 if the right config and dependencies were added.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1120/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1124,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1124,incubator-stormcrawler,2002702570,1124,AbstractIndexerBolt - avoid reparsing metadata keys for each document ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-11-20T17:44:29Z,2023-11-20T17:47:53Z,"The AbstractIndexerBolt class iterates on the list of keys to index and checks whether the index of a specific value is required.
This is wasteful and should be done only once, when initialising the indexer bolt.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1124/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1125,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1125,incubator-stormcrawler,2004587002,1125,FileSpout: spread the work based on the number of instances,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-11-21T15:43:36Z,2023-11-28T15:22:35Z,"The FileSpout is currently unaware of the number of instances it has. All of them are expected to process the same input; for this reason there is currently no benefit in having more than 1 instance.

There could be some gains in having more than 1 instance if the implementation was able to split the inputs based on that. A similar mechanism is used by the OpenSearch/Elasticsearch spouts to map an instance to a shard. In the case of Filespouts, it would be beneficial to classes extending it like  [WARCSpout](https://github.com/DigitalPebble/storm-crawler/blob/master/external/warc/src/main/java/com/digitalpebble/stormcrawler/warc/WARCSpout.java), which takes some processing to generate the inputs and could become a bottleneck.

The easiest approach would be to process only the lines where line number % instance num = 0 in the [populate buffer method](https://github.com/DigitalPebble/storm-crawler/blob/857bf09da6cb03a28ffab93623697494f5e69792/core/src/main/java/com/digitalpebble/stormcrawler/spout/FileSpout.java#L140). All the instances would be reading the same files but skipping the lines that are not for them.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1125/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1125,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5snL1I,incubator-stormcrawler,1822211400,1125,NA,rzo1,13417392,Richard Zowalla,,NA,2023-11-22T06:56:58Z,2023-11-22T06:56:58Z,"Sounds good to me.

Alternative approach would be to allow to read from multiple files and split on a ""per-file"" basis.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5snL1I/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1125,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5sncRc,incubator-stormcrawler,1822278748,1125,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-11-22T08:01:24Z,2023-11-22T08:01:24Z,"Thanks @rzo1. Splitting on file gives you no guarantee that the content will be balanced, one could be tiny, the other one very large. It is also less flexible + practically the files are handled in the constructor but we don't know about the number of instances until we get to the init method.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5sncRc/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1127,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1127,incubator-stormcrawler,2007815748,1127,Upgrade to Apache Storm 2.6.0,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-11-23T09:38:32Z,2023-11-23T09:42:34Z,https://storm.apache.org/2023/11/22/storm260-released.html,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1127/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1128,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1128,incubator-stormcrawler,2014613000,1128,Add configurable delay between launching Fetch threads  ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-11-28T14:45:24Z,2023-11-28T15:36:09Z,"Will happen somehere around [FetcherBolt](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/bolt/FetcherBolt.java#L871)
Similar to [Nutch-2929](https://issues.apache.org/jira/browse/NUTCH-2929)
This would be to prevent the threads to hit the DNS resolution too hard at the beginning of the crawl. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1128/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1129,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1129,incubator-stormcrawler,2014787468,1129,Remove default values for user agent,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-11-28T16:06:24Z,2023-12-06T13:36:05Z,"Goodbye ""Anonymous Coward""!!!

Forcing the users to set the user agent value is an incentive to crawl ethically and a good way for them to learn about the configuration.
The values crawler-default will be commented out, same for the configs generated by the archetype.


 ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1129/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1131,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1131,incubator-stormcrawler,2028152475,1131,Archetypes to prompt user for user agent values,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-12-06T09:47:44Z,2023-12-06T12:10:41Z,"See #1129 
The user agent values will not have a default and the topology should not start without them. To make things easier, the users should be prompted for the values to use when creating a new project from the artefact. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1131/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1132,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1132,incubator-stormcrawler,2030972167,1132,OpenSearch dashboard script work from anywhere,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-12-07T15:15:37Z,2023-12-07T15:16:03Z,It currently requires to be executed from the dir containing it so that the paths to the resources work.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1132/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1133,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1133,incubator-stormcrawler,2037177239,1133,custom DocumentID override is not capable in DeletionBolt,chhsiao90,10794200,"Chun-Han, Hsiao",chhsiao90@gmail.com,CLOSED,2023-12-12T07:49:36Z,2023-12-12T08:48:02Z,"What kind of issue is this?  Feature request

This feature was already implemented in #1028 and #1036 for indexer and status bolts, but not in deletion bolt.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1133/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1133,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5uWxc5,incubator-stormcrawler,1851463481,1133,NA,chhsiao90,10794200,"Chun-Han, Hsiao",chhsiao90@gmail.com,NA,2023-12-12T07:49:50Z,2023-12-12T07:49:50Z,Please let me know if we'd  like to have this feature in deletion bolt and I can have a PR for it. And a question about the implementation is that should we have an AbstractDeletionBolt?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5uWxc5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1133,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5uWyaK,incubator-stormcrawler,1851467402,1133,NA,rzo1,13417392,Richard Zowalla,,NA,2023-12-12T07:53:16Z,2023-12-12T07:53:16Z,"> This feature was already implemented in https://github.com/DigitalPebble/storm-crawler/pull/1028 and https://github.com/DigitalPebble/storm-crawler/pull/1036 for indexer and status bolts, but in deletion bolt.

Feel free to open a PR for it.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5uWyaK/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1133,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5uXGw4,incubator-stormcrawler,1851550776,1133,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-12-12T08:48:01Z,2023-12-12T08:48:01Z,Thanks a lot @chhsiao90 ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5uXGw4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1136,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1136,incubator-stormcrawler,2038004358,1136,import Kibana script work from anywhere ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-12-12T15:25:27Z,2023-12-12T15:28:39Z,Same as #1132 but for Elastic,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1136/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1137,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1137,incubator-stormcrawler,2039965449,1137,Dependency updates,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2023-12-13T15:35:04Z,2023-12-21T08:25:50Z,"mvn versions:display-dependency-updates 

[INFO]   org.opensearch.client:opensearch-rest-high-level-client ... 2.11.0 -> 2.11.1
[INFO]   com.amazonaws:aws-java-sdk-cloudsearch .......... 1.12.585 -> 1.12.616
[INFO]   com.amazonaws:aws-java-sdk-s3 ................... 1.12.585 -> 1.12.617
[INFO]   com.fasterxml.jackson.core:jackson-annotations ...... 2.15.2 -> 2.16.0
[INFO]   com.fasterxml.jackson.core:jackson-core ............. 2.15.2 -> 2.16.0
[INFO]   com.fasterxml.jackson.core:jackson-databind ......... 2.15.2 -> 2.16.0
[INFO]   com.ibm.icu:icu4j ....................................... 74.1 -> 74.2
~~[INFO]   com.squareup.okhttp3:okhttp ................. 4.12.0 -> 5.0.0-alpha.11~~
~~[INFO]   com.squareup.okhttp3:okhttp-brotli .......... 4.12.0 -> 5.0.0-alpha.11~~
[INFO]   javax.xml.bind:jaxb-api .................. 2.3.1 -> 2.4.0-b180830.0359
[INFO]   org.apache.logging.log4j:log4j-api ............. 2.20.0 -> 2.22.0
[INFO]   org.apache.logging.log4j:log4j-core ............ 2.20.0 -> 2.22.0
[INFO]   org.apache.logging.log4j:log4j-slf4j-impl ...... 2.20.0 -> 2.22.0
~~[INFO]   org.apache.tika:tika-core ........................ 2.9.1 -> 3.0.0-BETA~~
~~[INFO]   org.apache.tika:tika-parsers-standard-package .... 2.9.1 -> 3.0.0-BETA~~
[INFO]   org.jetbrains:annotations ........................... 24.0.1 -> 24.1.0
[[INFO]   org.jsoup:jsoup ..................................... 1.16.2 -> 1.17.1
](https://jsoup.org/news/release-1.17.1)[INFO]   org.mockito:mockito-core .............................. 5.7.0 -> 5.8.0
[INFO]   org.netpreserve:jwarc ............................... 0.28.3 -> 0.28.5
[INFO]   org.seleniumhq.selenium:selenium-chrome-driver ...... 4.15.0 -> 4.16.1
[INFO]   org.seleniumhq.selenium:selenium-remote-driver ...... 4.15.0 -> 4.16.1

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1137/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1137,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5uuj14,incubator-stormcrawler,1857699192,1137,NA,rzo1,13417392,Richard Zowalla,,NA,2023-12-15T11:09:03Z,2023-12-15T11:09:03Z,Wdyt about activating https://github.com/renovatebot/renovate - it seems to be better than dependabot.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5uuj14/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1137,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5uupez,incubator-stormcrawler,1857722291,1137,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2023-12-15T11:26:43Z,2023-12-15T11:26:43Z,"> Wdyt about activating https://github.com/renovatebot/renovate - it seems to be better than dependabot.

yes, why not. Especially if there is a way of telling it not to bother with alpha or beta versions
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5uupez/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1141,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1141,incubator-stormcrawler,2074179298,1141,Improve metrics for StatusUpdaterBolts,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2024-01-10T11:35:54Z,2024-03-28T14:02:36Z,"The metrics generated by the StatusUpdaterBolt in the **Elasticsearch** and **OpenSearch** modules could be improved.

* `waitAck` is generated every 10 secs when the other metrics use 30 secs
* `acked` is used both for tuples that are received from the back end but also the ones that are duplicates and not sent. Better to distinguish them
* `failed` is used both for tuples that got an error in the back end and the ones that got purged from the cache. Distinguish them
*  `bulks_received` is used in _beforeBulk_, should call it `bulks_sent` instead
* add a `received` metric to count everything that has been returned by the backend whether a duplicate or success
* add a metric to return the average number of received messages from the back end per second - useful for benchmarking


","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1141/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1142,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1142,incubator-stormcrawler,2076256816,1142,Add sniffing for OpenSearch,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2024-01-11T10:31:32Z,2024-05-06T06:33:18Z,"Currently, all the nodes must be explicitly declared in the configuration. There seems to be a library for sniffing but I could not find any references on how to use it.

See discussion on https://github.com/opensearch-project/OpenSearch/issues/3087","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1142/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1143,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1143,incubator-stormcrawler,2112091209,1143,Use proxy on a per URL basis,jnioche,218319,Julien Nioche,julien@digitalpebble.com,OPEN,2024-02-01T10:10:35Z,2024-02-01T10:10:42Z,"The proxies are configured once and for all the URLs. It would be more flexible to allow them to be used on a per URL basis by relying on their metadata.

The interface [ProxyManager](https://github.com/DigitalPebble/storm-crawler/blob/master/core/src/main/java/com/digitalpebble/stormcrawler/proxy/ProxyManager.java#L27) has a method

```
SCProxy getProxy(Metadata metadata);
```

which already allows that but the logic is not implemented yet.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1143/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1144,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1144,incubator-stormcrawler,2144695327,1144,Dependency upgrades,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2024-02-20T15:51:20Z,2024-05-06T06:32:46Z,"`mvn versions:display-dependency-updates ""-Dmaven.version.ignore=.*-M.*,.*-alpha.*,.*-beta.*,.*-BETA.*,.*-b.*"" | grep '\->' | sort | uniq `

Ignoring Elastic for licensing reasons

```
[INFO]   org.opensearch.client:opensearch-rest-client-sniffer ...
[INFO]                                                         2.11.1 -> 2.12.0
[INFO]   org.opensearch.client:opensearch-rest-high-level-client ...
[INFO]                                                         2.11.1 -> 2.12.0
[INFO]   com.amazonaws:aws-java-sdk-cloudsearch .......... 1.12.585 -> 1.12.663
[INFO]   com.amazonaws:aws-java-sdk-s3 ................... 1.12.585 -> 1.12.663
[INFO]   com.cosium.code:google-java-format ........................ 5.1 -> 5.3
[INFO]   com.fasterxml.jackson.core:jackson-annotations ...... 2.15.2 -> 2.16.1
[INFO]   com.fasterxml.jackson.core:jackson-core ............. 2.15.2 -> 2.16.1
[INFO]   com.fasterxml.jackson.core:jackson-databind ......... 2.15.2 -> 2.16.1
[INFO]   org.apache.logging.log4j:log4j-api .................. 2.21.1 -> 2.23.0
[INFO]   org.apache.logging.log4j:log4j-core ................. 2.21.1 -> 2.23.0
[INFO]   org.apache.logging.log4j:log4j-slf4j-impl ........... 2.21.1 -> 2.23.0
[INFO]   org.apache.solr:solr-solrj ............................ 9.4.0 -> 9.5.0
[INFO]   org.apache.storm:storm-client ......................... 2.6.0 -> 2.6.1
[INFO]   org.apache.storm:storm-hdfs ........................... 2.6.0 -> 2.6.1
[INFO]   org.mockito:mockito-core ............................. 5.8.0 -> 5.10.0
[INFO]   org.netpreserve:jwarc ............................... 0.28.5 -> 0.29.0
[INFO]   org.seleniumhq.selenium:selenium-chrome-driver ...... 4.16.1 -> 4.18.1
[INFO]   org.seleniumhq.selenium:selenium-remote-driver ...... 4.16.1 -> 4.18.1
[INFO]   org.seleniumhq.selenium:selenium-support ............ 4.16.1 -> 4.18.1
[INFO]   org.testcontainers:* ............................ 1.19.3 -> 1.19.5
[INFO]   org.wiremock:wiremock ................................. 3.3.1 -> 3.4.1
`","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1144/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1145,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1145,incubator-stormcrawler,2146260207,1145,Generate THIRD-PARTY.txt file,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2024-02-21T09:37:02Z,2024-02-21T13:22:07Z,"`mvn license:aggregate-add-third-party -Dlicense.outputDirectory=.`

generates a THIRD-PARTY.txt file with all the direct and transitive dependencies. It would be good to have this done automatically as part of the build. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1145/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1145,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc50mfJ2,incubator-stormcrawler,1956246134,1145,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-02-21T09:37:28Z,2024-02-21T09:37:28Z,"See https://www.mojohaus.org/license-maven-plugin/aggregate-add-third-party-mojo.html
and https://www.mojohaus.org/license-maven-plugin/examples/example-thirdparty.html","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc50mfJ2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1147,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1147,incubator-stormcrawler,2146753196,1147,OpenSearch tests to use explicitly versioned Docker image ,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2024-02-21T13:25:23Z,2024-05-06T06:33:01Z,"It currently relies on _latest_ , which as we have noticed in #1146 can cause unforeseen issues when a new version of OpenSearch is released.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1147/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1148,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1148,incubator-stormcrawler,2146826025,1148,Remove coveralls maven plugin,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2024-02-21T13:58:01Z,2024-05-06T06:33:05Z,"See discussion in [#1075](https://github.com/DigitalPebble/storm-crawler/issues/1075#issuecomment-1556943292)

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1148/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1150,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1150,incubator-stormcrawler,2148938689,1150,OpenSearch 2.12.0,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2024-02-22T12:13:49Z,2024-05-06T06:31:33Z,"Dependency update

This version of OpenSearch requires _OPENSEARCH_INITIAL_ADMIN_PASSWORD_ to be passed, even though the security is disabled

See https://opensearch.org/docs/latest/install-and-configure/install-opensearch/docker/","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1150/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1151,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1151,incubator-stormcrawler,2148959812,1151,Force version of commons-io to 2.11.0,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2024-02-22T12:25:01Z,2024-05-06T06:30:26Z,"Needed until https://github.com/apache/storm/pull/3626

We get 2.14.0 from Tika but Storm is still on 2.11.0 

The archetypes force the version but it is better to do it for everything in SC instead","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1151/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1152,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1152,incubator-stormcrawler,2152768250,1152,upgrade io.confluent:kafka-avro-serializer:jar:1.0,pjfanning,11783444,PJ Fanning,,CLOSED,2024-02-25T13:33:09Z,2024-05-06T06:30:17Z,"This is a very out of date version of this jar and is being reported as having an unknown license in the third party jar list.

This project not appear to publish to maven central - only to 3rd party maven repos.

https://mvnrepository.com/artifact/io.confluent/kafka-avro-serializer?repo=confluent-packages
 

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1152/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1152,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc51ARIf,incubator-stormcrawler,1963004447,1152,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-02-25T17:17:42Z,2024-02-25T17:17:42Z,"thanks @pjfanning 
This should be raised at Apache Storm instead, as we inherit it from its [storm-hdfs module](https://github.com/apache/storm/blob/4d92ba3df5e7542a926b300624c549c2b97482e7/external/storm-hdfs/pom.xml#L260)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc51ARIf/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1152,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc51ASHm,incubator-stormcrawler,1963008486,1152,NA,rzo1,13417392,Richard Zowalla,,NA,2024-02-25T17:34:40Z,2024-02-25T17:34:40Z,"Yeah, we should get rid of it in Storm. Feel free to open a Jira (and/or create a PR If you have some minutes). Otherwise, I can have a look at it inside of Storm too but might take a few days 🙃","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc51ASHm/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1152,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc51Eba-,incubator-stormcrawler,1964095166,1152,NA,rzo1,13417392,Richard Zowalla,,NA,2024-02-26T13:01:35Z,2024-02-26T13:01:35Z,https://issues.apache.org/jira/browse/STORM-4035,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc51Eba-/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1152,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc51FX5s,incubator-stormcrawler,1964342892,1152,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-02-26T14:56:53Z,2024-02-26T14:56:53Z,https://github.com/apache/storm/pull/3627 has been merged. Closing this issue as resolved,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc51FX5s/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1153,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1153,incubator-stormcrawler,2203146665,1153,Fix various quirks in OpenSearch archetype projet generation,rzo1,13417392,Richard Zowalla,,CLOSED,2024-03-22T19:08:45Z,2024-03-28T14:02:42Z,"There are a few quirks in the generated archetype. 

For example, the mapping files do not correspond to the file names used in the index creation script. 

Moreover, the mappings aren't added to the project generated by the archetype, so you have to copy paste it from source or form within the JAR. Let's just ship them and make life of users easier.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1153/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1153,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54MkFF,incubator-stormcrawler,2016559429,1153,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-03-23T17:48:20Z,2024-03-23T17:48:20Z,"> For example, the mapping files do not correspond to the file names used in the index creation script.

the mapping files are named after the type of bolt that creates it. For status and metrics, the name of the component and the index is the same but this is not the case for indexer != content. Let's just change the init script so that it distinguishes them.

> Moreover, the mappings aren't added to the project generated by the archetype, so you have to copy paste it from source or form within the JAR. Let's just ship them and make life of users easier.

perhaps we should have them in the archetype only?


 ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54MkFF/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1156,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1156,incubator-stormcrawler,2211204680,1156,can we rename the 'master' branch as 'main'?,pjfanning,11783444,PJ Fanning,,CLOSED,2024-03-27T16:08:13Z,2024-03-28T13:56:41Z,"Just feels a bit better name wise. 'main' is now the default in GitHub.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1156/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1156,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54l4eJ,incubator-stormcrawler,2023196553,1156,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-03-27T16:24:26Z,2024-03-27T16:24:26Z,"On my other repos I can see that this is done via _Settings -> General -> Default branches_ but now that it is at Apache, I don't have access to the Settings section.
Do we do it manually instead e.g. following https://www.git-tower.com/learn/git/faq/git-rename-master-to-main ?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54l4eJ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1156,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54l6OD,incubator-stormcrawler,2023203715,1156,NA,pjfanning,11783444,PJ Fanning,,NA,2024-03-27T16:26:10Z,2024-03-27T16:26:10Z,"We might need to raise an INFRA issue. They have full access. If we get agreement to proceed, I can raise the JIRA.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54l6OD/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1156,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54od7u,incubator-stormcrawler,2023874286,1156,NA,rzo1,13417392,Richard Zowalla,,NA,2024-03-27T20:09:05Z,2024-03-27T20:09:05Z,Needs to be done by INFRA ;-)  I have done that for a few ASF projects.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54od7u/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1156,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54toR8,incubator-stormcrawler,2025227388,1156,NA,pjfanning,11783444,PJ Fanning,,NA,2024-03-28T13:46:17Z,2024-03-28T13:46:17Z,I raised https://issues.apache.org/jira/browse/INFRA-25661,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54toR8/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1156,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54tt28,incubator-stormcrawler,2025250236,1156,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-03-28T13:56:41Z,2024-03-28T13:56:41Z,It has been done by infra.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54tt28/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1157,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1157,incubator-stormcrawler,2211205834,1157,Change package names from com.digitalpebble to org.apache,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2024-03-27T16:08:48Z,2024-03-28T11:30:36Z,"Now that SC is in incubation at the ASF, we need the package names to reflect the changes.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1157/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1162,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1162,incubator-stormcrawler,2211812436,1162,Drop coveralls code-coverage flow?,rzo1,13417392,Richard Zowalla,,CLOSED,2024-03-27T20:12:08Z,2024-09-05T17:24:05Z,"Can we drop the coveralls github action? 

I did a quick search at ASF level and I think, that only datasketches-cpp is using it. So might be good to just drop it and rely on other test coverage report metrics, which are more common at ASF level.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1162/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1162,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54pQrP,incubator-stormcrawler,2024082127,1162,NA,lewismc,1165719,Lewis John McGibbney,lewis.mcgibbney@gmail.com,NA,2024-03-27T22:15:49Z,2024-03-27T22:15:49Z,SonarCloud.io is very good.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54pQrP/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1162,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6J-UAf,incubator-stormcrawler,2314813471,1162,NA,sigee,6528240,Dávid Szigecsán,,NA,2024-08-28T09:31:02Z,2024-08-28T09:31:02Z,"Hi,
For checking and requiring a minimum test coverage you could use jacoco as it is used in [apache commons project](https://github.com/apache/commons-parent/blob/master/pom.xml#L218).

There is no generated badge for readme, but the pipeline could work perfectly by require a minimum coverage for different metrics (line coverage, branch coverage, class coverage, etc.).
Jacoco is already part of this project, so only the configuration is needed here.

What do you think?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6J-UAf/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1162,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6J-ZW9,incubator-stormcrawler,2314835389,1162,NA,rzo1,13417392,Richard Zowalla,,NA,2024-08-28T09:40:38Z,2024-08-28T09:40:38Z,I am using Jacoco in most of my projects ;-) - I have no objections in replacing it.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6J-ZW9/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1163,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1163,incubator-stormcrawler,2212591052,1163,Change the GitHub templates for PRs to be more ASF specific,pjfanning,11783444,PJ Fanning,,CLOSED,2024-03-28T07:59:19Z,2024-04-04T08:39:25Z,"The existing text seems a little out of date
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1163/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1163,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54uqrj,incubator-stormcrawler,2025499363,1163,NA,rzo1,13417392,Richard Zowalla,,NA,2024-03-28T15:27:42Z,2024-03-28T15:27:42Z,Also related to https://github.com/apache/incubator-stormcrawler/issues/1168,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54uqrj/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1164,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1164,incubator-stormcrawler,2212773399,1164,Change license headers,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2024-03-28T09:42:32Z,2024-03-28T16:36:58Z,"To be done after #1157 (which I am working on now)
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1164/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1166,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1166,incubator-stormcrawler,2213314709,1166,Delete branch 1.x,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2024-03-28T13:58:09Z,2024-03-28T15:19:01Z,Branch 1.x is pre-ASF and is not maintained. Now is the perfect time for a cleanup,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1166/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1166,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54ul-a,incubator-stormcrawler,2025480090,1166,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-03-28T15:19:01Z,2024-03-28T15:19:01Z,done,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54ul-a/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1167,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1167,incubator-stormcrawler,2213336100,1167,Deal with non-open source version of Elasticsearch,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2024-03-28T14:07:50Z,2024-04-02T10:17:07Z,"As mentioned in the incubation [proposal](https://cwiki.apache.org/confluence/display/INCUBATOR/StormCrawler+Proposal)

`Most dependencies are ASFv2 licensed. There are possible concerns around the Elasticsearch dependencies (Elastic License 2.0 - not open source). We will address these either by downgrading the version of Elasticsearch to 7.10.2, which is under ASFv2, remove the Elastic module altogether or make the dependency optional and instruct the users on how to activate it themselves to avoid having this non ASLv2 compliant licence in the distributions.`

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1167/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1167,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54t60H,incubator-stormcrawler,2025303303,1167,NA,rzo1,13417392,Richard Zowalla,,NA,2024-03-28T14:18:46Z,2024-03-28T14:18:46Z,+1 for downgrade (for now),"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54t60H/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1167,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc540u4G,incubator-stormcrawler,2027089414,1167,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-03-29T11:11:03Z,2024-03-29T11:11:03Z,"I'd be in favour of removing it altogether. If downgraded, the code will never evolve and will be so out of sync with Elastic that it won't be useful.
the code of the Opensearch plugin is also better. If people want to use their Elastic indices, they should be able to find a matching version of OS","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc540u4G/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1167,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5409wU,incubator-stormcrawler,2027150356,1167,NA,rzo1,13417392,Richard Zowalla,,NA,2024-03-29T11:54:13Z,2024-03-29T11:54:13Z,"I am ok with removing it but only if we provide some documentation for people / users on how to migrate existing indices / installation to the openserach plugin (and if it is just a README placed in the elastic search module folder pointing to existing open-search documentation). By doing so, we have a clear migration path and don't kill possible users. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5409wU/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1167,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc544A42,incubator-stormcrawler,2027949622,1167,NA,rzo1,13417392,Richard Zowalla,,NA,2024-03-30T07:12:50Z,2024-03-30T07:12:50Z,"To follow up here: 

Maybe we just place a README.md in the module (after we removed the content) and refer to https://opensearch.org/docs/latest/upgrade-to/upgrade-to/ (people looking to upgrade to 3.0 will than see, that the module isn't available anymore and find some direct links on how to upgrade their elastic search stuff and switch to the open search module). We can remove that README in the next minor release following 3.0 ? wdyt?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc544A42/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1168,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1168,incubator-stormcrawler,2213420051,1168,change CONTRIBUTING.md,pjfanning,11783444,PJ Fanning,,CLOSED,2024-03-28T14:44:04Z,2024-04-03T19:52:26Z,"The current file is out of date for an Apache podling.

I'm not sure what an updated file would say but it should probably mention that CLAs may be required for big changes.

https://www.apache.org/licenses/contributor-agreements.html","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1168/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1168,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54ukxu,incubator-stormcrawler,2025475182,1168,NA,rzo1,13417392,Richard Zowalla,,NA,2024-03-28T15:16:54Z,2024-03-28T15:16:54Z,We might find an answer along https://github.com/search?q=org%3Aapache%20CONTRIBUTING.md&type=code,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54ukxu/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1168,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc542qLh,incubator-stormcrawler,2027594465,1168,NA,ayushtkn,25608848,Ayush Saxena,ayushsaxena@apache.org,NA,2024-03-29T18:43:03Z,2024-03-29T18:43:03Z,"I think that DCO isn't required, & ICLA is also mandatory mostly for committers. I think this is a .md version of ""How To Contribute""
maybe we can get some pointers from similar docs & incorporate them
https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute
https://cwiki.apache.org/confluence/display/JCLOUDS/How+to+Contribute
https://cwiki.apache.org/confluence/display/FLUME/How+to+Contribute
https://cwiki.apache.org/confluence/display/SQOOP/How+to+Contribute
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc542qLh/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1169,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1169,incubator-stormcrawler,2213495669,1169,Introduce Apache Parent POM,rzo1,13417392,Richard Zowalla,,CLOSED,2024-03-28T15:17:52Z,2024-04-02T11:50:58Z,as the title says,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1169/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1169,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54ulyp,incubator-stormcrawler,2025479337,1169,NA,rzo1,13417392,Richard Zowalla,,NA,2024-03-28T15:18:49Z,2024-03-28T15:18:49Z,"This will bring the `rat` plugin with it, so might need https://github.com/apache/incubator-stormcrawler/issues/1164 first","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54ulyp/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1170,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1170,incubator-stormcrawler,2213523826,1170,Remove references to companies to be vendor-neutral,rzo1,13417392,Richard Zowalla,,CLOSED,2024-03-28T15:30:38Z,2024-05-06T06:28:11Z,"Carefully check for links to vendor / company for pre-ASF era. As an ASF project, we need to be vendor neutral, i.e. we need to remove references to the commercial support company.

Maybe we can do something similar to https://tomee.apache.org/commercial-support.html","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1170/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1170,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54uu22,incubator-stormcrawler,2025516470,1170,NA,rzo1,13417392,Richard Zowalla,,NA,2024-03-28T15:35:51Z,2024-03-28T15:35:51Z,"This also includes pages on the Wiki, i.e. links to sponsoring an entity (which do not work anyway)","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54uu22/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1170,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc55Yv4L,incubator-stormcrawler,2036530699,1170,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-04-04T08:31:54Z,2024-04-04T08:31:54Z,"The sponsoring has been removed from the WIKI
What about adding a Commercial Support section on the WIKI and remove the ref to DiPe on the README?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc55Yv4L/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1170,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc55Yw4V,incubator-stormcrawler,2036534805,1170,NA,rzo1,13417392,Richard Zowalla,,NA,2024-04-04T08:33:44Z,2024-04-04T08:33:44Z,Yes. We could phrase it like it is done on TomEE: https://tomee.apache.org/commercial-support.html wdyt?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc55Yw4V/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1170,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc57pWto,incubator-stormcrawler,2074438504,1170,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-04-24T08:55:10Z,2024-04-24T08:55:10Z,"the README bow points to the support page of the site. I can't see any references to companies apart from external repositories that could be useful,.
@rzo1 can you double check and close the issue if appropriate? thanks!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc57pWto/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1170,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58P1S7,incubator-stormcrawler,2084525243,1170,NA,rzo1,13417392,Richard Zowalla,,NA,2024-04-30T07:02:15Z,2024-04-30T07:02:15Z,"I think, that it is ok now. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58P1S7/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1171,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1171,incubator-stormcrawler,2213542721,1171,Close the Discord channel and move to #asf Slack,rzo1,13417392,Richard Zowalla,,CLOSED,2024-03-28T15:39:27Z,2024-04-03T13:29:07Z,"as the title says

We need to also update the README.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1171/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1171,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54ux1J,incubator-stormcrawler,2025528649,1171,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-03-28T15:41:18Z,2024-03-28T15:41:18Z,"the ASF slack is not open to the public AFAIK but only to ASF members
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54ux1J/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1171,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54uyYf,incubator-stormcrawler,2025530911,1171,NA,rzo1,13417392,Richard Zowalla,,NA,2024-03-28T15:42:14Z,2024-03-28T15:42:14Z,Everyone can join the ASF slack. It just requires an invitation from an asf committer  :),"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54uyYf/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1171,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc540UtO,incubator-stormcrawler,2026982222,1171,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-03-29T09:54:51Z,2024-03-29T09:54:51Z,"> Everyone can join the ASF slack. It just requires an invitation from an asf committer :)

that's not super open. Do other projects at Apache have Discord channels outside Apache?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc540UtO/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1171,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc540lWs,incubator-stormcrawler,2027050412,1171,NA,pjfanning,11783444,PJ Fanning,,NA,2024-03-29T10:38:05Z,2024-03-29T10:38:05Z,"> > Everyone can join the ASF slack. It just requires an invitation from an asf committer :)
> 
> that's not super open. Do other projects at Apache have Discord channels outside Apache?

You can split the channels. Have internal team chats on Slack. Leave Discord there for other users.
I would suggest that GitHub discussions can be used to replace many of the Slack/Discord conversations. The GitHub discussion keeps everything related to a given discussion together while Slack/Discord can be a pain if there are multiple concurrent discussions.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc540lWs/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1171,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc55Obb4,incubator-stormcrawler,2033825528,1171,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-04-03T08:00:08Z,2024-04-03T08:00:08Z,I also prefer Discussions. I will close Discord soon and remove its mention in the README,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc55Obb4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1172,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1172,incubator-stormcrawler,2213545570,1172,Send an announce to the old Google Group,rzo1,13417392,Richard Zowalla,,CLOSED,2024-03-28T15:40:40Z,2024-03-28T15:55:29Z,"We should announce on the old google groups (if they are used), that SC has now joined the incubation at the ASF. Users are encouraged to subscribe to the newly created user@ and/or dev@ lists.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1172/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1172,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54uyV4,incubator-stormcrawler,2025530744,1172,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-03-28T15:42:09Z,2024-03-28T15:42:09Z,"https://incubator.apache.org/projects/stormcrawler.html

There is no user@","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54uyV4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1172,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54uyqA,incubator-stormcrawler,2025532032,1172,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-03-28T15:42:50Z,2024-03-28T15:42:50Z,"the google group is not used anymore
most annoucements have been made on Linkedin
This is not milestone related IMHo
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54uyqA/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1172,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54uy1b,incubator-stormcrawler,2025532763,1172,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-03-28T15:43:13Z,2024-03-28T15:43:13Z,"but yes, we can announce on the dead mailing list 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54uy1b/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1172,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54uy-e,incubator-stormcrawler,2025533342,1172,NA,rzo1,13417392,Richard Zowalla,,NA,2024-03-28T15:43:31Z,2024-03-28T15:43:31Z,"Nobody knows, who might wake up ;-) last dead message.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54uy-e/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1172,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54u4GE,incubator-stormcrawler,2025554308,1172,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-03-28T15:53:26Z,2024-03-28T15:53:26Z,https://groups.google.com/g/digitalpebble/c/QCtHhCQdJEU/m/Ztb4S7HTAAAJ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54u4GE/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1172,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54u5H3,incubator-stormcrawler,2025558519,1172,NA,rzo1,13417392,Richard Zowalla,,NA,2024-03-28T15:55:29Z,2024-03-28T15:55:29Z,Thx @jnioche ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc54u5H3/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1174,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1174,incubator-stormcrawler,2213594963,1174,Fix references to confluent.io artifact resolution,rzo1,13417392,Richard Zowalla,,CLOSED,2024-03-28T16:03:13Z,2024-03-28T16:11:57Z,"Build breaks due to

```bash
Warning:  Unable to obtain POM for artifact: io.confluent:kafka-schema-registry-client:jar:1.0:compile
org.apache.maven.project.ProjectBuildingException: Error resolving project artifact: Could not transfer artifact io.confluent:kafka-schema-registry-client:pom:1.0 from/to jvnet-nexus-releases (https://maven.java.net/content/repositories/releases/): transfer failed for https://maven.java.net/content/repositories/releases/io/confluent/kafka-schema-registry-client/1.0/kafka-schema-registry-client-1.0.pom for project io.confluent:kafka-schema-registry-client:jar:1.0
```","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1174/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1176,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1176,incubator-stormcrawler,2213619004,1176,replace storm-crawler by stormcrawler in pom files,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2024-03-28T16:15:20Z,2024-04-02T11:12:27Z,"For  consistency, they should probably use 'stormcrawler' instead

For instance

./external/solr/pom.xml:		<artifactId>storm-crawler-external</artifactId>

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1176/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1178,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1178,incubator-stormcrawler,2215113644,1178,Set version to 3.0 snapshot?,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2024-03-29T10:49:51Z,2024-04-02T11:43:56Z,"The next release (and first at Apache) will break backwards compatibility. Time for a new major release.
I don't think we should start at 0.1 like a totally new project as we have pre-Apache releases","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1178/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1178,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc540ruv,incubator-stormcrawler,2027076527,1178,NA,rzo1,13417392,Richard Zowalla,,NA,2024-03-29T10:59:09Z,2024-03-29T10:59:09Z,+1,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc540ruv/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1179,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1179,incubator-stormcrawler,2215128460,1179,Remove developer list section in pom,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2024-03-29T11:00:59Z,2024-04-02T09:23:10Z,"Add Tim, remove Jorge Luis Betancourt who has not contributed in recent years and is not on the PMC ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1179/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1179,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc542olH,incubator-stormcrawler,2027587911,1179,NA,ayushtkn,25608848,Ayush Saxena,ayushsaxena@apache.org,NA,2024-03-29T18:37:22Z,2024-03-29T18:37:22Z,"not sure how fancy is the approach to keep on maintaining the pom.xml with developer names, I have seen usually the names being maintained on the website of the project.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc542olH/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1179,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc543G4b,incubator-stormcrawler,2027712027,1179,NA,rzo1,13417392,Richard Zowalla,,NA,2024-03-29T20:35:00Z,2024-03-29T20:35:00Z,"> not sure how fancy is the approach to keep on maintaining the pom.xml with developer names, I have seen usually the names being maintained on the website of the project.

We just removed it in Storm recently; imho we can omit this section here too because it is cumbersome to maintain and the information will be accessible by looking into the project's roaster.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc543G4b/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1179,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc543InU,incubator-stormcrawler,2027719124,1179,NA,dave2wave,29803617,Dave Fisher,davefisher023@gmail.com,NA,2024-03-29T20:44:15Z,2024-03-29T20:44:15Z,"I agree. Really the project (PMC) as a whole is always the responsible developer. The committee members and committers are trusted by the PMC as a whole. Putting the developers names in poms and such that will be part of a release may expose these individuals when as a whole the PMC is within the ""Legal Shield"" of the ASF. **Releases are an act of the ASF through the delegation of those duties to a PMC**

Having a list on the website (or the PMC keeping one) can be helpful in order to sort out names, emails, apache ids, and GitHub ids. It can get confusing who is saying what. If the list is public then it's fair to make it be opt-in.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc543InU/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1179,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc55Feia,incubator-stormcrawler,2031478938,1179,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-04-02T09:14:02Z,2024-04-02T09:14:02Z,"Thanks everyone for your comments. This section made sense when the project was outside ASF but not anymore.
I have removed it in #1181 ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc55Feia/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1187,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1187,incubator-stormcrawler,2224849492,1187,Build website,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2024-04-04T08:33:15Z,2024-04-18T08:37:43Z,"There is currently no ASF website for StormCrawler

https://stormcrawler.net/ points to the pre-ASF site
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1187/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1187,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56jQz5,incubator-stormcrawler,2056064249,1187,NA,rzo1,13417392,Richard Zowalla,,NA,2024-04-15T08:07:52Z,2024-04-15T08:07:52Z,"@pjfanning Can we request a new repository `incubator-stormcrawler-site` for the website? Or is there any restriction on the incubator part for the amount of repos?

As an initial version, we can migrate the content from our ""website"" branch to it and change it towards ASF requirements. In a next step, we can work on a re-ramp.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56jQz5/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1187,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56kJTS,incubator-stormcrawler,2056295634,1187,NA,pjfanning,11783444,PJ Fanning,,NA,2024-04-15T08:57:43Z,2024-04-15T08:57:43Z,"> @pjfanning Can we request a new repository `incubator-stormcrawler-site` for the website? Or is there any restriction on the incubator part for the amount of repos?
> 
> As an initial version, we can migrate the content from our ""website"" branch to it and change it towards ASF requirements. In a next step, we can work on a re-ramp.

There is no limit on number of repos for incubating projects. Raise an INFRA JIRA. We can create repos using the selfserve tool but this one is special but its content is published to the Apache CDN automatically.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56kJTS/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1187,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56kLpH,incubator-stormcrawler,2056305223,1187,NA,rzo1,13417392,Richard Zowalla,,NA,2024-04-15T09:00:42Z,2024-04-15T09:00:42Z,Thanks. Here is the Jira: https://issues.apache.org/jira/browse/INFRA-25715,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56kLpH/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1187,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56mVpX,incubator-stormcrawler,2056870487,1187,NA,rzo1,13417392,Richard Zowalla,,NA,2024-04-15T13:33:28Z,2024-04-15T13:33:28Z,"Infra says we can do it ourselves, so will give it a try later.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56mVpX/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1187,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56mhYH,incubator-stormcrawler,2056918535,1187,NA,pjfanning,11783444,PJ Fanning,,NA,2024-04-15T13:53:00Z,2024-04-15T13:53:00Z,"We can create the git repo itself - what we can't do is set it up so that its contents are published to the Apache CDN.

https://selfserve.apache.org/","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56mhYH/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1187,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56myGt,incubator-stormcrawler,2056987053,1187,NA,rzo1,13417392,Richard Zowalla,,NA,2024-04-15T14:23:26Z,2024-04-15T14:23:26Z,Not via asf.yml? We will see 😁,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56myGt/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1187,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56pWVM,incubator-stormcrawler,2057659724,1187,NA,rzo1,13417392,Richard Zowalla,,NA,2024-04-15T19:33:42Z,2024-04-15T19:33:42Z,"Seems to work. The migrated source is here https://github.com/apache/incubator-stormcrawler-site/
The website is reachable via https://stormcrawler.apache.org/ and now needs some work regarding:

- Drop 3rd party content (google analytics, ...)
- Migrate resources to be hosted locally, etc.
- Comply with ASF requirements
- Add mailinglists, etc.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56pWVM/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1187,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56-_mb,incubator-stormcrawler,2063333787,1187,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-04-18T08:37:43Z,2024-04-18T08:37:43Z,"thanks @rzo1 
let's track the work needed for the website in https://github.com/apache/incubator-stormcrawler-site/","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56-_mb/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1188,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1188,incubator-stormcrawler,2229285494,1188,Upgrade dependency Storm 2.6.2,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2024-04-06T15:01:08Z,2024-05-06T06:28:46Z,"https://storm.apache.org/2024/04/05/storm262-released.html

Storm 2.6.2 brings some much needed dependency upgrades and cleanup. The latter will benefit the WARC module in particular.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1188/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1190,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1190,incubator-stormcrawler,2230268432,1190,Documentation Bug: website url in 'Project Info' table is not found,harikrishna553,4006916,Harikrishna,,CLOSED,2024-04-08T05:07:02Z,2024-04-15T20:02:18Z,Go to the url https://incubator.apache.org/projects/stormcrawler.html and Click in the reference link against 'Website' item in 'Project Info' table to reproduce the issue,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1190/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1190,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56Eu0-,incubator-stormcrawler,2048060734,1190,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-04-10T17:03:00Z,2024-04-10T17:03:00Z,"Thanks @harikrishna553 
This is a duplicate of #1187. The link against website will be correct once the website is built","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56Eu0-/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1190,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56phw2,incubator-stormcrawler,2057706550,1190,NA,rzo1,13417392,Richard Zowalla,,NA,2024-04-15T20:02:18Z,2024-04-15T20:02:18Z,The former website is now migrated and available via https://stormcrawler.apache.org/ - we will address some changes with #1187 to comply with ASF requirements in the near future. Stay tuned :),"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56phw2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1191,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1191,incubator-stormcrawler,2243801808,1191,Continuing ES use 2.11+,sam-ulrich1,40002776,Sam Ulrich,,CLOSED,2024-04-15T14:14:07Z,2024-04-15T16:11:07Z,"What kind of issue is this?

 - [ ] Question. This issue tracker is not the best place for questions. If you want to ask how to do
       something, or to understand why something isn't working the way you expect it to, use StackOverflow
       instead with the label 'stormcrawler': https://stackoverflow.com/questions/tagged/stormcrawler 

 - [ ] Bug report. If you’ve found a bug, please include a test if you can, it makes it a lot easier to fix things. Use the label 'bug' on the issue.
 
 - [x ] Feature request. Please use the label 'wish' on the issue.

Thanks!

Please permit the continued use of ES. Migrating clusters may be viable in the future but a minor version jump with the major breaking change of no more ES is difficult to stomach
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1191/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1191,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56nO9b,incubator-stormcrawler,2057105243,1191,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-04-15T15:14:21Z,2024-04-15T15:14:21Z,"Hi @sam-ulrich1 (long time no see, I hope you are well)

The next release (and first at Apache) will be a major one so incompatibilities are expected. One of the advantages of SC is its modularity - you could totally piggyback the code for Elastic from previous releases and maintain it in your own repository.
 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56nO9b/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1191,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56nkIa,incubator-stormcrawler,2057191962,1191,NA,sam-ulrich1,40002776,Sam Ulrich,,NA,2024-04-15T15:54:06Z,2024-04-15T15:54:06Z,"@jnioche Been well! If anything take it as a compliment that it's been a while. SC has been basically bullet-proof since we last spoke. There's more maintenance on keeping the seed lists good than on the SC deployment!

Currently I am just using the old SC version for the ES plugin and it seems to be working. I definitely get the problem with ES, they really screwed things up. Is the reason y'all are removing because you don't want to maintain compact for both versions?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56nkIa/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1191,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56nrVI,incubator-stormcrawler,2057221448,1191,NA,sam-ulrich1,40002776,Sam Ulrich,,NA,2024-04-15T16:08:16Z,2024-04-15T16:08:16Z,Closing since it has been acknowledged that this isn't a priority,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56nrVI/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1191,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56nsyG,incubator-stormcrawler,2057227398,1191,NA,rzo1,13417392,Richard Zowalla,,NA,2024-04-15T16:11:06Z,2024-04-15T16:11:06Z,"@sam-ulrich1 since we are going ASF, WE need to comply with licensing. I.e. we can either stick with an old and outdated version, remove it or ship with optional dependency, so user needs to add the lib.  We did opt for remove.

Nevertheless, the code didn't changed much, so  it is possible to fork that module and maintain it outside the ASF umbrella.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56nsyG/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1193,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1193,incubator-stormcrawler,2244554793,1193,add incubator footer to stormcrawler web site ,pjfanning,11783444,PJ Fanning,,CLOSED,2024-04-15T20:29:07Z,2024-04-24T08:44:48Z,"See footer in https://streampark.apache.org/

In Apache Pekko, we were told off for not using the Apache Incubator logo with a white background.

See https://incubator.apache.org/guides/press-kit.html - it has the official white background logo

Also, in the docs we need to say 'Apache StormCrawler (Incubating)' as opposed to just plain  'Apache StormCrawler'.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1193/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1193,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56_DLc,incubator-stormcrawler,2063348444,1193,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-04-18T08:45:23Z,2024-04-18T08:45:23Z,"Tracking in https://github.com/apache/incubator-stormcrawler-site/issues/5
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56_DLc/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1193,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56_OhN,incubator-stormcrawler,2063394893,1193,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-04-18T09:09:15Z,2024-04-18T09:09:15Z,"Have added mentions of (Incubating) as part of 

[asf-site b7b1461] Added refs to Incubating + minor fixes to main page. Fixed links in header
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc56_OhN/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1193,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc57pRm0,incubator-stormcrawler,2074417588,1193,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-04-24T08:44:47Z,2024-04-24T08:44:47Z,The footer has been added,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc57pRm0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1194,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1194,incubator-stormcrawler,2245638473,1194,Delete branch gh-pages,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2024-04-16T09:59:28Z,2024-04-16T10:00:16Z,"The source of the site is in [a separate repository](https://github.com/apache/incubator-stormcrawler-site), there is no more need for the gh-pages branch in this repo","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1194/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1196,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1196,incubator-stormcrawler,2261253700,1196,Update Releases Page in GitHub and mark non-ASF releases,rzo1,13417392,Richard Zowalla,,CLOSED,2024-04-24T13:04:34Z,2024-04-30T07:00:40Z,"I noticed in some of the incubator vote threads, that people complained about ""pre-ASF"" releases on other projects.

Since we have those on https://github.com/apache/incubator-stormcrawler/releases too, we can prevent that before doing our first release.

I think, that we have two possibilities:

- (1) Mark every release listed there with a disclaimer like:

> This release was created and published prior to StormCrawler entering incubation at the Apache Software Foundation. Any subsequent developments or changes related to StormCrawler's status within the Apache Software Foundation are not reflected in this release.

- (2) Drop these releases from the overview in GitHub.


WDYT @jnioche @pjfanning ?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1196/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1196,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc57zw2y,incubator-stormcrawler,2077167026,1196,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-04-25T13:20:58Z,2024-04-25T13:20:58Z,"I think some users would like to be able to access the old releases, e.g. to get the source of the Elastic module and maintain it separately.
Option 1 would be better, maybe just for the first page of results. ","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc57zw2y/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1196,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58P0vt,incubator-stormcrawler,2084522989,1196,NA,rzo1,13417392,Richard Zowalla,,NA,2024-04-30T07:00:40Z,2024-04-30T07:00:40Z,I have added disclaimers for the first two pages. Should be sufficient (imho).,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58P0vt/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1197,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1197,incubator-stormcrawler,2265849916,1197,Allow to disable SSL/TLS verification in OpenSearchConnection,rzo1,13417392,Richard Zowalla,,CLOSED,2024-04-26T13:58:20Z,2024-04-29T15:19:10Z,"# Proposal

It might be useful for test  deployments of opensearch to ignore SSL/TLS certificate errors or cert path validation errors.

While one can start opensearch without security enabled, it might be worth to have an option to disable SSL/TLS checks for opensearch connections.

This is especially useful, if you operate on containers without access to the actual java certstore. Of course, it might be preferable to just use real world certificates, but having this option won't hurt.

This can be achieved by adding

```java
    SSLContextBuilder sslContext = new SSLContextBuilder();
    sslContext.loadTrustMaterial(null, new TrustAllStrategy());
     httpClientBuilder.setSSLContext(sslContext.build());
     httpClientBuilder.setSSLHostnameVerifier(NoopHostnameVerifier.INSTANCE);
                
```
in `OpenSearchConnection`.

Property could be named `opensearch.disable.tls.validation` (default: false).
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1197/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1197,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc578yGj,incubator-stormcrawler,2079531427,1197,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-04-26T14:41:35Z,2024-04-26T14:41:35Z,"yes, makes sense","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc578yGj/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1198,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1198,incubator-stormcrawler,2265861063,1198,Allow to add a custom DNS suffix to OpenSearch Node addresses returned by Sniffer,rzo1,13417392,Richard Zowalla,,CLOSED,2024-04-26T14:04:03Z,2024-05-05T09:18:04Z,"# Proposal

Currently, `opensearch.sniffer` is enabled by default. This will automatically return cluster members of an open search cluster and use those hostnames in client queries.

If you have a simple k8s deployment using the recommended way to set things up (opensearch operator), you will have something like:

```
ip              heap.percent ram.percent cpu load_1m load_5m load_15m node.role node.roles           cluster_manager name
192.168.246.253           17          64   3    0.27    0.43     0.45 dm        cluster_manager,data *               opensearch-sc-masters-1
192.168.129.88             9          65   3    0.08    0.09     0.14 dm        cluster_manager,data -               opensearch-sc-masters-0
192.168.174.52            47          63   3    2.41    2.43     2.14 dm        cluster_manager,data -               opensearch-sc-masters-2

```

However, those cluster member names liek `opensearch-sc-masters-XXX` aren't resolveable by clients connecting.

We would need to append the `cluster name`, which was set during creation of the resource: `opensearch-sc`. 

Thus, the correct and resolvable member url would be

```
opensearch-sc-masters-0.opensearch-sc
```

We could add the required suffix for such a use-case in a sniffer implementation, which can add this suffix by loading it from the configuration. The default (for non k8s usage) would remain unchanged.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1198/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1198,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58IA2L,incubator-stormcrawler,2082475403,1198,NA,rzo1,13417392,Richard Zowalla,,NA,2024-04-29T11:29:15Z,2024-04-29T11:29:15Z,This is not an actual issue if `sniffing` is disabled _or_ the k8s operated resources are configured correctly. Closing.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58IA2L/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1200,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1200,incubator-stormcrawler,2269221832,1200,Fix license headers,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2024-04-29T14:37:03Z,2024-04-30T06:52:20Z,"Ayush Saxena reported some files having ""Licensed to DigitalPebble Ltd under one or more"" ...","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1200/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1202,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1202,incubator-stormcrawler,2270646844,1202,Add Release Documentation,rzo1,13417392,Richard Zowalla,,CLOSED,2024-04-30T06:52:36Z,2024-05-01T09:24:24Z,as the title says,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1202/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1204,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1204,incubator-stormcrawler,2271859754,1204,Documentation site has path collision on case sensitive file systems.,joshfischer1108,5785700,Josh Fischer,josh@joshfischer.io,CLOSED,2024-04-30T15:42:20Z,2024-04-30T18:04:36Z,"When  cloning the website directory to a OSX machine I get the following output:

```bash
git clone git@github.com:apache/incubator-stormcrawler-site.git
Cloning into 'incubator-stormcrawler-site'...
.. removed for brevity... 
warning: the following paths have collided (e.g. case-sensitive paths
on a case-insensitive filesystem) and only one from the same
colliding group is in the working tree:

  'img/Logo.png'
  'img/logo.png'
```

I'll put in a PR to address this, unless someone has an objection.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1204/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1204,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58UZzg,incubator-stormcrawler,2085723360,1204,NA,rzo1,13417392,Richard Zowalla,,NA,2024-04-30T15:44:06Z,2024-04-30T15:44:06Z,Feel free!,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58UZzg/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1205,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1205,incubator-stormcrawler,2274162435,1205,3.0 archetype does not exist (README Instructions),joshfischer1108,5785700,Josh Fischer,josh@joshfischer.io,CLOSED,2024-05-01T20:41:31Z,2024-05-06T06:27:45Z,"Following the README, it states to execute the below to create a new StormCrawler project.  
```
mvn archetype:generate -DarchetypeGroupId=org.apache.stormcrawler -DarchetypeArtifactId=stormcrawler-archetype -DarchetypeVersion=3.0
```
However, the above command results in the below error:
```
[WARNING] The POM for org.apache.stormcrawler:stormcrawler-archetype:jar:3.0 is missing, no dependency information available
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  3.292 s
[INFO] Finished at: 2024-05-01T15:35:16-05:00
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-archetype-plugin:3.2.1:generate (default-cli) on project standalone-pom: The desired archetype does not exist (org.apache.stormcrawler:stormcrawler-archetype:3.0) -> [Help 1]
```

However, the documentation site has the a command that does work (listed below).  I can update the README with this value once we deem it's the right way to correct the documentation.
```
mvn archetype:generate -DarchetypeGroupId=com.digitalpebble.stormcrawler -DarchetypeArtifactId=storm-crawler-archetype -DarchetypeVersion=2.11
```","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1205/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1205,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58j5Dd,incubator-stormcrawler,2089783517,1205,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-05-02T07:20:52Z,2024-05-02T07:20:52Z,"thanks @joshfischer1108 
The instructions on the README will be correct once we publish our first release at Apache which hopefully will be soon.
Using the old digitalpebble releases is problematic.
What could be done though is to modify the README to add a comment about installing SC with `mvn clean install` then generate from the 3.0-SNAPSHOT archetype. Does that make sense?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58j5Dd/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1205,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58m0Mf,incubator-stormcrawler,2090550047,1205,NA,joshfischer1108,5785700,Josh Fischer,josh@joshfischer.io,NA,2024-05-02T13:49:11Z,2024-05-02T13:49:11Z,"Ok, that makes sense.  I will adjust the PR based on your recommendation.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58m0Mf/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1207,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1207,incubator-stormcrawler,2277556627,1207,Add forbidden-apis,tballison,6739646,Tim Allison,tallison@apache.org,CLOSED,2024-05-03T12:14:27Z,2024-05-05T09:17:35Z,"forbidden-apis makes for reproducible behavior and decreases the chances of surprise.

What kind of issue is this?

 - [ ] Question. This issue tracker is not the best place for questions. If you want to ask how to do
       something, or to understand why something isn't working the way you expect it to, use StackOverflow
       instead with the label 'stormcrawler': https://stackoverflow.com/questions/tagged/stormcrawler 

 - [ ] Bug report. If you’ve found a bug, please include a test if you can, it makes it a lot easier to fix things. Use the label 'bug' on the issue.
 
 - [ ] Feature request. Please use the label 'wish' on the issue.

Thanks!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1207/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1207,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58wXcp,incubator-stormcrawler,2093053737,1207,NA,tballison,6739646,Tim Allison,tallison@apache.org,NA,2024-05-03T13:44:26Z,2024-05-03T13:44:26Z,Working on this here: https://github.com/apache/incubator-stormcrawler/pull/1208,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58wXcp/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1207,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58wxAK,incubator-stormcrawler,2093158410,1207,NA,tballison,6739646,Tim Allison,tallison@apache.org,NA,2024-05-03T14:40:07Z,2024-05-03T14:40:07Z,"K, that's ready for review.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58wxAK/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1209,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1209,incubator-stormcrawler,2278472115,1209,Apple Silicon emulation issue in unit tests,joshfischer1108,5785700,Josh Fischer,josh@joshfischer.io,CLOSED,2024-05-03T21:48:27Z,2024-05-05T02:24:32Z,"When compiling Stormcrawler from source on Apple Silicon we are hitting timeout issues in selenium tests due to emulation issues. 
 
## Steps to reproduce:

Using an Apple M3:
From the top level directory run:
```
mvn clean install
```

First we get this warning.
```
The architecture 'amd64' for image 'selenium/standalone-chrome:120.0' (ID sha256:deff784da2138b912b66e2941cc976ced4ecba3a4e6941ca3bfa2b8c88886b75) does not match the Docker server architecture 'arm64'. This will cause the container to execute much more slowly due to emulation and may lead to timeout failures.
```
Then we get this error:
```
[ERROR] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 27.48 s <<< FAILURE! -- in org.apache.stormcrawler.protocol.selenium.ProtocolTest
[ERROR] org.apache.stormcrawler.protocol.selenium.ProtocolTest.testBlocking -- Time elapsed: 27.44 s <<< ERROR!
org.awaitility.core.ConditionTimeoutException: Condition with org.apache.stormcrawler.protocol.selenium.ProtocolTest was not fulfilled within 10 seconds.
```


Then the error should appear

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1209/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1209,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58zQ0Q,incubator-stormcrawler,2093813008,1209,NA,rzo1,13417392,Richard Zowalla,,NA,2024-05-03T21:55:50Z,2024-05-03T21:55:50Z,"Guess it is more or less an upstream thing: https://github.com/SeleniumHQ/docker-selenium/issues/1076

Might be worth adding a profile which exclude those tests from being run on arm64, or to write a vustom JUnit 5 extension to disable them in OSX ARM, or to try Geckodriver, or to play with the timeouts.

Guess we can start with increasing timeouts or switching to Geckodriver (which should be arm ready from cross reading).","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58zQ0Q/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1209,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58zUQE,incubator-stormcrawler,2093827076,1209,NA,joshfischer1108,5785700,Josh Fischer,josh@joshfischer.io,NA,2024-05-03T22:11:51Z,2024-05-03T22:11:51Z,"I'm looking at the test.  Are these the timeouts?  I've changed them to much higher values such as `100000` and the tests seem to timeout about the same time on my machine (which is around 27 seconds)

```
 timeouts.put(""implicit"", 10000);
timeouts.put(""pageLoad"", 10000);
timeouts.put(""script"", 10000);

conf.put(""selenium.timeouts"", timeouts);
```","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58zUQE/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1209,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58zVm9,incubator-stormcrawler,2093832637,1209,NA,joshfischer1108,5785700,Josh Fischer,josh@joshfischer.io,NA,2024-05-03T22:18:02Z,2024-05-03T22:18:02Z,I forgot to add the link.  [Here is where I am looking](https://github.com/apache/incubator-stormcrawler/blob/c1088fb3ff3ca9ca99bcce108d8bb2b40b97c094/core/src/test/java/org/apache/stormcrawler/protocol/selenium/ProtocolTest.java#L90),"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc58zVm9/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1211,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1211,incubator-stormcrawler,2278841502,1211,Check license of opensearch/Constants.java,ayushtkn,25608848,Ayush Saxena,ayushsaxena@apache.org,CLOSED,2024-05-04T08:28:47Z,2024-05-06T06:28:01Z,"What kind of issue is this?

 - [ ] Question. This issue tracker is not the best place for questions. If you want to ask how to do
       something, or to understand why something isn't working the way you expect it to, use StackOverflow
       instead with the label 'stormcrawler': https://stackoverflow.com/questions/tagged/stormcrawler 

 - [ ] Bug report. If you’ve found a bug, please include a test if you can, it makes it a lot easier to fix things. Use the label 'bug' on the issue.
 
 - [ ] Feature request. Please use the label 'wish' on the issue.

Thanks!

The license text seems not very standard :
https://github.com/apache/incubator-stormcrawler/blob/c1088fb3ff3ca9ca99bcce108d8bb2b40b97c094/external/opensearch/src/main/java/org/apache/stormcrawler/opensearch/Constants.java#L2

mentions
```
SPDX-FileCopyrightText: 2022 Presearch SPDX-License-Identifier: Apache-2.0 Licensed to Presearch
```
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1211/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1211,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc580Sxc,incubator-stormcrawler,2094083164,1211,NA,rzo1,13417392,Richard Zowalla,,NA,2024-05-04T08:47:43Z,2024-05-04T08:47:43Z,"Yep. Needs a fix. Good finding.
Wonder why Rat didn't spot.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc580Sxc/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1214,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1214,incubator-stormcrawler,2288906393,1214,Update Release Docs with Feedback from 3.0 RC2 Vote Thread,rzo1,13417392,Richard Zowalla,,CLOSED,2024-05-10T04:33:17Z,2024-05-13T09:03:49Z,"- Move Source before Maven
- Check Vote Mail Templates and Update accordingly","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1214/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1215,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1215,incubator-stormcrawler,2288910347,1215,Update RAT exclusions,rzo1,13417392,Richard Zowalla,,CLOSED,2024-05-10T04:36:23Z,2024-05-21T12:36:53Z,"During the vote for 3.0 RC2 we received some feedback related to missing license headers for specific file types such as YAML, etc.

We should update those files based in feedback from the general@ thread than.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1215/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1216,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1216,incubator-stormcrawler,2288911462,1216,Add RAT Exclusion File for standalone RAT,rzo1,13417392,Richard Zowalla,,CLOSED,2024-05-10T04:37:38Z,2024-06-21T08:53:06Z,As the title says. Not all people are using Maven to check via RAT. We should add an exclusion for the standalone case too.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1216/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1216,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6BtUGe,incubator-stormcrawler,2176139678,1216,NA,rzo1,13417392,Richard Zowalla,,NA,2024-06-18T13:43:22Z,2024-06-18T13:43:22Z,https://github.com/apache/incubator-stormcrawler/pull/1243,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6BtUGe/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1219,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1219,incubator-stormcrawler,2292762758,1219,Switch next release version to 3.1.0,rzo1,13417392,Richard Zowalla,,CLOSED,2024-05-13T13:03:28Z,2024-05-16T11:06:28Z,Feedback from @pjfanning via Slack. We should switch to the three digit version numbering scheme. ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1219/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1220,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1220,incubator-stormcrawler,2292764752,1220,Add a disclaimer for binary (test) artifacts ,rzo1,13417392,Richard Zowalla,,CLOSED,2024-05-13T13:04:26Z,2024-05-21T12:34:52Z,"Feedback by @pjfanning via Slack. We  might want to look at adding a file to the distribution that includes a description of the binary files and why they are safe 

> 
> + ./core/src/test/resources/tripadvisor.sitemap.xml.gz
>  + ./external/warc/src/test/resources/test.warc.gz
>  + ./external/warc/src/test/resources/unparsable-date.warc.gz
> 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1220/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1221,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1221,incubator-stormcrawler,2292769469,1221,Switch release source artifact to tar.gz,rzo1,13417392,Richard Zowalla,,CLOSED,2024-05-13T13:06:18Z,2024-05-21T12:36:23Z,"TAR.GZ is a way more common nowadays for source distributions. Either provide ZIP and TAR.GZ or switch to TAR.GZ only.

Also note:

Naming scheme should be 

> the incubating normally comes after the version number

so it becomes

apache-stormcrawler-3.0-incubating-source-release.zip","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1221/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1222,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1222,incubator-stormcrawler,2292774748,1222,Add a section to RELEASING.md which contains an IPMC vote template,rzo1,13417392,Richard Zowalla,,CLOSED,2024-05-13T13:08:45Z,2024-05-21T12:38:29Z,"We should have a vote template for the mail to general@a.o.

Note: We should add the git hash of the tag to this template.

We should also link to downloads.a.o instead of dist.a.o for the keys file.

Also fix broken link to https://github.com/apache/incubator-stormcrawler/blob/main/RELEASING.md","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1222/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1223,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1223,incubator-stormcrawler,2297269030,1223,"SOLR StatusUpdaterBolt ""deletion"" stream",mvolikas,115570991,Markos Volikas,,CLOSED,2024-05-15T08:55:34Z,2024-05-15T14:07:44Z,"In the Solr StatusUpdaterBolt, [declareOutputFields](https://github.com/apache/incubator-stormcrawler/blob/29bf627b91c2536f8b31ce8b8447c9e1a3be0074/external/solr/src/main/java/org/apache/stormcrawler/solr/persistence/StatusUpdaterBolt.java#L68) is overridden with an empty implementation.
As a result the stream ""deletion"" is not declared (see also [AbstractStatusUpdaterBolt](https://github.com/apache/incubator-stormcrawler/blob/29bf627b91c2536f8b31ce8b8447c9e1a3be0074/core/src/main/java/org/apache/stormcrawler/persistence/AbstractStatusUpdaterBolt.java#L270)), causing the exception:
`java.lang.IllegalArgumentException: Unknown stream ID: deletion`
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1223/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1223,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc594f5y,incubator-stormcrawler,2111962738,1223,NA,rzo1,13417392,Richard Zowalla,,NA,2024-05-15T09:05:24Z,2024-05-15T09:05:24Z,Thanks for the report! Do you want to open a PR addressing this issue?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc594f5y/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1226,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1226,incubator-stormcrawler,2302145874,1226,Add FileSpout TestCase for Custom Meta Data Injections,rzo1,13417392,Richard Zowalla,,CLOSED,2024-05-17T08:40:28Z,2024-05-17T09:02:21Z,as the title says,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1226/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1230,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1230,incubator-stormcrawler,2302732620,1230,Redirected sitemaps in SiteMapParserBolt / SiteMapFilter,mvolikas,115570991,Markos Volikas,,CLOSED,2024-05-17T13:17:07Z,2024-05-20T13:19:00Z,"Hi!

When the SiteMapParserBolt processes a redirected sitemap that contains links (see for example [http://sample-sitemap.xml](http://www.contexity.ch/sitemap_index.xml)), the [isSitemapKey is added](https://github.com/apache/incubator-stormcrawler/blob/0aad46b5c8a4ebcf455385272d742f8383c64e46/core/src/main/java/org/apache/stormcrawler/bolt/SiteMapParserBolt.java#L148-L150) only after the outlinks have been processed. If the SiteMapFilter is also enabled, then all the links are filtered out since the [SiteMapParserBolt.isSitemapKey is false](https://github.com/apache/incubator-stormcrawler/blob/0aad46b5c8a4ebcf455385272d742f8383c64e46/core/src/main/java/org/apache/stormcrawler/filtering/sitemap/SitemapFilter.java#L53-L54). This is fixed when the `metadata.setValue(isSitemapKey, ""true"")` is moved before the outlinks processing.

Also, the [sniff](https://github.com/apache/incubator-stormcrawler/blob/0aad46b5c8a4ebcf455385272d742f8383c64e46/core/src/main/java/org/apache/stormcrawler/bolt/SiteMapParserBolt.java#L377) method returns false for some sitemaps, because of the small `maxOffsetGuess`. For example, for this [sitemap](https://www.contexity.ch/post-sitemap.xml). This can be fixed by increasing `sitemap.offset.guess`, however, this might impact performance.

Should I create a PR with the fix for SiteMapParserBolt?
Should I take a shot at a different (efficient) way of ""sniffing"" a possible sitemap format?

Thanks,
Markos","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1230/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1230,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5-ODB1,incubator-stormcrawler,2117611637,1230,NA,rzo1,13417392,Richard Zowalla,,NA,2024-05-17T13:28:45Z,2024-05-17T13:28:45Z,"Feel free to provide a PR with a fix.
We can follow up with a more efficient approach in an additional PR. WDYT?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc5-ODB1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1236,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1236,incubator-stormcrawler,2307952785,1236,Fix Typos in SC,rzo1,13417392,Richard Zowalla,,CLOSED,2024-05-21T10:30:43Z,2024-05-21T12:40:57Z,"There are several typos present in the current code base, which can be fixed.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1236/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1238,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1238,incubator-stormcrawler,2308112005,1238,Avoid use of star imports,rzo1,13417392,Richard Zowalla,,CLOSED,2024-05-21T11:50:59Z,2024-05-21T17:13:15Z,"* imports aren't considered good practice. We should get rid of them.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1238/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1241,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1241,incubator-stormcrawler,2333380357,1241,Ensure SC can be build without a Docker environment,rzo1,13417392,Richard Zowalla,,CLOSED,2024-06-04T12:15:12Z,2024-06-21T08:52:20Z,"We should make use of `@Testcontainers(disabledWithoutDocker = true)` to avoid failures for people, who do not have Docker installed and just want to build from sources.


","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1241/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1241,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6BrAB-,incubator-stormcrawler,2175533182,1241,NA,rzo1,13417392,Richard Zowalla,,NA,2024-06-18T08:37:49Z,2024-06-18T08:37:49Z,This requires JUnit 5 -> https://github.com/apache/incubator-stormcrawler/issues/1244,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6BrAB-/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1244,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1244,incubator-stormcrawler,2359288725,1244,Migrate to JUnit 5,rzo1,13417392,Richard Zowalla,,CLOSED,2024-06-18T08:37:46Z,2024-06-21T08:52:20Z,"as the title says.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1244/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1246,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1246,incubator-stormcrawler,2391597115,1246,To allow ProxyManager return null (or empty proxy) for not using a proxy for some specific requests,chhsiao90,10794200,"Chun-Han, Hsiao",chhsiao90@gmail.com,OPEN,2024-07-05T01:01:43Z,2024-07-05T08:03:21Z,"What kind of issue is this?

 - [ ] Question. This issue tracker is not the best place for questions. If you want to ask how to do
       something, or to understand why something isn't working the way you expect it to, use StackOverflow
       instead with the label 'stormcrawler': https://stackoverflow.com/questions/tagged/stormcrawler 

 - [ ] Bug report. If you’ve found a bug, please include a test if you can, it makes it a lot easier to fix things. Use the label 'bug' on the issue.
 
 - [x] Feature request. Please use the label 'wish' on the issue.

In our use case, we have our own ProxyManager implementation, we'd like to have the flexibility to use proxies for some requests, but no proxy for other cases.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1246/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1246,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6Dtebv,incubator-stormcrawler,2209736431,1246,NA,chhsiao90,10794200,"Chun-Han, Hsiao",chhsiao90@gmail.com,NA,2024-07-05T01:02:15Z,2024-07-05T01:02:15Z,I'd like to create a PR for this.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6Dtebv/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1246,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6Dv_eH,incubator-stormcrawler,2210396039,1246,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-07-05T08:03:20Z,2024-07-05T08:03:20Z,"Yes please.
[ProxyManager](https://github.com/apache/incubator-stormcrawler/blob/dc84c569bc4fd94d3935a63478c00c8f3bfcbaca/core/src/main/java/org/apache/stormcrawler/proxy/ProxyManager.java#L29) could return an Optional<SCProxy> depending on the Metadata. The code in the protocol implementations would need changing accordingly","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6Dv_eH/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1247,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1247,incubator-stormcrawler,2391688634,1247,HttpProtocol (both okhttp and apache) race condition while having different proxies in different threads,chhsiao90,10794200,"Chun-Han, Hsiao",chhsiao90@gmail.com,OPEN,2024-07-05T03:14:06Z,2024-07-05T12:29:12Z,"What kind of issue is this?

 - [ ] Question. This issue tracker is not the best place for questions. If you want to ask how to do
       something, or to understand why something isn't working the way you expect it to, use StackOverflow
       instead with the label 'stormcrawler': https://stackoverflow.com/questions/tagged/stormcrawler 

 - [x] Bug report. If you’ve found a bug, please include a test if you can, it makes it a lot easier to fix things. Use the label 'bug' on the issue.
 
 - [ ] Feature request. Please use the label 'wish' on the issue.

### Reproduce steps

To reproduce it, we can run the HttpProtocol main function with many urls with MultiProxyFactory

the crawler.conf
```
config:
  http.agent.name: test
  http.proxy.manager: org.apache.stormcrawler.proxy.MultiProxyManager
  http.proxy.file: proxies
  http.robots.file.skip: true
```

the proxies file
```
http://first:password@proxy1:8888
http://second:password@proxy2:8888
```

### Root cause

The HttpProtocol (both okhttp and apache) is not thread-safe
- the same instance which was initiated by ProxyFactory may be used in different bolts (different workers) at same time
- the shared request/client builder was manipulated by different bolt/thread at same time

Example 1 (wrong proxy auth)
- (Thread 2) builder.setProxy(secondProxy)
- (Thread 1) builder.setProxy(firstProxy)
- (Thread 1) builder.setAuth(firstAuth)
- (Thread 2) builder.setAuth(secondAuth)
- (Thread 1) builder.build()
- We'll have firstProxy + secondAuth

Example 2 (wrong proxy used)
- (Thread 1) builder.setProxy(firstProxy)
- (Thread 1) builder.setAuth(firstAuth)
- (Thread 2) builder.setProxy(secondProxy)
- (Thread 2) builder.setAuth(secondAuth)
- (Thread 1) builder.build()
- Now both requests use the second proxy","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1247/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1247,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6Dv_tu,incubator-stormcrawler,2210397038,1247,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-07-05T08:03:58Z,2024-07-05T08:03:58Z,"thanks @chhsiao90, are you able to suggest a fix for it?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6Dv_tu/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1247,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6DxgJR,incubator-stormcrawler,2210792017,1247,NA,chhsiao90,10794200,"Chun-Han, Hsiao",chhsiao90@gmail.com,NA,2024-07-05T12:29:11Z,2024-07-05T12:29:11Z,"Sure, I can have a PR for it.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6DxgJR/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1248,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1248,incubator-stormcrawler,2392417101,1248,Use pre-compiled patterns for mime type matching in TikaParser,rzo1,13417392,Richard Zowalla,,CLOSED,2024-07-05T11:27:01Z,2024-07-05T14:24:22Z,"Currently, we compile a pattern for each mime type white list item each time it is parsed. Compiling a regex is very cost intensive. We can avoid it by pre-compiling early and re-use the pattern later.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1248/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1251,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1251,incubator-stormcrawler,2424905969,1251,Update to Storm 2.6.3,rzo1,13417392,Richard Zowalla,,CLOSED,2024-07-23T10:59:07Z,2024-08-15T18:07:20Z,as the title says,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1251/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1253,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1253,incubator-stormcrawler,2433769141,1253,Inquiry About StormCrawler Features and Capabilities,alikaz3mi,36949611,Ali Kazemi,,CLOSED,2024-07-28T06:06:52Z,2024-07-28T11:21:03Z,"I have a few specific questions regarding the usage and features of StormCrawler that I hope you could clarify:

Storage of Textual Information: When using StormCrawler with Elasticsearch as outlined in your documentation, will all the textual information from the crawled websites be stored directly in Elasticsearch?

Handling Multimedia Content: How does StormCrawler manage images and other multimedia content found on websites? Are these types of content also stored in Elasticsearch, or do they require a different approach or storage solution?

Crawling Authenticated Websites: Is StormCrawler capable of crawling websites that require user authentication? If so, how can I provide authentication details (e.g., usernames and passwords) to enable StormCrawler to access and crawl these sites?

Your insights and guidance on these questions would be immensely helpful for the successful implementation of my project. I am excited about the potential of using StormCrawler and look forward to understanding its full capabilities.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1253/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1253,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6GYKXD,incubator-stormcrawler,2254480835,1253,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-07-28T11:20:07Z,2024-07-28T11:20:07Z,"hi @alikaz3mi 

> Storage of Textual Information: When using StormCrawler with Elasticsearch as outlined in your documentation, will all the textual information from the crawled websites be stored directly in Elasticsearch?

The Elasticsearch module has been removed from SC due to licensing issues. You can use OpenSearch as an alternative. As explained in the documentation, the textual content of the pages is stored in the `content` index. A number of fields are configured to be indexed by default but this is extensible.

> Handling Multimedia Content: How does StormCrawler manage images and other multimedia content found on websites? Are these types of content also stored in Elasticsearch, or do they require a different approach or storage solution?

By default StormCrawler does not crawl or index multimedia files but it can be done (in fact several organisations do that with StormCrawler on a large scale). You will have to use a custom bolt to store the content - you could put it in OpenSearch but other forms of storage are probably more appropriate depending on your use case.

> Crawling Authenticated Websites: Is StormCrawler capable of crawling websites that require user authentication? If so, how can I provide authentication details (e.g., usernames and passwords) to enable StormCrawler to access and crawl these sites?

See https://github.com/apache/incubator-stormcrawler/wiki/Protocols
There is currently support for basic authentication, see https://github.com/apache/incubator-stormcrawler/blob/701999eb56c5ebe5632b012a2f0771d6538425aa/core/src/main/java/com/digitalpebble/stormcrawler/protocol/okhttp/HttpProtocol.java#L157

Please note that it is not currently possible to handle authentication per hostname or domain - only a single pair of username / password can be set. 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6GYKXD/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1253,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6GYKbM,incubator-stormcrawler,2254481100,1253,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-07-28T11:21:03Z,2024-07-28T11:21:03Z,@alikaz3mi will close this issue for now. Probably best to use the Discussions section instead of issues.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6GYKbM/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1254,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1254,incubator-stormcrawler,2468629011,1254,Incubator Branding Policy Compliance,rzo1,13417392,Richard Zowalla,,CLOSED,2024-08-15T18:08:16Z,2024-09-21T10:39:31Z,"This is a reminder, that we need to do 

> Are 3rd parties respecting and correctly using the podlings
name and brand? If not what actions has the PPMC taken to
correct this? Has the VP, Brand approved the project name?

Here is an example:
https://issues.apache.org/jira/browse/PODLINGNAMESEARCH-210

Based on:
https://incubator.apache.org/guides/names.html","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1254/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1254,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6Lr-cM,incubator-stormcrawler,2343560972,1254,NA,rzo1,13417392,Richard Zowalla,,NA,2024-09-11T12:40:22Z,2024-09-11T12:40:22Z,"Following the information in the issue, I can see the following sections:

1. GitHub shows only the Apache project StormCrawler, and projects in StormCrawler ecosystem, such as other extension or users of StormCrawler (some repos from before SC being donated to the ASF).
     https://github.com/search?q=stormcrawler&ref=commandbar

2. No result in OpenHub
     https://www.openhub.net/p?query=stormcrawler&sort=relevance

3. No result in Sourceforge:
https://sourceforge.net/directory/?q=stormcrawler

----

1. Trademarkia shows just 0 result
     http://www.trademarkia.com/trademarks-search.aspx?tn=stormcrawler

2. Trademarks Justia shows just 0 result
     https://trademarks.justia.com/search?q=stormcrawler

3. No results in uspto
    https://search.uspto.gov/search?query=stormcrawler&op=Search&affiliate=web-sdmg-uspto.gov
----

1. No other software showed in Google search
   https://www.google.com/search?q=stormcrawler

2. StackOverflow:
   https://stackoverflow.com/search?q=stormcrawler
   All records are about seatunnel users’ Q&A.

3. No results for StormCrawler in Google Code
  https://opensource.google/projects?q=stormcrawler&text=stormcrawler

4. No other software showed in Bing search
   https://www.bing.com/search?q=stormcrawler

5. No other software showed in Yahoo search
   https://search.yahoo.com/search?p=stormcrawler","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6Lr-cM/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1254,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6LsA06,incubator-stormcrawler,2343570746,1254,NA,rzo1,13417392,Richard Zowalla,,NA,2024-09-11T12:44:51Z,2024-09-11T12:44:51Z,Openend https://issues.apache.org/jira/browse/PODLINGNAMESEARCH-224 to check for compliance.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6LsA06/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1254,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6M-SgY,incubator-stormcrawler,2365138968,1254,NA,rzo1,13417392,Richard Zowalla,,NA,2024-09-21T10:39:13Z,2024-09-21T10:39:13Z,Name is approved.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6M-SgY/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1257,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1257,incubator-stormcrawler,2507052407,1257,Storm 2.6.4,rzo1,13417392,Richard Zowalla,,CLOSED,2024-09-05T07:53:04Z,2024-09-05T17:19:30Z,,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1257/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1259,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1259,incubator-stormcrawler,2507063992,1259,Enable Dependabot,rzo1,13417392,Richard Zowalla,,CLOSED,2024-09-05T07:58:17Z,2024-09-05T17:16:20Z,It might be a good thing to have dependabot enabled even if we decide to not merge every update for reasons.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1259/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1261,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1261,incubator-stormcrawler,2507070009,1261,Automatically generate THIRD-PARTY.txt via GitHub Action workflow.,rzo1,13417392,Richard Zowalla,,CLOSED,2024-09-05T08:00:25Z,2024-09-05T17:17:19Z,"We tend to forget to re-generate the THIRD-PARTY.txt license information file. This can be solved via GitHub actions.
If the file isn't up 2 date, we re-generate via GitHub actions and create a PR with the changes.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1261/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1290,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1290,incubator-stormcrawler,2513892310,1290,Add close/cleanup method to ParseFilters,rzo1,13417392,Richard Zowalla,,CLOSED,2024-09-09T12:54:19Z,2024-09-10T04:39:40Z,"A `ParseFilter` might use resources, which need to be cleaned after usage or shutdown, e.g. database connection pools, etc.

We can add a `cleanup()` or `close()` method to `ParseFilter` as well as in `ParseFilters`, so this hook can be called from the cleanup method of the related bolts called be the Storm framework.

This change shouldn't employ any compatibility issues but rather provide a way to plug this functionality in (for users) if needed.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1290/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1295,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1295,incubator-stormcrawler,2519623175,1295,Add workflow to publish SNAPSHOTS to repository.a.o,rzo1,13417392,Richard Zowalla,,CLOSED,2024-09-11T12:32:51Z,2024-09-11T18:09:42Z,as the title says.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1295/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1298,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1298,incubator-stormcrawler,2524336418,1298,Jacoco Coverage doesn't meet specified criteria if run in release mode,rzo1,13417392,Richard Zowalla,,OPEN,2024-09-13T09:21:54Z,2024-11-15T14:01:56Z,"If run in release mode 

` mvn release:prepare -Papache-release,apache`

coverage requirements are not meet on my M3 macbook (while they seem to work correctly on GitHub actions).

This issue is created to track this behaviour. 

The reason for it is, that if docker is not available (and tests are skipped), the coverage criteria is not meet and the build is failing. This should be fixed for 3.1.1 or 3.2.0.

Might be good to just put that into a profile and run that profile in CI only, so we get information about coverage or a failed build but don't get bothered while running a release on a system without docker.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1298/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1298,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6M7FKC,incubator-stormcrawler,2364297858,1298,NA,sigee,6528240,Dávid Szigecsán,,NA,2024-09-20T18:29:38Z,2024-09-20T18:29:38Z,"> The reason for it is, that if docker is not available (and tests are skipped), the coverage criteria is not meet and the build is failing. This should be fixed for 3.1.1 or 3.2.0.

If not all test cases are skipped and there is coverage, just not as much as in the criteria, you could decrease the threshold instead of disabling it. 
But I don't understand how it relates to docker, because I could run tests without docker.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6M7FKC/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1298,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6M7GmJ,incubator-stormcrawler,2364303753,1298,NA,rzo1,13417392,Richard Zowalla,,NA,2024-09-20T18:31:58Z,2024-09-20T18:31:58Z,"Some tests aren't executed, if docker isn't available in the executing system.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6M7GmJ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1298,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6RypNG,incubator-stormcrawler,2445972294,1298,NA,rzo1,13417392,Richard Zowalla,,NA,2024-10-30T06:25:01Z,2024-10-30T06:25:01Z,Guess a solution would be to decrease the thresholds to the coverage without docker (so the testcontainer tests are not executed and do not contribute to the coverage),"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6RypNG/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1299,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1299,incubator-stormcrawler,2526891177,1299,add DISCLAIMER to jars,pjfanning,11783444,PJ Fanning,,CLOSED,2024-09-15T12:25:56Z,2024-09-26T09:27:06Z,"The LICENSE and NOTICE are in the RC jars but not the DISCLAIMER. I'm not sure if it 100% required but many podlings include it.

I checked stormcrawler-core-3.1.0.jar
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1299/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1299,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6MKkqU,incubator-stormcrawler,2351581844,1299,NA,rzo1,13417392,Richard Zowalla,,NA,2024-09-15T12:55:17Z,2024-09-15T12:55:17Z,"It is required for release artifacts, which is the source artifact by ASF definition: https://apache.org/legal/release-policy.html#source-packages

Maven artifacts are convenience. I am not aware of an strict incubator policy for this class of files.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6MKkqU/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1299,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6MjEDA,incubator-stormcrawler,2358001856,1299,NA,pjfanning,11783444,PJ Fanning,,NA,2024-09-18T09:46:28Z,2024-09-18T09:46:28Z,The apache-parent pom.xml appears to have a feature to allow adding a disclaimer to jars. See https://github.com/apache/incubator-xtable/pull/539 (mainly for the code change).,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6MjEDA/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1300,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1300,incubator-stormcrawler,2526893104,1300,files in jars have odd dates,pjfanning,11783444,PJ Fanning,,CLOSED,2024-09-15T12:30:47Z,2024-10-01T08:01:50Z,"I checked the 3.1.0 RC jars and the files in stormcrawler-core-3.1.0.jar all had this date.

07-04-2024

I am in favour of reproducible builds meaning that files in jar may not have today's date but this date is confusing. Many reproducible builds just go with 01-01-1970 dates or some date hardcoded in build but that might reflect some date around the release (as long as the date is hardcoded in the source release so that all builds have this date regardless of when the build with that release is run.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1300/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1300,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6MKk4r,incubator-stormcrawler,2351582763,1300,NA,rzo1,13417392,Richard Zowalla,,NA,2024-09-15T12:58:08Z,2024-09-15T12:58:08Z,"Don't think we set it explicitly, so working towards reproducable builds would be good anyway.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6MKk4r/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1300,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6MKlZR,incubator-stormcrawler,2351584849,1300,NA,pjfanning,11783444,PJ Fanning,,NA,2024-09-15T13:04:22Z,2024-09-15T13:04:22Z,How did we end up with 7 April or 4 July as the date? (I'm not sure if the date in the file is in International or in US format),"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6MKlZR/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1300,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6MKl7Z,incubator-stormcrawler,2351587033,1300,NA,rzo1,13417392,Richard Zowalla,,NA,2024-09-15T13:10:27Z,2024-09-15T13:10:27Z,Guess it is a side effect from Apache Parent. Didn't dig into it though.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6MKl7Z/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1301,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1301,incubator-stormcrawler,2527030084,1301,add build doc for the source release,pjfanning,11783444,PJ Fanning,,CLOSED,2024-09-15T16:55:50Z,2024-10-30T08:14:54Z,"* IPMC members have to deal with a lot of podlings - it is useful to help them with build details
* there are test binaries in your source release and it is useful to explain why they are there - IPMC members are chacking for things like binary files in source releases and it is useful to explain why you need them
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1301/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1312,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1312,incubator-stormcrawler,2528236365,1312,sha512 hash of source release is missing the file part,rzo1,13417392,Richard Zowalla,,CLOSED,2024-09-16T11:46:08Z,2024-10-10T17:12:35Z,"Update release docs to manually update the sha512 hash of the source artifact to avoid ambiquity with unix command line tools, cf. https://lists.apache.org/thread/6mmpw5flzoyr09hlo4mnh4pthnfy33v2","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1312/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1313,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1313,incubator-stormcrawler,2528239228,1313,"Exclude ""__files"" from Source Release Artifacts",rzo1,13417392,Richard Zowalla,,CLOSED,2024-09-16T11:47:29Z,2024-10-30T08:05:22Z,During https://lists.apache.org/thread/6mmpw5flzoyr09hlo4mnh4pthnfy33v2 we found `__files` inside the source release. We should avoid that by adding some excludes for typical OSX files. Might be configurable by checking the ASF Parent POM,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1313/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1317,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1317,incubator-stormcrawler,2544381351,1317,Update version of StormCrawler in READMEs and archetypes,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2024-09-24T05:36:22Z,2024-10-19T11:17:09Z,The [website](https://stormcrawler.apache.org/getting-started/) also needs fixing,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1317/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1317,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6NVDFJ,incubator-stormcrawler,2371105097,1317,NA,rzo1,13417392,Richard Zowalla,,NA,2024-09-24T12:16:08Z,2024-09-24T12:16:08Z,@kunalpal97 would you like to check the website as well for similar occurences?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6NVDFJ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1317,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6NXDDp,incubator-stormcrawler,2371629289,1317,NA,kunalpal97,124446202,Kunal Pal ,,NA,2024-09-24T15:25:41Z,2024-09-24T15:25:41Z,"@rzo1  I’d be happy to help! Could you clarify which sections or pages of the website you'd like me to review, or should I go through the entire site?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6NXDDp/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1317,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6NXEuh,incubator-stormcrawler,2371636129,1317,NA,rzo1,13417392,Richard Zowalla,,NA,2024-09-24T15:28:22Z,2024-09-24T15:28:22Z,"The Link by @jnioche contains references to the archetype and the Storm version. There might be other occurences as well, maybe a search in an IDE will reveal other locations as well.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6NXEuh/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1317,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6NXW8k,incubator-stormcrawler,2371710756,1317,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-09-24T16:00:26Z,2024-09-24T16:00:26Z,"For the website here are my notes for the pre-Apache releases, the paths will need changing

```
git checkout gh-pages

point 
[_includes/header.html](https://github.com/DigitalPebble/storm-crawler/edit/gh-pages/_includes/header.html) to latest release

Modify “getting started” as well

[getting-started/index.html](https://github.com/DigitalPebble/storm-crawler/edit/gh-pages/getting-started/index.html)
```

For the READMEs in the repo

```
 README.md
 ./external/warc/README.md  
 ./external/opensearch/README.md
```

I used to `grep -r` on the previous version number to find occurrences.

Thanks @kunalpal97 for offering to contribute","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6NXW8k/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1317,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6Qd4o0,incubator-stormcrawler,2423753268,1317,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-10-19T10:42:02Z,2024-10-19T10:42:02Z,"for future reference, changes to the web site are made in https://github.com/apache/incubator-stormcrawler-site","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6Qd4o0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1317,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6Qd5iJ,incubator-stormcrawler,2423756937,1317,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-10-19T10:49:11Z,2024-10-19T10:49:11Z,"https://github.com/apache/incubator-stormcrawler-site/pull/32
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6Qd5iJ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1323,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1323,incubator-stormcrawler,2554190397,1323,Upgrade dependency Storm 2.6.4,mvolikas,115570991,Markos Volikas,,CLOSED,2024-09-28T12:14:08Z,2024-09-29T13:21:43Z,"The [maven archetype pom](https://github.com/apache/incubator-stormcrawler/blob/main/archetype/src/main/resources/archetype-resources/pom.xml#L35) has `storm.version 2.6.2`. When using this with `stormcrawler-solr` dependency a jetty version incompatibility issue arises. In particular, when submitting the shaded jar to Storm I get:
```
java.lang.IncompatibleClassChangeError:
class org.eclipse.jetty.http.HttpFields$Mutable can not implement org.eclipse.jetty.http.HttpFields,
because it is not an interface (org.eclipse.jetty.http.HttpFields is in unnamed module of loader 'app')
```
This is because Solr 9.6.1 uses Jetty 10.* while Storm 2.6.2 Jetty 9.*. Am I missing something?
When switching to storm 2.6.4 this gets resolved. Given that in storm-crawler 3.1.0 Storm 2.6.4 is used in the [main pom](https://github.com/apache/incubator-stormcrawler/blob/main/pom.xml#L68), maybe we could update the archetype pom to the latest version as well?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1323/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1323,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6N5XXx,incubator-stormcrawler,2380625393,1323,NA,rzo1,13417392,Richard Zowalla,,NA,2024-09-28T12:30:54Z,2024-09-28T12:30:54Z,Yes. It was missed in the update.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6N5XXx/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1323,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6N5Ywj,incubator-stormcrawler,2380631075,1323,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-09-28T12:53:59Z,2024-09-28T12:53:59Z,"@mvolikas if you write a PR for it, can you please also add a fix for the [core archetype ](archetype/src/main/resources/archetype-resources/pom.xml)? Thanks","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6N5Ywj/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1323,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6N5aKQ,incubator-stormcrawler,2380636816,1323,NA,mvolikas,115570991,Markos Volikas,,NA,2024-09-28T13:15:58Z,2024-09-28T13:15:58Z,@jnioche I cannot open the link you gave. I guess you mean this [pom](https://github.com/apache/incubator-stormcrawler/blob/main/archetype/src/main/resources/archetype-resources/pom.xml) right? This and the OpenSearch pom are the only places that have version 2.6.2.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6N5aKQ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1323,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6N6K8m,incubator-stormcrawler,2380836646,1323,NA,jnioche,218319,Julien Nioche,julien@digitalpebble.com,NA,2024-09-28T17:07:14Z,2024-09-28T17:07:14Z,"> @jnioche I cannot open the link you gave. I guess you mean this [pom](https://github.com/apache/incubator-stormcrawler/blob/main/archetype/src/main/resources/archetype-resources/pom.xml) right? This and the OpenSearch pom are the only places that have version 2.6.2.

yes, not sure where that link came from 
Thanks!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6N6K8m/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1339,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1339,incubator-stormcrawler,2559121635,1339,Reinstate support for Elasticsearch now that it's open source again,cbowdon,1069832,Chris Bowdon,,CLOSED,2024-10-01T12:46:06Z,2024-10-02T15:18:15Z,"Hi! Thanks for all your work on Stormcrawler, it's fantastically useful.

I appreciate that you removed support for Elasticsearch since it went closed-source. They've now got over their issues with AWS and [returned to a FOSS license (AGPL)](https://www.elastic.co/blog/elasticsearch-is-open-source-again). Would it be possible to add ES back in please?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1339/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1339,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6OPqJE,incubator-stormcrawler,2386469444,1339,NA,rzo1,13417392,Richard Zowalla,,NA,2024-10-01T16:31:01Z,2024-10-01T16:31:01Z,"AGPL is a category x license, cf. https://www.apache.org/legal/resolved.html#category-x which is a license we cannot include in a project under the ASF umbrella.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6OPqJE/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1339,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6OUnjq,incubator-stormcrawler,2387769578,1339,NA,cbowdon,1069832,Chris Bowdon,,NA,2024-10-02T07:07:05Z,2024-10-02T07:07:05Z,"Okay, disappointing but I understand. Thanks anyway.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6OUnjq/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1339,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6OUqNo,incubator-stormcrawler,2387780456,1339,NA,rzo1,13417392,Richard Zowalla,,NA,2024-10-02T07:14:06Z,2024-10-02T07:14:06Z,"You can just grab the elasticsearch module code before SC was donated to the ASF and put it directly into your project: https://github.com/apache/incubator-stormcrawler/commit/1e0dc43d882318f0209740901a21e3e09ce11a1a

 It is just a matter of copying some classes (the ones you actually need) and adding the necessary ES dependencies and updating imports. The code is still compatible.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6OUqNo/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1339,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6OZIAv,incubator-stormcrawler,2388951087,1339,NA,cbowdon,1069832,Chris Bowdon,,NA,2024-10-02T15:18:13Z,2024-10-02T15:18:13Z,That works. Thanks!,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6OZIAv/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1353,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1353,incubator-stormcrawler,2575057547,1353,URLFrontier spout doesn't take into account crawl Id,klockla,135588546,Laurent Klock,,CLOSED,2024-10-09T07:35:35Z,2024-10-25T13:09:21Z,"The URLFrontier Spout
( https://github.com/apache/incubator-stormcrawler/blob/main/external/urlfrontier/src/main/java/org/apache/stormcrawler/urlfrontier/Spout.java ) doesn't take into account the crawl Id that can be specified in the configuration parameters (URLFRONTIER_CRAWL_ID_KEY = ""urlfrontier.crawlid"" defined in  org.apache.stormcrawler.urlfrontier.Constants)

This results in a mix of URLs coming from distinct frontiers in URLFrontier.


","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1353/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1353,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6PJh4K,incubator-stormcrawler,2401639946,1353,NA,rzo1,13417392,Richard Zowalla,,NA,2024-10-09T08:10:41Z,2024-10-09T08:10:41Z,Would you Like to submit a PR with a fix?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6PJh4K/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1353,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6PJvS4,incubator-stormcrawler,2401694904,1353,NA,klockla,135588546,Laurent Klock,,NA,2024-10-09T08:36:07Z,2024-10-09T08:36:07Z,"> Would you Like to submit a PR with a fix?

Yes, I will but  won't be able to do before 2 weeks.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6PJvS4/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1354,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1354,incubator-stormcrawler,2577419160,1354,Should I fix some typos in project?,psxjoy,10711694,psxjoy,psxjoy@apache.org,CLOSED,2024-10-10T03:07:52Z,2024-10-10T07:19:21Z,"What kind of issue is this?

 - [X] Question. This issue tracker is not the best place for questions. If you want to ask how to do
       something, or to understand why something isn't working the way you expect it to, use StackOverflow
       instead with the label 'stormcrawler': https://stackoverflow.com/questions/tagged/stormcrawler 

 - [ ] Bug report. If you’ve found a bug, please include a test if you can, it makes it a lot easier to fix things. Use the label 'bug' on the issue.
 
 - [ ] Feature request. Please use the label 'wish' on the issue.

Thanks!
# Description
When I cloned the project and view some apis,I found some typos.
Should I make a PR to fix it? 
I think it will be a great idea for my first contribute to this project.

Feel free assign it to me when you think OK.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1354/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1354,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6PSQw-,incubator-stormcrawler,2403929150,1354,NA,rzo1,13417392,Richard Zowalla,,NA,2024-10-10T04:11:18Z,2024-10-10T04:11:18Z,Feel free.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6PSQw-/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1357,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1357,incubator-stormcrawler,2578093119,1357,Website Download Links are broken,rzo1,13417392,Richard Zowalla,,CLOSED,2024-10-10T08:38:47Z,2024-10-10T08:38:53Z,as the title says,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1357/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1357,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6PUTe0,incubator-stormcrawler,2404464564,1357,NA,rzo1,13417392,Richard Zowalla,,NA,2024-10-10T08:38:52Z,2024-10-10T08:38:52Z,Fixed with https://github.com/apache/incubator-stormcrawler-site/commit/2403b5129be5ebe9d3a056d0189d236c839226c9,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6PUTe0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1382,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1382,incubator-stormcrawler,2619233260,1382,Allow OpenSearch addresses to be specified as ; separated values in a single String,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2024-10-28T18:42:17Z,2024-11-03T14:56:24Z,"Addresses for connecting to an OpenSearch cluster can be set as a list

```
  opensearch.addresses: 
    - ""http://opensearch-node1:9200""
    - ""http://opensearch-node2:9200""
```

or a single String

`opensearch.addresses: ""http://opensearch-node1:9200""`

There are situations where we need to pass the values via environment variables or file substitution in which case being able to specify multiple values in a single string would help

`opensearch.addresses: ""http://opensearch-node1:9200;http://opensearch-node2:9200""`","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1382/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1385,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1385,incubator-stormcrawler,2626216295,1385,Entire tuple gets skipped if a single key is not found in the metadata,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2024-10-31T07:53:36Z,2024-10-31T10:51:11Z,"The new metadata record format[ iterates on the keys](https://github.com/apache/incubator-stormcrawler/blob/main/external/warc/src/main/java/org/apache/stormcrawler/warc/MetadataRecordFormat.java#L71) but since the values returned can be null, this triggers and exception in the for-each loop and the entire tuple gets skipped. Instead we should check whether the returned values are null and if so proceed with the next key.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1385/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1389,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1389,incubator-stormcrawler,2631236384,1389,Archetype generated Java topology misses class import,rzo1,13417392,Richard Zowalla,,CLOSED,2024-11-03T14:19:26Z,2024-11-12T15:34:39Z,"Archetyp misses an import for 

```
import org.apache.stormcrawler.ConfigurableTopology;
```

resulting in a compiliation error.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1389/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1389,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6SPLRV,incubator-stormcrawler,2453451861,1389,NA,rzo1,13417392,Richard Zowalla,,NA,2024-11-03T14:41:57Z,2024-11-03T14:41:57Z,"I just sent a mail to dev@ asking if we really want to keep these Java-based topology classes in the archetypes. Since it has been broken for a long time and no one has really complained, it is a clear sign that no one is actually using it.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6SPLRV/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1396,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1396,incubator-stormcrawler,2632235258,1396,Prevent Dependabot from suggesting dependency updates for Jackson,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2024-11-04T09:05:03Z,2024-12-02T14:21:34Z,"We need to use whatever Storm uses, which is not necessarily the latestt

See https://github.com/apache/incubator-stormcrawler/pull/1391#issuecomment-2454148742","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1396/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1396,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6TtuTJ,incubator-stormcrawler,2478236873,1396,NA,rzo1,13417392,Richard Zowalla,,NA,2024-11-15T08:38:04Z,2024-11-15T08:38:04Z,Here is an example: https://github.com/apache/shiro/blob/main/.github/dependabot.yml,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6TtuTJ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1396,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6Txx38,incubator-stormcrawler,2479300092,1396,NA,dave2wave,29803617,Dave Fisher,davefisher023@gmail.com,NA,2024-11-15T15:58:25Z,2024-11-15T15:58:25Z,"2.17.3 was released 2 days after 2.18.1 about 2 weeks ago.

Should StormCrawler stay on the exact same version or the same line? EG. Storm is on 2.17.2 while SC is 2.17.3?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6Txx38/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1397,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1397,incubator-stormcrawler,2632611392,1397,Update Tika to 3.0.0,tballison,6739646,Tim Allison,tallison@apache.org,CLOSED,2024-11-04T11:53:05Z,2024-11-04T14:55:17Z,"What kind of issue is this?

 - [ ] Question. This issue tracker is not the best place for questions. If you want to ask how to do
       something, or to understand why something isn't working the way you expect it to, use StackOverflow
       instead with the label 'stormcrawler': https://stackoverflow.com/questions/tagged/stormcrawler 

 - [ ] Bug report. If you’ve found a bug, please include a test if you can, it makes it a lot easier to fix things. Use the label 'bug' on the issue.
 
 - [ ] Feature request. Please use the label 'wish' on the issue.

- [*] Task. Upgrade dependencies.
Thanks!

I got a clean build locally with Tika 3.0.0 when I removed the aged commons-io version from dependency management. I realize that was there for an older version of hadoop. 

Does a clean build mean that we're good to go, or is it possible that I've just broken everything for hadoop? What other tests should I run (if any)?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1397/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1397,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6STfB1,incubator-stormcrawler,2454581365,1397,NA,pjfanning,11783444,PJ Fanning,,NA,2024-11-04T12:24:15Z,2024-11-04T12:24:15Z,"I contribute some dependency upgrades for Hadoop and I don't believe that commons-io presented any issues.

https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-common/3.4.1

That version uses a quite up to date commons-io.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6STfB1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1397,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6ST6eK,incubator-stormcrawler,2454693770,1397,NA,tballison,6739646,Tim Allison,tallison@apache.org,NA,2024-11-04T13:17:12Z,2024-11-04T13:17:12Z,"Looks like sc is still on hadoop-common 3.3.6 -- storm hdfs 2.6.2 brings in hadoop-common 3.3.6, which is commons-io 2.8.0.

If we bumped storm to 2.7.0, that'd bring hadoop to 3.4.0 and commons 2.14.0.

On Nutch, there are some local hadoop integration tests that would fail if there were a dependency problem. Do we have anything similar on sc or do we upgrade and hope that our unit tests show problems?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6ST6eK/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1397,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6SUoGY,incubator-stormcrawler,2454880664,1397,NA,pjfanning,11783444,PJ Fanning,,NA,2024-11-04T14:35:43Z,2024-11-04T14:35:43Z,What I meant is that commons-io seems to maintain good backward compatibility across releases.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6SUoGY/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1397,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6SUpQv,incubator-stormcrawler,2454885423,1397,NA,tballison,6739646,Tim Allison,tallison@apache.org,NA,2024-11-04T14:37:40Z,2024-11-04T14:37:40Z,Sorry. Thank you.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6SUpQv/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1397,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6SU0Q1,incubator-stormcrawler,2454930485,1397,NA,tballison,6739646,Tim Allison,tallison@apache.org,NA,2024-11-04T14:55:17Z,2024-11-04T14:55:17Z,:face_palm: this is already done. I hadn't updated my fork in some time. Sorry...,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6SU0Q1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1401,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1401,incubator-stormcrawler,2650151606,1401,Drop Java-based Topologies,rzo1,13417392,Richard Zowalla,,CLOSED,2024-11-11T19:08:44Z,2024-11-15T14:16:21Z,"As discussed on the list, we should remove those topology classes from the code base.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1401/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1401,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6TRe6R,incubator-stormcrawler,2470833809,1401,NA,mvolikas,115570991,Markos Volikas,,NA,2024-11-12T15:25:44Z,2024-11-12T15:25:44Z,"@rzo1 I could take this over.
This means we can close #1389 right?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6TRe6R/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1401,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6TRhNA,incubator-stormcrawler,2470843200,1401,NA,rzo1,13417392,Richard Zowalla,,NA,2024-11-12T15:29:24Z,2024-11-12T15:29:24Z,Yes,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6TRhNA/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1403,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1403,incubator-stormcrawler,2655846864,1403,Downgrade log4j2 2.24.1 for now,tballison,6739646,Tim Allison,tallison@apache.org,CLOSED,2024-11-13T15:17:22Z,2024-11-15T14:16:10Z,"What kind of issue is this?

 - [ ] Question. This issue tracker is not the best place for questions. If you want to ask how to do
       something, or to understand why something isn't working the way you expect it to, use StackOverflow
       instead with the label 'stormcrawler': https://stackoverflow.com/questions/tagged/stormcrawler 

 - [*] Bug report. If you’ve found a bug, please include a test if you can, it makes it a lot easier to fix things. Use the label 'bug' on the issue.
 
 - [ ] Feature request. Please use the label 'wish' on the issue.

Out of an abundance of caution, we may want to downgrade log4j2 to the version that Storm is using.

References

https://lists.apache.org/thread/bkb5y7mj3v3sld9sbk4r6jgmccs4k61j
https://github.com/apache/logging-log4j2/issues/3143
https://github.com/apache/logging-log4j2/issues/3196","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1403/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1405,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1405,incubator-stormcrawler,2655964688,1405,Bump development version to 3.2.0-SNAPSHOT,tballison,6739646,Tim Allison,tallison@apache.org,CLOSED,2024-11-13T15:52:34Z,2024-11-13T17:33:03Z,"What kind of issue is this?

 - [ ] Question. This issue tracker is not the best place for questions. If you want to ask how to do
       something, or to understand why something isn't working the way you expect it to, use StackOverflow
       instead with the label 'stormcrawler': https://stackoverflow.com/questions/tagged/stormcrawler 

 - [ ] Bug report. If you’ve found a bug, please include a test if you can, it makes it a lot easier to fix things. Use the label 'bug' on the issue.
 
 - [ ] Feature request. Please use the label 'wish' on the issue.

 - [*] Task

As discussed on the dev list: https://lists.apache.org/thread/sc8pg8x0tghfhoh4ot39wgk57ynrty3w","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1405/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1407,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1407,incubator-stormcrawler,2656461610,1407,Investigate if XSoup is still needed,jnioche,218319,Julien Nioche,julien@digitalpebble.com,OPEN,2024-11-13T18:48:05Z,2024-12-19T13:00:23Z,"IIRC we use Xsoup to be able to run Xpath expressions on documents parsed with Jsoup.
Judging by https://jsoup.org/cookbook/extracting-data/xpath-syntax JSoup can handle XPath expression directly","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1407/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1407,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6YOGoS,incubator-stormcrawler,2553834002,1407,NA,rzo1,13417392,Richard Zowalla,,NA,2024-12-19T13:00:22Z,2024-12-19T13:00:22Z,"We are using non standard expression from XSoup which are not compliant with XPath 1.0 - if we want to migrate to JSoup only, we need to get rid of those additional function like `tidyText()`.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6YOGoS/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1408,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1408,incubator-stormcrawler,2661963896,1408,Run the release process for 3.2.0,tballison,6739646,Tim Allison,tallison@apache.org,CLOSED,2024-11-15T13:19:07Z,2024-12-10T21:47:00Z,"What kind of issue is this?

 - [ ] Question. This issue tracker is not the best place for questions. If you want to ask how to do
       something, or to understand why something isn't working the way you expect it to, use StackOverflow
       instead with the label 'stormcrawler': https://stackoverflow.com/questions/tagged/stormcrawler 

 - [ ] Bug report. If you’ve found a bug, please include a test if you can, it makes it a lot easier to fix things. Use the label 'bug' on the issue.
 
 - [ ] Feature request. Please use the label 'wish' on the issue.
 - [*] Task -- run the release process

First step is select a release manager on the list. I think we did this with: https://lists.apache.org/thread/nfvmfof3l2kgwcqvp4t4h4t4c9v1clo4

","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1408/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1408,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6Twn-C,incubator-stormcrawler,2478997378,1408,NA,tballison,6739646,Tim Allison,tallison@apache.org,NA,2024-11-15T14:17:50Z,2024-11-15T14:17:50Z,"@rzo1 @jnioche and other fellow devs. What are the diffs I should mention in the email for the 3.2.0 release?

* Numerous dependency updates and bug fixes
* Drop Java-based topologies
* Add support for shards in SolrSpout","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6Twn-C/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1408,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6TwpJj,incubator-stormcrawler,2479002211,1408,NA,rzo1,13417392,Richard Zowalla,,NA,2024-11-15T14:20:21Z,2024-11-15T14:20:21Z,"Yep sounds got. Maybe mention the websocket option for Playwright protocol. Otherwise, it is mostly the SOLR thing + dependency updates","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6TwpJj/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1408,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6TwwOP,incubator-stormcrawler,2479031183,1408,NA,tballison,6739646,Tim Allison,tallison@apache.org,NA,2024-11-15T14:35:55Z,2024-11-15T14:35:55Z,Should we add KEYS to `https://dist.apache.org/repos/dist/dev/` ?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6TwwOP/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1408,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6TwxEt,incubator-stormcrawler,2479034669,1408,NA,rzo1,13417392,Richard Zowalla,,NA,2024-11-15T14:37:45Z,2024-11-15T14:37:45Z,Keys should only reside here: https://dist.apache.org/repos/dist/release/incubator/stormcrawler/KEYS (same as https://downloads.apache.org/incubator/stormcrawler/KEYS ) per ASF Infra policies,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6TwxEt/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1408,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6TwyN9,incubator-stormcrawler,2479039357,1408,NA,tballison,6739646,Tim Allison,tallison@apache.org,NA,2024-11-15T14:40:15Z,2024-11-15T14:40:15Z,Confirming that I only place source files in `dist.apache.org` NO binaries?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6TwyN9/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1408,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6Twywi,incubator-stormcrawler,2479041570,1408,NA,rzo1,13417392,Richard Zowalla,,NA,2024-11-15T14:41:30Z,2024-11-15T14:41:30Z,"Right. We only vote on source technically, binaries (Maven) are convinience artifacts only.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6Twywi/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1408,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6Tw5S2,incubator-stormcrawler,2479068342,1408,NA,tballison,6739646,Tim Allison,tallison@apache.org,NA,2024-11-15T14:53:56Z,2024-11-15T14:53:56Z,"When I update the site, that's a global replace of `3.1.0` to `3.2.0`? Anything else?

The links will work only once the vote has passed and the artifacts are released, right? Or do I temporarily point the links to the rc1 artifacts?","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6Tw5S2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1408,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6TxAT6,incubator-stormcrawler,2479097082,1408,NA,tballison,6739646,Tim Allison,tallison@apache.org,NA,2024-11-15T15:06:21Z,2024-11-15T15:06:21Z,"In the vote email, sorry for this, where are the Github release notes? `<Add link to the GitHub release notes>`

I don't actually create the release from https://github.com/apache/incubator-stormcrawler/releases/tag/stormcrawler-3.2.0-rc1 until after the vote, right?
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6TxAT6/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1408,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6TxB-0,incubator-stormcrawler,2479103924,1408,NA,rzo1,13417392,Richard Zowalla,,NA,2024-11-15T15:09:25Z,2024-11-15T15:09:25Z,You can create GitHub Release notes on the right site and Mark the release as pre-release or draft.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6TxB-0/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1408,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6TxCg2,incubator-stormcrawler,2479106102,1408,NA,rzo1,13417392,Richard Zowalla,,NA,2024-11-15T15:10:20Z,2024-11-15T15:10:20Z,"> When I update the site, that's a global replace of `3.1.0` to `3.2.0`? Anything else?
> 
> The links will work only once the vote has passed and the artifacts are released, right? Or do I temporarily point the links to the rc1 artifacts?

Yes. It is a replacement and a staging deploy manually triggered via starting the related GitHub Action for your Branch with the Site update","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6TxCg2/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1408,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6TxtBP,incubator-stormcrawler,2479280207,1408,NA,tballison,6739646,Tim Allison,tallison@apache.org,NA,2024-11-15T15:48:59Z,2024-11-15T15:48:59Z,"Thank you @rzo1!

It looks like I should not have included `-rc1` in the tag. If there's a successful vote, I'll rename the tag and update the Github release.

If there's some better way of handling this, let me know.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6TxtBP/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1408,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6Txto1,incubator-stormcrawler,2479282741,1408,NA,rzo1,13417392,Richard Zowalla,,NA,2024-11-15T15:50:14Z,2024-11-15T15:50:14Z,Should be fine.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6Txto1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1408,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6W-gUO,incubator-stormcrawler,2532967694,1408,NA,tballison,6739646,Tim Allison,tallison@apache.org,NA,2024-12-10T21:47:00Z,2024-12-10T21:47:00Z,"All set. Thank you, all!","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6W-gUO/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1409,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1409,incubator-stormcrawler,2662064343,1409,"Unrecognized tag ""component"" in assembly.xml",tballison,6739646,Tim Allison,tallison@apache.org,CLOSED,2024-11-15T13:58:35Z,2024-11-15T14:01:28Z,"What kind of issue is this?

 - [ ] Question. This issue tracker is not the best place for questions. If you want to ask how to do
       something, or to understand why something isn't working the way you expect it to, use StackOverflow
       instead with the label 'stormcrawler': https://stackoverflow.com/questions/tagged/stormcrawler 

 - [ ] Bug report. If you’ve found a bug, please include a test if you can, it makes it a lot easier to fix things. Use the label 'bug' on the issue.
 
 - [ ] Feature request. Please use the label 'wish' on the issue.
 - [ *] Task -- update assembly.xml to remove <component/> wrapper. I'm guessing this doesn't work now because of an update in plugins since the last release? 

Thanks!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1409/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1411,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1411,incubator-stormcrawler,2662125718,1411,"Add ""Task"" to the ISSUE_TEMPLATE.md",tballison,6739646,Tim Allison,tallison@apache.org,OPEN,2024-11-15T14:22:06Z,2025-01-27T10:55:00Z,"What kind of issue is this?

 - [ ] Question. This issue tracker is not the best place for questions. If you want to ask how to do
       something, or to understand why something isn't working the way you expect it to, use StackOverflow
       instead with the label 'stormcrawler': https://stackoverflow.com/questions/tagged/stormcrawler 

 - [ ] Bug report. If you’ve found a bug, please include a test if you can, it makes it a lot easier to fix things. Use the label 'bug' on the issue.
 
 - [ ] Feature request. Please use the label 'wish' on the issue.

It might make sense to add a ""Task"" option to the issue template for dependency upgrades and other maintenance work that doesn't fall within ""bug"" or ""feature request"".","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1411/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1411,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6TyBKT,incubator-stormcrawler,2479362707,1411,NA,tballison,6739646,Tim Allison,tallison@apache.org,NA,2024-11-15T16:26:06Z,2024-11-15T16:26:06Z,"I'm opening this for discussion. I kind of want this, but I don't know if fellow devs would find it useful.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6TyBKT/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1411,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6b5E4f,incubator-stormcrawler,2615430687,1411,NA,rzo1,13417392,Richard Zowalla,,NA,2025-01-27T10:54:59Z,2025-01-27T10:54:59Z,Sounds good. Feel free @tballison ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6b5E4f/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1412,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1412,incubator-stormcrawler,2662144013,1412,Small tweaks to RELEASING.md,tballison,6739646,Tim Allison,tallison@apache.org,CLOSED,2024-11-15T14:31:57Z,2024-12-11T07:49:33Z,"What kind of issue is this?

 - [ ] Question. This issue tracker is not the best place for questions. If you want to ask how to do
       something, or to understand why something isn't working the way you expect it to, use StackOverflow
       instead with the label 'stormcrawler': https://stackoverflow.com/questions/tagged/stormcrawler 

 - [ ] Bug report. If you’ve found a bug, please include a test if you can, it makes it a lot easier to fix things. Use the label 'bug' on the issue.
 
 - [ ] Feature request. Please use the label 'wish' on the issue.

Thanks!
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1412/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1418,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1418,incubator-stormcrawler,2684615434,1418,Configure mockito as an agent,tballison,6739646,Tim Allison,tallison@apache.org,OPEN,2024-11-22T21:27:25Z,2024-11-22T21:27:25Z,"What kind of issue is this?

 - [ ] Question. This issue tracker is not the best place for questions. If you want to ask how to do
       something, or to understand why something isn't working the way you expect it to, use StackOverflow
       instead with the label 'stormcrawler': https://stackoverflow.com/questions/tagged/stormcrawler 

 - [ ] Bug report. If you’ve found a bug, please include a test if you can, it makes it a lot easier to fix things. Use the label 'bug' on the issue.
 
 - [* ] Feature request. Please use the label 'wish' on the issue.

Thanks!

This is a trivial task, not really a wish.

Follow the directions here: so that we don't get error messages during the build: https://javadoc.io/doc/org.mockito/mockito-core/latest/org/mockito/Mockito.html#0.3
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1418/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1436,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1436,incubator-stormcrawler,2717982457,1436,use log4j-bom dependency to ensure that log4j jars match,pjfanning,11783444,PJ Fanning,,CLOSED,2024-12-04T14:46:02Z,2024-12-19T07:42:54Z,"The log4j team have told the Apache POI team that they expect all log4j jar versions to match. Some context in https://issues.apache.org/jira/browse/XMLBEANS-654 

The aim is to change the pom in stormcrawler to have a depenendencyManagement declaration to import the log4j-bom.

Eg https://github.com/apache/xmlbeans/commit/9b342d1dc539f59e60806067b3388a32d07ceb85

We would then remove the version from the log4j dependency declarations elsewhere in the pom.
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1436/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1436,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6WMhSQ,incubator-stormcrawler,2519864464,1436,NA,rzo1,13417392,Richard Zowalla,,NA,2024-12-05T10:17:44Z,2024-12-05T10:17:44Z,Note: We rely on the version provided by Storm. We can actually remove all references to log4j2 in SC (as we use the one provided by the storm client) which will be available in the Storm Environment.,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6WMhSQ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1436,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6WM634,incubator-stormcrawler,2519969272,1436,NA,pjfanning,11783444,PJ Fanning,,NA,2024-12-05T10:55:08Z,2024-12-05T10:55:08Z,Can Storm be updated to use the bom dependency?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6WM634/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1436,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6WNgE7,incubator-stormcrawler,2520121659,1436,NA,rzo1,13417392,Richard Zowalla,,NA,2024-12-05T12:00:17Z,2024-12-05T12:00:17Z,"> Can Storm be updated to use the bom dependency?

https://github.com/apache/storm/blob/ef493269bda096e6bd03bb70985626a988b70a2d/pom.xml#L802C10-L809C25","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6WNgE7/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1436,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6YK3e_,incubator-stormcrawler,2552985535,1436,NA,rzo1,13417392,Richard Zowalla,,NA,2024-12-19T07:42:53Z,2024-12-19T07:42:53Z,"Storm is updated, so it gets available with the next version update. Think we can close this here.","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6YK3e_/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1448,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1448,incubator-stormcrawler,2780220520,1448,BasicUrlNomalizer Double Encoding of % when code is written in smaller letters ,mstrewe,15155589,Maik Piel,,CLOSED,2025-01-10T13:41:51Z,2025-01-28T10:57:51Z,"The BasicUrlNormalizer will encode links if they are not already URL  encoded. 

The Bug occurs when URL has encoded chars in smaller case like `'/Exhibitions/Detail/NjAxOA%3d%3d'`. (the URL `'/Exhibitions/Detail/NjAxOA%3D%3D'` is not affected)

In BasicUrlNormalizer.java from line 145-150 the file of the URL gets unescaped and escaped again. After that the original file and the es-unes-caped file are compared. It will be 

`Exhibitions/Detail/NjAxOA%3d%3d == Exhibitions/Detail/NjAxOA%3D%3D`   (Capital D)

After that the original source URL will be reacreated (line 154) and results in 'Exhibitions/Detail/NjAxOA%253D%253D' 



Can be fixed if the statement in line 148

```
 if (!file.equals(file2)) {
 ```

will changed to 

```
 if (!file.toLowerCase().equals(file2.toLowerCase())) {
```

UpperCase doesnt matter. But now it does not 
","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1448/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1448,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6Z8YO1,incubator-stormcrawler,2582741941,1448,NA,mstrewe,15155589,Maik Piel,,NA,2025-01-10T13:42:56Z,2025-01-10T13:42:56Z,Becuase I gave lines number. Its of commit https://github.com/apache/incubator-stormcrawler/commit/26f0ce35f457344427ae902e42d07c353bb5fc1d,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6Z8YO1/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1448,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6b5DfJ,incubator-stormcrawler,2615424969,1448,NA,rzo1,13417392,Richard Zowalla,,NA,2025-01-27T10:52:23Z,2025-01-27T10:52:23Z,Thanks for the report. Do you want to provide a PR with test for it?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6b5DfJ/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1448,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6cFaQo,incubator-stormcrawler,2618663976,1448,NA,mstrewe,15155589,Maik Piel,,NA,2025-01-28T10:57:50Z,2025-01-28T10:57:50Z,Bug not exist in current version. Found the problem on outdated version,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6cFaQo/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
issue,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1459,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1459,incubator-stormcrawler,2823855236,1459,Fix version numbers in READMEs,jnioche,218319,Julien Nioche,julien@digitalpebble.com,CLOSED,2025-01-31T15:53:04Z,2025-02-04T18:41:08Z,"Some of the READMEs were not fixed after the latest release and contain references to version 3.1.0

grep -r 3\\.1\\.0 .
```

./external/warc/README.md:        fields.put(""software:"", ""Apache StormCrawler 3.1.0 http://stormcrawler.net/"");
./external/warc/README.md:         - ""Apache StormCrawler 3.1.0 http://stormcrawler.net/""
./external/opensearch/README.md:`mvn archetype:generate -DarchetypeGroupId=org.apache.stormcrawler -DarchetypeArtifactId=stormcrawler-opensearch-archetype -DarchetypeVersion=3.1.0`
./README.md:mvn archetype:generate -DarchetypeGroupId=org.apache.stormcrawler -DarchetypeArtifactId=stormcrawler-archetype -DarchetypeVersion=3.1.0

```

The README in the solr module has a reference to SNAPSHOT","{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/1459/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1459,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6c1rh_,incubator-stormcrawler,2631317631,1459,NA,Brijeshthummar02,178184249,Brijesh Thummar,,NA,2025-02-03T15:23:49Z,2025-02-03T15:23:49Z,it should be updated in main readme and under external folder readme and pom.xml snapshot version right?,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6c1rh_/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1459,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6c1uU7,incubator-stormcrawler,2631329083,1459,NA,Brijeshthummar02,178184249,Brijesh Thummar,,NA,2025-02-03T15:28:05Z,2025-02-03T15:28:05Z,just provide me path to the files and what's latest version it need to be updated to,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6c1uU7/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
comment,https://api.github.com/repos/apache/incubator-stormcrawler/issues/1459,https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6dBdd7,incubator-stormcrawler,2634405755,1459,NA,rzo1,13417392,Richard Zowalla,,NA,2025-02-04T16:01:02Z,2025-02-04T16:01:02Z,@Brijeshthummar02 Just search for it in an IDE or use the command posted by @jnioche ,"{""url"": ""https://api.github.com/repos/apache/incubator-stormcrawler/issues/comments/IC_kwDOAI9eMc6dBdd7/reactions"", ""total_count"": 0, ""+1"": 0, ""-1"": 0, ""laugh"": 0, ""hooray"": 0, ""confused"": 0, ""heart"": 0, ""rocket"": 0, ""eyes"": 0}"
